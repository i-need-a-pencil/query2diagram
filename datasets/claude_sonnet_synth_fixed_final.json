[
  {
    "language": "C++",
    "code": "\n#ifndef ZEPHYR_SUBSYS_USBC_PRL_H_\n#define ZEPHYR_SUBSYS_USBC_PRL_H_\n\n#include <zephyr/kernel.h>\n#include <zephyr/usb_c/usbc.h>\n#include <zephyr/drivers/usb_c/usbc_tcpc.h>\n#include <zephyr/smf.h>\n\n#include \"usbc_pe_common_internal.h\"\n#include \"usbc_timer.h\"\n\n/**\n * @brief PD counter definitions\n *\t  See Table 6-63 Counter parameters\n *\t  Parameter Name: nMessageIDCount\n */\n#define PD_MESSAGE_ID_COUNT 7\n\n/**\n * @brief Message Reception State Machine Object\n */\nstruct protocol_layer_rx_t {\n\t/** state machine flags */\n\tatomic_t flags;\n\t/** message ids for all valid port partners */\n\tint msg_id[NUM_SOP_STAR_TYPES];\n\t/** Received Power Delivery Messages are stored in emsg */\n\tstruct pd_msg emsg;\n};\n\n/**\n * @brief Message Transmission State Machine Object\n */\nstruct protocol_layer_tx_t {\n\t/** state machine context */\n\tstruct smf_ctx ctx;\n\t/** Port device */\n\tconst struct device *dev;\n\t/** state machine flags */\n\tatomic_t flags;\n\t/** last packet type we transmitted */\n\tenum pd_packet_type last_xmit_type;\n\t/** Current message type to transmit */\n\tuint8_t msg_type;\n\t/**\n\t * Power Delivery Messages meant for transmission are stored\n\t * in emsg\n\t */\n\tstruct pd_msg emsg;\n\n\t/* Counters */\n\n\t/** message id counters for all 6 port partners */\n\tuint32_t msg_id_counter[NUM_SOP_STAR_TYPES];\n\n\t/* Timers */\n\n\t/** tTxTimeout timer */\n\tstruct usbc_timer_t pd_t_tx_timeout;\n\t/** tSinkTx timer */\n\tstruct usbc_timer_t pd_t_sink_tx;\n};\n\n/**\n * @brief Hard Reset State Machine Object\n */\nstruct protocol_hard_reset_t {\n\t/** state machine context */\n\tstruct smf_ctx ctx;\n\t/** Port device */\n\tconst struct device *dev;\n\t/** state machine flags */\n\tatomic_t flags;\n\n\t/* Timers */\n\n\t/** tHardResetComplete timer */\n\tstruct usbc_timer_t pd_t_hard_reset_complete;\n};\n\n/**\n * @brief This function must only be called in the subsystem init function.\n *\n * @param dev Pointer to the device structure for the driver instance.\n */\nvoid prl_subsys_init(const struct device *dev);\n\n/**\n * @brief Start the PRL Layer state machine. This is only called from the\n *\t  Type-C state machine.\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_start(const struct device *dev);\n\n/**\n * @brief Inform the PRL that the first message in an AMS is being sent\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_first_msg_notificaiton(const struct device *dev);\n\n/**\n * @brief Suspends the PRL Layer state machine. This is only called from the\n *\t  Type-C state machine.\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_suspend(const struct device *dev);\n\n/**\n * @brief Reset the PRL Layer state machine\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_reset(const struct device *dev);\n\n/**\n * @brief Run the PRL Layer state machine. This is called from the subsystems\n *\t  port stack thread\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_run(const struct device *dev);\n\n/**\n * @brief Called from the Policy Engine to signal that a hard reset is complete\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_hard_reset_complete(const struct device *dev);\n\n/**\n * @brief Sets the revision received from the port partner\n *\n * @param dev Pointer to the device structure for the driver instance\n * @param type SOP* packet sent from port partner\n * @param rev Revision sent from the port partner\n */\nvoid prl_set_rev(const struct device *dev, const enum pd_packet_type type,\n\t\t const enum pd_rev_type rev);\n\n/**\n * @brief Gets the revision received assciated with a packet type\n *\n * @param dev Pointer to the device structure for the driver instance\n * @param type SOP* packet type to get the revision for\n *\n * @retval revsion associated with the packet type\n */\nenum pd_rev_type prl_get_rev(const struct device *dev, const enum pd_packet_type type);\n\n/**\n * @brief Instructs the Protocol Layer to send a Power Delivery control message\n *\n * @param dev Pointer to the device structure for the driver instance\n * @param type The port partner to send this message to\n * @param msg The control message to send\n */\nvoid prl_send_ctrl_msg(const struct device *dev, const enum pd_packet_type type,\n\t\t       const enum pd_ctrl_msg_type msg);\n\n/**\n * @brief Instructs the Protocol Layer to send a Power Delivery data message\n *\n * @param dev Pointer to the device structure for the driver instance\n * @param type The port partner to send this message to\n * @param msg The data message to send\n */\nvoid prl_send_data_msg(const struct device *dev, const enum pd_packet_type type,\n\t\t       const enum pd_data_msg_type msg);\n\n/**\n * @brief Instructs the Protocol Layer to execute a hard reset\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_execute_hard_reset(const struct device *dev);\n\n/**\n * @brief Query if the Protocol Layer is running\n *\n * @param dev Pointer to the device structure for the driver instance\n *\n * @retval TRUE if the Protocol Layer is running\n * @retval FALSE if the Protocol Layer is not running\n */\nbool prl_is_running(const struct device *dev);\n\n#endif /* ZEPHYR_SUBSYS_USBC_PRL_H_ */",
    "repo": "zephyrproject-rtos/zephyr",
    "path": "./datasets/diagrams-repos/zephyrproject-rtos/zephyr/subsys/usb/usb_c/usbc_prl.h",
    "query": "What is the sequence of operations when the PRL starts and runs its state machine?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'prl_start', 'node_id': 'prl_start', 'description': 'Starts the PRL Layer state machine', 'visibility': 'public', 'return_type': 'void', 'params': 'const struct device *dev', 'source_class_id': None}, {'type': 'function', 'name': 'prl_run', 'node_id': 'prl_run', 'description': 'Runs the PRL Layer state machine in port stack thread', 'visibility': 'public', 'return_type': 'void', 'params': 'const struct device *dev', 'source_class_id': None}, {'type': 'entity', 'name': 'stateMachine', 'node_id': 'stateMachine', 'description': 'Protocol Layer State Machine', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'prl_start', 'node_id_to': 'stateMachine', 'description': 'initializes'}, {'node_id_from': 'prl_run', 'node_id_to': 'stateMachine', 'description': 'executes'}], 'packages': [{'package_id': 'protocolLayer', 'children': ['prl_start', 'prl_run', 'stateMachine'], 'description': 'Core Protocol Layer operations'}]}",
    "version": "minimal",
    "text_answer": "The PRL state machine sequence starts with prl_subsys_init for initialization, followed by prl_start to activate the state machine. The actual execution happens through repeated calls to prl_run in the port stack thread, which manages both transmission (protocol_layer_tx_t) and reception (protocol_layer_rx_t) state machines.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C++",
    "code": "\n#ifndef ZEPHYR_SUBSYS_USBC_PRL_H_\n#define ZEPHYR_SUBSYS_USBC_PRL_H_\n\n#include <zephyr/kernel.h>\n#include <zephyr/usb_c/usbc.h>\n#include <zephyr/drivers/usb_c/usbc_tcpc.h>\n#include <zephyr/smf.h>\n\n#include \"usbc_pe_common_internal.h\"\n#include \"usbc_timer.h\"\n\n/**\n * @brief PD counter definitions\n *\t  See Table 6-63 Counter parameters\n *\t  Parameter Name: nMessageIDCount\n */\n#define PD_MESSAGE_ID_COUNT 7\n\n/**\n * @brief Message Reception State Machine Object\n */\nstruct protocol_layer_rx_t {\n\t/** state machine flags */\n\tatomic_t flags;\n\t/** message ids for all valid port partners */\n\tint msg_id[NUM_SOP_STAR_TYPES];\n\t/** Received Power Delivery Messages are stored in emsg */\n\tstruct pd_msg emsg;\n};\n\n/**\n * @brief Message Transmission State Machine Object\n */\nstruct protocol_layer_tx_t {\n\t/** state machine context */\n\tstruct smf_ctx ctx;\n\t/** Port device */\n\tconst struct device *dev;\n\t/** state machine flags */\n\tatomic_t flags;\n\t/** last packet type we transmitted */\n\tenum pd_packet_type last_xmit_type;\n\t/** Current message type to transmit */\n\tuint8_t msg_type;\n\t/**\n\t * Power Delivery Messages meant for transmission are stored\n\t * in emsg\n\t */\n\tstruct pd_msg emsg;\n\n\t/* Counters */\n\n\t/** message id counters for all 6 port partners */\n\tuint32_t msg_id_counter[NUM_SOP_STAR_TYPES];\n\n\t/* Timers */\n\n\t/** tTxTimeout timer */\n\tstruct usbc_timer_t pd_t_tx_timeout;\n\t/** tSinkTx timer */\n\tstruct usbc_timer_t pd_t_sink_tx;\n};\n\n/**\n * @brief Hard Reset State Machine Object\n */\nstruct protocol_hard_reset_t {\n\t/** state machine context */\n\tstruct smf_ctx ctx;\n\t/** Port device */\n\tconst struct device *dev;\n\t/** state machine flags */\n\tatomic_t flags;\n\n\t/* Timers */\n\n\t/** tHardResetComplete timer */\n\tstruct usbc_timer_t pd_t_hard_reset_complete;\n};\n\n/**\n * @brief This function must only be called in the subsystem init function.\n *\n * @param dev Pointer to the device structure for the driver instance.\n */\nvoid prl_subsys_init(const struct device *dev);\n\n/**\n * @brief Start the PRL Layer state machine. This is only called from the\n *\t  Type-C state machine.\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_start(const struct device *dev);\n\n/**\n * @brief Inform the PRL that the first message in an AMS is being sent\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_first_msg_notificaiton(const struct device *dev);\n\n/**\n * @brief Suspends the PRL Layer state machine. This is only called from the\n *\t  Type-C state machine.\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_suspend(const struct device *dev);\n\n/**\n * @brief Reset the PRL Layer state machine\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_reset(const struct device *dev);\n\n/**\n * @brief Run the PRL Layer state machine. This is called from the subsystems\n *\t  port stack thread\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_run(const struct device *dev);\n\n/**\n * @brief Called from the Policy Engine to signal that a hard reset is complete\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_hard_reset_complete(const struct device *dev);\n\n/**\n * @brief Sets the revision received from the port partner\n *\n * @param dev Pointer to the device structure for the driver instance\n * @param type SOP* packet sent from port partner\n * @param rev Revision sent from the port partner\n */\nvoid prl_set_rev(const struct device *dev, const enum pd_packet_type type,\n\t\t const enum pd_rev_type rev);\n\n/**\n * @brief Gets the revision received assciated with a packet type\n *\n * @param dev Pointer to the device structure for the driver instance\n * @param type SOP* packet type to get the revision for\n *\n * @retval revsion associated with the packet type\n */\nenum pd_rev_type prl_get_rev(const struct device *dev, const enum pd_packet_type type);\n\n/**\n * @brief Instructs the Protocol Layer to send a Power Delivery control message\n *\n * @param dev Pointer to the device structure for the driver instance\n * @param type The port partner to send this message to\n * @param msg The control message to send\n */\nvoid prl_send_ctrl_msg(const struct device *dev, const enum pd_packet_type type,\n\t\t       const enum pd_ctrl_msg_type msg);\n\n/**\n * @brief Instructs the Protocol Layer to send a Power Delivery data message\n *\n * @param dev Pointer to the device structure for the driver instance\n * @param type The port partner to send this message to\n * @param msg The data message to send\n */\nvoid prl_send_data_msg(const struct device *dev, const enum pd_packet_type type,\n\t\t       const enum pd_data_msg_type msg);\n\n/**\n * @brief Instructs the Protocol Layer to execute a hard reset\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_execute_hard_reset(const struct device *dev);\n\n/**\n * @brief Query if the Protocol Layer is running\n *\n * @param dev Pointer to the device structure for the driver instance\n *\n * @retval TRUE if the Protocol Layer is running\n * @retval FALSE if the Protocol Layer is not running\n */\nbool prl_is_running(const struct device *dev);\n\n#endif /* ZEPHYR_SUBSYS_USBC_PRL_H_ */",
    "repo": "zephyrproject-rtos/zephyr",
    "path": "./datasets/diagrams-repos/zephyrproject-rtos/zephyr/subsys/usb/usb_c/usbc_prl.h",
    "query": "What is the sequence of operations when the PRL starts and runs its state machine?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'prl_subsys_init', 'node_id': 'prl_subsys_init', 'description': 'Initializes the PRL subsystem', 'visibility': 'public', 'return_type': 'void', 'params': 'const struct device *dev', 'source_class_id': None}, {'type': 'function', 'name': 'prl_start', 'node_id': 'prl_start', 'description': 'Starts the PRL Layer state machine', 'visibility': 'public', 'return_type': 'void', 'params': 'const struct device *dev', 'source_class_id': None}, {'type': 'function', 'name': 'prl_run', 'node_id': 'prl_run', 'description': 'Runs the PRL Layer state machine in port stack thread', 'visibility': 'public', 'return_type': 'void', 'params': 'const struct device *dev', 'source_class_id': None}, {'type': 'class', 'name': 'protocol_layer_tx_t', 'node_id': 'protocol_layer_tx_t', 'description': 'Message Transmission State Machine', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'protocol_layer_rx_t', 'node_id': 'protocol_layer_rx_t', 'description': 'Message Reception State Machine', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'stateMachine', 'node_id': 'stateMachine', 'description': 'Protocol Layer State Machine', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'prl_subsys_init', 'node_id_to': 'stateMachine', 'description': 'initializes subsystem'}, {'node_id_from': 'prl_start', 'node_id_to': 'stateMachine', 'description': 'starts'}, {'node_id_from': 'prl_run', 'node_id_to': 'stateMachine', 'description': 'executes'}, {'node_id_from': 'stateMachine', 'node_id_to': 'protocol_layer_tx_t', 'description': 'manages'}, {'node_id_from': 'stateMachine', 'node_id_to': 'protocol_layer_rx_t', 'description': 'manages'}], 'packages': [{'package_id': 'protocolLayer', 'children': ['prl_subsys_init', 'prl_start', 'prl_run', 'stateMachine', 'stateObjects'], 'description': 'Protocol Layer components'}, {'package_id': 'stateObjects', 'children': ['protocol_layer_tx_t', 'protocol_layer_rx_t'], 'description': 'State machine objects'}]}",
    "version": "medium",
    "text_answer": "The PRL state machine sequence starts with prl_subsys_init for initialization, followed by prl_start to activate the state machine. The actual execution happens through repeated calls to prl_run in the port stack thread, which manages both transmission (protocol_layer_tx_t) and reception (protocol_layer_rx_t) state machines.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C++",
    "code": "\n#ifndef ZEPHYR_SUBSYS_USBC_PRL_H_\n#define ZEPHYR_SUBSYS_USBC_PRL_H_\n\n#include <zephyr/kernel.h>\n#include <zephyr/usb_c/usbc.h>\n#include <zephyr/drivers/usb_c/usbc_tcpc.h>\n#include <zephyr/smf.h>\n\n#include \"usbc_pe_common_internal.h\"\n#include \"usbc_timer.h\"\n\n/**\n * @brief PD counter definitions\n *\t  See Table 6-63 Counter parameters\n *\t  Parameter Name: nMessageIDCount\n */\n#define PD_MESSAGE_ID_COUNT 7\n\n/**\n * @brief Message Reception State Machine Object\n */\nstruct protocol_layer_rx_t {\n\t/** state machine flags */\n\tatomic_t flags;\n\t/** message ids for all valid port partners */\n\tint msg_id[NUM_SOP_STAR_TYPES];\n\t/** Received Power Delivery Messages are stored in emsg */\n\tstruct pd_msg emsg;\n};\n\n/**\n * @brief Message Transmission State Machine Object\n */\nstruct protocol_layer_tx_t {\n\t/** state machine context */\n\tstruct smf_ctx ctx;\n\t/** Port device */\n\tconst struct device *dev;\n\t/** state machine flags */\n\tatomic_t flags;\n\t/** last packet type we transmitted */\n\tenum pd_packet_type last_xmit_type;\n\t/** Current message type to transmit */\n\tuint8_t msg_type;\n\t/**\n\t * Power Delivery Messages meant for transmission are stored\n\t * in emsg\n\t */\n\tstruct pd_msg emsg;\n\n\t/* Counters */\n\n\t/** message id counters for all 6 port partners */\n\tuint32_t msg_id_counter[NUM_SOP_STAR_TYPES];\n\n\t/* Timers */\n\n\t/** tTxTimeout timer */\n\tstruct usbc_timer_t pd_t_tx_timeout;\n\t/** tSinkTx timer */\n\tstruct usbc_timer_t pd_t_sink_tx;\n};\n\n/**\n * @brief Hard Reset State Machine Object\n */\nstruct protocol_hard_reset_t {\n\t/** state machine context */\n\tstruct smf_ctx ctx;\n\t/** Port device */\n\tconst struct device *dev;\n\t/** state machine flags */\n\tatomic_t flags;\n\n\t/* Timers */\n\n\t/** tHardResetComplete timer */\n\tstruct usbc_timer_t pd_t_hard_reset_complete;\n};\n\n/**\n * @brief This function must only be called in the subsystem init function.\n *\n * @param dev Pointer to the device structure for the driver instance.\n */\nvoid prl_subsys_init(const struct device *dev);\n\n/**\n * @brief Start the PRL Layer state machine. This is only called from the\n *\t  Type-C state machine.\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_start(const struct device *dev);\n\n/**\n * @brief Inform the PRL that the first message in an AMS is being sent\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_first_msg_notificaiton(const struct device *dev);\n\n/**\n * @brief Suspends the PRL Layer state machine. This is only called from the\n *\t  Type-C state machine.\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_suspend(const struct device *dev);\n\n/**\n * @brief Reset the PRL Layer state machine\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_reset(const struct device *dev);\n\n/**\n * @brief Run the PRL Layer state machine. This is called from the subsystems\n *\t  port stack thread\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_run(const struct device *dev);\n\n/**\n * @brief Called from the Policy Engine to signal that a hard reset is complete\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_hard_reset_complete(const struct device *dev);\n\n/**\n * @brief Sets the revision received from the port partner\n *\n * @param dev Pointer to the device structure for the driver instance\n * @param type SOP* packet sent from port partner\n * @param rev Revision sent from the port partner\n */\nvoid prl_set_rev(const struct device *dev, const enum pd_packet_type type,\n\t\t const enum pd_rev_type rev);\n\n/**\n * @brief Gets the revision received assciated with a packet type\n *\n * @param dev Pointer to the device structure for the driver instance\n * @param type SOP* packet type to get the revision for\n *\n * @retval revsion associated with the packet type\n */\nenum pd_rev_type prl_get_rev(const struct device *dev, const enum pd_packet_type type);\n\n/**\n * @brief Instructs the Protocol Layer to send a Power Delivery control message\n *\n * @param dev Pointer to the device structure for the driver instance\n * @param type The port partner to send this message to\n * @param msg The control message to send\n */\nvoid prl_send_ctrl_msg(const struct device *dev, const enum pd_packet_type type,\n\t\t       const enum pd_ctrl_msg_type msg);\n\n/**\n * @brief Instructs the Protocol Layer to send a Power Delivery data message\n *\n * @param dev Pointer to the device structure for the driver instance\n * @param type The port partner to send this message to\n * @param msg The data message to send\n */\nvoid prl_send_data_msg(const struct device *dev, const enum pd_packet_type type,\n\t\t       const enum pd_data_msg_type msg);\n\n/**\n * @brief Instructs the Protocol Layer to execute a hard reset\n *\n * @param dev Pointer to the device structure for the driver instance\n */\nvoid prl_execute_hard_reset(const struct device *dev);\n\n/**\n * @brief Query if the Protocol Layer is running\n *\n * @param dev Pointer to the device structure for the driver instance\n *\n * @retval TRUE if the Protocol Layer is running\n * @retval FALSE if the Protocol Layer is not running\n */\nbool prl_is_running(const struct device *dev);\n\n#endif /* ZEPHYR_SUBSYS_USBC_PRL_H_ */",
    "repo": "zephyrproject-rtos/zephyr",
    "path": "./datasets/diagrams-repos/zephyrproject-rtos/zephyr/subsys/usb/usb_c/usbc_prl.h",
    "query": "What is the sequence of operations when the PRL starts and runs its state machine?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'prl_subsys_init', 'node_id': 'prl_subsys_init', 'description': 'Initializes the PRL subsystem', 'visibility': 'public', 'return_type': 'void', 'params': 'const struct device *dev', 'source_class_id': None}, {'type': 'function', 'name': 'prl_start', 'node_id': 'prl_start', 'description': 'Starts the PRL Layer state machine', 'visibility': 'public', 'return_type': 'void', 'params': 'const struct device *dev', 'source_class_id': None}, {'type': 'function', 'name': 'prl_run', 'node_id': 'prl_run', 'description': 'Runs the PRL Layer state machine', 'visibility': 'public', 'return_type': 'void', 'params': 'const struct device *dev', 'source_class_id': None}, {'type': 'function', 'name': 'prl_reset', 'node_id': 'prl_reset', 'description': 'Resets the PRL Layer state machine', 'visibility': 'public', 'return_type': 'void', 'params': 'const struct device *dev', 'source_class_id': None}, {'type': 'function', 'name': 'prl_suspend', 'node_id': 'prl_suspend', 'description': 'Suspends the PRL Layer state machine', 'visibility': 'public', 'return_type': 'void', 'params': 'const struct device *dev', 'source_class_id': None}, {'type': 'class', 'name': 'protocol_layer_tx_t', 'node_id': 'protocol_layer_tx_t', 'description': 'Message Transmission State Machine', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'protocol_layer_rx_t', 'node_id': 'protocol_layer_rx_t', 'description': 'Message Reception State Machine', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'protocol_hard_reset_t', 'node_id': 'protocol_hard_reset_t', 'description': 'Hard Reset State Machine', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'stateMachine', 'node_id': 'stateMachine', 'description': 'Protocol Layer State Machine', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'prl_send_ctrl_msg', 'node_id': 'prl_send_ctrl_msg', 'description': 'Sends PD control message', 'visibility': 'public', 'return_type': 'void', 'params': 'const struct device *dev, const enum pd_packet_type type, const enum pd_ctrl_msg_type msg', 'source_class_id': None}, {'type': 'function', 'name': 'prl_send_data_msg', 'node_id': 'prl_send_data_msg', 'description': 'Sends PD data message', 'visibility': 'public', 'return_type': 'void', 'params': 'const struct device *dev, const enum pd_packet_type type, const enum pd_data_msg_type msg', 'source_class_id': None}], 'edges': [{'node_id_from': 'prl_subsys_init', 'node_id_to': 'stateMachine', 'description': 'initializes subsystem'}, {'node_id_from': 'prl_start', 'node_id_to': 'stateMachine', 'description': 'starts'}, {'node_id_from': 'prl_run', 'node_id_to': 'stateMachine', 'description': 'executes'}, {'node_id_from': 'prl_reset', 'node_id_to': 'stateMachine', 'description': 'resets'}, {'node_id_from': 'prl_suspend', 'node_id_to': 'stateMachine', 'description': 'suspends'}, {'node_id_from': 'stateMachine', 'node_id_to': 'protocol_layer_tx_t', 'description': 'manages'}, {'node_id_from': 'stateMachine', 'node_id_to': 'protocol_layer_rx_t', 'description': 'manages'}, {'node_id_from': 'stateMachine', 'node_id_to': 'protocol_hard_reset_t', 'description': 'manages'}, {'node_id_from': 'prl_send_ctrl_msg', 'node_id_to': 'protocol_layer_tx_t', 'description': 'uses'}, {'node_id_from': 'prl_send_data_msg', 'node_id_to': 'protocol_layer_tx_t', 'description': 'uses'}], 'packages': [{'package_id': 'protocolLayer', 'children': ['controlFunctions', 'stateObjects', 'messagingFunctions'], 'description': 'Protocol Layer components'}, {'package_id': 'controlFunctions', 'children': ['prl_subsys_init', 'prl_start', 'prl_run', 'prl_reset', 'prl_suspend'], 'description': 'State machine control functions'}, {'package_id': 'stateObjects', 'children': ['protocol_layer_tx_t', 'protocol_layer_rx_t', 'protocol_hard_reset_t', 'stateMachine'], 'description': 'State machine objects'}, {'package_id': 'messagingFunctions', 'children': ['prl_send_ctrl_msg', 'prl_send_data_msg'], 'description': 'Message handling functions'}]}",
    "version": "full",
    "text_answer": "The PRL state machine sequence starts with prl_subsys_init for initialization, followed by prl_start to activate the state machine. The actual execution happens through repeated calls to prl_run in the port stack thread, which manages both transmission (protocol_layer_tx_t) and reception (protocol_layer_rx_t) state machines.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { Worker } from '../page';\nimport type { CRBrowserContext } from './crBrowser';\nimport type { CRSession } from './crConnection';\nimport { CRExecutionContext } from './crExecutionContext';\nimport { CRNetworkManager } from './crNetworkManager';\nimport * as network from '../network';\nimport { BrowserContext } from '../browserContext';\n\nexport class CRServiceWorker extends Worker {\n  readonly _browserContext: CRBrowserContext;\n  readonly _networkManager?: CRNetworkManager;\n  private _session: CRSession;\n\n  constructor(browserContext: CRBrowserContext, session: CRSession, url: string) {\n    super(browserContext, url);\n    this._session = session;\n    this._browserContext = browserContext;\n    if (!!process.env.PW_EXPERIMENTAL_SERVICE_WORKER_NETWORK_EVENTS)\n      this._networkManager = new CRNetworkManager(null, this);\n    session.once('Runtime.executionContextCreated', event => {\n      this._createExecutionContext(new CRExecutionContext(session, event.context));\n    });\n\n    if (this._networkManager && this._isNetworkInspectionEnabled()) {\n      this.updateRequestInterception();\n      this.updateExtraHTTPHeaders();\n      this.updateHttpCredentials();\n      this.updateOffline();\n      this._networkManager.addSession(session, undefined, true /* isMain */).catch(() => {});\n    }\n\n    session.send('Runtime.enable', {}).catch(e => { });\n    session.send('Runtime.runIfWaitingForDebugger').catch(e => { });\n    session.on('Inspector.targetReloadedAfterCrash', () => {\n      // Resume service worker after restart.\n      session._sendMayFail('Runtime.runIfWaitingForDebugger', {});\n    });\n  }\n\n  override didClose() {\n    this._networkManager?.removeSession(this._session);\n    this._session.dispose();\n    super.didClose();\n  }\n\n  async updateOffline(): Promise<void> {\n    if (!this._isNetworkInspectionEnabled())\n      return;\n    await this._networkManager?.setOffline(!!this._browserContext._options.offline).catch(() => {});\n  }\n\n  async updateHttpCredentials(): Promise<void> {\n    if (!this._isNetworkInspectionEnabled())\n      return;\n    await this._networkManager?.authenticate(this._browserContext._options.httpCredentials || null).catch(() => {});\n  }\n\n  async updateExtraHTTPHeaders(): Promise<void> {\n    if (!this._isNetworkInspectionEnabled())\n      return;\n    await this._networkManager?.setExtraHTTPHeaders(this._browserContext._options.extraHTTPHeaders || []).catch(() => {});\n  }\n\n  async updateRequestInterception(): Promise<void> {\n    if (!this._isNetworkInspectionEnabled())\n      return;\n    await this._networkManager?.setRequestInterception(this.needsRequestInterception()).catch(() => {});\n  }\n\n  needsRequestInterception(): boolean {\n    return this._isNetworkInspectionEnabled() && !!this._browserContext._requestInterceptor;\n  }\n\n  reportRequestFinished(request: network.Request, response: network.Response | null) {\n    this._browserContext.emit(BrowserContext.Events.RequestFinished, { request, response });\n  }\n\n  requestFailed(request: network.Request, _canceled: boolean) {\n    this._browserContext.emit(BrowserContext.Events.RequestFailed, request);\n  }\n\n  requestReceivedResponse(response: network.Response) {\n    this._browserContext.emit(BrowserContext.Events.Response, response);\n  }\n\n  requestStarted(request: network.Request, route?: network.RouteDelegate) {\n    this._browserContext.emit(BrowserContext.Events.Request, request);\n    if (route) {\n      const r = new network.Route(request, route);\n      if (this._browserContext._requestInterceptor?.(r, request))\n        return;\n      r.continue({ isFallback: true }).catch(() => {});\n    }\n  }\n\n  private _isNetworkInspectionEnabled(): boolean {\n    return this._browserContext._options.serviceWorkers !== 'block';\n  }\n}",
    "repo": "microsoft/playwright",
    "path": "./datasets/diagrams-repos/microsoft/playwright/packages/playwright-core/src/server/chromium/crServiceWorker.ts",
    "query": "Map out the event listeners set up in the CRServiceWorker constructor and their corresponding actions.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'CRServiceWorker', 'node_id': 'CRServiceWorker', 'description': 'Service worker implementation for Chrome', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'constructor', 'node_id': 'constructor', 'description': 'Initializes service worker and sets up event listeners', 'visibility': 'public', 'return_type': None, 'params': 'browserContext: CRBrowserContext, session: CRSession, url: string', 'source_class_id': 'CRServiceWorker'}, {'type': 'entity', 'name': 'RuntimeExecutionContextCreated', 'node_id': 'RuntimeExecutionContextCreated', 'description': 'Event for creation of execution context', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'InspectorTargetReloadedAfterCrash', 'node_id': 'InspectorTargetReloadedAfterCrash', 'description': 'Event for service worker reload after crash', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'constructor', 'node_id_to': 'RuntimeExecutionContextCreated', 'description': 'Listens to create execution context'}, {'node_id_from': 'constructor', 'node_id_to': 'InspectorTargetReloadedAfterCrash', 'description': 'Listens to resume service worker'}, {'node_id_from': 'CRServiceWorker', 'node_id_to': 'constructor', 'description': ''}], 'packages': [{'package_id': 'eventListeners', 'children': ['RuntimeExecutionContextCreated', 'InspectorTargetReloadedAfterCrash'], 'description': 'Main event listeners in constructor'}]}",
    "version": "minimal",
    "text_answer": "The CRServiceWorker constructor sets up two main event listeners: 'Runtime.executionContextCreated' which triggers the creation of a new execution context, and 'Inspector.targetReloadedAfterCrash' which resumes the service worker after a crash. It also initializes runtime operations and network-related configurations if network inspection is enabled.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { Worker } from '../page';\nimport type { CRBrowserContext } from './crBrowser';\nimport type { CRSession } from './crConnection';\nimport { CRExecutionContext } from './crExecutionContext';\nimport { CRNetworkManager } from './crNetworkManager';\nimport * as network from '../network';\nimport { BrowserContext } from '../browserContext';\n\nexport class CRServiceWorker extends Worker {\n  readonly _browserContext: CRBrowserContext;\n  readonly _networkManager?: CRNetworkManager;\n  private _session: CRSession;\n\n  constructor(browserContext: CRBrowserContext, session: CRSession, url: string) {\n    super(browserContext, url);\n    this._session = session;\n    this._browserContext = browserContext;\n    if (!!process.env.PW_EXPERIMENTAL_SERVICE_WORKER_NETWORK_EVENTS)\n      this._networkManager = new CRNetworkManager(null, this);\n    session.once('Runtime.executionContextCreated', event => {\n      this._createExecutionContext(new CRExecutionContext(session, event.context));\n    });\n\n    if (this._networkManager && this._isNetworkInspectionEnabled()) {\n      this.updateRequestInterception();\n      this.updateExtraHTTPHeaders();\n      this.updateHttpCredentials();\n      this.updateOffline();\n      this._networkManager.addSession(session, undefined, true /* isMain */).catch(() => {});\n    }\n\n    session.send('Runtime.enable', {}).catch(e => { });\n    session.send('Runtime.runIfWaitingForDebugger').catch(e => { });\n    session.on('Inspector.targetReloadedAfterCrash', () => {\n      // Resume service worker after restart.\n      session._sendMayFail('Runtime.runIfWaitingForDebugger', {});\n    });\n  }\n\n  override didClose() {\n    this._networkManager?.removeSession(this._session);\n    this._session.dispose();\n    super.didClose();\n  }\n\n  async updateOffline(): Promise<void> {\n    if (!this._isNetworkInspectionEnabled())\n      return;\n    await this._networkManager?.setOffline(!!this._browserContext._options.offline).catch(() => {});\n  }\n\n  async updateHttpCredentials(): Promise<void> {\n    if (!this._isNetworkInspectionEnabled())\n      return;\n    await this._networkManager?.authenticate(this._browserContext._options.httpCredentials || null).catch(() => {});\n  }\n\n  async updateExtraHTTPHeaders(): Promise<void> {\n    if (!this._isNetworkInspectionEnabled())\n      return;\n    await this._networkManager?.setExtraHTTPHeaders(this._browserContext._options.extraHTTPHeaders || []).catch(() => {});\n  }\n\n  async updateRequestInterception(): Promise<void> {\n    if (!this._isNetworkInspectionEnabled())\n      return;\n    await this._networkManager?.setRequestInterception(this.needsRequestInterception()).catch(() => {});\n  }\n\n  needsRequestInterception(): boolean {\n    return this._isNetworkInspectionEnabled() && !!this._browserContext._requestInterceptor;\n  }\n\n  reportRequestFinished(request: network.Request, response: network.Response | null) {\n    this._browserContext.emit(BrowserContext.Events.RequestFinished, { request, response });\n  }\n\n  requestFailed(request: network.Request, _canceled: boolean) {\n    this._browserContext.emit(BrowserContext.Events.RequestFailed, request);\n  }\n\n  requestReceivedResponse(response: network.Response) {\n    this._browserContext.emit(BrowserContext.Events.Response, response);\n  }\n\n  requestStarted(request: network.Request, route?: network.RouteDelegate) {\n    this._browserContext.emit(BrowserContext.Events.Request, request);\n    if (route) {\n      const r = new network.Route(request, route);\n      if (this._browserContext._requestInterceptor?.(r, request))\n        return;\n      r.continue({ isFallback: true }).catch(() => {});\n    }\n  }\n\n  private _isNetworkInspectionEnabled(): boolean {\n    return this._browserContext._options.serviceWorkers !== 'block';\n  }\n}",
    "repo": "microsoft/playwright",
    "path": "./datasets/diagrams-repos/microsoft/playwright/packages/playwright-core/src/server/chromium/crServiceWorker.ts",
    "query": "Map out the event listeners set up in the CRServiceWorker constructor and their corresponding actions.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'CRServiceWorker', 'node_id': 'CRServiceWorker', 'description': 'Service worker implementation for Chrome', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'Runtime', 'node_id': 'Runtime', 'description': 'JavaScript execution environment manager', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'Inspector', 'node_id': 'Inspector', 'description': 'Monitors targets and handles browser debugging/crash recovery', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'constructor', 'node_id': 'constructor', 'description': 'Initializes service worker and sets up event listeners', 'visibility': 'public', 'return_type': 'void', 'params': 'browserContext: CRBrowserContext, session: CRSession, url: string', 'source_class_id': 'CRServiceWorker'}, {'type': 'method', 'name': 'executionContextCreated', 'node_id': 'executionContextCreated', 'description': 'Event for creation of execution context', 'visibility': 'public', 'return_type': 'void', 'params': 'event:  Any', 'source_class_id': 'Runtime'}, {'type': 'method', 'name': 'targetReloadedAfterCrash', 'node_id': 'targetReloadedAfterCrash', 'description': 'Event for service worker reload after crash', 'visibility': 'public', 'return_type': 'Promise', 'params': '', 'source_class_id': 'Inspector'}, {'type': 'method', 'name': '_createExecutionContext', 'node_id': '_createExecutionContext', 'description': 'Creates new execution context', 'visibility': 'private', 'return_type': 'void', 'params': 'context: CRExecutionContext', 'source_class_id': 'CRServiceWorker'}, {'type': 'method', 'name': 'enable', 'node_id': 'enable', 'description': 'Enables runtime', 'visibility': 'public', 'return_type': 'Promise', 'params': '', 'source_class_id': 'Runtime'}, {'type': 'method', 'name': 'runIfWaitingForDebugger', 'node_id': 'runIfWaitingForDebugger', 'description': 'Runs if waiting for debugger', 'visibility': 'public', 'return_type': 'Promise', 'params': '', 'source_class_id': 'Runtime'}], 'edges': [{'node_id_from': 'constructor', 'node_id_to': 'executionContextCreated', 'description': 'Listens to create execution context'}, {'node_id_from': 'constructor', 'node_id_to': 'Inspector', 'description': 'Listens to resume service worker'}, {'node_id_from': 'executionContextCreated', 'node_id_to': '_createExecutionContext', 'description': 'Triggers context creation'}, {'node_id_from': 'constructor', 'node_id_to': 'enable', 'description': 'Enables runtime'}, {'node_id_from': 'constructor', 'node_id_to': 'runIfWaitingForDebugger', 'description': 'Runs if waiting for debugger'}, {'node_id_from': 'constructor', 'node_id_to': 'targetReloadedAfterCrash', 'description': 'Sets up reload service worker after crash'}, {'node_id_from': 'Runtime', 'node_id_to': 'executionContextCreated', 'description': ''}, {'node_id_from': 'Runtime', 'node_id_to': 'enable', 'description': ''}, {'node_id_from': 'Runtime', 'node_id_to': 'runIfWaitingForDebugger', 'description': ''}, {'node_id_from': 'Inspector', 'node_id_to': 'targetReloadedAfterCrash', 'description': ''}, {'node_id_from': 'CRServiceWorker', 'node_id_to': 'constructor', 'description': ''}, {'node_id_from': 'CRServiceWorker', 'node_id_to': '_createExecutionContext', 'description': ''}], 'packages': [{'package_id': 'eventListeners', 'children': ['executionContextCreated', 'targetReloadedAfterCrash'], 'description': 'Main event listeners in constructor'}, {'package_id': 'runtimeOperations', 'children': ['enable', 'runIfWaitingForDebugger'], 'description': 'Runtime-related operations'}]}",
    "version": "medium",
    "text_answer": "The CRServiceWorker constructor sets up two main event listeners: 'Runtime.executionContextCreated' which triggers the creation of a new execution context, and 'Inspector.targetReloadedAfterCrash' which resumes the service worker after a crash. It also initializes runtime operations and network-related configurations if network inspection is enabled.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { Worker } from '../page';\nimport type { CRBrowserContext } from './crBrowser';\nimport type { CRSession } from './crConnection';\nimport { CRExecutionContext } from './crExecutionContext';\nimport { CRNetworkManager } from './crNetworkManager';\nimport * as network from '../network';\nimport { BrowserContext } from '../browserContext';\n\nexport class CRServiceWorker extends Worker {\n  readonly _browserContext: CRBrowserContext;\n  readonly _networkManager?: CRNetworkManager;\n  private _session: CRSession;\n\n  constructor(browserContext: CRBrowserContext, session: CRSession, url: string) {\n    super(browserContext, url);\n    this._session = session;\n    this._browserContext = browserContext;\n    if (!!process.env.PW_EXPERIMENTAL_SERVICE_WORKER_NETWORK_EVENTS)\n      this._networkManager = new CRNetworkManager(null, this);\n    session.once('Runtime.executionContextCreated', event => {\n      this._createExecutionContext(new CRExecutionContext(session, event.context));\n    });\n\n    if (this._networkManager && this._isNetworkInspectionEnabled()) {\n      this.updateRequestInterception();\n      this.updateExtraHTTPHeaders();\n      this.updateHttpCredentials();\n      this.updateOffline();\n      this._networkManager.addSession(session, undefined, true /* isMain */).catch(() => {});\n    }\n\n    session.send('Runtime.enable', {}).catch(e => { });\n    session.send('Runtime.runIfWaitingForDebugger').catch(e => { });\n    session.on('Inspector.targetReloadedAfterCrash', () => {\n      // Resume service worker after restart.\n      session._sendMayFail('Runtime.runIfWaitingForDebugger', {});\n    });\n  }\n\n  override didClose() {\n    this._networkManager?.removeSession(this._session);\n    this._session.dispose();\n    super.didClose();\n  }\n\n  async updateOffline(): Promise<void> {\n    if (!this._isNetworkInspectionEnabled())\n      return;\n    await this._networkManager?.setOffline(!!this._browserContext._options.offline).catch(() => {});\n  }\n\n  async updateHttpCredentials(): Promise<void> {\n    if (!this._isNetworkInspectionEnabled())\n      return;\n    await this._networkManager?.authenticate(this._browserContext._options.httpCredentials || null).catch(() => {});\n  }\n\n  async updateExtraHTTPHeaders(): Promise<void> {\n    if (!this._isNetworkInspectionEnabled())\n      return;\n    await this._networkManager?.setExtraHTTPHeaders(this._browserContext._options.extraHTTPHeaders || []).catch(() => {});\n  }\n\n  async updateRequestInterception(): Promise<void> {\n    if (!this._isNetworkInspectionEnabled())\n      return;\n    await this._networkManager?.setRequestInterception(this.needsRequestInterception()).catch(() => {});\n  }\n\n  needsRequestInterception(): boolean {\n    return this._isNetworkInspectionEnabled() && !!this._browserContext._requestInterceptor;\n  }\n\n  reportRequestFinished(request: network.Request, response: network.Response | null) {\n    this._browserContext.emit(BrowserContext.Events.RequestFinished, { request, response });\n  }\n\n  requestFailed(request: network.Request, _canceled: boolean) {\n    this._browserContext.emit(BrowserContext.Events.RequestFailed, request);\n  }\n\n  requestReceivedResponse(response: network.Response) {\n    this._browserContext.emit(BrowserContext.Events.Response, response);\n  }\n\n  requestStarted(request: network.Request, route?: network.RouteDelegate) {\n    this._browserContext.emit(BrowserContext.Events.Request, request);\n    if (route) {\n      const r = new network.Route(request, route);\n      if (this._browserContext._requestInterceptor?.(r, request))\n        return;\n      r.continue({ isFallback: true }).catch(() => {});\n    }\n  }\n\n  private _isNetworkInspectionEnabled(): boolean {\n    return this._browserContext._options.serviceWorkers !== 'block';\n  }\n}",
    "repo": "microsoft/playwright",
    "path": "./datasets/diagrams-repos/microsoft/playwright/packages/playwright-core/src/server/chromium/crServiceWorker.ts",
    "query": "Map out the event listeners set up in the CRServiceWorker constructor and their corresponding actions.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'CRServiceWorker', 'node_id': 'CRServiceWorker', 'description': 'Service worker implementation for Chrome', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'Runtime', 'node_id': 'Runtime', 'description': 'JavaScript execution environment manager', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'Inspector', 'node_id': 'Inspector', 'description': 'Monitors targets and handles browser debugging/crash recovery', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'constructor', 'node_id': 'constructor', 'description': 'Initializes service worker and sets up event listeners', 'visibility': 'public', 'return_type': 'void', 'params': 'browserContext: CRBrowserContext, session: CRSession, url: string', 'source_class_id': 'CRServiceWorker'}, {'type': 'method', 'name': 'executionContextCreated', 'node_id': 'executionContextCreated', 'description': 'Event for creation of execution context', 'visibility': 'public', 'return_type': 'void', 'params': 'event:  Any', 'source_class_id': 'Runtime'}, {'type': 'method', 'name': 'targetReloadedAfterCrash', 'node_id': 'targetReloadedAfterCrash', 'description': 'Event for service worker reload after crash', 'visibility': 'public', 'return_type': 'Promise', 'params': '', 'source_class_id': 'Inspector'}, {'type': 'method', 'name': '_createExecutionContext', 'node_id': '_createExecutionContext', 'description': 'Creates new execution context', 'visibility': 'private', 'return_type': 'void', 'params': 'context: CRExecutionContext', 'source_class_id': 'CRServiceWorker'}, {'type': 'method', 'name': 'enable', 'node_id': 'enable', 'description': 'Enables runtime', 'visibility': 'public', 'return_type': 'Promise', 'params': '', 'source_class_id': 'Runtime'}, {'type': 'method', 'name': 'runIfWaitingForDebugger', 'node_id': 'runIfWaitingForDebugger', 'description': 'Runs if waiting for debugger', 'visibility': 'public', 'return_type': 'Promise', 'params': '', 'source_class_id': 'Runtime'}, {'type': 'method', 'name': 'updateRequestInterception', 'node_id': 'updateRequestInterception', 'description': 'Updates request interception settings', 'visibility': 'public', 'return_type': 'Promise<void>', 'params': '', 'source_class_id': 'CRServiceWorker'}, {'type': 'method', 'name': 'updateExtraHTTPHeaders', 'node_id': 'updateExtraHTTPHeaders', 'description': 'Updates extra HTTP headers', 'visibility': 'public', 'return_type': 'Promise<void>', 'params': '', 'source_class_id': 'CRServiceWorker'}, {'type': 'method', 'name': 'updateHttpCredentials', 'node_id': 'updateHttpCredentials', 'description': 'Updates HTTP credentials', 'visibility': 'public', 'return_type': 'Promise<void>', 'params': '', 'source_class_id': 'CRServiceWorker'}, {'type': 'method', 'name': 'updateOffline', 'node_id': 'updateOffline', 'description': 'Updates offline mode', 'visibility': 'public', 'return_type': 'Promise<void>', 'params': '', 'source_class_id': 'CRServiceWorker'}], 'edges': [{'node_id_from': 'constructor', 'node_id_to': 'executionContextCreated', 'description': 'Listens to create execution context'}, {'node_id_from': 'constructor', 'node_id_to': 'Inspector', 'description': 'Listens to resume service worker'}, {'node_id_from': 'executionContextCreated', 'node_id_to': '_createExecutionContext', 'description': 'Triggers context creation'}, {'node_id_from': 'constructor', 'node_id_to': 'enable', 'description': 'Enables runtime'}, {'node_id_from': 'constructor', 'node_id_to': 'runIfWaitingForDebugger', 'description': 'Runs if waiting for debugger'}, {'node_id_from': 'constructor', 'node_id_to': 'updateRequestInterception', 'description': 'Sets up request interception'}, {'node_id_from': 'constructor', 'node_id_to': 'updateExtraHTTPHeaders', 'description': 'Sets up HTTP headers'}, {'node_id_from': 'constructor', 'node_id_to': 'updateHttpCredentials', 'description': 'Sets up HTTP credentials'}, {'node_id_from': 'constructor', 'node_id_to': 'updateOffline', 'description': 'Sets up offline mode'}, {'node_id_from': 'constructor', 'node_id_to': 'targetReloadedAfterCrash', 'description': 'Sets up reload service worker after crash'}, {'node_id_from': 'Runtime', 'node_id_to': 'executionContextCreated', 'description': ''}, {'node_id_from': 'Runtime', 'node_id_to': 'enable', 'description': ''}, {'node_id_from': 'Runtime', 'node_id_to': 'runIfWaitingForDebugger', 'description': ''}, {'node_id_from': 'Inspector', 'node_id_to': 'targetReloadedAfterCrash', 'description': ''}, {'node_id_from': 'CRServiceWorker', 'node_id_to': 'constructor', 'description': ''}, {'node_id_from': 'CRServiceWorker', 'node_id_to': '_createExecutionContext', 'description': ''}, {'node_id_from': 'CRServiceWorker', 'node_id_to': 'updateRequestInterception', 'description': ''}, {'node_id_from': 'CRServiceWorker', 'node_id_to': 'updateExtraHTTPHeaders', 'description': ''}, {'node_id_from': 'CRServiceWorker', 'node_id_to': 'updateHttpCredentials', 'description': ''}, {'node_id_from': 'CRServiceWorker', 'node_id_to': 'updateOffline', 'description': ''}], 'packages': [{'package_id': 'eventListeners', 'children': ['executionContextCreated', 'targetReloadedAfterCrash'], 'description': 'Main event listeners in constructor'}, {'package_id': 'runtimeOperations', 'children': ['enable', 'runIfWaitingForDebugger'], 'description': 'Runtime-related operations'}, {'package_id': 'networkSetup', 'children': ['updateRequestInterception', 'updateExtraHTTPHeaders', 'updateHttpCredentials', 'updateOffline'], 'description': 'Network-related setup operations'}]}",
    "version": "full",
    "text_answer": "The CRServiceWorker constructor sets up two main event listeners: 'Runtime.executionContextCreated' which triggers the creation of a new execution context, and 'Inspector.targetReloadedAfterCrash' which resumes the service worker after a crash. It also initializes runtime operations and network-related configurations if network inspection is enabled.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { VTextField } from '../VTextField'\n\n// Utilities\nimport { mount } from '@vue/test-utils'\nimport { createVuetify } from '@/framework'\n\ndescribe('VTextField', () => {\n  const vuetify = createVuetify()\n\n  function mountFunction (component: any, options = {}) {\n    return mount(component, {\n      global: {\n        plugins: [vuetify],\n      },\n      ...options,\n    })\n  }\n\n  it('has affixed icons', () => {\n    const wrapper = mountFunction(\n      <VTextField\n        prependIcon=\"$vuetify\"\n        prependInnerIcon=\"$vuetify\"\n        appendInnerIcon=\"$vuetify\"\n        appendIcon=\"$vuetify\"\n      />\n    )\n\n    let el = wrapper.find('.v-input__prepend .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('true')\n    expect(el.attributes('aria-label')).toBeUndefined()\n\n    el = wrapper.find('.v-field__prepend-inner .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('true')\n    expect(el.attributes('aria-label')).toBeUndefined()\n\n    el = wrapper.find('.v-field__append-inner .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('true')\n    expect(el.attributes('aria-label')).toBeUndefined()\n\n    el = wrapper.find('.v-input__append .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('true')\n    expect(el.attributes('aria-label')).toBeUndefined()\n  })\n\n  it('has affixed icons with actions', () => {\n    const onClickPrepend = vi.fn()\n    const onClickPrependInner = vi.fn()\n    const onClickAppendInner = vi.fn()\n    const onClickAppend = vi.fn()\n\n    const wrapper = mountFunction(\n      <VTextField\n        prependIcon=\"$vuetify\"\n        prependInnerIcon=\"$vuetify\"\n        appendInnerIcon=\"$vuetify\"\n        appendIcon=\"$vuetify\"\n        onClick:prepend={ onClickPrepend }\n        onClick:prependInner={ onClickPrependInner }\n        onClick:appendInner={ onClickAppendInner }\n        onClick:append={ onClickAppend }\n      />\n    )\n\n    expect(onClickPrepend).toHaveBeenCalledTimes(0)\n    expect(onClickPrependInner).toHaveBeenCalledTimes(0)\n    expect(onClickAppendInner).toHaveBeenCalledTimes(0)\n    expect(onClickAppend).toHaveBeenCalledTimes(0)\n\n    let el = wrapper.find('.v-input__prepend .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('false')\n    expect(el.attributes('aria-label')).toBeTruthy()\n    el.trigger('click')\n    expect(onClickPrepend).toHaveBeenCalledTimes(1)\n\n    el = wrapper.find('.v-field__prepend-inner .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('false')\n    expect(el.attributes('aria-label')).toBeTruthy()\n    el.trigger('click')\n    expect(onClickPrependInner).toHaveBeenCalledTimes(1)\n\n    el = wrapper.find('.v-field__append-inner .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('false')\n    expect(el.attributes('aria-label')).toBeTruthy()\n    el.trigger('click')\n    expect(onClickAppendInner).toHaveBeenCalledTimes(1)\n\n    el = wrapper.find('.v-input__append .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('false')\n    expect(el.attributes('aria-label')).toBeTruthy()\n    el.trigger('click')\n    expect(onClickAppend).toHaveBeenCalledTimes(1)\n\n    expect(onClickPrepend).toHaveBeenCalledTimes(1)\n    expect(onClickPrependInner).toHaveBeenCalledTimes(1)\n    expect(onClickAppendInner).toHaveBeenCalledTimes(1)\n  })\n})",
    "repo": "vuetifyjs/vuetify",
    "path": "./datasets/diagrams-repos/vuetifyjs/vuetify/packages/vuetify/src/components/VTextField/__tests__/VTextField.spec.tsx",
    "query": "Visalize the test case 'has affixed icons with actions', showing the sequence of operations, including clicks and function calls.",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'mountFunction', 'node_id': 'mountFunction', 'description': 'Helper function to mount component with Vuetify plugin', 'visibility': 'private', 'return_type': 'VueWrapper', 'params': 'component, options', 'source_class_id': None}, {'type': 'class', 'name': 'VTextField', 'node_id': 'VTextField', 'description': 'Vuetify text field component with icon slots', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'clickHandler', 'node_id': 'clickHandler', 'description': 'Click event handler for icons', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'mountFunction', 'node_id_to': 'VTextField', 'description': 'mounts'}, {'node_id_from': 'VTextField', 'node_id_to': 'clickHandler', 'description': 'triggers'}], 'packages': [{'package_id': 'testCase', 'children': ['mountFunction', 'clickHandler'], 'description': 'Test case implementation'}]}",
    "version": "minimal",
    "text_answer": "The test mounts a VTextField component with four icon slots, then simulates clicks on each icon, verifying that the corresponding click handlers are called exactly once and checking the accessibility attributes before and after interactions.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { VTextField } from '../VTextField'\n\n// Utilities\nimport { mount } from '@vue/test-utils'\nimport { createVuetify } from '@/framework'\n\ndescribe('VTextField', () => {\n  const vuetify = createVuetify()\n\n  function mountFunction (component: any, options = {}) {\n    return mount(component, {\n      global: {\n        plugins: [vuetify],\n      },\n      ...options,\n    })\n  }\n\n  it('has affixed icons', () => {\n    const wrapper = mountFunction(\n      <VTextField\n        prependIcon=\"$vuetify\"\n        prependInnerIcon=\"$vuetify\"\n        appendInnerIcon=\"$vuetify\"\n        appendIcon=\"$vuetify\"\n      />\n    )\n\n    let el = wrapper.find('.v-input__prepend .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('true')\n    expect(el.attributes('aria-label')).toBeUndefined()\n\n    el = wrapper.find('.v-field__prepend-inner .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('true')\n    expect(el.attributes('aria-label')).toBeUndefined()\n\n    el = wrapper.find('.v-field__append-inner .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('true')\n    expect(el.attributes('aria-label')).toBeUndefined()\n\n    el = wrapper.find('.v-input__append .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('true')\n    expect(el.attributes('aria-label')).toBeUndefined()\n  })\n\n  it('has affixed icons with actions', () => {\n    const onClickPrepend = vi.fn()\n    const onClickPrependInner = vi.fn()\n    const onClickAppendInner = vi.fn()\n    const onClickAppend = vi.fn()\n\n    const wrapper = mountFunction(\n      <VTextField\n        prependIcon=\"$vuetify\"\n        prependInnerIcon=\"$vuetify\"\n        appendInnerIcon=\"$vuetify\"\n        appendIcon=\"$vuetify\"\n        onClick:prepend={ onClickPrepend }\n        onClick:prependInner={ onClickPrependInner }\n        onClick:appendInner={ onClickAppendInner }\n        onClick:append={ onClickAppend }\n      />\n    )\n\n    expect(onClickPrepend).toHaveBeenCalledTimes(0)\n    expect(onClickPrependInner).toHaveBeenCalledTimes(0)\n    expect(onClickAppendInner).toHaveBeenCalledTimes(0)\n    expect(onClickAppend).toHaveBeenCalledTimes(0)\n\n    let el = wrapper.find('.v-input__prepend .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('false')\n    expect(el.attributes('aria-label')).toBeTruthy()\n    el.trigger('click')\n    expect(onClickPrepend).toHaveBeenCalledTimes(1)\n\n    el = wrapper.find('.v-field__prepend-inner .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('false')\n    expect(el.attributes('aria-label')).toBeTruthy()\n    el.trigger('click')\n    expect(onClickPrependInner).toHaveBeenCalledTimes(1)\n\n    el = wrapper.find('.v-field__append-inner .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('false')\n    expect(el.attributes('aria-label')).toBeTruthy()\n    el.trigger('click')\n    expect(onClickAppendInner).toHaveBeenCalledTimes(1)\n\n    el = wrapper.find('.v-input__append .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('false')\n    expect(el.attributes('aria-label')).toBeTruthy()\n    el.trigger('click')\n    expect(onClickAppend).toHaveBeenCalledTimes(1)\n\n    expect(onClickPrepend).toHaveBeenCalledTimes(1)\n    expect(onClickPrependInner).toHaveBeenCalledTimes(1)\n    expect(onClickAppendInner).toHaveBeenCalledTimes(1)\n  })\n})",
    "repo": "vuetifyjs/vuetify",
    "path": "./datasets/diagrams-repos/vuetifyjs/vuetify/packages/vuetify/src/components/VTextField/__tests__/VTextField.spec.tsx",
    "query": "Visalize the test case 'has affixed icons with actions', showing the sequence of operations, including clicks and function calls.",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'mountFunction', 'node_id': 'mountFunction', 'description': 'Helper function to mount component with Vuetify plugin', 'visibility': 'private', 'return_type': 'VueWrapper', 'params': 'component, options', 'source_class_id': None}, {'type': 'class', 'name': 'VTextField', 'node_id': 'VTextField', 'description': 'Vuetify text field component with icon slots', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'onClickPrepend', 'node_id': 'onClickPrepend', 'description': 'Click handler for prepend icon', 'visibility': 'private', 'return_type': 'void', 'params': 'event', 'source_class_id': None}, {'type': 'function', 'name': 'onClickAppend', 'node_id': 'onClickAppend', 'description': 'Click handler for append icon', 'visibility': 'private', 'return_type': 'void', 'params': 'event', 'source_class_id': None}, {'type': 'entity', 'name': 'iconTrigger', 'node_id': 'iconTrigger', 'description': 'Icon click event simulation', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'mountFunction', 'node_id_to': 'VTextField', 'description': 'mounts'}, {'node_id_from': 'iconTrigger', 'node_id_to': 'onClickPrepend', 'description': 'triggers'}, {'node_id_from': 'iconTrigger', 'node_id_to': 'onClickAppend', 'description': 'triggers'}, {'node_id_from': 'VTextField', 'node_id_to': 'iconTrigger', 'description': 'listen to'}], 'packages': [{'package_id': 'testCase', 'children': ['mountFunction', 'onClickPrepend', 'onClickAppend', 'iconTrigger'], 'description': 'Test case implementation'}]}",
    "version": "medium",
    "text_answer": "The test mounts a VTextField component with four icon slots, then simulates clicks on each icon, verifying that the corresponding click handlers are called exactly once and checking the accessibility attributes before and after interactions.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { VTextField } from '../VTextField'\n\n// Utilities\nimport { mount } from '@vue/test-utils'\nimport { createVuetify } from '@/framework'\n\ndescribe('VTextField', () => {\n  const vuetify = createVuetify()\n\n  function mountFunction (component: any, options = {}) {\n    return mount(component, {\n      global: {\n        plugins: [vuetify],\n      },\n      ...options,\n    })\n  }\n\n  it('has affixed icons', () => {\n    const wrapper = mountFunction(\n      <VTextField\n        prependIcon=\"$vuetify\"\n        prependInnerIcon=\"$vuetify\"\n        appendInnerIcon=\"$vuetify\"\n        appendIcon=\"$vuetify\"\n      />\n    )\n\n    let el = wrapper.find('.v-input__prepend .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('true')\n    expect(el.attributes('aria-label')).toBeUndefined()\n\n    el = wrapper.find('.v-field__prepend-inner .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('true')\n    expect(el.attributes('aria-label')).toBeUndefined()\n\n    el = wrapper.find('.v-field__append-inner .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('true')\n    expect(el.attributes('aria-label')).toBeUndefined()\n\n    el = wrapper.find('.v-input__append .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('true')\n    expect(el.attributes('aria-label')).toBeUndefined()\n  })\n\n  it('has affixed icons with actions', () => {\n    const onClickPrepend = vi.fn()\n    const onClickPrependInner = vi.fn()\n    const onClickAppendInner = vi.fn()\n    const onClickAppend = vi.fn()\n\n    const wrapper = mountFunction(\n      <VTextField\n        prependIcon=\"$vuetify\"\n        prependInnerIcon=\"$vuetify\"\n        appendInnerIcon=\"$vuetify\"\n        appendIcon=\"$vuetify\"\n        onClick:prepend={ onClickPrepend }\n        onClick:prependInner={ onClickPrependInner }\n        onClick:appendInner={ onClickAppendInner }\n        onClick:append={ onClickAppend }\n      />\n    )\n\n    expect(onClickPrepend).toHaveBeenCalledTimes(0)\n    expect(onClickPrependInner).toHaveBeenCalledTimes(0)\n    expect(onClickAppendInner).toHaveBeenCalledTimes(0)\n    expect(onClickAppend).toHaveBeenCalledTimes(0)\n\n    let el = wrapper.find('.v-input__prepend .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('false')\n    expect(el.attributes('aria-label')).toBeTruthy()\n    el.trigger('click')\n    expect(onClickPrepend).toHaveBeenCalledTimes(1)\n\n    el = wrapper.find('.v-field__prepend-inner .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('false')\n    expect(el.attributes('aria-label')).toBeTruthy()\n    el.trigger('click')\n    expect(onClickPrependInner).toHaveBeenCalledTimes(1)\n\n    el = wrapper.find('.v-field__append-inner .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('false')\n    expect(el.attributes('aria-label')).toBeTruthy()\n    el.trigger('click')\n    expect(onClickAppendInner).toHaveBeenCalledTimes(1)\n\n    el = wrapper.find('.v-input__append .v-icon')\n    expect(el.attributes('aria-hidden')).toBe('false')\n    expect(el.attributes('aria-label')).toBeTruthy()\n    el.trigger('click')\n    expect(onClickAppend).toHaveBeenCalledTimes(1)\n\n    expect(onClickPrepend).toHaveBeenCalledTimes(1)\n    expect(onClickPrependInner).toHaveBeenCalledTimes(1)\n    expect(onClickAppendInner).toHaveBeenCalledTimes(1)\n  })\n})",
    "repo": "vuetifyjs/vuetify",
    "path": "./datasets/diagrams-repos/vuetifyjs/vuetify/packages/vuetify/src/components/VTextField/__tests__/VTextField.spec.tsx",
    "query": "Visalize the test case 'has affixed icons with actions', showing the sequence of operations, including clicks and function calls.",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'mountFunction', 'node_id': 'mountFunction', 'description': 'Helper function to mount component with Vuetify plugin', 'visibility': 'private', 'return_type': 'VueWrapper', 'params': 'component, options', 'source_class_id': None}, {'type': 'class', 'name': 'VTextField', 'node_id': 'VTextField', 'description': 'Vuetify text field component with icon slots', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'onClickPrepend', 'node_id': 'onClickPrepend', 'description': 'Click handler for prepend icon', 'visibility': 'private', 'return_type': 'void', 'params': 'event', 'source_class_id': None}, {'type': 'function', 'name': 'onClickPrependInner', 'node_id': 'onClickPrependInner', 'description': 'Click handler for prepend inner icon', 'visibility': 'private', 'return_type': 'void', 'params': 'event', 'source_class_id': None}, {'type': 'function', 'name': 'onClickAppendInner', 'node_id': 'onClickAppendInner', 'description': 'Click handler for append inner icon', 'visibility': 'private', 'return_type': 'void', 'params': 'event', 'source_class_id': None}, {'type': 'function', 'name': 'onClickAppend', 'node_id': 'onClickAppend', 'description': 'Click handler for append icon', 'visibility': 'private', 'return_type': 'void', 'params': 'event', 'source_class_id': None}, {'type': 'entity', 'name': 'iconTrigger', 'node_id': 'iconTrigger', 'description': 'Icon click event simulation', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'expectAttributes', 'node_id': 'expectAttributes', 'description': 'Verification of icon attributes', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'mountFunction', 'node_id_to': 'VTextField', 'description': 'mounts'}, {'node_id_from': 'iconTrigger', 'node_id_to': 'onClickPrepend', 'description': 'triggers'}, {'node_id_from': 'iconTrigger', 'node_id_to': 'onClickPrependInner', 'description': 'triggers'}, {'node_id_from': 'iconTrigger', 'node_id_to': 'onClickAppendInner', 'description': 'triggers'}, {'node_id_from': 'iconTrigger', 'node_id_to': 'onClickAppend', 'description': 'triggers'}, {'node_id_from': 'iconTrigger', 'node_id_to': 'expectAttributes', 'description': 'verifies'}, {'node_id_from': 'VTextField', 'node_id_to': 'iconTrigger', 'description': 'listen to'}], 'packages': [{'package_id': 'testCase', 'children': ['mountFunction', 'onClickPrepend', 'onClickPrependInner', 'onClickAppendInner', 'onClickAppend', 'iconTrigger', 'expectAttributes'], 'description': 'Test case implementation'}]}",
    "version": "full",
    "text_answer": "The test mounts a VTextField component with four icon slots, then simulates clicks on each icon, verifying that the corresponding click handlers are called exactly once and checking the accessibility attributes before and after interactions.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "PHP",
    "code": "\n<?php\n\n/**\n * @package    Grav\\Framework\\Acl\n *\n * @copyright  Copyright (c) 2015 - 2025 Trilby Media, LLC. All rights reserved.\n * @license    MIT License; see LICENSE file for details.\n */\n\nnamespace Grav\\Framework\\Acl;\n\nuse ArrayAccess;\nuse ArrayIterator;\nuse Countable;\nuse IteratorAggregate;\nuse RecursiveIteratorIterator;\nuse RuntimeException;\nuse Traversable;\nuse function count;\n\n/**\n * Class Permissions\n * @package Grav\\Framework\\Acl\n * @implements ArrayAccess<string,Action>\n * @implements IteratorAggregate<string,Action>\n */\nclass Permissions implements ArrayAccess, Countable, IteratorAggregate\n{\n    /** @var array<string,Action> */\n    protected $instances = [];\n    /** @var array<string,Action> */\n    protected $actions = [];\n    /** @var array */\n    protected $nested = [];\n    /** @var array */\n    protected $types = [];\n\n    /**\n     * @return array\n     */\n    public function getInstances(): array\n    {\n        $iterator = new RecursiveActionIterator($this->actions);\n        $recursive = new RecursiveIteratorIterator($iterator, RecursiveIteratorIterator::SELF_FIRST);\n\n        return iterator_to_array($recursive);\n    }\n\n    /**\n     * @param string $name\n     * @return bool\n     */\n    public function hasAction(string $name): bool\n    {\n        return isset($this->instances[$name]);\n    }\n\n    /**\n     * @param string $name\n     * @return Action|null\n     */\n    public function getAction(string $name): ?Action\n    {\n        return $this->instances[$name] ?? null;\n    }\n\n    /**\n     * @param Action $action\n     * @return void\n     */\n    public function addAction(Action $action): void\n    {\n        $name = $action->name;\n        $parent = $this->getParent($name);\n        if ($parent) {\n            $parent->addChild($action);\n        } else {\n            $this->actions[$name] = $action;\n        }\n\n        $this->instances[$name] = $action;\n\n        // If Action has children, add those, too.\n        foreach ($action->getChildren() as $child) {\n            $this->instances[$child->name] = $child;\n        }\n    }\n\n    /**\n     * @return array\n     */\n    public function getActions(): array\n    {\n        return $this->actions;\n    }\n\n    /**\n     * @param Action[] $actions\n     * @return void\n     */\n    public function addActions(array $actions): void\n    {\n        foreach ($actions as $action) {\n            $this->addAction($action);\n        }\n    }\n\n    /**\n     * @param string $name\n     * @return bool\n     */\n    public function hasType(string $name): bool\n    {\n        return isset($this->types[$name]);\n    }\n\n    /**\n     * @param string $name\n     * @return Action|null\n     */\n    public function getType(string $name): ?Action\n    {\n        return $this->types[$name] ?? null;\n    }\n\n    /**\n     * @param string $name\n     * @param array $type\n     * @return void\n     */\n    public function addType(string $name, array $type): void\n    {\n        $this->types[$name] = $type;\n    }\n\n    /**\n     * @return array\n     */\n    public function getTypes(): array\n    {\n        return $this->types;\n    }\n\n    /**\n     * @param array $types\n     * @return void\n     */\n    public function addTypes(array $types): void\n    {\n        $types = array_replace($this->types, $types);\n\n        $this->types = $types;\n    }\n\n    /**\n     * @param array|null $access\n     * @return Access\n     */\n    public function getAccess(array $access = null): Access\n    {\n        return new Access($access ?? []);\n    }\n\n    /**\n     * @param int|string $offset\n     * @return bool\n     */\n    public function offsetExists($offset): bool\n    {\n        return isset($this->nested[$offset]);\n    }\n\n    /**\n     * @param int|string $offset\n     * @return Action|null\n     */\n    public function offsetGet($offset): ?Action\n    {\n        return $this->nested[$offset] ?? null;\n    }\n\n    /**\n     * @param int|string $offset\n     * @param mixed $value\n     * @return void\n     */\n    public function offsetSet($offset, $value): void\n    {\n        throw new RuntimeException(__METHOD__ . '(): Not Supported');\n    }\n\n    /**\n     * @param int|string $offset\n     * @return void\n     */\n    public function offsetUnset($offset): void\n    {\n        throw new RuntimeException(__METHOD__ . '(): Not Supported');\n    }\n\n    /**\n     * @return int\n     */\n    public function count(): int\n    {\n        return count($this->actions);\n    }\n\n    /**\n     * @return ArrayIterator|Traversable\n     */\n    #[\\ReturnTypeWillChange]\n    public function getIterator()\n    {\n        return new ArrayIterator($this->actions);\n    }\n\n    /**\n     * @return array\n     */\n    #[\\ReturnTypeWillChange]\n    public function __debugInfo()\n    {\n        return [\n            'actions' => $this->actions\n        ];\n    }\n\n    /**\n     * @param string $name\n     * @return Action|null\n     */\n    protected function getParent(string $name): ?Action\n    {\n        if ($pos = strrpos($name, '.')) {\n            $parentName = substr($name, 0, $pos);\n\n            $parent = $this->getAction($parentName);\n            if (!$parent) {\n                $parent = new Action($parentName);\n                $this->addAction($parent);\n            }\n\n            return $parent;\n        }\n\n        return null;\n    }\n}",
    "repo": "getgrav/grav",
    "path": "./datasets/diagrams-repos/getgrav/grav/system/src/Grav/Framework/Acl/Permissions.php",
    "query": "Create a diagram illustrating the internal data structure used to store actions in the Permissions class, including how parent and child actions are related.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'Permissions', 'node_id': 'Permissions', 'description': 'Manages hierarchical action permissions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'instances', 'node_id': 'instances', 'description': 'Flat map of all actions by name', 'visibility': 'protected', 'return_type': 'array<string,Action>', 'params': None, 'source_class_id': 'Permissions'}, {'type': 'field', 'name': 'actions', 'node_id': 'actions', 'description': 'Root-level actions storage', 'visibility': 'protected', 'return_type': 'array<string,Action>', 'params': None, 'source_class_id': 'Permissions'}, {'type': 'class', 'name': 'Action', 'node_id': 'Action', 'description': 'Represents a single permission action', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'addAction', 'node_id': 'addAction', 'description': 'Adds new action to the hierarchy', 'visibility': 'public', 'return_type': 'void', 'params': 'Action $action', 'source_class_id': 'Permissions'}, {'type': 'method', 'name': 'getParent', 'node_id': 'getParent', 'description': 'Finds or creates parent action', 'visibility': 'protected', 'return_type': 'Action', 'params': 'string $name', 'source_class_id': 'Permissions'}], 'edges': [{'node_id_from': 'Permissions', 'node_id_to': 'Action', 'description': 'contains'}, {'node_id_from': 'Permissions', 'node_id_to': 'instances', 'description': ''}, {'node_id_from': 'Permissions', 'node_id_to': 'actions', 'description': ''}, {'node_id_from': 'addAction', 'node_id_to': 'getParent', 'description': 'calls'}, {'node_id_from': 'Permissions', 'node_id_to': 'addAction', 'description': ''}, {'node_id_from': 'Permissions', 'node_id_to': 'getParent', 'description': ''}], 'packages': [{'package_id': 'storage', 'children': ['instances', 'actions'], 'description': 'Internal storage structures'}]}",
    "version": "minimal",
    "text_answer": "The Permissions class uses a dual storage system for actions: 'instances' maintains a flat map of all actions by name for quick lookup, while 'actions' stores only root-level actions in a hierarchical structure. Parent-child relationships between actions are managed through the Action class itself, with parent actions being automatically created when needed during the addition of new actions.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "PHP",
    "code": "\n<?php\n\n/**\n * @package    Grav\\Framework\\Acl\n *\n * @copyright  Copyright (c) 2015 - 2025 Trilby Media, LLC. All rights reserved.\n * @license    MIT License; see LICENSE file for details.\n */\n\nnamespace Grav\\Framework\\Acl;\n\nuse ArrayAccess;\nuse ArrayIterator;\nuse Countable;\nuse IteratorAggregate;\nuse RecursiveIteratorIterator;\nuse RuntimeException;\nuse Traversable;\nuse function count;\n\n/**\n * Class Permissions\n * @package Grav\\Framework\\Acl\n * @implements ArrayAccess<string,Action>\n * @implements IteratorAggregate<string,Action>\n */\nclass Permissions implements ArrayAccess, Countable, IteratorAggregate\n{\n    /** @var array<string,Action> */\n    protected $instances = [];\n    /** @var array<string,Action> */\n    protected $actions = [];\n    /** @var array */\n    protected $nested = [];\n    /** @var array */\n    protected $types = [];\n\n    /**\n     * @return array\n     */\n    public function getInstances(): array\n    {\n        $iterator = new RecursiveActionIterator($this->actions);\n        $recursive = new RecursiveIteratorIterator($iterator, RecursiveIteratorIterator::SELF_FIRST);\n\n        return iterator_to_array($recursive);\n    }\n\n    /**\n     * @param string $name\n     * @return bool\n     */\n    public function hasAction(string $name): bool\n    {\n        return isset($this->instances[$name]);\n    }\n\n    /**\n     * @param string $name\n     * @return Action|null\n     */\n    public function getAction(string $name): ?Action\n    {\n        return $this->instances[$name] ?? null;\n    }\n\n    /**\n     * @param Action $action\n     * @return void\n     */\n    public function addAction(Action $action): void\n    {\n        $name = $action->name;\n        $parent = $this->getParent($name);\n        if ($parent) {\n            $parent->addChild($action);\n        } else {\n            $this->actions[$name] = $action;\n        }\n\n        $this->instances[$name] = $action;\n\n        // If Action has children, add those, too.\n        foreach ($action->getChildren() as $child) {\n            $this->instances[$child->name] = $child;\n        }\n    }\n\n    /**\n     * @return array\n     */\n    public function getActions(): array\n    {\n        return $this->actions;\n    }\n\n    /**\n     * @param Action[] $actions\n     * @return void\n     */\n    public function addActions(array $actions): void\n    {\n        foreach ($actions as $action) {\n            $this->addAction($action);\n        }\n    }\n\n    /**\n     * @param string $name\n     * @return bool\n     */\n    public function hasType(string $name): bool\n    {\n        return isset($this->types[$name]);\n    }\n\n    /**\n     * @param string $name\n     * @return Action|null\n     */\n    public function getType(string $name): ?Action\n    {\n        return $this->types[$name] ?? null;\n    }\n\n    /**\n     * @param string $name\n     * @param array $type\n     * @return void\n     */\n    public function addType(string $name, array $type): void\n    {\n        $this->types[$name] = $type;\n    }\n\n    /**\n     * @return array\n     */\n    public function getTypes(): array\n    {\n        return $this->types;\n    }\n\n    /**\n     * @param array $types\n     * @return void\n     */\n    public function addTypes(array $types): void\n    {\n        $types = array_replace($this->types, $types);\n\n        $this->types = $types;\n    }\n\n    /**\n     * @param array|null $access\n     * @return Access\n     */\n    public function getAccess(array $access = null): Access\n    {\n        return new Access($access ?? []);\n    }\n\n    /**\n     * @param int|string $offset\n     * @return bool\n     */\n    public function offsetExists($offset): bool\n    {\n        return isset($this->nested[$offset]);\n    }\n\n    /**\n     * @param int|string $offset\n     * @return Action|null\n     */\n    public function offsetGet($offset): ?Action\n    {\n        return $this->nested[$offset] ?? null;\n    }\n\n    /**\n     * @param int|string $offset\n     * @param mixed $value\n     * @return void\n     */\n    public function offsetSet($offset, $value): void\n    {\n        throw new RuntimeException(__METHOD__ . '(): Not Supported');\n    }\n\n    /**\n     * @param int|string $offset\n     * @return void\n     */\n    public function offsetUnset($offset): void\n    {\n        throw new RuntimeException(__METHOD__ . '(): Not Supported');\n    }\n\n    /**\n     * @return int\n     */\n    public function count(): int\n    {\n        return count($this->actions);\n    }\n\n    /**\n     * @return ArrayIterator|Traversable\n     */\n    #[\\ReturnTypeWillChange]\n    public function getIterator()\n    {\n        return new ArrayIterator($this->actions);\n    }\n\n    /**\n     * @return array\n     */\n    #[\\ReturnTypeWillChange]\n    public function __debugInfo()\n    {\n        return [\n            'actions' => $this->actions\n        ];\n    }\n\n    /**\n     * @param string $name\n     * @return Action|null\n     */\n    protected function getParent(string $name): ?Action\n    {\n        if ($pos = strrpos($name, '.')) {\n            $parentName = substr($name, 0, $pos);\n\n            $parent = $this->getAction($parentName);\n            if (!$parent) {\n                $parent = new Action($parentName);\n                $this->addAction($parent);\n            }\n\n            return $parent;\n        }\n\n        return null;\n    }\n}",
    "repo": "getgrav/grav",
    "path": "./datasets/diagrams-repos/getgrav/grav/system/src/Grav/Framework/Acl/Permissions.php",
    "query": "Create a diagram illustrating the internal data structure used to store actions in the Permissions class, including how parent and child actions are related.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'Permissions', 'node_id': 'Permissions', 'description': 'Manages hierarchical action permissions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'instances', 'node_id': 'instances', 'description': 'Flat map of all actions by name', 'visibility': 'protected', 'return_type': 'array<string,Action>', 'params': None, 'source_class_id': 'Permissions'}, {'type': 'field', 'name': 'actions', 'node_id': 'actions', 'description': 'Root-level actions storage', 'visibility': 'protected', 'return_type': 'array<string,Action>', 'params': None, 'source_class_id': 'Permissions'}, {'type': 'field', 'name': 'nested', 'node_id': 'nested', 'description': 'Nested actions structure', 'visibility': 'protected', 'return_type': 'array', 'params': None, 'source_class_id': 'Permissions'}, {'type': 'class', 'name': 'Action', 'node_id': 'Action', 'description': 'Represents a single permission action', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'addAction', 'node_id': 'addAction', 'description': 'Adds new action to the hierarchy', 'visibility': 'public', 'return_type': 'void', 'params': 'Action $action', 'source_class_id': 'Permissions'}, {'type': 'method', 'name': 'getParent', 'node_id': 'getParent', 'description': 'Finds or creates parent action', 'visibility': 'protected', 'return_type': 'Action', 'params': 'string $name', 'source_class_id': 'Permissions'}], 'edges': [{'node_id_from': 'Permissions', 'node_id_to': 'Action', 'description': 'contains'}, {'node_id_from': 'addAction', 'node_id_to': 'getParent', 'description': 'calls'}, {'node_id_from': 'Permissions', 'node_id_to': 'instances', 'description': ''}, {'node_id_from': 'Permissions', 'node_id_to': 'actions', 'description': ''}, {'node_id_from': 'Permissions', 'node_id_to': 'nested', 'description': ''}, {'node_id_from': 'Permissions', 'node_id_to': 'addAction', 'description': ''}, {'node_id_from': 'Permissions', 'node_id_to': 'getParent', 'description': ''}], 'packages': [{'package_id': 'storage', 'children': ['instances', 'actions', 'nested'], 'description': 'Internal storage structures'}, {'package_id': 'operations', 'children': ['addAction', 'getParent'], 'description': 'Methods for managing actions hierarchy'}]}",
    "version": "medium",
    "text_answer": "The Permissions class uses a dual storage system for actions: 'instances' maintains a flat map of all actions by name for quick lookup, while 'actions' stores only root-level actions in a hierarchical structure. Parent-child relationships between actions are managed through the Action class itself, with parent actions being automatically created when needed during the addition of new actions.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "PHP",
    "code": "\n<?php\n\n/**\n * @package    Grav\\Framework\\Acl\n *\n * @copyright  Copyright (c) 2015 - 2025 Trilby Media, LLC. All rights reserved.\n * @license    MIT License; see LICENSE file for details.\n */\n\nnamespace Grav\\Framework\\Acl;\n\nuse ArrayAccess;\nuse ArrayIterator;\nuse Countable;\nuse IteratorAggregate;\nuse RecursiveIteratorIterator;\nuse RuntimeException;\nuse Traversable;\nuse function count;\n\n/**\n * Class Permissions\n * @package Grav\\Framework\\Acl\n * @implements ArrayAccess<string,Action>\n * @implements IteratorAggregate<string,Action>\n */\nclass Permissions implements ArrayAccess, Countable, IteratorAggregate\n{\n    /** @var array<string,Action> */\n    protected $instances = [];\n    /** @var array<string,Action> */\n    protected $actions = [];\n    /** @var array */\n    protected $nested = [];\n    /** @var array */\n    protected $types = [];\n\n    /**\n     * @return array\n     */\n    public function getInstances(): array\n    {\n        $iterator = new RecursiveActionIterator($this->actions);\n        $recursive = new RecursiveIteratorIterator($iterator, RecursiveIteratorIterator::SELF_FIRST);\n\n        return iterator_to_array($recursive);\n    }\n\n    /**\n     * @param string $name\n     * @return bool\n     */\n    public function hasAction(string $name): bool\n    {\n        return isset($this->instances[$name]);\n    }\n\n    /**\n     * @param string $name\n     * @return Action|null\n     */\n    public function getAction(string $name): ?Action\n    {\n        return $this->instances[$name] ?? null;\n    }\n\n    /**\n     * @param Action $action\n     * @return void\n     */\n    public function addAction(Action $action): void\n    {\n        $name = $action->name;\n        $parent = $this->getParent($name);\n        if ($parent) {\n            $parent->addChild($action);\n        } else {\n            $this->actions[$name] = $action;\n        }\n\n        $this->instances[$name] = $action;\n\n        // If Action has children, add those, too.\n        foreach ($action->getChildren() as $child) {\n            $this->instances[$child->name] = $child;\n        }\n    }\n\n    /**\n     * @return array\n     */\n    public function getActions(): array\n    {\n        return $this->actions;\n    }\n\n    /**\n     * @param Action[] $actions\n     * @return void\n     */\n    public function addActions(array $actions): void\n    {\n        foreach ($actions as $action) {\n            $this->addAction($action);\n        }\n    }\n\n    /**\n     * @param string $name\n     * @return bool\n     */\n    public function hasType(string $name): bool\n    {\n        return isset($this->types[$name]);\n    }\n\n    /**\n     * @param string $name\n     * @return Action|null\n     */\n    public function getType(string $name): ?Action\n    {\n        return $this->types[$name] ?? null;\n    }\n\n    /**\n     * @param string $name\n     * @param array $type\n     * @return void\n     */\n    public function addType(string $name, array $type): void\n    {\n        $this->types[$name] = $type;\n    }\n\n    /**\n     * @return array\n     */\n    public function getTypes(): array\n    {\n        return $this->types;\n    }\n\n    /**\n     * @param array $types\n     * @return void\n     */\n    public function addTypes(array $types): void\n    {\n        $types = array_replace($this->types, $types);\n\n        $this->types = $types;\n    }\n\n    /**\n     * @param array|null $access\n     * @return Access\n     */\n    public function getAccess(array $access = null): Access\n    {\n        return new Access($access ?? []);\n    }\n\n    /**\n     * @param int|string $offset\n     * @return bool\n     */\n    public function offsetExists($offset): bool\n    {\n        return isset($this->nested[$offset]);\n    }\n\n    /**\n     * @param int|string $offset\n     * @return Action|null\n     */\n    public function offsetGet($offset): ?Action\n    {\n        return $this->nested[$offset] ?? null;\n    }\n\n    /**\n     * @param int|string $offset\n     * @param mixed $value\n     * @return void\n     */\n    public function offsetSet($offset, $value): void\n    {\n        throw new RuntimeException(__METHOD__ . '(): Not Supported');\n    }\n\n    /**\n     * @param int|string $offset\n     * @return void\n     */\n    public function offsetUnset($offset): void\n    {\n        throw new RuntimeException(__METHOD__ . '(): Not Supported');\n    }\n\n    /**\n     * @return int\n     */\n    public function count(): int\n    {\n        return count($this->actions);\n    }\n\n    /**\n     * @return ArrayIterator|Traversable\n     */\n    #[\\ReturnTypeWillChange]\n    public function getIterator()\n    {\n        return new ArrayIterator($this->actions);\n    }\n\n    /**\n     * @return array\n     */\n    #[\\ReturnTypeWillChange]\n    public function __debugInfo()\n    {\n        return [\n            'actions' => $this->actions\n        ];\n    }\n\n    /**\n     * @param string $name\n     * @return Action|null\n     */\n    protected function getParent(string $name): ?Action\n    {\n        if ($pos = strrpos($name, '.')) {\n            $parentName = substr($name, 0, $pos);\n\n            $parent = $this->getAction($parentName);\n            if (!$parent) {\n                $parent = new Action($parentName);\n                $this->addAction($parent);\n            }\n\n            return $parent;\n        }\n\n        return null;\n    }\n}",
    "repo": "getgrav/grav",
    "path": "./datasets/diagrams-repos/getgrav/grav/system/src/Grav/Framework/Acl/Permissions.php",
    "query": "Create a diagram illustrating the internal data structure used to store actions in the Permissions class, including how parent and child actions are related.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'Permissions', 'node_id': 'Permissions', 'description': 'Manages hierarchical action permissions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'instances', 'node_id': 'instances', 'description': 'Flat map of all actions by name', 'visibility': 'protected', 'return_type': 'array<string,Action>', 'params': None, 'source_class_id': 'Permissions'}, {'type': 'field', 'name': 'actions', 'node_id': 'actions', 'description': 'Root-level actions storage', 'visibility': 'protected', 'return_type': 'array<string,Action>', 'params': None, 'source_class_id': 'Permissions'}, {'type': 'field', 'name': 'nested', 'node_id': 'nested', 'description': 'Nested actions structure', 'visibility': 'protected', 'return_type': 'array', 'params': None, 'source_class_id': 'Permissions'}, {'type': 'field', 'name': 'types', 'node_id': 'types', 'description': 'Action types storage', 'visibility': 'protected', 'return_type': 'array', 'params': None, 'source_class_id': 'Permissions'}, {'type': 'class', 'name': 'Action', 'node_id': 'Action', 'description': 'Represents a single permission action', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'addAction', 'node_id': 'addAction', 'description': 'Adds new action to the hierarchy', 'visibility': 'public', 'return_type': 'void', 'params': 'Action $action', 'source_class_id': 'Permissions'}, {'type': 'method', 'name': 'getParent', 'node_id': 'getParent', 'description': 'Finds or creates parent action', 'visibility': 'protected', 'return_type': 'Action', 'params': 'string $name', 'source_class_id': 'Permissions'}, {'type': 'method', 'name': 'getInstances', 'node_id': 'getInstances', 'description': 'Returns flat list of all actions', 'visibility': 'public', 'return_type': 'array', 'params': '', 'source_class_id': 'Permissions'}, {'type': 'method', 'name': 'getActions', 'node_id': 'getActions', 'description': 'Returns root-level actions', 'visibility': 'public', 'return_type': 'array', 'params': '', 'source_class_id': 'Permissions'}, {'type': 'class', 'name': 'RecursiveActionIterator', 'node_id': 'RecursiveActionIterator', 'description': 'Iterator for traversing action hierarchy', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'Permissions', 'node_id_to': 'Action', 'description': 'contains'}, {'node_id_from': 'addAction', 'node_id_to': 'getParent', 'description': 'calls'}, {'node_id_from': 'getInstances', 'node_id_to': 'RecursiveActionIterator', 'description': 'uses'}, {'node_id_from': 'addAction', 'node_id_to': 'instances', 'description': 'updates'}, {'node_id_from': 'addAction', 'node_id_to': 'actions', 'description': 'updates'}, {'node_id_from': 'Permissions', 'node_id_to': 'nested', 'description': ''}, {'node_id_from': 'Permissions', 'node_id_to': 'types', 'description': ''}, {'node_id_from': 'Permissions', 'node_id_to': 'addAction', 'description': ''}, {'node_id_from': 'Permissions', 'node_id_to': 'getInstances', 'description': ''}, {'node_id_from': 'Permissions', 'node_id_to': 'getActions', 'description': ''}, {'node_id_from': 'Permissions', 'node_id_to': 'actions', 'description': ''}, {'node_id_from': 'Permissions', 'node_id_to': 'instances', 'description': ''}, {'node_id_from': 'Permissions', 'node_id_to': 'getParent', 'description': ''}], 'packages': [{'package_id': 'storage', 'children': ['instances', 'actions', 'nested', 'types'], 'description': 'Internal storage structures'}, {'package_id': 'operations', 'children': ['addAction', 'getParent', 'getInstances', 'getActions'], 'description': 'Methods for managing actions hierarchy'}]}",
    "version": "full",
    "text_answer": "The Permissions class uses a dual storage system for actions: 'instances' maintains a flat map of all actions by name for quick lookup, while 'actions' stores only root-level actions in a hierarchical structure. Parent-child relationships between actions are managed through the Action class itself, with parent actions being automatically created when needed during the addition of new actions.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.jkiss.dbeaver.ext.exasol.model;\n\nimport org.jkiss.code.NotNull;\nimport org.jkiss.code.Nullable;\nimport org.jkiss.dbeaver.DBException;\nimport org.jkiss.dbeaver.Log;\nimport org.jkiss.dbeaver.ext.exasol.ExasolMessages;\nimport org.jkiss.dbeaver.ext.exasol.ExasolSysTablePrefix;\nimport org.jkiss.dbeaver.ext.exasol.model.cache.*;\nimport org.jkiss.dbeaver.ext.exasol.model.security.ExasolGrantee;\nimport org.jkiss.dbeaver.ext.exasol.tools.ExasolJDBCObjectSimpleCacheLiterals;\nimport org.jkiss.dbeaver.ext.exasol.tools.ExasolUtils;\nimport org.jkiss.dbeaver.model.*;\nimport org.jkiss.dbeaver.model.exec.DBCException;\nimport org.jkiss.dbeaver.model.exec.jdbc.JDBCPreparedStatement;\nimport org.jkiss.dbeaver.model.exec.jdbc.JDBCResultSet;\nimport org.jkiss.dbeaver.model.exec.jdbc.JDBCSession;\nimport org.jkiss.dbeaver.model.impl.jdbc.JDBCUtils;\nimport org.jkiss.dbeaver.model.meta.Association;\nimport org.jkiss.dbeaver.model.meta.IPropertyValueListProvider;\nimport org.jkiss.dbeaver.model.meta.Property;\nimport org.jkiss.dbeaver.model.meta.PropertyLength;\nimport org.jkiss.dbeaver.model.runtime.DBRProgressMonitor;\nimport org.jkiss.dbeaver.model.struct.DBSObject;\nimport org.jkiss.dbeaver.model.struct.cache.DBSObjectCache;\nimport org.jkiss.dbeaver.model.struct.rdb.DBSProcedureContainer;\nimport org.jkiss.dbeaver.model.struct.rdb.DBSSchema;\nimport org.jkiss.utils.ByteNumberFormat;\n\nimport java.math.BigDecimal;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.sql.Timestamp;\nimport java.util.*;\nimport java.util.stream.Collectors;\n\n\npublic class ExasolSchema extends ExasolGlobalObject implements DBSSchema, DBPNamedObject2,  DBPRefreshableObject, DBPSystemObject, DBSProcedureContainer, DBPScriptObject {\n\n    private static final List<String> SYSTEM_SCHEMA = Arrays.asList(\"SYS\",\"EXA_STATISTICS\");\n    private static final Log log = Log.getLog(ExasolSchema.class);    \n    private String name;\n    private String owner;\n    private Timestamp createTime;\n    private String remarks;\n    private long objectId;\n    private String tablePrefix;\n    private BigDecimal rawObjectSize;\n    private BigDecimal memObjectSize;\n    private BigDecimal rawObjectSizeLimit;\n    private Boolean refreshed = false; \n\n\n    // ExasolSchema's children\n    public final DBSObjectCache<ExasolSchema, ExasolScript> scriptCache;\n\n    public final DBSObjectCache<ExasolSchema, ExasolFunction> functionCache;\n    private ExasolViewCache viewCache = new ExasolViewCache();\n    private ExasolTableCache tableCache = new ExasolTableCache();\n    \n    // ExasolTable's children\n    private final ExasolTableUniqueKeyCache constraintCache = new ExasolTableUniqueKeyCache(tableCache);\n    private final ExasolTableForeignKeyCache associationCache = new ExasolTableForeignKeyCache(tableCache);\n    private final ExasolTableIndexCache indexCache = new ExasolTableIndexCache(tableCache);\n\n    public ExasolSchema(ExasolDataSource exasolDataSource, String name, String owner) {\n        super(exasolDataSource, true);\n        this.tablePrefix = exasolDataSource.getTablePrefix(ExasolSysTablePrefix.ALL);\n        this.name = name;\n        this.owner = owner;\n        this.scriptCache = new ExasolJDBCObjectSimpleCacheLiterals<>(\n        \t\tExasolScript.class,\n        \t\t\"/*snapshot execution*/ select \"\n        \t\t+ \"script_name,script_owner,script_language,script_type,script_result_type,script_text,script_comment,b.created \"\n        \t\t+ \"from SYS.\" + tablePrefix + \"_SCRIPTS a inner join SYS.\" + tablePrefix + \"_OBJECTS b \"\n        \t\t+ \"on a.SCRIPT_OBJECT_ID  = b.object_id and b.object_type = 'SCRIPT' where a.script_schema = '%s' \"\n        \t\t+ \"order by script_name\",\n        \t\tname);\n\n        this.functionCache = new ExasolJDBCObjectSimpleCacheLiterals<>(ExasolFunction.class,\n                \"/*snapshot execution*/ SELECT\\n\" + \n                \"    F.*,\\n\" + \n                \"    O.CREATED\\n\" + \n                \"FROM\\n\" + \n                \"    SYS.\" +  tablePrefix + \"_FUNCTIONS F\\n\" + \n                \"INNER JOIN SYS.\" + tablePrefix + \"_OBJECTS O ON\\n\" + \n                \"    F.FUNCTION_OBJECT_ID = O.OBJECT_ID\\n\" + \n                \"WHERE\\n\" + \n                \"    F.FUNCTION_SCHEMA = '%s' and O.OBJECT_TYPE = 'FUNCTION' AND o.ROOT_NAME = '%s'\\n\" + \n                \"ORDER BY\\n\" + \n                \"    FUNCTION_NAME\\n\", \n                name,name);\n        \n        \n        \n\n    }\n\n    public ExasolSchema(ExasolDataSource exasolDataSource, ResultSet dbResult) throws DBException {\n\n        this(\n                exasolDataSource, \n                JDBCUtils.safeGetStringTrimmed(dbResult, \"OBJECT_NAME\"), \n                JDBCUtils.safeGetString(dbResult, \"OWNER\")\n            );\n        this.createTime = JDBCUtils.safeGetTimestamp(dbResult, \"CREATED\");\n        this.remarks = JDBCUtils.safeGetString(dbResult, \"OBJECT_COMMENT\");\n        this.name = JDBCUtils.safeGetString(dbResult, \"OBJECT_NAME\");\n        this.objectId = JDBCUtils.safeGetLong(dbResult, \"SCHEMA_OBJECT_ID\");\n\n\n    }\n    \n    @NotNull\n    @Override\n    @Property(viewable = true, editable = false, order = 1)\n    public String getName() {\n        return this.name;\n    }\n    \n    @Override\n    public void setName(String name) {\n        this.name = name;\n    }\n    \n    @Override\n    public Collection<ExasolTableBase> getChildren(@NotNull DBRProgressMonitor monitor) throws DBException {\n        List<ExasolTableBase> allChildren = new ArrayList<>();\n        allChildren.addAll(tableCache.getAllObjects(monitor, this));\n        allChildren.addAll(viewCache.getAllObjects(monitor, this));\n        return allChildren;\n    }\n\n    @Override\n    public ExasolTableBase getChild(@NotNull DBRProgressMonitor monitor, @NotNull String childName) throws DBException {\n\n        ExasolTableBase child = tableCache.getObject(monitor, this, childName);\n        if (child == null) {\n            child = viewCache.getObject(monitor, this, childName);\n        }\n        return child;\n    }\n\n    @NotNull\n    @Override\n    public Class<ExasolTable> getPrimaryChildType(@Nullable DBRProgressMonitor monitor) throws DBException {\n    \treturn ExasolTable.class;\n    }\n\n    @Override\n    public synchronized void cacheStructure(@NotNull DBRProgressMonitor monitor, int scope) throws DBException {\n    \t\n        if (((scope & STRUCT_ENTITIES) != 0)) {\n            monitor.subTask(\"Cache tables\");\n            tableCache.getAllObjects(monitor, this);\n            monitor.subTask(\"Cache Views\");\n            viewCache.getAllObjects(monitor, this);\n        }\n        if (((scope & STRUCT_ATTRIBUTES) != 0)) {\n            monitor.subTask(\"Cache table columns\");\n            tableCache.loadChildren(monitor, this, null);\n            monitor.subTask(\"Cache Views\");\n            viewCache.loadChildren(monitor, this, null);\n        }\n\n        if ((scope & STRUCT_ASSOCIATIONS) != 0) {\n            monitor.subTask(\"Cache table unique keys\");\n            constraintCache.getObjects(monitor, this, null);\n            monitor.subTask(\"Cache table foreign keys\");\n            associationCache.getObjects(monitor, this, null);\n            monitor.subTask(\"Cache Indexes\");\n            indexCache.getObjects(monitor, this, null);\n\n        }\n\n\n    }\n\n    // -----------------\n    // Associations\n    // -----------------\n\n    @Association\n    public Collection<ExasolTable> getTables(DBRProgressMonitor monitor) throws DBException {\n        return tableCache.getTypedObjects(monitor, this, ExasolTable.class);\n    }\n\n    public ExasolTable getTable(DBRProgressMonitor monitor, String name) throws DBException {\n        return tableCache.getObject(monitor, this, name, ExasolTable.class);\n    }\n\n    @Association\n    public Collection<ExasolView> getViews(DBRProgressMonitor monitor) throws DBException {\n        return viewCache.getTypedObjects(monitor, this, ExasolView.class);\n    }\n\n    public ExasolView getView(DBRProgressMonitor monitor, String name) throws DBException {\n        return viewCache.getObject(monitor, this, name, ExasolView.class);\n    }\n\n\n    @Override\n    public boolean isSystem() {\n        // TODO Auto-generated method stub\n        return SYSTEM_SCHEMA.contains(name);\n    }\n\n    @Override\n    public Collection<ExasolScript> getProcedures(DBRProgressMonitor monitor) throws DBException {\n\n        return scriptCache.getAllObjects(monitor, this).stream()\n    \t\t\t.filter(o -> o.getType().equals(\"SCRIPTING\"))\n    \t\t\t.collect(Collectors.toCollection(ArrayList::new));\n    }\n    \n    public Collection<ExasolScript> getUdfs(DBRProgressMonitor monitor) throws DBException {\n    \t\n    \treturn scriptCache.getAllObjects(monitor, this).stream()\n    \t\t\t.filter(o -> o.getType().equals(\"UDF\"))\n    \t\t\t.collect(Collectors.toCollection(ArrayList::new));\n    }\n\n    public ExasolScript getUdf(DBRProgressMonitor monitor, String name) throws DBException {\n\n        return scriptCache.getObject(monitor, this, name);\n    }\n\n\n    public Collection<ExasolScript> getAdapter(DBRProgressMonitor monitor) throws DBException {\n\n        return scriptCache.getAllObjects(monitor, this).stream()\n    \t\t\t.filter(o -> o.getType().equals(\"ADAPTER\"))\n    \t\t\t.collect(Collectors.toCollection(ArrayList::new));\n\n    }\n\n    public ExasolScript getAdapter(DBRProgressMonitor monitor, String name) throws DBException {\n\n        return scriptCache.getObject(monitor, this, name);\n    }\n    \n    \n    @Override\n    public ExasolScript getProcedure(DBRProgressMonitor monitor, String uniqueName) throws DBException {\n\n        return scriptCache.getObject(monitor, this, uniqueName);\n    }\n\n    public Collection<ExasolFunction> getFunctions(DBRProgressMonitor monitor) throws DBException {\n        return functionCache.getAllObjects(monitor, this);\n    }\n    \n    public ExasolFunction getFunction(DBRProgressMonitor monitor,String name) throws DBException {\n        return functionCache.getObject(monitor, this, name);\n    }\n\n    \n    @Override\n    public DBSObject refreshObject(@NotNull DBRProgressMonitor monitor) throws DBException {\n        \n        ((ExasolDataSource) getDataSource()).refreshObject(monitor);\n        functionCache.clearCache();\n        scriptCache.clearCache();\n        tableCache.clearCache();\n        viewCache.clearCache();\n        indexCache.clearCache();\n\n\n        constraintCache.clearCache();\n        associationCache.clearCache();\n        refreshed=false;\n        return this;\n    }\n\n    @Override\n    public String toString() {\n        return \"Schema \" + name;\n    }\n    \n    private synchronized void refresh(DBRProgressMonitor monitor) throws DBCException\n    {\n    \tif (!refreshed && this.objectId != 0) {\n\t    \tJDBCSession session = DBUtils.openMetaSession(monitor, this, ExasolMessages.read_schema_details );\n\t    \ttry (JDBCPreparedStatement stmt = session.prepareStatement(\"/*snapshot execution*/ SELECT * FROM SYS.\"+getDataSource().getTablePrefix(ExasolSysTablePrefix.ALL)+\"_OBJECT_SIZES WHERE OBJECT_ID = ?\"))\n\t    \t{\n\t    \t\tstmt.setLong(1, this.objectId);\n\t    \t\ttry (JDBCResultSet dbResult = stmt.executeQuery()) \n\t    \t\t{\n\t    \t\t\tif (dbResult.next()) {\n                        this.createTime = JDBCUtils.safeGetTimestamp(dbResult, \"CREATED\");\n                        this.rawObjectSize = JDBCUtils.safeGetBigDecimal(dbResult, \"RAW_OBJECT_SIZE\");\n                        this.memObjectSize = JDBCUtils.safeGetBigDecimal(dbResult, \"MEM_OBJECT_SIZE\");\n                        this.rawObjectSizeLimit = JDBCUtils.safeGetBigDecimal(dbResult, \"RAW_OBJECT_SIZE_LIMIT\");\n                    }\n\t    \t\t}\n\t    \t\trefreshed = true;\n\t    \t} catch (SQLException e) {\n\t    \t\tthrow new DBCException(e, session.getExecutionContext());\n\t\t\t}\n    \t}\n\t\t\n\t}\n\n    @Property(viewable = true, editable = false, order = 2)\n    public Timestamp getCreateTime(DBRProgressMonitor monitor) throws DBCException {\n    \trefresh(monitor);\n        return createTime;\n    }\n\n    @Property(viewable = true, editable = true, updatable = true, length = PropertyLength.MULTILINE, order = 3)\n    public String getDescription() {\n        return remarks;\n    }\n    \n    public void setDescription(String newRemarks)\n    {\n    \tremarks = newRemarks;\n    }\n\n    @Property(viewable = true, editable = false, updatable = true,  order = 4)\n    public String getOwner() {\n        return owner;\n    }\n\n    \n    \n    @Property(viewable = true, editable = false, updatable =  false,  order = 5, formatter = ByteNumberFormat.class)\n    public long getRawObjectSize() {\n    \tif (rawObjectSize == null)\n    \t\treturn -1;\n\t\treturn rawObjectSize.longValue();\n\t}\n\n    @Property(viewable = true, editable = false, updatable =  false,  order = 6, formatter = ByteNumberFormat.class)\n\tpublic long getMemObjectSize() {\n    \tif (memObjectSize == null)\n    \t\treturn -1;\n\t\treturn memObjectSize.longValue();\n\t}\n\n    @Property(viewable = true, editable = true, updatable = true,  order = 7)\n\tpublic BigDecimal getRawObjectSizeLimit() {\n\t\treturn rawObjectSizeLimit;\n\t}\n    \n    public void setRawObjectSizeLimit(BigDecimal limit) {\n    \tthis.rawObjectSizeLimit = limit;\n    }\n    \n\n\tpublic void setOwner(String owner)\n    {\n        this.owner = owner;\n    }\n\n    public ExasolTableCache getTableCache() {\n        return tableCache;\n    }\n\n    public ExasolViewCache getViewCache() {\n        return viewCache;\n    }\n\n\n    public ExasolTableUniqueKeyCache getConstraintCache() {\n        return constraintCache;\n    }\n\n    public ExasolTableForeignKeyCache getAssociationCache() {\n        return associationCache;\n    }\n\n\t@Override\n\tpublic String getObjectDefinitionText(DBRProgressMonitor monitor, Map<String, Object> options)\n\t\t\tthrows DBException\n\t{\n\t\treturn ExasolUtils.generateDDLforSchema(monitor, this);\n\t}\n\t\n\t\n\tpublic static class OwnerListProvider implements IPropertyValueListProvider<ExasolSchema> {\n\t\t\n\t\t@Override\n\t\tpublic boolean allowCustomValue() {\n\t\t\treturn false;\n\t\t}\n\t\t\n\t\tpublic Object[] getPossibleValues(ExasolSchema object)\n\t\t{\n\t\t\tExasolDataSource dataSource = object.getDataSource();\n\n            List<ExasolGrantee> allGrantee = new ArrayList<>();\n            allGrantee.addAll(dataSource.getUserCache().getCachedObjects());\n            allGrantee.addAll(dataSource.getRoleCache().getCachedObjects());\n            return allGrantee.toArray(new Object[0]);\n\t\t}\n\t\t\n\t}\n\t\n\tpublic Boolean isPhysicalSchema()\n\t{\n\t    return true;\n\t}\n\n\tpublic ExasolTableIndexCache getIndexCache() {\n\t\treturn indexCache;\n\t}\n\t\n\t@Association\n\tpublic Collection<ExasolTableIndex> getIndexes(DBRProgressMonitor monitor) throws DBException {\n\t\treturn indexCache.getObjects(monitor, this, null);\n\t}\n\t\n\t\n\t\n\t\n}",
    "repo": "dbeaver/dbeaver",
    "path": "./datasets/diagrams-repos/dbeaver/dbeaver/plugins/org.jkiss.dbeaver.ext.exasol/src/org/jkiss/dbeaver/ext/exasol/model/ExasolSchema.java",
    "query": "How does the ExasolSchema class handle the refreshing of its cached objects, and what is the sequence of operations involved?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'ExasolSchema', 'node_id': 'ExasolSchema', 'description': 'Main class representing Exasol database schema', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'refreshObject', 'node_id': 'refreshObject', 'description': 'Main method to refresh all schema objects', 'visibility': 'public', 'return_type': 'DBSObject', 'params': 'DBRProgressMonitor monitor', 'source_class_id': 'ExasolSchema'}, {'type': 'method', 'name': 'refresh', 'node_id': 'refresh', 'description': 'Internal method to refresh schema details', 'visibility': 'private', 'return_type': 'void', 'params': 'DBRProgressMonitor monitor', 'source_class_id': 'ExasolSchema'}, {'type': 'field', 'name': 'refreshed', 'node_id': 'refreshed', 'description': 'Flag indicating if schema was refreshed', 'visibility': 'private', 'return_type': 'Boolean', 'params': None, 'source_class_id': 'ExasolSchema'}], 'edges': [{'node_id_from': 'refreshObject', 'node_id_to': 'refresh', 'description': 'calls'}, {'node_id_from': 'ExasolSchema', 'node_id_to': 'refreshObject', 'description': ''}, {'node_id_from': 'ExasolSchema', 'node_id_to': 'refreshed', 'description': ''}, {'node_id_from': 'ExasolSchema', 'node_id_to': 'refresh', 'description': ''}], 'packages': [{'package_id': 'refreshLogic', 'children': ['refreshObject', 'refresh', 'refreshed'], 'description': 'Core refresh functionality'}]}",
    "version": "minimal",
    "text_answer": "ExasolSchema refreshes its cached objects through the refreshObject method, which first refreshes the data source, then clears all caches (scripts, functions, tables, views, constraints, foreign keys, and indexes), and finally resets the refreshed flag. The private refresh method handles detailed schema information updates when needed.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.jkiss.dbeaver.ext.exasol.model;\n\nimport org.jkiss.code.NotNull;\nimport org.jkiss.code.Nullable;\nimport org.jkiss.dbeaver.DBException;\nimport org.jkiss.dbeaver.Log;\nimport org.jkiss.dbeaver.ext.exasol.ExasolMessages;\nimport org.jkiss.dbeaver.ext.exasol.ExasolSysTablePrefix;\nimport org.jkiss.dbeaver.ext.exasol.model.cache.*;\nimport org.jkiss.dbeaver.ext.exasol.model.security.ExasolGrantee;\nimport org.jkiss.dbeaver.ext.exasol.tools.ExasolJDBCObjectSimpleCacheLiterals;\nimport org.jkiss.dbeaver.ext.exasol.tools.ExasolUtils;\nimport org.jkiss.dbeaver.model.*;\nimport org.jkiss.dbeaver.model.exec.DBCException;\nimport org.jkiss.dbeaver.model.exec.jdbc.JDBCPreparedStatement;\nimport org.jkiss.dbeaver.model.exec.jdbc.JDBCResultSet;\nimport org.jkiss.dbeaver.model.exec.jdbc.JDBCSession;\nimport org.jkiss.dbeaver.model.impl.jdbc.JDBCUtils;\nimport org.jkiss.dbeaver.model.meta.Association;\nimport org.jkiss.dbeaver.model.meta.IPropertyValueListProvider;\nimport org.jkiss.dbeaver.model.meta.Property;\nimport org.jkiss.dbeaver.model.meta.PropertyLength;\nimport org.jkiss.dbeaver.model.runtime.DBRProgressMonitor;\nimport org.jkiss.dbeaver.model.struct.DBSObject;\nimport org.jkiss.dbeaver.model.struct.cache.DBSObjectCache;\nimport org.jkiss.dbeaver.model.struct.rdb.DBSProcedureContainer;\nimport org.jkiss.dbeaver.model.struct.rdb.DBSSchema;\nimport org.jkiss.utils.ByteNumberFormat;\n\nimport java.math.BigDecimal;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.sql.Timestamp;\nimport java.util.*;\nimport java.util.stream.Collectors;\n\n\npublic class ExasolSchema extends ExasolGlobalObject implements DBSSchema, DBPNamedObject2,  DBPRefreshableObject, DBPSystemObject, DBSProcedureContainer, DBPScriptObject {\n\n    private static final List<String> SYSTEM_SCHEMA = Arrays.asList(\"SYS\",\"EXA_STATISTICS\");\n    private static final Log log = Log.getLog(ExasolSchema.class);    \n    private String name;\n    private String owner;\n    private Timestamp createTime;\n    private String remarks;\n    private long objectId;\n    private String tablePrefix;\n    private BigDecimal rawObjectSize;\n    private BigDecimal memObjectSize;\n    private BigDecimal rawObjectSizeLimit;\n    private Boolean refreshed = false; \n\n\n    // ExasolSchema's children\n    public final DBSObjectCache<ExasolSchema, ExasolScript> scriptCache;\n\n    public final DBSObjectCache<ExasolSchema, ExasolFunction> functionCache;\n    private ExasolViewCache viewCache = new ExasolViewCache();\n    private ExasolTableCache tableCache = new ExasolTableCache();\n    \n    // ExasolTable's children\n    private final ExasolTableUniqueKeyCache constraintCache = new ExasolTableUniqueKeyCache(tableCache);\n    private final ExasolTableForeignKeyCache associationCache = new ExasolTableForeignKeyCache(tableCache);\n    private final ExasolTableIndexCache indexCache = new ExasolTableIndexCache(tableCache);\n\n    public ExasolSchema(ExasolDataSource exasolDataSource, String name, String owner) {\n        super(exasolDataSource, true);\n        this.tablePrefix = exasolDataSource.getTablePrefix(ExasolSysTablePrefix.ALL);\n        this.name = name;\n        this.owner = owner;\n        this.scriptCache = new ExasolJDBCObjectSimpleCacheLiterals<>(\n        \t\tExasolScript.class,\n        \t\t\"/*snapshot execution*/ select \"\n        \t\t+ \"script_name,script_owner,script_language,script_type,script_result_type,script_text,script_comment,b.created \"\n        \t\t+ \"from SYS.\" + tablePrefix + \"_SCRIPTS a inner join SYS.\" + tablePrefix + \"_OBJECTS b \"\n        \t\t+ \"on a.SCRIPT_OBJECT_ID  = b.object_id and b.object_type = 'SCRIPT' where a.script_schema = '%s' \"\n        \t\t+ \"order by script_name\",\n        \t\tname);\n\n        this.functionCache = new ExasolJDBCObjectSimpleCacheLiterals<>(ExasolFunction.class,\n                \"/*snapshot execution*/ SELECT\\n\" + \n                \"    F.*,\\n\" + \n                \"    O.CREATED\\n\" + \n                \"FROM\\n\" + \n                \"    SYS.\" +  tablePrefix + \"_FUNCTIONS F\\n\" + \n                \"INNER JOIN SYS.\" + tablePrefix + \"_OBJECTS O ON\\n\" + \n                \"    F.FUNCTION_OBJECT_ID = O.OBJECT_ID\\n\" + \n                \"WHERE\\n\" + \n                \"    F.FUNCTION_SCHEMA = '%s' and O.OBJECT_TYPE = 'FUNCTION' AND o.ROOT_NAME = '%s'\\n\" + \n                \"ORDER BY\\n\" + \n                \"    FUNCTION_NAME\\n\", \n                name,name);\n        \n        \n        \n\n    }\n\n    public ExasolSchema(ExasolDataSource exasolDataSource, ResultSet dbResult) throws DBException {\n\n        this(\n                exasolDataSource, \n                JDBCUtils.safeGetStringTrimmed(dbResult, \"OBJECT_NAME\"), \n                JDBCUtils.safeGetString(dbResult, \"OWNER\")\n            );\n        this.createTime = JDBCUtils.safeGetTimestamp(dbResult, \"CREATED\");\n        this.remarks = JDBCUtils.safeGetString(dbResult, \"OBJECT_COMMENT\");\n        this.name = JDBCUtils.safeGetString(dbResult, \"OBJECT_NAME\");\n        this.objectId = JDBCUtils.safeGetLong(dbResult, \"SCHEMA_OBJECT_ID\");\n\n\n    }\n    \n    @NotNull\n    @Override\n    @Property(viewable = true, editable = false, order = 1)\n    public String getName() {\n        return this.name;\n    }\n    \n    @Override\n    public void setName(String name) {\n        this.name = name;\n    }\n    \n    @Override\n    public Collection<ExasolTableBase> getChildren(@NotNull DBRProgressMonitor monitor) throws DBException {\n        List<ExasolTableBase> allChildren = new ArrayList<>();\n        allChildren.addAll(tableCache.getAllObjects(monitor, this));\n        allChildren.addAll(viewCache.getAllObjects(monitor, this));\n        return allChildren;\n    }\n\n    @Override\n    public ExasolTableBase getChild(@NotNull DBRProgressMonitor monitor, @NotNull String childName) throws DBException {\n\n        ExasolTableBase child = tableCache.getObject(monitor, this, childName);\n        if (child == null) {\n            child = viewCache.getObject(monitor, this, childName);\n        }\n        return child;\n    }\n\n    @NotNull\n    @Override\n    public Class<ExasolTable> getPrimaryChildType(@Nullable DBRProgressMonitor monitor) throws DBException {\n    \treturn ExasolTable.class;\n    }\n\n    @Override\n    public synchronized void cacheStructure(@NotNull DBRProgressMonitor monitor, int scope) throws DBException {\n    \t\n        if (((scope & STRUCT_ENTITIES) != 0)) {\n            monitor.subTask(\"Cache tables\");\n            tableCache.getAllObjects(monitor, this);\n            monitor.subTask(\"Cache Views\");\n            viewCache.getAllObjects(monitor, this);\n        }\n        if (((scope & STRUCT_ATTRIBUTES) != 0)) {\n            monitor.subTask(\"Cache table columns\");\n            tableCache.loadChildren(monitor, this, null);\n            monitor.subTask(\"Cache Views\");\n            viewCache.loadChildren(monitor, this, null);\n        }\n\n        if ((scope & STRUCT_ASSOCIATIONS) != 0) {\n            monitor.subTask(\"Cache table unique keys\");\n            constraintCache.getObjects(monitor, this, null);\n            monitor.subTask(\"Cache table foreign keys\");\n            associationCache.getObjects(monitor, this, null);\n            monitor.subTask(\"Cache Indexes\");\n            indexCache.getObjects(monitor, this, null);\n\n        }\n\n\n    }\n\n    // -----------------\n    // Associations\n    // -----------------\n\n    @Association\n    public Collection<ExasolTable> getTables(DBRProgressMonitor monitor) throws DBException {\n        return tableCache.getTypedObjects(monitor, this, ExasolTable.class);\n    }\n\n    public ExasolTable getTable(DBRProgressMonitor monitor, String name) throws DBException {\n        return tableCache.getObject(monitor, this, name, ExasolTable.class);\n    }\n\n    @Association\n    public Collection<ExasolView> getViews(DBRProgressMonitor monitor) throws DBException {\n        return viewCache.getTypedObjects(monitor, this, ExasolView.class);\n    }\n\n    public ExasolView getView(DBRProgressMonitor monitor, String name) throws DBException {\n        return viewCache.getObject(monitor, this, name, ExasolView.class);\n    }\n\n\n    @Override\n    public boolean isSystem() {\n        // TODO Auto-generated method stub\n        return SYSTEM_SCHEMA.contains(name);\n    }\n\n    @Override\n    public Collection<ExasolScript> getProcedures(DBRProgressMonitor monitor) throws DBException {\n\n        return scriptCache.getAllObjects(monitor, this).stream()\n    \t\t\t.filter(o -> o.getType().equals(\"SCRIPTING\"))\n    \t\t\t.collect(Collectors.toCollection(ArrayList::new));\n    }\n    \n    public Collection<ExasolScript> getUdfs(DBRProgressMonitor monitor) throws DBException {\n    \t\n    \treturn scriptCache.getAllObjects(monitor, this).stream()\n    \t\t\t.filter(o -> o.getType().equals(\"UDF\"))\n    \t\t\t.collect(Collectors.toCollection(ArrayList::new));\n    }\n\n    public ExasolScript getUdf(DBRProgressMonitor monitor, String name) throws DBException {\n\n        return scriptCache.getObject(monitor, this, name);\n    }\n\n\n    public Collection<ExasolScript> getAdapter(DBRProgressMonitor monitor) throws DBException {\n\n        return scriptCache.getAllObjects(monitor, this).stream()\n    \t\t\t.filter(o -> o.getType().equals(\"ADAPTER\"))\n    \t\t\t.collect(Collectors.toCollection(ArrayList::new));\n\n    }\n\n    public ExasolScript getAdapter(DBRProgressMonitor monitor, String name) throws DBException {\n\n        return scriptCache.getObject(monitor, this, name);\n    }\n    \n    \n    @Override\n    public ExasolScript getProcedure(DBRProgressMonitor monitor, String uniqueName) throws DBException {\n\n        return scriptCache.getObject(monitor, this, uniqueName);\n    }\n\n    public Collection<ExasolFunction> getFunctions(DBRProgressMonitor monitor) throws DBException {\n        return functionCache.getAllObjects(monitor, this);\n    }\n    \n    public ExasolFunction getFunction(DBRProgressMonitor monitor,String name) throws DBException {\n        return functionCache.getObject(monitor, this, name);\n    }\n\n    \n    @Override\n    public DBSObject refreshObject(@NotNull DBRProgressMonitor monitor) throws DBException {\n        \n        ((ExasolDataSource) getDataSource()).refreshObject(monitor);\n        functionCache.clearCache();\n        scriptCache.clearCache();\n        tableCache.clearCache();\n        viewCache.clearCache();\n        indexCache.clearCache();\n\n\n        constraintCache.clearCache();\n        associationCache.clearCache();\n        refreshed=false;\n        return this;\n    }\n\n    @Override\n    public String toString() {\n        return \"Schema \" + name;\n    }\n    \n    private synchronized void refresh(DBRProgressMonitor monitor) throws DBCException\n    {\n    \tif (!refreshed && this.objectId != 0) {\n\t    \tJDBCSession session = DBUtils.openMetaSession(monitor, this, ExasolMessages.read_schema_details );\n\t    \ttry (JDBCPreparedStatement stmt = session.prepareStatement(\"/*snapshot execution*/ SELECT * FROM SYS.\"+getDataSource().getTablePrefix(ExasolSysTablePrefix.ALL)+\"_OBJECT_SIZES WHERE OBJECT_ID = ?\"))\n\t    \t{\n\t    \t\tstmt.setLong(1, this.objectId);\n\t    \t\ttry (JDBCResultSet dbResult = stmt.executeQuery()) \n\t    \t\t{\n\t    \t\t\tif (dbResult.next()) {\n                        this.createTime = JDBCUtils.safeGetTimestamp(dbResult, \"CREATED\");\n                        this.rawObjectSize = JDBCUtils.safeGetBigDecimal(dbResult, \"RAW_OBJECT_SIZE\");\n                        this.memObjectSize = JDBCUtils.safeGetBigDecimal(dbResult, \"MEM_OBJECT_SIZE\");\n                        this.rawObjectSizeLimit = JDBCUtils.safeGetBigDecimal(dbResult, \"RAW_OBJECT_SIZE_LIMIT\");\n                    }\n\t    \t\t}\n\t    \t\trefreshed = true;\n\t    \t} catch (SQLException e) {\n\t    \t\tthrow new DBCException(e, session.getExecutionContext());\n\t\t\t}\n    \t}\n\t\t\n\t}\n\n    @Property(viewable = true, editable = false, order = 2)\n    public Timestamp getCreateTime(DBRProgressMonitor monitor) throws DBCException {\n    \trefresh(monitor);\n        return createTime;\n    }\n\n    @Property(viewable = true, editable = true, updatable = true, length = PropertyLength.MULTILINE, order = 3)\n    public String getDescription() {\n        return remarks;\n    }\n    \n    public void setDescription(String newRemarks)\n    {\n    \tremarks = newRemarks;\n    }\n\n    @Property(viewable = true, editable = false, updatable = true,  order = 4)\n    public String getOwner() {\n        return owner;\n    }\n\n    \n    \n    @Property(viewable = true, editable = false, updatable =  false,  order = 5, formatter = ByteNumberFormat.class)\n    public long getRawObjectSize() {\n    \tif (rawObjectSize == null)\n    \t\treturn -1;\n\t\treturn rawObjectSize.longValue();\n\t}\n\n    @Property(viewable = true, editable = false, updatable =  false,  order = 6, formatter = ByteNumberFormat.class)\n\tpublic long getMemObjectSize() {\n    \tif (memObjectSize == null)\n    \t\treturn -1;\n\t\treturn memObjectSize.longValue();\n\t}\n\n    @Property(viewable = true, editable = true, updatable = true,  order = 7)\n\tpublic BigDecimal getRawObjectSizeLimit() {\n\t\treturn rawObjectSizeLimit;\n\t}\n    \n    public void setRawObjectSizeLimit(BigDecimal limit) {\n    \tthis.rawObjectSizeLimit = limit;\n    }\n    \n\n\tpublic void setOwner(String owner)\n    {\n        this.owner = owner;\n    }\n\n    public ExasolTableCache getTableCache() {\n        return tableCache;\n    }\n\n    public ExasolViewCache getViewCache() {\n        return viewCache;\n    }\n\n\n    public ExasolTableUniqueKeyCache getConstraintCache() {\n        return constraintCache;\n    }\n\n    public ExasolTableForeignKeyCache getAssociationCache() {\n        return associationCache;\n    }\n\n\t@Override\n\tpublic String getObjectDefinitionText(DBRProgressMonitor monitor, Map<String, Object> options)\n\t\t\tthrows DBException\n\t{\n\t\treturn ExasolUtils.generateDDLforSchema(monitor, this);\n\t}\n\t\n\t\n\tpublic static class OwnerListProvider implements IPropertyValueListProvider<ExasolSchema> {\n\t\t\n\t\t@Override\n\t\tpublic boolean allowCustomValue() {\n\t\t\treturn false;\n\t\t}\n\t\t\n\t\tpublic Object[] getPossibleValues(ExasolSchema object)\n\t\t{\n\t\t\tExasolDataSource dataSource = object.getDataSource();\n\n            List<ExasolGrantee> allGrantee = new ArrayList<>();\n            allGrantee.addAll(dataSource.getUserCache().getCachedObjects());\n            allGrantee.addAll(dataSource.getRoleCache().getCachedObjects());\n            return allGrantee.toArray(new Object[0]);\n\t\t}\n\t\t\n\t}\n\t\n\tpublic Boolean isPhysicalSchema()\n\t{\n\t    return true;\n\t}\n\n\tpublic ExasolTableIndexCache getIndexCache() {\n\t\treturn indexCache;\n\t}\n\t\n\t@Association\n\tpublic Collection<ExasolTableIndex> getIndexes(DBRProgressMonitor monitor) throws DBException {\n\t\treturn indexCache.getObjects(monitor, this, null);\n\t}\n\t\n\t\n\t\n\t\n}",
    "repo": "dbeaver/dbeaver",
    "path": "./datasets/diagrams-repos/dbeaver/dbeaver/plugins/org.jkiss.dbeaver.ext.exasol/src/org/jkiss/dbeaver/ext/exasol/model/ExasolSchema.java",
    "query": "How does the ExasolSchema class handle the refreshing of its cached objects, and what is the sequence of operations involved?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'ExasolSchema', 'node_id': 'ExasolSchema', 'description': 'Main class representing Exasol database schema', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'refreshObject', 'node_id': 'refreshObject', 'description': 'Main method to refresh all schema objects', 'visibility': 'public', 'return_type': 'DBSObject', 'params': 'DBRProgressMonitor monitor', 'source_class_id': 'ExasolSchema'}, {'type': 'method', 'name': 'refresh', 'node_id': 'refresh', 'description': 'Internal method to refresh schema details', 'visibility': 'private', 'return_type': 'void', 'params': 'DBRProgressMonitor monitor', 'source_class_id': 'ExasolSchema'}, {'type': 'field', 'name': 'refreshed', 'node_id': 'refreshed', 'description': 'Flag indicating if schema was refreshed', 'visibility': 'private', 'return_type': 'Boolean', 'params': None, 'source_class_id': 'ExasolSchema'}, {'type': 'field', 'name': 'scriptCache', 'node_id': 'scriptCache', 'description': 'Cache for schema scripts', 'visibility': 'public', 'return_type': 'DBSObjectCache', 'params': None, 'source_class_id': 'ExasolSchema'}, {'type': 'field', 'name': 'tableCache', 'node_id': 'tableCache', 'description': 'Cache for schema tables', 'visibility': 'private', 'return_type': 'ExasolTableCache', 'params': None, 'source_class_id': 'ExasolSchema'}, {'type': 'field', 'name': 'viewCache', 'node_id': 'viewCache', 'description': 'Cache for schema views', 'visibility': 'private', 'return_type': 'ExasolViewCache', 'params': None, 'source_class_id': 'ExasolSchema'}], 'edges': [{'node_id_from': 'refreshObject', 'node_id_to': 'refresh', 'description': 'calls'}, {'node_id_from': 'refreshObject', 'node_id_to': 'scriptCache', 'description': 'clears'}, {'node_id_from': 'refreshObject', 'node_id_to': 'tableCache', 'description': 'clears'}, {'node_id_from': 'refreshObject', 'node_id_to': 'viewCache', 'description': 'clears'}, {'node_id_from': 'ExasolSchema', 'node_id_to': 'refreshObject', 'description': ''}, {'node_id_from': 'ExasolSchema', 'node_id_to': 'refreshed', 'description': ''}, {'node_id_from': 'ExasolSchema', 'node_id_to': 'refresh', 'description': ''}, {'node_id_from': 'ExasolSchema', 'node_id_to': 'scriptCache', 'description': ''}, {'node_id_from': 'ExasolSchema', 'node_id_to': 'tableCache', 'description': ''}, {'node_id_from': 'ExasolSchema', 'node_id_to': 'viewCache', 'description': ''}], 'packages': [{'package_id': 'refreshLogic', 'children': ['refreshObject', 'refresh', 'refreshed'], 'description': 'Core refresh functionality'}, {'package_id': 'caches', 'children': ['scriptCache', 'tableCache', 'viewCache'], 'description': 'Schema object caches'}]}",
    "version": "medium",
    "text_answer": "ExasolSchema refreshes its cached objects through the refreshObject method, which first refreshes the data source, then clears all caches (scripts, functions, tables, views, constraints, foreign keys, and indexes), and finally resets the refreshed flag. The private refresh method handles detailed schema information updates when needed.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.jkiss.dbeaver.ext.exasol.model;\n\nimport org.jkiss.code.NotNull;\nimport org.jkiss.code.Nullable;\nimport org.jkiss.dbeaver.DBException;\nimport org.jkiss.dbeaver.Log;\nimport org.jkiss.dbeaver.ext.exasol.ExasolMessages;\nimport org.jkiss.dbeaver.ext.exasol.ExasolSysTablePrefix;\nimport org.jkiss.dbeaver.ext.exasol.model.cache.*;\nimport org.jkiss.dbeaver.ext.exasol.model.security.ExasolGrantee;\nimport org.jkiss.dbeaver.ext.exasol.tools.ExasolJDBCObjectSimpleCacheLiterals;\nimport org.jkiss.dbeaver.ext.exasol.tools.ExasolUtils;\nimport org.jkiss.dbeaver.model.*;\nimport org.jkiss.dbeaver.model.exec.DBCException;\nimport org.jkiss.dbeaver.model.exec.jdbc.JDBCPreparedStatement;\nimport org.jkiss.dbeaver.model.exec.jdbc.JDBCResultSet;\nimport org.jkiss.dbeaver.model.exec.jdbc.JDBCSession;\nimport org.jkiss.dbeaver.model.impl.jdbc.JDBCUtils;\nimport org.jkiss.dbeaver.model.meta.Association;\nimport org.jkiss.dbeaver.model.meta.IPropertyValueListProvider;\nimport org.jkiss.dbeaver.model.meta.Property;\nimport org.jkiss.dbeaver.model.meta.PropertyLength;\nimport org.jkiss.dbeaver.model.runtime.DBRProgressMonitor;\nimport org.jkiss.dbeaver.model.struct.DBSObject;\nimport org.jkiss.dbeaver.model.struct.cache.DBSObjectCache;\nimport org.jkiss.dbeaver.model.struct.rdb.DBSProcedureContainer;\nimport org.jkiss.dbeaver.model.struct.rdb.DBSSchema;\nimport org.jkiss.utils.ByteNumberFormat;\n\nimport java.math.BigDecimal;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.sql.Timestamp;\nimport java.util.*;\nimport java.util.stream.Collectors;\n\n\npublic class ExasolSchema extends ExasolGlobalObject implements DBSSchema, DBPNamedObject2,  DBPRefreshableObject, DBPSystemObject, DBSProcedureContainer, DBPScriptObject {\n\n    private static final List<String> SYSTEM_SCHEMA = Arrays.asList(\"SYS\",\"EXA_STATISTICS\");\n    private static final Log log = Log.getLog(ExasolSchema.class);    \n    private String name;\n    private String owner;\n    private Timestamp createTime;\n    private String remarks;\n    private long objectId;\n    private String tablePrefix;\n    private BigDecimal rawObjectSize;\n    private BigDecimal memObjectSize;\n    private BigDecimal rawObjectSizeLimit;\n    private Boolean refreshed = false; \n\n\n    // ExasolSchema's children\n    public final DBSObjectCache<ExasolSchema, ExasolScript> scriptCache;\n\n    public final DBSObjectCache<ExasolSchema, ExasolFunction> functionCache;\n    private ExasolViewCache viewCache = new ExasolViewCache();\n    private ExasolTableCache tableCache = new ExasolTableCache();\n    \n    // ExasolTable's children\n    private final ExasolTableUniqueKeyCache constraintCache = new ExasolTableUniqueKeyCache(tableCache);\n    private final ExasolTableForeignKeyCache associationCache = new ExasolTableForeignKeyCache(tableCache);\n    private final ExasolTableIndexCache indexCache = new ExasolTableIndexCache(tableCache);\n\n    public ExasolSchema(ExasolDataSource exasolDataSource, String name, String owner) {\n        super(exasolDataSource, true);\n        this.tablePrefix = exasolDataSource.getTablePrefix(ExasolSysTablePrefix.ALL);\n        this.name = name;\n        this.owner = owner;\n        this.scriptCache = new ExasolJDBCObjectSimpleCacheLiterals<>(\n        \t\tExasolScript.class,\n        \t\t\"/*snapshot execution*/ select \"\n        \t\t+ \"script_name,script_owner,script_language,script_type,script_result_type,script_text,script_comment,b.created \"\n        \t\t+ \"from SYS.\" + tablePrefix + \"_SCRIPTS a inner join SYS.\" + tablePrefix + \"_OBJECTS b \"\n        \t\t+ \"on a.SCRIPT_OBJECT_ID  = b.object_id and b.object_type = 'SCRIPT' where a.script_schema = '%s' \"\n        \t\t+ \"order by script_name\",\n        \t\tname);\n\n        this.functionCache = new ExasolJDBCObjectSimpleCacheLiterals<>(ExasolFunction.class,\n                \"/*snapshot execution*/ SELECT\\n\" + \n                \"    F.*,\\n\" + \n                \"    O.CREATED\\n\" + \n                \"FROM\\n\" + \n                \"    SYS.\" +  tablePrefix + \"_FUNCTIONS F\\n\" + \n                \"INNER JOIN SYS.\" + tablePrefix + \"_OBJECTS O ON\\n\" + \n                \"    F.FUNCTION_OBJECT_ID = O.OBJECT_ID\\n\" + \n                \"WHERE\\n\" + \n                \"    F.FUNCTION_SCHEMA = '%s' and O.OBJECT_TYPE = 'FUNCTION' AND o.ROOT_NAME = '%s'\\n\" + \n                \"ORDER BY\\n\" + \n                \"    FUNCTION_NAME\\n\", \n                name,name);\n        \n        \n        \n\n    }\n\n    public ExasolSchema(ExasolDataSource exasolDataSource, ResultSet dbResult) throws DBException {\n\n        this(\n                exasolDataSource, \n                JDBCUtils.safeGetStringTrimmed(dbResult, \"OBJECT_NAME\"), \n                JDBCUtils.safeGetString(dbResult, \"OWNER\")\n            );\n        this.createTime = JDBCUtils.safeGetTimestamp(dbResult, \"CREATED\");\n        this.remarks = JDBCUtils.safeGetString(dbResult, \"OBJECT_COMMENT\");\n        this.name = JDBCUtils.safeGetString(dbResult, \"OBJECT_NAME\");\n        this.objectId = JDBCUtils.safeGetLong(dbResult, \"SCHEMA_OBJECT_ID\");\n\n\n    }\n    \n    @NotNull\n    @Override\n    @Property(viewable = true, editable = false, order = 1)\n    public String getName() {\n        return this.name;\n    }\n    \n    @Override\n    public void setName(String name) {\n        this.name = name;\n    }\n    \n    @Override\n    public Collection<ExasolTableBase> getChildren(@NotNull DBRProgressMonitor monitor) throws DBException {\n        List<ExasolTableBase> allChildren = new ArrayList<>();\n        allChildren.addAll(tableCache.getAllObjects(monitor, this));\n        allChildren.addAll(viewCache.getAllObjects(monitor, this));\n        return allChildren;\n    }\n\n    @Override\n    public ExasolTableBase getChild(@NotNull DBRProgressMonitor monitor, @NotNull String childName) throws DBException {\n\n        ExasolTableBase child = tableCache.getObject(monitor, this, childName);\n        if (child == null) {\n            child = viewCache.getObject(monitor, this, childName);\n        }\n        return child;\n    }\n\n    @NotNull\n    @Override\n    public Class<ExasolTable> getPrimaryChildType(@Nullable DBRProgressMonitor monitor) throws DBException {\n    \treturn ExasolTable.class;\n    }\n\n    @Override\n    public synchronized void cacheStructure(@NotNull DBRProgressMonitor monitor, int scope) throws DBException {\n    \t\n        if (((scope & STRUCT_ENTITIES) != 0)) {\n            monitor.subTask(\"Cache tables\");\n            tableCache.getAllObjects(monitor, this);\n            monitor.subTask(\"Cache Views\");\n            viewCache.getAllObjects(monitor, this);\n        }\n        if (((scope & STRUCT_ATTRIBUTES) != 0)) {\n            monitor.subTask(\"Cache table columns\");\n            tableCache.loadChildren(monitor, this, null);\n            monitor.subTask(\"Cache Views\");\n            viewCache.loadChildren(monitor, this, null);\n        }\n\n        if ((scope & STRUCT_ASSOCIATIONS) != 0) {\n            monitor.subTask(\"Cache table unique keys\");\n            constraintCache.getObjects(monitor, this, null);\n            monitor.subTask(\"Cache table foreign keys\");\n            associationCache.getObjects(monitor, this, null);\n            monitor.subTask(\"Cache Indexes\");\n            indexCache.getObjects(monitor, this, null);\n\n        }\n\n\n    }\n\n    // -----------------\n    // Associations\n    // -----------------\n\n    @Association\n    public Collection<ExasolTable> getTables(DBRProgressMonitor monitor) throws DBException {\n        return tableCache.getTypedObjects(monitor, this, ExasolTable.class);\n    }\n\n    public ExasolTable getTable(DBRProgressMonitor monitor, String name) throws DBException {\n        return tableCache.getObject(monitor, this, name, ExasolTable.class);\n    }\n\n    @Association\n    public Collection<ExasolView> getViews(DBRProgressMonitor monitor) throws DBException {\n        return viewCache.getTypedObjects(monitor, this, ExasolView.class);\n    }\n\n    public ExasolView getView(DBRProgressMonitor monitor, String name) throws DBException {\n        return viewCache.getObject(monitor, this, name, ExasolView.class);\n    }\n\n\n    @Override\n    public boolean isSystem() {\n        // TODO Auto-generated method stub\n        return SYSTEM_SCHEMA.contains(name);\n    }\n\n    @Override\n    public Collection<ExasolScript> getProcedures(DBRProgressMonitor monitor) throws DBException {\n\n        return scriptCache.getAllObjects(monitor, this).stream()\n    \t\t\t.filter(o -> o.getType().equals(\"SCRIPTING\"))\n    \t\t\t.collect(Collectors.toCollection(ArrayList::new));\n    }\n    \n    public Collection<ExasolScript> getUdfs(DBRProgressMonitor monitor) throws DBException {\n    \t\n    \treturn scriptCache.getAllObjects(monitor, this).stream()\n    \t\t\t.filter(o -> o.getType().equals(\"UDF\"))\n    \t\t\t.collect(Collectors.toCollection(ArrayList::new));\n    }\n\n    public ExasolScript getUdf(DBRProgressMonitor monitor, String name) throws DBException {\n\n        return scriptCache.getObject(monitor, this, name);\n    }\n\n\n    public Collection<ExasolScript> getAdapter(DBRProgressMonitor monitor) throws DBException {\n\n        return scriptCache.getAllObjects(monitor, this).stream()\n    \t\t\t.filter(o -> o.getType().equals(\"ADAPTER\"))\n    \t\t\t.collect(Collectors.toCollection(ArrayList::new));\n\n    }\n\n    public ExasolScript getAdapter(DBRProgressMonitor monitor, String name) throws DBException {\n\n        return scriptCache.getObject(monitor, this, name);\n    }\n    \n    \n    @Override\n    public ExasolScript getProcedure(DBRProgressMonitor monitor, String uniqueName) throws DBException {\n\n        return scriptCache.getObject(monitor, this, uniqueName);\n    }\n\n    public Collection<ExasolFunction> getFunctions(DBRProgressMonitor monitor) throws DBException {\n        return functionCache.getAllObjects(monitor, this);\n    }\n    \n    public ExasolFunction getFunction(DBRProgressMonitor monitor,String name) throws DBException {\n        return functionCache.getObject(monitor, this, name);\n    }\n\n    \n    @Override\n    public DBSObject refreshObject(@NotNull DBRProgressMonitor monitor) throws DBException {\n        \n        ((ExasolDataSource) getDataSource()).refreshObject(monitor);\n        functionCache.clearCache();\n        scriptCache.clearCache();\n        tableCache.clearCache();\n        viewCache.clearCache();\n        indexCache.clearCache();\n\n\n        constraintCache.clearCache();\n        associationCache.clearCache();\n        refreshed=false;\n        return this;\n    }\n\n    @Override\n    public String toString() {\n        return \"Schema \" + name;\n    }\n    \n    private synchronized void refresh(DBRProgressMonitor monitor) throws DBCException\n    {\n    \tif (!refreshed && this.objectId != 0) {\n\t    \tJDBCSession session = DBUtils.openMetaSession(monitor, this, ExasolMessages.read_schema_details );\n\t    \ttry (JDBCPreparedStatement stmt = session.prepareStatement(\"/*snapshot execution*/ SELECT * FROM SYS.\"+getDataSource().getTablePrefix(ExasolSysTablePrefix.ALL)+\"_OBJECT_SIZES WHERE OBJECT_ID = ?\"))\n\t    \t{\n\t    \t\tstmt.setLong(1, this.objectId);\n\t    \t\ttry (JDBCResultSet dbResult = stmt.executeQuery()) \n\t    \t\t{\n\t    \t\t\tif (dbResult.next()) {\n                        this.createTime = JDBCUtils.safeGetTimestamp(dbResult, \"CREATED\");\n                        this.rawObjectSize = JDBCUtils.safeGetBigDecimal(dbResult, \"RAW_OBJECT_SIZE\");\n                        this.memObjectSize = JDBCUtils.safeGetBigDecimal(dbResult, \"MEM_OBJECT_SIZE\");\n                        this.rawObjectSizeLimit = JDBCUtils.safeGetBigDecimal(dbResult, \"RAW_OBJECT_SIZE_LIMIT\");\n                    }\n\t    \t\t}\n\t    \t\trefreshed = true;\n\t    \t} catch (SQLException e) {\n\t    \t\tthrow new DBCException(e, session.getExecutionContext());\n\t\t\t}\n    \t}\n\t\t\n\t}\n\n    @Property(viewable = true, editable = false, order = 2)\n    public Timestamp getCreateTime(DBRProgressMonitor monitor) throws DBCException {\n    \trefresh(monitor);\n        return createTime;\n    }\n\n    @Property(viewable = true, editable = true, updatable = true, length = PropertyLength.MULTILINE, order = 3)\n    public String getDescription() {\n        return remarks;\n    }\n    \n    public void setDescription(String newRemarks)\n    {\n    \tremarks = newRemarks;\n    }\n\n    @Property(viewable = true, editable = false, updatable = true,  order = 4)\n    public String getOwner() {\n        return owner;\n    }\n\n    \n    \n    @Property(viewable = true, editable = false, updatable =  false,  order = 5, formatter = ByteNumberFormat.class)\n    public long getRawObjectSize() {\n    \tif (rawObjectSize == null)\n    \t\treturn -1;\n\t\treturn rawObjectSize.longValue();\n\t}\n\n    @Property(viewable = true, editable = false, updatable =  false,  order = 6, formatter = ByteNumberFormat.class)\n\tpublic long getMemObjectSize() {\n    \tif (memObjectSize == null)\n    \t\treturn -1;\n\t\treturn memObjectSize.longValue();\n\t}\n\n    @Property(viewable = true, editable = true, updatable = true,  order = 7)\n\tpublic BigDecimal getRawObjectSizeLimit() {\n\t\treturn rawObjectSizeLimit;\n\t}\n    \n    public void setRawObjectSizeLimit(BigDecimal limit) {\n    \tthis.rawObjectSizeLimit = limit;\n    }\n    \n\n\tpublic void setOwner(String owner)\n    {\n        this.owner = owner;\n    }\n\n    public ExasolTableCache getTableCache() {\n        return tableCache;\n    }\n\n    public ExasolViewCache getViewCache() {\n        return viewCache;\n    }\n\n\n    public ExasolTableUniqueKeyCache getConstraintCache() {\n        return constraintCache;\n    }\n\n    public ExasolTableForeignKeyCache getAssociationCache() {\n        return associationCache;\n    }\n\n\t@Override\n\tpublic String getObjectDefinitionText(DBRProgressMonitor monitor, Map<String, Object> options)\n\t\t\tthrows DBException\n\t{\n\t\treturn ExasolUtils.generateDDLforSchema(monitor, this);\n\t}\n\t\n\t\n\tpublic static class OwnerListProvider implements IPropertyValueListProvider<ExasolSchema> {\n\t\t\n\t\t@Override\n\t\tpublic boolean allowCustomValue() {\n\t\t\treturn false;\n\t\t}\n\t\t\n\t\tpublic Object[] getPossibleValues(ExasolSchema object)\n\t\t{\n\t\t\tExasolDataSource dataSource = object.getDataSource();\n\n            List<ExasolGrantee> allGrantee = new ArrayList<>();\n            allGrantee.addAll(dataSource.getUserCache().getCachedObjects());\n            allGrantee.addAll(dataSource.getRoleCache().getCachedObjects());\n            return allGrantee.toArray(new Object[0]);\n\t\t}\n\t\t\n\t}\n\t\n\tpublic Boolean isPhysicalSchema()\n\t{\n\t    return true;\n\t}\n\n\tpublic ExasolTableIndexCache getIndexCache() {\n\t\treturn indexCache;\n\t}\n\t\n\t@Association\n\tpublic Collection<ExasolTableIndex> getIndexes(DBRProgressMonitor monitor) throws DBException {\n\t\treturn indexCache.getObjects(monitor, this, null);\n\t}\n\t\n\t\n\t\n\t\n}",
    "repo": "dbeaver/dbeaver",
    "path": "./datasets/diagrams-repos/dbeaver/dbeaver/plugins/org.jkiss.dbeaver.ext.exasol/src/org/jkiss/dbeaver/ext/exasol/model/ExasolSchema.java",
    "query": "How does the ExasolSchema class handle the refreshing of its cached objects, and what is the sequence of operations involved?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'ExasolSchema', 'node_id': 'ExasolSchema', 'description': 'Main class representing Exasol database schema', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'refreshObject', 'node_id': 'refreshObject', 'description': 'Main method to refresh all schema objects', 'visibility': 'public', 'return_type': 'DBSObject', 'params': 'DBRProgressMonitor monitor', 'source_class_id': 'ExasolSchema'}, {'type': 'method', 'name': 'refresh', 'node_id': 'refresh', 'description': 'Internal method to refresh schema details', 'visibility': 'private', 'return_type': 'void', 'params': 'DBRProgressMonitor monitor', 'source_class_id': 'ExasolSchema'}, {'type': 'field', 'name': 'refreshed', 'node_id': 'refreshed', 'description': 'Flag indicating if schema was refreshed', 'visibility': 'private', 'return_type': 'Boolean', 'params': None, 'source_class_id': 'ExasolSchema'}, {'type': 'field', 'name': 'scriptCache', 'node_id': 'scriptCache', 'description': 'Cache for schema scripts', 'visibility': 'public', 'return_type': 'DBSObjectCache', 'params': None, 'source_class_id': 'ExasolSchema'}, {'type': 'field', 'name': 'functionCache', 'node_id': 'functionCache', 'description': 'Cache for schema functions', 'visibility': 'public', 'return_type': 'DBSObjectCache', 'params': None, 'source_class_id': 'ExasolSchema'}, {'type': 'field', 'name': 'tableCache', 'node_id': 'tableCache', 'description': 'Cache for schema tables', 'visibility': 'private', 'return_type': 'ExasolTableCache', 'params': None, 'source_class_id': 'ExasolSchema'}, {'type': 'field', 'name': 'viewCache', 'node_id': 'viewCache', 'description': 'Cache for schema views', 'visibility': 'private', 'return_type': 'ExasolViewCache', 'params': None, 'source_class_id': 'ExasolSchema'}, {'type': 'field', 'name': 'constraintCache', 'node_id': 'constraintCache', 'description': 'Cache for table constraints', 'visibility': 'private', 'return_type': 'ExasolTableUniqueKeyCache', 'params': None, 'source_class_id': 'ExasolSchema'}, {'type': 'field', 'name': 'associationCache', 'node_id': 'associationCache', 'description': 'Cache for table foreign keys', 'visibility': 'private', 'return_type': 'ExasolTableForeignKeyCache', 'params': None, 'source_class_id': 'ExasolSchema'}, {'type': 'field', 'name': 'indexCache', 'node_id': 'indexCache', 'description': 'Cache for table indexes', 'visibility': 'private', 'return_type': 'ExasolTableIndexCache', 'params': None, 'source_class_id': 'ExasolSchema'}], 'edges': [{'node_id_from': 'refreshObject', 'node_id_to': 'refresh', 'description': 'calls'}, {'node_id_from': 'refreshObject', 'node_id_to': 'scriptCache', 'description': 'clears'}, {'node_id_from': 'refreshObject', 'node_id_to': 'functionCache', 'description': 'clears'}, {'node_id_from': 'refreshObject', 'node_id_to': 'tableCache', 'description': 'clears'}, {'node_id_from': 'refreshObject', 'node_id_to': 'viewCache', 'description': 'clears'}, {'node_id_from': 'refreshObject', 'node_id_to': 'constraintCache', 'description': 'clears'}, {'node_id_from': 'refreshObject', 'node_id_to': 'associationCache', 'description': 'clears'}, {'node_id_from': 'refreshObject', 'node_id_to': 'indexCache', 'description': 'clears'}, {'node_id_from': 'ExasolSchema', 'node_id_to': 'refreshObject', 'description': ''}, {'node_id_from': 'ExasolSchema', 'node_id_to': 'refreshed', 'description': ''}, {'node_id_from': 'ExasolSchema', 'node_id_to': 'refresh', 'description': ''}, {'node_id_from': 'ExasolSchema', 'node_id_to': 'scriptCache', 'description': ''}, {'node_id_from': 'ExasolSchema', 'node_id_to': 'functionCache', 'description': ''}, {'node_id_from': 'ExasolSchema', 'node_id_to': 'tableCache', 'description': ''}, {'node_id_from': 'ExasolSchema', 'node_id_to': 'viewCache', 'description': ''}, {'node_id_from': 'ExasolSchema', 'node_id_to': 'constraintCache', 'description': ''}, {'node_id_from': 'ExasolSchema', 'node_id_to': 'associationCache', 'description': ''}, {'node_id_from': 'ExasolSchema', 'node_id_to': 'indexCache', 'description': ''}], 'packages': [{'package_id': 'refreshLogic', 'children': ['refreshObject', 'refresh', 'refreshed'], 'description': 'Core refresh functionality'}, {'package_id': 'caches', 'children': ['scriptCache', 'functionCache', 'tableCache', 'viewCache', 'constraintCache', 'associationCache', 'indexCache'], 'description': 'Schema object caches'}]}",
    "version": "full",
    "text_answer": "ExasolSchema refreshes its cached objects through the refreshObject method, which first refreshes the data source, then clears all caches (scripts, functions, tables, views, constraints, foreign keys, and indexes), and finally resets the refreshed flag. The private refresh method handles detailed schema information updates when needed.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.activiti.spring.boot.process;\n\nimport static org.assertj.core.api.Assertions.assertThat;\nimport static org.assertj.core.api.Assertions.tuple;\n\nimport org.activiti.api.process.model.ProcessDefinition;\nimport org.activiti.api.process.model.ProcessInstance;\nimport org.activiti.api.process.model.ProcessInstance.ProcessInstanceStatus;\nimport org.activiti.api.process.model.builders.ProcessPayloadBuilder;\nimport org.activiti.api.process.model.events.BPMNSignalEvent;\nimport org.activiti.api.process.model.events.BPMNSignalReceivedEvent;\nimport org.activiti.api.process.model.payloads.SignalPayload;\nimport org.activiti.api.process.runtime.ProcessRuntime;\nimport org.activiti.api.runtime.shared.query.Page;\nimport org.activiti.api.runtime.shared.query.Pageable;\nimport org.activiti.spring.boot.process.listener.DummyBPMNSignalReceivedListener;\nimport org.activiti.spring.boot.security.util.SecurityUtil;\nimport org.activiti.spring.boot.test.util.ProcessCleanUpUtil;\nimport org.assertj.core.groups.Tuple;\nimport org.junit.jupiter.api.AfterEach;\nimport org.junit.jupiter.api.BeforeEach;\nimport org.junit.jupiter.api.Test;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.test.context.SpringBootTest;\nimport org.springframework.context.annotation.Import;\n\n@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.NONE)\npublic class ProcessRuntimeBPMNSignalReceivedIT {\n\n    private static final String PROCESS_WITH_BOUNDARY_SIGNAL = \"ProcessWithBoundarySignal\";\n\n    @Autowired\n    private ProcessRuntime processRuntime;\n\n    @Autowired\n    private SecurityUtil securityUtil;\n\n    @Autowired\n    private DummyBPMNSignalReceivedListener listener;\n\n    @Autowired\n    private ProcessCleanUpUtil processCleanUpUtil;\n\n    @BeforeEach\n    public void setUp() {\n        listener.clear();\n    }\n\n    @AfterEach\n    public void tearDown() {\n        processCleanUpUtil.cleanUpWithAdmin();\n    }\n\n    @Test\n    public void shouldGetSignalReceivedEventsForProcessWithSignalStart() {\n\n        //In this test processWithSignalStart1 should be started\n        //given\n        securityUtil.logInAs(\"user\");\n        Page<ProcessDefinition> processDefinitionPage = processRuntime\n                .processDefinitions(Pageable.of(0,\n                                                10),\n                                    ProcessPayloadBuilder\n                                            .processDefinitions()\n                                            .withProcessDefinitionKey(\"processWithSignalStart1\")\n                                            .build());\n        assertThat(processDefinitionPage.getContent()).hasSize(1);\n\n        //when\n        SignalPayload signalPayload = new SignalPayload(\"The Signal\",\n                                                        null);\n        processRuntime.signal(signalPayload);\n\n        //then\n        String processDefinitionId = processDefinitionPage.getContent().get(0).getId();\n        assertThat(listener.getSignalReceivedEvents())\n                .extracting(BPMNSignalReceivedEvent::getEventType,\n                            BPMNSignalReceivedEvent::getProcessDefinitionId,\n                            event -> event.getEntity().getSignalPayload().getName(),\n                            event -> event.getEntity().getElementId(),\n                            event -> event.getEntity().getProcessDefinitionId()\n                )\n                .contains(Tuple.tuple(BPMNSignalEvent.SignalEvents.SIGNAL_RECEIVED,\n                                      processDefinitionId,\n                                      \"The Signal\",\n                                      \"theStart\",\n                                      processDefinitionId\n                ));\n    }\n\n    @Test\n    public void shouldGetOneSignalReceivedEventPerWaitingSignalsForNonStartSignals() {\n\n        //given\n        securityUtil.logInAs(\"user\");\n\n        ProcessInstance boundarySignalProcInst1 = processRuntime.start(ProcessPayloadBuilder.start()\n                                                                               .withProcessDefinitionKey(PROCESS_WITH_BOUNDARY_SIGNAL)\n                                                                               .build());\n\n        ProcessInstance boundarySignalProcInst2 = processRuntime.start(ProcessPayloadBuilder.start()\n                                                                               .withProcessDefinitionKey(PROCESS_WITH_BOUNDARY_SIGNAL)\n                                                                               .build());\n\n        //when\n        ProcessInstance process = processRuntime.start(ProcessPayloadBuilder.start()\n                                     .withProcessDefinitionKey(\"signalThrowEventProcess\")\n                                     .build());\n\n        //then\n        assertThat(listener.getSignalReceivedEvents())\n                .isNotEmpty()\n                .hasSize(2);\n\n        assertThat(listener.getSignalReceivedEvents())\n                .extracting(BPMNSignalReceivedEvent::getEventType,\n                            BPMNSignalReceivedEvent::getProcessDefinitionId,\n                            BPMNSignalReceivedEvent::getProcessInstanceId,\n                            event -> event.getEntity().getSignalPayload().getName(),\n                            event -> event.getEntity().getElementId(),\n                            event -> event.getEntity().getProcessDefinitionId(),\n                            event -> event.getEntity().getProcessInstanceId()\n                )\n                .contains(\n                        tuple(BPMNSignalEvent.SignalEvents.SIGNAL_RECEIVED,\n                              boundarySignalProcInst1.getProcessDefinitionId(),\n                              boundarySignalProcInst1.getId(),\n                              \"go\",\n                              \"sid-6220E76D-719E-4C05-A664-BC186E50D477\",\n                              boundarySignalProcInst1.getProcessDefinitionId(),\n                              boundarySignalProcInst1.getId()\n                        ),\n                        tuple(BPMNSignalEvent.SignalEvents.SIGNAL_RECEIVED,\n                              boundarySignalProcInst2.getProcessDefinitionId(),\n                              boundarySignalProcInst2.getId(),\n                              \"go\",\n                              \"sid-6220E76D-719E-4C05-A664-BC186E50D477\",\n                              boundarySignalProcInst2.getProcessDefinitionId(),\n                              boundarySignalProcInst2.getId()\n                        )\n                );\n\n        assertThat(process.getStatus()).isEqualTo(ProcessInstanceStatus.COMPLETED);\n    }\n\n    @Test\n    public void shouldGetSignalReceivedEventWithVariables() {\n\n        //given\n        securityUtil.logInAs(\"user\");\n\n        //when\n        ProcessInstance process = processRuntime.start(ProcessPayloadBuilder.start()\n                                                               .withProcessDefinitionKey(PROCESS_WITH_BOUNDARY_SIGNAL)\n                                                               .withVariable(\"name\",\n                                                                             \"peter\")\n                                                               .build());\n\n        SignalPayload signalPayload = ProcessPayloadBuilder.signal()\n                .withName(\"go\")\n                .withVariable(\"signal_variable\",\n                              \"test\")\n                .build();\n        processRuntime.signal(signalPayload);\n\n        //then\n        assertThat(listener.getSignalReceivedEvents())\n                .isNotEmpty()\n                .hasSize(1);\n\n        BPMNSignalReceivedEvent event = listener.getSignalReceivedEvents().iterator().next();\n\n        assertThat(event.getEntity()).isNotNull();\n        assertThat(event.getProcessInstanceId()).isEqualTo(process.getId());\n        assertThat(event.getEntity().getSignalPayload()).isNotNull();\n        assertThat(event.getEntity().getSignalPayload().getName()).isEqualTo(\"go\");\n        assertThat(event.getEntity().getSignalPayload().getVariables().size()).isEqualTo(1);\n        assertThat(event.getEntity().getSignalPayload().getVariables().get(\"signal_variable\")).isEqualTo(\"test\");\n    }\n\n\n}",
    "repo": "Activiti/Activiti",
    "path": "./datasets/diagrams-repos/Activiti/Activiti/activiti-core/activiti-spring-boot-starter/src/test/java/org/activiti/spring/boot/process/ProcessRuntimeBPMNSignalReceivedIT.java",
    "query": "Show the interaction between ProcessRuntime and BPMNSignalReceivedEvent during signal emission and reception.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'ProcessRuntime', 'node_id': 'ProcessRuntime', 'description': 'Core runtime service for process execution', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'BPMNSignalReceivedEvent', 'node_id': 'BPMNSignalReceivedEvent', 'description': 'Event representing received BPMN signal', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'signal', 'node_id': 'signal', 'description': 'Emits signal with payload', 'visibility': 'public', 'return_type': 'void', 'params': 'SignalPayload', 'source_class_id': 'ProcessRuntime'}], 'edges': [{'node_id_from': 'ProcessRuntime', 'node_id_to': 'signal', 'description': 'executes'}, {'node_id_from': 'signal', 'node_id_to': 'BPMNSignalReceivedEvent', 'description': 'generates'}], 'packages': [{'package_id': 'signalProcessing', 'children': ['ProcessRuntime', 'signal', 'BPMNSignalReceivedEvent'], 'description': 'Core signal handling components'}]}",
    "version": "minimal",
    "text_answer": "ProcessRuntime emits signals using SignalPayload, which generates BPMNSignalReceivedEvents that are associated with specific ProcessInstances.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.activiti.spring.boot.process;\n\nimport static org.assertj.core.api.Assertions.assertThat;\nimport static org.assertj.core.api.Assertions.tuple;\n\nimport org.activiti.api.process.model.ProcessDefinition;\nimport org.activiti.api.process.model.ProcessInstance;\nimport org.activiti.api.process.model.ProcessInstance.ProcessInstanceStatus;\nimport org.activiti.api.process.model.builders.ProcessPayloadBuilder;\nimport org.activiti.api.process.model.events.BPMNSignalEvent;\nimport org.activiti.api.process.model.events.BPMNSignalReceivedEvent;\nimport org.activiti.api.process.model.payloads.SignalPayload;\nimport org.activiti.api.process.runtime.ProcessRuntime;\nimport org.activiti.api.runtime.shared.query.Page;\nimport org.activiti.api.runtime.shared.query.Pageable;\nimport org.activiti.spring.boot.process.listener.DummyBPMNSignalReceivedListener;\nimport org.activiti.spring.boot.security.util.SecurityUtil;\nimport org.activiti.spring.boot.test.util.ProcessCleanUpUtil;\nimport org.assertj.core.groups.Tuple;\nimport org.junit.jupiter.api.AfterEach;\nimport org.junit.jupiter.api.BeforeEach;\nimport org.junit.jupiter.api.Test;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.test.context.SpringBootTest;\nimport org.springframework.context.annotation.Import;\n\n@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.NONE)\npublic class ProcessRuntimeBPMNSignalReceivedIT {\n\n    private static final String PROCESS_WITH_BOUNDARY_SIGNAL = \"ProcessWithBoundarySignal\";\n\n    @Autowired\n    private ProcessRuntime processRuntime;\n\n    @Autowired\n    private SecurityUtil securityUtil;\n\n    @Autowired\n    private DummyBPMNSignalReceivedListener listener;\n\n    @Autowired\n    private ProcessCleanUpUtil processCleanUpUtil;\n\n    @BeforeEach\n    public void setUp() {\n        listener.clear();\n    }\n\n    @AfterEach\n    public void tearDown() {\n        processCleanUpUtil.cleanUpWithAdmin();\n    }\n\n    @Test\n    public void shouldGetSignalReceivedEventsForProcessWithSignalStart() {\n\n        //In this test processWithSignalStart1 should be started\n        //given\n        securityUtil.logInAs(\"user\");\n        Page<ProcessDefinition> processDefinitionPage = processRuntime\n                .processDefinitions(Pageable.of(0,\n                                                10),\n                                    ProcessPayloadBuilder\n                                            .processDefinitions()\n                                            .withProcessDefinitionKey(\"processWithSignalStart1\")\n                                            .build());\n        assertThat(processDefinitionPage.getContent()).hasSize(1);\n\n        //when\n        SignalPayload signalPayload = new SignalPayload(\"The Signal\",\n                                                        null);\n        processRuntime.signal(signalPayload);\n\n        //then\n        String processDefinitionId = processDefinitionPage.getContent().get(0).getId();\n        assertThat(listener.getSignalReceivedEvents())\n                .extracting(BPMNSignalReceivedEvent::getEventType,\n                            BPMNSignalReceivedEvent::getProcessDefinitionId,\n                            event -> event.getEntity().getSignalPayload().getName(),\n                            event -> event.getEntity().getElementId(),\n                            event -> event.getEntity().getProcessDefinitionId()\n                )\n                .contains(Tuple.tuple(BPMNSignalEvent.SignalEvents.SIGNAL_RECEIVED,\n                                      processDefinitionId,\n                                      \"The Signal\",\n                                      \"theStart\",\n                                      processDefinitionId\n                ));\n    }\n\n    @Test\n    public void shouldGetOneSignalReceivedEventPerWaitingSignalsForNonStartSignals() {\n\n        //given\n        securityUtil.logInAs(\"user\");\n\n        ProcessInstance boundarySignalProcInst1 = processRuntime.start(ProcessPayloadBuilder.start()\n                                                                               .withProcessDefinitionKey(PROCESS_WITH_BOUNDARY_SIGNAL)\n                                                                               .build());\n\n        ProcessInstance boundarySignalProcInst2 = processRuntime.start(ProcessPayloadBuilder.start()\n                                                                               .withProcessDefinitionKey(PROCESS_WITH_BOUNDARY_SIGNAL)\n                                                                               .build());\n\n        //when\n        ProcessInstance process = processRuntime.start(ProcessPayloadBuilder.start()\n                                     .withProcessDefinitionKey(\"signalThrowEventProcess\")\n                                     .build());\n\n        //then\n        assertThat(listener.getSignalReceivedEvents())\n                .isNotEmpty()\n                .hasSize(2);\n\n        assertThat(listener.getSignalReceivedEvents())\n                .extracting(BPMNSignalReceivedEvent::getEventType,\n                            BPMNSignalReceivedEvent::getProcessDefinitionId,\n                            BPMNSignalReceivedEvent::getProcessInstanceId,\n                            event -> event.getEntity().getSignalPayload().getName(),\n                            event -> event.getEntity().getElementId(),\n                            event -> event.getEntity().getProcessDefinitionId(),\n                            event -> event.getEntity().getProcessInstanceId()\n                )\n                .contains(\n                        tuple(BPMNSignalEvent.SignalEvents.SIGNAL_RECEIVED,\n                              boundarySignalProcInst1.getProcessDefinitionId(),\n                              boundarySignalProcInst1.getId(),\n                              \"go\",\n                              \"sid-6220E76D-719E-4C05-A664-BC186E50D477\",\n                              boundarySignalProcInst1.getProcessDefinitionId(),\n                              boundarySignalProcInst1.getId()\n                        ),\n                        tuple(BPMNSignalEvent.SignalEvents.SIGNAL_RECEIVED,\n                              boundarySignalProcInst2.getProcessDefinitionId(),\n                              boundarySignalProcInst2.getId(),\n                              \"go\",\n                              \"sid-6220E76D-719E-4C05-A664-BC186E50D477\",\n                              boundarySignalProcInst2.getProcessDefinitionId(),\n                              boundarySignalProcInst2.getId()\n                        )\n                );\n\n        assertThat(process.getStatus()).isEqualTo(ProcessInstanceStatus.COMPLETED);\n    }\n\n    @Test\n    public void shouldGetSignalReceivedEventWithVariables() {\n\n        //given\n        securityUtil.logInAs(\"user\");\n\n        //when\n        ProcessInstance process = processRuntime.start(ProcessPayloadBuilder.start()\n                                                               .withProcessDefinitionKey(PROCESS_WITH_BOUNDARY_SIGNAL)\n                                                               .withVariable(\"name\",\n                                                                             \"peter\")\n                                                               .build());\n\n        SignalPayload signalPayload = ProcessPayloadBuilder.signal()\n                .withName(\"go\")\n                .withVariable(\"signal_variable\",\n                              \"test\")\n                .build();\n        processRuntime.signal(signalPayload);\n\n        //then\n        assertThat(listener.getSignalReceivedEvents())\n                .isNotEmpty()\n                .hasSize(1);\n\n        BPMNSignalReceivedEvent event = listener.getSignalReceivedEvents().iterator().next();\n\n        assertThat(event.getEntity()).isNotNull();\n        assertThat(event.getProcessInstanceId()).isEqualTo(process.getId());\n        assertThat(event.getEntity().getSignalPayload()).isNotNull();\n        assertThat(event.getEntity().getSignalPayload().getName()).isEqualTo(\"go\");\n        assertThat(event.getEntity().getSignalPayload().getVariables().size()).isEqualTo(1);\n        assertThat(event.getEntity().getSignalPayload().getVariables().get(\"signal_variable\")).isEqualTo(\"test\");\n    }\n\n\n}",
    "repo": "Activiti/Activiti",
    "path": "./datasets/diagrams-repos/Activiti/Activiti/activiti-core/activiti-spring-boot-starter/src/test/java/org/activiti/spring/boot/process/ProcessRuntimeBPMNSignalReceivedIT.java",
    "query": "Show the interaction between ProcessRuntime and BPMNSignalReceivedEvent during signal emission and reception.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'ProcessRuntime', 'node_id': 'ProcessRuntime', 'description': 'Core runtime service for process execution', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'BPMNSignalReceivedEvent', 'node_id': 'BPMNSignalReceivedEvent', 'description': 'Event representing received BPMN signal', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'SignalPayload', 'node_id': 'SignalPayload', 'description': 'Container for signal data', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'signal', 'node_id': 'signal', 'description': 'Emits signal with payload', 'visibility': 'public', 'return_type': 'void', 'params': 'SignalPayload', 'source_class_id': 'ProcessRuntime'}, {'type': 'entity', 'name': 'ProcessInstance', 'node_id': 'ProcessInstance', 'description': 'Running instance of a process', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'ProcessRuntime', 'node_id_to': 'signal', 'description': 'executes'}, {'node_id_from': 'signal', 'node_id_to': 'BPMNSignalReceivedEvent', 'description': 'generates'}, {'node_id_from': 'SignalPayload', 'node_id_to': 'signal', 'description': 'input for'}, {'node_id_from': 'ProcessInstance', 'node_id_to': 'BPMNSignalReceivedEvent', 'description': 'associated with'}], 'packages': [{'package_id': 'signalProcessing', 'children': ['ProcessRuntime', 'signal', 'BPMNSignalReceivedEvent', 'SignalPayload'], 'description': 'Signal handling components'}]}",
    "version": "medium",
    "text_answer": "ProcessRuntime emits signals using SignalPayload, which generates BPMNSignalReceivedEvents that are associated with specific ProcessInstances.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.activiti.spring.boot.process;\n\nimport static org.assertj.core.api.Assertions.assertThat;\nimport static org.assertj.core.api.Assertions.tuple;\n\nimport org.activiti.api.process.model.ProcessDefinition;\nimport org.activiti.api.process.model.ProcessInstance;\nimport org.activiti.api.process.model.ProcessInstance.ProcessInstanceStatus;\nimport org.activiti.api.process.model.builders.ProcessPayloadBuilder;\nimport org.activiti.api.process.model.events.BPMNSignalEvent;\nimport org.activiti.api.process.model.events.BPMNSignalReceivedEvent;\nimport org.activiti.api.process.model.payloads.SignalPayload;\nimport org.activiti.api.process.runtime.ProcessRuntime;\nimport org.activiti.api.runtime.shared.query.Page;\nimport org.activiti.api.runtime.shared.query.Pageable;\nimport org.activiti.spring.boot.process.listener.DummyBPMNSignalReceivedListener;\nimport org.activiti.spring.boot.security.util.SecurityUtil;\nimport org.activiti.spring.boot.test.util.ProcessCleanUpUtil;\nimport org.assertj.core.groups.Tuple;\nimport org.junit.jupiter.api.AfterEach;\nimport org.junit.jupiter.api.BeforeEach;\nimport org.junit.jupiter.api.Test;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.test.context.SpringBootTest;\nimport org.springframework.context.annotation.Import;\n\n@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.NONE)\npublic class ProcessRuntimeBPMNSignalReceivedIT {\n\n    private static final String PROCESS_WITH_BOUNDARY_SIGNAL = \"ProcessWithBoundarySignal\";\n\n    @Autowired\n    private ProcessRuntime processRuntime;\n\n    @Autowired\n    private SecurityUtil securityUtil;\n\n    @Autowired\n    private DummyBPMNSignalReceivedListener listener;\n\n    @Autowired\n    private ProcessCleanUpUtil processCleanUpUtil;\n\n    @BeforeEach\n    public void setUp() {\n        listener.clear();\n    }\n\n    @AfterEach\n    public void tearDown() {\n        processCleanUpUtil.cleanUpWithAdmin();\n    }\n\n    @Test\n    public void shouldGetSignalReceivedEventsForProcessWithSignalStart() {\n\n        //In this test processWithSignalStart1 should be started\n        //given\n        securityUtil.logInAs(\"user\");\n        Page<ProcessDefinition> processDefinitionPage = processRuntime\n                .processDefinitions(Pageable.of(0,\n                                                10),\n                                    ProcessPayloadBuilder\n                                            .processDefinitions()\n                                            .withProcessDefinitionKey(\"processWithSignalStart1\")\n                                            .build());\n        assertThat(processDefinitionPage.getContent()).hasSize(1);\n\n        //when\n        SignalPayload signalPayload = new SignalPayload(\"The Signal\",\n                                                        null);\n        processRuntime.signal(signalPayload);\n\n        //then\n        String processDefinitionId = processDefinitionPage.getContent().get(0).getId();\n        assertThat(listener.getSignalReceivedEvents())\n                .extracting(BPMNSignalReceivedEvent::getEventType,\n                            BPMNSignalReceivedEvent::getProcessDefinitionId,\n                            event -> event.getEntity().getSignalPayload().getName(),\n                            event -> event.getEntity().getElementId(),\n                            event -> event.getEntity().getProcessDefinitionId()\n                )\n                .contains(Tuple.tuple(BPMNSignalEvent.SignalEvents.SIGNAL_RECEIVED,\n                                      processDefinitionId,\n                                      \"The Signal\",\n                                      \"theStart\",\n                                      processDefinitionId\n                ));\n    }\n\n    @Test\n    public void shouldGetOneSignalReceivedEventPerWaitingSignalsForNonStartSignals() {\n\n        //given\n        securityUtil.logInAs(\"user\");\n\n        ProcessInstance boundarySignalProcInst1 = processRuntime.start(ProcessPayloadBuilder.start()\n                                                                               .withProcessDefinitionKey(PROCESS_WITH_BOUNDARY_SIGNAL)\n                                                                               .build());\n\n        ProcessInstance boundarySignalProcInst2 = processRuntime.start(ProcessPayloadBuilder.start()\n                                                                               .withProcessDefinitionKey(PROCESS_WITH_BOUNDARY_SIGNAL)\n                                                                               .build());\n\n        //when\n        ProcessInstance process = processRuntime.start(ProcessPayloadBuilder.start()\n                                     .withProcessDefinitionKey(\"signalThrowEventProcess\")\n                                     .build());\n\n        //then\n        assertThat(listener.getSignalReceivedEvents())\n                .isNotEmpty()\n                .hasSize(2);\n\n        assertThat(listener.getSignalReceivedEvents())\n                .extracting(BPMNSignalReceivedEvent::getEventType,\n                            BPMNSignalReceivedEvent::getProcessDefinitionId,\n                            BPMNSignalReceivedEvent::getProcessInstanceId,\n                            event -> event.getEntity().getSignalPayload().getName(),\n                            event -> event.getEntity().getElementId(),\n                            event -> event.getEntity().getProcessDefinitionId(),\n                            event -> event.getEntity().getProcessInstanceId()\n                )\n                .contains(\n                        tuple(BPMNSignalEvent.SignalEvents.SIGNAL_RECEIVED,\n                              boundarySignalProcInst1.getProcessDefinitionId(),\n                              boundarySignalProcInst1.getId(),\n                              \"go\",\n                              \"sid-6220E76D-719E-4C05-A664-BC186E50D477\",\n                              boundarySignalProcInst1.getProcessDefinitionId(),\n                              boundarySignalProcInst1.getId()\n                        ),\n                        tuple(BPMNSignalEvent.SignalEvents.SIGNAL_RECEIVED,\n                              boundarySignalProcInst2.getProcessDefinitionId(),\n                              boundarySignalProcInst2.getId(),\n                              \"go\",\n                              \"sid-6220E76D-719E-4C05-A664-BC186E50D477\",\n                              boundarySignalProcInst2.getProcessDefinitionId(),\n                              boundarySignalProcInst2.getId()\n                        )\n                );\n\n        assertThat(process.getStatus()).isEqualTo(ProcessInstanceStatus.COMPLETED);\n    }\n\n    @Test\n    public void shouldGetSignalReceivedEventWithVariables() {\n\n        //given\n        securityUtil.logInAs(\"user\");\n\n        //when\n        ProcessInstance process = processRuntime.start(ProcessPayloadBuilder.start()\n                                                               .withProcessDefinitionKey(PROCESS_WITH_BOUNDARY_SIGNAL)\n                                                               .withVariable(\"name\",\n                                                                             \"peter\")\n                                                               .build());\n\n        SignalPayload signalPayload = ProcessPayloadBuilder.signal()\n                .withName(\"go\")\n                .withVariable(\"signal_variable\",\n                              \"test\")\n                .build();\n        processRuntime.signal(signalPayload);\n\n        //then\n        assertThat(listener.getSignalReceivedEvents())\n                .isNotEmpty()\n                .hasSize(1);\n\n        BPMNSignalReceivedEvent event = listener.getSignalReceivedEvents().iterator().next();\n\n        assertThat(event.getEntity()).isNotNull();\n        assertThat(event.getProcessInstanceId()).isEqualTo(process.getId());\n        assertThat(event.getEntity().getSignalPayload()).isNotNull();\n        assertThat(event.getEntity().getSignalPayload().getName()).isEqualTo(\"go\");\n        assertThat(event.getEntity().getSignalPayload().getVariables().size()).isEqualTo(1);\n        assertThat(event.getEntity().getSignalPayload().getVariables().get(\"signal_variable\")).isEqualTo(\"test\");\n    }\n\n\n}",
    "repo": "Activiti/Activiti",
    "path": "./datasets/diagrams-repos/Activiti/Activiti/activiti-core/activiti-spring-boot-starter/src/test/java/org/activiti/spring/boot/process/ProcessRuntimeBPMNSignalReceivedIT.java",
    "query": "Show the interaction between ProcessRuntime and BPMNSignalReceivedEvent during signal emission and reception.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'ProcessRuntime', 'node_id': 'ProcessRuntime', 'description': 'Core runtime service for process execution', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'BPMNSignalReceivedEvent', 'node_id': 'BPMNSignalReceivedEvent', 'description': 'Event representing received BPMN signal', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'SignalPayload', 'node_id': 'SignalPayload', 'description': 'Container for signal data', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'DummyBPMNSignalReceivedListener', 'node_id': 'DummyBPMNSignalReceivedListener', 'description': 'Test listener for signal events', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'signal', 'node_id': 'signal', 'description': 'Emits signal with payload', 'visibility': 'public', 'return_type': 'void', 'params': 'SignalPayload', 'source_class_id': 'ProcessRuntime'}, {'type': 'entity', 'name': 'ProcessInstance', 'node_id': 'ProcessInstance', 'description': 'Running instance of a process', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'ProcessDefinition', 'node_id': 'ProcessDefinition', 'description': 'Definition of a process', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'SecurityUtil', 'node_id': 'SecurityUtil', 'description': 'Security utility for process operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'ProcessRuntime', 'node_id_to': 'signal', 'description': 'executes'}, {'node_id_from': 'signal', 'node_id_to': 'BPMNSignalReceivedEvent', 'description': 'generates'}, {'node_id_from': 'SignalPayload', 'node_id_to': 'signal', 'description': 'input for'}, {'node_id_from': 'ProcessInstance', 'node_id_to': 'BPMNSignalReceivedEvent', 'description': 'associated with'}, {'node_id_from': 'DummyBPMNSignalReceivedListener', 'node_id_to': 'BPMNSignalReceivedEvent', 'description': 'listens to'}, {'node_id_from': 'ProcessDefinition', 'node_id_to': 'ProcessInstance', 'description': 'defines'}, {'node_id_from': 'SecurityUtil', 'node_id_to': 'ProcessRuntime', 'description': 'secures'}], 'packages': [{'package_id': 'signalProcessing', 'children': ['ProcessRuntime', 'signal', 'BPMNSignalReceivedEvent', 'SignalPayload'], 'description': 'Signal handling components'}, {'package_id': 'processExecution', 'children': ['ProcessInstance', 'ProcessDefinition'], 'description': 'Process execution components'}]}",
    "version": "full",
    "text_answer": "ProcessRuntime emits signals using SignalPayload, which generates BPMNSignalReceivedEvents that are associated with specific ProcessInstances.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C#",
    "code": "\nusing System;\nusing System.Collections.Generic;\nusing System.Diagnostics.CodeAnalysis;\nusing Orleans.Metadata;\nusing Orleans.Runtime;\nusing Orleans.Streams;\n\nnamespace Orleans\n{\n    /// <summary>\n    /// The [Orleans.ImplicitStreamSubscription] attribute is used to mark grains as implicit stream subscriptions.\n    /// </summary>\n    [AttributeUsage(AttributeTargets.Class, AllowMultiple = true)]\n    public class ImplicitStreamSubscriptionAttribute : Attribute, IGrainBindingsProviderAttribute\n    {\n        /// <summary>\n        /// Gets the stream namespace filter predicate.\n        /// </summary>\n        public IStreamNamespacePredicate Predicate { get; }\n\n        /// <summary>\n        /// Gets the name of the stream identifier mapper.\n        /// </summary>\n        /// <value>The name of the stream identifier mapper.</value>\n        /// <remarks>\n        /// This value is the name used to resolve the <see cref=\"IStreamIdMapper\"/> registered in the dependency injection container.\n        /// </remarks>\n        public string StreamIdMapper { get; init; }\n\n        /// <summary>\n        /// Used to subscribe to all stream namespaces.\n        /// </summary>\n        public ImplicitStreamSubscriptionAttribute()\n        {\n            Predicate = new AllStreamNamespacesPredicate();\n        }\n\n        /// <summary>\n        /// Used to subscribe to the specified stream namespace.\n        /// </summary>\n        /// <param name=\"streamNamespace\">The stream namespace to subscribe.</param>\n        /// <param name=\"streamIdMapper\">The name of the stream identity mapper.</param>\n        public ImplicitStreamSubscriptionAttribute(string streamNamespace, string streamIdMapper = null)\n        {\n            Predicate = new ExactMatchStreamNamespacePredicate(streamNamespace.Trim());\n            StreamIdMapper = streamIdMapper;\n        }\n\n        /// <summary>\n        /// Allows to pass an arbitrary predicate type to filter stream namespaces to subscribe. The predicate type \n        /// must have a constructor without parameters.\n        /// </summary>\n        /// <param name=\"predicateType\">The stream namespace predicate type.</param>\n        /// <param name=\"streamIdMapper\">The name of the stream identity mapper.</param>\n        public ImplicitStreamSubscriptionAttribute(Type predicateType, string streamIdMapper = null)\n        {\n            Predicate = (IStreamNamespacePredicate) Activator.CreateInstance(predicateType);\n            StreamIdMapper = streamIdMapper;\n        }\n\n        /// <summary>\n        /// Allows to pass an instance of the stream namespace predicate. To be used mainly as an extensibility point\n        /// via inheriting attributes.\n        /// </summary>\n        /// <param name=\"predicate\">The stream namespace predicate.</param>\n        /// <param name=\"streamIdMapper\">The name of the stream identity mapper.</param>\n        public ImplicitStreamSubscriptionAttribute(IStreamNamespacePredicate predicate, string streamIdMapper = null)\n        {\n            Predicate = predicate;\n            StreamIdMapper = streamIdMapper;\n        }\n\n        /// <inheritdoc />\n        public IEnumerable<Dictionary<string, string>> GetBindings(IServiceProvider services, Type grainClass, GrainType grainType)\n        {\n            var binding = new Dictionary<string, string>\n            {\n                [WellKnownGrainTypeProperties.BindingTypeKey] = WellKnownGrainTypeProperties.StreamBindingTypeValue,\n                [WellKnownGrainTypeProperties.StreamBindingPatternKey] = this.Predicate.PredicatePattern,\n                [WellKnownGrainTypeProperties.StreamIdMapperKey] = this.StreamIdMapper,\n            };\n\n            if (LegacyGrainId.IsLegacyGrainType(grainClass))\n            {\n                string keyType;\n\n                if (typeof(IGrainWithGuidKey).IsAssignableFrom(grainClass) || typeof(IGrainWithGuidCompoundKey).IsAssignableFrom(grainClass))\n                    keyType = nameof(Guid);\n                else if (typeof(IGrainWithIntegerKey).IsAssignableFrom(grainClass) || typeof(IGrainWithIntegerCompoundKey).IsAssignableFrom(grainClass))\n                    keyType = nameof(Int64);\n                else // fallback to string\n                    keyType = nameof(String);\n\n                binding[WellKnownGrainTypeProperties.LegacyGrainKeyType] = keyType;\n            }\n\n            if (LegacyGrainId.IsLegacyKeyExtGrainType(grainClass))\n            {\n                binding[WellKnownGrainTypeProperties.StreamBindingIncludeNamespaceKey] = \"true\";\n            }\n\n            yield return binding;\n        }\n    }\n\n    /// <summary>\n    /// The [Orleans.RegexImplicitStreamSubscription] attribute is used to mark grains as implicit stream\n    /// subscriptions by filtering stream namespaces to subscribe using a regular expression.\n    /// </summary>\n    [AttributeUsage(AttributeTargets.Class, AllowMultiple = true)]\n    public sealed class RegexImplicitStreamSubscriptionAttribute : ImplicitStreamSubscriptionAttribute\n    {\n        /// <summary>\n        /// Allows to pass a regular expression to filter stream namespaces to subscribe to.\n        /// </summary>\n        /// <param name=\"pattern\">The stream namespace regular expression filter.</param>\n        public RegexImplicitStreamSubscriptionAttribute([StringSyntax(StringSyntaxAttribute.Regex)] string pattern)\n            : base(new RegexStreamNamespacePredicate(pattern))\n        {\n        }\n    }\n}",
    "repo": "dotnet/orleans",
    "path": "./datasets/diagrams-repos/dotnet/orleans/src/Orleans.Streaming/Predicates/StreamSubscriptionAttributes.cs",
    "query": "Illustrate the configuration of grain bindings for stream subscriptions, focusing on the keys and values used in the GetBindings method, including how legacy grains are handled differently.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'ImplicitStreamSubscriptionAttribute', 'node_id': 'ImplicitStreamSubscriptionAttribute', 'description': 'Attribute for configuring implicit stream subscriptions in grains', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'GetBindings', 'node_id': 'GetBindings', 'description': 'Creates binding configuration for stream subscriptions', 'visibility': 'public', 'return_type': 'IEnumerable<Dictionary<string, string>>', 'params': 'IServiceProvider services, Type grainClass, GrainType grainType', 'source_class_id': 'ImplicitStreamSubscriptionAttribute'}, {'type': 'entity', 'name': 'BasicBindingConfig', 'node_id': 'BasicBindingConfig', 'description': 'Standard stream binding configuration keys', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'LegacyGrainConfig', 'node_id': 'LegacyGrainConfig', 'description': 'Additional configuration for legacy grain types', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'ImplicitStreamSubscriptionAttribute', 'node_id_to': 'GetBindings', 'description': 'implements'}, {'node_id_from': 'GetBindings', 'node_id_to': 'BasicBindingConfig', 'description': 'creates'}, {'node_id_from': 'GetBindings', 'node_id_to': 'LegacyGrainConfig', 'description': 'extends with'}], 'packages': [{'package_id': 'StreamBinding', 'children': ['ImplicitStreamSubscriptionAttribute', 'GetBindings', 'BasicBindingConfig', 'LegacyGrainConfig'], 'description': 'Stream subscription binding configuration'}]}",
    "version": "minimal",
    "text_answer": "The GetBindings method configures stream subscriptions by creating a dictionary with standard keys (binding type, pattern, mapper) and adds special handling for legacy grains by including key type (Guid/Integer/String) and namespace configuration when applicable.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C#",
    "code": "\nusing System;\nusing System.Collections.Generic;\nusing System.Diagnostics.CodeAnalysis;\nusing Orleans.Metadata;\nusing Orleans.Runtime;\nusing Orleans.Streams;\n\nnamespace Orleans\n{\n    /// <summary>\n    /// The [Orleans.ImplicitStreamSubscription] attribute is used to mark grains as implicit stream subscriptions.\n    /// </summary>\n    [AttributeUsage(AttributeTargets.Class, AllowMultiple = true)]\n    public class ImplicitStreamSubscriptionAttribute : Attribute, IGrainBindingsProviderAttribute\n    {\n        /// <summary>\n        /// Gets the stream namespace filter predicate.\n        /// </summary>\n        public IStreamNamespacePredicate Predicate { get; }\n\n        /// <summary>\n        /// Gets the name of the stream identifier mapper.\n        /// </summary>\n        /// <value>The name of the stream identifier mapper.</value>\n        /// <remarks>\n        /// This value is the name used to resolve the <see cref=\"IStreamIdMapper\"/> registered in the dependency injection container.\n        /// </remarks>\n        public string StreamIdMapper { get; init; }\n\n        /// <summary>\n        /// Used to subscribe to all stream namespaces.\n        /// </summary>\n        public ImplicitStreamSubscriptionAttribute()\n        {\n            Predicate = new AllStreamNamespacesPredicate();\n        }\n\n        /// <summary>\n        /// Used to subscribe to the specified stream namespace.\n        /// </summary>\n        /// <param name=\"streamNamespace\">The stream namespace to subscribe.</param>\n        /// <param name=\"streamIdMapper\">The name of the stream identity mapper.</param>\n        public ImplicitStreamSubscriptionAttribute(string streamNamespace, string streamIdMapper = null)\n        {\n            Predicate = new ExactMatchStreamNamespacePredicate(streamNamespace.Trim());\n            StreamIdMapper = streamIdMapper;\n        }\n\n        /// <summary>\n        /// Allows to pass an arbitrary predicate type to filter stream namespaces to subscribe. The predicate type \n        /// must have a constructor without parameters.\n        /// </summary>\n        /// <param name=\"predicateType\">The stream namespace predicate type.</param>\n        /// <param name=\"streamIdMapper\">The name of the stream identity mapper.</param>\n        public ImplicitStreamSubscriptionAttribute(Type predicateType, string streamIdMapper = null)\n        {\n            Predicate = (IStreamNamespacePredicate) Activator.CreateInstance(predicateType);\n            StreamIdMapper = streamIdMapper;\n        }\n\n        /// <summary>\n        /// Allows to pass an instance of the stream namespace predicate. To be used mainly as an extensibility point\n        /// via inheriting attributes.\n        /// </summary>\n        /// <param name=\"predicate\">The stream namespace predicate.</param>\n        /// <param name=\"streamIdMapper\">The name of the stream identity mapper.</param>\n        public ImplicitStreamSubscriptionAttribute(IStreamNamespacePredicate predicate, string streamIdMapper = null)\n        {\n            Predicate = predicate;\n            StreamIdMapper = streamIdMapper;\n        }\n\n        /// <inheritdoc />\n        public IEnumerable<Dictionary<string, string>> GetBindings(IServiceProvider services, Type grainClass, GrainType grainType)\n        {\n            var binding = new Dictionary<string, string>\n            {\n                [WellKnownGrainTypeProperties.BindingTypeKey] = WellKnownGrainTypeProperties.StreamBindingTypeValue,\n                [WellKnownGrainTypeProperties.StreamBindingPatternKey] = this.Predicate.PredicatePattern,\n                [WellKnownGrainTypeProperties.StreamIdMapperKey] = this.StreamIdMapper,\n            };\n\n            if (LegacyGrainId.IsLegacyGrainType(grainClass))\n            {\n                string keyType;\n\n                if (typeof(IGrainWithGuidKey).IsAssignableFrom(grainClass) || typeof(IGrainWithGuidCompoundKey).IsAssignableFrom(grainClass))\n                    keyType = nameof(Guid);\n                else if (typeof(IGrainWithIntegerKey).IsAssignableFrom(grainClass) || typeof(IGrainWithIntegerCompoundKey).IsAssignableFrom(grainClass))\n                    keyType = nameof(Int64);\n                else // fallback to string\n                    keyType = nameof(String);\n\n                binding[WellKnownGrainTypeProperties.LegacyGrainKeyType] = keyType;\n            }\n\n            if (LegacyGrainId.IsLegacyKeyExtGrainType(grainClass))\n            {\n                binding[WellKnownGrainTypeProperties.StreamBindingIncludeNamespaceKey] = \"true\";\n            }\n\n            yield return binding;\n        }\n    }\n\n    /// <summary>\n    /// The [Orleans.RegexImplicitStreamSubscription] attribute is used to mark grains as implicit stream\n    /// subscriptions by filtering stream namespaces to subscribe using a regular expression.\n    /// </summary>\n    [AttributeUsage(AttributeTargets.Class, AllowMultiple = true)]\n    public sealed class RegexImplicitStreamSubscriptionAttribute : ImplicitStreamSubscriptionAttribute\n    {\n        /// <summary>\n        /// Allows to pass a regular expression to filter stream namespaces to subscribe to.\n        /// </summary>\n        /// <param name=\"pattern\">The stream namespace regular expression filter.</param>\n        public RegexImplicitStreamSubscriptionAttribute([StringSyntax(StringSyntaxAttribute.Regex)] string pattern)\n            : base(new RegexStreamNamespacePredicate(pattern))\n        {\n        }\n    }\n}",
    "repo": "dotnet/orleans",
    "path": "./datasets/diagrams-repos/dotnet/orleans/src/Orleans.Streaming/Predicates/StreamSubscriptionAttributes.cs",
    "query": "Illustrate the configuration of grain bindings for stream subscriptions, focusing on the keys and values used in the GetBindings method, including how legacy grains are handled differently.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'ImplicitStreamSubscriptionAttribute', 'node_id': 'ImplicitStreamSubscriptionAttribute', 'description': 'Attribute for configuring implicit stream subscriptions in grains', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'GetBindings', 'node_id': 'GetBindings', 'description': 'Creates binding configuration for stream subscriptions', 'visibility': 'public', 'return_type': 'IEnumerable<Dictionary<string, string>>', 'params': 'IServiceProvider services, Type grainClass, GrainType grainType', 'source_class_id': 'ImplicitStreamSubscriptionAttribute'}, {'type': 'entity', 'name': 'StandardBindingKeys', 'node_id': 'StandardBindingKeys', 'description': 'Standard binding configuration keys', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'LegacyGrainTypes', 'node_id': 'LegacyGrainTypes', 'description': 'Types of legacy grains (Guid, Integer, String)', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'StreamBindingProperties', 'node_id': 'StreamBindingProperties', 'description': 'Well-known properties for stream binding configuration', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'RegexImplicitStreamSubscriptionAttribute', 'node_id': 'RegexImplicitStreamSubscriptionAttribute', 'description': 'Attribute for regex-based stream namespace filtering', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'ImplicitStreamSubscriptionAttribute', 'node_id_to': 'GetBindings', 'description': 'implements'}, {'node_id_from': 'GetBindings', 'node_id_to': 'StandardBindingKeys', 'description': 'uses'}, {'node_id_from': 'GetBindings', 'node_id_to': 'LegacyGrainTypes', 'description': 'checks'}, {'node_id_from': 'GetBindings', 'node_id_to': 'StreamBindingProperties', 'description': 'configures'}, {'node_id_from': 'RegexImplicitStreamSubscriptionAttribute', 'node_id_to': 'ImplicitStreamSubscriptionAttribute', 'description': 'extends'}], 'packages': [{'package_id': 'StreamConfiguration', 'children': ['ImplicitStreamSubscriptionAttribute', 'RegexImplicitStreamSubscriptionAttribute', 'BindingConfiguration'], 'description': 'Stream subscription attributes'}, {'package_id': 'BindingConfiguration', 'children': ['GetBindings', 'StandardBindingKeys', 'LegacyGrainTypes', 'StreamBindingProperties'], 'description': 'Binding configuration components'}]}",
    "version": "medium",
    "text_answer": "The GetBindings method configures stream subscriptions by creating a dictionary with standard keys (binding type, pattern, mapper) and adds special handling for legacy grains by including key type (Guid/Integer/String) and namespace configuration when applicable.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C#",
    "code": "\nusing System;\nusing System.Collections.Generic;\nusing System.Diagnostics.CodeAnalysis;\nusing Orleans.Metadata;\nusing Orleans.Runtime;\nusing Orleans.Streams;\n\nnamespace Orleans\n{\n    /// <summary>\n    /// The [Orleans.ImplicitStreamSubscription] attribute is used to mark grains as implicit stream subscriptions.\n    /// </summary>\n    [AttributeUsage(AttributeTargets.Class, AllowMultiple = true)]\n    public class ImplicitStreamSubscriptionAttribute : Attribute, IGrainBindingsProviderAttribute\n    {\n        /// <summary>\n        /// Gets the stream namespace filter predicate.\n        /// </summary>\n        public IStreamNamespacePredicate Predicate { get; }\n\n        /// <summary>\n        /// Gets the name of the stream identifier mapper.\n        /// </summary>\n        /// <value>The name of the stream identifier mapper.</value>\n        /// <remarks>\n        /// This value is the name used to resolve the <see cref=\"IStreamIdMapper\"/> registered in the dependency injection container.\n        /// </remarks>\n        public string StreamIdMapper { get; init; }\n\n        /// <summary>\n        /// Used to subscribe to all stream namespaces.\n        /// </summary>\n        public ImplicitStreamSubscriptionAttribute()\n        {\n            Predicate = new AllStreamNamespacesPredicate();\n        }\n\n        /// <summary>\n        /// Used to subscribe to the specified stream namespace.\n        /// </summary>\n        /// <param name=\"streamNamespace\">The stream namespace to subscribe.</param>\n        /// <param name=\"streamIdMapper\">The name of the stream identity mapper.</param>\n        public ImplicitStreamSubscriptionAttribute(string streamNamespace, string streamIdMapper = null)\n        {\n            Predicate = new ExactMatchStreamNamespacePredicate(streamNamespace.Trim());\n            StreamIdMapper = streamIdMapper;\n        }\n\n        /// <summary>\n        /// Allows to pass an arbitrary predicate type to filter stream namespaces to subscribe. The predicate type \n        /// must have a constructor without parameters.\n        /// </summary>\n        /// <param name=\"predicateType\">The stream namespace predicate type.</param>\n        /// <param name=\"streamIdMapper\">The name of the stream identity mapper.</param>\n        public ImplicitStreamSubscriptionAttribute(Type predicateType, string streamIdMapper = null)\n        {\n            Predicate = (IStreamNamespacePredicate) Activator.CreateInstance(predicateType);\n            StreamIdMapper = streamIdMapper;\n        }\n\n        /// <summary>\n        /// Allows to pass an instance of the stream namespace predicate. To be used mainly as an extensibility point\n        /// via inheriting attributes.\n        /// </summary>\n        /// <param name=\"predicate\">The stream namespace predicate.</param>\n        /// <param name=\"streamIdMapper\">The name of the stream identity mapper.</param>\n        public ImplicitStreamSubscriptionAttribute(IStreamNamespacePredicate predicate, string streamIdMapper = null)\n        {\n            Predicate = predicate;\n            StreamIdMapper = streamIdMapper;\n        }\n\n        /// <inheritdoc />\n        public IEnumerable<Dictionary<string, string>> GetBindings(IServiceProvider services, Type grainClass, GrainType grainType)\n        {\n            var binding = new Dictionary<string, string>\n            {\n                [WellKnownGrainTypeProperties.BindingTypeKey] = WellKnownGrainTypeProperties.StreamBindingTypeValue,\n                [WellKnownGrainTypeProperties.StreamBindingPatternKey] = this.Predicate.PredicatePattern,\n                [WellKnownGrainTypeProperties.StreamIdMapperKey] = this.StreamIdMapper,\n            };\n\n            if (LegacyGrainId.IsLegacyGrainType(grainClass))\n            {\n                string keyType;\n\n                if (typeof(IGrainWithGuidKey).IsAssignableFrom(grainClass) || typeof(IGrainWithGuidCompoundKey).IsAssignableFrom(grainClass))\n                    keyType = nameof(Guid);\n                else if (typeof(IGrainWithIntegerKey).IsAssignableFrom(grainClass) || typeof(IGrainWithIntegerCompoundKey).IsAssignableFrom(grainClass))\n                    keyType = nameof(Int64);\n                else // fallback to string\n                    keyType = nameof(String);\n\n                binding[WellKnownGrainTypeProperties.LegacyGrainKeyType] = keyType;\n            }\n\n            if (LegacyGrainId.IsLegacyKeyExtGrainType(grainClass))\n            {\n                binding[WellKnownGrainTypeProperties.StreamBindingIncludeNamespaceKey] = \"true\";\n            }\n\n            yield return binding;\n        }\n    }\n\n    /// <summary>\n    /// The [Orleans.RegexImplicitStreamSubscription] attribute is used to mark grains as implicit stream\n    /// subscriptions by filtering stream namespaces to subscribe using a regular expression.\n    /// </summary>\n    [AttributeUsage(AttributeTargets.Class, AllowMultiple = true)]\n    public sealed class RegexImplicitStreamSubscriptionAttribute : ImplicitStreamSubscriptionAttribute\n    {\n        /// <summary>\n        /// Allows to pass a regular expression to filter stream namespaces to subscribe to.\n        /// </summary>\n        /// <param name=\"pattern\">The stream namespace regular expression filter.</param>\n        public RegexImplicitStreamSubscriptionAttribute([StringSyntax(StringSyntaxAttribute.Regex)] string pattern)\n            : base(new RegexStreamNamespacePredicate(pattern))\n        {\n        }\n    }\n}",
    "repo": "dotnet/orleans",
    "path": "./datasets/diagrams-repos/dotnet/orleans/src/Orleans.Streaming/Predicates/StreamSubscriptionAttributes.cs",
    "query": "Illustrate the configuration of grain bindings for stream subscriptions, focusing on the keys and values used in the GetBindings method, including how legacy grains are handled differently.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'ImplicitStreamSubscriptionAttribute', 'node_id': 'ImplicitStreamSubscriptionAttribute', 'description': 'Attribute for configuring implicit stream subscriptions in grains', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'Predicate', 'node_id': 'Predicate', 'description': 'Stream namespace filter predicate', 'visibility': 'public', 'return_type': 'IStreamNamespacePredicate', 'params': None, 'source_class_id': 'ImplicitStreamSubscriptionAttribute'}, {'type': 'field', 'name': 'StreamIdMapper', 'node_id': 'StreamIdMapper', 'description': 'Name of the stream identifier mapper', 'visibility': 'public', 'return_type': 'string', 'params': None, 'source_class_id': 'ImplicitStreamSubscriptionAttribute'}, {'type': 'method', 'name': 'GetBindings', 'node_id': 'GetBindings', 'description': 'Creates binding configuration for stream subscriptions', 'visibility': 'public', 'return_type': 'IEnumerable<Dictionary<string, string>>', 'params': 'IServiceProvider services, Type grainClass, GrainType grainType', 'source_class_id': 'ImplicitStreamSubscriptionAttribute'}, {'type': 'entity', 'name': 'BindingTypeKey', 'node_id': 'BindingTypeKey', 'description': 'Key for binding type in configuration', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'StreamBindingPatternKey', 'node_id': 'StreamBindingPatternKey', 'description': 'Key for stream binding pattern', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'StreamIdMapperKey', 'node_id': 'StreamIdMapperKey', 'description': 'Key for stream ID mapper', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'LegacyGrainKeyType', 'node_id': 'LegacyGrainKeyType', 'description': 'Key type for legacy grains', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'StreamBindingIncludeNamespaceKey', 'node_id': 'StreamBindingIncludeNamespaceKey', 'description': 'Key for including namespace in stream binding', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'RegexImplicitStreamSubscriptionAttribute', 'node_id': 'RegexImplicitStreamSubscriptionAttribute', 'description': 'Attribute for regex-based stream namespace filtering', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'IGrainWithGuidKey', 'node_id': 'IGrainWithGuidKey', 'description': 'Interface for grains with GUID key', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'IGrainWithIntegerKey', 'node_id': 'IGrainWithIntegerKey', 'description': 'Interface for grains with integer key', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'ImplicitStreamSubscriptionAttribute', 'node_id_to': 'GetBindings', 'description': 'implements'}, {'node_id_from': 'GetBindings', 'node_id_to': 'BindingTypeKey', 'description': 'sets'}, {'node_id_from': 'GetBindings', 'node_id_to': 'StreamBindingPatternKey', 'description': 'sets'}, {'node_id_from': 'GetBindings', 'node_id_to': 'StreamIdMapperKey', 'description': 'sets'}, {'node_id_from': 'GetBindings', 'node_id_to': 'LegacyGrainKeyType', 'description': 'sets for legacy'}, {'node_id_from': 'GetBindings', 'node_id_to': 'StreamBindingIncludeNamespaceKey', 'description': 'sets for legacy'}, {'node_id_from': 'RegexImplicitStreamSubscriptionAttribute', 'node_id_to': 'ImplicitStreamSubscriptionAttribute', 'description': 'extends'}, {'node_id_from': 'GetBindings', 'node_id_to': 'IGrainWithGuidKey', 'description': 'checks'}, {'node_id_from': 'GetBindings', 'node_id_to': 'IGrainWithIntegerKey', 'description': 'checks'}, {'node_id_from': 'ImplicitStreamSubscriptionAttribute', 'node_id_to': 'Predicate', 'description': ''}, {'node_id_from': 'ImplicitStreamSubscriptionAttribute', 'node_id_to': 'StreamIdMapper', 'description': ''}], 'packages': [{'package_id': 'Attributes', 'children': ['ImplicitStreamSubscriptionAttribute', 'RegexImplicitStreamSubscriptionAttribute', 'Configuration'], 'description': 'Stream subscription attributes'}, {'package_id': 'Configuration', 'children': ['GetBindings', 'Predicate', 'StreamIdMapper'], 'description': 'Core configuration components'}, {'package_id': 'BindingKeys', 'children': ['BindingTypeKey', 'StreamBindingPatternKey', 'StreamIdMapperKey', 'LegacyGrainKeyType', 'StreamBindingIncludeNamespaceKey'], 'description': 'Binding configuration keys'}, {'package_id': 'GrainInterfaces', 'children': ['IGrainWithGuidKey', 'IGrainWithIntegerKey'], 'description': 'Grain key type interfaces'}]}",
    "version": "full",
    "text_answer": "The GetBindings method configures stream subscriptions by creating a dictionary with standard keys (binding type, pattern, mapper) and adds special handling for legacy grains by including key type (Guid/Integer/String) and namespace configuration when applicable.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Rust",
    "code": "\nuse std::net::IpAddr;\nuse std::path::PathBuf;\n\nuse clap::{Parser, Subcommand};\nuse clap_complete::Shell;\n\n#[derive(Parser)]\n#[clap(version, author, about)]\npub struct Cli {\n    /// Directory to use as root of project\n    #[clap(short = 'r', long, default_value = \".\")]\n    pub root: PathBuf,\n\n    /// Path to a config file other than config.toml in the root of project\n    #[clap(short = 'c', long, default_value = \"config.toml\")]\n    pub config: PathBuf,\n\n    #[clap(subcommand)]\n    pub command: Command,\n}\n\n#[derive(Subcommand)]\npub enum Command {\n    /// Create a new Zola project\n    Init {\n        /// Name of the project. Will create a new directory with that name in the current directory\n        #[clap(default_value = \".\")]\n        name: String,\n\n        /// Force creation of project even if directory is non-empty\n        #[clap(short = 'f', long)]\n        force: bool,\n    },\n\n    /// Deletes the output directory if there is one and builds the site\n    Build {\n        /// Force the base URL to be that value (defaults to the one in config.toml)\n        #[clap(short = 'u', long)]\n        base_url: Option<String>,\n\n        /// Outputs the generated site in the given path (by default 'public' dir in project root)\n        #[clap(short = 'o', long)]\n        output_dir: Option<PathBuf>,\n\n        /// Force building the site even if output directory is non-empty\n        #[clap(short = 'f', long)]\n        force: bool,\n\n        /// Include drafts when loading the site\n        #[clap(long)]\n        drafts: bool,\n    },\n\n    /// Serve the site. Rebuild and reload on change automatically\n    Serve {\n        /// Interface to bind on\n        #[clap(short = 'i', long, default_value = \"127.0.0.1\")]\n        interface: IpAddr,\n\n        /// Which port to use\n        #[clap(short = 'p', long, default_value_t = 1111)]\n        port: u16,\n\n        /// Outputs assets of the generated site in the given path (by default 'public' dir in project root).\n        /// HTML/XML will be stored in memory.\n        #[clap(short = 'o', long)]\n        output_dir: Option<PathBuf>,\n\n        /// Force use of the directory for serving the site even if output directory is non-empty\n        #[clap(long)]\n        force: bool,\n\n        /// Changes the base_url\n        #[clap(short = 'u', long)]\n        base_url: Option<String>,\n\n        /// Include drafts when loading the site\n        #[clap(long)]\n        drafts: bool,\n\n        /// Open site in the default browser\n        #[clap(short = 'O', long)]\n        open: bool,\n\n        /// Only rebuild the minimum on change - useful when working on a specific page/section\n        #[clap(short = 'f', long)]\n        fast: bool,\n\n        /// Default append port to the base url.\n        #[clap(long)]\n        no_port_append: bool,\n    },\n\n    /// Try to build the project without rendering it. Checks links\n    Check {\n        /// Include drafts when loading the site\n        #[clap(long)]\n        drafts: bool,\n    },\n\n    /// Generate shell completion\n    Completion {\n        /// Shell to generate completion for\n        #[clap(value_enum)]\n        shell: Shell,\n    },\n}",
    "repo": "getzola/zola",
    "path": "./datasets/diagrams-repos/getzola/zola/src/cli.rs",
    "query": "What is the control flow within the main function based on the selected command?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'Cli', 'node_id': 'Cli', 'description': 'Main CLI structure that handles command-line arguments', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'Command', 'node_id': 'Command', 'description': 'Available commands for the CLI application', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'Cli', 'node_id_to': 'Command', 'description': 'contains'}], 'packages': []}",
    "version": "minimal",
    "text_answer": "The main function's control flow is determined by the Command enum, which defines five main commands (Init, Build, Serve, Check, and Completion). Each command has its own set of parameters and triggers different functionality in the application.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Rust",
    "code": "\nuse std::net::IpAddr;\nuse std::path::PathBuf;\n\nuse clap::{Parser, Subcommand};\nuse clap_complete::Shell;\n\n#[derive(Parser)]\n#[clap(version, author, about)]\npub struct Cli {\n    /// Directory to use as root of project\n    #[clap(short = 'r', long, default_value = \".\")]\n    pub root: PathBuf,\n\n    /// Path to a config file other than config.toml in the root of project\n    #[clap(short = 'c', long, default_value = \"config.toml\")]\n    pub config: PathBuf,\n\n    #[clap(subcommand)]\n    pub command: Command,\n}\n\n#[derive(Subcommand)]\npub enum Command {\n    /// Create a new Zola project\n    Init {\n        /// Name of the project. Will create a new directory with that name in the current directory\n        #[clap(default_value = \".\")]\n        name: String,\n\n        /// Force creation of project even if directory is non-empty\n        #[clap(short = 'f', long)]\n        force: bool,\n    },\n\n    /// Deletes the output directory if there is one and builds the site\n    Build {\n        /// Force the base URL to be that value (defaults to the one in config.toml)\n        #[clap(short = 'u', long)]\n        base_url: Option<String>,\n\n        /// Outputs the generated site in the given path (by default 'public' dir in project root)\n        #[clap(short = 'o', long)]\n        output_dir: Option<PathBuf>,\n\n        /// Force building the site even if output directory is non-empty\n        #[clap(short = 'f', long)]\n        force: bool,\n\n        /// Include drafts when loading the site\n        #[clap(long)]\n        drafts: bool,\n    },\n\n    /// Serve the site. Rebuild and reload on change automatically\n    Serve {\n        /// Interface to bind on\n        #[clap(short = 'i', long, default_value = \"127.0.0.1\")]\n        interface: IpAddr,\n\n        /// Which port to use\n        #[clap(short = 'p', long, default_value_t = 1111)]\n        port: u16,\n\n        /// Outputs assets of the generated site in the given path (by default 'public' dir in project root).\n        /// HTML/XML will be stored in memory.\n        #[clap(short = 'o', long)]\n        output_dir: Option<PathBuf>,\n\n        /// Force use of the directory for serving the site even if output directory is non-empty\n        #[clap(long)]\n        force: bool,\n\n        /// Changes the base_url\n        #[clap(short = 'u', long)]\n        base_url: Option<String>,\n\n        /// Include drafts when loading the site\n        #[clap(long)]\n        drafts: bool,\n\n        /// Open site in the default browser\n        #[clap(short = 'O', long)]\n        open: bool,\n\n        /// Only rebuild the minimum on change - useful when working on a specific page/section\n        #[clap(short = 'f', long)]\n        fast: bool,\n\n        /// Default append port to the base url.\n        #[clap(long)]\n        no_port_append: bool,\n    },\n\n    /// Try to build the project without rendering it. Checks links\n    Check {\n        /// Include drafts when loading the site\n        #[clap(long)]\n        drafts: bool,\n    },\n\n    /// Generate shell completion\n    Completion {\n        /// Shell to generate completion for\n        #[clap(value_enum)]\n        shell: Shell,\n    },\n}",
    "repo": "getzola/zola",
    "path": "./datasets/diagrams-repos/getzola/zola/src/cli.rs",
    "query": "What is the control flow within the main function based on the selected command?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'Cli', 'node_id': 'Cli', 'description': 'Main CLI structure that handles command-line arguments', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'root', 'node_id': 'root', 'description': 'Project root directory', 'visibility': 'public', 'return_type': 'PathBuf', 'params': None, 'source_class_id': 'Cli'}, {'type': 'field', 'name': 'config', 'node_id': 'config', 'description': 'Path to config file', 'visibility': 'public', 'return_type': 'PathBuf', 'params': None, 'source_class_id': 'Cli'}, {'type': 'class', 'name': 'Command', 'node_id': 'Command', 'description': 'Available commands for the CLI application', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'Cli', 'node_id_to': 'Command', 'description': 'contains'}, {'node_id_from': 'Cli', 'node_id_to': 'root', 'description': 'has'}, {'node_id_from': 'Cli', 'node_id_to': 'config', 'description': 'has'}], 'packages': [{'package_id': 'cliConfiguration', 'children': ['root', 'config'], 'description': 'CLI configuration parameters'}]}",
    "version": "medium",
    "text_answer": "The main function's control flow is determined by the Command enum, which defines five main commands (Init, Build, Serve, Check, and Completion). Each command has its own set of parameters and triggers different functionality in the application.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Rust",
    "code": "\nuse std::net::IpAddr;\nuse std::path::PathBuf;\n\nuse clap::{Parser, Subcommand};\nuse clap_complete::Shell;\n\n#[derive(Parser)]\n#[clap(version, author, about)]\npub struct Cli {\n    /// Directory to use as root of project\n    #[clap(short = 'r', long, default_value = \".\")]\n    pub root: PathBuf,\n\n    /// Path to a config file other than config.toml in the root of project\n    #[clap(short = 'c', long, default_value = \"config.toml\")]\n    pub config: PathBuf,\n\n    #[clap(subcommand)]\n    pub command: Command,\n}\n\n#[derive(Subcommand)]\npub enum Command {\n    /// Create a new Zola project\n    Init {\n        /// Name of the project. Will create a new directory with that name in the current directory\n        #[clap(default_value = \".\")]\n        name: String,\n\n        /// Force creation of project even if directory is non-empty\n        #[clap(short = 'f', long)]\n        force: bool,\n    },\n\n    /// Deletes the output directory if there is one and builds the site\n    Build {\n        /// Force the base URL to be that value (defaults to the one in config.toml)\n        #[clap(short = 'u', long)]\n        base_url: Option<String>,\n\n        /// Outputs the generated site in the given path (by default 'public' dir in project root)\n        #[clap(short = 'o', long)]\n        output_dir: Option<PathBuf>,\n\n        /// Force building the site even if output directory is non-empty\n        #[clap(short = 'f', long)]\n        force: bool,\n\n        /// Include drafts when loading the site\n        #[clap(long)]\n        drafts: bool,\n    },\n\n    /// Serve the site. Rebuild and reload on change automatically\n    Serve {\n        /// Interface to bind on\n        #[clap(short = 'i', long, default_value = \"127.0.0.1\")]\n        interface: IpAddr,\n\n        /// Which port to use\n        #[clap(short = 'p', long, default_value_t = 1111)]\n        port: u16,\n\n        /// Outputs assets of the generated site in the given path (by default 'public' dir in project root).\n        /// HTML/XML will be stored in memory.\n        #[clap(short = 'o', long)]\n        output_dir: Option<PathBuf>,\n\n        /// Force use of the directory for serving the site even if output directory is non-empty\n        #[clap(long)]\n        force: bool,\n\n        /// Changes the base_url\n        #[clap(short = 'u', long)]\n        base_url: Option<String>,\n\n        /// Include drafts when loading the site\n        #[clap(long)]\n        drafts: bool,\n\n        /// Open site in the default browser\n        #[clap(short = 'O', long)]\n        open: bool,\n\n        /// Only rebuild the minimum on change - useful when working on a specific page/section\n        #[clap(short = 'f', long)]\n        fast: bool,\n\n        /// Default append port to the base url.\n        #[clap(long)]\n        no_port_append: bool,\n    },\n\n    /// Try to build the project without rendering it. Checks links\n    Check {\n        /// Include drafts when loading the site\n        #[clap(long)]\n        drafts: bool,\n    },\n\n    /// Generate shell completion\n    Completion {\n        /// Shell to generate completion for\n        #[clap(value_enum)]\n        shell: Shell,\n    },\n}",
    "repo": "getzola/zola",
    "path": "./datasets/diagrams-repos/getzola/zola/src/cli.rs",
    "query": "What is the control flow within the main function based on the selected command?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'Cli', 'node_id': 'Cli', 'description': 'Main CLI structure that handles command-line arguments', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'root', 'node_id': 'root', 'description': 'Project root directory', 'visibility': 'public', 'return_type': 'PathBuf', 'params': None, 'source_class_id': 'Cli'}, {'type': 'field', 'name': 'config', 'node_id': 'config', 'description': 'Path to config file', 'visibility': 'public', 'return_type': 'PathBuf', 'params': None, 'source_class_id': 'Cli'}, {'type': 'class', 'name': 'Command', 'node_id': 'Command', 'description': 'Available commands for the CLI application', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'Init', 'node_id': 'Init', 'description': 'Creates new Zola project', 'visibility': 'public', 'return_type': None, 'params': 'name: String, force: bool', 'source_class_id': None}, {'type': 'entity', 'name': 'Build', 'node_id': 'Build', 'description': 'Builds the site', 'visibility': 'public', 'return_type': None, 'params': 'base_url: Option<String>, output_dir: Option<PathBuf>, force: bool, drafts: bool', 'source_class_id': None}, {'type': 'entity', 'name': 'Serve', 'node_id': 'Serve', 'description': 'Serves the site with auto-reload', 'visibility': 'public', 'return_type': None, 'params': 'interface: IpAddr, port: u16, output_dir: Option<PathBuf>, force: bool, base_url: Option<String>, drafts: bool, open: bool, fast: bool, no_port_append: bool', 'source_class_id': None}, {'type': 'entity', 'name': 'Check', 'node_id': 'Check', 'description': 'Validates project without rendering', 'visibility': 'public', 'return_type': None, 'params': 'drafts: bool', 'source_class_id': None}, {'type': 'entity', 'name': 'Completion', 'node_id': 'Completion', 'description': 'Generates shell completion', 'visibility': 'public', 'return_type': None, 'params': 'shell: Shell', 'source_class_id': None}], 'edges': [{'node_id_from': 'Cli', 'node_id_to': 'Command', 'description': 'contains'}, {'node_id_from': 'Command', 'node_id_to': 'Init', 'description': 'variant'}, {'node_id_from': 'Command', 'node_id_to': 'Build', 'description': 'variant'}, {'node_id_from': 'Command', 'node_id_to': 'Serve', 'description': 'variant'}, {'node_id_from': 'Command', 'node_id_to': 'Check', 'description': 'variant'}, {'node_id_from': 'Command', 'node_id_to': 'Completion', 'description': 'variant'}, {'node_id_from': 'Cli', 'node_id_to': 'root', 'description': ''}, {'node_id_from': 'Cli', 'node_id_to': 'config', 'description': ''}], 'packages': [{'package_id': 'cliCommands', 'children': ['Init', 'Build', 'Serve', 'Check', 'Completion'], 'description': 'Available CLI commands'}, {'package_id': 'cliConfiguration', 'children': ['root', 'config'], 'description': 'CLI configuration parameters'}]}",
    "version": "full",
    "text_answer": "The main function's control flow is determined by the Command enum, which defines five main commands (Init, Build, Serve, Check, and Completion). Each command has its own set of parameters and triggers different functionality in the application.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C",
    "code": "\n#include <arm_cmse.h>\n#include \"NuMicro.h\"\n\n/* FreeRTOS includes. */\n#include \"FreeRTOS.h\"\n#include \"task.h\"\n\n/* Demo includes. */\n#include \"tz_demo.h\"\n#include \"mpu_demo.h\"\n#include \"reg_tests.h\"\n\n/* Externs needed by the MPU setup code. These are defined in Scatter-Loading\n * description file (FreeRTOSDemo_ns.sct). */\nextern uint32_t Image$$ER_IROM_NS_PRIVILEGED$$Base;\nextern uint32_t Image$$ER_IROM_NS_PRIVILEGED_ALIGN$$Limit;\nextern uint32_t Image$$ER_IROM_NS_FREERTOS_SYSTEM_CALLS$$Base;\nextern uint32_t Image$$ER_IROM_NS_FREERTOS_SYSTEM_CALLS_ALIGN$$Limit;\nextern uint32_t Image$$ER_IROM_NS_UNPRIVILEGED$$Base;\nextern uint32_t Image$$ER_IROM_NS_UNPRIVILEGED_ALIGN$$Limit;\n\nextern uint32_t Image$$ER_IRAM_NS_PRIVILEGED$$Base;\nextern uint32_t Image$$ER_IRAM_NS_PRIVILEGED_ALIGN$$Limit;\nextern uint32_t Image$$ER_IRAM_NS_UNPRIVILEGED$$Base;\nextern uint32_t Image$$ER_IRAM_NS_UNPRIVILEGED_ALIGN$$Limit;\n\n/* Privileged flash. */\nconst uint32_t * __privileged_functions_start__\t\t= ( uint32_t * ) &( Image$$ER_IROM_NS_PRIVILEGED$$Base );\nconst uint32_t * __privileged_functions_end__\t\t= ( uint32_t * ) ( ( uint32_t ) &( Image$$ER_IROM_NS_PRIVILEGED_ALIGN$$Limit ) - 0x1 ); /* Last address in privileged Flash region. */\n\n/* Flash containing system calls. */\nconst uint32_t * __syscalls_flash_start__\t\t\t= ( uint32_t * ) &( Image$$ER_IROM_NS_FREERTOS_SYSTEM_CALLS$$Base );\nconst uint32_t * __syscalls_flash_end__\t\t\t\t= ( uint32_t * ) ( ( uint32_t ) &( Image$$ER_IROM_NS_FREERTOS_SYSTEM_CALLS_ALIGN$$Limit ) - 0x1 ); /* Last address in Flash region containing system calls. */\n\n/* Unprivileged flash. Note that the section containing system calls is\n * unprivileged so that unprivileged tasks can make system calls. */\nconst uint32_t * __unprivileged_flash_start__\t\t= ( uint32_t * ) &( Image$$ER_IROM_NS_UNPRIVILEGED$$Base );\nconst uint32_t * __unprivileged_flash_end__\t\t\t= ( uint32_t * ) ( ( uint32_t ) &( Image$$ER_IROM_NS_UNPRIVILEGED_ALIGN$$Limit ) - 0x1 ); /* Last address in un-privileged Flash region. */\n\n/* RAM with priviledged access only. This contains kernel data. */\nconst uint32_t * __privileged_sram_start__\t\t\t= ( uint32_t * ) &( Image$$ER_IRAM_NS_PRIVILEGED$$Base );\nconst uint32_t * __privileged_sram_end__\t\t\t= ( uint32_t * ) ( ( uint32_t ) &( Image$$ER_IRAM_NS_PRIVILEGED_ALIGN$$Limit ) - 0x1 ); /* Last address in privileged RAM. */\n\n/* Unprivileged RAM. */\nconst uint32_t * __unprivileged_sram_start__\t\t= ( uint32_t * ) &( Image$$ER_IRAM_NS_UNPRIVILEGED$$Base );\nconst uint32_t * __unprivileged_sram_end__\t\t\t= ( uint32_t * ) ( ( uint32_t ) &( Image$$ER_IRAM_NS_UNPRIVILEGED_ALIGN$$Limit ) - 0x1 ); /* Last address in un-privileged RAM. */\n/*-----------------------------------------------------------*/\n\n/**\n * @brief Create all demo tasks.\n */\nstatic void prvCreateTasks( void );\n\n/**\n * @brief The hard fault handler.\n *\n * It calls a function called vHandleMemoryFault.\n */\nvoid HardFault_Handler( void ) __attribute__ ( ( naked ) );\n/*-----------------------------------------------------------*/\n\n/* For instructions on how to build and run this demo, visit the following link:\n * https://www.freertos.org/RTOS-Cortex-M23-NuMaker-PFM-M2351-Keil.html\n */\n\n/* Non-Secure main. */\nint main( void )\n{\n\t/* Initialize debug port. */\n\tDEBUG_PORT->BAUD = UART_BAUD_MODE2 | UART_BAUD_MODE2_DIVIDER( __HIRC, 115200 );\n\tDEBUG_PORT->LINE = UART_WORD_LEN_8 | UART_PARITY_NONE | UART_STOP_BIT_1;\n\n\t/* Print banner. */\n\tprintf( \"\\r\\n\" );\n\tprintf( \"+---------------------------------------------+\\r\\n\" );\n\tprintf( \"|           Nonsecure is running ...          |\\r\\n\" );\n\tprintf( \"+---------------------------------------------+\\r\\n\" );\n\n\t/* Create tasks. */\n\tprvCreateTasks();\n\n\t/* Start scheduler. */\n\tvTaskStartScheduler();\n\n\t/* Will not get here if the scheduler starts successfully.  If you do end up\n\there then there wasn't enough heap memory available to start either the idle\n\ttask or the timer/daemon task.  https://www.freertos.org/a00111.html */\n\n\tfor( ; ; )\n\t{\n\t}\n}\n/*-----------------------------------------------------------*/\n\nstatic void prvCreateTasks( void )\n{\n\t/* Create tasks for the MPU Demo. */\n\tvStartMPUDemo();\n\n\t/* Create tasks for the TZ Demo. */\n\tvStartTZDemo();\n\n\t/* Create tasks for register tests. */\n\tvStartRegTests();\n}\n/*-----------------------------------------------------------*/\n\n/* Stack overflow hook. */\nvoid vApplicationStackOverflowHook( TaskHandle_t xTask, char *pcTaskName )\n{\n\t/* Force an assert. */\n\tconfigASSERT( pcTaskName == 0 );\n}\n/*-----------------------------------------------------------*/\n\n/* configUSE_STATIC_ALLOCATION is set to 1, so the application must provide an\n * implementation of vApplicationGetIdleTaskMemory() to provide the memory that\n * is used by the Idle task. */\nvoid vApplicationGetIdleTaskMemory(\tStaticTask_t ** ppxIdleTaskTCBBuffer,\n\t\t\t\t\t\t\t\t\tStackType_t ** ppxIdleTaskStackBuffer,\n\t\t\t\t\t\t\t\t\tuint32_t * pulIdleTaskStackSize )\n{\n\t/* If the buffers to be provided to the Idle task are declared inside this\n\t * function then they must be declared static - otherwise they will be\n\t * allocated on the stack and so not exists after this function exits. */\n\tstatic StaticTask_t xIdleTaskTCB;\n\tstatic StackType_t uxIdleTaskStack[ configMINIMAL_STACK_SIZE ] __attribute__( ( aligned( 32 ) ) );\n\n\t/* Pass out a pointer to the StaticTask_t structure in which the Idle\n\t * task's state will be stored. */\n\t*ppxIdleTaskTCBBuffer = &xIdleTaskTCB;\n\n\t/* Pass out the array that will be used as the Idle task's stack. */\n\t*ppxIdleTaskStackBuffer = uxIdleTaskStack;\n\n\t/* Pass out the size of the array pointed to by *ppxIdleTaskStackBuffer.\n\t * Note that, as the array is necessarily of type StackType_t,\n\t * configMINIMAL_STACK_SIZE is specified in words, not bytes. */\n\t*pulIdleTaskStackSize = configMINIMAL_STACK_SIZE;\n}\n/*-----------------------------------------------------------*/\n\n/* configUSE_STATIC_ALLOCATION and configUSE_TIMERS are both set to 1, so the\n * application must provide an implementation of vApplicationGetTimerTaskMemory()\n * to provide the memory that is used by the Timer service task. */\nvoid vApplicationGetTimerTaskMemory( StaticTask_t ** ppxTimerTaskTCBBuffer,\n\t\t\t\t\t\t\t\t\t StackType_t ** ppxTimerTaskStackBuffer,\n\t\t\t\t\t\t\t\t\t uint32_t * pulTimerTaskStackSize )\n{\n\t/* If the buffers to be provided to the Timer task are declared inside this\n\t * function then they must be declared static - otherwise they will be\n\t * allocated on the stack and so not exists after this function exits. */\n\tstatic StaticTask_t xTimerTaskTCB;\n\tstatic StackType_t uxTimerTaskStack[ configTIMER_TASK_STACK_DEPTH ] __attribute__( ( aligned( 32 ) ) );\n\n\t/* Pass out a pointer to the StaticTask_t structure in which the Timer\n\t * task's state will be stored. */\n\t*ppxTimerTaskTCBBuffer = &xTimerTaskTCB;\n\n\t/* Pass out the array that will be used as the Timer task's stack. */\n\t*ppxTimerTaskStackBuffer = uxTimerTaskStack;\n\n\t/* Pass out the size of the array pointed to by *ppxTimerTaskStackBuffer.\n\t * Note that, as the array is necessarily of type StackType_t,\n\t * configTIMER_TASK_STACK_DEPTH is specified in words, not bytes. */\n\t*pulTimerTaskStackSize = configTIMER_TASK_STACK_DEPTH;\n}\n/*-----------------------------------------------------------*/\n\nvoid HardFault_Handler( void )\n{\n\t__asm volatile\n\t(\n\t\t\" movs r0, #4\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\" mov r1, lr\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\" tst r0, r1\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\" beq msp_used_for_stacking\t\t\t\t\t\t\t\\n\"\n\t\t\" mrs r0, psp\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\" ldr r2, handler_address_const\t\t\t\t\t\t\\n\"\n\t\t\" bx r2\t\t\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\"msp_used_for_stacking:\t\t\t\t\t\t\t\t\\n\"\n\t\t\"\tmrs r0, msp\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\"\tldr r2, handler_address_const\t\t\t\t\t\\n\"\n\t\t\"\tbx r2\t\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\"\t\t\t\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\" .align 4\t\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\" handler_address_const: .word vHandleMemoryFault\t\\n\"\n\t);\n}\n/*-----------------------------------------------------------*/",
    "repo": "FreeRTOS/FreeRTOS",
    "path": "./datasets/diagrams-repos/FreeRTOS/FreeRTOS/FreeRTOS/Demo/CORTEX_MPU_M23_Nuvoton_NuMaker_PFM_M2351_IAR_GCC/Projects/Keil/NonSecure/main_ns.c",
    "query": "Can you depict the process of handling a hard fault in this system, including the determination of stacking mode and the branching to the memory fault handler?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'HardFault_Handler', 'node_id': 'HardFault_Handler', 'description': 'Main hard fault handler function that determines stack pointer and branches to memory fault handler', 'visibility': 'public', 'return_type': 'void', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'vHandleMemoryFault', 'node_id': 'vHandleMemoryFault', 'description': 'External memory fault handler that processes the fault', 'visibility': 'public', 'return_type': 'void', 'params': 'uint32_t *faultStackAddress', 'source_class_id': None}], 'edges': [{'node_id_from': 'HardFault_Handler', 'node_id_to': 'vHandleMemoryFault', 'description': 'Calls with stack pointer'}], 'packages': [{'package_id': 'faultHandling', 'children': ['HardFault_Handler', 'vHandleMemoryFault'], 'description': 'Fault handling system components'}]}",
    "version": "minimal",
    "text_answer": "The hard fault handling process begins when HardFault_Handler is triggered. It first examines bit 2 of the Link Register (LR) to determine which stack pointer was in use when the fault occurred. If the thread mode was active, it reads the Process Stack Pointer (PSP); if handler mode was active, it reads the Main Stack Pointer (MSP). The appropriate stack pointer is then passed to vHandleMemoryFault for further processing.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C",
    "code": "\n#include <arm_cmse.h>\n#include \"NuMicro.h\"\n\n/* FreeRTOS includes. */\n#include \"FreeRTOS.h\"\n#include \"task.h\"\n\n/* Demo includes. */\n#include \"tz_demo.h\"\n#include \"mpu_demo.h\"\n#include \"reg_tests.h\"\n\n/* Externs needed by the MPU setup code. These are defined in Scatter-Loading\n * description file (FreeRTOSDemo_ns.sct). */\nextern uint32_t Image$$ER_IROM_NS_PRIVILEGED$$Base;\nextern uint32_t Image$$ER_IROM_NS_PRIVILEGED_ALIGN$$Limit;\nextern uint32_t Image$$ER_IROM_NS_FREERTOS_SYSTEM_CALLS$$Base;\nextern uint32_t Image$$ER_IROM_NS_FREERTOS_SYSTEM_CALLS_ALIGN$$Limit;\nextern uint32_t Image$$ER_IROM_NS_UNPRIVILEGED$$Base;\nextern uint32_t Image$$ER_IROM_NS_UNPRIVILEGED_ALIGN$$Limit;\n\nextern uint32_t Image$$ER_IRAM_NS_PRIVILEGED$$Base;\nextern uint32_t Image$$ER_IRAM_NS_PRIVILEGED_ALIGN$$Limit;\nextern uint32_t Image$$ER_IRAM_NS_UNPRIVILEGED$$Base;\nextern uint32_t Image$$ER_IRAM_NS_UNPRIVILEGED_ALIGN$$Limit;\n\n/* Privileged flash. */\nconst uint32_t * __privileged_functions_start__\t\t= ( uint32_t * ) &( Image$$ER_IROM_NS_PRIVILEGED$$Base );\nconst uint32_t * __privileged_functions_end__\t\t= ( uint32_t * ) ( ( uint32_t ) &( Image$$ER_IROM_NS_PRIVILEGED_ALIGN$$Limit ) - 0x1 ); /* Last address in privileged Flash region. */\n\n/* Flash containing system calls. */\nconst uint32_t * __syscalls_flash_start__\t\t\t= ( uint32_t * ) &( Image$$ER_IROM_NS_FREERTOS_SYSTEM_CALLS$$Base );\nconst uint32_t * __syscalls_flash_end__\t\t\t\t= ( uint32_t * ) ( ( uint32_t ) &( Image$$ER_IROM_NS_FREERTOS_SYSTEM_CALLS_ALIGN$$Limit ) - 0x1 ); /* Last address in Flash region containing system calls. */\n\n/* Unprivileged flash. Note that the section containing system calls is\n * unprivileged so that unprivileged tasks can make system calls. */\nconst uint32_t * __unprivileged_flash_start__\t\t= ( uint32_t * ) &( Image$$ER_IROM_NS_UNPRIVILEGED$$Base );\nconst uint32_t * __unprivileged_flash_end__\t\t\t= ( uint32_t * ) ( ( uint32_t ) &( Image$$ER_IROM_NS_UNPRIVILEGED_ALIGN$$Limit ) - 0x1 ); /* Last address in un-privileged Flash region. */\n\n/* RAM with priviledged access only. This contains kernel data. */\nconst uint32_t * __privileged_sram_start__\t\t\t= ( uint32_t * ) &( Image$$ER_IRAM_NS_PRIVILEGED$$Base );\nconst uint32_t * __privileged_sram_end__\t\t\t= ( uint32_t * ) ( ( uint32_t ) &( Image$$ER_IRAM_NS_PRIVILEGED_ALIGN$$Limit ) - 0x1 ); /* Last address in privileged RAM. */\n\n/* Unprivileged RAM. */\nconst uint32_t * __unprivileged_sram_start__\t\t= ( uint32_t * ) &( Image$$ER_IRAM_NS_UNPRIVILEGED$$Base );\nconst uint32_t * __unprivileged_sram_end__\t\t\t= ( uint32_t * ) ( ( uint32_t ) &( Image$$ER_IRAM_NS_UNPRIVILEGED_ALIGN$$Limit ) - 0x1 ); /* Last address in un-privileged RAM. */\n/*-----------------------------------------------------------*/\n\n/**\n * @brief Create all demo tasks.\n */\nstatic void prvCreateTasks( void );\n\n/**\n * @brief The hard fault handler.\n *\n * It calls a function called vHandleMemoryFault.\n */\nvoid HardFault_Handler( void ) __attribute__ ( ( naked ) );\n/*-----------------------------------------------------------*/\n\n/* For instructions on how to build and run this demo, visit the following link:\n * https://www.freertos.org/RTOS-Cortex-M23-NuMaker-PFM-M2351-Keil.html\n */\n\n/* Non-Secure main. */\nint main( void )\n{\n\t/* Initialize debug port. */\n\tDEBUG_PORT->BAUD = UART_BAUD_MODE2 | UART_BAUD_MODE2_DIVIDER( __HIRC, 115200 );\n\tDEBUG_PORT->LINE = UART_WORD_LEN_8 | UART_PARITY_NONE | UART_STOP_BIT_1;\n\n\t/* Print banner. */\n\tprintf( \"\\r\\n\" );\n\tprintf( \"+---------------------------------------------+\\r\\n\" );\n\tprintf( \"|           Nonsecure is running ...          |\\r\\n\" );\n\tprintf( \"+---------------------------------------------+\\r\\n\" );\n\n\t/* Create tasks. */\n\tprvCreateTasks();\n\n\t/* Start scheduler. */\n\tvTaskStartScheduler();\n\n\t/* Will not get here if the scheduler starts successfully.  If you do end up\n\there then there wasn't enough heap memory available to start either the idle\n\ttask or the timer/daemon task.  https://www.freertos.org/a00111.html */\n\n\tfor( ; ; )\n\t{\n\t}\n}\n/*-----------------------------------------------------------*/\n\nstatic void prvCreateTasks( void )\n{\n\t/* Create tasks for the MPU Demo. */\n\tvStartMPUDemo();\n\n\t/* Create tasks for the TZ Demo. */\n\tvStartTZDemo();\n\n\t/* Create tasks for register tests. */\n\tvStartRegTests();\n}\n/*-----------------------------------------------------------*/\n\n/* Stack overflow hook. */\nvoid vApplicationStackOverflowHook( TaskHandle_t xTask, char *pcTaskName )\n{\n\t/* Force an assert. */\n\tconfigASSERT( pcTaskName == 0 );\n}\n/*-----------------------------------------------------------*/\n\n/* configUSE_STATIC_ALLOCATION is set to 1, so the application must provide an\n * implementation of vApplicationGetIdleTaskMemory() to provide the memory that\n * is used by the Idle task. */\nvoid vApplicationGetIdleTaskMemory(\tStaticTask_t ** ppxIdleTaskTCBBuffer,\n\t\t\t\t\t\t\t\t\tStackType_t ** ppxIdleTaskStackBuffer,\n\t\t\t\t\t\t\t\t\tuint32_t * pulIdleTaskStackSize )\n{\n\t/* If the buffers to be provided to the Idle task are declared inside this\n\t * function then they must be declared static - otherwise they will be\n\t * allocated on the stack and so not exists after this function exits. */\n\tstatic StaticTask_t xIdleTaskTCB;\n\tstatic StackType_t uxIdleTaskStack[ configMINIMAL_STACK_SIZE ] __attribute__( ( aligned( 32 ) ) );\n\n\t/* Pass out a pointer to the StaticTask_t structure in which the Idle\n\t * task's state will be stored. */\n\t*ppxIdleTaskTCBBuffer = &xIdleTaskTCB;\n\n\t/* Pass out the array that will be used as the Idle task's stack. */\n\t*ppxIdleTaskStackBuffer = uxIdleTaskStack;\n\n\t/* Pass out the size of the array pointed to by *ppxIdleTaskStackBuffer.\n\t * Note that, as the array is necessarily of type StackType_t,\n\t * configMINIMAL_STACK_SIZE is specified in words, not bytes. */\n\t*pulIdleTaskStackSize = configMINIMAL_STACK_SIZE;\n}\n/*-----------------------------------------------------------*/\n\n/* configUSE_STATIC_ALLOCATION and configUSE_TIMERS are both set to 1, so the\n * application must provide an implementation of vApplicationGetTimerTaskMemory()\n * to provide the memory that is used by the Timer service task. */\nvoid vApplicationGetTimerTaskMemory( StaticTask_t ** ppxTimerTaskTCBBuffer,\n\t\t\t\t\t\t\t\t\t StackType_t ** ppxTimerTaskStackBuffer,\n\t\t\t\t\t\t\t\t\t uint32_t * pulTimerTaskStackSize )\n{\n\t/* If the buffers to be provided to the Timer task are declared inside this\n\t * function then they must be declared static - otherwise they will be\n\t * allocated on the stack and so not exists after this function exits. */\n\tstatic StaticTask_t xTimerTaskTCB;\n\tstatic StackType_t uxTimerTaskStack[ configTIMER_TASK_STACK_DEPTH ] __attribute__( ( aligned( 32 ) ) );\n\n\t/* Pass out a pointer to the StaticTask_t structure in which the Timer\n\t * task's state will be stored. */\n\t*ppxTimerTaskTCBBuffer = &xTimerTaskTCB;\n\n\t/* Pass out the array that will be used as the Timer task's stack. */\n\t*ppxTimerTaskStackBuffer = uxTimerTaskStack;\n\n\t/* Pass out the size of the array pointed to by *ppxTimerTaskStackBuffer.\n\t * Note that, as the array is necessarily of type StackType_t,\n\t * configTIMER_TASK_STACK_DEPTH is specified in words, not bytes. */\n\t*pulTimerTaskStackSize = configTIMER_TASK_STACK_DEPTH;\n}\n/*-----------------------------------------------------------*/\n\nvoid HardFault_Handler( void )\n{\n\t__asm volatile\n\t(\n\t\t\" movs r0, #4\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\" mov r1, lr\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\" tst r0, r1\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\" beq msp_used_for_stacking\t\t\t\t\t\t\t\\n\"\n\t\t\" mrs r0, psp\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\" ldr r2, handler_address_const\t\t\t\t\t\t\\n\"\n\t\t\" bx r2\t\t\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\"msp_used_for_stacking:\t\t\t\t\t\t\t\t\\n\"\n\t\t\"\tmrs r0, msp\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\"\tldr r2, handler_address_const\t\t\t\t\t\\n\"\n\t\t\"\tbx r2\t\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\"\t\t\t\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\" .align 4\t\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\" handler_address_const: .word vHandleMemoryFault\t\\n\"\n\t);\n}\n/*-----------------------------------------------------------*/",
    "repo": "FreeRTOS/FreeRTOS",
    "path": "./datasets/diagrams-repos/FreeRTOS/FreeRTOS/FreeRTOS/Demo/CORTEX_MPU_M23_Nuvoton_NuMaker_PFM_M2351_IAR_GCC/Projects/Keil/NonSecure/main_ns.c",
    "query": "Can you depict the process of handling a hard fault in this system, including the determination of stacking mode and the branching to the memory fault handler?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'HardFault_Handler', 'node_id': 'HardFault_Handler', 'description': 'Main hard fault handler function that determines stack pointer and branches to memory fault handler', 'visibility': 'public', 'return_type': 'void', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'vHandleMemoryFault', 'node_id': 'vHandleMemoryFault', 'description': 'External memory fault handler that processes the fault', 'visibility': 'public', 'return_type': 'void', 'params': 'uint32_t *faultStackAddress', 'source_class_id': None}, {'type': 'entity', 'name': 'PSP', 'node_id': 'PSP', 'description': 'Process Stack Pointer used in thread mode', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'MSP', 'node_id': 'MSP', 'description': 'Main Stack Pointer used in handler mode', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'HardFault_Handler', 'node_id_to': 'vHandleMemoryFault', 'description': 'Calls with stack pointer'}, {'node_id_from': 'HardFault_Handler', 'node_id_to': 'PSP', 'description': 'Reads if thread mode'}, {'node_id_from': 'HardFault_Handler', 'node_id_to': 'MSP', 'description': 'Reads if handler mode'}], 'packages': [{'package_id': 'faultHandling', 'children': ['HardFault_Handler', 'vHandleMemoryFault'], 'description': 'Fault handling system components'}, {'package_id': 'stackPointers', 'children': ['PSP', 'MSP'], 'description': 'System stack pointers'}]}",
    "version": "medium",
    "text_answer": "The hard fault handling process begins when HardFault_Handler is triggered. It first examines bit 2 of the Link Register (LR) to determine which stack pointer was in use when the fault occurred. If the thread mode was active, it reads the Process Stack Pointer (PSP); if handler mode was active, it reads the Main Stack Pointer (MSP). The appropriate stack pointer is then passed to vHandleMemoryFault for further processing.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C",
    "code": "\n#include <arm_cmse.h>\n#include \"NuMicro.h\"\n\n/* FreeRTOS includes. */\n#include \"FreeRTOS.h\"\n#include \"task.h\"\n\n/* Demo includes. */\n#include \"tz_demo.h\"\n#include \"mpu_demo.h\"\n#include \"reg_tests.h\"\n\n/* Externs needed by the MPU setup code. These are defined in Scatter-Loading\n * description file (FreeRTOSDemo_ns.sct). */\nextern uint32_t Image$$ER_IROM_NS_PRIVILEGED$$Base;\nextern uint32_t Image$$ER_IROM_NS_PRIVILEGED_ALIGN$$Limit;\nextern uint32_t Image$$ER_IROM_NS_FREERTOS_SYSTEM_CALLS$$Base;\nextern uint32_t Image$$ER_IROM_NS_FREERTOS_SYSTEM_CALLS_ALIGN$$Limit;\nextern uint32_t Image$$ER_IROM_NS_UNPRIVILEGED$$Base;\nextern uint32_t Image$$ER_IROM_NS_UNPRIVILEGED_ALIGN$$Limit;\n\nextern uint32_t Image$$ER_IRAM_NS_PRIVILEGED$$Base;\nextern uint32_t Image$$ER_IRAM_NS_PRIVILEGED_ALIGN$$Limit;\nextern uint32_t Image$$ER_IRAM_NS_UNPRIVILEGED$$Base;\nextern uint32_t Image$$ER_IRAM_NS_UNPRIVILEGED_ALIGN$$Limit;\n\n/* Privileged flash. */\nconst uint32_t * __privileged_functions_start__\t\t= ( uint32_t * ) &( Image$$ER_IROM_NS_PRIVILEGED$$Base );\nconst uint32_t * __privileged_functions_end__\t\t= ( uint32_t * ) ( ( uint32_t ) &( Image$$ER_IROM_NS_PRIVILEGED_ALIGN$$Limit ) - 0x1 ); /* Last address in privileged Flash region. */\n\n/* Flash containing system calls. */\nconst uint32_t * __syscalls_flash_start__\t\t\t= ( uint32_t * ) &( Image$$ER_IROM_NS_FREERTOS_SYSTEM_CALLS$$Base );\nconst uint32_t * __syscalls_flash_end__\t\t\t\t= ( uint32_t * ) ( ( uint32_t ) &( Image$$ER_IROM_NS_FREERTOS_SYSTEM_CALLS_ALIGN$$Limit ) - 0x1 ); /* Last address in Flash region containing system calls. */\n\n/* Unprivileged flash. Note that the section containing system calls is\n * unprivileged so that unprivileged tasks can make system calls. */\nconst uint32_t * __unprivileged_flash_start__\t\t= ( uint32_t * ) &( Image$$ER_IROM_NS_UNPRIVILEGED$$Base );\nconst uint32_t * __unprivileged_flash_end__\t\t\t= ( uint32_t * ) ( ( uint32_t ) &( Image$$ER_IROM_NS_UNPRIVILEGED_ALIGN$$Limit ) - 0x1 ); /* Last address in un-privileged Flash region. */\n\n/* RAM with priviledged access only. This contains kernel data. */\nconst uint32_t * __privileged_sram_start__\t\t\t= ( uint32_t * ) &( Image$$ER_IRAM_NS_PRIVILEGED$$Base );\nconst uint32_t * __privileged_sram_end__\t\t\t= ( uint32_t * ) ( ( uint32_t ) &( Image$$ER_IRAM_NS_PRIVILEGED_ALIGN$$Limit ) - 0x1 ); /* Last address in privileged RAM. */\n\n/* Unprivileged RAM. */\nconst uint32_t * __unprivileged_sram_start__\t\t= ( uint32_t * ) &( Image$$ER_IRAM_NS_UNPRIVILEGED$$Base );\nconst uint32_t * __unprivileged_sram_end__\t\t\t= ( uint32_t * ) ( ( uint32_t ) &( Image$$ER_IRAM_NS_UNPRIVILEGED_ALIGN$$Limit ) - 0x1 ); /* Last address in un-privileged RAM. */\n/*-----------------------------------------------------------*/\n\n/**\n * @brief Create all demo tasks.\n */\nstatic void prvCreateTasks( void );\n\n/**\n * @brief The hard fault handler.\n *\n * It calls a function called vHandleMemoryFault.\n */\nvoid HardFault_Handler( void ) __attribute__ ( ( naked ) );\n/*-----------------------------------------------------------*/\n\n/* For instructions on how to build and run this demo, visit the following link:\n * https://www.freertos.org/RTOS-Cortex-M23-NuMaker-PFM-M2351-Keil.html\n */\n\n/* Non-Secure main. */\nint main( void )\n{\n\t/* Initialize debug port. */\n\tDEBUG_PORT->BAUD = UART_BAUD_MODE2 | UART_BAUD_MODE2_DIVIDER( __HIRC, 115200 );\n\tDEBUG_PORT->LINE = UART_WORD_LEN_8 | UART_PARITY_NONE | UART_STOP_BIT_1;\n\n\t/* Print banner. */\n\tprintf( \"\\r\\n\" );\n\tprintf( \"+---------------------------------------------+\\r\\n\" );\n\tprintf( \"|           Nonsecure is running ...          |\\r\\n\" );\n\tprintf( \"+---------------------------------------------+\\r\\n\" );\n\n\t/* Create tasks. */\n\tprvCreateTasks();\n\n\t/* Start scheduler. */\n\tvTaskStartScheduler();\n\n\t/* Will not get here if the scheduler starts successfully.  If you do end up\n\there then there wasn't enough heap memory available to start either the idle\n\ttask or the timer/daemon task.  https://www.freertos.org/a00111.html */\n\n\tfor( ; ; )\n\t{\n\t}\n}\n/*-----------------------------------------------------------*/\n\nstatic void prvCreateTasks( void )\n{\n\t/* Create tasks for the MPU Demo. */\n\tvStartMPUDemo();\n\n\t/* Create tasks for the TZ Demo. */\n\tvStartTZDemo();\n\n\t/* Create tasks for register tests. */\n\tvStartRegTests();\n}\n/*-----------------------------------------------------------*/\n\n/* Stack overflow hook. */\nvoid vApplicationStackOverflowHook( TaskHandle_t xTask, char *pcTaskName )\n{\n\t/* Force an assert. */\n\tconfigASSERT( pcTaskName == 0 );\n}\n/*-----------------------------------------------------------*/\n\n/* configUSE_STATIC_ALLOCATION is set to 1, so the application must provide an\n * implementation of vApplicationGetIdleTaskMemory() to provide the memory that\n * is used by the Idle task. */\nvoid vApplicationGetIdleTaskMemory(\tStaticTask_t ** ppxIdleTaskTCBBuffer,\n\t\t\t\t\t\t\t\t\tStackType_t ** ppxIdleTaskStackBuffer,\n\t\t\t\t\t\t\t\t\tuint32_t * pulIdleTaskStackSize )\n{\n\t/* If the buffers to be provided to the Idle task are declared inside this\n\t * function then they must be declared static - otherwise they will be\n\t * allocated on the stack and so not exists after this function exits. */\n\tstatic StaticTask_t xIdleTaskTCB;\n\tstatic StackType_t uxIdleTaskStack[ configMINIMAL_STACK_SIZE ] __attribute__( ( aligned( 32 ) ) );\n\n\t/* Pass out a pointer to the StaticTask_t structure in which the Idle\n\t * task's state will be stored. */\n\t*ppxIdleTaskTCBBuffer = &xIdleTaskTCB;\n\n\t/* Pass out the array that will be used as the Idle task's stack. */\n\t*ppxIdleTaskStackBuffer = uxIdleTaskStack;\n\n\t/* Pass out the size of the array pointed to by *ppxIdleTaskStackBuffer.\n\t * Note that, as the array is necessarily of type StackType_t,\n\t * configMINIMAL_STACK_SIZE is specified in words, not bytes. */\n\t*pulIdleTaskStackSize = configMINIMAL_STACK_SIZE;\n}\n/*-----------------------------------------------------------*/\n\n/* configUSE_STATIC_ALLOCATION and configUSE_TIMERS are both set to 1, so the\n * application must provide an implementation of vApplicationGetTimerTaskMemory()\n * to provide the memory that is used by the Timer service task. */\nvoid vApplicationGetTimerTaskMemory( StaticTask_t ** ppxTimerTaskTCBBuffer,\n\t\t\t\t\t\t\t\t\t StackType_t ** ppxTimerTaskStackBuffer,\n\t\t\t\t\t\t\t\t\t uint32_t * pulTimerTaskStackSize )\n{\n\t/* If the buffers to be provided to the Timer task are declared inside this\n\t * function then they must be declared static - otherwise they will be\n\t * allocated on the stack and so not exists after this function exits. */\n\tstatic StaticTask_t xTimerTaskTCB;\n\tstatic StackType_t uxTimerTaskStack[ configTIMER_TASK_STACK_DEPTH ] __attribute__( ( aligned( 32 ) ) );\n\n\t/* Pass out a pointer to the StaticTask_t structure in which the Timer\n\t * task's state will be stored. */\n\t*ppxTimerTaskTCBBuffer = &xTimerTaskTCB;\n\n\t/* Pass out the array that will be used as the Timer task's stack. */\n\t*ppxTimerTaskStackBuffer = uxTimerTaskStack;\n\n\t/* Pass out the size of the array pointed to by *ppxTimerTaskStackBuffer.\n\t * Note that, as the array is necessarily of type StackType_t,\n\t * configTIMER_TASK_STACK_DEPTH is specified in words, not bytes. */\n\t*pulTimerTaskStackSize = configTIMER_TASK_STACK_DEPTH;\n}\n/*-----------------------------------------------------------*/\n\nvoid HardFault_Handler( void )\n{\n\t__asm volatile\n\t(\n\t\t\" movs r0, #4\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\" mov r1, lr\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\" tst r0, r1\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\" beq msp_used_for_stacking\t\t\t\t\t\t\t\\n\"\n\t\t\" mrs r0, psp\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\" ldr r2, handler_address_const\t\t\t\t\t\t\\n\"\n\t\t\" bx r2\t\t\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\"msp_used_for_stacking:\t\t\t\t\t\t\t\t\\n\"\n\t\t\"\tmrs r0, msp\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\"\tldr r2, handler_address_const\t\t\t\t\t\\n\"\n\t\t\"\tbx r2\t\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\"\t\t\t\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\" .align 4\t\t\t\t\t\t\t\t\t\t\t\\n\"\n\t\t\" handler_address_const: .word vHandleMemoryFault\t\\n\"\n\t);\n}\n/*-----------------------------------------------------------*/",
    "repo": "FreeRTOS/FreeRTOS",
    "path": "./datasets/diagrams-repos/FreeRTOS/FreeRTOS/FreeRTOS/Demo/CORTEX_MPU_M23_Nuvoton_NuMaker_PFM_M2351_IAR_GCC/Projects/Keil/NonSecure/main_ns.c",
    "query": "Can you depict the process of handling a hard fault in this system, including the determination of stacking mode and the branching to the memory fault handler?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'HardFault_Handler', 'node_id': 'HardFault_Handler', 'description': 'Main hard fault handler function that determines stack pointer and branches to memory fault handler', 'visibility': 'public', 'return_type': 'void', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'vHandleMemoryFault', 'node_id': 'vHandleMemoryFault', 'description': 'External memory fault handler that processes the fault', 'visibility': 'public', 'return_type': 'void', 'params': 'uint32_t *faultStackAddress', 'source_class_id': None}, {'type': 'entity', 'name': 'PSP', 'node_id': 'PSP', 'description': 'Process Stack Pointer used in thread mode', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'MSP', 'node_id': 'MSP', 'description': 'Main Stack Pointer used in handler mode', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'LR', 'node_id': 'LR', 'description': 'Link Register containing return information', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'stackingMode', 'node_id': 'stackingMode', 'description': 'Determines which stack pointer was used', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'HardFault_Handler', 'node_id_to': 'vHandleMemoryFault', 'description': 'Calls with stack pointer'}, {'node_id_from': 'HardFault_Handler', 'node_id_to': 'PSP', 'description': 'Reads if thread mode'}, {'node_id_from': 'HardFault_Handler', 'node_id_to': 'MSP', 'description': 'Reads if handler mode'}, {'node_id_from': 'HardFault_Handler', 'node_id_to': 'LR', 'description': 'Checks bit 2 for stack usage'}, {'node_id_from': 'LR', 'node_id_to': 'stackingMode', 'description': 'Determines stack mode'}, {'node_id_from': 'stackingMode', 'node_id_to': 'PSP', 'description': 'Selects if thread mode'}, {'node_id_from': 'stackingMode', 'node_id_to': 'MSP', 'description': 'Selects if handler mode'}], 'packages': [{'package_id': 'faultHandling', 'children': ['HardFault_Handler', 'vHandleMemoryFault'], 'description': 'Fault handling system components'}, {'package_id': 'stackPointers', 'children': ['PSP', 'MSP'], 'description': 'System stack pointers'}, {'package_id': 'registers', 'children': ['LR', 'stackingMode'], 'description': 'CPU registers and modes'}]}",
    "version": "full",
    "text_answer": "The hard fault handling process begins when HardFault_Handler is triggered. It first examines bit 2 of the Link Register (LR) to determine which stack pointer was in use when the fault occurred. If the thread mode was active, it reads the Process Stack Pointer (PSP); if handler mode was active, it reads the Main Stack Pointer (MSP). The appropriate stack pointer is then passed to vHandleMemoryFault for further processing.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C++",
    "code": "\n#if     _MSC_VER > 1000\n#pragma once\n#endif\n\n#if !defined(_INC_ERRNO)\n#define _INC_ERRNO\n\n#if !defined(_WIN32)\n#error ERROR: Only Win32 targets supported!\n#endif\n\n//#include <winsock.h>\n\n#if defined(__cplusplus)\nextern \"C\" {\n#endif\n\n\n\n/* Define _CRTIMP */\n\n#ifndef _CRTIMP\n#if defined(_DLL)\n#define _CRTIMP __declspec(dllimport)\n#else   /* ndef _DLL */\n#define _CRTIMP\n#endif  /* _DLL */\n#endif  /* _CRTIMP */\n\n\n/* Define __cdecl for non-Microsoft compilers */\n\n#if ( !defined(_MSC_VER) && !defined(__cdecl) )\n#define __cdecl\n#endif\n\n/* Define _CRTAPI1 (for compatibility with the NT SDK) */\n\n#if !defined(_CRTAPI1)\n#if\t_MSC_VER >= 800 && _M_IX86 >= 300\n#define _CRTAPI1 __cdecl\n#else\n#define _CRTAPI1\n#endif\n#endif\n\n#if defined(__PTW32_STATIC_LIB) && defined(_MSC_VER) && _MSC_VER >= 1400\n#  define __PTW32_STATIC_TLSLIB\n#endif\n\n#if defined (__PTW32_STATIC_LIB) || defined (__PTW32_STATIC_TLSLIB)\n#  define  __PTW32_DLLPORT\n#elif defined (__PTW32_BUILD)\n#    define  __PTW32_DLLPORT __declspec (dllexport)\n#  else\n#    define  __PTW32_DLLPORT __declspec (dllimport)\n#  endif\n\n/* declare reference to errno */\n\n#if (defined(_MT) || defined(_MD) || defined(_DLL)) && !defined(_MAC)\n__PTW32_DLLPORT int * __cdecl _errno(void);\n#define errno   (*_errno())\n#else   /* ndef _MT && ndef _MD && ndef _DLL */\n_CRTIMP extern int errno;\n#endif  /* _MT || _MD || _DLL */\n\n/* Error Codes */\n\n#define EPERM           1\n#define ENOENT          2\n#define ESRCH           3\n#define EINTR           4\n#define EIO             5\n#define ENXIO           6\n#define E2BIG           7\n#define ENOEXEC         8\n#define EBADF           9\n#define ECHILD          10\n#define EAGAIN          11\n#define ENOMEM          12\n#define EACCES          13\n#define EFAULT          14\n#define EBUSY           16\n#define EEXIST          17\n#define EXDEV           18\n#define ENODEV          19\n#define ENOTDIR         20\n#define EISDIR          21\n#define EINVAL          22\n#define ENFILE          23\n#define EMFILE          24\n#define ENOTTY          25\n#define EFBIG           27\n#define ENOSPC          28\n#define ESPIPE          29\n#define EROFS           30\n#define EMLINK          31\n#define EPIPE           32\n#define EDOM            33\n#define ERANGE          34\n#define EDEADLK         36\n\n/* defined differently in winsock.h on WinCE\n * We don't use this value.\n */\n//#if !defined(ENAMETOOLONG)\n//#define ENAMETOOLONG    38\n//#endif\n\n#define ENOLCK          39\n#define ENOSYS          40\n\n/* defined differently in winsock.h on WinCE\n * We don't use this value.\n */\n//#if !defined(ENOTEMPTY)\n//#define ENOTEMPTY       41\n//#endif\n\n#define EILSEQ          42\n\n/*\n * POSIX 2008 - robust mutexes.\n */\n#if  __PTW32_VERSION_MAJOR > 2\n#  if !defined(EOWNERDEAD)\n#    define EOWNERDEAD 1000\n#  endif\n#  if !defined(ENOTRECOVERABLE)\n#    define ENOTRECOVERABLE 1001\n#  endif\n#else\n#  if !defined(EOWNERDEAD)\n#    define EOWNERDEAD 42\n#  endif\n#  if !defined(ENOTRECOVERABLE)\n#    define ENOTRECOVERABLE 43\n#  endif\n#endif\n\n/*\n * Support EDEADLOCK for compatibility with older MS-C versions.\n */\n#define EDEADLOCK       EDEADLK\n\n#if defined(__cplusplus)\n}\n#endif\n\n#endif  /* _INC_ERRNO */",
    "repo": "gozfree/gear-lib",
    "path": "./datasets/diagrams-repos/gozfree/gear-lib/gear-lib/libposix/pthreads4w/need_errno.h",
    "query": "What is the significance of the EOWNERDEAD and ENOTRECOVERABLE error codes in the context of this code?",
    "diagram": "{'nodes': [{'type': 'variable', 'name': 'EOWNERDEAD', 'node_id': 'EOWNERDEAD', 'description': 'Error code for robust mutex owner death condition', 'visibility': 'public', 'return_type': 'int', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'ENOTRECOVERABLE', 'node_id': 'ENOTRECOVERABLE', 'description': 'Error code for unrecoverable mutex state', 'visibility': 'public', 'return_type': 'int', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': '__PTW32_VERSION_MAJOR', 'node_id': '__PTW32_VERSION_MAJOR', 'description': 'Version identifier for PThreads-Win32', 'visibility': 'public', 'return_type': 'int', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': '__PTW32_VERSION_MAJOR', 'node_id_to': 'EOWNERDEAD', 'description': 'Determines error code value'}, {'node_id_from': '__PTW32_VERSION_MAJOR', 'node_id_to': 'ENOTRECOVERABLE', 'description': 'Determines error code value'}], 'packages': [{'package_id': 'robustMutexErrors', 'children': ['EOWNERDEAD', 'ENOTRECOVERABLE'], 'description': 'POSIX 2008 robust mutex error codes'}]}",
    "version": "medium",
    "text_answer": "EOWNERDEAD and ENOTRECOVERABLE are error codes introduced in POSIX 2008 for robust mutex handling. EOWNERDEAD (1000 or 42 depending on version) indicates that the owner of a mutex died while holding it, while ENOTRECOVERABLE (1001 or 43) signals that the mutex is in an unrecoverable state after owner death.",
    "possible_version": [
      "minimal",
      "medium"
    ]
  },
  {
    "language": "C++",
    "code": "\n#if     _MSC_VER > 1000\n#pragma once\n#endif\n\n#if !defined(_INC_ERRNO)\n#define _INC_ERRNO\n\n#if !defined(_WIN32)\n#error ERROR: Only Win32 targets supported!\n#endif\n\n//#include <winsock.h>\n\n#if defined(__cplusplus)\nextern \"C\" {\n#endif\n\n\n\n/* Define _CRTIMP */\n\n#ifndef _CRTIMP\n#if defined(_DLL)\n#define _CRTIMP __declspec(dllimport)\n#else   /* ndef _DLL */\n#define _CRTIMP\n#endif  /* _DLL */\n#endif  /* _CRTIMP */\n\n\n/* Define __cdecl for non-Microsoft compilers */\n\n#if ( !defined(_MSC_VER) && !defined(__cdecl) )\n#define __cdecl\n#endif\n\n/* Define _CRTAPI1 (for compatibility with the NT SDK) */\n\n#if !defined(_CRTAPI1)\n#if\t_MSC_VER >= 800 && _M_IX86 >= 300\n#define _CRTAPI1 __cdecl\n#else\n#define _CRTAPI1\n#endif\n#endif\n\n#if defined(__PTW32_STATIC_LIB) && defined(_MSC_VER) && _MSC_VER >= 1400\n#  define __PTW32_STATIC_TLSLIB\n#endif\n\n#if defined (__PTW32_STATIC_LIB) || defined (__PTW32_STATIC_TLSLIB)\n#  define  __PTW32_DLLPORT\n#elif defined (__PTW32_BUILD)\n#    define  __PTW32_DLLPORT __declspec (dllexport)\n#  else\n#    define  __PTW32_DLLPORT __declspec (dllimport)\n#  endif\n\n/* declare reference to errno */\n\n#if (defined(_MT) || defined(_MD) || defined(_DLL)) && !defined(_MAC)\n__PTW32_DLLPORT int * __cdecl _errno(void);\n#define errno   (*_errno())\n#else   /* ndef _MT && ndef _MD && ndef _DLL */\n_CRTIMP extern int errno;\n#endif  /* _MT || _MD || _DLL */\n\n/* Error Codes */\n\n#define EPERM           1\n#define ENOENT          2\n#define ESRCH           3\n#define EINTR           4\n#define EIO             5\n#define ENXIO           6\n#define E2BIG           7\n#define ENOEXEC         8\n#define EBADF           9\n#define ECHILD          10\n#define EAGAIN          11\n#define ENOMEM          12\n#define EACCES          13\n#define EFAULT          14\n#define EBUSY           16\n#define EEXIST          17\n#define EXDEV           18\n#define ENODEV          19\n#define ENOTDIR         20\n#define EISDIR          21\n#define EINVAL          22\n#define ENFILE          23\n#define EMFILE          24\n#define ENOTTY          25\n#define EFBIG           27\n#define ENOSPC          28\n#define ESPIPE          29\n#define EROFS           30\n#define EMLINK          31\n#define EPIPE           32\n#define EDOM            33\n#define ERANGE          34\n#define EDEADLK         36\n\n/* defined differently in winsock.h on WinCE\n * We don't use this value.\n */\n//#if !defined(ENAMETOOLONG)\n//#define ENAMETOOLONG    38\n//#endif\n\n#define ENOLCK          39\n#define ENOSYS          40\n\n/* defined differently in winsock.h on WinCE\n * We don't use this value.\n */\n//#if !defined(ENOTEMPTY)\n//#define ENOTEMPTY       41\n//#endif\n\n#define EILSEQ          42\n\n/*\n * POSIX 2008 - robust mutexes.\n */\n#if  __PTW32_VERSION_MAJOR > 2\n#  if !defined(EOWNERDEAD)\n#    define EOWNERDEAD 1000\n#  endif\n#  if !defined(ENOTRECOVERABLE)\n#    define ENOTRECOVERABLE 1001\n#  endif\n#else\n#  if !defined(EOWNERDEAD)\n#    define EOWNERDEAD 42\n#  endif\n#  if !defined(ENOTRECOVERABLE)\n#    define ENOTRECOVERABLE 43\n#  endif\n#endif\n\n/*\n * Support EDEADLOCK for compatibility with older MS-C versions.\n */\n#define EDEADLOCK       EDEADLK\n\n#if defined(__cplusplus)\n}\n#endif\n\n#endif  /* _INC_ERRNO */",
    "repo": "gozfree/gear-lib",
    "path": "./datasets/diagrams-repos/gozfree/gear-lib/gear-lib/libposix/pthreads4w/need_errno.h",
    "query": "What is the significance of the EOWNERDEAD and ENOTRECOVERABLE error codes in the context of this code?",
    "diagram": "{'nodes': [{'type': 'variable', 'name': 'EOWNERDEAD', 'node_id': 'EOWNERDEAD', 'description': 'Error code for robust mutex owner death condition', 'visibility': 'public', 'return_type': 'int', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'ENOTRECOVERABLE', 'node_id': 'ENOTRECOVERABLE', 'description': 'Error code for unrecoverable mutex state', 'visibility': 'public', 'return_type': 'int', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': '__PTW32_VERSION_MAJOR', 'node_id': '__PTW32_VERSION_MAJOR', 'description': 'Version identifier for PThreads-Win32', 'visibility': 'public', 'return_type': 'int', 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'POSIX2008Standard', 'node_id': 'POSIX2008Standard', 'description': 'POSIX.1-2008 standard specification', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'robustMutexFeature', 'node_id': 'robustMutexFeature', 'description': 'Robust mutex functionality in POSIX threads', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': '__PTW32_VERSION_MAJOR', 'node_id_to': 'EOWNERDEAD', 'description': 'Determines error code value'}, {'node_id_from': '__PTW32_VERSION_MAJOR', 'node_id_to': 'ENOTRECOVERABLE', 'description': 'Determines error code value'}, {'node_id_from': 'POSIX2008Standard', 'node_id_to': 'robustMutexFeature', 'description': 'Defines'}, {'node_id_from': 'robustMutexFeature', 'node_id_to': 'EOWNERDEAD', 'description': 'Requires'}, {'node_id_from': 'robustMutexFeature', 'node_id_to': 'ENOTRECOVERABLE', 'description': 'Requires'}], 'packages': [{'package_id': 'robustMutexErrors', 'children': ['EOWNERDEAD', 'ENOTRECOVERABLE'], 'description': 'POSIX 2008 robust mutex error codes'}, {'package_id': 'posixStandards', 'children': ['POSIX2008Standard', 'robustMutexFeature'], 'description': 'POSIX standard specifications and features'}]}",
    "version": "full",
    "text_answer": "EOWNERDEAD and ENOTRECOVERABLE are error codes introduced in POSIX 2008 for robust mutex handling. EOWNERDEAD (1000 or 42 depending on version) indicates that the owner of a mutex died while holding it, while ENOTRECOVERABLE (1001 or 43) signals that the mutex is in an unrecoverable state after owner death.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.apache.hadoop.yarn.sls.appmaster;\n\nimport java.io.IOException;\nimport java.security.PrivilegedExceptionAction;\nimport java.util.ArrayList;\nimport java.util.Collection;\nimport java.util.HashMap;\nimport java.util.LinkedList;\nimport java.util.List;\nimport java.util.Map;\n\nimport org.apache.hadoop.classification.InterfaceAudience.Private;\nimport org.apache.hadoop.classification.InterfaceStability.Unstable;\nimport org.apache.hadoop.security.UserGroupInformation;\nimport org.apache.hadoop.security.token.Token;\nimport org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest;\nimport org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse;\nimport org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest;\nimport org.apache.hadoop.yarn.api.records.ApplicationId;\nimport org.apache.hadoop.yarn.api.records.Container;\nimport org.apache.hadoop.yarn.api.records.ReservationId;\nimport org.apache.hadoop.yarn.api.records.Resource;\nimport org.apache.hadoop.yarn.api.records.ContainerExitStatus;\nimport org.apache.hadoop.yarn.api.records.ContainerId;\nimport org.apache.hadoop.yarn.api.records.ContainerStatus;\nimport org.apache.hadoop.yarn.api.records.ResourceRequest;\nimport org.apache.hadoop.yarn.exceptions.YarnException;\nimport org.apache.hadoop.yarn.security.AMRMTokenIdentifier;\nimport org.apache.hadoop.yarn.server.resourcemanager.ResourceManager;\nimport org.apache.hadoop.yarn.sls.AMDefinition;\nimport org.apache.hadoop.yarn.sls.ReservationClientUtil;\nimport org.apache.hadoop.yarn.sls.scheduler.ContainerSimulator;\nimport org.apache.hadoop.yarn.sls.SLSRunner;\nimport org.apache.hadoop.yarn.util.resource.Resources;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\n@Private\n@Unstable\npublic class MRAMSimulator extends AMSimulator {\n  /*\n  Vocabulary Used:\n  pending -> requests which are NOT yet sent to RM\n  scheduled -> requests which are sent to RM but not yet assigned\n  assigned -> requests which are assigned to a container\n  completed -> request corresponding to which container has completed\n\n  Maps are scheduled as soon as their requests are received. Reduces are\n  scheduled when all maps have finished (not support slow-start currently).\n  */\n\n  public static final String MAP_TYPE = \"map\";\n  public static final String REDUCE_TYPE = \"reduce\";\n\n  private static final int PRIORITY_REDUCE = 10;\n  private static final int PRIORITY_MAP = 20;\n\n  // pending maps\n  private LinkedList<ContainerSimulator> pendingMaps =\n          new LinkedList<>();\n\n  // pending failed maps\n  private LinkedList<ContainerSimulator> pendingFailedMaps =\n          new LinkedList<ContainerSimulator>();\n\n  // scheduled maps\n  private LinkedList<ContainerSimulator> scheduledMaps =\n          new LinkedList<ContainerSimulator>();\n\n  // assigned maps\n  private Map<ContainerId, ContainerSimulator> assignedMaps =\n          new HashMap<ContainerId, ContainerSimulator>();\n\n  // reduces which are not yet scheduled\n  private LinkedList<ContainerSimulator> pendingReduces =\n          new LinkedList<ContainerSimulator>();\n\n  // pending failed reduces\n  private LinkedList<ContainerSimulator> pendingFailedReduces =\n          new LinkedList<ContainerSimulator>();\n\n  // scheduled reduces\n  private LinkedList<ContainerSimulator> scheduledReduces =\n          new LinkedList<ContainerSimulator>();\n\n  // assigned reduces\n  private Map<ContainerId, ContainerSimulator> assignedReduces =\n          new HashMap<ContainerId, ContainerSimulator>();\n\n  // all maps & reduces\n  private LinkedList<ContainerSimulator> allMaps =\n          new LinkedList<ContainerSimulator>();\n  private LinkedList<ContainerSimulator> allReduces =\n          new LinkedList<ContainerSimulator>();\n\n  // counters\n  private int mapFinished = 0;\n  private int mapTotal = 0;\n  private int reduceFinished = 0;\n  private int reduceTotal = 0;\n\n  // finished\n  private boolean isFinished = false;\n\n  private static final Logger LOG =\n      LoggerFactory.getLogger(MRAMSimulator.class);\n\n  @SuppressWarnings(\"checkstyle:parameternumber\")\n  public void init(AMDefinition amDef, ResourceManager rm, SLSRunner slsRunner,\n      boolean tracked, long baselineTimeMS, long heartbeatInterval,\n      Map<ApplicationId, AMSimulator> appIdToAMSim) {\n    super.init(amDef, rm, slsRunner, tracked, baselineTimeMS,\n        heartbeatInterval, appIdToAMSim);\n    amtype = \"mapreduce\";\n\n    // get map/reduce tasks\n    for (ContainerSimulator cs : amDef.getTaskContainers()) {\n      if (cs.getType().equals(\"map\")) {\n        cs.setPriority(PRIORITY_MAP);\n        allMaps.add(cs);\n      } else if (cs.getType().equals(\"reduce\")) {\n        cs.setPriority(PRIORITY_REDUCE);\n        allReduces.add(cs);\n      }\n    }\n\n    LOG.info(\"Added new job with {} mapper and {} reducers\",\n        allMaps.size(), allReduces.size());\n\n    mapTotal = allMaps.size();\n    reduceTotal = allReduces.size();\n    totalContainers = mapTotal + reduceTotal;\n  }\n\n  @Override\n  public synchronized void notifyAMContainerLaunched(Container masterContainer)\n      throws Exception {\n    if (null != masterContainer) {\n      restart();\n      super.notifyAMContainerLaunched(masterContainer);\n    }\n  }\n\n  @Override\n  @SuppressWarnings(\"unchecked\")\n  protected void processResponseQueue() throws Exception {\n    while (! responseQueue.isEmpty()) {\n      AllocateResponse response = responseQueue.take();\n\n      // check completed containers\n      if (! response.getCompletedContainersStatuses().isEmpty()) {\n        for (ContainerStatus cs : response.getCompletedContainersStatuses()) {\n          ContainerId containerId = cs.getContainerId();\n          if (cs.getExitStatus() == ContainerExitStatus.SUCCESS) {\n            if (assignedMaps.containsKey(containerId)) {\n              LOG.debug(\"Application {} has one mapper finished ({}).\",\n                  appId, containerId);\n              assignedMaps.remove(containerId);\n              mapFinished ++;\n              finishedContainers ++;\n            } else if (assignedReduces.containsKey(containerId)) {\n              LOG.debug(\"Application {} has one reducer finished ({}).\",\n                  appId, containerId);\n              assignedReduces.remove(containerId);\n              reduceFinished ++;\n              finishedContainers ++;\n            } else if (amContainer.getId().equals(containerId)){\n              // am container released event\n              isFinished = true;\n              LOG.info(\"Application {} goes to finish.\", appId);\n            }\n\n            if (mapFinished >= mapTotal && reduceFinished >= reduceTotal) {\n              lastStep();\n            }\n          } else {\n            // container to be killed\n            if (assignedMaps.containsKey(containerId)) {\n              LOG.debug(\"Application {} has one mapper killed ({}).\",\n                  appId, containerId);\n              pendingFailedMaps.add(assignedMaps.remove(containerId));\n            } else if (assignedReduces.containsKey(containerId)) {\n              LOG.debug(\"Application {} has one reducer killed ({}).\",\n                  appId, containerId);\n              pendingFailedReduces.add(assignedReduces.remove(containerId));\n            } else if (amContainer.getId().equals(containerId)){\n              LOG.info(\"Application {}'s AM is \" +\n                  \"going to be killed. Waiting for rescheduling...\", appId);\n            }\n          }\n        }\n      }\n\n      // check finished\n      if (isAMContainerRunning &&\n              (mapFinished >= mapTotal) &&\n              (reduceFinished >= reduceTotal)) {\n        isAMContainerRunning = false;\n        LOG.debug(\"Application {} sends out event to clean up\"\n            + \" its AM container.\", appId);\n        isFinished = true;\n        break;\n      }\n\n      // check allocated containers\n      for (Container container : response.getAllocatedContainers()) {\n        if (! scheduledMaps.isEmpty()) {\n          ContainerSimulator cs = scheduledMaps.remove();\n          LOG.debug(\"Application {} starts to launch a mapper ({}).\",\n              appId, container.getId());\n          assignedMaps.put(container.getId(), cs);\n          se.getNmMap().get(container.getNodeId())\n              .addNewContainer(container, cs.getLifeTime(), appId);\n          getRanNodes().add(container.getNodeId());\n        } else if (! this.scheduledReduces.isEmpty()) {\n          ContainerSimulator cs = scheduledReduces.remove();\n          LOG.debug(\"Application {} starts to launch a reducer ({}).\",\n              appId, container.getId());\n          assignedReduces.put(container.getId(), cs);\n          se.getNmMap().get(container.getNodeId())\n              .addNewContainer(container, cs.getLifeTime(), appId);\n          getRanNodes().add(container.getNodeId());\n        }\n      }\n    }\n  }\n\n  /**\n   * restart running because of the am container killed\n   */\n  private void restart()\n          throws YarnException, IOException, InterruptedException {\n    // clear\n    isFinished = false;\n    pendingFailedMaps.clear();\n    pendingMaps.clear();\n    pendingReduces.clear();\n    pendingFailedReduces.clear();\n\n    // Only add totalMaps - finishedMaps\n    int added = 0;\n    for (ContainerSimulator cs : allMaps) {\n      if (added >= mapTotal - mapFinished) {\n        break;\n      }\n      pendingMaps.add(cs);\n    }\n\n    // And same, only add totalReduces - finishedReduces\n    added = 0;\n    for (ContainerSimulator cs : allReduces) {\n      if (added >= reduceTotal - reduceFinished) {\n        break;\n      }\n      pendingReduces.add(cs);\n    }\n    amContainer = null;\n  }\n\n  private List<ContainerSimulator> mergeLists(List<ContainerSimulator> left, List<ContainerSimulator> right) {\n    List<ContainerSimulator> list = new ArrayList<>();\n    list.addAll(left);\n    list.addAll(right);\n    return list;\n  }\n\n  @Override\n  protected void sendContainerRequest()\n          throws YarnException, IOException, InterruptedException {\n    if (isFinished) {\n      return;\n    }\n\n    // send out request\n    List<ResourceRequest> ask = null;\n    if (mapFinished != mapTotal) {\n      // map phase\n      if (!pendingMaps.isEmpty()) {\n        ask = packageRequests(mergeLists(pendingMaps, scheduledMaps),\n            PRIORITY_MAP);\n        LOG.debug(\"Application {} sends out request for {} mappers.\",\n            appId, pendingMaps.size());\n        scheduledMaps.addAll(pendingMaps);\n        pendingMaps.clear();\n      } else if (!pendingFailedMaps.isEmpty()) {\n        ask = packageRequests(mergeLists(pendingFailedMaps, scheduledMaps),\n            PRIORITY_MAP);\n        LOG.debug(\"Application {} sends out requests for {} failed mappers.\",\n            appId, pendingFailedMaps.size());\n        scheduledMaps.addAll(pendingFailedMaps);\n        pendingFailedMaps.clear();\n      }\n    } else if (reduceFinished != reduceTotal) {\n      // reduce phase\n      if (!pendingReduces.isEmpty()) {\n        ask = packageRequests(mergeLists(pendingReduces, scheduledReduces),\n            PRIORITY_REDUCE);\n        LOG.debug(\"Application {} sends out requests for {} reducers.\",\n                appId, pendingReduces.size());\n        scheduledReduces.addAll(pendingReduces);\n        pendingReduces.clear();\n      } else if (!pendingFailedReduces.isEmpty()) {\n        ask = packageRequests(mergeLists(pendingFailedReduces, scheduledReduces),\n            PRIORITY_REDUCE);\n        LOG.debug(\"Application {} sends out request for {} failed reducers.\",\n            appId, pendingFailedReduces.size());\n        scheduledReduces.addAll(pendingFailedReduces);\n        pendingFailedReduces.clear();\n      }\n    }\n\n    if (ask == null) {\n      ask = new ArrayList<>();\n    }\n\n    final AllocateRequest request = createAllocateRequest(ask);\n    if (totalContainers == 0) {\n      request.setProgress(1.0f);\n    } else {\n      request.setProgress((float) finishedContainers / totalContainers);\n    }\n\n    UserGroupInformation ugi =\n            UserGroupInformation.createRemoteUser(appAttemptId.toString());\n    Token<AMRMTokenIdentifier> token = rm.getRMContext().getRMApps()\n            .get(appAttemptId.getApplicationId())\n            .getRMAppAttempt(appAttemptId).getAMRMToken();\n    ugi.addTokenIdentifier(token.decodeIdentifier());\n    AllocateResponse response = ugi.doAs(\n            new PrivilegedExceptionAction<AllocateResponse>() {\n      @Override\n      public AllocateResponse run() throws Exception {\n        return rm.getApplicationMasterService().allocate(request);\n      }\n    });\n    if (response != null) {\n      responseQueue.put(response);\n    }\n  }\n\n  @Override\n  public void initReservation(ReservationId reservationId, long deadline,\n      long now) {\n\n    Resource mapRes = getMaxResource(allMaps);\n    long mapDur = getMaxDuration(allMaps);\n    Resource redRes = getMaxResource(allReduces);\n    long redDur = getMaxDuration(allReduces);\n\n    ReservationSubmissionRequest rr = ReservationClientUtil.\n        createMRReservation(reservationId,\n            \"reservation_\" + reservationId.getId(), mapRes, allMaps.size(),\n            mapDur, redRes, allReduces.size(), redDur, now + traceStartTimeMS,\n            now + deadline, queue);\n\n    setReservationRequest(rr);\n  }\n\n  // Helper to compute the component-wise maximum resource used by any container\n  private Resource getMaxResource(Collection<ContainerSimulator> containers) {\n    return containers.parallelStream()\n        .map(ContainerSimulator::getResource)\n        .reduce(Resource.newInstance(0, 0), Resources::componentwiseMax);\n  }\n\n  // Helper to compute the maximum resource used by any map container\n  private long getMaxDuration(Collection<ContainerSimulator> containers) {\n    return containers.parallelStream()\n        .mapToLong(ContainerSimulator::getLifeTime)\n        .reduce(0L, Long::max);\n  }\n\n  @Override\n  protected void checkStop() {\n    if (isFinished) {\n      super.setEndTime(System.currentTimeMillis());\n    }\n  }\n\n  @Override\n  public void lastStep() throws Exception {\n    super.lastStep();\n\n    // clear data structures\n    allMaps.clear();\n    allReduces.clear();\n    assignedMaps.clear();\n    assignedReduces.clear();\n    pendingFailedMaps.clear();\n    pendingFailedReduces.clear();\n    pendingMaps.clear();\n    pendingReduces.clear();\n    scheduledMaps.clear();\n    scheduledReduces.clear();\n    responseQueue.clear();\n  }\n}",
    "repo": "apache/hadoop",
    "path": "./datasets/diagrams-repos/apache/hadoop/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/appmaster/MRAMSimulator.java",
    "query": "Can you show the flow of map tasks from pending to completed in the MRAMSimulator, including how failures are handled?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'MRAMSimulator', 'node_id': 'MRAMSimulator', 'description': 'MapReduce Application Master Simulator', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'pendingMaps', 'node_id': 'pendingMaps', 'description': 'Queue of map tasks waiting to be scheduled', 'visibility': 'private', 'return_type': 'LinkedList<ContainerSimulator>', 'params': None, 'source_class_id': 'MRAMSimulator'}, {'type': 'field', 'name': 'scheduledMaps', 'node_id': 'scheduledMaps', 'description': 'Queue of map tasks sent to ResourceManager', 'visibility': 'private', 'return_type': 'LinkedList<ContainerSimulator>', 'params': None, 'source_class_id': 'MRAMSimulator'}, {'type': 'field', 'name': 'assignedMaps', 'node_id': 'assignedMaps', 'description': 'Map tasks assigned to containers', 'visibility': 'private', 'return_type': 'Map<ContainerId, ContainerSimulator>', 'params': None, 'source_class_id': 'MRAMSimulator'}, {'type': 'field', 'name': 'pendingFailedMaps', 'node_id': 'pendingFailedMaps', 'description': 'Queue of failed map tasks waiting to be rescheduled', 'visibility': 'private', 'return_type': 'LinkedList<ContainerSimulator>', 'params': None, 'source_class_id': 'MRAMSimulator'}], 'edges': [{'node_id_from': 'pendingMaps', 'node_id_to': 'scheduledMaps', 'description': 'Send request to RM'}, {'node_id_from': 'scheduledMaps', 'node_id_to': 'assignedMaps', 'description': 'Allocated container'}, {'node_id_from': 'assignedMaps', 'node_id_to': 'pendingFailedMaps', 'description': 'Container failed'}, {'node_id_from': 'pendingFailedMaps', 'node_id_to': 'scheduledMaps', 'description': 'Reschedule failed tasks'}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'pendingMaps', 'description': ''}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'scheduledMaps', 'description': ''}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'assignedMaps', 'description': ''}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'pendingFailedMaps', 'description': ''}], 'packages': [{'package_id': 'mapTaskStates', 'children': ['pendingMaps', 'scheduledMaps', 'assignedMaps', 'pendingFailedMaps'], 'description': 'States of map tasks in MRAppMaster'}]}",
    "version": "minimal",
    "text_answer": "Map tasks flow through four main states: pendingMaps (initial) -> scheduledMaps (requested from RM) -> assignedMaps (running in containers) -> completed. Failed tasks move to pendingFailedMaps and are rescheduled back through scheduledMaps for retry.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.apache.hadoop.yarn.sls.appmaster;\n\nimport java.io.IOException;\nimport java.security.PrivilegedExceptionAction;\nimport java.util.ArrayList;\nimport java.util.Collection;\nimport java.util.HashMap;\nimport java.util.LinkedList;\nimport java.util.List;\nimport java.util.Map;\n\nimport org.apache.hadoop.classification.InterfaceAudience.Private;\nimport org.apache.hadoop.classification.InterfaceStability.Unstable;\nimport org.apache.hadoop.security.UserGroupInformation;\nimport org.apache.hadoop.security.token.Token;\nimport org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest;\nimport org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse;\nimport org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest;\nimport org.apache.hadoop.yarn.api.records.ApplicationId;\nimport org.apache.hadoop.yarn.api.records.Container;\nimport org.apache.hadoop.yarn.api.records.ReservationId;\nimport org.apache.hadoop.yarn.api.records.Resource;\nimport org.apache.hadoop.yarn.api.records.ContainerExitStatus;\nimport org.apache.hadoop.yarn.api.records.ContainerId;\nimport org.apache.hadoop.yarn.api.records.ContainerStatus;\nimport org.apache.hadoop.yarn.api.records.ResourceRequest;\nimport org.apache.hadoop.yarn.exceptions.YarnException;\nimport org.apache.hadoop.yarn.security.AMRMTokenIdentifier;\nimport org.apache.hadoop.yarn.server.resourcemanager.ResourceManager;\nimport org.apache.hadoop.yarn.sls.AMDefinition;\nimport org.apache.hadoop.yarn.sls.ReservationClientUtil;\nimport org.apache.hadoop.yarn.sls.scheduler.ContainerSimulator;\nimport org.apache.hadoop.yarn.sls.SLSRunner;\nimport org.apache.hadoop.yarn.util.resource.Resources;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\n@Private\n@Unstable\npublic class MRAMSimulator extends AMSimulator {\n  /*\n  Vocabulary Used:\n  pending -> requests which are NOT yet sent to RM\n  scheduled -> requests which are sent to RM but not yet assigned\n  assigned -> requests which are assigned to a container\n  completed -> request corresponding to which container has completed\n\n  Maps are scheduled as soon as their requests are received. Reduces are\n  scheduled when all maps have finished (not support slow-start currently).\n  */\n\n  public static final String MAP_TYPE = \"map\";\n  public static final String REDUCE_TYPE = \"reduce\";\n\n  private static final int PRIORITY_REDUCE = 10;\n  private static final int PRIORITY_MAP = 20;\n\n  // pending maps\n  private LinkedList<ContainerSimulator> pendingMaps =\n          new LinkedList<>();\n\n  // pending failed maps\n  private LinkedList<ContainerSimulator> pendingFailedMaps =\n          new LinkedList<ContainerSimulator>();\n\n  // scheduled maps\n  private LinkedList<ContainerSimulator> scheduledMaps =\n          new LinkedList<ContainerSimulator>();\n\n  // assigned maps\n  private Map<ContainerId, ContainerSimulator> assignedMaps =\n          new HashMap<ContainerId, ContainerSimulator>();\n\n  // reduces which are not yet scheduled\n  private LinkedList<ContainerSimulator> pendingReduces =\n          new LinkedList<ContainerSimulator>();\n\n  // pending failed reduces\n  private LinkedList<ContainerSimulator> pendingFailedReduces =\n          new LinkedList<ContainerSimulator>();\n\n  // scheduled reduces\n  private LinkedList<ContainerSimulator> scheduledReduces =\n          new LinkedList<ContainerSimulator>();\n\n  // assigned reduces\n  private Map<ContainerId, ContainerSimulator> assignedReduces =\n          new HashMap<ContainerId, ContainerSimulator>();\n\n  // all maps & reduces\n  private LinkedList<ContainerSimulator> allMaps =\n          new LinkedList<ContainerSimulator>();\n  private LinkedList<ContainerSimulator> allReduces =\n          new LinkedList<ContainerSimulator>();\n\n  // counters\n  private int mapFinished = 0;\n  private int mapTotal = 0;\n  private int reduceFinished = 0;\n  private int reduceTotal = 0;\n\n  // finished\n  private boolean isFinished = false;\n\n  private static final Logger LOG =\n      LoggerFactory.getLogger(MRAMSimulator.class);\n\n  @SuppressWarnings(\"checkstyle:parameternumber\")\n  public void init(AMDefinition amDef, ResourceManager rm, SLSRunner slsRunner,\n      boolean tracked, long baselineTimeMS, long heartbeatInterval,\n      Map<ApplicationId, AMSimulator> appIdToAMSim) {\n    super.init(amDef, rm, slsRunner, tracked, baselineTimeMS,\n        heartbeatInterval, appIdToAMSim);\n    amtype = \"mapreduce\";\n\n    // get map/reduce tasks\n    for (ContainerSimulator cs : amDef.getTaskContainers()) {\n      if (cs.getType().equals(\"map\")) {\n        cs.setPriority(PRIORITY_MAP);\n        allMaps.add(cs);\n      } else if (cs.getType().equals(\"reduce\")) {\n        cs.setPriority(PRIORITY_REDUCE);\n        allReduces.add(cs);\n      }\n    }\n\n    LOG.info(\"Added new job with {} mapper and {} reducers\",\n        allMaps.size(), allReduces.size());\n\n    mapTotal = allMaps.size();\n    reduceTotal = allReduces.size();\n    totalContainers = mapTotal + reduceTotal;\n  }\n\n  @Override\n  public synchronized void notifyAMContainerLaunched(Container masterContainer)\n      throws Exception {\n    if (null != masterContainer) {\n      restart();\n      super.notifyAMContainerLaunched(masterContainer);\n    }\n  }\n\n  @Override\n  @SuppressWarnings(\"unchecked\")\n  protected void processResponseQueue() throws Exception {\n    while (! responseQueue.isEmpty()) {\n      AllocateResponse response = responseQueue.take();\n\n      // check completed containers\n      if (! response.getCompletedContainersStatuses().isEmpty()) {\n        for (ContainerStatus cs : response.getCompletedContainersStatuses()) {\n          ContainerId containerId = cs.getContainerId();\n          if (cs.getExitStatus() == ContainerExitStatus.SUCCESS) {\n            if (assignedMaps.containsKey(containerId)) {\n              LOG.debug(\"Application {} has one mapper finished ({}).\",\n                  appId, containerId);\n              assignedMaps.remove(containerId);\n              mapFinished ++;\n              finishedContainers ++;\n            } else if (assignedReduces.containsKey(containerId)) {\n              LOG.debug(\"Application {} has one reducer finished ({}).\",\n                  appId, containerId);\n              assignedReduces.remove(containerId);\n              reduceFinished ++;\n              finishedContainers ++;\n            } else if (amContainer.getId().equals(containerId)){\n              // am container released event\n              isFinished = true;\n              LOG.info(\"Application {} goes to finish.\", appId);\n            }\n\n            if (mapFinished >= mapTotal && reduceFinished >= reduceTotal) {\n              lastStep();\n            }\n          } else {\n            // container to be killed\n            if (assignedMaps.containsKey(containerId)) {\n              LOG.debug(\"Application {} has one mapper killed ({}).\",\n                  appId, containerId);\n              pendingFailedMaps.add(assignedMaps.remove(containerId));\n            } else if (assignedReduces.containsKey(containerId)) {\n              LOG.debug(\"Application {} has one reducer killed ({}).\",\n                  appId, containerId);\n              pendingFailedReduces.add(assignedReduces.remove(containerId));\n            } else if (amContainer.getId().equals(containerId)){\n              LOG.info(\"Application {}'s AM is \" +\n                  \"going to be killed. Waiting for rescheduling...\", appId);\n            }\n          }\n        }\n      }\n\n      // check finished\n      if (isAMContainerRunning &&\n              (mapFinished >= mapTotal) &&\n              (reduceFinished >= reduceTotal)) {\n        isAMContainerRunning = false;\n        LOG.debug(\"Application {} sends out event to clean up\"\n            + \" its AM container.\", appId);\n        isFinished = true;\n        break;\n      }\n\n      // check allocated containers\n      for (Container container : response.getAllocatedContainers()) {\n        if (! scheduledMaps.isEmpty()) {\n          ContainerSimulator cs = scheduledMaps.remove();\n          LOG.debug(\"Application {} starts to launch a mapper ({}).\",\n              appId, container.getId());\n          assignedMaps.put(container.getId(), cs);\n          se.getNmMap().get(container.getNodeId())\n              .addNewContainer(container, cs.getLifeTime(), appId);\n          getRanNodes().add(container.getNodeId());\n        } else if (! this.scheduledReduces.isEmpty()) {\n          ContainerSimulator cs = scheduledReduces.remove();\n          LOG.debug(\"Application {} starts to launch a reducer ({}).\",\n              appId, container.getId());\n          assignedReduces.put(container.getId(), cs);\n          se.getNmMap().get(container.getNodeId())\n              .addNewContainer(container, cs.getLifeTime(), appId);\n          getRanNodes().add(container.getNodeId());\n        }\n      }\n    }\n  }\n\n  /**\n   * restart running because of the am container killed\n   */\n  private void restart()\n          throws YarnException, IOException, InterruptedException {\n    // clear\n    isFinished = false;\n    pendingFailedMaps.clear();\n    pendingMaps.clear();\n    pendingReduces.clear();\n    pendingFailedReduces.clear();\n\n    // Only add totalMaps - finishedMaps\n    int added = 0;\n    for (ContainerSimulator cs : allMaps) {\n      if (added >= mapTotal - mapFinished) {\n        break;\n      }\n      pendingMaps.add(cs);\n    }\n\n    // And same, only add totalReduces - finishedReduces\n    added = 0;\n    for (ContainerSimulator cs : allReduces) {\n      if (added >= reduceTotal - reduceFinished) {\n        break;\n      }\n      pendingReduces.add(cs);\n    }\n    amContainer = null;\n  }\n\n  private List<ContainerSimulator> mergeLists(List<ContainerSimulator> left, List<ContainerSimulator> right) {\n    List<ContainerSimulator> list = new ArrayList<>();\n    list.addAll(left);\n    list.addAll(right);\n    return list;\n  }\n\n  @Override\n  protected void sendContainerRequest()\n          throws YarnException, IOException, InterruptedException {\n    if (isFinished) {\n      return;\n    }\n\n    // send out request\n    List<ResourceRequest> ask = null;\n    if (mapFinished != mapTotal) {\n      // map phase\n      if (!pendingMaps.isEmpty()) {\n        ask = packageRequests(mergeLists(pendingMaps, scheduledMaps),\n            PRIORITY_MAP);\n        LOG.debug(\"Application {} sends out request for {} mappers.\",\n            appId, pendingMaps.size());\n        scheduledMaps.addAll(pendingMaps);\n        pendingMaps.clear();\n      } else if (!pendingFailedMaps.isEmpty()) {\n        ask = packageRequests(mergeLists(pendingFailedMaps, scheduledMaps),\n            PRIORITY_MAP);\n        LOG.debug(\"Application {} sends out requests for {} failed mappers.\",\n            appId, pendingFailedMaps.size());\n        scheduledMaps.addAll(pendingFailedMaps);\n        pendingFailedMaps.clear();\n      }\n    } else if (reduceFinished != reduceTotal) {\n      // reduce phase\n      if (!pendingReduces.isEmpty()) {\n        ask = packageRequests(mergeLists(pendingReduces, scheduledReduces),\n            PRIORITY_REDUCE);\n        LOG.debug(\"Application {} sends out requests for {} reducers.\",\n                appId, pendingReduces.size());\n        scheduledReduces.addAll(pendingReduces);\n        pendingReduces.clear();\n      } else if (!pendingFailedReduces.isEmpty()) {\n        ask = packageRequests(mergeLists(pendingFailedReduces, scheduledReduces),\n            PRIORITY_REDUCE);\n        LOG.debug(\"Application {} sends out request for {} failed reducers.\",\n            appId, pendingFailedReduces.size());\n        scheduledReduces.addAll(pendingFailedReduces);\n        pendingFailedReduces.clear();\n      }\n    }\n\n    if (ask == null) {\n      ask = new ArrayList<>();\n    }\n\n    final AllocateRequest request = createAllocateRequest(ask);\n    if (totalContainers == 0) {\n      request.setProgress(1.0f);\n    } else {\n      request.setProgress((float) finishedContainers / totalContainers);\n    }\n\n    UserGroupInformation ugi =\n            UserGroupInformation.createRemoteUser(appAttemptId.toString());\n    Token<AMRMTokenIdentifier> token = rm.getRMContext().getRMApps()\n            .get(appAttemptId.getApplicationId())\n            .getRMAppAttempt(appAttemptId).getAMRMToken();\n    ugi.addTokenIdentifier(token.decodeIdentifier());\n    AllocateResponse response = ugi.doAs(\n            new PrivilegedExceptionAction<AllocateResponse>() {\n      @Override\n      public AllocateResponse run() throws Exception {\n        return rm.getApplicationMasterService().allocate(request);\n      }\n    });\n    if (response != null) {\n      responseQueue.put(response);\n    }\n  }\n\n  @Override\n  public void initReservation(ReservationId reservationId, long deadline,\n      long now) {\n\n    Resource mapRes = getMaxResource(allMaps);\n    long mapDur = getMaxDuration(allMaps);\n    Resource redRes = getMaxResource(allReduces);\n    long redDur = getMaxDuration(allReduces);\n\n    ReservationSubmissionRequest rr = ReservationClientUtil.\n        createMRReservation(reservationId,\n            \"reservation_\" + reservationId.getId(), mapRes, allMaps.size(),\n            mapDur, redRes, allReduces.size(), redDur, now + traceStartTimeMS,\n            now + deadline, queue);\n\n    setReservationRequest(rr);\n  }\n\n  // Helper to compute the component-wise maximum resource used by any container\n  private Resource getMaxResource(Collection<ContainerSimulator> containers) {\n    return containers.parallelStream()\n        .map(ContainerSimulator::getResource)\n        .reduce(Resource.newInstance(0, 0), Resources::componentwiseMax);\n  }\n\n  // Helper to compute the maximum resource used by any map container\n  private long getMaxDuration(Collection<ContainerSimulator> containers) {\n    return containers.parallelStream()\n        .mapToLong(ContainerSimulator::getLifeTime)\n        .reduce(0L, Long::max);\n  }\n\n  @Override\n  protected void checkStop() {\n    if (isFinished) {\n      super.setEndTime(System.currentTimeMillis());\n    }\n  }\n\n  @Override\n  public void lastStep() throws Exception {\n    super.lastStep();\n\n    // clear data structures\n    allMaps.clear();\n    allReduces.clear();\n    assignedMaps.clear();\n    assignedReduces.clear();\n    pendingFailedMaps.clear();\n    pendingFailedReduces.clear();\n    pendingMaps.clear();\n    pendingReduces.clear();\n    scheduledMaps.clear();\n    scheduledReduces.clear();\n    responseQueue.clear();\n  }\n}",
    "repo": "apache/hadoop",
    "path": "./datasets/diagrams-repos/apache/hadoop/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/appmaster/MRAMSimulator.java",
    "query": "Can you show the flow of map tasks from pending to completed in the MRAMSimulator, including how failures are handled?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'MRAMSimulator', 'node_id': 'MRAMSimulator', 'description': 'MapReduce Application Master Simulator', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'pendingMaps', 'node_id': 'pendingMaps', 'description': 'Queue of map tasks waiting to be scheduled', 'visibility': 'private', 'return_type': 'LinkedList<ContainerSimulator>', 'params': None, 'source_class_id': 'MRAMSimulator'}, {'type': 'field', 'name': 'scheduledMaps', 'node_id': 'scheduledMaps', 'description': 'Queue of map tasks sent to ResourceManager', 'visibility': 'private', 'return_type': 'LinkedList<ContainerSimulator>', 'params': None, 'source_class_id': 'MRAMSimulator'}, {'type': 'field', 'name': 'assignedMaps', 'node_id': 'assignedMaps', 'description': 'Map tasks assigned to containers', 'visibility': 'private', 'return_type': 'Map<ContainerId, ContainerSimulator>', 'params': None, 'source_class_id': 'MRAMSimulator'}, {'type': 'field', 'name': 'pendingFailedMaps', 'node_id': 'pendingFailedMaps', 'description': 'Queue of failed map tasks waiting to be rescheduled', 'visibility': 'private', 'return_type': 'LinkedList<ContainerSimulator>', 'params': None, 'source_class_id': 'MRAMSimulator'}, {'type': 'field', 'name': 'mapFinished', 'node_id': 'mapFinished', 'description': 'Counter of completed map tasks', 'visibility': 'private', 'return_type': 'int', 'params': None, 'source_class_id': 'MRAMSimulator'}, {'type': 'method', 'name': 'sendContainerRequest', 'node_id': 'sendContainerRequest', 'description': 'Sends resource requests for pending maps', 'visibility': 'protected', 'return_type': 'void', 'params': '', 'source_class_id': 'MRAMSimulator'}, {'type': 'method', 'name': 'processResponseQueue', 'node_id': 'processResponseQueue', 'description': 'Processes container allocations and completions', 'visibility': 'protected', 'return_type': 'void', 'params': '', 'source_class_id': 'MRAMSimulator'}], 'edges': [{'node_id_from': 'pendingMaps', 'node_id_to': 'scheduledMaps', 'description': 'Send request to RM'}, {'node_id_from': 'scheduledMaps', 'node_id_to': 'assignedMaps', 'description': 'Allocated container'}, {'node_id_from': 'assignedMaps', 'node_id_to': 'pendingFailedMaps', 'description': 'Container failed'}, {'node_id_from': 'pendingFailedMaps', 'node_id_to': 'scheduledMaps', 'description': 'Reschedule failed tasks'}, {'node_id_from': 'sendContainerRequest', 'node_id_to': 'scheduledMaps', 'description': 'Sends requests'}, {'node_id_from': 'processResponseQueue', 'node_id_to': 'assignedMaps', 'description': 'Updates assignments'}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'pendingMaps', 'description': ''}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'mapFinished', 'description': ''}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'sendContainerRequest', 'description': ''}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'processResponseQueue', 'description': ''}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'scheduledMaps', 'description': ''}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'assignedMaps', 'description': ''}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'pendingFailedMaps', 'description': ''}], 'packages': [{'package_id': 'mapTaskStates', 'children': ['pendingMaps', 'scheduledMaps', 'assignedMaps', 'pendingFailedMaps', 'mapFinished'], 'description': 'States of map tasks in MRAppMaster'}, {'package_id': 'taskManagement', 'children': ['sendContainerRequest', 'processResponseQueue'], 'description': 'Methods for managing task lifecycle'}]}",
    "version": "medium",
    "text_answer": "Map tasks flow through four main states: pendingMaps (initial) -> scheduledMaps (requested from RM) -> assignedMaps (running in containers) -> completed. Failed tasks move to pendingFailedMaps and are rescheduled back through scheduledMaps for retry.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.apache.hadoop.yarn.sls.appmaster;\n\nimport java.io.IOException;\nimport java.security.PrivilegedExceptionAction;\nimport java.util.ArrayList;\nimport java.util.Collection;\nimport java.util.HashMap;\nimport java.util.LinkedList;\nimport java.util.List;\nimport java.util.Map;\n\nimport org.apache.hadoop.classification.InterfaceAudience.Private;\nimport org.apache.hadoop.classification.InterfaceStability.Unstable;\nimport org.apache.hadoop.security.UserGroupInformation;\nimport org.apache.hadoop.security.token.Token;\nimport org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest;\nimport org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse;\nimport org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest;\nimport org.apache.hadoop.yarn.api.records.ApplicationId;\nimport org.apache.hadoop.yarn.api.records.Container;\nimport org.apache.hadoop.yarn.api.records.ReservationId;\nimport org.apache.hadoop.yarn.api.records.Resource;\nimport org.apache.hadoop.yarn.api.records.ContainerExitStatus;\nimport org.apache.hadoop.yarn.api.records.ContainerId;\nimport org.apache.hadoop.yarn.api.records.ContainerStatus;\nimport org.apache.hadoop.yarn.api.records.ResourceRequest;\nimport org.apache.hadoop.yarn.exceptions.YarnException;\nimport org.apache.hadoop.yarn.security.AMRMTokenIdentifier;\nimport org.apache.hadoop.yarn.server.resourcemanager.ResourceManager;\nimport org.apache.hadoop.yarn.sls.AMDefinition;\nimport org.apache.hadoop.yarn.sls.ReservationClientUtil;\nimport org.apache.hadoop.yarn.sls.scheduler.ContainerSimulator;\nimport org.apache.hadoop.yarn.sls.SLSRunner;\nimport org.apache.hadoop.yarn.util.resource.Resources;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\n@Private\n@Unstable\npublic class MRAMSimulator extends AMSimulator {\n  /*\n  Vocabulary Used:\n  pending -> requests which are NOT yet sent to RM\n  scheduled -> requests which are sent to RM but not yet assigned\n  assigned -> requests which are assigned to a container\n  completed -> request corresponding to which container has completed\n\n  Maps are scheduled as soon as their requests are received. Reduces are\n  scheduled when all maps have finished (not support slow-start currently).\n  */\n\n  public static final String MAP_TYPE = \"map\";\n  public static final String REDUCE_TYPE = \"reduce\";\n\n  private static final int PRIORITY_REDUCE = 10;\n  private static final int PRIORITY_MAP = 20;\n\n  // pending maps\n  private LinkedList<ContainerSimulator> pendingMaps =\n          new LinkedList<>();\n\n  // pending failed maps\n  private LinkedList<ContainerSimulator> pendingFailedMaps =\n          new LinkedList<ContainerSimulator>();\n\n  // scheduled maps\n  private LinkedList<ContainerSimulator> scheduledMaps =\n          new LinkedList<ContainerSimulator>();\n\n  // assigned maps\n  private Map<ContainerId, ContainerSimulator> assignedMaps =\n          new HashMap<ContainerId, ContainerSimulator>();\n\n  // reduces which are not yet scheduled\n  private LinkedList<ContainerSimulator> pendingReduces =\n          new LinkedList<ContainerSimulator>();\n\n  // pending failed reduces\n  private LinkedList<ContainerSimulator> pendingFailedReduces =\n          new LinkedList<ContainerSimulator>();\n\n  // scheduled reduces\n  private LinkedList<ContainerSimulator> scheduledReduces =\n          new LinkedList<ContainerSimulator>();\n\n  // assigned reduces\n  private Map<ContainerId, ContainerSimulator> assignedReduces =\n          new HashMap<ContainerId, ContainerSimulator>();\n\n  // all maps & reduces\n  private LinkedList<ContainerSimulator> allMaps =\n          new LinkedList<ContainerSimulator>();\n  private LinkedList<ContainerSimulator> allReduces =\n          new LinkedList<ContainerSimulator>();\n\n  // counters\n  private int mapFinished = 0;\n  private int mapTotal = 0;\n  private int reduceFinished = 0;\n  private int reduceTotal = 0;\n\n  // finished\n  private boolean isFinished = false;\n\n  private static final Logger LOG =\n      LoggerFactory.getLogger(MRAMSimulator.class);\n\n  @SuppressWarnings(\"checkstyle:parameternumber\")\n  public void init(AMDefinition amDef, ResourceManager rm, SLSRunner slsRunner,\n      boolean tracked, long baselineTimeMS, long heartbeatInterval,\n      Map<ApplicationId, AMSimulator> appIdToAMSim) {\n    super.init(amDef, rm, slsRunner, tracked, baselineTimeMS,\n        heartbeatInterval, appIdToAMSim);\n    amtype = \"mapreduce\";\n\n    // get map/reduce tasks\n    for (ContainerSimulator cs : amDef.getTaskContainers()) {\n      if (cs.getType().equals(\"map\")) {\n        cs.setPriority(PRIORITY_MAP);\n        allMaps.add(cs);\n      } else if (cs.getType().equals(\"reduce\")) {\n        cs.setPriority(PRIORITY_REDUCE);\n        allReduces.add(cs);\n      }\n    }\n\n    LOG.info(\"Added new job with {} mapper and {} reducers\",\n        allMaps.size(), allReduces.size());\n\n    mapTotal = allMaps.size();\n    reduceTotal = allReduces.size();\n    totalContainers = mapTotal + reduceTotal;\n  }\n\n  @Override\n  public synchronized void notifyAMContainerLaunched(Container masterContainer)\n      throws Exception {\n    if (null != masterContainer) {\n      restart();\n      super.notifyAMContainerLaunched(masterContainer);\n    }\n  }\n\n  @Override\n  @SuppressWarnings(\"unchecked\")\n  protected void processResponseQueue() throws Exception {\n    while (! responseQueue.isEmpty()) {\n      AllocateResponse response = responseQueue.take();\n\n      // check completed containers\n      if (! response.getCompletedContainersStatuses().isEmpty()) {\n        for (ContainerStatus cs : response.getCompletedContainersStatuses()) {\n          ContainerId containerId = cs.getContainerId();\n          if (cs.getExitStatus() == ContainerExitStatus.SUCCESS) {\n            if (assignedMaps.containsKey(containerId)) {\n              LOG.debug(\"Application {} has one mapper finished ({}).\",\n                  appId, containerId);\n              assignedMaps.remove(containerId);\n              mapFinished ++;\n              finishedContainers ++;\n            } else if (assignedReduces.containsKey(containerId)) {\n              LOG.debug(\"Application {} has one reducer finished ({}).\",\n                  appId, containerId);\n              assignedReduces.remove(containerId);\n              reduceFinished ++;\n              finishedContainers ++;\n            } else if (amContainer.getId().equals(containerId)){\n              // am container released event\n              isFinished = true;\n              LOG.info(\"Application {} goes to finish.\", appId);\n            }\n\n            if (mapFinished >= mapTotal && reduceFinished >= reduceTotal) {\n              lastStep();\n            }\n          } else {\n            // container to be killed\n            if (assignedMaps.containsKey(containerId)) {\n              LOG.debug(\"Application {} has one mapper killed ({}).\",\n                  appId, containerId);\n              pendingFailedMaps.add(assignedMaps.remove(containerId));\n            } else if (assignedReduces.containsKey(containerId)) {\n              LOG.debug(\"Application {} has one reducer killed ({}).\",\n                  appId, containerId);\n              pendingFailedReduces.add(assignedReduces.remove(containerId));\n            } else if (amContainer.getId().equals(containerId)){\n              LOG.info(\"Application {}'s AM is \" +\n                  \"going to be killed. Waiting for rescheduling...\", appId);\n            }\n          }\n        }\n      }\n\n      // check finished\n      if (isAMContainerRunning &&\n              (mapFinished >= mapTotal) &&\n              (reduceFinished >= reduceTotal)) {\n        isAMContainerRunning = false;\n        LOG.debug(\"Application {} sends out event to clean up\"\n            + \" its AM container.\", appId);\n        isFinished = true;\n        break;\n      }\n\n      // check allocated containers\n      for (Container container : response.getAllocatedContainers()) {\n        if (! scheduledMaps.isEmpty()) {\n          ContainerSimulator cs = scheduledMaps.remove();\n          LOG.debug(\"Application {} starts to launch a mapper ({}).\",\n              appId, container.getId());\n          assignedMaps.put(container.getId(), cs);\n          se.getNmMap().get(container.getNodeId())\n              .addNewContainer(container, cs.getLifeTime(), appId);\n          getRanNodes().add(container.getNodeId());\n        } else if (! this.scheduledReduces.isEmpty()) {\n          ContainerSimulator cs = scheduledReduces.remove();\n          LOG.debug(\"Application {} starts to launch a reducer ({}).\",\n              appId, container.getId());\n          assignedReduces.put(container.getId(), cs);\n          se.getNmMap().get(container.getNodeId())\n              .addNewContainer(container, cs.getLifeTime(), appId);\n          getRanNodes().add(container.getNodeId());\n        }\n      }\n    }\n  }\n\n  /**\n   * restart running because of the am container killed\n   */\n  private void restart()\n          throws YarnException, IOException, InterruptedException {\n    // clear\n    isFinished = false;\n    pendingFailedMaps.clear();\n    pendingMaps.clear();\n    pendingReduces.clear();\n    pendingFailedReduces.clear();\n\n    // Only add totalMaps - finishedMaps\n    int added = 0;\n    for (ContainerSimulator cs : allMaps) {\n      if (added >= mapTotal - mapFinished) {\n        break;\n      }\n      pendingMaps.add(cs);\n    }\n\n    // And same, only add totalReduces - finishedReduces\n    added = 0;\n    for (ContainerSimulator cs : allReduces) {\n      if (added >= reduceTotal - reduceFinished) {\n        break;\n      }\n      pendingReduces.add(cs);\n    }\n    amContainer = null;\n  }\n\n  private List<ContainerSimulator> mergeLists(List<ContainerSimulator> left, List<ContainerSimulator> right) {\n    List<ContainerSimulator> list = new ArrayList<>();\n    list.addAll(left);\n    list.addAll(right);\n    return list;\n  }\n\n  @Override\n  protected void sendContainerRequest()\n          throws YarnException, IOException, InterruptedException {\n    if (isFinished) {\n      return;\n    }\n\n    // send out request\n    List<ResourceRequest> ask = null;\n    if (mapFinished != mapTotal) {\n      // map phase\n      if (!pendingMaps.isEmpty()) {\n        ask = packageRequests(mergeLists(pendingMaps, scheduledMaps),\n            PRIORITY_MAP);\n        LOG.debug(\"Application {} sends out request for {} mappers.\",\n            appId, pendingMaps.size());\n        scheduledMaps.addAll(pendingMaps);\n        pendingMaps.clear();\n      } else if (!pendingFailedMaps.isEmpty()) {\n        ask = packageRequests(mergeLists(pendingFailedMaps, scheduledMaps),\n            PRIORITY_MAP);\n        LOG.debug(\"Application {} sends out requests for {} failed mappers.\",\n            appId, pendingFailedMaps.size());\n        scheduledMaps.addAll(pendingFailedMaps);\n        pendingFailedMaps.clear();\n      }\n    } else if (reduceFinished != reduceTotal) {\n      // reduce phase\n      if (!pendingReduces.isEmpty()) {\n        ask = packageRequests(mergeLists(pendingReduces, scheduledReduces),\n            PRIORITY_REDUCE);\n        LOG.debug(\"Application {} sends out requests for {} reducers.\",\n                appId, pendingReduces.size());\n        scheduledReduces.addAll(pendingReduces);\n        pendingReduces.clear();\n      } else if (!pendingFailedReduces.isEmpty()) {\n        ask = packageRequests(mergeLists(pendingFailedReduces, scheduledReduces),\n            PRIORITY_REDUCE);\n        LOG.debug(\"Application {} sends out request for {} failed reducers.\",\n            appId, pendingFailedReduces.size());\n        scheduledReduces.addAll(pendingFailedReduces);\n        pendingFailedReduces.clear();\n      }\n    }\n\n    if (ask == null) {\n      ask = new ArrayList<>();\n    }\n\n    final AllocateRequest request = createAllocateRequest(ask);\n    if (totalContainers == 0) {\n      request.setProgress(1.0f);\n    } else {\n      request.setProgress((float) finishedContainers / totalContainers);\n    }\n\n    UserGroupInformation ugi =\n            UserGroupInformation.createRemoteUser(appAttemptId.toString());\n    Token<AMRMTokenIdentifier> token = rm.getRMContext().getRMApps()\n            .get(appAttemptId.getApplicationId())\n            .getRMAppAttempt(appAttemptId).getAMRMToken();\n    ugi.addTokenIdentifier(token.decodeIdentifier());\n    AllocateResponse response = ugi.doAs(\n            new PrivilegedExceptionAction<AllocateResponse>() {\n      @Override\n      public AllocateResponse run() throws Exception {\n        return rm.getApplicationMasterService().allocate(request);\n      }\n    });\n    if (response != null) {\n      responseQueue.put(response);\n    }\n  }\n\n  @Override\n  public void initReservation(ReservationId reservationId, long deadline,\n      long now) {\n\n    Resource mapRes = getMaxResource(allMaps);\n    long mapDur = getMaxDuration(allMaps);\n    Resource redRes = getMaxResource(allReduces);\n    long redDur = getMaxDuration(allReduces);\n\n    ReservationSubmissionRequest rr = ReservationClientUtil.\n        createMRReservation(reservationId,\n            \"reservation_\" + reservationId.getId(), mapRes, allMaps.size(),\n            mapDur, redRes, allReduces.size(), redDur, now + traceStartTimeMS,\n            now + deadline, queue);\n\n    setReservationRequest(rr);\n  }\n\n  // Helper to compute the component-wise maximum resource used by any container\n  private Resource getMaxResource(Collection<ContainerSimulator> containers) {\n    return containers.parallelStream()\n        .map(ContainerSimulator::getResource)\n        .reduce(Resource.newInstance(0, 0), Resources::componentwiseMax);\n  }\n\n  // Helper to compute the maximum resource used by any map container\n  private long getMaxDuration(Collection<ContainerSimulator> containers) {\n    return containers.parallelStream()\n        .mapToLong(ContainerSimulator::getLifeTime)\n        .reduce(0L, Long::max);\n  }\n\n  @Override\n  protected void checkStop() {\n    if (isFinished) {\n      super.setEndTime(System.currentTimeMillis());\n    }\n  }\n\n  @Override\n  public void lastStep() throws Exception {\n    super.lastStep();\n\n    // clear data structures\n    allMaps.clear();\n    allReduces.clear();\n    assignedMaps.clear();\n    assignedReduces.clear();\n    pendingFailedMaps.clear();\n    pendingFailedReduces.clear();\n    pendingMaps.clear();\n    pendingReduces.clear();\n    scheduledMaps.clear();\n    scheduledReduces.clear();\n    responseQueue.clear();\n  }\n}",
    "repo": "apache/hadoop",
    "path": "./datasets/diagrams-repos/apache/hadoop/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/appmaster/MRAMSimulator.java",
    "query": "Can you show the flow of map tasks from pending to completed in the MRAMSimulator, including how failures are handled?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'MRAMSimulator', 'node_id': 'MRAMSimulator', 'description': 'MapReduce Application Master Simulator', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'pendingMaps', 'node_id': 'pendingMaps', 'description': 'Queue of map tasks waiting to be scheduled', 'visibility': 'private', 'return_type': 'LinkedList<ContainerSimulator>', 'params': None, 'source_class_id': 'MRAMSimulator'}, {'type': 'field', 'name': 'scheduledMaps', 'node_id': 'scheduledMaps', 'description': 'Queue of map tasks sent to ResourceManager', 'visibility': 'private', 'return_type': 'LinkedList<ContainerSimulator>', 'params': None, 'source_class_id': 'MRAMSimulator'}, {'type': 'field', 'name': 'assignedMaps', 'node_id': 'assignedMaps', 'description': 'Map tasks assigned to containers', 'visibility': 'private', 'return_type': 'Map<ContainerId, ContainerSimulator>', 'params': None, 'source_class_id': 'MRAMSimulator'}, {'type': 'field', 'name': 'pendingFailedMaps', 'node_id': 'pendingFailedMaps', 'description': 'Queue of failed map tasks waiting to be rescheduled', 'visibility': 'private', 'return_type': 'LinkedList<ContainerSimulator>', 'params': None, 'source_class_id': 'MRAMSimulator'}, {'type': 'field', 'name': 'mapFinished', 'node_id': 'mapFinished', 'description': 'Counter of completed map tasks', 'visibility': 'private', 'return_type': 'int', 'params': None, 'source_class_id': 'MRAMSimulator'}, {'type': 'field', 'name': 'mapTotal', 'node_id': 'mapTotal', 'description': 'Total number of map tasks', 'visibility': 'private', 'return_type': 'int', 'params': None, 'source_class_id': 'MRAMSimulator'}, {'type': 'method', 'name': 'init', 'node_id': 'init', 'description': 'Initializes the simulator with map tasks', 'visibility': 'public', 'return_type': 'void', 'params': 'AMDefinition, ResourceManager, SLSRunner, boolean, long, long, Map', 'source_class_id': 'MRAMSimulator'}, {'type': 'method', 'name': 'sendContainerRequest', 'node_id': 'sendContainerRequest', 'description': 'Sends resource requests for pending maps', 'visibility': 'protected', 'return_type': 'void', 'params': '', 'source_class_id': 'MRAMSimulator'}, {'type': 'method', 'name': 'processResponseQueue', 'node_id': 'processResponseQueue', 'description': 'Processes container allocations and completions', 'visibility': 'protected', 'return_type': 'void', 'params': '', 'source_class_id': 'MRAMSimulator'}, {'type': 'method', 'name': 'restart', 'node_id': 'restart', 'description': 'Restarts processing after AM container failure', 'visibility': 'private', 'return_type': 'void', 'params': '', 'source_class_id': 'MRAMSimulator'}, {'type': 'method', 'name': 'lastStep', 'node_id': 'lastStep', 'description': 'Cleans up data structures at completion', 'visibility': 'public', 'return_type': 'void', 'params': '', 'source_class_id': 'MRAMSimulator'}], 'edges': [{'node_id_from': 'pendingMaps', 'node_id_to': 'scheduledMaps', 'description': 'Send request to RM'}, {'node_id_from': 'scheduledMaps', 'node_id_to': 'assignedMaps', 'description': 'Allocated container'}, {'node_id_from': 'assignedMaps', 'node_id_to': 'pendingFailedMaps', 'description': 'Container failed'}, {'node_id_from': 'pendingFailedMaps', 'node_id_to': 'scheduledMaps', 'description': 'Reschedule failed tasks'}, {'node_id_from': 'init', 'node_id_to': 'pendingMaps', 'description': 'Initialize maps'}, {'node_id_from': 'sendContainerRequest', 'node_id_to': 'scheduledMaps', 'description': 'Sends requests'}, {'node_id_from': 'processResponseQueue', 'node_id_to': 'assignedMaps', 'description': 'Updates assignments'}, {'node_id_from': 'restart', 'node_id_to': 'pendingMaps', 'description': 'Resets maps'}, {'node_id_from': 'assignedMaps', 'node_id_to': 'mapFinished', 'description': 'Increment on completion'}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'mapTotal', 'description': ''}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'init', 'description': ''}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'sendContainerRequest', 'description': ''}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'processResponseQueue', 'description': ''}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'restart', 'description': ''}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'lastStep', 'description': ''}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'pendingMaps', 'description': ''}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'scheduledMaps', 'description': ''}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'assignedMaps', 'description': ''}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'pendingFailedMaps', 'description': ''}, {'node_id_from': 'MRAMSimulator', 'node_id_to': 'mapFinished', 'description': ''}], 'packages': [{'package_id': 'mapTaskStates', 'children': ['pendingMaps', 'scheduledMaps', 'assignedMaps', 'pendingFailedMaps'], 'description': 'States of map tasks in MRAppMaster'}, {'package_id': 'taskManagement', 'children': ['sendContainerRequest', 'processResponseQueue', 'restart', 'lastStep'], 'description': 'Methods for managing task lifecycle'}, {'package_id': 'metrics', 'children': ['mapFinished', 'mapTotal'], 'description': 'Counters and metrics for map tasks'}]}",
    "version": "full",
    "text_answer": "Map tasks flow through four main states: pendingMaps (initial) -> scheduledMaps (requested from RM) -> assignedMaps (running in containers) -> completed. Failed tasks move to pendingFailedMaps and are rescheduled back through scheduledMaps for retry.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include \"editor_run_native.h\"\n\n#include \"editor/editor_node.h\"\n#include \"editor/editor_settings.h\"\n#include \"editor/export/editor_export.h\"\n#include \"editor/export/editor_export_platform.h\"\n#include \"editor/themes/editor_scale.h\"\n\nvoid EditorRunNative::_notification(int p_what) {\n\tswitch (p_what) {\n\t\tcase NOTIFICATION_THEME_CHANGED: {\n\t\t\tremote_debug->set_button_icon(get_editor_theme_icon(SNAME(\"PlayRemote\")));\n\t\t} break;\n\n\t\tcase NOTIFICATION_PROCESS: {\n\t\t\tbool changed = EditorExport::get_singleton()->poll_export_platforms() || first;\n\n\t\t\tif (changed) {\n\t\t\t\tPopupMenu *popup = remote_debug->get_popup();\n\t\t\t\tpopup->clear();\n\t\t\t\tint device_shortcut_id = 1;\n\t\t\t\tfor (int i = 0; i < EditorExport::get_singleton()->get_export_preset_count(); i++) {\n\t\t\t\t\tRef<EditorExportPreset> preset = EditorExport::get_singleton()->get_export_preset(i);\n\t\t\t\t\tRef<EditorExportPlatform> eep = preset->get_platform();\n\t\t\t\t\tif (eep.is_null()) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tint platform_idx = -1;\n\t\t\t\t\tfor (int j = 0; j < EditorExport::get_singleton()->get_export_platform_count(); j++) {\n\t\t\t\t\t\tif (eep->get_name() == EditorExport::get_singleton()->get_export_platform(j)->get_name()) {\n\t\t\t\t\t\t\tplatform_idx = j;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tint dc = MIN(eep->get_options_count(), 9000);\n\t\t\t\t\tString error;\n\t\t\t\t\tif (dc > 0 && preset->is_runnable()) {\n\t\t\t\t\t\tpopup->add_icon_item(eep->get_run_icon(), eep->get_name(), -1);\n\t\t\t\t\t\tpopup->set_item_disabled(-1, true);\n\t\t\t\t\t\tfor (int j = 0; j < dc; j++) {\n\t\t\t\t\t\t\tpopup->add_icon_item(eep->get_option_icon(j), eep->get_option_label(j), 10000 * platform_idx + j);\n\t\t\t\t\t\t\tpopup->set_item_tooltip(-1, eep->get_option_tooltip(j));\n\t\t\t\t\t\t\tpopup->set_item_indent(-1, 2);\n\t\t\t\t\t\t\tif (device_shortcut_id <= 4) {\n\t\t\t\t\t\t\t\t// Assign shortcuts for the first 4 devices added in the list.\n\t\t\t\t\t\t\t\tpopup->set_item_shortcut(-1, ED_GET_SHORTCUT(vformat(\"remote_deploy/deploy_to_device_%d\", device_shortcut_id)), true);\n\t\t\t\t\t\t\t\tdevice_shortcut_id += 1;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (popup->get_item_count() == 0) {\n\t\t\t\t\tremote_debug->set_disabled(true);\n\t\t\t\t\tremote_debug->set_tooltip_text(TTR(\"No Remote Deploy export presets configured.\"));\n\t\t\t\t} else {\n\t\t\t\t\tremote_debug->set_disabled(false);\n\t\t\t\t\tremote_debug->set_tooltip_text(TTR(\"Remote Deploy\"));\n\t\t\t\t}\n\n\t\t\t\tfirst = false;\n\t\t\t}\n\t\t} break;\n\t}\n}\n\nvoid EditorRunNative::_confirm_run_native() {\n\trun_confirmed = true;\n\tresume_run_native();\n}\n\nError EditorRunNative::start_run_native(int p_id) {\n\tif (p_id < 0) {\n\t\treturn OK;\n\t}\n\n\tint platform = p_id / 10000;\n\tint idx = p_id % 10000;\n\tresume_id = p_id;\n\n\tif (!EditorNode::get_singleton()->ensure_main_scene(true)) {\n\t\treturn OK;\n\t}\n\n\tRef<EditorExportPlatform> eep = EditorExport::get_singleton()->get_export_platform(platform);\n\tERR_FAIL_COND_V(eep.is_null(), ERR_UNAVAILABLE);\n\n\tRef<EditorExportPreset> preset;\n\n\tfor (int i = 0; i < EditorExport::get_singleton()->get_export_preset_count(); i++) {\n\t\tRef<EditorExportPreset> ep = EditorExport::get_singleton()->get_export_preset(i);\n\t\tif (ep->is_runnable() && ep->get_platform() == eep) {\n\t\t\tpreset = ep;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (preset.is_null()) {\n\t\tEditorNode::get_singleton()->show_warning(TTR(\"No runnable export preset found for this platform.\\nPlease add a runnable preset in the Export menu or define an existing preset as runnable.\"));\n\t\treturn ERR_UNAVAILABLE;\n\t}\n\n\tString architecture = eep->get_device_architecture(idx);\n\tif (!run_confirmed && !architecture.is_empty()) {\n\t\tString preset_arch = \"architectures/\" + architecture;\n\t\tbool is_arch_enabled = preset->get(preset_arch);\n\n\t\tif (!is_arch_enabled) {\n\t\t\tString warning_message = vformat(TTR(\"Warning: The CPU architecture \\\"%s\\\" is not active in your export preset.\\n\\n\"), Variant(architecture));\n\t\t\twarning_message += TTR(\"Run \\\"Remote Deploy\\\" anyway?\");\n\n\t\t\trun_native_confirm->set_text(warning_message);\n\t\t\trun_native_confirm->popup_centered();\n\t\t\treturn OK;\n\t\t}\n\t}\n\trun_confirmed = false;\n\n\tpreset->update_value_overrides();\n\n\temit_signal(SNAME(\"native_run\"), preset);\n\n\tBitField<EditorExportPlatform::DebugFlags> flags = 0;\n\n\tbool deploy_debug_remote = is_deploy_debug_remote_enabled();\n\tbool deploy_dumb = EditorSettings::get_singleton()->get_project_metadata(\"debug_options\", \"run_file_server\", false);\n\tbool debug_collisions = EditorSettings::get_singleton()->get_project_metadata(\"debug_options\", \"run_debug_collisions\", false);\n\tbool debug_navigation = EditorSettings::get_singleton()->get_project_metadata(\"debug_options\", \"run_debug_navigation\", false);\n\n\tif (deploy_debug_remote) {\n\t\tflags.set_flag(EditorExportPlatform::DEBUG_FLAG_REMOTE_DEBUG);\n\t}\n\tif (deploy_dumb) {\n\t\tflags.set_flag(EditorExportPlatform::DEBUG_FLAG_DUMB_CLIENT);\n\t}\n\tif (debug_collisions) {\n\t\tflags.set_flag(EditorExportPlatform::DEBUG_FLAG_VIEW_COLLISIONS);\n\t}\n\tif (debug_navigation) {\n\t\tflags.set_flag(EditorExportPlatform::DEBUG_FLAG_VIEW_NAVIGATION);\n\t}\n\n\teep->clear_messages();\n\tError err = eep->run(preset, idx, flags);\n\tresult_dialog_log->clear();\n\tif (eep->fill_log_messages(result_dialog_log, err)) {\n\t\tif (eep->get_worst_message_type() >= EditorExportPlatform::EXPORT_MESSAGE_ERROR) {\n\t\t\tresult_dialog->popup_centered_ratio(0.5);\n\t\t}\n\t}\n\treturn err;\n}\n\nvoid EditorRunNative::resume_run_native() {\n\tstart_run_native(resume_id);\n}\n\nvoid EditorRunNative::_bind_methods() {\n\tADD_SIGNAL(MethodInfo(\"native_run\", PropertyInfo(Variant::OBJECT, \"preset\", PROPERTY_HINT_RESOURCE_TYPE, \"EditorExportPreset\")));\n}\n\nbool EditorRunNative::is_deploy_debug_remote_enabled() const {\n\treturn EditorSettings::get_singleton()->get_project_metadata(\"debug_options\", \"run_deploy_remote_debug\", true);\n}\n\nEditorRunNative::EditorRunNative() {\n\tED_SHORTCUT(\"remote_deploy/deploy_to_device_1\", TTRC(\"Deploy to First Device in List\"), KeyModifierMask::SHIFT | Key::F5);\n\tED_SHORTCUT_OVERRIDE(\"remote_deploy/deploy_to_device_1\", \"macos\", KeyModifierMask::META | KeyModifierMask::SHIFT | Key::B);\n\tED_SHORTCUT(\"remote_deploy/deploy_to_device_2\", TTRC(\"Deploy to Second Device in List\"));\n\tED_SHORTCUT(\"remote_deploy/deploy_to_device_3\", TTRC(\"Deploy to Third Device in List\"));\n\tED_SHORTCUT(\"remote_deploy/deploy_to_device_4\", TTRC(\"Deploy to Fourth Device in List\"));\n\n\tremote_debug = memnew(MenuButton);\n\tremote_debug->set_flat(false);\n\tremote_debug->set_theme_type_variation(\"RunBarButton\");\n\tremote_debug->get_popup()->connect(SceneStringName(id_pressed), callable_mp(this, &EditorRunNative::start_run_native));\n\tremote_debug->set_tooltip_text(TTR(\"Remote Deploy\"));\n\tremote_debug->set_disabled(true);\n\n\tadd_child(remote_debug);\n\n\tresult_dialog = memnew(AcceptDialog);\n\tresult_dialog->set_title(TTR(\"Project Run\"));\n\tresult_dialog_log = memnew(RichTextLabel);\n\tresult_dialog_log->set_custom_minimum_size(Size2(300, 80) * EDSCALE);\n\tresult_dialog->add_child(result_dialog_log);\n\n\tadd_child(result_dialog);\n\tresult_dialog->hide();\n\n\trun_native_confirm = memnew(ConfirmationDialog);\n\tadd_child(run_native_confirm);\n\trun_native_confirm->connect(SceneStringName(confirmed), callable_mp(this, &EditorRunNative::_confirm_run_native));\n\n\tset_process(true);\n}",
    "repo": "godotengine/godot",
    "path": "./datasets/diagrams-repos/godotengine/godot/editor/editor_run_native.cpp",
    "query": "Can you represent the error handling flow in the start_run_native method?",
    "diagram": "{'nodes': [{'type': 'method', 'name': 'start_run_native', 'node_id': 'start_run_native', 'description': 'Main method for starting native run with error handling', 'visibility': 'public', 'return_type': 'Error', 'params': 'int p_id', 'source_class_id': 'EditorRunNative'}, {'type': 'function', 'name': 'ensure_main_scene', 'node_id': 'ensure_main_scene', 'description': 'Checks if main scene is ready', 'visibility': 'public', 'return_type': 'bool', 'params': 'bool p_force', 'source_class_id': None}, {'type': 'entity', 'name': 'errorCheck', 'node_id': 'errorCheck', 'description': 'Error validation point', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'show_warning', 'node_id': 'show_warning', 'description': 'Shows warning message to user', 'visibility': 'public', 'return_type': None, 'params': 'String message', 'source_class_id': 'EditorNode'}, {'type': 'class', 'name': 'EditorRunNative', 'node_id': 'EditorRunNative', 'description': 'Manages remote deployment of Godot projects to devices, handling export presets, platform detection, and debug options through a menu interface', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'EditorNode', 'node_id': 'EditorNode', 'description': 'Core editor singleton that manages editor functionality', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'start_run_native', 'node_id_to': 'ensure_main_scene', 'description': 'Check scene'}, {'node_id_from': 'ensure_main_scene', 'node_id_to': 'errorCheck', 'description': 'Validate'}, {'node_id_from': 'errorCheck', 'node_id_to': 'EditorNode', 'description': ''}, {'node_id_from': 'EditorNode', 'node_id_to': 'show_warning', 'description': 'Show error'}, {'node_id_from': 'EditorRunNative', 'node_id_to': 'start_run_native', 'description': ''}], 'packages': [{'package_id': 'errorHandling', 'children': ['start_run_native', 'ensure_main_scene', 'errorCheck', 'show_warning', 'EditorNode'], 'description': 'Error handling flow components'}]}",
    "version": "minimal",
    "text_answer": "The start_run_native method implements a multi-step error handling flow: it first validates input parameters, checks main scene readiness, verifies export platform and preset availability, and finally handles any runtime errors by logging them and showing appropriate UI feedback through warnings or error dialogs.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include \"editor_run_native.h\"\n\n#include \"editor/editor_node.h\"\n#include \"editor/editor_settings.h\"\n#include \"editor/export/editor_export.h\"\n#include \"editor/export/editor_export_platform.h\"\n#include \"editor/themes/editor_scale.h\"\n\nvoid EditorRunNative::_notification(int p_what) {\n\tswitch (p_what) {\n\t\tcase NOTIFICATION_THEME_CHANGED: {\n\t\t\tremote_debug->set_button_icon(get_editor_theme_icon(SNAME(\"PlayRemote\")));\n\t\t} break;\n\n\t\tcase NOTIFICATION_PROCESS: {\n\t\t\tbool changed = EditorExport::get_singleton()->poll_export_platforms() || first;\n\n\t\t\tif (changed) {\n\t\t\t\tPopupMenu *popup = remote_debug->get_popup();\n\t\t\t\tpopup->clear();\n\t\t\t\tint device_shortcut_id = 1;\n\t\t\t\tfor (int i = 0; i < EditorExport::get_singleton()->get_export_preset_count(); i++) {\n\t\t\t\t\tRef<EditorExportPreset> preset = EditorExport::get_singleton()->get_export_preset(i);\n\t\t\t\t\tRef<EditorExportPlatform> eep = preset->get_platform();\n\t\t\t\t\tif (eep.is_null()) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tint platform_idx = -1;\n\t\t\t\t\tfor (int j = 0; j < EditorExport::get_singleton()->get_export_platform_count(); j++) {\n\t\t\t\t\t\tif (eep->get_name() == EditorExport::get_singleton()->get_export_platform(j)->get_name()) {\n\t\t\t\t\t\t\tplatform_idx = j;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tint dc = MIN(eep->get_options_count(), 9000);\n\t\t\t\t\tString error;\n\t\t\t\t\tif (dc > 0 && preset->is_runnable()) {\n\t\t\t\t\t\tpopup->add_icon_item(eep->get_run_icon(), eep->get_name(), -1);\n\t\t\t\t\t\tpopup->set_item_disabled(-1, true);\n\t\t\t\t\t\tfor (int j = 0; j < dc; j++) {\n\t\t\t\t\t\t\tpopup->add_icon_item(eep->get_option_icon(j), eep->get_option_label(j), 10000 * platform_idx + j);\n\t\t\t\t\t\t\tpopup->set_item_tooltip(-1, eep->get_option_tooltip(j));\n\t\t\t\t\t\t\tpopup->set_item_indent(-1, 2);\n\t\t\t\t\t\t\tif (device_shortcut_id <= 4) {\n\t\t\t\t\t\t\t\t// Assign shortcuts for the first 4 devices added in the list.\n\t\t\t\t\t\t\t\tpopup->set_item_shortcut(-1, ED_GET_SHORTCUT(vformat(\"remote_deploy/deploy_to_device_%d\", device_shortcut_id)), true);\n\t\t\t\t\t\t\t\tdevice_shortcut_id += 1;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (popup->get_item_count() == 0) {\n\t\t\t\t\tremote_debug->set_disabled(true);\n\t\t\t\t\tremote_debug->set_tooltip_text(TTR(\"No Remote Deploy export presets configured.\"));\n\t\t\t\t} else {\n\t\t\t\t\tremote_debug->set_disabled(false);\n\t\t\t\t\tremote_debug->set_tooltip_text(TTR(\"Remote Deploy\"));\n\t\t\t\t}\n\n\t\t\t\tfirst = false;\n\t\t\t}\n\t\t} break;\n\t}\n}\n\nvoid EditorRunNative::_confirm_run_native() {\n\trun_confirmed = true;\n\tresume_run_native();\n}\n\nError EditorRunNative::start_run_native(int p_id) {\n\tif (p_id < 0) {\n\t\treturn OK;\n\t}\n\n\tint platform = p_id / 10000;\n\tint idx = p_id % 10000;\n\tresume_id = p_id;\n\n\tif (!EditorNode::get_singleton()->ensure_main_scene(true)) {\n\t\treturn OK;\n\t}\n\n\tRef<EditorExportPlatform> eep = EditorExport::get_singleton()->get_export_platform(platform);\n\tERR_FAIL_COND_V(eep.is_null(), ERR_UNAVAILABLE);\n\n\tRef<EditorExportPreset> preset;\n\n\tfor (int i = 0; i < EditorExport::get_singleton()->get_export_preset_count(); i++) {\n\t\tRef<EditorExportPreset> ep = EditorExport::get_singleton()->get_export_preset(i);\n\t\tif (ep->is_runnable() && ep->get_platform() == eep) {\n\t\t\tpreset = ep;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (preset.is_null()) {\n\t\tEditorNode::get_singleton()->show_warning(TTR(\"No runnable export preset found for this platform.\\nPlease add a runnable preset in the Export menu or define an existing preset as runnable.\"));\n\t\treturn ERR_UNAVAILABLE;\n\t}\n\n\tString architecture = eep->get_device_architecture(idx);\n\tif (!run_confirmed && !architecture.is_empty()) {\n\t\tString preset_arch = \"architectures/\" + architecture;\n\t\tbool is_arch_enabled = preset->get(preset_arch);\n\n\t\tif (!is_arch_enabled) {\n\t\t\tString warning_message = vformat(TTR(\"Warning: The CPU architecture \\\"%s\\\" is not active in your export preset.\\n\\n\"), Variant(architecture));\n\t\t\twarning_message += TTR(\"Run \\\"Remote Deploy\\\" anyway?\");\n\n\t\t\trun_native_confirm->set_text(warning_message);\n\t\t\trun_native_confirm->popup_centered();\n\t\t\treturn OK;\n\t\t}\n\t}\n\trun_confirmed = false;\n\n\tpreset->update_value_overrides();\n\n\temit_signal(SNAME(\"native_run\"), preset);\n\n\tBitField<EditorExportPlatform::DebugFlags> flags = 0;\n\n\tbool deploy_debug_remote = is_deploy_debug_remote_enabled();\n\tbool deploy_dumb = EditorSettings::get_singleton()->get_project_metadata(\"debug_options\", \"run_file_server\", false);\n\tbool debug_collisions = EditorSettings::get_singleton()->get_project_metadata(\"debug_options\", \"run_debug_collisions\", false);\n\tbool debug_navigation = EditorSettings::get_singleton()->get_project_metadata(\"debug_options\", \"run_debug_navigation\", false);\n\n\tif (deploy_debug_remote) {\n\t\tflags.set_flag(EditorExportPlatform::DEBUG_FLAG_REMOTE_DEBUG);\n\t}\n\tif (deploy_dumb) {\n\t\tflags.set_flag(EditorExportPlatform::DEBUG_FLAG_DUMB_CLIENT);\n\t}\n\tif (debug_collisions) {\n\t\tflags.set_flag(EditorExportPlatform::DEBUG_FLAG_VIEW_COLLISIONS);\n\t}\n\tif (debug_navigation) {\n\t\tflags.set_flag(EditorExportPlatform::DEBUG_FLAG_VIEW_NAVIGATION);\n\t}\n\n\teep->clear_messages();\n\tError err = eep->run(preset, idx, flags);\n\tresult_dialog_log->clear();\n\tif (eep->fill_log_messages(result_dialog_log, err)) {\n\t\tif (eep->get_worst_message_type() >= EditorExportPlatform::EXPORT_MESSAGE_ERROR) {\n\t\t\tresult_dialog->popup_centered_ratio(0.5);\n\t\t}\n\t}\n\treturn err;\n}\n\nvoid EditorRunNative::resume_run_native() {\n\tstart_run_native(resume_id);\n}\n\nvoid EditorRunNative::_bind_methods() {\n\tADD_SIGNAL(MethodInfo(\"native_run\", PropertyInfo(Variant::OBJECT, \"preset\", PROPERTY_HINT_RESOURCE_TYPE, \"EditorExportPreset\")));\n}\n\nbool EditorRunNative::is_deploy_debug_remote_enabled() const {\n\treturn EditorSettings::get_singleton()->get_project_metadata(\"debug_options\", \"run_deploy_remote_debug\", true);\n}\n\nEditorRunNative::EditorRunNative() {\n\tED_SHORTCUT(\"remote_deploy/deploy_to_device_1\", TTRC(\"Deploy to First Device in List\"), KeyModifierMask::SHIFT | Key::F5);\n\tED_SHORTCUT_OVERRIDE(\"remote_deploy/deploy_to_device_1\", \"macos\", KeyModifierMask::META | KeyModifierMask::SHIFT | Key::B);\n\tED_SHORTCUT(\"remote_deploy/deploy_to_device_2\", TTRC(\"Deploy to Second Device in List\"));\n\tED_SHORTCUT(\"remote_deploy/deploy_to_device_3\", TTRC(\"Deploy to Third Device in List\"));\n\tED_SHORTCUT(\"remote_deploy/deploy_to_device_4\", TTRC(\"Deploy to Fourth Device in List\"));\n\n\tremote_debug = memnew(MenuButton);\n\tremote_debug->set_flat(false);\n\tremote_debug->set_theme_type_variation(\"RunBarButton\");\n\tremote_debug->get_popup()->connect(SceneStringName(id_pressed), callable_mp(this, &EditorRunNative::start_run_native));\n\tremote_debug->set_tooltip_text(TTR(\"Remote Deploy\"));\n\tremote_debug->set_disabled(true);\n\n\tadd_child(remote_debug);\n\n\tresult_dialog = memnew(AcceptDialog);\n\tresult_dialog->set_title(TTR(\"Project Run\"));\n\tresult_dialog_log = memnew(RichTextLabel);\n\tresult_dialog_log->set_custom_minimum_size(Size2(300, 80) * EDSCALE);\n\tresult_dialog->add_child(result_dialog_log);\n\n\tadd_child(result_dialog);\n\tresult_dialog->hide();\n\n\trun_native_confirm = memnew(ConfirmationDialog);\n\tadd_child(run_native_confirm);\n\trun_native_confirm->connect(SceneStringName(confirmed), callable_mp(this, &EditorRunNative::_confirm_run_native));\n\n\tset_process(true);\n}",
    "repo": "godotengine/godot",
    "path": "./datasets/diagrams-repos/godotengine/godot/editor/editor_run_native.cpp",
    "query": "Can you represent the error handling flow in the start_run_native method?",
    "diagram": "{'nodes': [{'type': 'method', 'name': 'start_run_native', 'node_id': 'start_run_native', 'description': 'Main method for starting native run with error handling', 'visibility': 'public', 'return_type': 'Error', 'params': 'int p_id', 'source_class_id': 'EditorRunNative'}, {'type': 'function', 'name': 'ensure_main_scene', 'node_id': 'ensure_main_scene', 'description': 'Checks if main scene is ready', 'visibility': 'public', 'return_type': 'bool', 'params': 'bool p_force', 'source_class_id': None}, {'type': 'entity', 'name': 'errorCheck', 'node_id': 'errorCheck', 'description': 'Error validation point', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'show_warning', 'node_id': 'show_warning', 'description': 'Shows warning message to user', 'visibility': 'public', 'return_type': None, 'params': 'String message', 'source_class_id': 'EditorNode'}, {'type': 'method', 'name': 'fill_log_messages', 'node_id': 'fill_log_messages', 'description': 'Fills log with error messages', 'visibility': 'public', 'return_type': 'bool', 'params': 'TextLog log, Error err', 'source_class_id': 'EditorExportPlatform'}, {'type': 'method', 'name': 'popup_centered_ratio', 'node_id': 'popup_centered_ratio', 'description': 'Shows error dialog', 'visibility': 'public', 'return_type': None, 'params': 'float ratio', 'source_class_id': 'AcceptDialog'}, {'type': 'class', 'name': 'EditorRunNative', 'node_id': 'EditorRunNative', 'description': 'Manages remote deployment of Godot projects to devices, handling export presets, platform detection, and debug options through a menu interface', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'EditorNode', 'node_id': 'EditorNode', 'description': 'Core editor singleton that manages editor functionality', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'EditorExportPlatform', 'node_id': 'EditorExportPlatform', 'description': 'Handles platform-specific export and deployment logic', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'AcceptDialog', 'node_id': 'AcceptDialog', 'description': 'Modal dialog window for displaying messages and warnings', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'start_run_native', 'node_id_to': 'ensure_main_scene', 'description': 'Check scene'}, {'node_id_from': 'ensure_main_scene', 'node_id_to': 'errorCheck', 'description': 'Validate'}, {'node_id_from': 'errorCheck', 'node_id_to': 'EditorNode', 'description': ''}, {'node_id_from': 'errorCheck', 'node_id_to': 'EditorExportPlatform', 'description': ''}, {'node_id_from': 'fill_log_messages', 'node_id_to': 'AcceptDialog', 'description': ''}, {'node_id_from': 'EditorRunNative', 'node_id_to': 'start_run_native', 'description': ''}, {'node_id_from': 'EditorNode', 'node_id_to': 'show_warning', 'description': 'Show error'}, {'node_id_from': 'EditorExportPlatform', 'node_id_to': 'fill_log_messages', 'description': 'Log error'}, {'node_id_from': 'AcceptDialog', 'node_id_to': 'popup_centered_ratio', 'description': 'Show dialog'}], 'packages': [{'package_id': 'errorHandling', 'children': ['start_run_native', 'ensure_main_scene', 'errorCheck'], 'description': 'Core error handling components'}, {'package_id': 'errorUI', 'children': ['show_warning', 'fill_log_messages', 'popup_centered_ratio', 'EditorNode', 'EditorExportPlatform', 'AcceptDialog'], 'description': 'Error UI components'}]}",
    "version": "medium",
    "text_answer": "The start_run_native method implements a multi-step error handling flow: it first validates input parameters, checks main scene readiness, verifies export platform and preset availability, and finally handles any runtime errors by logging them and showing appropriate UI feedback through warnings or error dialogs.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include \"editor_run_native.h\"\n\n#include \"editor/editor_node.h\"\n#include \"editor/editor_settings.h\"\n#include \"editor/export/editor_export.h\"\n#include \"editor/export/editor_export_platform.h\"\n#include \"editor/themes/editor_scale.h\"\n\nvoid EditorRunNative::_notification(int p_what) {\n\tswitch (p_what) {\n\t\tcase NOTIFICATION_THEME_CHANGED: {\n\t\t\tremote_debug->set_button_icon(get_editor_theme_icon(SNAME(\"PlayRemote\")));\n\t\t} break;\n\n\t\tcase NOTIFICATION_PROCESS: {\n\t\t\tbool changed = EditorExport::get_singleton()->poll_export_platforms() || first;\n\n\t\t\tif (changed) {\n\t\t\t\tPopupMenu *popup = remote_debug->get_popup();\n\t\t\t\tpopup->clear();\n\t\t\t\tint device_shortcut_id = 1;\n\t\t\t\tfor (int i = 0; i < EditorExport::get_singleton()->get_export_preset_count(); i++) {\n\t\t\t\t\tRef<EditorExportPreset> preset = EditorExport::get_singleton()->get_export_preset(i);\n\t\t\t\t\tRef<EditorExportPlatform> eep = preset->get_platform();\n\t\t\t\t\tif (eep.is_null()) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tint platform_idx = -1;\n\t\t\t\t\tfor (int j = 0; j < EditorExport::get_singleton()->get_export_platform_count(); j++) {\n\t\t\t\t\t\tif (eep->get_name() == EditorExport::get_singleton()->get_export_platform(j)->get_name()) {\n\t\t\t\t\t\t\tplatform_idx = j;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tint dc = MIN(eep->get_options_count(), 9000);\n\t\t\t\t\tString error;\n\t\t\t\t\tif (dc > 0 && preset->is_runnable()) {\n\t\t\t\t\t\tpopup->add_icon_item(eep->get_run_icon(), eep->get_name(), -1);\n\t\t\t\t\t\tpopup->set_item_disabled(-1, true);\n\t\t\t\t\t\tfor (int j = 0; j < dc; j++) {\n\t\t\t\t\t\t\tpopup->add_icon_item(eep->get_option_icon(j), eep->get_option_label(j), 10000 * platform_idx + j);\n\t\t\t\t\t\t\tpopup->set_item_tooltip(-1, eep->get_option_tooltip(j));\n\t\t\t\t\t\t\tpopup->set_item_indent(-1, 2);\n\t\t\t\t\t\t\tif (device_shortcut_id <= 4) {\n\t\t\t\t\t\t\t\t// Assign shortcuts for the first 4 devices added in the list.\n\t\t\t\t\t\t\t\tpopup->set_item_shortcut(-1, ED_GET_SHORTCUT(vformat(\"remote_deploy/deploy_to_device_%d\", device_shortcut_id)), true);\n\t\t\t\t\t\t\t\tdevice_shortcut_id += 1;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (popup->get_item_count() == 0) {\n\t\t\t\t\tremote_debug->set_disabled(true);\n\t\t\t\t\tremote_debug->set_tooltip_text(TTR(\"No Remote Deploy export presets configured.\"));\n\t\t\t\t} else {\n\t\t\t\t\tremote_debug->set_disabled(false);\n\t\t\t\t\tremote_debug->set_tooltip_text(TTR(\"Remote Deploy\"));\n\t\t\t\t}\n\n\t\t\t\tfirst = false;\n\t\t\t}\n\t\t} break;\n\t}\n}\n\nvoid EditorRunNative::_confirm_run_native() {\n\trun_confirmed = true;\n\tresume_run_native();\n}\n\nError EditorRunNative::start_run_native(int p_id) {\n\tif (p_id < 0) {\n\t\treturn OK;\n\t}\n\n\tint platform = p_id / 10000;\n\tint idx = p_id % 10000;\n\tresume_id = p_id;\n\n\tif (!EditorNode::get_singleton()->ensure_main_scene(true)) {\n\t\treturn OK;\n\t}\n\n\tRef<EditorExportPlatform> eep = EditorExport::get_singleton()->get_export_platform(platform);\n\tERR_FAIL_COND_V(eep.is_null(), ERR_UNAVAILABLE);\n\n\tRef<EditorExportPreset> preset;\n\n\tfor (int i = 0; i < EditorExport::get_singleton()->get_export_preset_count(); i++) {\n\t\tRef<EditorExportPreset> ep = EditorExport::get_singleton()->get_export_preset(i);\n\t\tif (ep->is_runnable() && ep->get_platform() == eep) {\n\t\t\tpreset = ep;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (preset.is_null()) {\n\t\tEditorNode::get_singleton()->show_warning(TTR(\"No runnable export preset found for this platform.\\nPlease add a runnable preset in the Export menu or define an existing preset as runnable.\"));\n\t\treturn ERR_UNAVAILABLE;\n\t}\n\n\tString architecture = eep->get_device_architecture(idx);\n\tif (!run_confirmed && !architecture.is_empty()) {\n\t\tString preset_arch = \"architectures/\" + architecture;\n\t\tbool is_arch_enabled = preset->get(preset_arch);\n\n\t\tif (!is_arch_enabled) {\n\t\t\tString warning_message = vformat(TTR(\"Warning: The CPU architecture \\\"%s\\\" is not active in your export preset.\\n\\n\"), Variant(architecture));\n\t\t\twarning_message += TTR(\"Run \\\"Remote Deploy\\\" anyway?\");\n\n\t\t\trun_native_confirm->set_text(warning_message);\n\t\t\trun_native_confirm->popup_centered();\n\t\t\treturn OK;\n\t\t}\n\t}\n\trun_confirmed = false;\n\n\tpreset->update_value_overrides();\n\n\temit_signal(SNAME(\"native_run\"), preset);\n\n\tBitField<EditorExportPlatform::DebugFlags> flags = 0;\n\n\tbool deploy_debug_remote = is_deploy_debug_remote_enabled();\n\tbool deploy_dumb = EditorSettings::get_singleton()->get_project_metadata(\"debug_options\", \"run_file_server\", false);\n\tbool debug_collisions = EditorSettings::get_singleton()->get_project_metadata(\"debug_options\", \"run_debug_collisions\", false);\n\tbool debug_navigation = EditorSettings::get_singleton()->get_project_metadata(\"debug_options\", \"run_debug_navigation\", false);\n\n\tif (deploy_debug_remote) {\n\t\tflags.set_flag(EditorExportPlatform::DEBUG_FLAG_REMOTE_DEBUG);\n\t}\n\tif (deploy_dumb) {\n\t\tflags.set_flag(EditorExportPlatform::DEBUG_FLAG_DUMB_CLIENT);\n\t}\n\tif (debug_collisions) {\n\t\tflags.set_flag(EditorExportPlatform::DEBUG_FLAG_VIEW_COLLISIONS);\n\t}\n\tif (debug_navigation) {\n\t\tflags.set_flag(EditorExportPlatform::DEBUG_FLAG_VIEW_NAVIGATION);\n\t}\n\n\teep->clear_messages();\n\tError err = eep->run(preset, idx, flags);\n\tresult_dialog_log->clear();\n\tif (eep->fill_log_messages(result_dialog_log, err)) {\n\t\tif (eep->get_worst_message_type() >= EditorExportPlatform::EXPORT_MESSAGE_ERROR) {\n\t\t\tresult_dialog->popup_centered_ratio(0.5);\n\t\t}\n\t}\n\treturn err;\n}\n\nvoid EditorRunNative::resume_run_native() {\n\tstart_run_native(resume_id);\n}\n\nvoid EditorRunNative::_bind_methods() {\n\tADD_SIGNAL(MethodInfo(\"native_run\", PropertyInfo(Variant::OBJECT, \"preset\", PROPERTY_HINT_RESOURCE_TYPE, \"EditorExportPreset\")));\n}\n\nbool EditorRunNative::is_deploy_debug_remote_enabled() const {\n\treturn EditorSettings::get_singleton()->get_project_metadata(\"debug_options\", \"run_deploy_remote_debug\", true);\n}\n\nEditorRunNative::EditorRunNative() {\n\tED_SHORTCUT(\"remote_deploy/deploy_to_device_1\", TTRC(\"Deploy to First Device in List\"), KeyModifierMask::SHIFT | Key::F5);\n\tED_SHORTCUT_OVERRIDE(\"remote_deploy/deploy_to_device_1\", \"macos\", KeyModifierMask::META | KeyModifierMask::SHIFT | Key::B);\n\tED_SHORTCUT(\"remote_deploy/deploy_to_device_2\", TTRC(\"Deploy to Second Device in List\"));\n\tED_SHORTCUT(\"remote_deploy/deploy_to_device_3\", TTRC(\"Deploy to Third Device in List\"));\n\tED_SHORTCUT(\"remote_deploy/deploy_to_device_4\", TTRC(\"Deploy to Fourth Device in List\"));\n\n\tremote_debug = memnew(MenuButton);\n\tremote_debug->set_flat(false);\n\tremote_debug->set_theme_type_variation(\"RunBarButton\");\n\tremote_debug->get_popup()->connect(SceneStringName(id_pressed), callable_mp(this, &EditorRunNative::start_run_native));\n\tremote_debug->set_tooltip_text(TTR(\"Remote Deploy\"));\n\tremote_debug->set_disabled(true);\n\n\tadd_child(remote_debug);\n\n\tresult_dialog = memnew(AcceptDialog);\n\tresult_dialog->set_title(TTR(\"Project Run\"));\n\tresult_dialog_log = memnew(RichTextLabel);\n\tresult_dialog_log->set_custom_minimum_size(Size2(300, 80) * EDSCALE);\n\tresult_dialog->add_child(result_dialog_log);\n\n\tadd_child(result_dialog);\n\tresult_dialog->hide();\n\n\trun_native_confirm = memnew(ConfirmationDialog);\n\tadd_child(run_native_confirm);\n\trun_native_confirm->connect(SceneStringName(confirmed), callable_mp(this, &EditorRunNative::_confirm_run_native));\n\n\tset_process(true);\n}",
    "repo": "godotengine/godot",
    "path": "./datasets/diagrams-repos/godotengine/godot/editor/editor_run_native.cpp",
    "query": "Can you represent the error handling flow in the start_run_native method?",
    "diagram": "{'nodes': [{'type': 'method', 'name': 'start_run_native', 'node_id': 'start_run_native', 'description': 'Main method for starting native run with error handling', 'visibility': 'public', 'return_type': 'Error', 'params': 'int p_id', 'source_class_id': 'EditorRunNative'}, {'type': 'function', 'name': 'ensure_main_scene', 'node_id': 'ensure_main_scene', 'description': 'Checks if main scene is ready', 'visibility': 'public', 'return_type': 'bool', 'params': 'bool p_force', 'source_class_id': None}, {'type': 'entity', 'name': 'initialCheck', 'node_id': 'initialCheck', 'description': 'Initial parameter validation', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'platformCheck', 'node_id': 'platformCheck', 'description': 'Export platform validation', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'presetCheck', 'node_id': 'presetCheck', 'description': 'Export preset validation', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'show_warning', 'node_id': 'show_warning', 'description': 'Shows warning message to user', 'visibility': 'public', 'return_type': None, 'params': 'String message', 'source_class_id': 'EditorNode'}, {'type': 'method', 'name': 'clear_messages', 'node_id': 'clear_messages', 'description': 'Clears previous error messages', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': 'EditorExportPlatform'}, {'type': 'method', 'name': 'fill_log_messages', 'node_id': 'fill_log_messages', 'description': 'Fills log with error messages', 'visibility': 'public', 'return_type': 'bool', 'params': 'TextLog log, Error err', 'source_class_id': 'EditorExportPlatform'}, {'type': 'method', 'name': 'get_worst_message_type', 'node_id': 'get_worst_message_type', 'description': 'Gets most severe error type', 'visibility': 'public', 'return_type': 'int', 'params': None, 'source_class_id': 'EditorExportPlatform'}, {'type': 'method', 'name': 'popup_centered_ratio', 'node_id': 'popup_centered_ratio', 'description': 'Shows error dialog', 'visibility': 'public', 'return_type': None, 'params': 'float ratio', 'source_class_id': 'AcceptDialog'}, {'type': 'class', 'name': 'EditorRunNative', 'node_id': 'EditorRunNative', 'description': 'Manages remote deployment of Godot projects to devices, handling export presets, platform detection, and debug options through a menu interface', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'EditorNode', 'node_id': 'EditorNode', 'description': 'Core editor singleton that manages editor functionality', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'EditorExportPlatform', 'node_id': 'EditorExportPlatform', 'description': 'Handles platform-specific export and deployment logic', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'AcceptDialog', 'node_id': 'AcceptDialog', 'description': 'Modal dialog window for displaying messages and warnings', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'start_run_native', 'node_id_to': 'initialCheck', 'description': 'Check p_id'}, {'node_id_from': 'initialCheck', 'node_id_to': 'ensure_main_scene', 'description': 'Validate scene'}, {'node_id_from': 'ensure_main_scene', 'node_id_to': 'platformCheck', 'description': 'Check platform'}, {'node_id_from': 'platformCheck', 'node_id_to': 'presetCheck', 'description': 'Check preset'}, {'node_id_from': 'presetCheck', 'node_id_to': 'EditorNode', 'description': ''}, {'node_id_from': 'start_run_native', 'node_id_to': 'EditorExportPlatform', 'description': ''}, {'node_id_from': 'clear_messages', 'node_id_to': 'fill_log_messages', 'description': ''}, {'node_id_from': 'fill_log_messages', 'node_id_to': 'get_worst_message_type', 'description': ''}, {'node_id_from': 'get_worst_message_type', 'node_id_to': 'AcceptDialog', 'description': ''}, {'node_id_from': 'EditorRunNative', 'node_id_to': 'start_run_native', 'description': ''}, {'node_id_from': 'EditorNode', 'node_id_to': 'show_warning', 'description': 'Show error'}, {'node_id_from': 'EditorExportPlatform', 'node_id_to': 'fill_log_messages', 'description': 'Fill new messages'}, {'node_id_from': 'EditorExportPlatform', 'node_id_to': 'get_worst_message_type', 'description': 'Check severity'}, {'node_id_from': 'EditorExportPlatform', 'node_id_to': 'clear_messages', 'description': 'Clear previous'}, {'node_id_from': 'AcceptDialog', 'node_id_to': 'popup_centered_ratio', 'description': 'Show if error'}], 'packages': [{'package_id': 'validation', 'children': ['initialCheck', 'platformCheck', 'presetCheck'], 'description': 'Validation steps'}, {'package_id': 'errorHandling', 'children': ['start_run_native', 'ensure_main_scene'], 'description': 'Core error handling'}, {'package_id': 'errorUI', 'children': ['show_warning', 'clear_messages', 'fill_log_messages', 'get_worst_message_type', 'popup_centered_ratio', 'EditorNode', 'EditorExportPlatform', 'AcceptDialog'], 'description': 'Error UI handling'}]}",
    "version": "full",
    "text_answer": "The start_run_native method implements a multi-step error handling flow: it first validates input parameters, checks main scene readiness, verifies export platform and preset availability, and finally handles any runtime errors by logging them and showing appropriate UI feedback through warnings or error dialogs.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include \"retdec/llvmir2hll/semantics/semantics/win_api_semantics/get_name_of_param/p.h\"\n\nnamespace retdec {\nnamespace llvmir2hll {\nnamespace semantics {\nnamespace win_api {\n\n/**\n* @brief Initializes the given map with info about functions starting with P.\n*/\nvoid initFuncParamNamesMap_P(FuncParamNamesMap &funcParamNamesMap) {\n\t//\n\t// windows.h\n\t//\n\tADD_PARAM_NAME(\"PFXExportCertStore\", 1, \"hStore\"); // HCERTSTORE\n\tADD_PARAM_NAME(\"PFXExportCertStore\", 2, \"pPFX\"); // CRYPT_DATA_BLOB *\n\tADD_PARAM_NAME(\"PFXExportCertStore\", 3, \"szPassword\"); // LPCWSTR\n\tADD_PARAM_NAME(\"PFXExportCertStore\", 4, \"dwFlags\"); // DWORD\n\tADD_PARAM_NAME(\"PFXExportCertStoreEx\", 1, \"hStore\"); // HCERTSTORE\n\tADD_PARAM_NAME(\"PFXExportCertStoreEx\", 2, \"pPFX\"); // CRYPT_DATA_BLOB *\n\tADD_PARAM_NAME(\"PFXExportCertStoreEx\", 3, \"szPassword\"); // LPCWSTR\n\tADD_PARAM_NAME(\"PFXExportCertStoreEx\", 4, \"pvReserved\"); // void *\n\tADD_PARAM_NAME(\"PFXExportCertStoreEx\", 5, \"dwFlags\"); // DWORD\n\tADD_PARAM_NAME(\"PFXImportCertStore\", 1, \"pPFX\"); // CRYPT_DATA_BLOB *\n\tADD_PARAM_NAME(\"PFXImportCertStore\", 2, \"szPassword\"); // LPCWSTR\n\tADD_PARAM_NAME(\"PFXImportCertStore\", 3, \"dwFlags\"); // DWORD\n\tADD_PARAM_NAME(\"PFXIsPFXBlob\", 1, \"pPFX\"); // CRYPT_DATA_BLOB *\n\tADD_PARAM_NAME(\"PFXVerifyPassword\", 1, \"pPFX\"); // CRYPT_DATA_BLOB *\n\tADD_PARAM_NAME(\"PFXVerifyPassword\", 2, \"szPassword\"); // LPCWSTR\n\tADD_PARAM_NAME(\"PFXVerifyPassword\", 3, \"dwFlags\"); // DWORD\n\tADD_PARAM_NAME(\"PaintDesktop\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PaintRgn\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PaintRgn\", 2, \"hrgn\"); // HRGN\n\tADD_PARAM_NAME(\"PartialReplyPrinterChangeNotification\", 1, \"hNotify\"); // HANDLE\n\tADD_PARAM_NAME(\"PartialReplyPrinterChangeNotification\", 2, \"pInfoDataSrc\"); // PPRINTER_NOTIFY_INFO_DATA\n\tADD_PARAM_NAME(\"PatBlt\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PatBlt\", 2, \"x\"); // int\n\tADD_PARAM_NAME(\"PatBlt\", 3, \"y\"); // int\n\tADD_PARAM_NAME(\"PatBlt\", 4, \"w\"); // int\n\tADD_PARAM_NAME(\"PatBlt\", 5, \"h\"); // int\n\tADD_PARAM_NAME(\"PatBlt\", 6, \"rop\"); // DWORD\n\tADD_PARAM_NAME(\"PathToRegion\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PeekConsoleInputA\", 1, \"hConsoleInput\"); // HANDLE\n\tADD_PARAM_NAME(\"PeekConsoleInputA\", 2, \"lpBuffer\"); // PINPUT_RECORD\n\tADD_PARAM_NAME(\"PeekConsoleInputA\", 3, \"nLength\"); // DWORD\n\tADD_PARAM_NAME(\"PeekConsoleInputA\", 4, \"lpNumberOfEventsRead\"); // LPDWORD\n\tADD_PARAM_NAME(\"PeekConsoleInputW\", 1, \"hConsoleInput\"); // HANDLE\n\tADD_PARAM_NAME(\"PeekConsoleInputW\", 2, \"lpBuffer\"); // PINPUT_RECORD\n\tADD_PARAM_NAME(\"PeekConsoleInputW\", 3, \"nLength\"); // DWORD\n\tADD_PARAM_NAME(\"PeekConsoleInputW\", 4, \"lpNumberOfEventsRead\"); // LPDWORD\n\tADD_PARAM_NAME(\"PeekMessageA\", 1, \"lpMsg\"); // LPMSG\n\tADD_PARAM_NAME(\"PeekMessageA\", 2, \"hWnd\"); // HWND\n\tADD_PARAM_NAME(\"PeekMessageA\", 3, \"wMsgFilterMin\"); // UINT\n\tADD_PARAM_NAME(\"PeekMessageA\", 4, \"wMsgFilterMax\"); // UINT\n\tADD_PARAM_NAME(\"PeekMessageA\", 5, \"wRemoveMsg\"); // UINT\n\tADD_PARAM_NAME(\"PeekMessageW\", 1, \"lpMsg\"); // LPMSG\n\tADD_PARAM_NAME(\"PeekMessageW\", 2, \"hWnd\"); // HWND\n\tADD_PARAM_NAME(\"PeekMessageW\", 3, \"wMsgFilterMin\"); // UINT\n\tADD_PARAM_NAME(\"PeekMessageW\", 4, \"wMsgFilterMax\"); // UINT\n\tADD_PARAM_NAME(\"PeekMessageW\", 5, \"wRemoveMsg\"); // UINT\n\tADD_PARAM_NAME(\"PeekNamedPipe\", 1, \"hNamedPipe\"); // HANDLE\n\tADD_PARAM_NAME(\"PeekNamedPipe\", 2, \"lpBuffer\"); // LPVOID\n\tADD_PARAM_NAME(\"PeekNamedPipe\", 3, \"nBufferSize\"); // DWORD\n\tADD_PARAM_NAME(\"PeekNamedPipe\", 4, \"lpBytesRead\"); // LPDWORD\n\tADD_PARAM_NAME(\"PeekNamedPipe\", 5, \"lpTotalBytesAvail\"); // LPDWORD\n\tADD_PARAM_NAME(\"PeekNamedPipe\", 6, \"lpBytesLeftThisMessage\"); // LPDWORD\n\tADD_PARAM_NAME(\"Pie\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"Pie\", 2, \"left\"); // int\n\tADD_PARAM_NAME(\"Pie\", 3, \"top\"); // int\n\tADD_PARAM_NAME(\"Pie\", 4, \"right\"); // int\n\tADD_PARAM_NAME(\"Pie\", 5, \"bottom\"); // int\n\tADD_PARAM_NAME(\"Pie\", 6, \"xr1\"); // int\n\tADD_PARAM_NAME(\"Pie\", 7, \"yr1\"); // int\n\tADD_PARAM_NAME(\"Pie\", 8, \"xr2\"); // int\n\tADD_PARAM_NAME(\"Pie\", 9, \"yr2\"); // int\n\tADD_PARAM_NAME(\"PlayEnhMetaFile\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PlayEnhMetaFile\", 2, \"hmf\"); // HENHMETAFILE\n\tADD_PARAM_NAME(\"PlayEnhMetaFile\", 3, \"lprect\"); // CONST RECT *\n\tADD_PARAM_NAME(\"PlayEnhMetaFileRecord\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PlayEnhMetaFileRecord\", 2, \"pht\"); // LPHANDLETABLE\n\tADD_PARAM_NAME(\"PlayEnhMetaFileRecord\", 3, \"pmr\"); // CONST ENHMETARECORD *\n\tADD_PARAM_NAME(\"PlayEnhMetaFileRecord\", 4, \"cht\"); // UINT\n\tADD_PARAM_NAME(\"PlayGdiScriptOnPrinterIC\", 1, \"hPrinterIC\"); // HANDLE\n\tADD_PARAM_NAME(\"PlayGdiScriptOnPrinterIC\", 2, \"pIn\"); // LPBYTE\n\tADD_PARAM_NAME(\"PlayGdiScriptOnPrinterIC\", 3, \"cIn\"); // DWORD\n\tADD_PARAM_NAME(\"PlayGdiScriptOnPrinterIC\", 4, \"pOut\"); // LPBYTE\n\tADD_PARAM_NAME(\"PlayGdiScriptOnPrinterIC\", 5, \"cOut\"); // DWORD\n\tADD_PARAM_NAME(\"PlayGdiScriptOnPrinterIC\", 6, \"ul\"); // DWORD\n\tADD_PARAM_NAME(\"PlayMetaFile\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PlayMetaFile\", 2, \"hmf\"); // HMETAFILE\n\tADD_PARAM_NAME(\"PlayMetaFileRecord\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PlayMetaFileRecord\", 2, \"lpHandleTable\"); // LPHANDLETABLE\n\tADD_PARAM_NAME(\"PlayMetaFileRecord\", 3, \"lpMR\"); // LPMETARECORD\n\tADD_PARAM_NAME(\"PlayMetaFileRecord\", 4, \"noObjs\"); // UINT\n\tADD_PARAM_NAME(\"PlgBlt\", 1, \"hdcDest\"); // HDC\n\tADD_PARAM_NAME(\"PlgBlt\", 2, \"lpPoint\"); // CONST POINT *\n\tADD_PARAM_NAME(\"PlgBlt\", 3, \"hdcSrc\"); // HDC\n\tADD_PARAM_NAME(\"PlgBlt\", 4, \"xSrc\"); // int\n\tADD_PARAM_NAME(\"PlgBlt\", 5, \"ySrc\"); // int\n\tADD_PARAM_NAME(\"PlgBlt\", 6, \"width\"); // int\n\tADD_PARAM_NAME(\"PlgBlt\", 7, \"height\"); // int\n\tADD_PARAM_NAME(\"PlgBlt\", 8, \"hbmMask\"); // HBITMAP\n\tADD_PARAM_NAME(\"PlgBlt\", 9, \"xMask\"); // int\n\tADD_PARAM_NAME(\"PlgBlt\", 10, \"yMask\"); // int\n\tADD_PARAM_NAME(\"PolyBezier\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PolyBezier\", 2, \"apt\"); // CONST POINT *\n\tADD_PARAM_NAME(\"PolyBezier\", 3, \"cpt\"); // DWORD\n\tADD_PARAM_NAME(\"PolyBezierTo\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PolyBezierTo\", 2, \"apt\"); // CONST POINT *\n\tADD_PARAM_NAME(\"PolyBezierTo\", 3, \"cpt\"); // DWORD\n\tADD_PARAM_NAME(\"PolyDraw\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PolyDraw\", 2, \"apt\"); // CONST POINT *\n\tADD_PARAM_NAME(\"PolyDraw\", 3, \"aj\"); // CONST BYTE *\n\tADD_PARAM_NAME(\"PolyDraw\", 4, \"cpt\"); // int\n\tADD_PARAM_NAME(\"PolyPolygon\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PolyPolygon\", 2, \"apt\"); // CONST POINT *\n\tADD_PARAM_NAME(\"PolyPolygon\", 3, \"asz\"); // CONST INT *\n\tADD_PARAM_NAME(\"PolyPolygon\", 4, \"csz\"); // int\n\tADD_PARAM_NAME(\"PolyPolyline\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PolyPolyline\", 2, \"apt\"); // CONST POINT *\n\tADD_PARAM_NAME(\"PolyPolyline\", 3, \"asz\"); // CONST DWORD *\n\tADD_PARAM_NAME(\"PolyPolyline\", 4, \"csz\"); // DWORD\n\tADD_PARAM_NAME(\"PolyTextOutA\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PolyTextOutA\", 2, \"ppt\"); // CONST POLYTEXTA *\n\tADD_PARAM_NAME(\"PolyTextOutA\", 3, \"nstrings\"); // int\n\tADD_PARAM_NAME(\"PolyTextOutW\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PolyTextOutW\", 2, \"ppt\"); // CONST POLYTEXTW *\n\tADD_PARAM_NAME(\"PolyTextOutW\", 3, \"nstrings\"); // int\n\tADD_PARAM_NAME(\"Polygon\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"Polygon\", 2, \"apt\"); // CONST POINT *\n\tADD_PARAM_NAME(\"Polygon\", 3, \"cpt\"); // int\n\tADD_PARAM_NAME(\"Polyline\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"Polyline\", 2, \"apt\"); // CONST POINT *\n\tADD_PARAM_NAME(\"Polyline\", 3, \"cpt\"); // int\n\tADD_PARAM_NAME(\"PolylineTo\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PolylineTo\", 2, \"apt\"); // CONST POINT *\n\tADD_PARAM_NAME(\"PolylineTo\", 3, \"cpt\"); // DWORD\n\tADD_PARAM_NAME(\"PostMessageA\", 1, \"hWnd\"); // HWND\n\tADD_PARAM_NAME(\"PostMessageA\", 2, \"Msg\"); // UINT\n\tADD_PARAM_NAME(\"PostMessageA\", 3, \"wParam\"); // WPARAM\n\tADD_PARAM_NAME(\"PostMessageA\", 4, \"lParam\"); // LPARAM\n\tADD_PARAM_NAME(\"PostMessageW\", 1, \"hWnd\"); // HWND\n\tADD_PARAM_NAME(\"PostMessageW\", 2, \"Msg\"); // UINT\n\tADD_PARAM_NAME(\"PostMessageW\", 3, \"wParam\"); // WPARAM\n\tADD_PARAM_NAME(\"PostMessageW\", 4, \"lParam\"); // LPARAM\n\tADD_PARAM_NAME(\"PostQueuedCompletionStatus\", 1, \"CompletionPort\"); // HANDLE\n\tADD_PARAM_NAME(\"PostQueuedCompletionStatus\", 2, \"dwNumberOfBytesTransferred\"); // DWORD\n\tADD_PARAM_NAME(\"PostQueuedCompletionStatus\", 3, \"dwCompletionKey\"); // ULONG_PTR\n\tADD_PARAM_NAME(\"PostQueuedCompletionStatus\", 4, \"lpOverlapped\"); // LPOVERLAPPED\n\tADD_PARAM_NAME(\"PostQuitMessage\", 1, \"nExitCode\"); // int\n\tADD_PARAM_NAME(\"PostThreadMessageA\", 1, \"idThread\"); // DWORD\n\tADD_PARAM_NAME(\"PostThreadMessageA\", 2, \"Msg\"); // UINT\n\tADD_PARAM_NAME(\"PostThreadMessageA\", 3, \"wParam\"); // WPARAM\n\tADD_PARAM_NAME(\"PostThreadMessageA\", 4, \"lParam\"); // LPARAM\n\tADD_PARAM_NAME(\"PostThreadMessageW\", 1, \"idThread\"); // DWORD\n\tADD_PARAM_NAME(\"PostThreadMessageW\", 2, \"Msg\"); // UINT\n\tADD_PARAM_NAME(\"PostThreadMessageW\", 3, \"wParam\"); // WPARAM\n\tADD_PARAM_NAME(\"PostThreadMessageW\", 4, \"lParam\"); // LPARAM\n\tADD_PARAM_NAME(\"PrepareTape\", 1, \"hDevice\"); // HANDLE\n\tADD_PARAM_NAME(\"PrepareTape\", 2, \"dwOperation\"); // DWORD\n\tADD_PARAM_NAME(\"PrepareTape\", 3, \"bImmediate\"); // WINBOOL\n\tADD_PARAM_NAME(\"PrintWindow\", 1, \"hWnd\"); // HWND\n\tADD_PARAM_NAME(\"PrintWindow\", 2, \"hdcBlt\"); // HDC\n\tADD_PARAM_NAME(\"PrintWindow\", 3, \"nFlags\"); // UINT\n\tADD_PARAM_NAME(\"PrinterMessageBoxA\", 1, \"hPrinter\"); // HANDLE\n\tADD_PARAM_NAME(\"PrinterMessageBoxA\", 2, \"Error\"); // DWORD\n\tADD_PARAM_NAME(\"PrinterMessageBoxA\", 3, \"hWnd\"); // HWND\n\tADD_PARAM_NAME(\"PrinterMessageBoxA\", 4, \"pText\"); // LPSTR\n\tADD_PARAM_NAME(\"PrinterMessageBoxA\", 5, \"pCaption\"); // LPSTR\n\tADD_PARAM_NAME(\"PrinterMessageBoxA\", 6, \"dwType\"); // DWORD\n\tADD_PARAM_NAME(\"PrinterMessageBoxW\", 1, \"hPrinter\"); // HANDLE\n\tADD_PARAM_NAME(\"PrinterMessageBoxW\", 2, \"Error\"); // DWORD\n\tADD_PARAM_NAME(\"PrinterMessageBoxW\", 3, \"hWnd\"); // HWND\n\tADD_PARAM_NAME(\"PrinterMessageBoxW\", 4, \"pText\"); // LPWSTR\n\tADD_PARAM_NAME(\"PrinterMessageBoxW\", 5, \"pCaption\"); // LPWSTR\n\tADD_PARAM_NAME(\"PrinterMessageBoxW\", 6, \"dwType\"); // DWORD\n\tADD_PARAM_NAME(\"PrinterProperties\", 1, \"hWnd\"); // HWND\n\tADD_PARAM_NAME(\"PrinterProperties\", 2, \"hPrinter\"); // HANDLE\n\tADD_PARAM_NAME(\"PrivateExtractIconsA\", 1, \"szFileName\"); // LPCSTR\n\tADD_PARAM_NAME(\"PrivateExtractIconsA\", 2, \"nIconIndex\"); // int\n\tADD_PARAM_NAME(\"PrivateExtractIconsA\", 3, \"cxIcon\"); // int\n\tADD_PARAM_NAME(\"PrivateExtractIconsA\", 4, \"cyIcon\"); // int\n\tADD_PARAM_NAME(\"PrivateExtractIconsA\", 5, \"phicon\"); // HICON *\n\tADD_PARAM_NAME(\"PrivateExtractIconsA\", 6, \"piconid\"); // UINT *\n\tADD_PARAM_NAME(\"PrivateExtractIconsA\", 7, \"nIcons\"); // UINT\n\tADD_PARAM_NAME(\"PrivateExtractIconsA\", 8, \"flags\"); // UINT\n\tADD_PARAM_NAME(\"PrivateExtractIconsW\", 1, \"szFileName\"); // LPCWSTR\n\tADD_PARAM_NAME(\"PrivateExtractIconsW\", 2, \"nIconIndex\"); // int\n\tADD_PARAM_NAME(\"PrivateExtractIconsW\", 3, \"cxIcon\"); // int\n\tADD_PARAM_NAME(\"PrivateExtractIconsW\", 4, \"cyIcon\"); // int\n\tADD_PARAM_NAME(\"PrivateExtractIconsW\", 5, \"phicon\"); // HICON *\n\tADD_PARAM_NAME(\"PrivateExtractIconsW\", 6, \"piconid\"); // UINT *\n\tADD_PARAM_NAME(\"PrivateExtractIconsW\", 7, \"nIcons\"); // UINT\n\tADD_PARAM_NAME(\"PrivateExtractIconsW\", 8, \"flags\"); // UINT\n\tADD_PARAM_NAME(\"PrivilegeCheck\", 1, \"ClientToken\"); // HANDLE\n\tADD_PARAM_NAME(\"PrivilegeCheck\", 2, \"RequiredPrivileges\"); // PPRIVILEGE_SET\n\tADD_PARAM_NAME(\"PrivilegeCheck\", 3, \"pfResult\"); // LPBOOL\n\tADD_PARAM_NAME(\"PrivilegedServiceAuditAlarmA\", 1, \"SubsystemName\"); // LPCSTR\n\tADD_PARAM_NAME(\"PrivilegedServiceAuditAlarmA\", 2, \"ServiceName\"); // LPCSTR\n\tADD_PARAM_NAME(\"PrivilegedServiceAuditAlarmA\", 3, \"ClientToken\"); // HANDLE\n\tADD_PARAM_NAME(\"PrivilegedServiceAuditAlarmA\", 4, \"Privileges\"); // PPRIVILEGE_SET\n\tADD_PARAM_NAME(\"PrivilegedServiceAuditAlarmA\", 5, \"AccessGranted\"); // WINBOOL\n\tADD_PARAM_NAME(\"PrivilegedServiceAuditAlarmW\", 1, \"SubsystemName\"); // LPCWSTR\n\tADD_PARAM_NAME(\"PrivilegedServiceAuditAlarmW\", 2, \"ServiceName\"); // LPCWSTR\n\tADD_PARAM_NAME(\"PrivilegedServiceAuditAlarmW\", 3, \"ClientToken\"); // HANDLE\n\tADD_PARAM_NAME(\"PrivilegedServiceAuditAlarmW\", 4, \"Privileges\"); // PPRIVILEGE_SET\n\tADD_PARAM_NAME(\"PrivilegedServiceAuditAlarmW\", 5, \"AccessGranted\"); // WINBOOL\n\tADD_PARAM_NAME(\"ProcessIdToSessionId\", 1, \"dwProcessId\"); // DWORD\n\tADD_PARAM_NAME(\"ProcessIdToSessionId\", 2, \"pSessionId\"); // DWORD *\n\tADD_PARAM_NAME(\"ProvidorFindClosePrinterChangeNotification\", 1, \"hPrinter\"); // HANDLE\n\tADD_PARAM_NAME(\"ProvidorFindFirstPrinterChangeNotification\", 1, \"hPrinter\"); // HANDLE\n\tADD_PARAM_NAME(\"ProvidorFindFirstPrinterChangeNotification\", 2, \"fdwFlags\"); // DWORD\n\tADD_PARAM_NAME(\"ProvidorFindFirstPrinterChangeNotification\", 3, \"fdwOptions\"); // DWORD\n\tADD_PARAM_NAME(\"ProvidorFindFirstPrinterChangeNotification\", 4, \"hNotify\"); // HANDLE\n\tADD_PARAM_NAME(\"ProvidorFindFirstPrinterChangeNotification\", 5, \"pvReserved0\"); // PVOID\n\tADD_PARAM_NAME(\"ProvidorFindFirstPrinterChangeNotification\", 6, \"pvReserved1\"); // PVOID\n\tADD_PARAM_NAME(\"PtInRect\", 1, \"lprc\"); // CONST RECT *\n\tADD_PARAM_NAME(\"PtInRect\", 2, \"pt\"); // POINT\n\tADD_PARAM_NAME(\"PtInRegion\", 1, \"hrgn\"); // HRGN\n\tADD_PARAM_NAME(\"PtInRegion\", 2, \"x\"); // int\n\tADD_PARAM_NAME(\"PtInRegion\", 3, \"y\"); // int\n\tADD_PARAM_NAME(\"PtVisible\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PtVisible\", 2, \"x\"); // int\n\tADD_PARAM_NAME(\"PtVisible\", 3, \"y\"); // int\n\tADD_PARAM_NAME(\"PulseEvent\", 1, \"hEvent\"); // HANDLE\n\tADD_PARAM_NAME(\"PurgeComm\", 1, \"hFile\"); // HANDLE\n\tADD_PARAM_NAME(\"PurgeComm\", 2, \"dwFlags\"); // DWORD\n}\n\n} // namespace win_api\n} // namespace semantics\n} // namespace llvmir2hll\n} // namespace retdec",
    "repo": "avast/retdec",
    "path": "./datasets/diagrams-repos/avast/retdec/src/llvmir2hll/semantics/semantics/win_api_semantics/get_name_of_param/p.cpp",
    "query": "How are the parameter names and positions mapped for the function 'PFXExportCertStore'?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'initFuncParamNamesMap_P', 'node_id': 'initFuncParamNamesMap_P', 'description': 'Initializes map with parameter names for functions starting with P', 'visibility': 'public', 'return_type': 'void', 'params': 'FuncParamNamesMap &funcParamNamesMap', 'source_class_id': None}, {'type': 'entity', 'name': 'PFXExportCertStore_params', 'node_id': 'PFXExportCertStore_params', 'description': 'Parameter mapping for PFXExportCertStore function', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'param1_hStore', 'node_id': 'param1_hStore', 'description': 'First parameter of PFXExportCertStore is HCERTSTORE', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'param2_pPFX', 'node_id': 'param2_pPFX', 'description': 'Second parameter of PFXExportCertStore is CRYPT_DATA_BLOB*', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'param3_szPassword', 'node_id': 'param3_szPassword', 'description': 'Third parameter of PFXExportCertStore is LPCWSTR', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'param4_dwFlags', 'node_id': 'param4_dwFlags', 'description': 'Fourth parameter of PFXExportCertStore is DWORD', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'initFuncParamNamesMap_P', 'node_id_to': 'PFXExportCertStore_params', 'description': 'defines parameters'}, {'node_id_from': 'PFXExportCertStore_params', 'node_id_to': 'param1_hStore', 'description': 'has parameter'}, {'node_id_from': 'PFXExportCertStore_params', 'node_id_to': 'param2_pPFX', 'description': 'has parameter'}, {'node_id_from': 'PFXExportCertStore_params', 'node_id_to': 'param3_szPassword', 'description': 'has parameter'}, {'node_id_from': 'PFXExportCertStore_params', 'node_id_to': 'param4_dwFlags', 'description': 'has parameter'}], 'packages': [{'package_id': 'win_api_semantics', 'children': ['initFuncParamNamesMap_P', 'PFXExportCertStore_params', 'param1_hStore', 'param2_pPFX', 'param3_szPassword', 'param4_dwFlags'], 'description': 'Windows API parameter mapping functionality'}]}",
    "version": "medium",
    "text_answer": "PFXExportCertStore has 4 parameters mapped in order: hStore (HCERTSTORE), pPFX (CRYPT_DATA_BLOB*), szPassword (LPCWSTR), and dwFlags (DWORD).",
    "possible_version": [
      "minimal",
      "medium"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include \"retdec/llvmir2hll/semantics/semantics/win_api_semantics/get_name_of_param/p.h\"\n\nnamespace retdec {\nnamespace llvmir2hll {\nnamespace semantics {\nnamespace win_api {\n\n/**\n* @brief Initializes the given map with info about functions starting with P.\n*/\nvoid initFuncParamNamesMap_P(FuncParamNamesMap &funcParamNamesMap) {\n\t//\n\t// windows.h\n\t//\n\tADD_PARAM_NAME(\"PFXExportCertStore\", 1, \"hStore\"); // HCERTSTORE\n\tADD_PARAM_NAME(\"PFXExportCertStore\", 2, \"pPFX\"); // CRYPT_DATA_BLOB *\n\tADD_PARAM_NAME(\"PFXExportCertStore\", 3, \"szPassword\"); // LPCWSTR\n\tADD_PARAM_NAME(\"PFXExportCertStore\", 4, \"dwFlags\"); // DWORD\n\tADD_PARAM_NAME(\"PFXExportCertStoreEx\", 1, \"hStore\"); // HCERTSTORE\n\tADD_PARAM_NAME(\"PFXExportCertStoreEx\", 2, \"pPFX\"); // CRYPT_DATA_BLOB *\n\tADD_PARAM_NAME(\"PFXExportCertStoreEx\", 3, \"szPassword\"); // LPCWSTR\n\tADD_PARAM_NAME(\"PFXExportCertStoreEx\", 4, \"pvReserved\"); // void *\n\tADD_PARAM_NAME(\"PFXExportCertStoreEx\", 5, \"dwFlags\"); // DWORD\n\tADD_PARAM_NAME(\"PFXImportCertStore\", 1, \"pPFX\"); // CRYPT_DATA_BLOB *\n\tADD_PARAM_NAME(\"PFXImportCertStore\", 2, \"szPassword\"); // LPCWSTR\n\tADD_PARAM_NAME(\"PFXImportCertStore\", 3, \"dwFlags\"); // DWORD\n\tADD_PARAM_NAME(\"PFXIsPFXBlob\", 1, \"pPFX\"); // CRYPT_DATA_BLOB *\n\tADD_PARAM_NAME(\"PFXVerifyPassword\", 1, \"pPFX\"); // CRYPT_DATA_BLOB *\n\tADD_PARAM_NAME(\"PFXVerifyPassword\", 2, \"szPassword\"); // LPCWSTR\n\tADD_PARAM_NAME(\"PFXVerifyPassword\", 3, \"dwFlags\"); // DWORD\n\tADD_PARAM_NAME(\"PaintDesktop\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PaintRgn\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PaintRgn\", 2, \"hrgn\"); // HRGN\n\tADD_PARAM_NAME(\"PartialReplyPrinterChangeNotification\", 1, \"hNotify\"); // HANDLE\n\tADD_PARAM_NAME(\"PartialReplyPrinterChangeNotification\", 2, \"pInfoDataSrc\"); // PPRINTER_NOTIFY_INFO_DATA\n\tADD_PARAM_NAME(\"PatBlt\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PatBlt\", 2, \"x\"); // int\n\tADD_PARAM_NAME(\"PatBlt\", 3, \"y\"); // int\n\tADD_PARAM_NAME(\"PatBlt\", 4, \"w\"); // int\n\tADD_PARAM_NAME(\"PatBlt\", 5, \"h\"); // int\n\tADD_PARAM_NAME(\"PatBlt\", 6, \"rop\"); // DWORD\n\tADD_PARAM_NAME(\"PathToRegion\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PeekConsoleInputA\", 1, \"hConsoleInput\"); // HANDLE\n\tADD_PARAM_NAME(\"PeekConsoleInputA\", 2, \"lpBuffer\"); // PINPUT_RECORD\n\tADD_PARAM_NAME(\"PeekConsoleInputA\", 3, \"nLength\"); // DWORD\n\tADD_PARAM_NAME(\"PeekConsoleInputA\", 4, \"lpNumberOfEventsRead\"); // LPDWORD\n\tADD_PARAM_NAME(\"PeekConsoleInputW\", 1, \"hConsoleInput\"); // HANDLE\n\tADD_PARAM_NAME(\"PeekConsoleInputW\", 2, \"lpBuffer\"); // PINPUT_RECORD\n\tADD_PARAM_NAME(\"PeekConsoleInputW\", 3, \"nLength\"); // DWORD\n\tADD_PARAM_NAME(\"PeekConsoleInputW\", 4, \"lpNumberOfEventsRead\"); // LPDWORD\n\tADD_PARAM_NAME(\"PeekMessageA\", 1, \"lpMsg\"); // LPMSG\n\tADD_PARAM_NAME(\"PeekMessageA\", 2, \"hWnd\"); // HWND\n\tADD_PARAM_NAME(\"PeekMessageA\", 3, \"wMsgFilterMin\"); // UINT\n\tADD_PARAM_NAME(\"PeekMessageA\", 4, \"wMsgFilterMax\"); // UINT\n\tADD_PARAM_NAME(\"PeekMessageA\", 5, \"wRemoveMsg\"); // UINT\n\tADD_PARAM_NAME(\"PeekMessageW\", 1, \"lpMsg\"); // LPMSG\n\tADD_PARAM_NAME(\"PeekMessageW\", 2, \"hWnd\"); // HWND\n\tADD_PARAM_NAME(\"PeekMessageW\", 3, \"wMsgFilterMin\"); // UINT\n\tADD_PARAM_NAME(\"PeekMessageW\", 4, \"wMsgFilterMax\"); // UINT\n\tADD_PARAM_NAME(\"PeekMessageW\", 5, \"wRemoveMsg\"); // UINT\n\tADD_PARAM_NAME(\"PeekNamedPipe\", 1, \"hNamedPipe\"); // HANDLE\n\tADD_PARAM_NAME(\"PeekNamedPipe\", 2, \"lpBuffer\"); // LPVOID\n\tADD_PARAM_NAME(\"PeekNamedPipe\", 3, \"nBufferSize\"); // DWORD\n\tADD_PARAM_NAME(\"PeekNamedPipe\", 4, \"lpBytesRead\"); // LPDWORD\n\tADD_PARAM_NAME(\"PeekNamedPipe\", 5, \"lpTotalBytesAvail\"); // LPDWORD\n\tADD_PARAM_NAME(\"PeekNamedPipe\", 6, \"lpBytesLeftThisMessage\"); // LPDWORD\n\tADD_PARAM_NAME(\"Pie\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"Pie\", 2, \"left\"); // int\n\tADD_PARAM_NAME(\"Pie\", 3, \"top\"); // int\n\tADD_PARAM_NAME(\"Pie\", 4, \"right\"); // int\n\tADD_PARAM_NAME(\"Pie\", 5, \"bottom\"); // int\n\tADD_PARAM_NAME(\"Pie\", 6, \"xr1\"); // int\n\tADD_PARAM_NAME(\"Pie\", 7, \"yr1\"); // int\n\tADD_PARAM_NAME(\"Pie\", 8, \"xr2\"); // int\n\tADD_PARAM_NAME(\"Pie\", 9, \"yr2\"); // int\n\tADD_PARAM_NAME(\"PlayEnhMetaFile\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PlayEnhMetaFile\", 2, \"hmf\"); // HENHMETAFILE\n\tADD_PARAM_NAME(\"PlayEnhMetaFile\", 3, \"lprect\"); // CONST RECT *\n\tADD_PARAM_NAME(\"PlayEnhMetaFileRecord\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PlayEnhMetaFileRecord\", 2, \"pht\"); // LPHANDLETABLE\n\tADD_PARAM_NAME(\"PlayEnhMetaFileRecord\", 3, \"pmr\"); // CONST ENHMETARECORD *\n\tADD_PARAM_NAME(\"PlayEnhMetaFileRecord\", 4, \"cht\"); // UINT\n\tADD_PARAM_NAME(\"PlayGdiScriptOnPrinterIC\", 1, \"hPrinterIC\"); // HANDLE\n\tADD_PARAM_NAME(\"PlayGdiScriptOnPrinterIC\", 2, \"pIn\"); // LPBYTE\n\tADD_PARAM_NAME(\"PlayGdiScriptOnPrinterIC\", 3, \"cIn\"); // DWORD\n\tADD_PARAM_NAME(\"PlayGdiScriptOnPrinterIC\", 4, \"pOut\"); // LPBYTE\n\tADD_PARAM_NAME(\"PlayGdiScriptOnPrinterIC\", 5, \"cOut\"); // DWORD\n\tADD_PARAM_NAME(\"PlayGdiScriptOnPrinterIC\", 6, \"ul\"); // DWORD\n\tADD_PARAM_NAME(\"PlayMetaFile\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PlayMetaFile\", 2, \"hmf\"); // HMETAFILE\n\tADD_PARAM_NAME(\"PlayMetaFileRecord\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PlayMetaFileRecord\", 2, \"lpHandleTable\"); // LPHANDLETABLE\n\tADD_PARAM_NAME(\"PlayMetaFileRecord\", 3, \"lpMR\"); // LPMETARECORD\n\tADD_PARAM_NAME(\"PlayMetaFileRecord\", 4, \"noObjs\"); // UINT\n\tADD_PARAM_NAME(\"PlgBlt\", 1, \"hdcDest\"); // HDC\n\tADD_PARAM_NAME(\"PlgBlt\", 2, \"lpPoint\"); // CONST POINT *\n\tADD_PARAM_NAME(\"PlgBlt\", 3, \"hdcSrc\"); // HDC\n\tADD_PARAM_NAME(\"PlgBlt\", 4, \"xSrc\"); // int\n\tADD_PARAM_NAME(\"PlgBlt\", 5, \"ySrc\"); // int\n\tADD_PARAM_NAME(\"PlgBlt\", 6, \"width\"); // int\n\tADD_PARAM_NAME(\"PlgBlt\", 7, \"height\"); // int\n\tADD_PARAM_NAME(\"PlgBlt\", 8, \"hbmMask\"); // HBITMAP\n\tADD_PARAM_NAME(\"PlgBlt\", 9, \"xMask\"); // int\n\tADD_PARAM_NAME(\"PlgBlt\", 10, \"yMask\"); // int\n\tADD_PARAM_NAME(\"PolyBezier\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PolyBezier\", 2, \"apt\"); // CONST POINT *\n\tADD_PARAM_NAME(\"PolyBezier\", 3, \"cpt\"); // DWORD\n\tADD_PARAM_NAME(\"PolyBezierTo\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PolyBezierTo\", 2, \"apt\"); // CONST POINT *\n\tADD_PARAM_NAME(\"PolyBezierTo\", 3, \"cpt\"); // DWORD\n\tADD_PARAM_NAME(\"PolyDraw\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PolyDraw\", 2, \"apt\"); // CONST POINT *\n\tADD_PARAM_NAME(\"PolyDraw\", 3, \"aj\"); // CONST BYTE *\n\tADD_PARAM_NAME(\"PolyDraw\", 4, \"cpt\"); // int\n\tADD_PARAM_NAME(\"PolyPolygon\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PolyPolygon\", 2, \"apt\"); // CONST POINT *\n\tADD_PARAM_NAME(\"PolyPolygon\", 3, \"asz\"); // CONST INT *\n\tADD_PARAM_NAME(\"PolyPolygon\", 4, \"csz\"); // int\n\tADD_PARAM_NAME(\"PolyPolyline\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PolyPolyline\", 2, \"apt\"); // CONST POINT *\n\tADD_PARAM_NAME(\"PolyPolyline\", 3, \"asz\"); // CONST DWORD *\n\tADD_PARAM_NAME(\"PolyPolyline\", 4, \"csz\"); // DWORD\n\tADD_PARAM_NAME(\"PolyTextOutA\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PolyTextOutA\", 2, \"ppt\"); // CONST POLYTEXTA *\n\tADD_PARAM_NAME(\"PolyTextOutA\", 3, \"nstrings\"); // int\n\tADD_PARAM_NAME(\"PolyTextOutW\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PolyTextOutW\", 2, \"ppt\"); // CONST POLYTEXTW *\n\tADD_PARAM_NAME(\"PolyTextOutW\", 3, \"nstrings\"); // int\n\tADD_PARAM_NAME(\"Polygon\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"Polygon\", 2, \"apt\"); // CONST POINT *\n\tADD_PARAM_NAME(\"Polygon\", 3, \"cpt\"); // int\n\tADD_PARAM_NAME(\"Polyline\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"Polyline\", 2, \"apt\"); // CONST POINT *\n\tADD_PARAM_NAME(\"Polyline\", 3, \"cpt\"); // int\n\tADD_PARAM_NAME(\"PolylineTo\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PolylineTo\", 2, \"apt\"); // CONST POINT *\n\tADD_PARAM_NAME(\"PolylineTo\", 3, \"cpt\"); // DWORD\n\tADD_PARAM_NAME(\"PostMessageA\", 1, \"hWnd\"); // HWND\n\tADD_PARAM_NAME(\"PostMessageA\", 2, \"Msg\"); // UINT\n\tADD_PARAM_NAME(\"PostMessageA\", 3, \"wParam\"); // WPARAM\n\tADD_PARAM_NAME(\"PostMessageA\", 4, \"lParam\"); // LPARAM\n\tADD_PARAM_NAME(\"PostMessageW\", 1, \"hWnd\"); // HWND\n\tADD_PARAM_NAME(\"PostMessageW\", 2, \"Msg\"); // UINT\n\tADD_PARAM_NAME(\"PostMessageW\", 3, \"wParam\"); // WPARAM\n\tADD_PARAM_NAME(\"PostMessageW\", 4, \"lParam\"); // LPARAM\n\tADD_PARAM_NAME(\"PostQueuedCompletionStatus\", 1, \"CompletionPort\"); // HANDLE\n\tADD_PARAM_NAME(\"PostQueuedCompletionStatus\", 2, \"dwNumberOfBytesTransferred\"); // DWORD\n\tADD_PARAM_NAME(\"PostQueuedCompletionStatus\", 3, \"dwCompletionKey\"); // ULONG_PTR\n\tADD_PARAM_NAME(\"PostQueuedCompletionStatus\", 4, \"lpOverlapped\"); // LPOVERLAPPED\n\tADD_PARAM_NAME(\"PostQuitMessage\", 1, \"nExitCode\"); // int\n\tADD_PARAM_NAME(\"PostThreadMessageA\", 1, \"idThread\"); // DWORD\n\tADD_PARAM_NAME(\"PostThreadMessageA\", 2, \"Msg\"); // UINT\n\tADD_PARAM_NAME(\"PostThreadMessageA\", 3, \"wParam\"); // WPARAM\n\tADD_PARAM_NAME(\"PostThreadMessageA\", 4, \"lParam\"); // LPARAM\n\tADD_PARAM_NAME(\"PostThreadMessageW\", 1, \"idThread\"); // DWORD\n\tADD_PARAM_NAME(\"PostThreadMessageW\", 2, \"Msg\"); // UINT\n\tADD_PARAM_NAME(\"PostThreadMessageW\", 3, \"wParam\"); // WPARAM\n\tADD_PARAM_NAME(\"PostThreadMessageW\", 4, \"lParam\"); // LPARAM\n\tADD_PARAM_NAME(\"PrepareTape\", 1, \"hDevice\"); // HANDLE\n\tADD_PARAM_NAME(\"PrepareTape\", 2, \"dwOperation\"); // DWORD\n\tADD_PARAM_NAME(\"PrepareTape\", 3, \"bImmediate\"); // WINBOOL\n\tADD_PARAM_NAME(\"PrintWindow\", 1, \"hWnd\"); // HWND\n\tADD_PARAM_NAME(\"PrintWindow\", 2, \"hdcBlt\"); // HDC\n\tADD_PARAM_NAME(\"PrintWindow\", 3, \"nFlags\"); // UINT\n\tADD_PARAM_NAME(\"PrinterMessageBoxA\", 1, \"hPrinter\"); // HANDLE\n\tADD_PARAM_NAME(\"PrinterMessageBoxA\", 2, \"Error\"); // DWORD\n\tADD_PARAM_NAME(\"PrinterMessageBoxA\", 3, \"hWnd\"); // HWND\n\tADD_PARAM_NAME(\"PrinterMessageBoxA\", 4, \"pText\"); // LPSTR\n\tADD_PARAM_NAME(\"PrinterMessageBoxA\", 5, \"pCaption\"); // LPSTR\n\tADD_PARAM_NAME(\"PrinterMessageBoxA\", 6, \"dwType\"); // DWORD\n\tADD_PARAM_NAME(\"PrinterMessageBoxW\", 1, \"hPrinter\"); // HANDLE\n\tADD_PARAM_NAME(\"PrinterMessageBoxW\", 2, \"Error\"); // DWORD\n\tADD_PARAM_NAME(\"PrinterMessageBoxW\", 3, \"hWnd\"); // HWND\n\tADD_PARAM_NAME(\"PrinterMessageBoxW\", 4, \"pText\"); // LPWSTR\n\tADD_PARAM_NAME(\"PrinterMessageBoxW\", 5, \"pCaption\"); // LPWSTR\n\tADD_PARAM_NAME(\"PrinterMessageBoxW\", 6, \"dwType\"); // DWORD\n\tADD_PARAM_NAME(\"PrinterProperties\", 1, \"hWnd\"); // HWND\n\tADD_PARAM_NAME(\"PrinterProperties\", 2, \"hPrinter\"); // HANDLE\n\tADD_PARAM_NAME(\"PrivateExtractIconsA\", 1, \"szFileName\"); // LPCSTR\n\tADD_PARAM_NAME(\"PrivateExtractIconsA\", 2, \"nIconIndex\"); // int\n\tADD_PARAM_NAME(\"PrivateExtractIconsA\", 3, \"cxIcon\"); // int\n\tADD_PARAM_NAME(\"PrivateExtractIconsA\", 4, \"cyIcon\"); // int\n\tADD_PARAM_NAME(\"PrivateExtractIconsA\", 5, \"phicon\"); // HICON *\n\tADD_PARAM_NAME(\"PrivateExtractIconsA\", 6, \"piconid\"); // UINT *\n\tADD_PARAM_NAME(\"PrivateExtractIconsA\", 7, \"nIcons\"); // UINT\n\tADD_PARAM_NAME(\"PrivateExtractIconsA\", 8, \"flags\"); // UINT\n\tADD_PARAM_NAME(\"PrivateExtractIconsW\", 1, \"szFileName\"); // LPCWSTR\n\tADD_PARAM_NAME(\"PrivateExtractIconsW\", 2, \"nIconIndex\"); // int\n\tADD_PARAM_NAME(\"PrivateExtractIconsW\", 3, \"cxIcon\"); // int\n\tADD_PARAM_NAME(\"PrivateExtractIconsW\", 4, \"cyIcon\"); // int\n\tADD_PARAM_NAME(\"PrivateExtractIconsW\", 5, \"phicon\"); // HICON *\n\tADD_PARAM_NAME(\"PrivateExtractIconsW\", 6, \"piconid\"); // UINT *\n\tADD_PARAM_NAME(\"PrivateExtractIconsW\", 7, \"nIcons\"); // UINT\n\tADD_PARAM_NAME(\"PrivateExtractIconsW\", 8, \"flags\"); // UINT\n\tADD_PARAM_NAME(\"PrivilegeCheck\", 1, \"ClientToken\"); // HANDLE\n\tADD_PARAM_NAME(\"PrivilegeCheck\", 2, \"RequiredPrivileges\"); // PPRIVILEGE_SET\n\tADD_PARAM_NAME(\"PrivilegeCheck\", 3, \"pfResult\"); // LPBOOL\n\tADD_PARAM_NAME(\"PrivilegedServiceAuditAlarmA\", 1, \"SubsystemName\"); // LPCSTR\n\tADD_PARAM_NAME(\"PrivilegedServiceAuditAlarmA\", 2, \"ServiceName\"); // LPCSTR\n\tADD_PARAM_NAME(\"PrivilegedServiceAuditAlarmA\", 3, \"ClientToken\"); // HANDLE\n\tADD_PARAM_NAME(\"PrivilegedServiceAuditAlarmA\", 4, \"Privileges\"); // PPRIVILEGE_SET\n\tADD_PARAM_NAME(\"PrivilegedServiceAuditAlarmA\", 5, \"AccessGranted\"); // WINBOOL\n\tADD_PARAM_NAME(\"PrivilegedServiceAuditAlarmW\", 1, \"SubsystemName\"); // LPCWSTR\n\tADD_PARAM_NAME(\"PrivilegedServiceAuditAlarmW\", 2, \"ServiceName\"); // LPCWSTR\n\tADD_PARAM_NAME(\"PrivilegedServiceAuditAlarmW\", 3, \"ClientToken\"); // HANDLE\n\tADD_PARAM_NAME(\"PrivilegedServiceAuditAlarmW\", 4, \"Privileges\"); // PPRIVILEGE_SET\n\tADD_PARAM_NAME(\"PrivilegedServiceAuditAlarmW\", 5, \"AccessGranted\"); // WINBOOL\n\tADD_PARAM_NAME(\"ProcessIdToSessionId\", 1, \"dwProcessId\"); // DWORD\n\tADD_PARAM_NAME(\"ProcessIdToSessionId\", 2, \"pSessionId\"); // DWORD *\n\tADD_PARAM_NAME(\"ProvidorFindClosePrinterChangeNotification\", 1, \"hPrinter\"); // HANDLE\n\tADD_PARAM_NAME(\"ProvidorFindFirstPrinterChangeNotification\", 1, \"hPrinter\"); // HANDLE\n\tADD_PARAM_NAME(\"ProvidorFindFirstPrinterChangeNotification\", 2, \"fdwFlags\"); // DWORD\n\tADD_PARAM_NAME(\"ProvidorFindFirstPrinterChangeNotification\", 3, \"fdwOptions\"); // DWORD\n\tADD_PARAM_NAME(\"ProvidorFindFirstPrinterChangeNotification\", 4, \"hNotify\"); // HANDLE\n\tADD_PARAM_NAME(\"ProvidorFindFirstPrinterChangeNotification\", 5, \"pvReserved0\"); // PVOID\n\tADD_PARAM_NAME(\"ProvidorFindFirstPrinterChangeNotification\", 6, \"pvReserved1\"); // PVOID\n\tADD_PARAM_NAME(\"PtInRect\", 1, \"lprc\"); // CONST RECT *\n\tADD_PARAM_NAME(\"PtInRect\", 2, \"pt\"); // POINT\n\tADD_PARAM_NAME(\"PtInRegion\", 1, \"hrgn\"); // HRGN\n\tADD_PARAM_NAME(\"PtInRegion\", 2, \"x\"); // int\n\tADD_PARAM_NAME(\"PtInRegion\", 3, \"y\"); // int\n\tADD_PARAM_NAME(\"PtVisible\", 1, \"hdc\"); // HDC\n\tADD_PARAM_NAME(\"PtVisible\", 2, \"x\"); // int\n\tADD_PARAM_NAME(\"PtVisible\", 3, \"y\"); // int\n\tADD_PARAM_NAME(\"PulseEvent\", 1, \"hEvent\"); // HANDLE\n\tADD_PARAM_NAME(\"PurgeComm\", 1, \"hFile\"); // HANDLE\n\tADD_PARAM_NAME(\"PurgeComm\", 2, \"dwFlags\"); // DWORD\n}\n\n} // namespace win_api\n} // namespace semantics\n} // namespace llvmir2hll\n} // namespace retdec",
    "repo": "avast/retdec",
    "path": "./datasets/diagrams-repos/avast/retdec/src/llvmir2hll/semantics/semantics/win_api_semantics/get_name_of_param/p.cpp",
    "query": "How are the parameter names and positions mapped for the function 'PFXExportCertStore'?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'initFuncParamNamesMap_P', 'node_id': 'initFuncParamNamesMap_P', 'description': 'Initializes map with parameter names for functions starting with P', 'visibility': 'public', 'return_type': 'void', 'params': 'FuncParamNamesMap &funcParamNamesMap', 'source_class_id': None}, {'type': 'entity', 'name': 'PFXExportCertStore_params', 'node_id': 'PFXExportCertStore_params', 'description': 'Parameter mapping for PFXExportCertStore function', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'param1_hStore', 'node_id': 'param1_hStore', 'description': 'First parameter of PFXExportCertStore is HCERTSTORE', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'param2_pPFX', 'node_id': 'param2_pPFX', 'description': 'Second parameter of PFXExportCertStore is CRYPT_DATA_BLOB*', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'param3_szPassword', 'node_id': 'param3_szPassword', 'description': 'Third parameter of PFXExportCertStore is LPCWSTR', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'param4_dwFlags', 'node_id': 'param4_dwFlags', 'description': 'Fourth parameter of PFXExportCertStore is DWORD', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'ADD_PARAM_NAME', 'node_id': 'ADD_PARAM_NAME', 'description': 'Macro for adding parameter names to the map', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'funcParamNamesMap', 'node_id': 'funcParamNamesMap', 'description': 'Map storing function parameter names', 'visibility': 'private', 'return_type': 'FuncParamNamesMap', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'initFuncParamNamesMap_P', 'node_id_to': 'PFXExportCertStore_params', 'description': 'defines parameters'}, {'node_id_from': 'PFXExportCertStore_params', 'node_id_to': 'param1_hStore', 'description': 'has parameter'}, {'node_id_from': 'PFXExportCertStore_params', 'node_id_to': 'param2_pPFX', 'description': 'has parameter'}, {'node_id_from': 'PFXExportCertStore_params', 'node_id_to': 'param3_szPassword', 'description': 'has parameter'}, {'node_id_from': 'PFXExportCertStore_params', 'node_id_to': 'param4_dwFlags', 'description': 'has parameter'}, {'node_id_from': 'initFuncParamNamesMap_P', 'node_id_to': 'ADD_PARAM_NAME', 'description': 'uses'}, {'node_id_from': 'initFuncParamNamesMap_P', 'node_id_to': 'funcParamNamesMap', 'description': 'modifies'}], 'packages': [{'package_id': 'win_api_semantics', 'children': ['initFuncParamNamesMap_P', 'PFXExportCertStore_params', 'param1_hStore', 'param2_pPFX', 'param3_szPassword', 'param4_dwFlags', 'ADD_PARAM_NAME', 'funcParamNamesMap'], 'description': 'Windows API parameter mapping functionality'}]}",
    "version": "full",
    "text_answer": "PFXExportCertStore has 4 parameters mapped in order: hStore (HCERTSTORE), pPFX (CRYPT_DATA_BLOB*), szPassword (LPCWSTR), and dwFlags (DWORD).",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C",
    "code": "\n#include \"ref.h\"\n\nq31_t ref__QADD8(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q7_t r, s, t, u;\n\n   r = (q7_t) x;\n   s = (q7_t) y;\n\n   r = ref_sat_n((q31_t) (r + s), 8);\n   s = ref_sat_n(((q31_t) (((x << 16) >> 24) + ((y << 16) >> 24))), 8);\n   t = ref_sat_n(((q31_t) (((x << 8) >> 24) + ((y << 8) >> 24))), 8);\n   u = ref_sat_n(((q31_t) ((x >> 24) + (y >> 24))), 8);\n\n   sum =\n      (((q31_t) u << 24) & 0xFF000000) | (((q31_t) t << 16) & 0x00FF0000) |\n      (((q31_t) s << 8) & 0x0000FF00) | (r & 0x000000FF);\n\n   return sum;\n\n}\n\nq31_t ref__QSUB8(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q31_t r, s, t, u;\n\n   r = (q7_t) x;\n   s = (q7_t) y;\n\n   r = ref_sat_n((r - s), 8);\n   s = ref_sat_n(((q31_t) (((x << 16) >> 24) - ((y << 16) >> 24))), 8) << 8;\n   t = ref_sat_n(((q31_t) (((x << 8) >> 24) - ((y << 8) >> 24))), 8) << 16;\n   u = ref_sat_n(((q31_t) ((x >> 24) - (y >> 24))), 8) << 24;\n\n   sum = (u & 0xFF000000) | (t & 0x00FF0000) | (s & 0x0000FF00) | (r & 0x000000FF);\n\n   return sum;\n}\n\nq31_t ref__QADD16(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q31_t r, s;\n\n   r = (q15_t) x;\n   s = (q15_t) y;\n\n   r = ref_sat_q15(r + s);\n   s = (q31_t)ref_sat_q15(((q31_t) ((x >> 16) + (y >> 16)))) << 16;\n\n   sum = (s & 0xFFFF0000) | (r & 0x0000FFFF);\n\n   return sum;\n\n}\n\nq31_t ref__SHADD16(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q31_t r, s;\n\n   r = (q15_t) x;\n   s = (q15_t) y;\n\n   r = (r + s) >> 1;\n   s = ((q31_t) (((x >> 16) + (y >> 16)) >> 1) << 16);\n\n   sum = (s & 0xFFFF0000) | (r & 0x0000FFFF);\n\n   return sum;\n\n}\n\nq31_t ref__QSUB16(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q31_t r, s;\n\n   r = (q15_t) x;\n   s = (q15_t) y;\n\n   r = ref_sat_q15(r - s);\n   s = (q31_t)ref_sat_q15(((q31_t) ((x >> 16) - (y >> 16)))) << 16;\n\n   sum = (s & 0xFFFF0000) | (r & 0x0000FFFF);\n\n   return sum;\n}\n\nq31_t ref__SHSUB16(q31_t x, q31_t y)\n{\n   q31_t diff;\n   q31_t r, s;\n\n   r = (q15_t) x;\n   s = (q15_t) y;\n\n   r = ((r >> 1) - (s >> 1));\n   s = (((x >> 17) - (y >> 17)) << 16);\n\n   diff = (s & 0xFFFF0000) | (r & 0x0000FFFF);\n\n   return diff;\n}\n\nq31_t ref__QASX(q31_t x, q31_t y)\n{\n   q31_t sum = 0;\n\tq31_t xL, xH, yL, yH;\n\t\n   // extract bottom halfword and sign extend\n\txL = (q15_t)(x & 0xffff);\n   // extract bottom halfword and sign extend\n\tyL = (q15_t)(y & 0xffff);\n   // extract top halfword and sign extend\n   xH = (q15_t)(x >> 16);\n   // extract top halfword and sign extend\n   yH = (q15_t)(y >> 16);\n   \n   sum = (((q31_t)ref_sat_q15(xH + yL )) << 16) |\n         (((q31_t)ref_sat_q15(xL - yH )) & 0xffff);\n\n   return sum;\n}\n\nq31_t ref__SHASX(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q31_t r, s;\n\n   r = (q15_t) x;\n   s = (q15_t) y;\n\n    r = (r - (y >> 16)) / 2;\n    s = (((x >> 16) + s) << 15);\n\n   sum = (s & 0xFFFF0000) | (r & 0x0000FFFF);\n\n   return sum;\n}\n\nq31_t ref__QSAX(q31_t x, q31_t y)\n{\n   q31_t sum = 0;\n\tq31_t xL, xH, yL, yH;\n\t\n   // extract bottom halfword and sign extend\n\txL = (q15_t)(x & 0xffff);\n   // extract bottom halfword and sign extend\n\tyL = (q15_t)(y & 0xffff);\n   // extract top halfword and sign extend\n   xH = (q15_t)(x >> 16);\n   // extract top halfword and sign extend\n   yH = (q15_t)(y >> 16);\n   \n   sum = (((q31_t)ref_sat_q15(xH - yL )) << 16) |\n         (((q31_t)ref_sat_q15(xL + yH )) & 0xffff);\n\n   return sum;\n}\n\nq31_t ref__SHSAX(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q31_t r, s;\n\n   r = (q15_t) x;\n   s = (q15_t) y;\n\n    r = (r + (y >> 16)) / 2;\n    s = (((x >> 16) - s) << 15);\n\n   sum = (s & 0xFFFF0000) | (r & 0x0000FFFF);\n\n   return sum;\n}\n\nq31_t ref__SMUSDX(q31_t x, q31_t y)\n{\n   return ((q31_t) (((q15_t) x * (q15_t) (y >> 16)) - ((q15_t) (x >> 16) * (q15_t) y)));\n}\n\nq31_t ref__SMUADX(q31_t x, q31_t y)\n{\n   return ((q31_t) (((q15_t) x * (q15_t) (y >> 16)) + ((q15_t) (x >> 16) * (q15_t) y)));\n}\n\nq31_t ref__QADD(q31_t x, q31_t y)\n{\n   return ref_sat_q31((q63_t) x + y);\n}\n\nq31_t ref__QSUB(q31_t x, q31_t y)\n{\n   return ref_sat_q31((q63_t) x - y);\n}\n\nq31_t ref__SMLAD(q31_t x, q31_t y, q31_t sum)\n{\n   return (sum + ((q15_t) (x >> 16) * (q15_t) (y >> 16)) + ((q15_t) x * (q15_t) y));\n}\n\nq31_t ref__SMLADX(q31_t x, q31_t y, q31_t sum)\n{\n   return (sum + ((q15_t) (x >> 16) * (q15_t) (y)) + ((q15_t) x * (q15_t) (y >> 16)));\n}\n\nq31_t ref__SMLSDX(q31_t x, q31_t y, q31_t sum)\n{\n   return (sum - ((q15_t) (x >> 16) * (q15_t) (y)) + ((q15_t) x * (q15_t) (y >> 16)));\n}\n\nq63_t ref__SMLALD(q31_t x, q31_t y, q63_t sum)\n{\n   return (sum + ((q15_t) (x >> 16) * (q15_t) (y >> 16)) + ((q15_t) x * (q15_t) y));\n}\n\nq63_t ref__SMLALDX(q31_t x, q31_t y, q63_t sum)\n{\n   return (sum + ((q15_t) (x >> 16) * (q15_t) y)) + ((q15_t) x * (q15_t) (y >> 16));\n}\n\nq31_t ref__SMUAD(q31_t x, q31_t y)\n{\n   return (((x >> 16) * (y >> 16)) + (((x << 16) >> 16) * ((y << 16) >> 16)));\n}\n\nq31_t ref__SMUSD(q31_t x, q31_t y)\n{\n   return (-((x >> 16) * (y >> 16)) + (((x << 16) >> 16) * ((y << 16) >> 16)));\n}\n\nq31_t ref__SXTB16(q31_t x)\n{\n   return ((((x << 24) >> 24) & 0x0000FFFF) | (((x << 8) >> 8) & 0xFFFF0000));\n}",
    "repo": "XiaoMi/mace",
    "path": "./datasets/diagrams-repos/XiaoMi/mace/micro/third_party/CMSIS_5/CMSIS/DSP/DSP_Lib_TestSuite/RefLibs/src/Intrinsics/intrinsics.c",
    "query": "How does the ref__QADD8 function break down and combine 32-bit integers for addition?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'ref__QADD8', 'node_id': 'ref__QADD8', 'description': 'Adds two 32-bit integers by breaking them into 4 8-bit values', 'visibility': 'public', 'return_type': 'q31_t', 'params': 'q31_t x, q31_t y', 'source_class_id': None}, {'type': 'entity', 'name': 'byteExtraction', 'node_id': 'byteExtraction', 'description': 'Process of extracting individual bytes using bit shifts and masks', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'byteCombination', 'node_id': 'byteCombination', 'description': 'Process of combining processed bytes back into 32-bit result', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'ref__QADD8', 'node_id_to': 'byteExtraction', 'description': 'extracts bytes'}, {'node_id_from': 'byteExtraction', 'node_id_to': 'byteCombination', 'description': 'provides processed bytes'}], 'packages': [{'package_id': 'arithmeticOperations', 'children': ['ref__QADD8', 'byteExtraction', 'byteCombination'], 'description': 'Core arithmetic operations for 8-bit addition'}]}",
    "version": "minimal",
    "text_answer": "The ref__QADD8 function breaks down two 32-bit integers into four 8-bit values using bit shifts and masks, adds corresponding bytes, applies saturation to prevent overflow, and then combines the results back into a 32-bit integer using bitwise operations.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C",
    "code": "\n#include \"ref.h\"\n\nq31_t ref__QADD8(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q7_t r, s, t, u;\n\n   r = (q7_t) x;\n   s = (q7_t) y;\n\n   r = ref_sat_n((q31_t) (r + s), 8);\n   s = ref_sat_n(((q31_t) (((x << 16) >> 24) + ((y << 16) >> 24))), 8);\n   t = ref_sat_n(((q31_t) (((x << 8) >> 24) + ((y << 8) >> 24))), 8);\n   u = ref_sat_n(((q31_t) ((x >> 24) + (y >> 24))), 8);\n\n   sum =\n      (((q31_t) u << 24) & 0xFF000000) | (((q31_t) t << 16) & 0x00FF0000) |\n      (((q31_t) s << 8) & 0x0000FF00) | (r & 0x000000FF);\n\n   return sum;\n\n}\n\nq31_t ref__QSUB8(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q31_t r, s, t, u;\n\n   r = (q7_t) x;\n   s = (q7_t) y;\n\n   r = ref_sat_n((r - s), 8);\n   s = ref_sat_n(((q31_t) (((x << 16) >> 24) - ((y << 16) >> 24))), 8) << 8;\n   t = ref_sat_n(((q31_t) (((x << 8) >> 24) - ((y << 8) >> 24))), 8) << 16;\n   u = ref_sat_n(((q31_t) ((x >> 24) - (y >> 24))), 8) << 24;\n\n   sum = (u & 0xFF000000) | (t & 0x00FF0000) | (s & 0x0000FF00) | (r & 0x000000FF);\n\n   return sum;\n}\n\nq31_t ref__QADD16(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q31_t r, s;\n\n   r = (q15_t) x;\n   s = (q15_t) y;\n\n   r = ref_sat_q15(r + s);\n   s = (q31_t)ref_sat_q15(((q31_t) ((x >> 16) + (y >> 16)))) << 16;\n\n   sum = (s & 0xFFFF0000) | (r & 0x0000FFFF);\n\n   return sum;\n\n}\n\nq31_t ref__SHADD16(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q31_t r, s;\n\n   r = (q15_t) x;\n   s = (q15_t) y;\n\n   r = (r + s) >> 1;\n   s = ((q31_t) (((x >> 16) + (y >> 16)) >> 1) << 16);\n\n   sum = (s & 0xFFFF0000) | (r & 0x0000FFFF);\n\n   return sum;\n\n}\n\nq31_t ref__QSUB16(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q31_t r, s;\n\n   r = (q15_t) x;\n   s = (q15_t) y;\n\n   r = ref_sat_q15(r - s);\n   s = (q31_t)ref_sat_q15(((q31_t) ((x >> 16) - (y >> 16)))) << 16;\n\n   sum = (s & 0xFFFF0000) | (r & 0x0000FFFF);\n\n   return sum;\n}\n\nq31_t ref__SHSUB16(q31_t x, q31_t y)\n{\n   q31_t diff;\n   q31_t r, s;\n\n   r = (q15_t) x;\n   s = (q15_t) y;\n\n   r = ((r >> 1) - (s >> 1));\n   s = (((x >> 17) - (y >> 17)) << 16);\n\n   diff = (s & 0xFFFF0000) | (r & 0x0000FFFF);\n\n   return diff;\n}\n\nq31_t ref__QASX(q31_t x, q31_t y)\n{\n   q31_t sum = 0;\n\tq31_t xL, xH, yL, yH;\n\t\n   // extract bottom halfword and sign extend\n\txL = (q15_t)(x & 0xffff);\n   // extract bottom halfword and sign extend\n\tyL = (q15_t)(y & 0xffff);\n   // extract top halfword and sign extend\n   xH = (q15_t)(x >> 16);\n   // extract top halfword and sign extend\n   yH = (q15_t)(y >> 16);\n   \n   sum = (((q31_t)ref_sat_q15(xH + yL )) << 16) |\n         (((q31_t)ref_sat_q15(xL - yH )) & 0xffff);\n\n   return sum;\n}\n\nq31_t ref__SHASX(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q31_t r, s;\n\n   r = (q15_t) x;\n   s = (q15_t) y;\n\n    r = (r - (y >> 16)) / 2;\n    s = (((x >> 16) + s) << 15);\n\n   sum = (s & 0xFFFF0000) | (r & 0x0000FFFF);\n\n   return sum;\n}\n\nq31_t ref__QSAX(q31_t x, q31_t y)\n{\n   q31_t sum = 0;\n\tq31_t xL, xH, yL, yH;\n\t\n   // extract bottom halfword and sign extend\n\txL = (q15_t)(x & 0xffff);\n   // extract bottom halfword and sign extend\n\tyL = (q15_t)(y & 0xffff);\n   // extract top halfword and sign extend\n   xH = (q15_t)(x >> 16);\n   // extract top halfword and sign extend\n   yH = (q15_t)(y >> 16);\n   \n   sum = (((q31_t)ref_sat_q15(xH - yL )) << 16) |\n         (((q31_t)ref_sat_q15(xL + yH )) & 0xffff);\n\n   return sum;\n}\n\nq31_t ref__SHSAX(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q31_t r, s;\n\n   r = (q15_t) x;\n   s = (q15_t) y;\n\n    r = (r + (y >> 16)) / 2;\n    s = (((x >> 16) - s) << 15);\n\n   sum = (s & 0xFFFF0000) | (r & 0x0000FFFF);\n\n   return sum;\n}\n\nq31_t ref__SMUSDX(q31_t x, q31_t y)\n{\n   return ((q31_t) (((q15_t) x * (q15_t) (y >> 16)) - ((q15_t) (x >> 16) * (q15_t) y)));\n}\n\nq31_t ref__SMUADX(q31_t x, q31_t y)\n{\n   return ((q31_t) (((q15_t) x * (q15_t) (y >> 16)) + ((q15_t) (x >> 16) * (q15_t) y)));\n}\n\nq31_t ref__QADD(q31_t x, q31_t y)\n{\n   return ref_sat_q31((q63_t) x + y);\n}\n\nq31_t ref__QSUB(q31_t x, q31_t y)\n{\n   return ref_sat_q31((q63_t) x - y);\n}\n\nq31_t ref__SMLAD(q31_t x, q31_t y, q31_t sum)\n{\n   return (sum + ((q15_t) (x >> 16) * (q15_t) (y >> 16)) + ((q15_t) x * (q15_t) y));\n}\n\nq31_t ref__SMLADX(q31_t x, q31_t y, q31_t sum)\n{\n   return (sum + ((q15_t) (x >> 16) * (q15_t) (y)) + ((q15_t) x * (q15_t) (y >> 16)));\n}\n\nq31_t ref__SMLSDX(q31_t x, q31_t y, q31_t sum)\n{\n   return (sum - ((q15_t) (x >> 16) * (q15_t) (y)) + ((q15_t) x * (q15_t) (y >> 16)));\n}\n\nq63_t ref__SMLALD(q31_t x, q31_t y, q63_t sum)\n{\n   return (sum + ((q15_t) (x >> 16) * (q15_t) (y >> 16)) + ((q15_t) x * (q15_t) y));\n}\n\nq63_t ref__SMLALDX(q31_t x, q31_t y, q63_t sum)\n{\n   return (sum + ((q15_t) (x >> 16) * (q15_t) y)) + ((q15_t) x * (q15_t) (y >> 16));\n}\n\nq31_t ref__SMUAD(q31_t x, q31_t y)\n{\n   return (((x >> 16) * (y >> 16)) + (((x << 16) >> 16) * ((y << 16) >> 16)));\n}\n\nq31_t ref__SMUSD(q31_t x, q31_t y)\n{\n   return (-((x >> 16) * (y >> 16)) + (((x << 16) >> 16) * ((y << 16) >> 16)));\n}\n\nq31_t ref__SXTB16(q31_t x)\n{\n   return ((((x << 24) >> 24) & 0x0000FFFF) | (((x << 8) >> 8) & 0xFFFF0000));\n}",
    "repo": "XiaoMi/mace",
    "path": "./datasets/diagrams-repos/XiaoMi/mace/micro/third_party/CMSIS_5/CMSIS/DSP/DSP_Lib_TestSuite/RefLibs/src/Intrinsics/intrinsics.c",
    "query": "How does the ref__QADD8 function break down and combine 32-bit integers for addition?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'ref__QADD8', 'node_id': 'ref__QADD8', 'description': 'Adds two 32-bit integers by breaking them into 4 8-bit values', 'visibility': 'public', 'return_type': 'q31_t', 'params': 'q31_t x, q31_t y', 'source_class_id': None}, {'type': 'entity', 'name': 'byteExtraction', 'node_id': 'byteExtraction', 'description': 'Process of extracting individual bytes using bit shifts and masks', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'saturation', 'node_id': 'saturation', 'description': 'Saturation operation for 8-bit values', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'byteCombination', 'node_id': 'byteCombination', 'description': 'Process of combining processed bytes back into 32-bit result', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'ref_sat_n', 'node_id': 'ref_sat_n', 'description': 'Performs saturation for n-bit values', 'visibility': 'public', 'return_type': 'q7_t', 'params': 'q31_t value, int bits', 'source_class_id': None}], 'edges': [{'node_id_from': 'ref__QADD8', 'node_id_to': 'byteExtraction', 'description': 'extracts bytes'}, {'node_id_from': 'byteExtraction', 'node_id_to': 'saturation', 'description': 'sends for saturation'}, {'node_id_from': 'saturation', 'node_id_to': 'ref_sat_n', 'description': 'uses'}, {'node_id_from': 'saturation', 'node_id_to': 'byteCombination', 'description': 'provides saturated bytes'}], 'packages': [{'package_id': 'arithmeticOperations', 'children': ['ref__QADD8', 'byteExtraction', 'saturation', 'byteCombination', 'ref_sat_n'], 'description': 'Core arithmetic operations for 8-bit addition with saturation'}]}",
    "version": "medium",
    "text_answer": "The ref__QADD8 function breaks down two 32-bit integers into four 8-bit values using bit shifts and masks, adds corresponding bytes, applies saturation to prevent overflow, and then combines the results back into a 32-bit integer using bitwise operations.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C",
    "code": "\n#include \"ref.h\"\n\nq31_t ref__QADD8(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q7_t r, s, t, u;\n\n   r = (q7_t) x;\n   s = (q7_t) y;\n\n   r = ref_sat_n((q31_t) (r + s), 8);\n   s = ref_sat_n(((q31_t) (((x << 16) >> 24) + ((y << 16) >> 24))), 8);\n   t = ref_sat_n(((q31_t) (((x << 8) >> 24) + ((y << 8) >> 24))), 8);\n   u = ref_sat_n(((q31_t) ((x >> 24) + (y >> 24))), 8);\n\n   sum =\n      (((q31_t) u << 24) & 0xFF000000) | (((q31_t) t << 16) & 0x00FF0000) |\n      (((q31_t) s << 8) & 0x0000FF00) | (r & 0x000000FF);\n\n   return sum;\n\n}\n\nq31_t ref__QSUB8(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q31_t r, s, t, u;\n\n   r = (q7_t) x;\n   s = (q7_t) y;\n\n   r = ref_sat_n((r - s), 8);\n   s = ref_sat_n(((q31_t) (((x << 16) >> 24) - ((y << 16) >> 24))), 8) << 8;\n   t = ref_sat_n(((q31_t) (((x << 8) >> 24) - ((y << 8) >> 24))), 8) << 16;\n   u = ref_sat_n(((q31_t) ((x >> 24) - (y >> 24))), 8) << 24;\n\n   sum = (u & 0xFF000000) | (t & 0x00FF0000) | (s & 0x0000FF00) | (r & 0x000000FF);\n\n   return sum;\n}\n\nq31_t ref__QADD16(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q31_t r, s;\n\n   r = (q15_t) x;\n   s = (q15_t) y;\n\n   r = ref_sat_q15(r + s);\n   s = (q31_t)ref_sat_q15(((q31_t) ((x >> 16) + (y >> 16)))) << 16;\n\n   sum = (s & 0xFFFF0000) | (r & 0x0000FFFF);\n\n   return sum;\n\n}\n\nq31_t ref__SHADD16(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q31_t r, s;\n\n   r = (q15_t) x;\n   s = (q15_t) y;\n\n   r = (r + s) >> 1;\n   s = ((q31_t) (((x >> 16) + (y >> 16)) >> 1) << 16);\n\n   sum = (s & 0xFFFF0000) | (r & 0x0000FFFF);\n\n   return sum;\n\n}\n\nq31_t ref__QSUB16(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q31_t r, s;\n\n   r = (q15_t) x;\n   s = (q15_t) y;\n\n   r = ref_sat_q15(r - s);\n   s = (q31_t)ref_sat_q15(((q31_t) ((x >> 16) - (y >> 16)))) << 16;\n\n   sum = (s & 0xFFFF0000) | (r & 0x0000FFFF);\n\n   return sum;\n}\n\nq31_t ref__SHSUB16(q31_t x, q31_t y)\n{\n   q31_t diff;\n   q31_t r, s;\n\n   r = (q15_t) x;\n   s = (q15_t) y;\n\n   r = ((r >> 1) - (s >> 1));\n   s = (((x >> 17) - (y >> 17)) << 16);\n\n   diff = (s & 0xFFFF0000) | (r & 0x0000FFFF);\n\n   return diff;\n}\n\nq31_t ref__QASX(q31_t x, q31_t y)\n{\n   q31_t sum = 0;\n\tq31_t xL, xH, yL, yH;\n\t\n   // extract bottom halfword and sign extend\n\txL = (q15_t)(x & 0xffff);\n   // extract bottom halfword and sign extend\n\tyL = (q15_t)(y & 0xffff);\n   // extract top halfword and sign extend\n   xH = (q15_t)(x >> 16);\n   // extract top halfword and sign extend\n   yH = (q15_t)(y >> 16);\n   \n   sum = (((q31_t)ref_sat_q15(xH + yL )) << 16) |\n         (((q31_t)ref_sat_q15(xL - yH )) & 0xffff);\n\n   return sum;\n}\n\nq31_t ref__SHASX(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q31_t r, s;\n\n   r = (q15_t) x;\n   s = (q15_t) y;\n\n    r = (r - (y >> 16)) / 2;\n    s = (((x >> 16) + s) << 15);\n\n   sum = (s & 0xFFFF0000) | (r & 0x0000FFFF);\n\n   return sum;\n}\n\nq31_t ref__QSAX(q31_t x, q31_t y)\n{\n   q31_t sum = 0;\n\tq31_t xL, xH, yL, yH;\n\t\n   // extract bottom halfword and sign extend\n\txL = (q15_t)(x & 0xffff);\n   // extract bottom halfword and sign extend\n\tyL = (q15_t)(y & 0xffff);\n   // extract top halfword and sign extend\n   xH = (q15_t)(x >> 16);\n   // extract top halfword and sign extend\n   yH = (q15_t)(y >> 16);\n   \n   sum = (((q31_t)ref_sat_q15(xH - yL )) << 16) |\n         (((q31_t)ref_sat_q15(xL + yH )) & 0xffff);\n\n   return sum;\n}\n\nq31_t ref__SHSAX(q31_t x, q31_t y)\n{\n   q31_t sum;\n   q31_t r, s;\n\n   r = (q15_t) x;\n   s = (q15_t) y;\n\n    r = (r + (y >> 16)) / 2;\n    s = (((x >> 16) - s) << 15);\n\n   sum = (s & 0xFFFF0000) | (r & 0x0000FFFF);\n\n   return sum;\n}\n\nq31_t ref__SMUSDX(q31_t x, q31_t y)\n{\n   return ((q31_t) (((q15_t) x * (q15_t) (y >> 16)) - ((q15_t) (x >> 16) * (q15_t) y)));\n}\n\nq31_t ref__SMUADX(q31_t x, q31_t y)\n{\n   return ((q31_t) (((q15_t) x * (q15_t) (y >> 16)) + ((q15_t) (x >> 16) * (q15_t) y)));\n}\n\nq31_t ref__QADD(q31_t x, q31_t y)\n{\n   return ref_sat_q31((q63_t) x + y);\n}\n\nq31_t ref__QSUB(q31_t x, q31_t y)\n{\n   return ref_sat_q31((q63_t) x - y);\n}\n\nq31_t ref__SMLAD(q31_t x, q31_t y, q31_t sum)\n{\n   return (sum + ((q15_t) (x >> 16) * (q15_t) (y >> 16)) + ((q15_t) x * (q15_t) y));\n}\n\nq31_t ref__SMLADX(q31_t x, q31_t y, q31_t sum)\n{\n   return (sum + ((q15_t) (x >> 16) * (q15_t) (y)) + ((q15_t) x * (q15_t) (y >> 16)));\n}\n\nq31_t ref__SMLSDX(q31_t x, q31_t y, q31_t sum)\n{\n   return (sum - ((q15_t) (x >> 16) * (q15_t) (y)) + ((q15_t) x * (q15_t) (y >> 16)));\n}\n\nq63_t ref__SMLALD(q31_t x, q31_t y, q63_t sum)\n{\n   return (sum + ((q15_t) (x >> 16) * (q15_t) (y >> 16)) + ((q15_t) x * (q15_t) y));\n}\n\nq63_t ref__SMLALDX(q31_t x, q31_t y, q63_t sum)\n{\n   return (sum + ((q15_t) (x >> 16) * (q15_t) y)) + ((q15_t) x * (q15_t) (y >> 16));\n}\n\nq31_t ref__SMUAD(q31_t x, q31_t y)\n{\n   return (((x >> 16) * (y >> 16)) + (((x << 16) >> 16) * ((y << 16) >> 16)));\n}\n\nq31_t ref__SMUSD(q31_t x, q31_t y)\n{\n   return (-((x >> 16) * (y >> 16)) + (((x << 16) >> 16) * ((y << 16) >> 16)));\n}\n\nq31_t ref__SXTB16(q31_t x)\n{\n   return ((((x << 24) >> 24) & 0x0000FFFF) | (((x << 8) >> 8) & 0xFFFF0000));\n}",
    "repo": "XiaoMi/mace",
    "path": "./datasets/diagrams-repos/XiaoMi/mace/micro/third_party/CMSIS_5/CMSIS/DSP/DSP_Lib_TestSuite/RefLibs/src/Intrinsics/intrinsics.c",
    "query": "How does the ref__QADD8 function break down and combine 32-bit integers for addition?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'ref__QADD8', 'node_id': 'ref__QADD8', 'description': 'Adds two 32-bit integers by breaking them into 4 8-bit values', 'visibility': 'public', 'return_type': 'q31_t', 'params': 'q31_t x, q31_t y', 'source_class_id': None}, {'type': 'variable', 'name': 'sum', 'node_id': 'sum', 'description': 'Final result of byte additions', 'visibility': 'private', 'return_type': 'q31_t', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'r', 'node_id': 'r', 'description': 'Lowest byte result', 'visibility': 'private', 'return_type': 'q7_t', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 's', 'node_id': 's', 'description': 'Second byte result', 'visibility': 'private', 'return_type': 'q7_t', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 't', 'node_id': 't', 'description': 'Third byte result', 'visibility': 'private', 'return_type': 'q7_t', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'u', 'node_id': 'u', 'description': 'Highest byte result', 'visibility': 'private', 'return_type': 'q7_t', 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'byteExtraction', 'node_id': 'byteExtraction', 'description': 'Process of extracting individual bytes using bit shifts and masks', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'saturation', 'node_id': 'saturation', 'description': 'Saturation operation for 8-bit values', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'byteCombination', 'node_id': 'byteCombination', 'description': 'Process of combining processed bytes back into 32-bit result', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'ref_sat_n', 'node_id': 'ref_sat_n', 'description': 'Performs saturation for n-bit values', 'visibility': 'public', 'return_type': 'q7_t', 'params': 'q31_t value, int bits', 'source_class_id': None}], 'edges': [{'node_id_from': 'ref__QADD8', 'node_id_to': 'byteExtraction', 'description': 'extracts bytes'}, {'node_id_from': 'byteExtraction', 'node_id_to': 'r', 'description': 'extracts lowest byte'}, {'node_id_from': 'byteExtraction', 'node_id_to': 's', 'description': 'extracts second byte'}, {'node_id_from': 'byteExtraction', 'node_id_to': 't', 'description': 'extracts third byte'}, {'node_id_from': 'byteExtraction', 'node_id_to': 'u', 'description': 'extracts highest byte'}, {'node_id_from': 'r', 'node_id_to': 'saturation', 'description': 'saturates'}, {'node_id_from': 's', 'node_id_to': 'saturation', 'description': 'saturates'}, {'node_id_from': 't', 'node_id_to': 'saturation', 'description': 'saturates'}, {'node_id_from': 'u', 'node_id_to': 'saturation', 'description': 'saturates'}, {'node_id_from': 'saturation', 'node_id_to': 'ref_sat_n', 'description': 'uses'}, {'node_id_from': 'saturation', 'node_id_to': 'byteCombination', 'description': 'provides saturated bytes'}, {'node_id_from': 'byteCombination', 'node_id_to': 'sum', 'description': 'combines into result'}], 'packages': [{'package_id': 'arithmeticOperations', 'children': ['ref__QADD8', 'byteExtraction', 'saturation', 'byteCombination', 'ref_sat_n'], 'description': 'Core arithmetic operations for 8-bit addition with saturation'}, {'package_id': 'variables', 'children': ['sum', 'r', 's', 't', 'u'], 'description': 'Variables used in the addition process'}]}",
    "version": "full",
    "text_answer": "The ref__QADD8 function breaks down two 32-bit integers into four 8-bit values using bit shifts and masks, adds corresponding bytes, applies saturation to prevent overflow, and then combines the results back into a 32-bit integer using bitwise operations.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C",
    "code": "\n#include <stdlib.h>\n#include \"bitops.h\"\n#include \"../deps/cifra/src/ext/handy.h\"\n#include \"poly1305.h\"\n#include \"salsa20.h\"\n#include \"sha2.h\"\n#include \"picotls.h\"\n#include \"picotls/minicrypto.h\"\n#include \"../chacha20poly1305.h\"\n\nstruct chacha20_context_t {\n    ptls_cipher_context_t super;\n    cf_chacha20_ctx chacha;\n    uint8_t key[PTLS_CHACHA20_KEY_SIZE];\n};\n\nstatic void chacha20_dispose(ptls_cipher_context_t *_ctx)\n{\n    struct chacha20_context_t *ctx = (struct chacha20_context_t *)_ctx;\n    ptls_clear_memory(ctx, sizeof(*ctx));\n}\n\nstatic void chacha20_init(ptls_cipher_context_t *_ctx, const void *iv)\n{\n    struct chacha20_context_t *ctx = (struct chacha20_context_t *)_ctx;\n    ctx->chacha.nblock = 0;\n    ctx->chacha.ncounter = 0;\n    memcpy(ctx->chacha.nonce, iv, sizeof ctx->chacha.nonce);\n}\n\nstatic void chacha20_transform(ptls_cipher_context_t *_ctx, void *output, const void *input, size_t len)\n{\n    struct chacha20_context_t *ctx = (struct chacha20_context_t *)_ctx;\n    cf_chacha20_cipher(&ctx->chacha, input, output, len);\n}\n\nstatic int chacha20_setup_crypto(ptls_cipher_context_t *_ctx, int is_enc, const void *key)\n{\n    struct chacha20_context_t *ctx = (struct chacha20_context_t *)_ctx;\n    ctx->super.do_dispose = chacha20_dispose;\n    ctx->super.do_init = chacha20_init;\n    ctx->super.do_transform = chacha20_transform;\n    cf_chacha20_init(&ctx->chacha, key, PTLS_CHACHA20_KEY_SIZE, (const uint8_t *)\"01234567\" /* not used */);\n    return 0;\n}\n\nstruct cifra_chacha20poly1305_context_t {\n    struct chacha20poly1305_context_t super;\n    cf_poly1305 poly;\n};\n\nstatic void cifra_poly1305_init(struct chacha20poly1305_context_t *_ctx, const void *rs)\n{\n    struct cifra_chacha20poly1305_context_t *ctx = (struct cifra_chacha20poly1305_context_t *)_ctx;\n    cf_poly1305_init(&ctx->poly, rs, (const uint8_t *)rs + 16);\n}\n\nstatic void cifra_poly1305_update(struct chacha20poly1305_context_t *_ctx, const void *input, size_t len)\n{\n    struct cifra_chacha20poly1305_context_t *ctx = (struct cifra_chacha20poly1305_context_t *)_ctx;\n    cf_poly1305_update(&ctx->poly, input, len);\n}\n\nstatic void cifra_poly1305_finish(struct chacha20poly1305_context_t *_ctx, void *tag)\n{\n    struct cifra_chacha20poly1305_context_t *ctx = (struct cifra_chacha20poly1305_context_t *)_ctx;\n    cf_poly1305_finish(&ctx->poly, tag);\n}\n\nstatic int cifra_chacha20poly1305_setup_crypto(ptls_aead_context_t *ctx, int is_enc, const void *key, const void *iv)\n{\n    return chacha20poly1305_setup_crypto(ctx, is_enc, key, iv, &ptls_minicrypto_chacha20, cifra_poly1305_init,\n                                         cifra_poly1305_update, cifra_poly1305_finish);\n}\n\nptls_cipher_algorithm_t ptls_minicrypto_chacha20 = {\n    \"CHACHA20\",           PTLS_CHACHA20_KEY_SIZE, 1 /* block size */, PTLS_CHACHA20_IV_SIZE, sizeof(struct chacha20_context_t),\n    chacha20_setup_crypto};\nptls_aead_algorithm_t ptls_minicrypto_chacha20poly1305 = {\n    \"CHACHA20-POLY1305\",\n    PTLS_CHACHA20POLY1305_CONFIDENTIALITY_LIMIT,\n    PTLS_CHACHA20POLY1305_INTEGRITY_LIMIT,\n    &ptls_minicrypto_chacha20,\n    NULL,\n    PTLS_CHACHA20_KEY_SIZE,\n    PTLS_CHACHA20POLY1305_IV_SIZE,\n    PTLS_CHACHA20POLY1305_TAG_SIZE,\n    {PTLS_TLS12_CHACHAPOLY_FIXED_IV_SIZE, PTLS_TLS12_CHACHAPOLY_RECORD_IV_SIZE},\n    0,\n    0,\n    sizeof(struct cifra_chacha20poly1305_context_t),\n    cifra_chacha20poly1305_setup_crypto};\nptls_cipher_suite_t ptls_minicrypto_chacha20poly1305sha256 = {.id = PTLS_CIPHER_SUITE_CHACHA20_POLY1305_SHA256,\n                                                              .name = PTLS_CIPHER_SUITE_NAME_CHACHA20_POLY1305_SHA256,\n                                                              .aead = &ptls_minicrypto_chacha20poly1305,\n                                                              .hash = &ptls_minicrypto_sha256};",
    "repo": "h2o/h2o",
    "path": "./datasets/diagrams-repos/h2o/h2o/deps/picotls/lib/cifra/chacha20.c",
    "query": "How are the chacha20_context_t and cifra_chacha20poly1305_context_t structures related in terms of inheritance and composition?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'chacha20_context_t', 'node_id': 'chacha20_context_t', 'description': 'Context structure for ChaCha20 cipher operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'cifra_chacha20poly1305_context_t', 'node_id': 'cifra_chacha20poly1305_context_t', 'description': 'Context structure combining ChaCha20 and Poly1305 operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'ptls_minicrypto_chacha20', 'node_id': 'ptls_minicrypto_chacha20', 'description': 'ChaCha20 cipher algorithm implementation', 'visibility': 'public', 'return_type': 'ptls_cipher_algorithm_t', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'ptls_minicrypto_chacha20poly1305', 'node_id': 'ptls_minicrypto_chacha20poly1305', 'description': 'ChaCha20-Poly1305 AEAD algorithm implementation', 'visibility': 'public', 'return_type': 'ptls_aead_algorithm_t', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'ptls_minicrypto_chacha20', 'node_id_to': 'chacha20_context_t', 'description': 'uses'}, {'node_id_from': 'ptls_minicrypto_chacha20poly1305', 'node_id_to': 'ptls_minicrypto_chacha20', 'description': 'references'}, {'node_id_from': 'ptls_minicrypto_chacha20poly1305', 'node_id_to': 'cifra_chacha20poly1305_context_t', 'description': 'uses'}], 'packages': [{'package_id': 'cryptoContexts', 'children': ['chacha20_context_t', 'cifra_chacha20poly1305_context_t'], 'description': 'Crypto context structures'}]}",
    "version": "minimal",
    "text_answer": "chacha20_context_t inherits from ptls_cipher_context_t, while cifra_chacha20poly1305_context_t inherits from chacha20poly1305_context_t. There is no direct inheritance relationship between these two structures, but they are related through their roles in the ChaCha20-Poly1305 cryptographic operations.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C",
    "code": "\n#include <stdlib.h>\n#include \"bitops.h\"\n#include \"../deps/cifra/src/ext/handy.h\"\n#include \"poly1305.h\"\n#include \"salsa20.h\"\n#include \"sha2.h\"\n#include \"picotls.h\"\n#include \"picotls/minicrypto.h\"\n#include \"../chacha20poly1305.h\"\n\nstruct chacha20_context_t {\n    ptls_cipher_context_t super;\n    cf_chacha20_ctx chacha;\n    uint8_t key[PTLS_CHACHA20_KEY_SIZE];\n};\n\nstatic void chacha20_dispose(ptls_cipher_context_t *_ctx)\n{\n    struct chacha20_context_t *ctx = (struct chacha20_context_t *)_ctx;\n    ptls_clear_memory(ctx, sizeof(*ctx));\n}\n\nstatic void chacha20_init(ptls_cipher_context_t *_ctx, const void *iv)\n{\n    struct chacha20_context_t *ctx = (struct chacha20_context_t *)_ctx;\n    ctx->chacha.nblock = 0;\n    ctx->chacha.ncounter = 0;\n    memcpy(ctx->chacha.nonce, iv, sizeof ctx->chacha.nonce);\n}\n\nstatic void chacha20_transform(ptls_cipher_context_t *_ctx, void *output, const void *input, size_t len)\n{\n    struct chacha20_context_t *ctx = (struct chacha20_context_t *)_ctx;\n    cf_chacha20_cipher(&ctx->chacha, input, output, len);\n}\n\nstatic int chacha20_setup_crypto(ptls_cipher_context_t *_ctx, int is_enc, const void *key)\n{\n    struct chacha20_context_t *ctx = (struct chacha20_context_t *)_ctx;\n    ctx->super.do_dispose = chacha20_dispose;\n    ctx->super.do_init = chacha20_init;\n    ctx->super.do_transform = chacha20_transform;\n    cf_chacha20_init(&ctx->chacha, key, PTLS_CHACHA20_KEY_SIZE, (const uint8_t *)\"01234567\" /* not used */);\n    return 0;\n}\n\nstruct cifra_chacha20poly1305_context_t {\n    struct chacha20poly1305_context_t super;\n    cf_poly1305 poly;\n};\n\nstatic void cifra_poly1305_init(struct chacha20poly1305_context_t *_ctx, const void *rs)\n{\n    struct cifra_chacha20poly1305_context_t *ctx = (struct cifra_chacha20poly1305_context_t *)_ctx;\n    cf_poly1305_init(&ctx->poly, rs, (const uint8_t *)rs + 16);\n}\n\nstatic void cifra_poly1305_update(struct chacha20poly1305_context_t *_ctx, const void *input, size_t len)\n{\n    struct cifra_chacha20poly1305_context_t *ctx = (struct cifra_chacha20poly1305_context_t *)_ctx;\n    cf_poly1305_update(&ctx->poly, input, len);\n}\n\nstatic void cifra_poly1305_finish(struct chacha20poly1305_context_t *_ctx, void *tag)\n{\n    struct cifra_chacha20poly1305_context_t *ctx = (struct cifra_chacha20poly1305_context_t *)_ctx;\n    cf_poly1305_finish(&ctx->poly, tag);\n}\n\nstatic int cifra_chacha20poly1305_setup_crypto(ptls_aead_context_t *ctx, int is_enc, const void *key, const void *iv)\n{\n    return chacha20poly1305_setup_crypto(ctx, is_enc, key, iv, &ptls_minicrypto_chacha20, cifra_poly1305_init,\n                                         cifra_poly1305_update, cifra_poly1305_finish);\n}\n\nptls_cipher_algorithm_t ptls_minicrypto_chacha20 = {\n    \"CHACHA20\",           PTLS_CHACHA20_KEY_SIZE, 1 /* block size */, PTLS_CHACHA20_IV_SIZE, sizeof(struct chacha20_context_t),\n    chacha20_setup_crypto};\nptls_aead_algorithm_t ptls_minicrypto_chacha20poly1305 = {\n    \"CHACHA20-POLY1305\",\n    PTLS_CHACHA20POLY1305_CONFIDENTIALITY_LIMIT,\n    PTLS_CHACHA20POLY1305_INTEGRITY_LIMIT,\n    &ptls_minicrypto_chacha20,\n    NULL,\n    PTLS_CHACHA20_KEY_SIZE,\n    PTLS_CHACHA20POLY1305_IV_SIZE,\n    PTLS_CHACHA20POLY1305_TAG_SIZE,\n    {PTLS_TLS12_CHACHAPOLY_FIXED_IV_SIZE, PTLS_TLS12_CHACHAPOLY_RECORD_IV_SIZE},\n    0,\n    0,\n    sizeof(struct cifra_chacha20poly1305_context_t),\n    cifra_chacha20poly1305_setup_crypto};\nptls_cipher_suite_t ptls_minicrypto_chacha20poly1305sha256 = {.id = PTLS_CIPHER_SUITE_CHACHA20_POLY1305_SHA256,\n                                                              .name = PTLS_CIPHER_SUITE_NAME_CHACHA20_POLY1305_SHA256,\n                                                              .aead = &ptls_minicrypto_chacha20poly1305,\n                                                              .hash = &ptls_minicrypto_sha256};",
    "repo": "h2o/h2o",
    "path": "./datasets/diagrams-repos/h2o/h2o/deps/picotls/lib/cifra/chacha20.c",
    "query": "How are the chacha20_context_t and cifra_chacha20poly1305_context_t structures related in terms of inheritance and composition?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'chacha20_context_t', 'node_id': 'chacha20_context_t', 'description': 'Context structure for ChaCha20 cipher operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'cifra_chacha20poly1305_context_t', 'node_id': 'cifra_chacha20poly1305_context_t', 'description': 'Context structure combining ChaCha20 and Poly1305 operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'ptls_cipher_context_t', 'node_id': 'ptls_cipher_context_t', 'description': 'Base cipher context structure', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'chacha20poly1305_context_t', 'node_id': 'chacha20poly1305_context_t', 'description': 'Base context for ChaCha20-Poly1305 operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'cf_chacha20_ctx', 'node_id': 'cf_chacha20_ctx', 'description': \"Cifra library's ChaCha20 context structure\", 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'cf_poly1305', 'node_id': 'cf_poly1305', 'description': \"Cifra library's Poly1305 authentication context\", 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'ptls_minicrypto_chacha20', 'node_id': 'ptls_minicrypto_chacha20', 'description': 'ChaCha20 cipher algorithm implementation', 'visibility': 'public', 'return_type': 'ptls_cipher_algorithm_t', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'ptls_minicrypto_chacha20poly1305', 'node_id': 'ptls_minicrypto_chacha20poly1305', 'description': 'ChaCha20-Poly1305 AEAD algorithm implementation', 'visibility': 'public', 'return_type': 'ptls_aead_algorithm_t', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'chacha20poly1305_setup_crypto', 'node_id': 'chacha20poly1305_setup_crypto', 'description': 'Generic setup function for ChaCha20-Poly1305', 'visibility': 'public', 'return_type': None, 'params': 'ptls_aead_context_t *_ctx, int is_enc, const void *key, const void *iv, ptls_cipher_algorithm_t *chacha, void (*poly1305_init)(struct chacha20poly1305_context_t *, const void *), void (*poly1305_update)(struct chacha20poly1305_context_t *, const void *, size_t), void (*poly1305_finish)(struct chacha20poly1305_context_t *, void *)', 'source_class_id': None}], 'edges': [{'node_id_from': 'chacha20_context_t', 'node_id_to': 'ptls_cipher_context_t', 'description': 'inherits'}, {'node_id_from': 'cifra_chacha20poly1305_context_t', 'node_id_to': 'chacha20poly1305_context_t', 'description': 'inherits'}, {'node_id_from': 'chacha20_context_t', 'node_id_to': 'cf_chacha20_ctx', 'description': 'contains'}, {'node_id_from': 'cifra_chacha20poly1305_context_t', 'node_id_to': 'cf_poly1305', 'description': 'contains'}, {'node_id_from': 'ptls_minicrypto_chacha20', 'node_id_to': 'chacha20_context_t', 'description': 'uses'}, {'node_id_from': 'ptls_minicrypto_chacha20poly1305', 'node_id_to': 'ptls_minicrypto_chacha20', 'description': 'references'}, {'node_id_from': 'chacha20poly1305_setup_crypto', 'node_id_to': 'ptls_minicrypto_chacha20', 'description': 'uses'}, {'node_id_from': 'ptls_minicrypto_chacha20poly1305', 'node_id_to': 'cifra_chacha20poly1305_context_t', 'description': 'uses'}, {'node_id_from': 'ptls_minicrypto_chacha20poly1305', 'node_id_to': 'chacha20poly1305_setup_crypto', 'description': 'uses'}], 'packages': [{'package_id': 'cryptoContexts', 'children': ['chacha20_context_t', 'cifra_chacha20poly1305_context_t', 'ptls_cipher_context_t', 'chacha20poly1305_context_t', 'cf_poly1305', 'cf_chacha20_ctx'], 'description': 'Crypto context structures'}, {'package_id': 'cipherSuites', 'children': ['ptls_minicrypto_chacha20', 'ptls_minicrypto_chacha20poly1305'], 'description': 'Cipher suite implementations'}]}",
    "version": "medium",
    "text_answer": "chacha20_context_t inherits from ptls_cipher_context_t, while cifra_chacha20poly1305_context_t inherits from chacha20poly1305_context_t. There is no direct inheritance relationship between these two structures, but they are related through their roles in the ChaCha20-Poly1305 cryptographic operations.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C",
    "code": "\n#include <stdlib.h>\n#include \"bitops.h\"\n#include \"../deps/cifra/src/ext/handy.h\"\n#include \"poly1305.h\"\n#include \"salsa20.h\"\n#include \"sha2.h\"\n#include \"picotls.h\"\n#include \"picotls/minicrypto.h\"\n#include \"../chacha20poly1305.h\"\n\nstruct chacha20_context_t {\n    ptls_cipher_context_t super;\n    cf_chacha20_ctx chacha;\n    uint8_t key[PTLS_CHACHA20_KEY_SIZE];\n};\n\nstatic void chacha20_dispose(ptls_cipher_context_t *_ctx)\n{\n    struct chacha20_context_t *ctx = (struct chacha20_context_t *)_ctx;\n    ptls_clear_memory(ctx, sizeof(*ctx));\n}\n\nstatic void chacha20_init(ptls_cipher_context_t *_ctx, const void *iv)\n{\n    struct chacha20_context_t *ctx = (struct chacha20_context_t *)_ctx;\n    ctx->chacha.nblock = 0;\n    ctx->chacha.ncounter = 0;\n    memcpy(ctx->chacha.nonce, iv, sizeof ctx->chacha.nonce);\n}\n\nstatic void chacha20_transform(ptls_cipher_context_t *_ctx, void *output, const void *input, size_t len)\n{\n    struct chacha20_context_t *ctx = (struct chacha20_context_t *)_ctx;\n    cf_chacha20_cipher(&ctx->chacha, input, output, len);\n}\n\nstatic int chacha20_setup_crypto(ptls_cipher_context_t *_ctx, int is_enc, const void *key)\n{\n    struct chacha20_context_t *ctx = (struct chacha20_context_t *)_ctx;\n    ctx->super.do_dispose = chacha20_dispose;\n    ctx->super.do_init = chacha20_init;\n    ctx->super.do_transform = chacha20_transform;\n    cf_chacha20_init(&ctx->chacha, key, PTLS_CHACHA20_KEY_SIZE, (const uint8_t *)\"01234567\" /* not used */);\n    return 0;\n}\n\nstruct cifra_chacha20poly1305_context_t {\n    struct chacha20poly1305_context_t super;\n    cf_poly1305 poly;\n};\n\nstatic void cifra_poly1305_init(struct chacha20poly1305_context_t *_ctx, const void *rs)\n{\n    struct cifra_chacha20poly1305_context_t *ctx = (struct cifra_chacha20poly1305_context_t *)_ctx;\n    cf_poly1305_init(&ctx->poly, rs, (const uint8_t *)rs + 16);\n}\n\nstatic void cifra_poly1305_update(struct chacha20poly1305_context_t *_ctx, const void *input, size_t len)\n{\n    struct cifra_chacha20poly1305_context_t *ctx = (struct cifra_chacha20poly1305_context_t *)_ctx;\n    cf_poly1305_update(&ctx->poly, input, len);\n}\n\nstatic void cifra_poly1305_finish(struct chacha20poly1305_context_t *_ctx, void *tag)\n{\n    struct cifra_chacha20poly1305_context_t *ctx = (struct cifra_chacha20poly1305_context_t *)_ctx;\n    cf_poly1305_finish(&ctx->poly, tag);\n}\n\nstatic int cifra_chacha20poly1305_setup_crypto(ptls_aead_context_t *ctx, int is_enc, const void *key, const void *iv)\n{\n    return chacha20poly1305_setup_crypto(ctx, is_enc, key, iv, &ptls_minicrypto_chacha20, cifra_poly1305_init,\n                                         cifra_poly1305_update, cifra_poly1305_finish);\n}\n\nptls_cipher_algorithm_t ptls_minicrypto_chacha20 = {\n    \"CHACHA20\",           PTLS_CHACHA20_KEY_SIZE, 1 /* block size */, PTLS_CHACHA20_IV_SIZE, sizeof(struct chacha20_context_t),\n    chacha20_setup_crypto};\nptls_aead_algorithm_t ptls_minicrypto_chacha20poly1305 = {\n    \"CHACHA20-POLY1305\",\n    PTLS_CHACHA20POLY1305_CONFIDENTIALITY_LIMIT,\n    PTLS_CHACHA20POLY1305_INTEGRITY_LIMIT,\n    &ptls_minicrypto_chacha20,\n    NULL,\n    PTLS_CHACHA20_KEY_SIZE,\n    PTLS_CHACHA20POLY1305_IV_SIZE,\n    PTLS_CHACHA20POLY1305_TAG_SIZE,\n    {PTLS_TLS12_CHACHAPOLY_FIXED_IV_SIZE, PTLS_TLS12_CHACHAPOLY_RECORD_IV_SIZE},\n    0,\n    0,\n    sizeof(struct cifra_chacha20poly1305_context_t),\n    cifra_chacha20poly1305_setup_crypto};\nptls_cipher_suite_t ptls_minicrypto_chacha20poly1305sha256 = {.id = PTLS_CIPHER_SUITE_CHACHA20_POLY1305_SHA256,\n                                                              .name = PTLS_CIPHER_SUITE_NAME_CHACHA20_POLY1305_SHA256,\n                                                              .aead = &ptls_minicrypto_chacha20poly1305,\n                                                              .hash = &ptls_minicrypto_sha256};",
    "repo": "h2o/h2o",
    "path": "./datasets/diagrams-repos/h2o/h2o/deps/picotls/lib/cifra/chacha20.c",
    "query": "How are the chacha20_context_t and cifra_chacha20poly1305_context_t structures related in terms of inheritance and composition?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'chacha20_context_t', 'node_id': 'chacha20_context_t', 'description': 'Context structure for ChaCha20 cipher operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'cifra_chacha20poly1305_context_t', 'node_id': 'cifra_chacha20poly1305_context_t', 'description': 'Context structure combining ChaCha20 and Poly1305 operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'ptls_cipher_context_t', 'node_id': 'ptls_cipher_context_t', 'description': 'Base cipher context structure', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'chacha20poly1305_context_t', 'node_id': 'chacha20poly1305_context_t', 'description': 'Base context for ChaCha20-Poly1305 operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'cf_chacha20_ctx', 'node_id': 'cf_chacha20_ctx', 'description': \"Cifra library's ChaCha20 context structure\", 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'cf_poly1305', 'node_id': 'cf_poly1305', 'description': \"Cifra library's Poly1305 authentication context\", 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'ptls_minicrypto_chacha20', 'node_id': 'ptls_minicrypto_chacha20', 'description': 'ChaCha20 cipher algorithm implementation', 'visibility': 'public', 'return_type': 'ptls_cipher_algorithm_t', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'ptls_minicrypto_chacha20poly1305', 'node_id': 'ptls_minicrypto_chacha20poly1305', 'description': 'ChaCha20-Poly1305 AEAD algorithm implementation', 'visibility': 'public', 'return_type': 'ptls_aead_algorithm_t', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'chacha20poly1305_setup_crypto', 'node_id': 'chacha20poly1305_setup_crypto', 'description': 'Generic setup function for ChaCha20-Poly1305', 'visibility': 'public', 'return_type': None, 'params': 'ptls_aead_context_t *_ctx, int is_enc, const void *key, const void *iv, ptls_cipher_algorithm_t *chacha, void (*poly1305_init)(struct chacha20poly1305_context_t *, const void *), void (*poly1305_update)(struct chacha20poly1305_context_t *, const void *, size_t), void (*poly1305_finish)(struct chacha20poly1305_context_t *, void *)', 'source_class_id': None}, {'type': 'function', 'name': 'chacha20_setup_crypto', 'node_id': 'chacha20_setup_crypto', 'description': 'Initializes the ChaCha20 context structure', 'visibility': 'public', 'return_type': 'int', 'params': 'ptls_cipher_context_t *_ctx, int is_enc, const void *key', 'source_class_id': None}, {'type': 'function', 'name': 'cifra_chacha20poly1305_setup_crypto', 'node_id': 'cifra_chacha20poly1305_setup_crypto', 'description': 'Sets up the ChaCha20-Poly1305 AEAD context', 'visibility': 'public', 'return_type': 'int', 'params': 'ptls_aead_context_t *ctx, int is_enc, const void *key, const void *iv', 'source_class_id': None}], 'edges': [{'node_id_from': 'chacha20_context_t', 'node_id_to': 'ptls_cipher_context_t', 'description': 'inherits'}, {'node_id_from': 'cifra_chacha20poly1305_context_t', 'node_id_to': 'chacha20poly1305_context_t', 'description': 'inherits'}, {'node_id_from': 'chacha20_context_t', 'node_id_to': 'cf_chacha20_ctx', 'description': 'contains'}, {'node_id_from': 'cifra_chacha20poly1305_context_t', 'node_id_to': 'cf_poly1305', 'description': 'contains'}, {'node_id_from': 'ptls_minicrypto_chacha20', 'node_id_to': 'chacha20_setup_crypto', 'description': 'uses'}, {'node_id_from': 'ptls_minicrypto_chacha20poly1305', 'node_id_to': 'ptls_minicrypto_chacha20', 'description': 'references'}, {'node_id_from': 'chacha20poly1305_setup_crypto', 'node_id_to': 'ptls_minicrypto_chacha20', 'description': 'uses'}, {'node_id_from': 'ptls_minicrypto_chacha20poly1305', 'node_id_to': 'cifra_chacha20poly1305_setup_crypto', 'description': 'uses'}, {'node_id_from': 'chacha20_setup_crypto', 'node_id_to': 'chacha20_context_t', 'description': 'initializes'}, {'node_id_from': 'cifra_chacha20poly1305_setup_crypto', 'node_id_to': 'chacha20poly1305_setup_crypto', 'description': 'calls'}, {'node_id_from': 'cifra_chacha20poly1305_setup_crypto', 'node_id_to': 'cifra_chacha20poly1305_context_t', 'description': 'initializes'}], 'packages': [{'package_id': 'cryptoContexts', 'children': ['chacha20_context_t', 'cifra_chacha20poly1305_context_t', 'ptls_cipher_context_t', 'chacha20poly1305_context_t', 'cf_poly1305', 'cf_chacha20_ctx'], 'description': 'Crypto context structures'}, {'package_id': 'cryptoOperations', 'children': ['chacha20_setup_crypto', 'chacha20poly1305_setup_crypto', 'cifra_chacha20poly1305_setup_crypto'], 'description': 'Cryptographic operation implementations'}, {'package_id': 'cipherSuites', 'children': ['ptls_minicrypto_chacha20', 'ptls_minicrypto_chacha20poly1305'], 'description': 'Cipher suite implementations'}]}",
    "version": "full",
    "text_answer": "chacha20_context_t inherits from ptls_cipher_context_t, while cifra_chacha20poly1305_context_t inherits from chacha20poly1305_context_t. There is no direct inheritance relationship between these two structures, but they are related through their roles in the ChaCha20-Poly1305 cryptographic operations.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C#",
    "code": "\nusing System;\nusing AppKit;\nusing RectangleF = CoreGraphics.CGRect;\nusing System.Linq;\nusing Microsoft.Maui.Controls.Compatibility.Internals;\n\nnamespace Microsoft.Maui.Controls.Compatibility.Platform.MacOS\n{\n\tpublic class Platform : BindableObject, IDisposable\n\t{\n\t\tinternal static readonly BindableProperty RendererProperty = BindableProperty.CreateAttached(\"Renderer\",\n\t\t\ttypeof(IVisualElementRenderer), typeof(Platform), default(IVisualElementRenderer),\n\t\t\tpropertyChanged: (bindable, oldvalue, newvalue) =>\n\t\t\t{\n\t\t\t\tvar view = bindable as VisualElement;\n\t\t\t\tif (view != null)\n\t\t\t\t\tview.IsPlatformEnabled = newvalue != null;\n\t\t\t});\n\n\t\treadonly PlatformRenderer _renderer;\n\n\t\tbool _appeared;\n\t\tbool _disposed;\n\n\t\tinternal static NativeToolbarTracker NativeToolbarTracker = new NativeToolbarTracker();\n\n\t\tinternal Platform()\n\t\t{\n\t\t\t_renderer = new PlatformRenderer(this);\n\n\t\t\tMessagingCenter.Subscribe(this, Page.AlertSignalName, (Page sender, AlertArguments arguments) =>\n\t\t\t{\n\t\t\t\tvar alert = NSAlert.WithMessage(arguments.Title, arguments.Cancel, arguments.Accept, null, arguments.Message);\n\t\t\t\tvar result = alert.RunSheetModal(_renderer.View.Window);\n\t\t\t\tif (arguments.Accept == null)\n\t\t\t\t\targuments.SetResult(result == 1);\n\t\t\t\telse\n\t\t\t\t\targuments.SetResult(result == 0);\n\t\t\t});\n\n\t\t\tMessagingCenter.Subscribe(this, Page.ActionSheetSignalName, (Page sender, ActionSheetArguments arguments) =>\n\t\t\t{\n\t\t\t\tvar alert = NSAlert.WithMessage(arguments.Title, arguments.Cancel, arguments.Destruction, null, \"\");\n\t\t\t\tif (arguments.Buttons != null)\n\t\t\t\t{\n\t\t\t\t\tint maxScrollHeight = (int)(0.6 * NSScreen.MainScreen.Frame.Height);\n\t\t\t\t\tNSView extraButtons = GetExtraButton(arguments);\n\t\t\t\t\tif (extraButtons.Frame.Height > maxScrollHeight)\n\t\t\t\t\t{\n\t\t\t\t\t\tNSScrollView scrollView = new NSScrollView();\n\t\t\t\t\t\tscrollView.Frame = new RectangleF(0, 0, extraButtons.Frame.Width, maxScrollHeight);\n\t\t\t\t\t\tscrollView.DocumentView = extraButtons;\n\t\t\t\t\t\tscrollView.HasVerticalScroller = true;\n\t\t\t\t\t\talert.AccessoryView = scrollView;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\talert.AccessoryView = extraButtons;\n\t\t\t\t\t}\n\t\t\t\t\talert.Layout();\n\t\t\t\t}\n\n\t\t\t\tvar result = (int)alert.RunSheetModal(_renderer.View.Window);\n\t\t\t\tvar titleResult = string.Empty;\n\t\t\t\tif (result == 1)\n\t\t\t\t\ttitleResult = arguments.Cancel;\n\t\t\t\telse if (result == 0)\n\t\t\t\t\ttitleResult = arguments.Destruction;\n\t\t\t\telse if (result > 1 && arguments.Buttons != null && result - 2 <= arguments.Buttons.Count())\n\t\t\t\t\ttitleResult = arguments.Buttons.ElementAt(result - 2);\n\n\t\t\t\targuments.SetResult(titleResult);\n\t\t\t});\n\t\t}\n\n\t\tpublic static SizeRequest GetNativeSize(VisualElement view, double widthConstraint, double heightConstraint)\n\t\t{\n\t\t\tvar renderView = GetRenderer(view);\n\t\t\tif (renderView == null || renderView.NativeView == null)\n\t\t\t\treturn new SizeRequest(Size.Zero);\n\n\t\t\treturn renderView.GetDesiredSize(widthConstraint, heightConstraint);\n\t\t}\n\n\t\tPage Page { get; set; }\n\n\t\tApplication TargetApplication\n\t\t{\n\t\t\tget\n\t\t\t{\n\t\t\t\tif (Page == null)\n\t\t\t\t\treturn null;\n\t\t\t\treturn Page.RealParent as Application;\n\t\t\t}\n\t\t}\n\n\t\tvoid IDisposable.Dispose()\n\t\t{\n\t\t\tif (_disposed)\n\t\t\t\treturn;\n\t\t\t_disposed = true;\n\n\t\t\tPage.DescendantRemoved -= HandleChildRemoved;\n\t\t\tMessagingCenter.Unsubscribe<Page, ActionSheetArguments>(this, Page.ActionSheetSignalName);\n\t\t\tMessagingCenter.Unsubscribe<Page, AlertArguments>(this, Page.AlertSignalName);\n\t\t\tMessagingCenter.Unsubscribe<Page, bool>(this, Page.BusySetSignalName);\n\n\t\t\tPage.DisposeModalAndChildRenderers();\n\t\t\t//foreach (var modal in _modals)\n\t\t\t//modal.DisposeModalAndChildRenderers();\n\t\t\t_renderer.Dispose();\n\t\t}\n\n\t\tpublic static IVisualElementRenderer CreateRenderer(VisualElement element)\n\t\t{\n\t\t\tvar renderer = Internals.Registrar.Registered.GetHandlerForObject<IVisualElementRenderer>(element) ?? new DefaultRenderer();\n\t\t\trenderer.SetElement(element);\n\t\t\treturn renderer;\n\t\t}\n\n\t\tpublic static IVisualElementRenderer GetRenderer(VisualElement bindable)\n\t\t{\n\t\t\treturn (IVisualElementRenderer)bindable.GetValue(RendererProperty);\n\t\t}\n\n\t\tpublic static void SetRenderer(VisualElement bindable, IVisualElementRenderer value)\n\t\t{\n\t\t\tbindable.SetValue(RendererProperty, value);\n\t\t}\n\n\t\tprotected override void OnBindingContextChanged()\n\t\t{\n\t\t\tSetInheritedBindingContext(Page, BindingContext);\n\n\t\t\tbase.OnBindingContextChanged();\n\t\t}\n\n\t\tinternal NSViewController ViewController => _renderer;\n\n\t\tinternal void LayoutSubviews()\n\t\t{\n\t\t\tif (Page == null)\n\t\t\t\treturn;\n\n\t\t\tvar rootRenderer = GetRenderer(Page);\n\n\t\t\tif (rootRenderer == null)\n\t\t\t\treturn;\n\n\t\t\trootRenderer.SetElementSize(new Size(_renderer.View.Bounds.Width, _renderer.View.Bounds.Height));\n\t\t}\n\n\t\tinternal void SetPage(Page newRoot)\n\t\t{\n\t\t\tif (newRoot == null)\n\t\t\t\treturn;\n\t\t\tif (Page != null)\n\t\t\t\tthrow new NotImplementedException();\n\t\t\tPage = newRoot;\n\n\t\t\tif (_appeared == false)\n\t\t\t\treturn;\n\n\t\t\tAddChild(Page);\n\n\t\t\tPage.DescendantRemoved += HandleChildRemoved;\n\n\t\t\tTargetApplication.NavigationProxy.Inner = _renderer.Navigation;\n\t\t}\n\n\t\tinternal void DidAppear()\n\t\t{\n\t\t\t_renderer.Navigation.AnimateModalPages = false;\n\t\t\tTargetApplication.NavigationProxy.Inner = _renderer.Navigation;\n\t\t\t_renderer.Navigation.AnimateModalPages = true;\n\t\t}\n\n\t\tinternal void WillAppear()\n\t\t{\n\t\t\tif (_appeared)\n\t\t\t\treturn;\n\n\t\t\tAddChild(Page);\n\n\t\t\tPage.DescendantRemoved += HandleChildRemoved;\n\n\t\t\t_appeared = true;\n\t\t}\n\n\t\tstatic NSView GetExtraButton(ActionSheetArguments arguments)\n\t\t{\n\t\t\tvar newView = new NSView();\n\t\t\tint height = 50;\n\t\t\tint width = 300;\n\t\t\tint i = 0;\n\t\t\tforeach (var button in arguments.Buttons)\n\t\t\t{\n\t\t\t\tvar btn = new NSButton { Title = button, Tag = i };\n\t\t\t\tbtn.SetButtonType(NSButtonType.MomentaryPushIn);\n\t\t\t\tbtn.Activated +=\n\t\t\t\t\t(s, e) =>\n\t\t\t\t\t{\n\t\t\t\t\t\tNSApplication.SharedApplication.EndSheet(NSApplication.SharedApplication.MainWindow.AttachedSheet,\n\t\t\t\t\t\t\t((NSButton)s).Tag + 2);\n\t\t\t\t\t};\n\t\t\t\tbtn.Frame = new RectangleF(0, height * i, width, height);\n\t\t\t\tnewView.AddSubview(btn);\n\t\t\t\ti++;\n\t\t\t}\n\t\t\tnewView.Frame = new RectangleF(0, 0, width, height * i);\n\t\t\treturn newView;\n\t\t}\n\n\t\tvoid AddChild(VisualElement view)\n\t\t{\n\t\t\tif (!Application.IsApplicationOrNull(view.RealParent))\n\t\t\t\tConsole.Error.WriteLine(\"Tried to add parented view to canvas directly\");\n\n\t\t\tif (GetRenderer(view) == null)\n\t\t\t{\n\t\t\t\tvar viewRenderer = CreateRenderer(view);\n\t\t\t\tSetRenderer(view, viewRenderer);\n\n\t\t\t\t_renderer.View.AddSubview(viewRenderer.NativeView);\n\t\t\t\tif (viewRenderer.ViewController != null)\n\t\t\t\t\t_renderer.AddChildViewController(viewRenderer.ViewController);\n\t\t\t\tviewRenderer.SetElementSize(new Size(_renderer.View.Bounds.Width, _renderer.View.Bounds.Height));\n\t\t\t}\n\t\t\telse\n\t\t\t\tConsole.Error.WriteLine(\"A Renderer was already found, potential view double add\");\n\t\t}\n\n\t\tvoid HandleChildRemoved(object sender, ElementEventArgs e)\n\t\t{\n\t\t\tvar view = e.Element;\n\t\t\tview.DisposeModalAndChildRenderers();\n\t\t}\n\t}\n}",
    "repo": "dotnet/maui",
    "path": "./datasets/diagrams-repos/dotnet/maui/src/Compatibility/Core/src/MacOS/Platform.cs",
    "query": "How are renderers attached to visual elements in the Platform class?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'Platform', 'node_id': 'Platform', 'description': 'Core class managing renderer attachment to visual elements', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'RendererProperty', 'node_id': 'RendererProperty', 'description': 'Bindable property storing renderer for visual element', 'visibility': 'private', 'return_type': 'BindableProperty', 'params': None, 'source_class_id': 'Platform'}, {'type': 'method', 'name': 'CreateRenderer', 'node_id': 'CreateRenderer', 'description': 'Creates new renderer for visual element', 'visibility': 'public', 'return_type': 'IVisualElementRenderer', 'params': 'VisualElement element', 'source_class_id': 'Platform'}, {'type': 'method', 'name': 'SetRenderer', 'node_id': 'SetRenderer', 'description': 'Attaches renderer to visual element', 'visibility': 'public', 'return_type': 'void', 'params': 'VisualElement bindable, IVisualElementRenderer value', 'source_class_id': 'Platform'}], 'edges': [{'node_id_from': 'CreateRenderer', 'node_id_to': 'SetRenderer', 'description': 'calls'}, {'node_id_from': 'SetRenderer', 'node_id_to': 'RendererProperty', 'description': 'uses'}, {'node_id_from': 'Platform', 'node_id_to': 'CreateRenderer', 'description': ''}, {'node_id_from': 'Platform', 'node_id_to': 'RendererProperty', 'description': ''}, {'node_id_from': 'Platform', 'node_id_to': 'SetRenderer', 'description': ''}], 'packages': [{'package_id': 'rendererManagement', 'children': ['CreateRenderer', 'SetRenderer', 'RendererProperty'], 'description': 'Core renderer management functionality'}]}",
    "version": "minimal",
    "text_answer": "Renderers are attached to visual elements through the RendererProperty bindable property. The CreateRenderer method creates a new renderer for an element, and SetRenderer method attaches it by setting the RendererProperty value. This process is primarily managed when adding child views through the AddChild method.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C#",
    "code": "\nusing System;\nusing AppKit;\nusing RectangleF = CoreGraphics.CGRect;\nusing System.Linq;\nusing Microsoft.Maui.Controls.Compatibility.Internals;\n\nnamespace Microsoft.Maui.Controls.Compatibility.Platform.MacOS\n{\n\tpublic class Platform : BindableObject, IDisposable\n\t{\n\t\tinternal static readonly BindableProperty RendererProperty = BindableProperty.CreateAttached(\"Renderer\",\n\t\t\ttypeof(IVisualElementRenderer), typeof(Platform), default(IVisualElementRenderer),\n\t\t\tpropertyChanged: (bindable, oldvalue, newvalue) =>\n\t\t\t{\n\t\t\t\tvar view = bindable as VisualElement;\n\t\t\t\tif (view != null)\n\t\t\t\t\tview.IsPlatformEnabled = newvalue != null;\n\t\t\t});\n\n\t\treadonly PlatformRenderer _renderer;\n\n\t\tbool _appeared;\n\t\tbool _disposed;\n\n\t\tinternal static NativeToolbarTracker NativeToolbarTracker = new NativeToolbarTracker();\n\n\t\tinternal Platform()\n\t\t{\n\t\t\t_renderer = new PlatformRenderer(this);\n\n\t\t\tMessagingCenter.Subscribe(this, Page.AlertSignalName, (Page sender, AlertArguments arguments) =>\n\t\t\t{\n\t\t\t\tvar alert = NSAlert.WithMessage(arguments.Title, arguments.Cancel, arguments.Accept, null, arguments.Message);\n\t\t\t\tvar result = alert.RunSheetModal(_renderer.View.Window);\n\t\t\t\tif (arguments.Accept == null)\n\t\t\t\t\targuments.SetResult(result == 1);\n\t\t\t\telse\n\t\t\t\t\targuments.SetResult(result == 0);\n\t\t\t});\n\n\t\t\tMessagingCenter.Subscribe(this, Page.ActionSheetSignalName, (Page sender, ActionSheetArguments arguments) =>\n\t\t\t{\n\t\t\t\tvar alert = NSAlert.WithMessage(arguments.Title, arguments.Cancel, arguments.Destruction, null, \"\");\n\t\t\t\tif (arguments.Buttons != null)\n\t\t\t\t{\n\t\t\t\t\tint maxScrollHeight = (int)(0.6 * NSScreen.MainScreen.Frame.Height);\n\t\t\t\t\tNSView extraButtons = GetExtraButton(arguments);\n\t\t\t\t\tif (extraButtons.Frame.Height > maxScrollHeight)\n\t\t\t\t\t{\n\t\t\t\t\t\tNSScrollView scrollView = new NSScrollView();\n\t\t\t\t\t\tscrollView.Frame = new RectangleF(0, 0, extraButtons.Frame.Width, maxScrollHeight);\n\t\t\t\t\t\tscrollView.DocumentView = extraButtons;\n\t\t\t\t\t\tscrollView.HasVerticalScroller = true;\n\t\t\t\t\t\talert.AccessoryView = scrollView;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\talert.AccessoryView = extraButtons;\n\t\t\t\t\t}\n\t\t\t\t\talert.Layout();\n\t\t\t\t}\n\n\t\t\t\tvar result = (int)alert.RunSheetModal(_renderer.View.Window);\n\t\t\t\tvar titleResult = string.Empty;\n\t\t\t\tif (result == 1)\n\t\t\t\t\ttitleResult = arguments.Cancel;\n\t\t\t\telse if (result == 0)\n\t\t\t\t\ttitleResult = arguments.Destruction;\n\t\t\t\telse if (result > 1 && arguments.Buttons != null && result - 2 <= arguments.Buttons.Count())\n\t\t\t\t\ttitleResult = arguments.Buttons.ElementAt(result - 2);\n\n\t\t\t\targuments.SetResult(titleResult);\n\t\t\t});\n\t\t}\n\n\t\tpublic static SizeRequest GetNativeSize(VisualElement view, double widthConstraint, double heightConstraint)\n\t\t{\n\t\t\tvar renderView = GetRenderer(view);\n\t\t\tif (renderView == null || renderView.NativeView == null)\n\t\t\t\treturn new SizeRequest(Size.Zero);\n\n\t\t\treturn renderView.GetDesiredSize(widthConstraint, heightConstraint);\n\t\t}\n\n\t\tPage Page { get; set; }\n\n\t\tApplication TargetApplication\n\t\t{\n\t\t\tget\n\t\t\t{\n\t\t\t\tif (Page == null)\n\t\t\t\t\treturn null;\n\t\t\t\treturn Page.RealParent as Application;\n\t\t\t}\n\t\t}\n\n\t\tvoid IDisposable.Dispose()\n\t\t{\n\t\t\tif (_disposed)\n\t\t\t\treturn;\n\t\t\t_disposed = true;\n\n\t\t\tPage.DescendantRemoved -= HandleChildRemoved;\n\t\t\tMessagingCenter.Unsubscribe<Page, ActionSheetArguments>(this, Page.ActionSheetSignalName);\n\t\t\tMessagingCenter.Unsubscribe<Page, AlertArguments>(this, Page.AlertSignalName);\n\t\t\tMessagingCenter.Unsubscribe<Page, bool>(this, Page.BusySetSignalName);\n\n\t\t\tPage.DisposeModalAndChildRenderers();\n\t\t\t//foreach (var modal in _modals)\n\t\t\t//modal.DisposeModalAndChildRenderers();\n\t\t\t_renderer.Dispose();\n\t\t}\n\n\t\tpublic static IVisualElementRenderer CreateRenderer(VisualElement element)\n\t\t{\n\t\t\tvar renderer = Internals.Registrar.Registered.GetHandlerForObject<IVisualElementRenderer>(element) ?? new DefaultRenderer();\n\t\t\trenderer.SetElement(element);\n\t\t\treturn renderer;\n\t\t}\n\n\t\tpublic static IVisualElementRenderer GetRenderer(VisualElement bindable)\n\t\t{\n\t\t\treturn (IVisualElementRenderer)bindable.GetValue(RendererProperty);\n\t\t}\n\n\t\tpublic static void SetRenderer(VisualElement bindable, IVisualElementRenderer value)\n\t\t{\n\t\t\tbindable.SetValue(RendererProperty, value);\n\t\t}\n\n\t\tprotected override void OnBindingContextChanged()\n\t\t{\n\t\t\tSetInheritedBindingContext(Page, BindingContext);\n\n\t\t\tbase.OnBindingContextChanged();\n\t\t}\n\n\t\tinternal NSViewController ViewController => _renderer;\n\n\t\tinternal void LayoutSubviews()\n\t\t{\n\t\t\tif (Page == null)\n\t\t\t\treturn;\n\n\t\t\tvar rootRenderer = GetRenderer(Page);\n\n\t\t\tif (rootRenderer == null)\n\t\t\t\treturn;\n\n\t\t\trootRenderer.SetElementSize(new Size(_renderer.View.Bounds.Width, _renderer.View.Bounds.Height));\n\t\t}\n\n\t\tinternal void SetPage(Page newRoot)\n\t\t{\n\t\t\tif (newRoot == null)\n\t\t\t\treturn;\n\t\t\tif (Page != null)\n\t\t\t\tthrow new NotImplementedException();\n\t\t\tPage = newRoot;\n\n\t\t\tif (_appeared == false)\n\t\t\t\treturn;\n\n\t\t\tAddChild(Page);\n\n\t\t\tPage.DescendantRemoved += HandleChildRemoved;\n\n\t\t\tTargetApplication.NavigationProxy.Inner = _renderer.Navigation;\n\t\t}\n\n\t\tinternal void DidAppear()\n\t\t{\n\t\t\t_renderer.Navigation.AnimateModalPages = false;\n\t\t\tTargetApplication.NavigationProxy.Inner = _renderer.Navigation;\n\t\t\t_renderer.Navigation.AnimateModalPages = true;\n\t\t}\n\n\t\tinternal void WillAppear()\n\t\t{\n\t\t\tif (_appeared)\n\t\t\t\treturn;\n\n\t\t\tAddChild(Page);\n\n\t\t\tPage.DescendantRemoved += HandleChildRemoved;\n\n\t\t\t_appeared = true;\n\t\t}\n\n\t\tstatic NSView GetExtraButton(ActionSheetArguments arguments)\n\t\t{\n\t\t\tvar newView = new NSView();\n\t\t\tint height = 50;\n\t\t\tint width = 300;\n\t\t\tint i = 0;\n\t\t\tforeach (var button in arguments.Buttons)\n\t\t\t{\n\t\t\t\tvar btn = new NSButton { Title = button, Tag = i };\n\t\t\t\tbtn.SetButtonType(NSButtonType.MomentaryPushIn);\n\t\t\t\tbtn.Activated +=\n\t\t\t\t\t(s, e) =>\n\t\t\t\t\t{\n\t\t\t\t\t\tNSApplication.SharedApplication.EndSheet(NSApplication.SharedApplication.MainWindow.AttachedSheet,\n\t\t\t\t\t\t\t((NSButton)s).Tag + 2);\n\t\t\t\t\t};\n\t\t\t\tbtn.Frame = new RectangleF(0, height * i, width, height);\n\t\t\t\tnewView.AddSubview(btn);\n\t\t\t\ti++;\n\t\t\t}\n\t\t\tnewView.Frame = new RectangleF(0, 0, width, height * i);\n\t\t\treturn newView;\n\t\t}\n\n\t\tvoid AddChild(VisualElement view)\n\t\t{\n\t\t\tif (!Application.IsApplicationOrNull(view.RealParent))\n\t\t\t\tConsole.Error.WriteLine(\"Tried to add parented view to canvas directly\");\n\n\t\t\tif (GetRenderer(view) == null)\n\t\t\t{\n\t\t\t\tvar viewRenderer = CreateRenderer(view);\n\t\t\t\tSetRenderer(view, viewRenderer);\n\n\t\t\t\t_renderer.View.AddSubview(viewRenderer.NativeView);\n\t\t\t\tif (viewRenderer.ViewController != null)\n\t\t\t\t\t_renderer.AddChildViewController(viewRenderer.ViewController);\n\t\t\t\tviewRenderer.SetElementSize(new Size(_renderer.View.Bounds.Width, _renderer.View.Bounds.Height));\n\t\t\t}\n\t\t\telse\n\t\t\t\tConsole.Error.WriteLine(\"A Renderer was already found, potential view double add\");\n\t\t}\n\n\t\tvoid HandleChildRemoved(object sender, ElementEventArgs e)\n\t\t{\n\t\t\tvar view = e.Element;\n\t\t\tview.DisposeModalAndChildRenderers();\n\t\t}\n\t}\n}",
    "repo": "dotnet/maui",
    "path": "./datasets/diagrams-repos/dotnet/maui/src/Compatibility/Core/src/MacOS/Platform.cs",
    "query": "How are renderers attached to visual elements in the Platform class?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'Platform', 'node_id': 'Platform', 'description': 'Core class managing renderer attachment to visual elements', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'RendererProperty', 'node_id': 'RendererProperty', 'description': 'Bindable property storing renderer for visual element', 'visibility': 'private', 'return_type': 'BindableProperty', 'params': None, 'source_class_id': 'Platform'}, {'type': 'method', 'name': 'CreateRenderer', 'node_id': 'CreateRenderer', 'description': 'Creates new renderer for visual element', 'visibility': 'public', 'return_type': 'IVisualElementRenderer', 'params': 'VisualElement element', 'source_class_id': 'Platform'}, {'type': 'method', 'name': 'SetRenderer', 'node_id': 'SetRenderer', 'description': 'Attaches renderer to visual element', 'visibility': 'public', 'return_type': 'void', 'params': 'VisualElement bindable, IVisualElementRenderer value', 'source_class_id': 'Platform'}, {'type': 'method', 'name': 'GetRenderer', 'node_id': 'GetRenderer', 'description': 'Retrieves renderer for visual element', 'visibility': 'public', 'return_type': 'IVisualElementRenderer', 'params': 'VisualElement bindable', 'source_class_id': 'Platform'}, {'type': 'method', 'name': 'AddChild', 'node_id': 'AddChild', 'description': 'Adds child view and creates renderer if needed', 'visibility': 'private', 'return_type': 'void', 'params': 'VisualElement view', 'source_class_id': 'Platform'}], 'edges': [{'node_id_from': 'CreateRenderer', 'node_id_to': 'SetRenderer', 'description': 'calls'}, {'node_id_from': 'SetRenderer', 'node_id_to': 'RendererProperty', 'description': 'uses'}, {'node_id_from': 'GetRenderer', 'node_id_to': 'RendererProperty', 'description': 'reads'}, {'node_id_from': 'AddChild', 'node_id_to': 'CreateRenderer', 'description': 'calls'}, {'node_id_from': 'AddChild', 'node_id_to': 'SetRenderer', 'description': 'calls'}, {'node_id_from': 'Platform', 'node_id_to': 'CreateRenderer', 'description': ''}, {'node_id_from': 'Platform', 'node_id_to': 'RendererProperty', 'description': ''}, {'node_id_from': 'Platform', 'node_id_to': 'SetRenderer', 'description': ''}, {'node_id_from': 'Platform', 'node_id_to': 'GetRenderer', 'description': ''}, {'node_id_from': 'Platform', 'node_id_to': 'AddChild', 'description': ''}], 'packages': [{'package_id': 'rendererManagement', 'children': ['CreateRenderer', 'SetRenderer', 'GetRenderer', 'RendererProperty'], 'description': 'Core renderer management functionality'}]}",
    "version": "medium",
    "text_answer": "Renderers are attached to visual elements through the RendererProperty bindable property. The CreateRenderer method creates a new renderer for an element, and SetRenderer method attaches it by setting the RendererProperty value. This process is primarily managed when adding child views through the AddChild method.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C#",
    "code": "\nusing System;\nusing AppKit;\nusing RectangleF = CoreGraphics.CGRect;\nusing System.Linq;\nusing Microsoft.Maui.Controls.Compatibility.Internals;\n\nnamespace Microsoft.Maui.Controls.Compatibility.Platform.MacOS\n{\n\tpublic class Platform : BindableObject, IDisposable\n\t{\n\t\tinternal static readonly BindableProperty RendererProperty = BindableProperty.CreateAttached(\"Renderer\",\n\t\t\ttypeof(IVisualElementRenderer), typeof(Platform), default(IVisualElementRenderer),\n\t\t\tpropertyChanged: (bindable, oldvalue, newvalue) =>\n\t\t\t{\n\t\t\t\tvar view = bindable as VisualElement;\n\t\t\t\tif (view != null)\n\t\t\t\t\tview.IsPlatformEnabled = newvalue != null;\n\t\t\t});\n\n\t\treadonly PlatformRenderer _renderer;\n\n\t\tbool _appeared;\n\t\tbool _disposed;\n\n\t\tinternal static NativeToolbarTracker NativeToolbarTracker = new NativeToolbarTracker();\n\n\t\tinternal Platform()\n\t\t{\n\t\t\t_renderer = new PlatformRenderer(this);\n\n\t\t\tMessagingCenter.Subscribe(this, Page.AlertSignalName, (Page sender, AlertArguments arguments) =>\n\t\t\t{\n\t\t\t\tvar alert = NSAlert.WithMessage(arguments.Title, arguments.Cancel, arguments.Accept, null, arguments.Message);\n\t\t\t\tvar result = alert.RunSheetModal(_renderer.View.Window);\n\t\t\t\tif (arguments.Accept == null)\n\t\t\t\t\targuments.SetResult(result == 1);\n\t\t\t\telse\n\t\t\t\t\targuments.SetResult(result == 0);\n\t\t\t});\n\n\t\t\tMessagingCenter.Subscribe(this, Page.ActionSheetSignalName, (Page sender, ActionSheetArguments arguments) =>\n\t\t\t{\n\t\t\t\tvar alert = NSAlert.WithMessage(arguments.Title, arguments.Cancel, arguments.Destruction, null, \"\");\n\t\t\t\tif (arguments.Buttons != null)\n\t\t\t\t{\n\t\t\t\t\tint maxScrollHeight = (int)(0.6 * NSScreen.MainScreen.Frame.Height);\n\t\t\t\t\tNSView extraButtons = GetExtraButton(arguments);\n\t\t\t\t\tif (extraButtons.Frame.Height > maxScrollHeight)\n\t\t\t\t\t{\n\t\t\t\t\t\tNSScrollView scrollView = new NSScrollView();\n\t\t\t\t\t\tscrollView.Frame = new RectangleF(0, 0, extraButtons.Frame.Width, maxScrollHeight);\n\t\t\t\t\t\tscrollView.DocumentView = extraButtons;\n\t\t\t\t\t\tscrollView.HasVerticalScroller = true;\n\t\t\t\t\t\talert.AccessoryView = scrollView;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\talert.AccessoryView = extraButtons;\n\t\t\t\t\t}\n\t\t\t\t\talert.Layout();\n\t\t\t\t}\n\n\t\t\t\tvar result = (int)alert.RunSheetModal(_renderer.View.Window);\n\t\t\t\tvar titleResult = string.Empty;\n\t\t\t\tif (result == 1)\n\t\t\t\t\ttitleResult = arguments.Cancel;\n\t\t\t\telse if (result == 0)\n\t\t\t\t\ttitleResult = arguments.Destruction;\n\t\t\t\telse if (result > 1 && arguments.Buttons != null && result - 2 <= arguments.Buttons.Count())\n\t\t\t\t\ttitleResult = arguments.Buttons.ElementAt(result - 2);\n\n\t\t\t\targuments.SetResult(titleResult);\n\t\t\t});\n\t\t}\n\n\t\tpublic static SizeRequest GetNativeSize(VisualElement view, double widthConstraint, double heightConstraint)\n\t\t{\n\t\t\tvar renderView = GetRenderer(view);\n\t\t\tif (renderView == null || renderView.NativeView == null)\n\t\t\t\treturn new SizeRequest(Size.Zero);\n\n\t\t\treturn renderView.GetDesiredSize(widthConstraint, heightConstraint);\n\t\t}\n\n\t\tPage Page { get; set; }\n\n\t\tApplication TargetApplication\n\t\t{\n\t\t\tget\n\t\t\t{\n\t\t\t\tif (Page == null)\n\t\t\t\t\treturn null;\n\t\t\t\treturn Page.RealParent as Application;\n\t\t\t}\n\t\t}\n\n\t\tvoid IDisposable.Dispose()\n\t\t{\n\t\t\tif (_disposed)\n\t\t\t\treturn;\n\t\t\t_disposed = true;\n\n\t\t\tPage.DescendantRemoved -= HandleChildRemoved;\n\t\t\tMessagingCenter.Unsubscribe<Page, ActionSheetArguments>(this, Page.ActionSheetSignalName);\n\t\t\tMessagingCenter.Unsubscribe<Page, AlertArguments>(this, Page.AlertSignalName);\n\t\t\tMessagingCenter.Unsubscribe<Page, bool>(this, Page.BusySetSignalName);\n\n\t\t\tPage.DisposeModalAndChildRenderers();\n\t\t\t//foreach (var modal in _modals)\n\t\t\t//modal.DisposeModalAndChildRenderers();\n\t\t\t_renderer.Dispose();\n\t\t}\n\n\t\tpublic static IVisualElementRenderer CreateRenderer(VisualElement element)\n\t\t{\n\t\t\tvar renderer = Internals.Registrar.Registered.GetHandlerForObject<IVisualElementRenderer>(element) ?? new DefaultRenderer();\n\t\t\trenderer.SetElement(element);\n\t\t\treturn renderer;\n\t\t}\n\n\t\tpublic static IVisualElementRenderer GetRenderer(VisualElement bindable)\n\t\t{\n\t\t\treturn (IVisualElementRenderer)bindable.GetValue(RendererProperty);\n\t\t}\n\n\t\tpublic static void SetRenderer(VisualElement bindable, IVisualElementRenderer value)\n\t\t{\n\t\t\tbindable.SetValue(RendererProperty, value);\n\t\t}\n\n\t\tprotected override void OnBindingContextChanged()\n\t\t{\n\t\t\tSetInheritedBindingContext(Page, BindingContext);\n\n\t\t\tbase.OnBindingContextChanged();\n\t\t}\n\n\t\tinternal NSViewController ViewController => _renderer;\n\n\t\tinternal void LayoutSubviews()\n\t\t{\n\t\t\tif (Page == null)\n\t\t\t\treturn;\n\n\t\t\tvar rootRenderer = GetRenderer(Page);\n\n\t\t\tif (rootRenderer == null)\n\t\t\t\treturn;\n\n\t\t\trootRenderer.SetElementSize(new Size(_renderer.View.Bounds.Width, _renderer.View.Bounds.Height));\n\t\t}\n\n\t\tinternal void SetPage(Page newRoot)\n\t\t{\n\t\t\tif (newRoot == null)\n\t\t\t\treturn;\n\t\t\tif (Page != null)\n\t\t\t\tthrow new NotImplementedException();\n\t\t\tPage = newRoot;\n\n\t\t\tif (_appeared == false)\n\t\t\t\treturn;\n\n\t\t\tAddChild(Page);\n\n\t\t\tPage.DescendantRemoved += HandleChildRemoved;\n\n\t\t\tTargetApplication.NavigationProxy.Inner = _renderer.Navigation;\n\t\t}\n\n\t\tinternal void DidAppear()\n\t\t{\n\t\t\t_renderer.Navigation.AnimateModalPages = false;\n\t\t\tTargetApplication.NavigationProxy.Inner = _renderer.Navigation;\n\t\t\t_renderer.Navigation.AnimateModalPages = true;\n\t\t}\n\n\t\tinternal void WillAppear()\n\t\t{\n\t\t\tif (_appeared)\n\t\t\t\treturn;\n\n\t\t\tAddChild(Page);\n\n\t\t\tPage.DescendantRemoved += HandleChildRemoved;\n\n\t\t\t_appeared = true;\n\t\t}\n\n\t\tstatic NSView GetExtraButton(ActionSheetArguments arguments)\n\t\t{\n\t\t\tvar newView = new NSView();\n\t\t\tint height = 50;\n\t\t\tint width = 300;\n\t\t\tint i = 0;\n\t\t\tforeach (var button in arguments.Buttons)\n\t\t\t{\n\t\t\t\tvar btn = new NSButton { Title = button, Tag = i };\n\t\t\t\tbtn.SetButtonType(NSButtonType.MomentaryPushIn);\n\t\t\t\tbtn.Activated +=\n\t\t\t\t\t(s, e) =>\n\t\t\t\t\t{\n\t\t\t\t\t\tNSApplication.SharedApplication.EndSheet(NSApplication.SharedApplication.MainWindow.AttachedSheet,\n\t\t\t\t\t\t\t((NSButton)s).Tag + 2);\n\t\t\t\t\t};\n\t\t\t\tbtn.Frame = new RectangleF(0, height * i, width, height);\n\t\t\t\tnewView.AddSubview(btn);\n\t\t\t\ti++;\n\t\t\t}\n\t\t\tnewView.Frame = new RectangleF(0, 0, width, height * i);\n\t\t\treturn newView;\n\t\t}\n\n\t\tvoid AddChild(VisualElement view)\n\t\t{\n\t\t\tif (!Application.IsApplicationOrNull(view.RealParent))\n\t\t\t\tConsole.Error.WriteLine(\"Tried to add parented view to canvas directly\");\n\n\t\t\tif (GetRenderer(view) == null)\n\t\t\t{\n\t\t\t\tvar viewRenderer = CreateRenderer(view);\n\t\t\t\tSetRenderer(view, viewRenderer);\n\n\t\t\t\t_renderer.View.AddSubview(viewRenderer.NativeView);\n\t\t\t\tif (viewRenderer.ViewController != null)\n\t\t\t\t\t_renderer.AddChildViewController(viewRenderer.ViewController);\n\t\t\t\tviewRenderer.SetElementSize(new Size(_renderer.View.Bounds.Width, _renderer.View.Bounds.Height));\n\t\t\t}\n\t\t\telse\n\t\t\t\tConsole.Error.WriteLine(\"A Renderer was already found, potential view double add\");\n\t\t}\n\n\t\tvoid HandleChildRemoved(object sender, ElementEventArgs e)\n\t\t{\n\t\t\tvar view = e.Element;\n\t\t\tview.DisposeModalAndChildRenderers();\n\t\t}\n\t}\n}",
    "repo": "dotnet/maui",
    "path": "./datasets/diagrams-repos/dotnet/maui/src/Compatibility/Core/src/MacOS/Platform.cs",
    "query": "How are renderers attached to visual elements in the Platform class?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'Platform', 'node_id': 'Platform', 'description': 'Core class managing renderer attachment to visual elements', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'RendererProperty', 'node_id': 'RendererProperty', 'description': 'Bindable property storing renderer for visual element', 'visibility': 'private', 'return_type': 'BindableProperty', 'params': None, 'source_class_id': 'Platform'}, {'type': 'field', 'name': '_renderer', 'node_id': '_renderer', 'description': 'Platform renderer instance', 'visibility': 'private', 'return_type': 'PlatformRenderer', 'params': None, 'source_class_id': 'Platform'}, {'type': 'method', 'name': 'CreateRenderer', 'node_id': 'CreateRenderer', 'description': 'Creates new renderer for visual element', 'visibility': 'public', 'return_type': 'IVisualElementRenderer', 'params': 'VisualElement element', 'source_class_id': 'Platform'}, {'type': 'method', 'name': 'SetRenderer', 'node_id': 'SetRenderer', 'description': 'Attaches renderer to visual element', 'visibility': 'public', 'return_type': 'void', 'params': 'VisualElement bindable, IVisualElementRenderer value', 'source_class_id': 'Platform'}, {'type': 'method', 'name': 'GetRenderer', 'node_id': 'GetRenderer', 'description': 'Retrieves renderer for visual element', 'visibility': 'public', 'return_type': 'IVisualElementRenderer', 'params': 'VisualElement bindable', 'source_class_id': 'Platform'}, {'type': 'method', 'name': 'AddChild', 'node_id': 'AddChild', 'description': 'Adds child view and creates renderer if needed', 'visibility': 'private', 'return_type': 'void', 'params': 'VisualElement view', 'source_class_id': 'Platform'}, {'type': 'method', 'name': 'SetPage', 'node_id': 'SetPage', 'description': 'Sets the root page and initializes its renderer', 'visibility': 'package private', 'return_type': 'void', 'params': 'Page newRoot', 'source_class_id': 'Platform'}, {'type': 'method', 'name': 'HandleChildRemoved', 'node_id': 'HandleChildRemoved', 'description': 'Handles removal of child elements and their renderers', 'visibility': 'private', 'return_type': 'void', 'params': 'object sender, ElementEventArgs e', 'source_class_id': 'Platform'}, {'type': 'method', 'name': 'LayoutSubviews', 'node_id': 'LayoutSubviews', 'description': 'Updates layout of root renderer', 'visibility': 'package private', 'return_type': 'void', 'params': None, 'source_class_id': 'Platform'}], 'edges': [{'node_id_from': 'CreateRenderer', 'node_id_to': 'SetRenderer', 'description': 'calls'}, {'node_id_from': 'SetRenderer', 'node_id_to': 'RendererProperty', 'description': 'uses'}, {'node_id_from': 'GetRenderer', 'node_id_to': 'RendererProperty', 'description': 'reads'}, {'node_id_from': 'AddChild', 'node_id_to': 'CreateRenderer', 'description': 'calls'}, {'node_id_from': 'AddChild', 'node_id_to': 'SetRenderer', 'description': 'calls'}, {'node_id_from': 'SetPage', 'node_id_to': 'AddChild', 'description': 'calls'}, {'node_id_from': 'LayoutSubviews', 'node_id_to': 'GetRenderer', 'description': 'calls'}, {'node_id_from': 'HandleChildRemoved', 'node_id_to': 'GetRenderer', 'description': 'indirect usage'}, {'node_id_from': 'Platform', 'node_id_to': '_renderer', 'description': ''}, {'node_id_from': 'Platform', 'node_id_to': 'SetPage', 'description': ''}, {'node_id_from': 'Platform', 'node_id_to': 'HandleChildRemoved', 'description': ''}, {'node_id_from': 'Platform', 'node_id_to': 'LayoutSubviews', 'description': ''}, {'node_id_from': 'Platform', 'node_id_to': 'CreateRenderer', 'description': ''}, {'node_id_from': 'Platform', 'node_id_to': 'RendererProperty', 'description': ''}, {'node_id_from': 'Platform', 'node_id_to': 'SetRenderer', 'description': ''}, {'node_id_from': 'Platform', 'node_id_to': 'GetRenderer', 'description': ''}, {'node_id_from': 'Platform', 'node_id_to': 'AddChild', 'description': ''}], 'packages': [{'package_id': 'rendererManagement', 'children': ['CreateRenderer', 'SetRenderer', 'GetRenderer', 'RendererProperty'], 'description': 'Core renderer management functionality'}, {'package_id': 'viewManagement', 'children': ['AddChild', 'SetPage', 'HandleChildRemoved', 'LayoutSubviews'], 'description': 'View hierarchy management'}]}",
    "version": "full",
    "text_answer": "Renderers are attached to visual elements through the RendererProperty bindable property. The CreateRenderer method creates a new renderer for an element, and SetRenderer method attaches it by setting the RendererProperty value. This process is primarily managed when adding child views through the AddChild method.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C",
    "code": "\n#include \"c.h\"\n\n#define _DIAGASSERT(x) do {} while (0)\n\n\n/*\t$NetBSD: gettemp.c,v 1.17 2014/01/21 19:09:48 seanb Exp $\t*/\n\n/*\n * Copyright (c) 1987, 1993\n *\tThe Regents of the University of California.  All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *\t  notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *\t  notice, this list of conditions and the following disclaimer in the\n *\t  documentation and/or other materials provided with the distribution.\n * 3. Neither the name of the University nor the names of its contributors\n *\t  may be used to endorse or promote products derived from this software\n *\t  without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n */\n\n#if HAVE_NBTOOL_CONFIG_H\n#include \"nbtool_config.h\"\n#endif\n\n#if !HAVE_NBTOOL_CONFIG_H || !HAVE_MKSTEMP || !HAVE_MKDTEMP\n\n#ifdef NOT_POSTGRESQL\n#include <sys/cdefs.h>\n#if defined(LIBC_SCCS) && !defined(lint)\n#if 0\nstatic char sccsid[] = \"@(#)mktemp.c\t8.1 (Berkeley) 6/4/93\";\n#else\n__RCSID(\"$NetBSD: gettemp.c,v 1.17 2014/01/21 19:09:48 seanb Exp $\");\n#endif\n#endif\t\t\t\t\t\t\t/* LIBC_SCCS and not lint */\n#endif\n\n#include <sys/types.h>\n#include <sys/stat.h>\n\n#include <assert.h>\n#include <ctype.h>\n#include <errno.h>\n#include <fcntl.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n\n#ifdef NOT_POSTGRESQL\n#if HAVE_NBTOOL_CONFIG_H\n#define GETTEMP\t\t__nbcompat_gettemp\n#else\n#include \"reentrant.h\"\n#include \"local.h\"\n#define GETTEMP\t\t__gettemp\n#endif\n#endif\n\nstatic int\nGETTEMP(char *path, int *doopen, int domkdir)\n{\n\tchar\t   *start,\n\t\t\t   *trv;\n\tstruct stat sbuf;\n\tu_int\t\tpid;\n\n\t/*\n\t * To guarantee multiple calls generate unique names even if the file is\n\t * not created. 676 different possibilities with 7 or more X's, 26 with 6\n\t * or less.\n\t */\n\tstatic char xtra[2] = \"aa\";\n\tint\t\t\txcnt = 0;\n\n\t_DIAGASSERT(path != NULL);\n\t/* doopen may be NULL */\n\n\tpid = getpid();\n\n\t/* Move to end of path and count trailing X's. */\n\tfor (trv = path; *trv; ++trv)\n\t\tif (*trv == 'X')\n\t\t\txcnt++;\n\t\telse\n\t\t\txcnt = 0;\n\n\t/* Use at least one from xtra.  Use 2 if more than 6 X's. */\n\tif (xcnt > 0)\n\t{\n\t\t*--trv = xtra[0];\n\t\txcnt--;\n\t}\n\tif (xcnt > 5)\n\t{\n\t\t*--trv = xtra[1];\n\t\txcnt--;\n\t}\n\n\t/* Set remaining X's to pid digits with 0's to the left. */\n\tfor (; xcnt > 0; xcnt--)\n\t{\n\t\t*--trv = (pid % 10) + '0';\n\t\tpid /= 10;\n\t}\n\n\t/* update xtra for next call. */\n\tif (xtra[0] != 'z')\n\t\txtra[0]++;\n\telse\n\t{\n\t\txtra[0] = 'a';\n\t\tif (xtra[1] != 'z')\n\t\t\txtra[1]++;\n\t\telse\n\t\t\txtra[1] = 'a';\n\t}\n\n\t/*\n\t * check the target directory; if you have six X's and it doesn't exist\n\t * this runs for a *very* long time.\n\t */\n\tfor (start = trv + 1;; --trv)\n\t{\n\t\tif (trv <= path)\n\t\t\tbreak;\n\t\tif (*trv == '/')\n\t\t{\n\t\t\tint\t\t\te;\n\n\t\t\t*trv = '\\0';\n\t\t\te = stat(path, &sbuf);\n\t\t\t*trv = '/';\n\t\t\tif (e == -1)\n\t\t\t\treturn doopen == NULL && !domkdir;\n\t\t\tif (!S_ISDIR(sbuf.st_mode))\n\t\t\t{\n\t\t\t\terrno = ENOTDIR;\n\t\t\t\treturn doopen == NULL && !domkdir;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tfor (;;)\n\t{\n\t\tif (doopen)\n\t\t{\n\t\t\tif ((*doopen =\n\t\t\t\t open(path, O_CREAT | O_EXCL | O_RDWR, 0600)) >= 0)\n\t\t\t\treturn 1;\n\t\t\tif (errno != EEXIST)\n\t\t\t\treturn 0;\n\t\t}\n\t\telse if (domkdir)\n\t\t{\n\t\t\tif (mkdir(path, 0700) >= 0)\n\t\t\t\treturn 1;\n\t\t\tif (errno != EEXIST)\n\t\t\t\treturn 0;\n\t\t}\n\t\telse if (lstat(path, &sbuf))\n\t\t\treturn errno == ENOENT ? 1 : 0;\n\n\t\t/* tricky little algorithm for backward compatibility */\n\t\tfor (trv = start;;)\n\t\t{\n\t\t\tif (!*trv)\n\t\t\t\treturn 0;\n\t\t\tif (*trv == 'z')\n\t\t\t\t*trv++ = 'a';\n\t\t\telse\n\t\t\t{\n\t\t\t\tif (isdigit((unsigned char) *trv))\n\t\t\t\t\t*trv = 'a';\n\t\t\t\telse\n\t\t\t\t\t++*trv;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\t/* NOTREACHED */\n}\n\n#endif\t\t\t\t\t\t\t/* !HAVE_NBTOOL_CONFIG_H || !HAVE_MKSTEMP ||\n\t\t\t\t\t\t\t\t * !HAVE_MKDTEMP */\n\n\n/*\t$NetBSD: mkdtemp.c,v 1.11 2012/03/15 18:22:30 christos Exp $\t*/\n\n/*\n * Copyright (c) 1987, 1993\n *\tThe Regents of the University of California.  All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *\t  notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *\t  notice, this list of conditions and the following disclaimer in the\n *\t  documentation and/or other materials provided with the distribution.\n * 3. Neither the name of the University nor the names of its contributors\n *\t  may be used to endorse or promote products derived from this software\n *\t  without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n */\n\n#if HAVE_NBTOOL_CONFIG_H\n#include \"nbtool_config.h\"\n#endif\n\n#if !HAVE_NBTOOL_CONFIG_H || !HAVE_MKDTEMP\n\n#ifdef NOT_POSTGRESQL\n\n#include <sys/cdefs.h>\n#if defined(LIBC_SCCS) && !defined(lint)\n#if 0\nstatic char sccsid[] = \"@(#)mktemp.c\t8.1 (Berkeley) 6/4/93\";\n#else\n__RCSID(\"$NetBSD: mkdtemp.c,v 1.11 2012/03/15 18:22:30 christos Exp $\");\n#endif\n#endif\t\t\t\t\t\t\t/* LIBC_SCCS and not lint */\n\n#if HAVE_NBTOOL_CONFIG_H\n#define GETTEMP\t\t__nbcompat_gettemp\n#else\n#include <assert.h>\n#include <errno.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include \"reentrant.h\"\n#include \"local.h\"\n#define GETTEMP\t\t__gettemp\n#endif\n\n#endif\n\nchar *\nmkdtemp(char *path)\n{\n\t_DIAGASSERT(path != NULL);\n\n\treturn GETTEMP(path, NULL, 1) ? path : NULL;\n}\n\n#endif\t\t\t\t\t\t\t/* !HAVE_NBTOOL_CONFIG_H || !HAVE_MKDTEMP */",
    "repo": "ApsaraDB/PolarDB-for-PostgreSQL",
    "path": "./datasets/diagrams-repos/ApsaraDB/PolarDB-for-PostgreSQL/src/port/mkdtemp.c",
    "query": "Illustrate the process by which mkdtemp utilizes GETTEMP to create a temporary directory, including error handling and the conditions under which it returns the path or NULL.",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'mkdtemp', 'node_id': 'mkdtemp', 'description': 'Creates a unique temporary directory from template', 'visibility': 'public', 'return_type': 'char*', 'params': 'char *path', 'source_class_id': None}, {'type': 'function', 'name': 'GETTEMP', 'node_id': 'GETTEMP', 'description': 'Core function that generates unique path and creates directory', 'visibility': 'private', 'return_type': 'int', 'params': 'char *path, int *doopen, int domkdir', 'source_class_id': None}], 'edges': [{'node_id_from': 'mkdtemp', 'node_id_to': 'GETTEMP', 'description': 'calls with domkdir=1'}], 'packages': [{'package_id': 'tempDirCreation', 'children': ['mkdtemp', 'GETTEMP'], 'description': 'Temporary directory creation functionality'}]}",
    "version": "minimal",
    "text_answer": "mkdtemp creates a unique temporary directory by calling GETTEMP with domkdir=1. GETTEMP generates a unique name using process ID and incremental characters, validates the path, attempts to create the directory using mkdir, and returns 1 on success (mkdtemp returns path) or 0 on failure (mkdtemp returns NULL).",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C",
    "code": "\n#include \"c.h\"\n\n#define _DIAGASSERT(x) do {} while (0)\n\n\n/*\t$NetBSD: gettemp.c,v 1.17 2014/01/21 19:09:48 seanb Exp $\t*/\n\n/*\n * Copyright (c) 1987, 1993\n *\tThe Regents of the University of California.  All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *\t  notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *\t  notice, this list of conditions and the following disclaimer in the\n *\t  documentation and/or other materials provided with the distribution.\n * 3. Neither the name of the University nor the names of its contributors\n *\t  may be used to endorse or promote products derived from this software\n *\t  without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n */\n\n#if HAVE_NBTOOL_CONFIG_H\n#include \"nbtool_config.h\"\n#endif\n\n#if !HAVE_NBTOOL_CONFIG_H || !HAVE_MKSTEMP || !HAVE_MKDTEMP\n\n#ifdef NOT_POSTGRESQL\n#include <sys/cdefs.h>\n#if defined(LIBC_SCCS) && !defined(lint)\n#if 0\nstatic char sccsid[] = \"@(#)mktemp.c\t8.1 (Berkeley) 6/4/93\";\n#else\n__RCSID(\"$NetBSD: gettemp.c,v 1.17 2014/01/21 19:09:48 seanb Exp $\");\n#endif\n#endif\t\t\t\t\t\t\t/* LIBC_SCCS and not lint */\n#endif\n\n#include <sys/types.h>\n#include <sys/stat.h>\n\n#include <assert.h>\n#include <ctype.h>\n#include <errno.h>\n#include <fcntl.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n\n#ifdef NOT_POSTGRESQL\n#if HAVE_NBTOOL_CONFIG_H\n#define GETTEMP\t\t__nbcompat_gettemp\n#else\n#include \"reentrant.h\"\n#include \"local.h\"\n#define GETTEMP\t\t__gettemp\n#endif\n#endif\n\nstatic int\nGETTEMP(char *path, int *doopen, int domkdir)\n{\n\tchar\t   *start,\n\t\t\t   *trv;\n\tstruct stat sbuf;\n\tu_int\t\tpid;\n\n\t/*\n\t * To guarantee multiple calls generate unique names even if the file is\n\t * not created. 676 different possibilities with 7 or more X's, 26 with 6\n\t * or less.\n\t */\n\tstatic char xtra[2] = \"aa\";\n\tint\t\t\txcnt = 0;\n\n\t_DIAGASSERT(path != NULL);\n\t/* doopen may be NULL */\n\n\tpid = getpid();\n\n\t/* Move to end of path and count trailing X's. */\n\tfor (trv = path; *trv; ++trv)\n\t\tif (*trv == 'X')\n\t\t\txcnt++;\n\t\telse\n\t\t\txcnt = 0;\n\n\t/* Use at least one from xtra.  Use 2 if more than 6 X's. */\n\tif (xcnt > 0)\n\t{\n\t\t*--trv = xtra[0];\n\t\txcnt--;\n\t}\n\tif (xcnt > 5)\n\t{\n\t\t*--trv = xtra[1];\n\t\txcnt--;\n\t}\n\n\t/* Set remaining X's to pid digits with 0's to the left. */\n\tfor (; xcnt > 0; xcnt--)\n\t{\n\t\t*--trv = (pid % 10) + '0';\n\t\tpid /= 10;\n\t}\n\n\t/* update xtra for next call. */\n\tif (xtra[0] != 'z')\n\t\txtra[0]++;\n\telse\n\t{\n\t\txtra[0] = 'a';\n\t\tif (xtra[1] != 'z')\n\t\t\txtra[1]++;\n\t\telse\n\t\t\txtra[1] = 'a';\n\t}\n\n\t/*\n\t * check the target directory; if you have six X's and it doesn't exist\n\t * this runs for a *very* long time.\n\t */\n\tfor (start = trv + 1;; --trv)\n\t{\n\t\tif (trv <= path)\n\t\t\tbreak;\n\t\tif (*trv == '/')\n\t\t{\n\t\t\tint\t\t\te;\n\n\t\t\t*trv = '\\0';\n\t\t\te = stat(path, &sbuf);\n\t\t\t*trv = '/';\n\t\t\tif (e == -1)\n\t\t\t\treturn doopen == NULL && !domkdir;\n\t\t\tif (!S_ISDIR(sbuf.st_mode))\n\t\t\t{\n\t\t\t\terrno = ENOTDIR;\n\t\t\t\treturn doopen == NULL && !domkdir;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tfor (;;)\n\t{\n\t\tif (doopen)\n\t\t{\n\t\t\tif ((*doopen =\n\t\t\t\t open(path, O_CREAT | O_EXCL | O_RDWR, 0600)) >= 0)\n\t\t\t\treturn 1;\n\t\t\tif (errno != EEXIST)\n\t\t\t\treturn 0;\n\t\t}\n\t\telse if (domkdir)\n\t\t{\n\t\t\tif (mkdir(path, 0700) >= 0)\n\t\t\t\treturn 1;\n\t\t\tif (errno != EEXIST)\n\t\t\t\treturn 0;\n\t\t}\n\t\telse if (lstat(path, &sbuf))\n\t\t\treturn errno == ENOENT ? 1 : 0;\n\n\t\t/* tricky little algorithm for backward compatibility */\n\t\tfor (trv = start;;)\n\t\t{\n\t\t\tif (!*trv)\n\t\t\t\treturn 0;\n\t\t\tif (*trv == 'z')\n\t\t\t\t*trv++ = 'a';\n\t\t\telse\n\t\t\t{\n\t\t\t\tif (isdigit((unsigned char) *trv))\n\t\t\t\t\t*trv = 'a';\n\t\t\t\telse\n\t\t\t\t\t++*trv;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\t/* NOTREACHED */\n}\n\n#endif\t\t\t\t\t\t\t/* !HAVE_NBTOOL_CONFIG_H || !HAVE_MKSTEMP ||\n\t\t\t\t\t\t\t\t * !HAVE_MKDTEMP */\n\n\n/*\t$NetBSD: mkdtemp.c,v 1.11 2012/03/15 18:22:30 christos Exp $\t*/\n\n/*\n * Copyright (c) 1987, 1993\n *\tThe Regents of the University of California.  All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *\t  notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *\t  notice, this list of conditions and the following disclaimer in the\n *\t  documentation and/or other materials provided with the distribution.\n * 3. Neither the name of the University nor the names of its contributors\n *\t  may be used to endorse or promote products derived from this software\n *\t  without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n */\n\n#if HAVE_NBTOOL_CONFIG_H\n#include \"nbtool_config.h\"\n#endif\n\n#if !HAVE_NBTOOL_CONFIG_H || !HAVE_MKDTEMP\n\n#ifdef NOT_POSTGRESQL\n\n#include <sys/cdefs.h>\n#if defined(LIBC_SCCS) && !defined(lint)\n#if 0\nstatic char sccsid[] = \"@(#)mktemp.c\t8.1 (Berkeley) 6/4/93\";\n#else\n__RCSID(\"$NetBSD: mkdtemp.c,v 1.11 2012/03/15 18:22:30 christos Exp $\");\n#endif\n#endif\t\t\t\t\t\t\t/* LIBC_SCCS and not lint */\n\n#if HAVE_NBTOOL_CONFIG_H\n#define GETTEMP\t\t__nbcompat_gettemp\n#else\n#include <assert.h>\n#include <errno.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include \"reentrant.h\"\n#include \"local.h\"\n#define GETTEMP\t\t__gettemp\n#endif\n\n#endif\n\nchar *\nmkdtemp(char *path)\n{\n\t_DIAGASSERT(path != NULL);\n\n\treturn GETTEMP(path, NULL, 1) ? path : NULL;\n}\n\n#endif\t\t\t\t\t\t\t/* !HAVE_NBTOOL_CONFIG_H || !HAVE_MKDTEMP */",
    "repo": "ApsaraDB/PolarDB-for-PostgreSQL",
    "path": "./datasets/diagrams-repos/ApsaraDB/PolarDB-for-PostgreSQL/src/port/mkdtemp.c",
    "query": "Illustrate the process by which mkdtemp utilizes GETTEMP to create a temporary directory, including error handling and the conditions under which it returns the path or NULL.",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'mkdtemp', 'node_id': 'mkdtemp', 'description': 'Creates a unique temporary directory from template', 'visibility': 'public', 'return_type': 'char*', 'params': 'char *path', 'source_class_id': None}, {'type': 'function', 'name': 'GETTEMP', 'node_id': 'GETTEMP', 'description': 'Core function that generates unique path and creates directory', 'visibility': 'private', 'return_type': 'int', 'params': 'char *path, int *doopen, int domkdir', 'source_class_id': None}, {'type': 'function', 'name': 'mkdir', 'node_id': 'mkdir', 'description': 'System call to create directory', 'visibility': 'public', 'return_type': 'int', 'params': 'const char *path, mode_t mode', 'source_class_id': None}, {'type': 'entity', 'name': 'successPath', 'node_id': 'successPath', 'description': 'Return original path on success', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'NoneReturn', 'node_id': 'NoneReturn', 'description': 'Return NULL on failure', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'mkdtemp', 'node_id_to': 'GETTEMP', 'description': 'calls with domkdir=1'}, {'node_id_from': 'GETTEMP', 'node_id_to': 'mkdir', 'description': 'creates directory'}, {'node_id_from': 'GETTEMP', 'node_id_to': 'successPath', 'description': 'returns 1'}, {'node_id_from': 'GETTEMP', 'node_id_to': 'NoneReturn', 'description': 'returns 0'}], 'packages': [{'package_id': 'tempDirCreation', 'children': ['mkdtemp', 'GETTEMP'], 'description': 'Temporary directory creation functionality'}]}",
    "version": "medium",
    "text_answer": "mkdtemp creates a unique temporary directory by calling GETTEMP with domkdir=1. GETTEMP generates a unique name using process ID and incremental characters, validates the path, attempts to create the directory using mkdir, and returns 1 on success (mkdtemp returns path) or 0 on failure (mkdtemp returns NULL).",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C",
    "code": "\n#include \"c.h\"\n\n#define _DIAGASSERT(x) do {} while (0)\n\n\n/*\t$NetBSD: gettemp.c,v 1.17 2014/01/21 19:09:48 seanb Exp $\t*/\n\n/*\n * Copyright (c) 1987, 1993\n *\tThe Regents of the University of California.  All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *\t  notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *\t  notice, this list of conditions and the following disclaimer in the\n *\t  documentation and/or other materials provided with the distribution.\n * 3. Neither the name of the University nor the names of its contributors\n *\t  may be used to endorse or promote products derived from this software\n *\t  without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n */\n\n#if HAVE_NBTOOL_CONFIG_H\n#include \"nbtool_config.h\"\n#endif\n\n#if !HAVE_NBTOOL_CONFIG_H || !HAVE_MKSTEMP || !HAVE_MKDTEMP\n\n#ifdef NOT_POSTGRESQL\n#include <sys/cdefs.h>\n#if defined(LIBC_SCCS) && !defined(lint)\n#if 0\nstatic char sccsid[] = \"@(#)mktemp.c\t8.1 (Berkeley) 6/4/93\";\n#else\n__RCSID(\"$NetBSD: gettemp.c,v 1.17 2014/01/21 19:09:48 seanb Exp $\");\n#endif\n#endif\t\t\t\t\t\t\t/* LIBC_SCCS and not lint */\n#endif\n\n#include <sys/types.h>\n#include <sys/stat.h>\n\n#include <assert.h>\n#include <ctype.h>\n#include <errno.h>\n#include <fcntl.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n\n#ifdef NOT_POSTGRESQL\n#if HAVE_NBTOOL_CONFIG_H\n#define GETTEMP\t\t__nbcompat_gettemp\n#else\n#include \"reentrant.h\"\n#include \"local.h\"\n#define GETTEMP\t\t__gettemp\n#endif\n#endif\n\nstatic int\nGETTEMP(char *path, int *doopen, int domkdir)\n{\n\tchar\t   *start,\n\t\t\t   *trv;\n\tstruct stat sbuf;\n\tu_int\t\tpid;\n\n\t/*\n\t * To guarantee multiple calls generate unique names even if the file is\n\t * not created. 676 different possibilities with 7 or more X's, 26 with 6\n\t * or less.\n\t */\n\tstatic char xtra[2] = \"aa\";\n\tint\t\t\txcnt = 0;\n\n\t_DIAGASSERT(path != NULL);\n\t/* doopen may be NULL */\n\n\tpid = getpid();\n\n\t/* Move to end of path and count trailing X's. */\n\tfor (trv = path; *trv; ++trv)\n\t\tif (*trv == 'X')\n\t\t\txcnt++;\n\t\telse\n\t\t\txcnt = 0;\n\n\t/* Use at least one from xtra.  Use 2 if more than 6 X's. */\n\tif (xcnt > 0)\n\t{\n\t\t*--trv = xtra[0];\n\t\txcnt--;\n\t}\n\tif (xcnt > 5)\n\t{\n\t\t*--trv = xtra[1];\n\t\txcnt--;\n\t}\n\n\t/* Set remaining X's to pid digits with 0's to the left. */\n\tfor (; xcnt > 0; xcnt--)\n\t{\n\t\t*--trv = (pid % 10) + '0';\n\t\tpid /= 10;\n\t}\n\n\t/* update xtra for next call. */\n\tif (xtra[0] != 'z')\n\t\txtra[0]++;\n\telse\n\t{\n\t\txtra[0] = 'a';\n\t\tif (xtra[1] != 'z')\n\t\t\txtra[1]++;\n\t\telse\n\t\t\txtra[1] = 'a';\n\t}\n\n\t/*\n\t * check the target directory; if you have six X's and it doesn't exist\n\t * this runs for a *very* long time.\n\t */\n\tfor (start = trv + 1;; --trv)\n\t{\n\t\tif (trv <= path)\n\t\t\tbreak;\n\t\tif (*trv == '/')\n\t\t{\n\t\t\tint\t\t\te;\n\n\t\t\t*trv = '\\0';\n\t\t\te = stat(path, &sbuf);\n\t\t\t*trv = '/';\n\t\t\tif (e == -1)\n\t\t\t\treturn doopen == NULL && !domkdir;\n\t\t\tif (!S_ISDIR(sbuf.st_mode))\n\t\t\t{\n\t\t\t\terrno = ENOTDIR;\n\t\t\t\treturn doopen == NULL && !domkdir;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tfor (;;)\n\t{\n\t\tif (doopen)\n\t\t{\n\t\t\tif ((*doopen =\n\t\t\t\t open(path, O_CREAT | O_EXCL | O_RDWR, 0600)) >= 0)\n\t\t\t\treturn 1;\n\t\t\tif (errno != EEXIST)\n\t\t\t\treturn 0;\n\t\t}\n\t\telse if (domkdir)\n\t\t{\n\t\t\tif (mkdir(path, 0700) >= 0)\n\t\t\t\treturn 1;\n\t\t\tif (errno != EEXIST)\n\t\t\t\treturn 0;\n\t\t}\n\t\telse if (lstat(path, &sbuf))\n\t\t\treturn errno == ENOENT ? 1 : 0;\n\n\t\t/* tricky little algorithm for backward compatibility */\n\t\tfor (trv = start;;)\n\t\t{\n\t\t\tif (!*trv)\n\t\t\t\treturn 0;\n\t\t\tif (*trv == 'z')\n\t\t\t\t*trv++ = 'a';\n\t\t\telse\n\t\t\t{\n\t\t\t\tif (isdigit((unsigned char) *trv))\n\t\t\t\t\t*trv = 'a';\n\t\t\t\telse\n\t\t\t\t\t++*trv;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\t/* NOTREACHED */\n}\n\n#endif\t\t\t\t\t\t\t/* !HAVE_NBTOOL_CONFIG_H || !HAVE_MKSTEMP ||\n\t\t\t\t\t\t\t\t * !HAVE_MKDTEMP */\n\n\n/*\t$NetBSD: mkdtemp.c,v 1.11 2012/03/15 18:22:30 christos Exp $\t*/\n\n/*\n * Copyright (c) 1987, 1993\n *\tThe Regents of the University of California.  All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *\t  notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *\t  notice, this list of conditions and the following disclaimer in the\n *\t  documentation and/or other materials provided with the distribution.\n * 3. Neither the name of the University nor the names of its contributors\n *\t  may be used to endorse or promote products derived from this software\n *\t  without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n */\n\n#if HAVE_NBTOOL_CONFIG_H\n#include \"nbtool_config.h\"\n#endif\n\n#if !HAVE_NBTOOL_CONFIG_H || !HAVE_MKDTEMP\n\n#ifdef NOT_POSTGRESQL\n\n#include <sys/cdefs.h>\n#if defined(LIBC_SCCS) && !defined(lint)\n#if 0\nstatic char sccsid[] = \"@(#)mktemp.c\t8.1 (Berkeley) 6/4/93\";\n#else\n__RCSID(\"$NetBSD: mkdtemp.c,v 1.11 2012/03/15 18:22:30 christos Exp $\");\n#endif\n#endif\t\t\t\t\t\t\t/* LIBC_SCCS and not lint */\n\n#if HAVE_NBTOOL_CONFIG_H\n#define GETTEMP\t\t__nbcompat_gettemp\n#else\n#include <assert.h>\n#include <errno.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include \"reentrant.h\"\n#include \"local.h\"\n#define GETTEMP\t\t__gettemp\n#endif\n\n#endif\n\nchar *\nmkdtemp(char *path)\n{\n\t_DIAGASSERT(path != NULL);\n\n\treturn GETTEMP(path, NULL, 1) ? path : NULL;\n}\n\n#endif\t\t\t\t\t\t\t/* !HAVE_NBTOOL_CONFIG_H || !HAVE_MKDTEMP */",
    "repo": "ApsaraDB/PolarDB-for-PostgreSQL",
    "path": "./datasets/diagrams-repos/ApsaraDB/PolarDB-for-PostgreSQL/src/port/mkdtemp.c",
    "query": "Illustrate the process by which mkdtemp utilizes GETTEMP to create a temporary directory, including error handling and the conditions under which it returns the path or NULL.",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'mkdtemp', 'node_id': 'mkdtemp', 'description': 'Creates a unique temporary directory from template', 'visibility': 'public', 'return_type': 'char*', 'params': 'char *path', 'source_class_id': None}, {'type': 'function', 'name': 'GETTEMP', 'node_id': 'GETTEMP', 'description': 'Core function that generates unique path and creates directory', 'visibility': 'private', 'return_type': 'int', 'params': 'char *path, int *doopen, int domkdir', 'source_class_id': None}, {'type': 'function', 'name': 'mkdir', 'node_id': 'mkdir', 'description': 'System call to create directory', 'visibility': 'public', 'return_type': 'int', 'params': 'const char *path, mode_t mode', 'source_class_id': None}, {'type': 'function', 'name': 'getpid', 'node_id': 'getpid', 'description': 'Get process ID for unique name generation', 'visibility': 'public', 'return_type': 'pid_t', 'params': 'void', 'source_class_id': None}, {'type': 'function', 'name': 'stat', 'node_id': 'stat', 'description': 'Get file status', 'visibility': 'public', 'return_type': 'int', 'params': 'const char *path, struct stat *buf', 'source_class_id': None}, {'type': 'function', 'name': 'lstat', 'node_id': 'lstat', 'description': 'Get file status (not following links)', 'visibility': 'public', 'return_type': 'int', 'params': 'const char *path, struct stat *buf', 'source_class_id': None}, {'type': 'variable', 'name': 'xtra', 'node_id': 'xtra', 'description': 'Static array for generating unique names', 'visibility': 'private', 'return_type': 'char[2]', 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'pathValidation', 'node_id': 'pathValidation', 'description': 'Validates directory path existence', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'uniqueNameGeneration', 'node_id': 'uniqueNameGeneration', 'description': 'Process of generating unique directory name', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'errorHandling', 'node_id': 'errorHandling', 'description': 'Error checking and handling', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'mkdtemp', 'node_id_to': 'GETTEMP', 'description': 'calls with domkdir=1'}, {'node_id_from': 'GETTEMP', 'node_id_to': 'getpid', 'description': 'gets process ID'}, {'node_id_from': 'GETTEMP', 'node_id_to': 'uniqueNameGeneration', 'description': 'generates name'}, {'node_id_from': 'GETTEMP', 'node_id_to': 'pathValidation', 'description': 'validates path'}, {'node_id_from': 'pathValidation', 'node_id_to': 'stat', 'description': 'checks directory'}, {'node_id_from': 'GETTEMP', 'node_id_to': 'mkdir', 'description': 'creates directory'}, {'node_id_from': 'GETTEMP', 'node_id_to': 'lstat', 'description': 'checks file existence'}, {'node_id_from': 'GETTEMP', 'node_id_to': 'errorHandling', 'description': 'handles errors'}, {'node_id_from': 'uniqueNameGeneration', 'node_id_to': 'xtra', 'description': 'uses'}], 'packages': [{'package_id': 'tempDirCreation', 'children': ['mkdtemp', 'GETTEMP', 'uniqueNameGeneration', 'errorHandling', 'xtra'], 'description': 'Temporary directory creation functionality'}, {'package_id': 'systemCalls', 'children': ['mkdir', 'getpid', 'stat', 'lstat'], 'description': 'System-level operations'}]}",
    "version": "full",
    "text_answer": "mkdtemp creates a unique temporary directory by calling GETTEMP with domkdir=1. GETTEMP generates a unique name using process ID and incremental characters, validates the path, attempts to create the directory using mkdir, and returns 1 on success (mkdtemp returns path) or 0 on failure (mkdtemp returns NULL).",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { ImageResponse } from '@vercel/og';\nimport { env } from '../../utils/env';\nimport { fetchFont } from '../../utils/fetchFont';\n\nexport const config = {\n  runtime: 'edge',\n};\n\nconst fetchGithubStars = async () => {\n  const data = await (\n    await fetch('https://api.github.com/repos/trpc/trpc', {\n      headers: { authorization: `Bearer ${env.GITHUB_TOKEN}` },\n    })\n  ).json();\n  if (typeof data?.stargazers_count !== 'number')\n    throw new Error('Could not fetch stars');\n  return new Intl.NumberFormat().format(data.stargazers_count);\n};\n\nconst fetchNpmDownloads = async () => {\n  const data = await (\n    await fetch('https://api.npmjs.org/downloads/point/last-week/@trpc/server')\n  ).json();\n  if (typeof data?.downloads !== 'number')\n    throw new Error('Could not fetch npm downloads');\n  return new Intl.NumberFormat().format(data.downloads);\n};\n\n// const fetchTwitterFollowers = async () => {\n//   const data = await (\n//     await fetch(\n//       'https://api.twitter.com/2/users/1353123577193779201?user.fields=public_metrics',\n//       {\n//         headers: { authorization: `Bearer ${env.TWITTER_BEARER_TOKEN}` },\n//       },\n//     )\n//   ).json();\n//   if (typeof data?.data?.public_metrics?.followers_count !== 'number')\n//     throw new Error('Could not fetch twitter followers');\n//   return new Intl.NumberFormat().format(\n//     data?.data?.public_metrics?.followers_count,\n//   );\n// };\n\nexport default async (_req: Request) => {\n  const [inter800, inter700, ghStars, npmDownloads /**, twitterFollowers */] =\n    await Promise.all([\n      fetchFont('Inter', 800, 'tRPC   Move Fast and Break Nothing'),\n      fetchFont(\n        'Inter',\n        700,\n        'End-to-end typesafe APIs made easy. 0123456789,',\n      ),\n      fetchGithubStars(),\n      fetchNpmDownloads(),\n      // fetchTwitterFollowers(),\n    ]);\n\n  return new ImageResponse(\n    (\n      <div\n        tw=\"bg-zinc-900 h-full w-full text-white bg-cover flex flex-col p-14\"\n        style={{ fontFamily: 'Inter' }}\n      >\n        <img\n          src=\"https://assets.trpc.io/www/og-pattern-dark.svg\"\n          alt=\"background\"\n          tw=\"absolute\"\n        />\n        <div tw=\"flex flex-col justify-center items-center w-full h-full\">\n          <div tw=\"flex items-center\">\n            <img\n              src=\"https://assets.trpc.io/icons/svgs/blue-bg-rounded.svg\"\n              width=\"128px\"\n              height=\"128px\"\n              alt=\"tRPC logo\"\n            />\n            <h1 tw=\"text-8xl ml-8 font-extrabold\">tRPC</h1>\n          </div>\n          <div tw=\"flex flex-col items-center\">\n            <p tw=\"text-center pt-6 text-6xl font-extrabold\">\n              Move Fast and Break Nothing\n            </p>\n            <p tw=\"text-center pt-3 text-4xl text-zinc-300 font-bold mt-0\">\n              End-to-end typesafe APIs made easy.\n            </p>\n          </div>\n          <div tw=\"flex items-center text-zinc-300\">\n            <div tw=\"flex items-center mx-8\">\n              <div tw=\"flex items-center mx-8\">\n                <svg\n                  xmlns=\"http://www.w3.org/2000/svg\"\n                  height={36}\n                  fill=\"#fff\"\n                  viewBox=\"0 0 512 512\"\n                >\n                  <path d=\"M256 32C132.3 32 32 134.9 32 261.7c0 101.5 64.2 187.5 153.2 217.9a17.56 17.56 0 003.8.4c8.3 0 11.5-6.1 11.5-11.4 0-5.5-.2-19.9-.3-39.1a102.4 102.4 0 01-22.6 2.7c-43.1 0-52.9-33.5-52.9-33.5-10.2-26.5-24.9-33.6-24.9-33.6-19.5-13.7-.1-14.1 1.4-14.1h.1c22.5 2 34.3 23.8 34.3 23.8 11.2 19.6 26.2 25.1 39.6 25.1a63 63 0 0025.6-6c2-14.8 7.8-24.9 14.2-30.7-49.7-5.8-102-25.5-102-113.5 0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8a18.64 18.64 0 015-.5c8.1 0 26.4 3.1 56.6 24.1a208.21 208.21 0 01112.2 0c30.2-21 48.5-24.1 56.6-24.1a18.64 18.64 0 015 .5c12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6 0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5 0 30.7-.3 55.5-.3 63 0 5.4 3.1 11.5 11.4 11.5a19.35 19.35 0 004-.4C415.9 449.2 480 363.1 480 261.7 480 134.9 379.7 32 256 32z\" />\n                </svg>\n                <p tw=\"text-3xl font-bold ml-2\">{ghStars}</p>\n              </div>\n\n              {/* <div tw=\"flex items-center mx-8\">\n                <svg\n                  stroke=\"#fff\"\n                  fill=\"#fff\"\n                  viewBox=\"0 0 24 24\"\n                  height={32}\n                  width={32}\n                  xmlns=\"http://www.w3.org/2000/svg\"\n                >\n                  <path d=\"M23.953 4.57a10 10 0 01-2.825.775 4.958 4.958 0 002.163-2.723c-.951.555-2.005.959-3.127 1.184a4.92 4.92 0 00-8.384 4.482C7.69 8.095 4.067 6.13 1.64 3.162a4.822 4.822 0 00-.666 2.475c0 1.71.87 3.213 2.188 4.096a4.904 4.904 0 01-2.228-.616v.06a4.923 4.923 0 003.946 4.827 4.996 4.996 0 01-2.212.085 4.936 4.936 0 004.604 3.417 9.867 9.867 0 01-6.102 2.105c-.39 0-.779-.023-1.17-.067a13.995 13.995 0 007.557 2.209c9.053 0 13.998-7.496 13.998-13.985 0-.21 0-.42-.015-.63A9.935 9.935 0 0024 4.59z\" />\n                </svg>\n                <p tw=\"text-3xl font-bold ml-2\">{twitterFollowers}</p>\n              </div> */}\n\n              <div tw=\"flex items-center mx-8\">\n                {/* <svg\n                  xmlns=\"http://www.w3.org/2000/svg\"\n                  stroke=\"#fff\"\n                  fill=\"#fff\"\n                  height={48}\n                  viewBox=\"0 0 512 512\"\n                >\n                  <path d=\"M227.6 213.1H256v57.1h-28.4z\" />\n                  <path d=\"M0 156v171.4h142.2V356H256v-28.6h256V156zm142.2 142.9h-28.4v-85.7H85.3v85.7H28.4V184.6h113.8zm142.2 0h-56.9v28.6h-56.9V184.6h113.8zm199.2 0h-28.4v-85.7h-28.4v85.7h-28.4v-85.7H370v85.7h-56.9V184.6h170.7v114.3z\" />\n                </svg> */}\n                <svg\n                  role=\"img\"\n                  stroke=\"#fff\"\n                  fill=\"#fff\"\n                  height={32}\n                  viewBox=\"0 0 24 24\"\n                  xmlns=\"http://www.w3.org/2000/svg\"\n                >\n                  <path d=\"M1.763 0C.786 0 0 .786 0 1.763v20.474C0 23.214.786 24 1.763 24h20.474c.977 0 1.763-.786 1.763-1.763V1.763C24 .786 23.214 0 22.237 0zM5.13 5.323l13.837.019-.009 13.836h-3.464l.01-10.382h-3.456L12.04 19.17H5.113z\" />\n                </svg>\n                <p tw=\"text-3xl font-bold ml-2\">{npmDownloads}</p>\n              </div>\n            </div>\n          </div>\n        </div>\n      </div>\n    ),\n    {\n      headers: {\n        'Cache-Control': 's-maxage=86400, stale-while-revalidate',\n      },\n      width: 1200,\n      height: 600,\n      fonts: [\n        { name: 'Inter', data: inter800, weight: 800 },\n        { name: 'Inter', data: inter700, weight: 700 },\n      ],\n    },\n  );\n};",
    "repo": "trpc/trpc",
    "path": "./datasets/diagrams-repos/trpc/trpc/www/og-image/pages/api/landing.tsx",
    "query": "How are the different data sources (GitHub stars, npm downloads, Twitter followers) integrated into the OG image generation process?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'fetchGithubStars', 'node_id': 'fetchGithubStars', 'description': 'Fetches star count from GitHub API', 'visibility': 'private', 'return_type': 'Promise<string>', 'params': '', 'source_class_id': None}, {'type': 'function', 'name': 'fetchNpmDownloads', 'node_id': 'fetchNpmDownloads', 'description': 'Fetches download count from npm API', 'visibility': 'private', 'return_type': 'Promise<string>', 'params': '', 'source_class_id': None}, {'type': 'function', 'name': 'fetchTwitterFollowers', 'node_id': 'fetchTwitterFollowers', 'description': 'Fetches number of Twitter followers (commented out)', 'visibility': 'public', 'return_type': 'Promise<string>', 'params': '', 'source_class_id': None}, {'type': 'function', 'name': 'default', 'node_id': 'default', 'description': 'Main function generating OG image with stats', 'visibility': 'public', 'return_type': 'Promise<ImageResponse>', 'params': '_req: Request', 'source_class_id': None}], 'edges': [{'node_id_from': 'default', 'node_id_to': 'fetchGithubStars', 'description': 'calls to get GitHub stats'}, {'node_id_from': 'default', 'node_id_to': 'fetchNpmDownloads', 'description': 'calls to get npm stats'}, {'node_id_from': 'default', 'node_id_to': 'fetchTwitterFollowers', 'description': 'calls to get twitter followers (commented out)'}], 'packages': [{'package_id': 'dataFetching', 'children': ['fetchGithubStars', 'fetchNpmDownloads', 'fetchTwitterFollowers'], 'description': 'Data fetching functions'}]}",
    "version": "minimal",
    "text_answer": "The OG image integrates data from external sources through separate async functions: fetchGithubStars fetches repository stars from GitHub API, fetchNpmDownloads retrieves weekly download counts from npm, and there's a commented-out fetchTwitterFollowers function. These data points are fetched concurrently using Promise.all and then rendered into the final image using Vercel's ImageResponse.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { ImageResponse } from '@vercel/og';\nimport { env } from '../../utils/env';\nimport { fetchFont } from '../../utils/fetchFont';\n\nexport const config = {\n  runtime: 'edge',\n};\n\nconst fetchGithubStars = async () => {\n  const data = await (\n    await fetch('https://api.github.com/repos/trpc/trpc', {\n      headers: { authorization: `Bearer ${env.GITHUB_TOKEN}` },\n    })\n  ).json();\n  if (typeof data?.stargazers_count !== 'number')\n    throw new Error('Could not fetch stars');\n  return new Intl.NumberFormat().format(data.stargazers_count);\n};\n\nconst fetchNpmDownloads = async () => {\n  const data = await (\n    await fetch('https://api.npmjs.org/downloads/point/last-week/@trpc/server')\n  ).json();\n  if (typeof data?.downloads !== 'number')\n    throw new Error('Could not fetch npm downloads');\n  return new Intl.NumberFormat().format(data.downloads);\n};\n\n// const fetchTwitterFollowers = async () => {\n//   const data = await (\n//     await fetch(\n//       'https://api.twitter.com/2/users/1353123577193779201?user.fields=public_metrics',\n//       {\n//         headers: { authorization: `Bearer ${env.TWITTER_BEARER_TOKEN}` },\n//       },\n//     )\n//   ).json();\n//   if (typeof data?.data?.public_metrics?.followers_count !== 'number')\n//     throw new Error('Could not fetch twitter followers');\n//   return new Intl.NumberFormat().format(\n//     data?.data?.public_metrics?.followers_count,\n//   );\n// };\n\nexport default async (_req: Request) => {\n  const [inter800, inter700, ghStars, npmDownloads /**, twitterFollowers */] =\n    await Promise.all([\n      fetchFont('Inter', 800, 'tRPC   Move Fast and Break Nothing'),\n      fetchFont(\n        'Inter',\n        700,\n        'End-to-end typesafe APIs made easy. 0123456789,',\n      ),\n      fetchGithubStars(),\n      fetchNpmDownloads(),\n      // fetchTwitterFollowers(),\n    ]);\n\n  return new ImageResponse(\n    (\n      <div\n        tw=\"bg-zinc-900 h-full w-full text-white bg-cover flex flex-col p-14\"\n        style={{ fontFamily: 'Inter' }}\n      >\n        <img\n          src=\"https://assets.trpc.io/www/og-pattern-dark.svg\"\n          alt=\"background\"\n          tw=\"absolute\"\n        />\n        <div tw=\"flex flex-col justify-center items-center w-full h-full\">\n          <div tw=\"flex items-center\">\n            <img\n              src=\"https://assets.trpc.io/icons/svgs/blue-bg-rounded.svg\"\n              width=\"128px\"\n              height=\"128px\"\n              alt=\"tRPC logo\"\n            />\n            <h1 tw=\"text-8xl ml-8 font-extrabold\">tRPC</h1>\n          </div>\n          <div tw=\"flex flex-col items-center\">\n            <p tw=\"text-center pt-6 text-6xl font-extrabold\">\n              Move Fast and Break Nothing\n            </p>\n            <p tw=\"text-center pt-3 text-4xl text-zinc-300 font-bold mt-0\">\n              End-to-end typesafe APIs made easy.\n            </p>\n          </div>\n          <div tw=\"flex items-center text-zinc-300\">\n            <div tw=\"flex items-center mx-8\">\n              <div tw=\"flex items-center mx-8\">\n                <svg\n                  xmlns=\"http://www.w3.org/2000/svg\"\n                  height={36}\n                  fill=\"#fff\"\n                  viewBox=\"0 0 512 512\"\n                >\n                  <path d=\"M256 32C132.3 32 32 134.9 32 261.7c0 101.5 64.2 187.5 153.2 217.9a17.56 17.56 0 003.8.4c8.3 0 11.5-6.1 11.5-11.4 0-5.5-.2-19.9-.3-39.1a102.4 102.4 0 01-22.6 2.7c-43.1 0-52.9-33.5-52.9-33.5-10.2-26.5-24.9-33.6-24.9-33.6-19.5-13.7-.1-14.1 1.4-14.1h.1c22.5 2 34.3 23.8 34.3 23.8 11.2 19.6 26.2 25.1 39.6 25.1a63 63 0 0025.6-6c2-14.8 7.8-24.9 14.2-30.7-49.7-5.8-102-25.5-102-113.5 0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8a18.64 18.64 0 015-.5c8.1 0 26.4 3.1 56.6 24.1a208.21 208.21 0 01112.2 0c30.2-21 48.5-24.1 56.6-24.1a18.64 18.64 0 015 .5c12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6 0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5 0 30.7-.3 55.5-.3 63 0 5.4 3.1 11.5 11.4 11.5a19.35 19.35 0 004-.4C415.9 449.2 480 363.1 480 261.7 480 134.9 379.7 32 256 32z\" />\n                </svg>\n                <p tw=\"text-3xl font-bold ml-2\">{ghStars}</p>\n              </div>\n\n              {/* <div tw=\"flex items-center mx-8\">\n                <svg\n                  stroke=\"#fff\"\n                  fill=\"#fff\"\n                  viewBox=\"0 0 24 24\"\n                  height={32}\n                  width={32}\n                  xmlns=\"http://www.w3.org/2000/svg\"\n                >\n                  <path d=\"M23.953 4.57a10 10 0 01-2.825.775 4.958 4.958 0 002.163-2.723c-.951.555-2.005.959-3.127 1.184a4.92 4.92 0 00-8.384 4.482C7.69 8.095 4.067 6.13 1.64 3.162a4.822 4.822 0 00-.666 2.475c0 1.71.87 3.213 2.188 4.096a4.904 4.904 0 01-2.228-.616v.06a4.923 4.923 0 003.946 4.827 4.996 4.996 0 01-2.212.085 4.936 4.936 0 004.604 3.417 9.867 9.867 0 01-6.102 2.105c-.39 0-.779-.023-1.17-.067a13.995 13.995 0 007.557 2.209c9.053 0 13.998-7.496 13.998-13.985 0-.21 0-.42-.015-.63A9.935 9.935 0 0024 4.59z\" />\n                </svg>\n                <p tw=\"text-3xl font-bold ml-2\">{twitterFollowers}</p>\n              </div> */}\n\n              <div tw=\"flex items-center mx-8\">\n                {/* <svg\n                  xmlns=\"http://www.w3.org/2000/svg\"\n                  stroke=\"#fff\"\n                  fill=\"#fff\"\n                  height={48}\n                  viewBox=\"0 0 512 512\"\n                >\n                  <path d=\"M227.6 213.1H256v57.1h-28.4z\" />\n                  <path d=\"M0 156v171.4h142.2V356H256v-28.6h256V156zm142.2 142.9h-28.4v-85.7H85.3v85.7H28.4V184.6h113.8zm142.2 0h-56.9v28.6h-56.9V184.6h113.8zm199.2 0h-28.4v-85.7h-28.4v85.7h-28.4v-85.7H370v85.7h-56.9V184.6h170.7v114.3z\" />\n                </svg> */}\n                <svg\n                  role=\"img\"\n                  stroke=\"#fff\"\n                  fill=\"#fff\"\n                  height={32}\n                  viewBox=\"0 0 24 24\"\n                  xmlns=\"http://www.w3.org/2000/svg\"\n                >\n                  <path d=\"M1.763 0C.786 0 0 .786 0 1.763v20.474C0 23.214.786 24 1.763 24h20.474c.977 0 1.763-.786 1.763-1.763V1.763C24 .786 23.214 0 22.237 0zM5.13 5.323l13.837.019-.009 13.836h-3.464l.01-10.382h-3.456L12.04 19.17H5.113z\" />\n                </svg>\n                <p tw=\"text-3xl font-bold ml-2\">{npmDownloads}</p>\n              </div>\n            </div>\n          </div>\n        </div>\n      </div>\n    ),\n    {\n      headers: {\n        'Cache-Control': 's-maxage=86400, stale-while-revalidate',\n      },\n      width: 1200,\n      height: 600,\n      fonts: [\n        { name: 'Inter', data: inter800, weight: 800 },\n        { name: 'Inter', data: inter700, weight: 700 },\n      ],\n    },\n  );\n};",
    "repo": "trpc/trpc",
    "path": "./datasets/diagrams-repos/trpc/trpc/www/og-image/pages/api/landing.tsx",
    "query": "How are the different data sources (GitHub stars, npm downloads, Twitter followers) integrated into the OG image generation process?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'fetchGithubStars', 'node_id': 'fetchGithubStars', 'description': 'Fetches star count from GitHub API', 'visibility': 'private', 'return_type': 'Promise<string>', 'params': '', 'source_class_id': None}, {'type': 'function', 'name': 'fetchNpmDownloads', 'node_id': 'fetchNpmDownloads', 'description': 'Fetches download count from npm API', 'visibility': 'private', 'return_type': 'Promise<string>', 'params': '', 'source_class_id': None}, {'type': 'function', 'name': 'fetchTwitterFollowers', 'node_id': 'fetchTwitterFollowers', 'description': 'Fetches number of Twitter followers (commented out)', 'visibility': 'public', 'return_type': 'Promise<string>', 'params': '', 'source_class_id': None}, {'type': 'function', 'name': 'fetchFont', 'node_id': 'fetchFont', 'description': 'Fetches font for image rendering', 'visibility': 'private', 'return_type': 'Promise<ArrayBuffer>', 'params': 'name: string, weight: number, text: string', 'source_class_id': None}, {'type': 'function', 'name': 'default', 'node_id': 'default', 'description': 'Main function generating OG image with stats', 'visibility': 'public', 'return_type': 'Promise<ImageResponse>', 'params': '_req: Request', 'source_class_id': None}, {'type': 'entity', 'name': 'ImageResponse', 'node_id': 'ImageResponse', 'description': \"Vercel's OG image generation component\", 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'default', 'node_id_to': 'fetchGithubStars', 'description': 'calls to get GitHub stats'}, {'node_id_from': 'default', 'node_id_to': 'fetchNpmDownloads', 'description': 'calls to get npm stats'}, {'node_id_from': 'default', 'node_id_to': 'fetchTwitterFollowers', 'description': 'calls to get twitter followers (commented out)'}, {'node_id_from': 'default', 'node_id_to': 'fetchFont', 'description': 'calls to load fonts'}, {'node_id_from': 'default', 'node_id_to': 'ImageResponse', 'description': 'creates image'}], 'packages': [{'package_id': 'dataFetching', 'children': ['fetchGithubStars', 'fetchNpmDownloads', 'fetchTwitterFollowers'], 'description': 'Data fetching functions'}, {'package_id': 'imageGeneration', 'children': ['ImageResponse', 'fetchFont'], 'description': 'Image generation related components'}]}",
    "version": "medium",
    "text_answer": "The OG image integrates data from external sources through separate async functions: fetchGithubStars fetches repository stars from GitHub API, fetchNpmDownloads retrieves weekly download counts from npm, and there's a commented-out fetchTwitterFollowers function. These data points are fetched concurrently using Promise.all and then rendered into the final image using Vercel's ImageResponse.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { ImageResponse } from '@vercel/og';\nimport { env } from '../../utils/env';\nimport { fetchFont } from '../../utils/fetchFont';\n\nexport const config = {\n  runtime: 'edge',\n};\n\nconst fetchGithubStars = async () => {\n  const data = await (\n    await fetch('https://api.github.com/repos/trpc/trpc', {\n      headers: { authorization: `Bearer ${env.GITHUB_TOKEN}` },\n    })\n  ).json();\n  if (typeof data?.stargazers_count !== 'number')\n    throw new Error('Could not fetch stars');\n  return new Intl.NumberFormat().format(data.stargazers_count);\n};\n\nconst fetchNpmDownloads = async () => {\n  const data = await (\n    await fetch('https://api.npmjs.org/downloads/point/last-week/@trpc/server')\n  ).json();\n  if (typeof data?.downloads !== 'number')\n    throw new Error('Could not fetch npm downloads');\n  return new Intl.NumberFormat().format(data.downloads);\n};\n\n// const fetchTwitterFollowers = async () => {\n//   const data = await (\n//     await fetch(\n//       'https://api.twitter.com/2/users/1353123577193779201?user.fields=public_metrics',\n//       {\n//         headers: { authorization: `Bearer ${env.TWITTER_BEARER_TOKEN}` },\n//       },\n//     )\n//   ).json();\n//   if (typeof data?.data?.public_metrics?.followers_count !== 'number')\n//     throw new Error('Could not fetch twitter followers');\n//   return new Intl.NumberFormat().format(\n//     data?.data?.public_metrics?.followers_count,\n//   );\n// };\n\nexport default async (_req: Request) => {\n  const [inter800, inter700, ghStars, npmDownloads /**, twitterFollowers */] =\n    await Promise.all([\n      fetchFont('Inter', 800, 'tRPC   Move Fast and Break Nothing'),\n      fetchFont(\n        'Inter',\n        700,\n        'End-to-end typesafe APIs made easy. 0123456789,',\n      ),\n      fetchGithubStars(),\n      fetchNpmDownloads(),\n      // fetchTwitterFollowers(),\n    ]);\n\n  return new ImageResponse(\n    (\n      <div\n        tw=\"bg-zinc-900 h-full w-full text-white bg-cover flex flex-col p-14\"\n        style={{ fontFamily: 'Inter' }}\n      >\n        <img\n          src=\"https://assets.trpc.io/www/og-pattern-dark.svg\"\n          alt=\"background\"\n          tw=\"absolute\"\n        />\n        <div tw=\"flex flex-col justify-center items-center w-full h-full\">\n          <div tw=\"flex items-center\">\n            <img\n              src=\"https://assets.trpc.io/icons/svgs/blue-bg-rounded.svg\"\n              width=\"128px\"\n              height=\"128px\"\n              alt=\"tRPC logo\"\n            />\n            <h1 tw=\"text-8xl ml-8 font-extrabold\">tRPC</h1>\n          </div>\n          <div tw=\"flex flex-col items-center\">\n            <p tw=\"text-center pt-6 text-6xl font-extrabold\">\n              Move Fast and Break Nothing\n            </p>\n            <p tw=\"text-center pt-3 text-4xl text-zinc-300 font-bold mt-0\">\n              End-to-end typesafe APIs made easy.\n            </p>\n          </div>\n          <div tw=\"flex items-center text-zinc-300\">\n            <div tw=\"flex items-center mx-8\">\n              <div tw=\"flex items-center mx-8\">\n                <svg\n                  xmlns=\"http://www.w3.org/2000/svg\"\n                  height={36}\n                  fill=\"#fff\"\n                  viewBox=\"0 0 512 512\"\n                >\n                  <path d=\"M256 32C132.3 32 32 134.9 32 261.7c0 101.5 64.2 187.5 153.2 217.9a17.56 17.56 0 003.8.4c8.3 0 11.5-6.1 11.5-11.4 0-5.5-.2-19.9-.3-39.1a102.4 102.4 0 01-22.6 2.7c-43.1 0-52.9-33.5-52.9-33.5-10.2-26.5-24.9-33.6-24.9-33.6-19.5-13.7-.1-14.1 1.4-14.1h.1c22.5 2 34.3 23.8 34.3 23.8 11.2 19.6 26.2 25.1 39.6 25.1a63 63 0 0025.6-6c2-14.8 7.8-24.9 14.2-30.7-49.7-5.8-102-25.5-102-113.5 0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8a18.64 18.64 0 015-.5c8.1 0 26.4 3.1 56.6 24.1a208.21 208.21 0 01112.2 0c30.2-21 48.5-24.1 56.6-24.1a18.64 18.64 0 015 .5c12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6 0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5 0 30.7-.3 55.5-.3 63 0 5.4 3.1 11.5 11.4 11.5a19.35 19.35 0 004-.4C415.9 449.2 480 363.1 480 261.7 480 134.9 379.7 32 256 32z\" />\n                </svg>\n                <p tw=\"text-3xl font-bold ml-2\">{ghStars}</p>\n              </div>\n\n              {/* <div tw=\"flex items-center mx-8\">\n                <svg\n                  stroke=\"#fff\"\n                  fill=\"#fff\"\n                  viewBox=\"0 0 24 24\"\n                  height={32}\n                  width={32}\n                  xmlns=\"http://www.w3.org/2000/svg\"\n                >\n                  <path d=\"M23.953 4.57a10 10 0 01-2.825.775 4.958 4.958 0 002.163-2.723c-.951.555-2.005.959-3.127 1.184a4.92 4.92 0 00-8.384 4.482C7.69 8.095 4.067 6.13 1.64 3.162a4.822 4.822 0 00-.666 2.475c0 1.71.87 3.213 2.188 4.096a4.904 4.904 0 01-2.228-.616v.06a4.923 4.923 0 003.946 4.827 4.996 4.996 0 01-2.212.085 4.936 4.936 0 004.604 3.417 9.867 9.867 0 01-6.102 2.105c-.39 0-.779-.023-1.17-.067a13.995 13.995 0 007.557 2.209c9.053 0 13.998-7.496 13.998-13.985 0-.21 0-.42-.015-.63A9.935 9.935 0 0024 4.59z\" />\n                </svg>\n                <p tw=\"text-3xl font-bold ml-2\">{twitterFollowers}</p>\n              </div> */}\n\n              <div tw=\"flex items-center mx-8\">\n                {/* <svg\n                  xmlns=\"http://www.w3.org/2000/svg\"\n                  stroke=\"#fff\"\n                  fill=\"#fff\"\n                  height={48}\n                  viewBox=\"0 0 512 512\"\n                >\n                  <path d=\"M227.6 213.1H256v57.1h-28.4z\" />\n                  <path d=\"M0 156v171.4h142.2V356H256v-28.6h256V156zm142.2 142.9h-28.4v-85.7H85.3v85.7H28.4V184.6h113.8zm142.2 0h-56.9v28.6h-56.9V184.6h113.8zm199.2 0h-28.4v-85.7h-28.4v85.7h-28.4v-85.7H370v85.7h-56.9V184.6h170.7v114.3z\" />\n                </svg> */}\n                <svg\n                  role=\"img\"\n                  stroke=\"#fff\"\n                  fill=\"#fff\"\n                  height={32}\n                  viewBox=\"0 0 24 24\"\n                  xmlns=\"http://www.w3.org/2000/svg\"\n                >\n                  <path d=\"M1.763 0C.786 0 0 .786 0 1.763v20.474C0 23.214.786 24 1.763 24h20.474c.977 0 1.763-.786 1.763-1.763V1.763C24 .786 23.214 0 22.237 0zM5.13 5.323l13.837.019-.009 13.836h-3.464l.01-10.382h-3.456L12.04 19.17H5.113z\" />\n                </svg>\n                <p tw=\"text-3xl font-bold ml-2\">{npmDownloads}</p>\n              </div>\n            </div>\n          </div>\n        </div>\n      </div>\n    ),\n    {\n      headers: {\n        'Cache-Control': 's-maxage=86400, stale-while-revalidate',\n      },\n      width: 1200,\n      height: 600,\n      fonts: [\n        { name: 'Inter', data: inter800, weight: 800 },\n        { name: 'Inter', data: inter700, weight: 700 },\n      ],\n    },\n  );\n};",
    "repo": "trpc/trpc",
    "path": "./datasets/diagrams-repos/trpc/trpc/www/og-image/pages/api/landing.tsx",
    "query": "How are the different data sources (GitHub stars, npm downloads, Twitter followers) integrated into the OG image generation process?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'fetchGithubStars', 'node_id': 'fetchGithubStars', 'description': 'Fetches star count from GitHub API', 'visibility': 'private', 'return_type': 'Promise<string>', 'params': '', 'source_class_id': None}, {'type': 'function', 'name': 'fetchNpmDownloads', 'node_id': 'fetchNpmDownloads', 'description': 'Fetches download count from npm API', 'visibility': 'private', 'return_type': 'Promise<string>', 'params': '', 'source_class_id': None}, {'type': 'function', 'name': 'fetchTwitterFollowers', 'node_id': 'fetchTwitterFollowers', 'description': 'Fetches number of Twitter followers (commented out)', 'visibility': 'public', 'return_type': 'Promise<string>', 'params': '', 'source_class_id': None}, {'type': 'function', 'name': 'fetchFont', 'node_id': 'fetchFont', 'description': 'Fetches font for image rendering', 'visibility': 'private', 'return_type': 'Promise<ArrayBuffer>', 'params': 'name: string, weight: number, text: string', 'source_class_id': None}, {'type': 'function', 'name': 'default', 'node_id': 'default', 'description': 'Main function generating OG image with stats', 'visibility': 'public', 'return_type': 'Promise<ImageResponse>', 'params': '_req: Request', 'source_class_id': None}, {'type': 'entity', 'name': 'ImageResponse', 'node_id': 'ImageResponse', 'description': \"Vercel's OG image generation component\", 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'env', 'node_id': 'env', 'description': 'Environment variables', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'default', 'node_id_to': 'fetchGithubStars', 'description': 'calls to get GitHub stats'}, {'node_id_from': 'default', 'node_id_to': 'fetchNpmDownloads', 'description': 'calls to get npm stats'}, {'node_id_from': 'default', 'node_id_to': 'fetchTwitterFollowers', 'description': 'calls to get twitter followers (commented out)'}, {'node_id_from': 'default', 'node_id_to': 'fetchFont', 'description': 'calls to load fonts'}, {'node_id_from': 'default', 'node_id_to': 'ImageResponse', 'description': 'creates image'}, {'node_id_from': 'fetchNpmDownloads', 'node_id_to': 'env', 'description': 'GITHUB_TOKEN'}, {'node_id_from': 'fetchTwitterFollowers', 'node_id_to': 'env', 'description': 'TWITTER_BEARER_TOKEN'}], 'packages': [{'package_id': 'dataFetching', 'children': ['fetchGithubStars', 'fetchNpmDownloads', 'fetchTwitterFollowers'], 'description': 'Data fetching functions'}, {'package_id': 'imageGeneration', 'children': ['ImageResponse', 'fetchFont'], 'description': 'Image generation related components'}]}",
    "version": "full",
    "text_answer": "The OG image integrates data from external sources through separate async functions: fetchGithubStars fetches repository stars from GitHub API, fetchNpmDownloads retrieves weekly download counts from npm, and there's a commented-out fetchTwitterFollowers function. These data points are fetched concurrently using Promise.all and then rendered into the final image using Vercel's ImageResponse.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Scala",
    "code": "\npackage com.linkedin.feathr.offline.generation\n\nimport com.linkedin.feathr.exception.FeathrException\nimport com.linkedin.feathr.common.{ErasedEntityTaggedFeature, FeatureTypeConfig}\nimport com.linkedin.feathr.offline.derived.{DerivedFeature, DerivedFeatureEvaluator}\nimport com.linkedin.feathr.offline.evaluator.{BaseDataFrameMetadata, DerivedFeatureGenStage}\nimport com.linkedin.feathr.offline.logical.{FeatureGroups, MultiStageJoinPlan}\nimport com.linkedin.feathr.offline.{FeatureDataFrame, TestFeathr}\nimport org.mockito.Mockito._\nimport org.scalatest.mockito.MockitoSugar\nimport org.testng.Assert._\nimport org.testng.annotations.Test\n\nimport java.util\n\nclass TestStageEvaluator extends TestFeathr with MockitoSugar {\n\n  /**\n   * Test evaluateStage returns the input DataFrame if the derived feature already exists.\n   */\n  @Test\n  def testEvaluateStageSkipsComputationIfFeatureExists(): Unit = {\n    val mockAnalyzeFeatureInfo = mock[MultiStageJoinPlan]\n    val mockFeatureGroups = mock[FeatureGroups]\n    val mockDerivedFeature = mock[DerivedFeature]\n    val mockDerivedFeatureUtils = mock[DerivedFeatureEvaluator]\n\n    val erasedEntityTaggedAnchored =\n      Seq(new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"f\"), new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"g\"))\n\n    when(mockFeatureGroups.allDerivedFeatures).thenReturn(Map(\"h\" -> mockDerivedFeature))\n    when(mockDerivedFeature.consumedFeatureNames).thenReturn(erasedEntityTaggedAnchored)\n\n    val derivedFeatureGenStage = new DerivedFeatureGenStage(mockFeatureGroups, mockAnalyzeFeatureInfo, mockDerivedFeatureUtils)\n    val sqlContext = ss.sqlContext\n    import sqlContext.implicits._\n    val df =\n      Seq((1, \"f1\", \"g1\", \"h1\"), (2, \"f2\", \"g2\", \"h2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}f\", s\"${FeathrFeatureNamePrefix}g\", s\"${FeathrFeatureNamePrefix}h\")\n    val featureTypeMap =\n      Map(\"f\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG, \"g\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG, \"h\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG)\n    val featureDataFrame = FeatureDataFrame(df, featureTypeMap)\n    val evaluatedMap =\n      derivedFeatureGenStage.evaluate(Seq(\"h\"), Seq(0), Map(\"f\" -> (featureDataFrame, Seq(\"key\")), \"g\" -> (featureDataFrame, Seq(\"key\")))).groupBy(_._2._1.df)\n    assertEquals(evaluatedMap.size, 1) // exactly one DataFrame\n    assertEquals(evaluatedMap.head._2.size, 3)\n    assertTrue(evaluatedMap.head._2.contains(\"h\"))\n    verifyNoInteractions(mockDerivedFeatureUtils)\n  }\n\n  /**\n   * Test evaluateBaseDataFrameForDerivation joins DataFrames if the consumed features are on different DataFrames.\n   */\n  @Test\n  def testEvaluateBaseDataFrameWhenFeaturesAreOnDifferentDf(): Unit = {\n    val mockAnalyzeFeatureInfo = mock[MultiStageJoinPlan]\n    val mockFeatureGroups = mock[FeatureGroups]\n    val mockDerivedFeature = mock[DerivedFeature]\n    val mockDerivedFeatureUtils = mock[DerivedFeatureEvaluator]\n\n    val erasedEntityTaggedAnchored =\n      Seq(new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"f\"), new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"g\"))\n\n    when(mockFeatureGroups.allDerivedFeatures).thenReturn(Map(\"h\" -> mockDerivedFeature))\n    when(mockDerivedFeature.consumedFeatureNames).thenReturn(erasedEntityTaggedAnchored)\n\n    val derivedFeatureGenStage = new DerivedFeatureGenStage(mockFeatureGroups, mockAnalyzeFeatureInfo, mockDerivedFeatureUtils)\n    val sqlContext = ss.sqlContext\n    import sqlContext.implicits._\n    val df1 =\n      FeatureDataFrame(Seq((1, \"f1\"), (2, \"f2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}f\"), Map(\"f\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n    val df2 =\n      FeatureDataFrame(Seq((1, \"g1\"), (2, \"g2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}g\"), Map(\"g\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n\n    val BaseDataFrameMetadata(featureDataFrame, joinKeys, featuresOnBaseDf) =\n      derivedFeatureGenStage\n        .evaluateBaseDataFrameForDerivation(\"h\", mockDerivedFeature, Map(\"f\" -> (df1, Seq(\"key\")), \"g\" -> (df2, Seq(\"key\"))))\n    assertEquals(featureDataFrame.df.columns.length, 3)\n    assertEquals(s\"[${joinKeys.mkString(\",\")}]\", \"[key]\")\n    assertEquals(s\"[${featuresOnBaseDf.mkString(\",\")}]\", s\"[f,g]\")\n    verifyNoInteractions(mockDerivedFeatureUtils)\n  }\n\n  /**\n   * Test evaluateBaseDataFrameForDerivation fails if dependent features are not already evaluated.\n   */\n  @Test(\n    expectedExceptions = Array(classOf[FeathrException]),\n    expectedExceptionsMessageRegExp = \".*Error when processing derived feature.*Requires following features to be generated.*\")\n  def testEvaluateBaseDataFrameFailsWhenDependentFeaturesDoesNotExist(): Unit = {\n    val mockAnalyzeFeatureInfo = mock[MultiStageJoinPlan]\n    val mockFeatureGroups = mock[FeatureGroups]\n    val mockDerivedFeature = mock[DerivedFeature]\n    val mockDerivedFeatureUtils = mock[DerivedFeatureEvaluator]\n\n    val erasedEntityTaggedAnchored =\n      Seq(new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"f\"), new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"g\"))\n\n    when(mockFeatureGroups.allDerivedFeatures).thenReturn(Map(\"h\" -> mockDerivedFeature))\n    when(mockDerivedFeature.consumedFeatureNames).thenReturn(erasedEntityTaggedAnchored)\n\n    val derivedFeatureGenStage = new DerivedFeatureGenStage(mockFeatureGroups, mockAnalyzeFeatureInfo, mockDerivedFeatureUtils)\n    val sqlContext = ss.sqlContext\n    import sqlContext.implicits._\n    val df1 =\n      FeatureDataFrame(Seq((1, \"f1\"), (2, \"f2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}f\"), Map(\"f\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n    derivedFeatureGenStage\n      .evaluateBaseDataFrameForDerivation(\"h\", mockDerivedFeature, Map(\"f\" -> (df1, Seq(\"key\"))))\n  }\n\n  /**\n   * Test evaluateBaseDataFrameForDerivation fails if dependent features do not share the same join key.\n   * This is a cross join scenario.\n   */\n  @Test(\n    expectedExceptions = Array(classOf[FeathrException]),\n    expectedExceptionsMessageRegExp = \".*Error when processing derived feature.*Join Keys for dependent feature do not match.*\")\n  def testEvaluateBaseDataFrameFailsWhenJoinKeysDoNotMatch(): Unit = {\n    val mockAnalyzeFeatureInfo = mock[MultiStageJoinPlan]\n    val mockFeatureGroups = mock[FeatureGroups]\n    val mockDerivedFeature = mock[DerivedFeature]\n    val mockDerivedFeatureUtils = mock[DerivedFeatureEvaluator]\n\n    val erasedEntityTaggedAnchored =\n      Seq(new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"f\"), new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"g\"))\n\n    when(mockFeatureGroups.allDerivedFeatures).thenReturn(Map(\"h\" -> mockDerivedFeature))\n    when(mockDerivedFeature.consumedFeatureNames).thenReturn(erasedEntityTaggedAnchored)\n\n    val derivedFeatureGenStage = new DerivedFeatureGenStage(mockFeatureGroups, mockAnalyzeFeatureInfo, mockDerivedFeatureUtils)\n    val sqlContext = ss.sqlContext\n    import sqlContext.implicits._\n    val df1 =\n      FeatureDataFrame(Seq((1, \"f1\"), (2, \"f2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}f\"), Map(\"f\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n    val df2 =\n      FeatureDataFrame(Seq((1, \"g1\"), (2, \"g2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}g\"), Map(\"g\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n\n    derivedFeatureGenStage\n      .evaluateBaseDataFrameForDerivation(\"h\", mockDerivedFeature, Map(\"f\" -> (df1, Seq(\"key\")), \"g\" -> (df2, Seq(\"key\", \"rogueKey\"))))\n  }\n\n  /**\n   * Test evaluateBaseDataFrameForDerivation merges FeatureTypeMap.\n   */\n  @Test\n  def testEvaluateBaseDataFrameMergesFeatureTypeMap(): Unit = {\n    val mockAnalyzeFeatureInfo = mock[MultiStageJoinPlan]\n    val mockFeatureGroups = mock[FeatureGroups]\n    val mockDerivedFeature = mock[DerivedFeature]\n    val mockDerivedFeatureUtils = mock[DerivedFeatureEvaluator]\n\n    val erasedEntityTaggedAnchored =\n      Seq(new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"f\"), new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"g\"))\n\n    when(mockFeatureGroups.allDerivedFeatures).thenReturn(Map(\"h\" -> mockDerivedFeature))\n    when(mockDerivedFeature.consumedFeatureNames).thenReturn(erasedEntityTaggedAnchored)\n\n    val derivedFeatureGenStage = new DerivedFeatureGenStage(mockFeatureGroups, mockAnalyzeFeatureInfo, mockDerivedFeatureUtils)\n    val sqlContext = ss.sqlContext\n    import sqlContext.implicits._\n    val df1 =\n      FeatureDataFrame(Seq((1, \"f1\"), (2, \"f2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}f\"), Map(\"f\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n    val df2 =\n      FeatureDataFrame(Seq((1, \"g1\"), (2, \"g2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}g\"), Map(\"g\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n\n    val BaseDataFrameMetadata(featureDataFrame, joinKeys, featuresOnBaseDf) =\n      derivedFeatureGenStage\n        .evaluateBaseDataFrameForDerivation(\"h\", mockDerivedFeature, Map(\"f\" -> (df1, Seq(\"key\")), \"g\" -> (df2, Seq(\"key\"))))\n    assertEquals(featureDataFrame.df.columns.length, 3)\n    assertEquals(featureDataFrame.inferredFeatureType.keySet.size, 2)\n    assertTrue(Seq(\"f\", \"g\").forall(featureDataFrame.inferredFeatureType.keySet.contains))\n    verifyNoInteractions(mockDerivedFeatureUtils)\n  }\n\n  /**\n   * Test evaluateBaseDataFrameForDerivation does not fail FeatureTypeMap is empty.\n   */\n  @Test\n  def testEvaluateBaseDataFrameWithEmptyFeatureTypeMap(): Unit = {\n    val mockAnalyzeFeatureInfo = mock[MultiStageJoinPlan]\n    val mockFeatureGroups = mock[FeatureGroups]\n    val mockDerivedFeature = mock[DerivedFeature]\n    val mockDerivedFeatureUtils = mock[DerivedFeatureEvaluator]\n\n    val erasedEntityTaggedAnchored =\n      Seq(new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"f\"), new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"g\"))\n\n    when(mockFeatureGroups.allDerivedFeatures).thenReturn(Map(\"h\" -> mockDerivedFeature))\n    when(mockDerivedFeature.consumedFeatureNames).thenReturn(erasedEntityTaggedAnchored)\n\n    val derivedFeatureGenStage = new DerivedFeatureGenStage(mockFeatureGroups, mockAnalyzeFeatureInfo, mockDerivedFeatureUtils)\n    val sqlContext = ss.sqlContext\n    import sqlContext.implicits._\n    val df1 =\n      FeatureDataFrame(Seq((1, \"f1\"), (2, \"f2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}f\"), Map.empty[String, FeatureTypeConfig])\n    val df2 =\n      FeatureDataFrame(Seq((1, \"g1\"), (2, \"g2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}g\"), Map.empty[String, FeatureTypeConfig])\n\n    val BaseDataFrameMetadata(featureDataFrame, joinKeys, featuresOnBaseDf) =\n      derivedFeatureGenStage\n        .evaluateBaseDataFrameForDerivation(\"h\", mockDerivedFeature, Map(\"f\" -> (df1, Seq(\"key\")), \"g\" -> (df2, Seq(\"key\"))))\n    assertEquals(featureDataFrame.df.columns.length, 3)\n    assertEquals(s\"[${joinKeys.mkString(\",\")}]\", \"[key]\")\n    assertEquals(s\"[${featuresOnBaseDf.mkString(\",\")}]\", s\"[f,g]\")\n    verifyNoInteractions(mockDerivedFeatureUtils)\n  }\n}",
    "repo": "feathr-ai/feathr",
    "path": "./datasets/diagrams-repos/feathr-ai/feathr/feathr-impl/src/test/scala/com/linkedin/feathr/offline/generation/TestStageEvaluator.scala",
    "query": "Visualize the test method 'testEvaluateStageSkipsComputationIfFeatureExists'. Show how dataframes are created, manipulated, and verified.",
    "diagram": "{'nodes': [{'type': 'variable', 'name': 'df', 'node_id': 'df', 'description': 'Input DataFrame with features f, g, h', 'visibility': 'private', 'return_type': 'DataFrame', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'featureDataFrame', 'node_id': 'featureDataFrame', 'description': 'DataFrame wrapped with feature type information', 'visibility': 'private', 'return_type': 'FeatureDataFrame', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'evaluatedMap', 'node_id': 'evaluatedMap', 'description': 'Result of stage evaluation grouped by DataFrame', 'visibility': 'private', 'return_type': 'Map', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'df', 'node_id_to': 'featureDataFrame', 'description': 'Wraps with feature types'}, {'node_id_from': 'featureDataFrame', 'node_id_to': 'evaluatedMap', 'description': 'Evaluates features'}], 'packages': [{'package_id': 'testEvaluateStageSkipsComputationIfFeatureExists', 'children': ['df', 'featureDataFrame', 'evaluatedMap'], 'description': 'Test method to verify that stage evaluation skips computation if feature exists'}]}",
    "version": "minimal",
    "text_answer": "The test creates a DataFrame with features f, g, h, wraps it with feature type information into FeatureDataFrame, and verifies that DerivedFeatureGenStage skips computation when feature 'h' already exists in the input DataFrame.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Scala",
    "code": "\npackage com.linkedin.feathr.offline.generation\n\nimport com.linkedin.feathr.exception.FeathrException\nimport com.linkedin.feathr.common.{ErasedEntityTaggedFeature, FeatureTypeConfig}\nimport com.linkedin.feathr.offline.derived.{DerivedFeature, DerivedFeatureEvaluator}\nimport com.linkedin.feathr.offline.evaluator.{BaseDataFrameMetadata, DerivedFeatureGenStage}\nimport com.linkedin.feathr.offline.logical.{FeatureGroups, MultiStageJoinPlan}\nimport com.linkedin.feathr.offline.{FeatureDataFrame, TestFeathr}\nimport org.mockito.Mockito._\nimport org.scalatest.mockito.MockitoSugar\nimport org.testng.Assert._\nimport org.testng.annotations.Test\n\nimport java.util\n\nclass TestStageEvaluator extends TestFeathr with MockitoSugar {\n\n  /**\n   * Test evaluateStage returns the input DataFrame if the derived feature already exists.\n   */\n  @Test\n  def testEvaluateStageSkipsComputationIfFeatureExists(): Unit = {\n    val mockAnalyzeFeatureInfo = mock[MultiStageJoinPlan]\n    val mockFeatureGroups = mock[FeatureGroups]\n    val mockDerivedFeature = mock[DerivedFeature]\n    val mockDerivedFeatureUtils = mock[DerivedFeatureEvaluator]\n\n    val erasedEntityTaggedAnchored =\n      Seq(new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"f\"), new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"g\"))\n\n    when(mockFeatureGroups.allDerivedFeatures).thenReturn(Map(\"h\" -> mockDerivedFeature))\n    when(mockDerivedFeature.consumedFeatureNames).thenReturn(erasedEntityTaggedAnchored)\n\n    val derivedFeatureGenStage = new DerivedFeatureGenStage(mockFeatureGroups, mockAnalyzeFeatureInfo, mockDerivedFeatureUtils)\n    val sqlContext = ss.sqlContext\n    import sqlContext.implicits._\n    val df =\n      Seq((1, \"f1\", \"g1\", \"h1\"), (2, \"f2\", \"g2\", \"h2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}f\", s\"${FeathrFeatureNamePrefix}g\", s\"${FeathrFeatureNamePrefix}h\")\n    val featureTypeMap =\n      Map(\"f\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG, \"g\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG, \"h\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG)\n    val featureDataFrame = FeatureDataFrame(df, featureTypeMap)\n    val evaluatedMap =\n      derivedFeatureGenStage.evaluate(Seq(\"h\"), Seq(0), Map(\"f\" -> (featureDataFrame, Seq(\"key\")), \"g\" -> (featureDataFrame, Seq(\"key\")))).groupBy(_._2._1.df)\n    assertEquals(evaluatedMap.size, 1) // exactly one DataFrame\n    assertEquals(evaluatedMap.head._2.size, 3)\n    assertTrue(evaluatedMap.head._2.contains(\"h\"))\n    verifyNoInteractions(mockDerivedFeatureUtils)\n  }\n\n  /**\n   * Test evaluateBaseDataFrameForDerivation joins DataFrames if the consumed features are on different DataFrames.\n   */\n  @Test\n  def testEvaluateBaseDataFrameWhenFeaturesAreOnDifferentDf(): Unit = {\n    val mockAnalyzeFeatureInfo = mock[MultiStageJoinPlan]\n    val mockFeatureGroups = mock[FeatureGroups]\n    val mockDerivedFeature = mock[DerivedFeature]\n    val mockDerivedFeatureUtils = mock[DerivedFeatureEvaluator]\n\n    val erasedEntityTaggedAnchored =\n      Seq(new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"f\"), new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"g\"))\n\n    when(mockFeatureGroups.allDerivedFeatures).thenReturn(Map(\"h\" -> mockDerivedFeature))\n    when(mockDerivedFeature.consumedFeatureNames).thenReturn(erasedEntityTaggedAnchored)\n\n    val derivedFeatureGenStage = new DerivedFeatureGenStage(mockFeatureGroups, mockAnalyzeFeatureInfo, mockDerivedFeatureUtils)\n    val sqlContext = ss.sqlContext\n    import sqlContext.implicits._\n    val df1 =\n      FeatureDataFrame(Seq((1, \"f1\"), (2, \"f2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}f\"), Map(\"f\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n    val df2 =\n      FeatureDataFrame(Seq((1, \"g1\"), (2, \"g2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}g\"), Map(\"g\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n\n    val BaseDataFrameMetadata(featureDataFrame, joinKeys, featuresOnBaseDf) =\n      derivedFeatureGenStage\n        .evaluateBaseDataFrameForDerivation(\"h\", mockDerivedFeature, Map(\"f\" -> (df1, Seq(\"key\")), \"g\" -> (df2, Seq(\"key\"))))\n    assertEquals(featureDataFrame.df.columns.length, 3)\n    assertEquals(s\"[${joinKeys.mkString(\",\")}]\", \"[key]\")\n    assertEquals(s\"[${featuresOnBaseDf.mkString(\",\")}]\", s\"[f,g]\")\n    verifyNoInteractions(mockDerivedFeatureUtils)\n  }\n\n  /**\n   * Test evaluateBaseDataFrameForDerivation fails if dependent features are not already evaluated.\n   */\n  @Test(\n    expectedExceptions = Array(classOf[FeathrException]),\n    expectedExceptionsMessageRegExp = \".*Error when processing derived feature.*Requires following features to be generated.*\")\n  def testEvaluateBaseDataFrameFailsWhenDependentFeaturesDoesNotExist(): Unit = {\n    val mockAnalyzeFeatureInfo = mock[MultiStageJoinPlan]\n    val mockFeatureGroups = mock[FeatureGroups]\n    val mockDerivedFeature = mock[DerivedFeature]\n    val mockDerivedFeatureUtils = mock[DerivedFeatureEvaluator]\n\n    val erasedEntityTaggedAnchored =\n      Seq(new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"f\"), new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"g\"))\n\n    when(mockFeatureGroups.allDerivedFeatures).thenReturn(Map(\"h\" -> mockDerivedFeature))\n    when(mockDerivedFeature.consumedFeatureNames).thenReturn(erasedEntityTaggedAnchored)\n\n    val derivedFeatureGenStage = new DerivedFeatureGenStage(mockFeatureGroups, mockAnalyzeFeatureInfo, mockDerivedFeatureUtils)\n    val sqlContext = ss.sqlContext\n    import sqlContext.implicits._\n    val df1 =\n      FeatureDataFrame(Seq((1, \"f1\"), (2, \"f2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}f\"), Map(\"f\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n    derivedFeatureGenStage\n      .evaluateBaseDataFrameForDerivation(\"h\", mockDerivedFeature, Map(\"f\" -> (df1, Seq(\"key\"))))\n  }\n\n  /**\n   * Test evaluateBaseDataFrameForDerivation fails if dependent features do not share the same join key.\n   * This is a cross join scenario.\n   */\n  @Test(\n    expectedExceptions = Array(classOf[FeathrException]),\n    expectedExceptionsMessageRegExp = \".*Error when processing derived feature.*Join Keys for dependent feature do not match.*\")\n  def testEvaluateBaseDataFrameFailsWhenJoinKeysDoNotMatch(): Unit = {\n    val mockAnalyzeFeatureInfo = mock[MultiStageJoinPlan]\n    val mockFeatureGroups = mock[FeatureGroups]\n    val mockDerivedFeature = mock[DerivedFeature]\n    val mockDerivedFeatureUtils = mock[DerivedFeatureEvaluator]\n\n    val erasedEntityTaggedAnchored =\n      Seq(new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"f\"), new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"g\"))\n\n    when(mockFeatureGroups.allDerivedFeatures).thenReturn(Map(\"h\" -> mockDerivedFeature))\n    when(mockDerivedFeature.consumedFeatureNames).thenReturn(erasedEntityTaggedAnchored)\n\n    val derivedFeatureGenStage = new DerivedFeatureGenStage(mockFeatureGroups, mockAnalyzeFeatureInfo, mockDerivedFeatureUtils)\n    val sqlContext = ss.sqlContext\n    import sqlContext.implicits._\n    val df1 =\n      FeatureDataFrame(Seq((1, \"f1\"), (2, \"f2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}f\"), Map(\"f\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n    val df2 =\n      FeatureDataFrame(Seq((1, \"g1\"), (2, \"g2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}g\"), Map(\"g\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n\n    derivedFeatureGenStage\n      .evaluateBaseDataFrameForDerivation(\"h\", mockDerivedFeature, Map(\"f\" -> (df1, Seq(\"key\")), \"g\" -> (df2, Seq(\"key\", \"rogueKey\"))))\n  }\n\n  /**\n   * Test evaluateBaseDataFrameForDerivation merges FeatureTypeMap.\n   */\n  @Test\n  def testEvaluateBaseDataFrameMergesFeatureTypeMap(): Unit = {\n    val mockAnalyzeFeatureInfo = mock[MultiStageJoinPlan]\n    val mockFeatureGroups = mock[FeatureGroups]\n    val mockDerivedFeature = mock[DerivedFeature]\n    val mockDerivedFeatureUtils = mock[DerivedFeatureEvaluator]\n\n    val erasedEntityTaggedAnchored =\n      Seq(new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"f\"), new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"g\"))\n\n    when(mockFeatureGroups.allDerivedFeatures).thenReturn(Map(\"h\" -> mockDerivedFeature))\n    when(mockDerivedFeature.consumedFeatureNames).thenReturn(erasedEntityTaggedAnchored)\n\n    val derivedFeatureGenStage = new DerivedFeatureGenStage(mockFeatureGroups, mockAnalyzeFeatureInfo, mockDerivedFeatureUtils)\n    val sqlContext = ss.sqlContext\n    import sqlContext.implicits._\n    val df1 =\n      FeatureDataFrame(Seq((1, \"f1\"), (2, \"f2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}f\"), Map(\"f\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n    val df2 =\n      FeatureDataFrame(Seq((1, \"g1\"), (2, \"g2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}g\"), Map(\"g\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n\n    val BaseDataFrameMetadata(featureDataFrame, joinKeys, featuresOnBaseDf) =\n      derivedFeatureGenStage\n        .evaluateBaseDataFrameForDerivation(\"h\", mockDerivedFeature, Map(\"f\" -> (df1, Seq(\"key\")), \"g\" -> (df2, Seq(\"key\"))))\n    assertEquals(featureDataFrame.df.columns.length, 3)\n    assertEquals(featureDataFrame.inferredFeatureType.keySet.size, 2)\n    assertTrue(Seq(\"f\", \"g\").forall(featureDataFrame.inferredFeatureType.keySet.contains))\n    verifyNoInteractions(mockDerivedFeatureUtils)\n  }\n\n  /**\n   * Test evaluateBaseDataFrameForDerivation does not fail FeatureTypeMap is empty.\n   */\n  @Test\n  def testEvaluateBaseDataFrameWithEmptyFeatureTypeMap(): Unit = {\n    val mockAnalyzeFeatureInfo = mock[MultiStageJoinPlan]\n    val mockFeatureGroups = mock[FeatureGroups]\n    val mockDerivedFeature = mock[DerivedFeature]\n    val mockDerivedFeatureUtils = mock[DerivedFeatureEvaluator]\n\n    val erasedEntityTaggedAnchored =\n      Seq(new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"f\"), new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"g\"))\n\n    when(mockFeatureGroups.allDerivedFeatures).thenReturn(Map(\"h\" -> mockDerivedFeature))\n    when(mockDerivedFeature.consumedFeatureNames).thenReturn(erasedEntityTaggedAnchored)\n\n    val derivedFeatureGenStage = new DerivedFeatureGenStage(mockFeatureGroups, mockAnalyzeFeatureInfo, mockDerivedFeatureUtils)\n    val sqlContext = ss.sqlContext\n    import sqlContext.implicits._\n    val df1 =\n      FeatureDataFrame(Seq((1, \"f1\"), (2, \"f2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}f\"), Map.empty[String, FeatureTypeConfig])\n    val df2 =\n      FeatureDataFrame(Seq((1, \"g1\"), (2, \"g2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}g\"), Map.empty[String, FeatureTypeConfig])\n\n    val BaseDataFrameMetadata(featureDataFrame, joinKeys, featuresOnBaseDf) =\n      derivedFeatureGenStage\n        .evaluateBaseDataFrameForDerivation(\"h\", mockDerivedFeature, Map(\"f\" -> (df1, Seq(\"key\")), \"g\" -> (df2, Seq(\"key\"))))\n    assertEquals(featureDataFrame.df.columns.length, 3)\n    assertEquals(s\"[${joinKeys.mkString(\",\")}]\", \"[key]\")\n    assertEquals(s\"[${featuresOnBaseDf.mkString(\",\")}]\", s\"[f,g]\")\n    verifyNoInteractions(mockDerivedFeatureUtils)\n  }\n}",
    "repo": "feathr-ai/feathr",
    "path": "./datasets/diagrams-repos/feathr-ai/feathr/feathr-impl/src/test/scala/com/linkedin/feathr/offline/generation/TestStageEvaluator.scala",
    "query": "Visualize the test method 'testEvaluateStageSkipsComputationIfFeatureExists'. Show how dataframes are created, manipulated, and verified.",
    "diagram": "{'nodes': [{'type': 'variable', 'name': 'mockDerivedFeatureUtils', 'node_id': 'mockDerivedFeatureUtils', 'description': 'Mock object for derived feature evaluation', 'visibility': 'private', 'return_type': 'DerivedFeatureEvaluator', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'df', 'node_id': 'df', 'description': 'Input DataFrame with features f, g, h', 'visibility': 'private', 'return_type': 'DataFrame', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'featureTypeMap', 'node_id': 'featureTypeMap', 'description': 'Map of feature names to their types', 'visibility': 'private', 'return_type': 'Map', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'featureDataFrame', 'node_id': 'featureDataFrame', 'description': 'DataFrame wrapped with feature type information', 'visibility': 'private', 'return_type': 'FeatureDataFrame', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'evaluatedMap', 'node_id': 'evaluatedMap', 'description': 'Result of stage evaluation grouped by DataFrame', 'visibility': 'private', 'return_type': 'Map', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'derivedFeatureGenStage', 'node_id': 'derivedFeatureGenStage', 'description': 'Stage for generating derived features', 'visibility': 'private', 'return_type': 'DerivedFeatureGenStage', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'df', 'node_id_to': 'featureDataFrame', 'description': 'Wraps with feature types'}, {'node_id_from': 'featureTypeMap', 'node_id_to': 'featureDataFrame', 'description': 'Provides type information'}, {'node_id_from': 'featureDataFrame', 'node_id_to': 'evaluatedMap', 'description': 'Evaluates features'}, {'node_id_from': 'derivedFeatureGenStage', 'node_id_to': 'evaluatedMap', 'description': 'Performs evaluation'}, {'node_id_from': 'mockDerivedFeatureUtils', 'node_id_to': 'derivedFeatureGenStage', 'description': 'Used in construction'}], 'packages': [{'package_id': 'testEvaluateStageSkipsComputationIfFeatureExists', 'children': ['df', 'featureTypeMap', 'featureDataFrame', 'evaluatedMap', 'mocks'], 'description': 'Test method to verify that stage evaluation skips computation if feature exists'}, {'package_id': 'mocks', 'children': ['mockDerivedFeatureUtils', 'derivedFeatureGenStage'], 'description': 'Mock objects and test infrastructure'}]}",
    "version": "medium",
    "text_answer": "The test creates a DataFrame with features f, g, h, wraps it with feature type information into FeatureDataFrame, and verifies that DerivedFeatureGenStage skips computation when feature 'h' already exists in the input DataFrame.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Scala",
    "code": "\npackage com.linkedin.feathr.offline.generation\n\nimport com.linkedin.feathr.exception.FeathrException\nimport com.linkedin.feathr.common.{ErasedEntityTaggedFeature, FeatureTypeConfig}\nimport com.linkedin.feathr.offline.derived.{DerivedFeature, DerivedFeatureEvaluator}\nimport com.linkedin.feathr.offline.evaluator.{BaseDataFrameMetadata, DerivedFeatureGenStage}\nimport com.linkedin.feathr.offline.logical.{FeatureGroups, MultiStageJoinPlan}\nimport com.linkedin.feathr.offline.{FeatureDataFrame, TestFeathr}\nimport org.mockito.Mockito._\nimport org.scalatest.mockito.MockitoSugar\nimport org.testng.Assert._\nimport org.testng.annotations.Test\n\nimport java.util\n\nclass TestStageEvaluator extends TestFeathr with MockitoSugar {\n\n  /**\n   * Test evaluateStage returns the input DataFrame if the derived feature already exists.\n   */\n  @Test\n  def testEvaluateStageSkipsComputationIfFeatureExists(): Unit = {\n    val mockAnalyzeFeatureInfo = mock[MultiStageJoinPlan]\n    val mockFeatureGroups = mock[FeatureGroups]\n    val mockDerivedFeature = mock[DerivedFeature]\n    val mockDerivedFeatureUtils = mock[DerivedFeatureEvaluator]\n\n    val erasedEntityTaggedAnchored =\n      Seq(new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"f\"), new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"g\"))\n\n    when(mockFeatureGroups.allDerivedFeatures).thenReturn(Map(\"h\" -> mockDerivedFeature))\n    when(mockDerivedFeature.consumedFeatureNames).thenReturn(erasedEntityTaggedAnchored)\n\n    val derivedFeatureGenStage = new DerivedFeatureGenStage(mockFeatureGroups, mockAnalyzeFeatureInfo, mockDerivedFeatureUtils)\n    val sqlContext = ss.sqlContext\n    import sqlContext.implicits._\n    val df =\n      Seq((1, \"f1\", \"g1\", \"h1\"), (2, \"f2\", \"g2\", \"h2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}f\", s\"${FeathrFeatureNamePrefix}g\", s\"${FeathrFeatureNamePrefix}h\")\n    val featureTypeMap =\n      Map(\"f\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG, \"g\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG, \"h\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG)\n    val featureDataFrame = FeatureDataFrame(df, featureTypeMap)\n    val evaluatedMap =\n      derivedFeatureGenStage.evaluate(Seq(\"h\"), Seq(0), Map(\"f\" -> (featureDataFrame, Seq(\"key\")), \"g\" -> (featureDataFrame, Seq(\"key\")))).groupBy(_._2._1.df)\n    assertEquals(evaluatedMap.size, 1) // exactly one DataFrame\n    assertEquals(evaluatedMap.head._2.size, 3)\n    assertTrue(evaluatedMap.head._2.contains(\"h\"))\n    verifyNoInteractions(mockDerivedFeatureUtils)\n  }\n\n  /**\n   * Test evaluateBaseDataFrameForDerivation joins DataFrames if the consumed features are on different DataFrames.\n   */\n  @Test\n  def testEvaluateBaseDataFrameWhenFeaturesAreOnDifferentDf(): Unit = {\n    val mockAnalyzeFeatureInfo = mock[MultiStageJoinPlan]\n    val mockFeatureGroups = mock[FeatureGroups]\n    val mockDerivedFeature = mock[DerivedFeature]\n    val mockDerivedFeatureUtils = mock[DerivedFeatureEvaluator]\n\n    val erasedEntityTaggedAnchored =\n      Seq(new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"f\"), new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"g\"))\n\n    when(mockFeatureGroups.allDerivedFeatures).thenReturn(Map(\"h\" -> mockDerivedFeature))\n    when(mockDerivedFeature.consumedFeatureNames).thenReturn(erasedEntityTaggedAnchored)\n\n    val derivedFeatureGenStage = new DerivedFeatureGenStage(mockFeatureGroups, mockAnalyzeFeatureInfo, mockDerivedFeatureUtils)\n    val sqlContext = ss.sqlContext\n    import sqlContext.implicits._\n    val df1 =\n      FeatureDataFrame(Seq((1, \"f1\"), (2, \"f2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}f\"), Map(\"f\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n    val df2 =\n      FeatureDataFrame(Seq((1, \"g1\"), (2, \"g2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}g\"), Map(\"g\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n\n    val BaseDataFrameMetadata(featureDataFrame, joinKeys, featuresOnBaseDf) =\n      derivedFeatureGenStage\n        .evaluateBaseDataFrameForDerivation(\"h\", mockDerivedFeature, Map(\"f\" -> (df1, Seq(\"key\")), \"g\" -> (df2, Seq(\"key\"))))\n    assertEquals(featureDataFrame.df.columns.length, 3)\n    assertEquals(s\"[${joinKeys.mkString(\",\")}]\", \"[key]\")\n    assertEquals(s\"[${featuresOnBaseDf.mkString(\",\")}]\", s\"[f,g]\")\n    verifyNoInteractions(mockDerivedFeatureUtils)\n  }\n\n  /**\n   * Test evaluateBaseDataFrameForDerivation fails if dependent features are not already evaluated.\n   */\n  @Test(\n    expectedExceptions = Array(classOf[FeathrException]),\n    expectedExceptionsMessageRegExp = \".*Error when processing derived feature.*Requires following features to be generated.*\")\n  def testEvaluateBaseDataFrameFailsWhenDependentFeaturesDoesNotExist(): Unit = {\n    val mockAnalyzeFeatureInfo = mock[MultiStageJoinPlan]\n    val mockFeatureGroups = mock[FeatureGroups]\n    val mockDerivedFeature = mock[DerivedFeature]\n    val mockDerivedFeatureUtils = mock[DerivedFeatureEvaluator]\n\n    val erasedEntityTaggedAnchored =\n      Seq(new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"f\"), new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"g\"))\n\n    when(mockFeatureGroups.allDerivedFeatures).thenReturn(Map(\"h\" -> mockDerivedFeature))\n    when(mockDerivedFeature.consumedFeatureNames).thenReturn(erasedEntityTaggedAnchored)\n\n    val derivedFeatureGenStage = new DerivedFeatureGenStage(mockFeatureGroups, mockAnalyzeFeatureInfo, mockDerivedFeatureUtils)\n    val sqlContext = ss.sqlContext\n    import sqlContext.implicits._\n    val df1 =\n      FeatureDataFrame(Seq((1, \"f1\"), (2, \"f2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}f\"), Map(\"f\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n    derivedFeatureGenStage\n      .evaluateBaseDataFrameForDerivation(\"h\", mockDerivedFeature, Map(\"f\" -> (df1, Seq(\"key\"))))\n  }\n\n  /**\n   * Test evaluateBaseDataFrameForDerivation fails if dependent features do not share the same join key.\n   * This is a cross join scenario.\n   */\n  @Test(\n    expectedExceptions = Array(classOf[FeathrException]),\n    expectedExceptionsMessageRegExp = \".*Error when processing derived feature.*Join Keys for dependent feature do not match.*\")\n  def testEvaluateBaseDataFrameFailsWhenJoinKeysDoNotMatch(): Unit = {\n    val mockAnalyzeFeatureInfo = mock[MultiStageJoinPlan]\n    val mockFeatureGroups = mock[FeatureGroups]\n    val mockDerivedFeature = mock[DerivedFeature]\n    val mockDerivedFeatureUtils = mock[DerivedFeatureEvaluator]\n\n    val erasedEntityTaggedAnchored =\n      Seq(new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"f\"), new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"g\"))\n\n    when(mockFeatureGroups.allDerivedFeatures).thenReturn(Map(\"h\" -> mockDerivedFeature))\n    when(mockDerivedFeature.consumedFeatureNames).thenReturn(erasedEntityTaggedAnchored)\n\n    val derivedFeatureGenStage = new DerivedFeatureGenStage(mockFeatureGroups, mockAnalyzeFeatureInfo, mockDerivedFeatureUtils)\n    val sqlContext = ss.sqlContext\n    import sqlContext.implicits._\n    val df1 =\n      FeatureDataFrame(Seq((1, \"f1\"), (2, \"f2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}f\"), Map(\"f\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n    val df2 =\n      FeatureDataFrame(Seq((1, \"g1\"), (2, \"g2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}g\"), Map(\"g\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n\n    derivedFeatureGenStage\n      .evaluateBaseDataFrameForDerivation(\"h\", mockDerivedFeature, Map(\"f\" -> (df1, Seq(\"key\")), \"g\" -> (df2, Seq(\"key\", \"rogueKey\"))))\n  }\n\n  /**\n   * Test evaluateBaseDataFrameForDerivation merges FeatureTypeMap.\n   */\n  @Test\n  def testEvaluateBaseDataFrameMergesFeatureTypeMap(): Unit = {\n    val mockAnalyzeFeatureInfo = mock[MultiStageJoinPlan]\n    val mockFeatureGroups = mock[FeatureGroups]\n    val mockDerivedFeature = mock[DerivedFeature]\n    val mockDerivedFeatureUtils = mock[DerivedFeatureEvaluator]\n\n    val erasedEntityTaggedAnchored =\n      Seq(new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"f\"), new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"g\"))\n\n    when(mockFeatureGroups.allDerivedFeatures).thenReturn(Map(\"h\" -> mockDerivedFeature))\n    when(mockDerivedFeature.consumedFeatureNames).thenReturn(erasedEntityTaggedAnchored)\n\n    val derivedFeatureGenStage = new DerivedFeatureGenStage(mockFeatureGroups, mockAnalyzeFeatureInfo, mockDerivedFeatureUtils)\n    val sqlContext = ss.sqlContext\n    import sqlContext.implicits._\n    val df1 =\n      FeatureDataFrame(Seq((1, \"f1\"), (2, \"f2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}f\"), Map(\"f\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n    val df2 =\n      FeatureDataFrame(Seq((1, \"g1\"), (2, \"g2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}g\"), Map(\"g\" -> FeatureTypeConfig.CATEGORICAL_TYPE_CONFIG))\n\n    val BaseDataFrameMetadata(featureDataFrame, joinKeys, featuresOnBaseDf) =\n      derivedFeatureGenStage\n        .evaluateBaseDataFrameForDerivation(\"h\", mockDerivedFeature, Map(\"f\" -> (df1, Seq(\"key\")), \"g\" -> (df2, Seq(\"key\"))))\n    assertEquals(featureDataFrame.df.columns.length, 3)\n    assertEquals(featureDataFrame.inferredFeatureType.keySet.size, 2)\n    assertTrue(Seq(\"f\", \"g\").forall(featureDataFrame.inferredFeatureType.keySet.contains))\n    verifyNoInteractions(mockDerivedFeatureUtils)\n  }\n\n  /**\n   * Test evaluateBaseDataFrameForDerivation does not fail FeatureTypeMap is empty.\n   */\n  @Test\n  def testEvaluateBaseDataFrameWithEmptyFeatureTypeMap(): Unit = {\n    val mockAnalyzeFeatureInfo = mock[MultiStageJoinPlan]\n    val mockFeatureGroups = mock[FeatureGroups]\n    val mockDerivedFeature = mock[DerivedFeature]\n    val mockDerivedFeatureUtils = mock[DerivedFeatureEvaluator]\n\n    val erasedEntityTaggedAnchored =\n      Seq(new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"f\"), new ErasedEntityTaggedFeature(new util.ArrayList[Integer](0), \"g\"))\n\n    when(mockFeatureGroups.allDerivedFeatures).thenReturn(Map(\"h\" -> mockDerivedFeature))\n    when(mockDerivedFeature.consumedFeatureNames).thenReturn(erasedEntityTaggedAnchored)\n\n    val derivedFeatureGenStage = new DerivedFeatureGenStage(mockFeatureGroups, mockAnalyzeFeatureInfo, mockDerivedFeatureUtils)\n    val sqlContext = ss.sqlContext\n    import sqlContext.implicits._\n    val df1 =\n      FeatureDataFrame(Seq((1, \"f1\"), (2, \"f2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}f\"), Map.empty[String, FeatureTypeConfig])\n    val df2 =\n      FeatureDataFrame(Seq((1, \"g1\"), (2, \"g2\")).toDF(\"key\", s\"${FeathrFeatureNamePrefix}g\"), Map.empty[String, FeatureTypeConfig])\n\n    val BaseDataFrameMetadata(featureDataFrame, joinKeys, featuresOnBaseDf) =\n      derivedFeatureGenStage\n        .evaluateBaseDataFrameForDerivation(\"h\", mockDerivedFeature, Map(\"f\" -> (df1, Seq(\"key\")), \"g\" -> (df2, Seq(\"key\"))))\n    assertEquals(featureDataFrame.df.columns.length, 3)\n    assertEquals(s\"[${joinKeys.mkString(\",\")}]\", \"[key]\")\n    assertEquals(s\"[${featuresOnBaseDf.mkString(\",\")}]\", s\"[f,g]\")\n    verifyNoInteractions(mockDerivedFeatureUtils)\n  }\n}",
    "repo": "feathr-ai/feathr",
    "path": "./datasets/diagrams-repos/feathr-ai/feathr/feathr-impl/src/test/scala/com/linkedin/feathr/offline/generation/TestStageEvaluator.scala",
    "query": "Visualize the test method 'testEvaluateStageSkipsComputationIfFeatureExists'. Show how dataframes are created, manipulated, and verified.",
    "diagram": "{'nodes': [{'type': 'variable', 'name': 'mockAnalyzeFeatureInfo', 'node_id': 'mockAnalyzeFeatureInfo', 'description': 'Mock object for feature analysis', 'visibility': 'private', 'return_type': 'MultiStageJoinPlan', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'mockFeatureGroups', 'node_id': 'mockFeatureGroups', 'description': 'Mock object for feature groups', 'visibility': 'private', 'return_type': 'FeatureGroups', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'mockDerivedFeature', 'node_id': 'mockDerivedFeature', 'description': 'Mock object for derived feature', 'visibility': 'private', 'return_type': 'DerivedFeature', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'mockDerivedFeatureUtils', 'node_id': 'mockDerivedFeatureUtils', 'description': 'Mock object for derived feature evaluation', 'visibility': 'private', 'return_type': 'DerivedFeatureEvaluator', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'erasedEntityTaggedAnchored', 'node_id': 'erasedEntityTaggedAnchored', 'description': 'List of tagged features', 'visibility': 'private', 'return_type': 'Seq[ErasedEntityTaggedFeature]', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'sqlContext', 'node_id': 'sqlContext', 'description': 'SQL context for DataFrame operations', 'visibility': 'private', 'return_type': 'SQLContext', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'df', 'node_id': 'df', 'description': 'Input DataFrame with features f, g, h', 'visibility': 'private', 'return_type': 'DataFrame', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'featureTypeMap', 'node_id': 'featureTypeMap', 'description': 'Map of feature names to their types', 'visibility': 'private', 'return_type': 'Map', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'featureDataFrame', 'node_id': 'featureDataFrame', 'description': 'DataFrame wrapped with feature type information', 'visibility': 'private', 'return_type': 'FeatureDataFrame', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'evaluatedMap', 'node_id': 'evaluatedMap', 'description': 'Result of stage evaluation grouped by DataFrame', 'visibility': 'private', 'return_type': 'Map', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'derivedFeatureGenStage', 'node_id': 'derivedFeatureGenStage', 'description': 'Stage for generating derived features', 'visibility': 'private', 'return_type': 'DerivedFeatureGenStage', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'mockFeatureGroups', 'node_id_to': 'derivedFeatureGenStage', 'description': 'Used in construction'}, {'node_id_from': 'mockAnalyzeFeatureInfo', 'node_id_to': 'derivedFeatureGenStage', 'description': 'Used in construction'}, {'node_id_from': 'mockDerivedFeatureUtils', 'node_id_to': 'derivedFeatureGenStage', 'description': 'Used in construction'}, {'node_id_from': 'sqlContext', 'node_id_to': 'df', 'description': 'Creates'}, {'node_id_from': 'df', 'node_id_to': 'featureDataFrame', 'description': 'Wraps with feature types'}, {'node_id_from': 'featureTypeMap', 'node_id_to': 'featureDataFrame', 'description': 'Provides type information'}, {'node_id_from': 'featureDataFrame', 'node_id_to': 'evaluatedMap', 'description': 'Evaluates features'}, {'node_id_from': 'derivedFeatureGenStage', 'node_id_to': 'evaluatedMap', 'description': 'Performs evaluation'}, {'node_id_from': 'mockDerivedFeature', 'node_id_to': 'erasedEntityTaggedAnchored', 'description': 'Consumes features'}, {'node_id_from': 'mockFeatureGroups', 'node_id_to': 'mockDerivedFeature', 'description': ''}], 'packages': [{'package_id': 'testEvaluateStageSkipsComputationIfFeatureExists', 'children': ['df', 'featureTypeMap', 'featureDataFrame', 'evaluatedMap', 'mocks', 'infrastructure'], 'description': 'Test method to verify that stage evaluation skips computation if feature exists'}, {'package_id': 'mocks', 'children': ['mockAnalyzeFeatureInfo', 'mockFeatureGroups', 'mockDerivedFeature', 'mockDerivedFeatureUtils'], 'description': 'Mock objects'}, {'package_id': 'infrastructure', 'children': ['sqlContext', 'derivedFeatureGenStage', 'erasedEntityTaggedAnchored'], 'description': 'Test infrastructure components'}]}",
    "version": "full",
    "text_answer": "The test creates a DataFrame with features f, g, h, wraps it with feature type information into FeatureDataFrame, and verifies that DerivedFeatureGenStage skips computation when feature 'h' already exists in the input DataFrame.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include \"SupervisorCallMonitor/misc_utility.h\"\n#include \"dobby_internal.h\"\n#include \"PlatformUtil/ProcessRuntimeUtility.h\"\n\n#include \"misc-helper/async_logger.h\"\n\n#include <vector>\nstd::vector<DBICallTy> *g_supervisor_call_handlers;\n\nstatic const char *fast_get_main_app_bundle_udid() {\n  static char *main_app_bundle_udid = NULL;\n  if (main_app_bundle_udid)\n    return main_app_bundle_udid;\n\n  auto main = ProcessRuntimeUtility::GetProcessModuleMap()[0];\n  char main_binary_path[2048] = {0};\n  if (realpath(main.path, main_binary_path) == NULL)\n    return NULL;\n\n  char *bundle_udid_ndx = main_binary_path + strlen(\"/private/var/containers/Bundle/Application/\");\n  main_app_bundle_udid = (char *)malloc(36 + 1);\n  strncpy(main_app_bundle_udid, bundle_udid_ndx, 36);\n  main_app_bundle_udid[36] = 0;\n  return main_app_bundle_udid;\n}\n\nstatic void common_supervisor_call_monitor_handler(RegisterContext *ctx, const HookEntryInfo *info) {\n  if (g_supervisor_call_handlers == NULL) {\n    return;\n  }\n  for (auto handler : *g_supervisor_call_handlers) {\n    handler(ctx, info);\n  }\n}\n\nvoid supervisor_call_monitor_register_handler(DBICallTy handler) {\n  if (g_supervisor_call_handlers == NULL) {\n    g_supervisor_call_handlers = new std::vector<DBICallTy>();\n  }\n  g_supervisor_call_handlers->push_back(handler);\n}\n\nstd::vector<addr_t> *g_svc_addr_array;\n\nvoid supervisor_call_monitor_register_svc(addr_t svc_addr) {\n  if (g_svc_addr_array == NULL) {\n    g_svc_addr_array = new std::vector<addr_t>();\n  }\n\n  if (g_svc_addr_array) {\n    auto iter = g_svc_addr_array->begin();\n    for (; iter != g_svc_addr_array->end(); iter++) {\n      if (*iter == svc_addr)\n        return;\n    }\n  }\n\n  g_svc_addr_array->push_back(svc_addr);\n  DobbyInstrument((void *)svc_addr, common_supervisor_call_monitor_handler);\n  DLOG(2, \"register supervisor_call_monitor at %p\", svc_addr);\n}\n\nvoid supervisor_call_monitor_register_image(void *header) {\n  auto text_section = macho_kit_get_section_by_name((mach_header_t *)header, \"__TEXT\", \"__text\");\n\n  addr_t insn_addr = (addr_t)header + (addr_t)text_section->offset;\n  addr_t insn_addr_end = insn_addr + text_section->size;\n\n  for (; insn_addr < insn_addr_end; insn_addr += sizeof(uint32_t)) {\n    if (*(uint32_t *)insn_addr == 0xd4001001) {\n      supervisor_call_monitor_register_svc((addr_t)insn_addr);\n    }\n  }\n}\n\nvoid supervisor_call_monitor_register_main_app() {\n  const char *main_bundle_udid = fast_get_main_app_bundle_udid();\n  auto module_map = ProcessRuntimeUtility::GetProcessModuleMap();\n  for (auto module : module_map) {\n    if (strstr(module.path, main_bundle_udid)) {\n      LOG(2, \"[supervisor_call_monitor] %s\", module.path);\n      supervisor_call_monitor_register_image((void *)module.load_address);\n    }\n  }\n}\n\nextern \"C\" int __shared_region_check_np(uint64_t *startaddress);\n\nstruct dyld_cache_header *shared_cache_get_load_addr() {\n  static struct dyld_cache_header *shared_cache_load_addr = 0;\n  if (shared_cache_load_addr)\n    return shared_cache_load_addr;\n#if 0\n  if (syscall(294, &shared_cache_load_addr) == 0) {\n#else\n  // FIXME:\n  if (__shared_region_check_np((uint64_t *)&shared_cache_load_addr) != 0) {\n#endif\n  shared_cache_load_addr = 0;\n}\nreturn shared_cache_load_addr;\n}\nvoid supervisor_call_monitor_register_system_kernel() {\n  auto libsystem = ProcessRuntimeUtility::GetProcessModule(\"libsystem_kernel.dylib\");\n  addr_t libsystem_header = (addr_t)libsystem.load_address;\n  auto text_section = macho_kit_get_section_by_name((mach_header_t *)libsystem_header, \"__TEXT\", \"__text\");\n\n  addr_t shared_cache_load_addr = (addr_t)shared_cache_get_load_addr();\n  addr_t insn_addr = shared_cache_load_addr + (addr_t)text_section->offset;\n  addr_t insn_addr_end = insn_addr + text_section->size;\n\n  addr_t write_svc_addr = (addr_t)DobbySymbolResolver(\"libsystem_kernel.dylib\", \"write\");\n  write_svc_addr += 4;\n\n  addr_t __psynch_mutexwait_svc_addr = (addr_t)DobbySymbolResolver(\"libsystem_kernel.dylib\", \"__psynch_mutexwait\");\n  __psynch_mutexwait_svc_addr += 4;\n\n  for (; insn_addr < insn_addr_end; insn_addr += sizeof(uint32_t)) {\n    if (*(uint32_t *)insn_addr == 0xd4001001) {\n      if (insn_addr == write_svc_addr)\n        continue;\n\n      if (insn_addr == __psynch_mutexwait_svc_addr)\n        continue;\n      supervisor_call_monitor_register_svc((addr_t)insn_addr);\n    }\n  }\n}\n\nvoid supervisor_call_monitor_init() {\n  // create logger file\n  char logger_path[1024] = {0};\n  sprintf(logger_path, \"%s%s\", getenv(\"HOME\"), \"/Documents/svc_monitor.txt\");\n  LOG(2, \"HOME: %s\", logger_path);\n  async_logger_init(logger_path);\n\n  dobby_enable_near_branch_trampoline();\n}",
    "repo": "CodingGay/BlackDex",
    "path": "./datasets/diagrams-repos/CodingGay/BlackDex/Bcore/src/main/cpp/Dobby/builtin-plugin/SupervisorCallMonitor/supervisor_call_monitor.cc",
    "query": "How are supervisor call handlers registered and invoked in the monitoring system?",
    "diagram": "{'nodes': [{'type': 'variable', 'name': 'g_supervisor_call_handlers', 'node_id': 'g_supervisor_call_handlers', 'description': 'Global vector storing supervisor call handlers', 'visibility': 'public', 'return_type': 'std::vector<DBICallTy>*', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'supervisor_call_monitor_register_handler', 'node_id': 'supervisor_call_monitor_register_handler', 'description': 'Registers a new handler for supervisor calls', 'visibility': 'public', 'return_type': 'void', 'params': 'DBICallTy handler', 'source_class_id': None}, {'type': 'function', 'name': 'common_supervisor_call_monitor_handler', 'node_id': 'common_supervisor_call_monitor_handler', 'description': 'Common handler that invokes all registered handlers', 'visibility': 'private', 'return_type': 'void', 'params': 'RegisterContext *ctx, const HookEntryInfo *info', 'source_class_id': None}], 'edges': [{'node_id_from': 'supervisor_call_monitor_register_handler', 'node_id_to': 'g_supervisor_call_handlers', 'description': 'adds handler'}, {'node_id_from': 'common_supervisor_call_monitor_handler', 'node_id_to': 'g_supervisor_call_handlers', 'description': 'iterates and executes'}], 'packages': [{'package_id': 'supervisorCallHandling', 'children': ['g_supervisor_call_handlers', 'supervisor_call_monitor_register_handler', 'common_supervisor_call_monitor_handler'], 'description': 'Core handler registration and execution logic'}]}",
    "version": "minimal",
    "text_answer": "Supervisor call handlers are registered using supervisor_call_monitor_register_handler which stores them in g_supervisor_call_handlers vector. When a supervisor call occurs, common_supervisor_call_monitor_handler is invoked, which then executes all registered handlers sequentially.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include \"SupervisorCallMonitor/misc_utility.h\"\n#include \"dobby_internal.h\"\n#include \"PlatformUtil/ProcessRuntimeUtility.h\"\n\n#include \"misc-helper/async_logger.h\"\n\n#include <vector>\nstd::vector<DBICallTy> *g_supervisor_call_handlers;\n\nstatic const char *fast_get_main_app_bundle_udid() {\n  static char *main_app_bundle_udid = NULL;\n  if (main_app_bundle_udid)\n    return main_app_bundle_udid;\n\n  auto main = ProcessRuntimeUtility::GetProcessModuleMap()[0];\n  char main_binary_path[2048] = {0};\n  if (realpath(main.path, main_binary_path) == NULL)\n    return NULL;\n\n  char *bundle_udid_ndx = main_binary_path + strlen(\"/private/var/containers/Bundle/Application/\");\n  main_app_bundle_udid = (char *)malloc(36 + 1);\n  strncpy(main_app_bundle_udid, bundle_udid_ndx, 36);\n  main_app_bundle_udid[36] = 0;\n  return main_app_bundle_udid;\n}\n\nstatic void common_supervisor_call_monitor_handler(RegisterContext *ctx, const HookEntryInfo *info) {\n  if (g_supervisor_call_handlers == NULL) {\n    return;\n  }\n  for (auto handler : *g_supervisor_call_handlers) {\n    handler(ctx, info);\n  }\n}\n\nvoid supervisor_call_monitor_register_handler(DBICallTy handler) {\n  if (g_supervisor_call_handlers == NULL) {\n    g_supervisor_call_handlers = new std::vector<DBICallTy>();\n  }\n  g_supervisor_call_handlers->push_back(handler);\n}\n\nstd::vector<addr_t> *g_svc_addr_array;\n\nvoid supervisor_call_monitor_register_svc(addr_t svc_addr) {\n  if (g_svc_addr_array == NULL) {\n    g_svc_addr_array = new std::vector<addr_t>();\n  }\n\n  if (g_svc_addr_array) {\n    auto iter = g_svc_addr_array->begin();\n    for (; iter != g_svc_addr_array->end(); iter++) {\n      if (*iter == svc_addr)\n        return;\n    }\n  }\n\n  g_svc_addr_array->push_back(svc_addr);\n  DobbyInstrument((void *)svc_addr, common_supervisor_call_monitor_handler);\n  DLOG(2, \"register supervisor_call_monitor at %p\", svc_addr);\n}\n\nvoid supervisor_call_monitor_register_image(void *header) {\n  auto text_section = macho_kit_get_section_by_name((mach_header_t *)header, \"__TEXT\", \"__text\");\n\n  addr_t insn_addr = (addr_t)header + (addr_t)text_section->offset;\n  addr_t insn_addr_end = insn_addr + text_section->size;\n\n  for (; insn_addr < insn_addr_end; insn_addr += sizeof(uint32_t)) {\n    if (*(uint32_t *)insn_addr == 0xd4001001) {\n      supervisor_call_monitor_register_svc((addr_t)insn_addr);\n    }\n  }\n}\n\nvoid supervisor_call_monitor_register_main_app() {\n  const char *main_bundle_udid = fast_get_main_app_bundle_udid();\n  auto module_map = ProcessRuntimeUtility::GetProcessModuleMap();\n  for (auto module : module_map) {\n    if (strstr(module.path, main_bundle_udid)) {\n      LOG(2, \"[supervisor_call_monitor] %s\", module.path);\n      supervisor_call_monitor_register_image((void *)module.load_address);\n    }\n  }\n}\n\nextern \"C\" int __shared_region_check_np(uint64_t *startaddress);\n\nstruct dyld_cache_header *shared_cache_get_load_addr() {\n  static struct dyld_cache_header *shared_cache_load_addr = 0;\n  if (shared_cache_load_addr)\n    return shared_cache_load_addr;\n#if 0\n  if (syscall(294, &shared_cache_load_addr) == 0) {\n#else\n  // FIXME:\n  if (__shared_region_check_np((uint64_t *)&shared_cache_load_addr) != 0) {\n#endif\n  shared_cache_load_addr = 0;\n}\nreturn shared_cache_load_addr;\n}\nvoid supervisor_call_monitor_register_system_kernel() {\n  auto libsystem = ProcessRuntimeUtility::GetProcessModule(\"libsystem_kernel.dylib\");\n  addr_t libsystem_header = (addr_t)libsystem.load_address;\n  auto text_section = macho_kit_get_section_by_name((mach_header_t *)libsystem_header, \"__TEXT\", \"__text\");\n\n  addr_t shared_cache_load_addr = (addr_t)shared_cache_get_load_addr();\n  addr_t insn_addr = shared_cache_load_addr + (addr_t)text_section->offset;\n  addr_t insn_addr_end = insn_addr + text_section->size;\n\n  addr_t write_svc_addr = (addr_t)DobbySymbolResolver(\"libsystem_kernel.dylib\", \"write\");\n  write_svc_addr += 4;\n\n  addr_t __psynch_mutexwait_svc_addr = (addr_t)DobbySymbolResolver(\"libsystem_kernel.dylib\", \"__psynch_mutexwait\");\n  __psynch_mutexwait_svc_addr += 4;\n\n  for (; insn_addr < insn_addr_end; insn_addr += sizeof(uint32_t)) {\n    if (*(uint32_t *)insn_addr == 0xd4001001) {\n      if (insn_addr == write_svc_addr)\n        continue;\n\n      if (insn_addr == __psynch_mutexwait_svc_addr)\n        continue;\n      supervisor_call_monitor_register_svc((addr_t)insn_addr);\n    }\n  }\n}\n\nvoid supervisor_call_monitor_init() {\n  // create logger file\n  char logger_path[1024] = {0};\n  sprintf(logger_path, \"%s%s\", getenv(\"HOME\"), \"/Documents/svc_monitor.txt\");\n  LOG(2, \"HOME: %s\", logger_path);\n  async_logger_init(logger_path);\n\n  dobby_enable_near_branch_trampoline();\n}",
    "repo": "CodingGay/BlackDex",
    "path": "./datasets/diagrams-repos/CodingGay/BlackDex/Bcore/src/main/cpp/Dobby/builtin-plugin/SupervisorCallMonitor/supervisor_call_monitor.cc",
    "query": "How are supervisor call handlers registered and invoked in the monitoring system?",
    "diagram": "{'nodes': [{'type': 'variable', 'name': 'g_supervisor_call_handlers', 'node_id': 'g_supervisor_call_handlers', 'description': 'Global vector storing supervisor call handlers', 'visibility': 'public', 'return_type': 'std::vector<DBICallTy>*', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'g_svc_addr_array', 'node_id': 'g_svc_addr_array', 'description': 'Global vector storing supervisor call addresses', 'visibility': 'public', 'return_type': 'std::vector<addr_t>*', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'supervisor_call_monitor_register_handler', 'node_id': 'supervisor_call_monitor_register_handler', 'description': 'Registers a new handler for supervisor calls', 'visibility': 'public', 'return_type': 'void', 'params': 'DBICallTy handler', 'source_class_id': None}, {'type': 'function', 'name': 'supervisor_call_monitor_register_svc', 'node_id': 'supervisor_call_monitor_register_svc', 'description': 'Registers a supervisor call address for monitoring', 'visibility': 'public', 'return_type': 'void', 'params': 'addr_t svc_addr', 'source_class_id': None}, {'type': 'function', 'name': 'common_supervisor_call_monitor_handler', 'node_id': 'common_supervisor_call_monitor_handler', 'description': 'Common handler that invokes all registered handlers', 'visibility': 'private', 'return_type': 'void', 'params': 'RegisterContext *ctx, const HookEntryInfo *info', 'source_class_id': None}, {'type': 'function', 'name': 'DobbyInstrument', 'node_id': 'DobbyInstrument', 'description': 'External function for instrumenting code', 'visibility': 'public', 'return_type': 'void', 'params': 'void *address, void *handler', 'source_class_id': None}], 'edges': [{'node_id_from': 'supervisor_call_monitor_register_handler', 'node_id_to': 'g_supervisor_call_handlers', 'description': 'adds handler'}, {'node_id_from': 'supervisor_call_monitor_register_svc', 'node_id_to': 'g_svc_addr_array', 'description': 'stores address'}, {'node_id_from': 'supervisor_call_monitor_register_svc', 'node_id_to': 'DobbyInstrument', 'description': 'instruments address'}, {'node_id_from': 'DobbyInstrument', 'node_id_to': 'common_supervisor_call_monitor_handler', 'description': 'sets as handler'}, {'node_id_from': 'common_supervisor_call_monitor_handler', 'node_id_to': 'g_supervisor_call_handlers', 'description': 'iterates and executes'}], 'packages': [{'package_id': 'supervisorCallHandling', 'children': ['g_supervisor_call_handlers', 'supervisor_call_monitor_register_handler', 'common_supervisor_call_monitor_handler'], 'description': 'Core handler registration and execution logic'}, {'package_id': 'supervisorCallMonitoring', 'children': ['g_svc_addr_array', 'supervisor_call_monitor_register_svc', 'DobbyInstrument'], 'description': 'Supervisor call address registration and instrumentation'}]}",
    "version": "medium",
    "text_answer": "Supervisor call handlers are registered using supervisor_call_monitor_register_handler which stores them in g_supervisor_call_handlers vector. When a supervisor call occurs, common_supervisor_call_monitor_handler is invoked, which then executes all registered handlers sequentially.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include \"SupervisorCallMonitor/misc_utility.h\"\n#include \"dobby_internal.h\"\n#include \"PlatformUtil/ProcessRuntimeUtility.h\"\n\n#include \"misc-helper/async_logger.h\"\n\n#include <vector>\nstd::vector<DBICallTy> *g_supervisor_call_handlers;\n\nstatic const char *fast_get_main_app_bundle_udid() {\n  static char *main_app_bundle_udid = NULL;\n  if (main_app_bundle_udid)\n    return main_app_bundle_udid;\n\n  auto main = ProcessRuntimeUtility::GetProcessModuleMap()[0];\n  char main_binary_path[2048] = {0};\n  if (realpath(main.path, main_binary_path) == NULL)\n    return NULL;\n\n  char *bundle_udid_ndx = main_binary_path + strlen(\"/private/var/containers/Bundle/Application/\");\n  main_app_bundle_udid = (char *)malloc(36 + 1);\n  strncpy(main_app_bundle_udid, bundle_udid_ndx, 36);\n  main_app_bundle_udid[36] = 0;\n  return main_app_bundle_udid;\n}\n\nstatic void common_supervisor_call_monitor_handler(RegisterContext *ctx, const HookEntryInfo *info) {\n  if (g_supervisor_call_handlers == NULL) {\n    return;\n  }\n  for (auto handler : *g_supervisor_call_handlers) {\n    handler(ctx, info);\n  }\n}\n\nvoid supervisor_call_monitor_register_handler(DBICallTy handler) {\n  if (g_supervisor_call_handlers == NULL) {\n    g_supervisor_call_handlers = new std::vector<DBICallTy>();\n  }\n  g_supervisor_call_handlers->push_back(handler);\n}\n\nstd::vector<addr_t> *g_svc_addr_array;\n\nvoid supervisor_call_monitor_register_svc(addr_t svc_addr) {\n  if (g_svc_addr_array == NULL) {\n    g_svc_addr_array = new std::vector<addr_t>();\n  }\n\n  if (g_svc_addr_array) {\n    auto iter = g_svc_addr_array->begin();\n    for (; iter != g_svc_addr_array->end(); iter++) {\n      if (*iter == svc_addr)\n        return;\n    }\n  }\n\n  g_svc_addr_array->push_back(svc_addr);\n  DobbyInstrument((void *)svc_addr, common_supervisor_call_monitor_handler);\n  DLOG(2, \"register supervisor_call_monitor at %p\", svc_addr);\n}\n\nvoid supervisor_call_monitor_register_image(void *header) {\n  auto text_section = macho_kit_get_section_by_name((mach_header_t *)header, \"__TEXT\", \"__text\");\n\n  addr_t insn_addr = (addr_t)header + (addr_t)text_section->offset;\n  addr_t insn_addr_end = insn_addr + text_section->size;\n\n  for (; insn_addr < insn_addr_end; insn_addr += sizeof(uint32_t)) {\n    if (*(uint32_t *)insn_addr == 0xd4001001) {\n      supervisor_call_monitor_register_svc((addr_t)insn_addr);\n    }\n  }\n}\n\nvoid supervisor_call_monitor_register_main_app() {\n  const char *main_bundle_udid = fast_get_main_app_bundle_udid();\n  auto module_map = ProcessRuntimeUtility::GetProcessModuleMap();\n  for (auto module : module_map) {\n    if (strstr(module.path, main_bundle_udid)) {\n      LOG(2, \"[supervisor_call_monitor] %s\", module.path);\n      supervisor_call_monitor_register_image((void *)module.load_address);\n    }\n  }\n}\n\nextern \"C\" int __shared_region_check_np(uint64_t *startaddress);\n\nstruct dyld_cache_header *shared_cache_get_load_addr() {\n  static struct dyld_cache_header *shared_cache_load_addr = 0;\n  if (shared_cache_load_addr)\n    return shared_cache_load_addr;\n#if 0\n  if (syscall(294, &shared_cache_load_addr) == 0) {\n#else\n  // FIXME:\n  if (__shared_region_check_np((uint64_t *)&shared_cache_load_addr) != 0) {\n#endif\n  shared_cache_load_addr = 0;\n}\nreturn shared_cache_load_addr;\n}\nvoid supervisor_call_monitor_register_system_kernel() {\n  auto libsystem = ProcessRuntimeUtility::GetProcessModule(\"libsystem_kernel.dylib\");\n  addr_t libsystem_header = (addr_t)libsystem.load_address;\n  auto text_section = macho_kit_get_section_by_name((mach_header_t *)libsystem_header, \"__TEXT\", \"__text\");\n\n  addr_t shared_cache_load_addr = (addr_t)shared_cache_get_load_addr();\n  addr_t insn_addr = shared_cache_load_addr + (addr_t)text_section->offset;\n  addr_t insn_addr_end = insn_addr + text_section->size;\n\n  addr_t write_svc_addr = (addr_t)DobbySymbolResolver(\"libsystem_kernel.dylib\", \"write\");\n  write_svc_addr += 4;\n\n  addr_t __psynch_mutexwait_svc_addr = (addr_t)DobbySymbolResolver(\"libsystem_kernel.dylib\", \"__psynch_mutexwait\");\n  __psynch_mutexwait_svc_addr += 4;\n\n  for (; insn_addr < insn_addr_end; insn_addr += sizeof(uint32_t)) {\n    if (*(uint32_t *)insn_addr == 0xd4001001) {\n      if (insn_addr == write_svc_addr)\n        continue;\n\n      if (insn_addr == __psynch_mutexwait_svc_addr)\n        continue;\n      supervisor_call_monitor_register_svc((addr_t)insn_addr);\n    }\n  }\n}\n\nvoid supervisor_call_monitor_init() {\n  // create logger file\n  char logger_path[1024] = {0};\n  sprintf(logger_path, \"%s%s\", getenv(\"HOME\"), \"/Documents/svc_monitor.txt\");\n  LOG(2, \"HOME: %s\", logger_path);\n  async_logger_init(logger_path);\n\n  dobby_enable_near_branch_trampoline();\n}",
    "repo": "CodingGay/BlackDex",
    "path": "./datasets/diagrams-repos/CodingGay/BlackDex/Bcore/src/main/cpp/Dobby/builtin-plugin/SupervisorCallMonitor/supervisor_call_monitor.cc",
    "query": "How are supervisor call handlers registered and invoked in the monitoring system?",
    "diagram": "{'nodes': [{'type': 'variable', 'name': 'g_supervisor_call_handlers', 'node_id': 'g_supervisor_call_handlers', 'description': 'Global vector storing supervisor call handlers', 'visibility': 'public', 'return_type': 'std::vector<DBICallTy>*', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'g_svc_addr_array', 'node_id': 'g_svc_addr_array', 'description': 'Global vector storing supervisor call addresses', 'visibility': 'public', 'return_type': 'std::vector<addr_t>*', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'supervisor_call_monitor_init', 'node_id': 'supervisor_call_monitor_init', 'description': 'Initializes the supervisor call monitoring system', 'visibility': 'public', 'return_type': 'void', 'params': '', 'source_class_id': None}, {'type': 'function', 'name': 'supervisor_call_monitor_register_handler', 'node_id': 'supervisor_call_monitor_register_handler', 'description': 'Registers a new handler for supervisor calls', 'visibility': 'public', 'return_type': 'void', 'params': 'DBICallTy handler', 'source_class_id': None}, {'type': 'function', 'name': 'supervisor_call_monitor_register_svc', 'node_id': 'supervisor_call_monitor_register_svc', 'description': 'Registers a supervisor call address for monitoring', 'visibility': 'public', 'return_type': 'void', 'params': 'addr_t svc_addr', 'source_class_id': None}, {'type': 'function', 'name': 'supervisor_call_monitor_register_image', 'node_id': 'supervisor_call_monitor_register_image', 'description': 'Registers supervisor calls from a binary image', 'visibility': 'public', 'return_type': 'void', 'params': 'void *header', 'source_class_id': None}, {'type': 'function', 'name': 'supervisor_call_monitor_register_main_app', 'node_id': 'supervisor_call_monitor_register_main_app', 'description': 'Registers supervisor calls from the main application', 'visibility': 'public', 'return_type': 'void', 'params': '', 'source_class_id': None}, {'type': 'function', 'name': 'supervisor_call_monitor_register_system_kernel', 'node_id': 'supervisor_call_monitor_register_system_kernel', 'description': 'Registers supervisor calls from the system kernel', 'visibility': 'public', 'return_type': 'void', 'params': '', 'source_class_id': None}, {'type': 'function', 'name': 'common_supervisor_call_monitor_handler', 'node_id': 'common_supervisor_call_monitor_handler', 'description': 'Common handler that invokes all registered handlers', 'visibility': 'private', 'return_type': 'void', 'params': 'RegisterContext *ctx, const HookEntryInfo *info', 'source_class_id': None}, {'type': 'function', 'name': 'DobbyInstrument', 'node_id': 'DobbyInstrument', 'description': 'External function for instrumenting code', 'visibility': 'public', 'return_type': 'void', 'params': 'void *address, void *handler', 'source_class_id': None}, {'type': 'function', 'name': 'fast_get_main_app_bundle_udid', 'node_id': 'fast_get_main_app_bundle_udid', 'description': 'Helper function to get main app bundle ID', 'visibility': 'private', 'return_type': 'const char*', 'params': '', 'source_class_id': None}, {'type': 'entity', 'name': 'MonitoringSystem', 'node_id': 'MonitoringSystem', 'description': 'The active supervisor call monitoring system that intercepts and processes system calls', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'supervisor_call_monitor_register_handler', 'node_id_to': 'g_supervisor_call_handlers', 'description': 'adds handler'}, {'node_id_from': 'supervisor_call_monitor_register_svc', 'node_id_to': 'g_svc_addr_array', 'description': 'stores address'}, {'node_id_from': 'supervisor_call_monitor_register_svc', 'node_id_to': 'DobbyInstrument', 'description': 'instruments address'}, {'node_id_from': 'supervisor_call_monitor_register_image', 'node_id_to': 'supervisor_call_monitor_register_svc', 'description': 'calls for each SVC'}, {'node_id_from': 'supervisor_call_monitor_register_main_app', 'node_id_to': 'fast_get_main_app_bundle_udid', 'description': 'gets ID'}, {'node_id_from': 'supervisor_call_monitor_register_main_app', 'node_id_to': 'supervisor_call_monitor_register_image', 'description': 'registers app image'}, {'node_id_from': 'supervisor_call_monitor_register_system_kernel', 'node_id_to': 'supervisor_call_monitor_register_svc', 'description': 'registers kernel SVCs'}, {'node_id_from': 'DobbyInstrument', 'node_id_to': 'common_supervisor_call_monitor_handler', 'description': 'sets as handler'}, {'node_id_from': 'common_supervisor_call_monitor_handler', 'node_id_to': 'g_supervisor_call_handlers', 'description': 'iterates and executes'}, {'node_id_from': 'supervisor_call_monitor_init', 'node_id_to': 'MonitoringSystem', 'description': 'initializes and enables'}, {'node_id_from': 'MonitoringSystem', 'node_id_to': 'supervisor_call_monitor_register_handler', 'description': 'provides registration interface'}, {'node_id_from': 'MonitoringSystem', 'node_id_to': 'common_supervisor_call_monitor_handler', 'description': 'uses for interception'}], 'packages': [{'package_id': 'supervisorCallSystem', 'children': ['supervisorCallHandling', 'supervisorCallMonitoring', 'supervisorCallRegistration'], 'description': 'Complete supervisor call monitoring system'}, {'package_id': 'supervisorCallHandling', 'children': ['g_supervisor_call_handlers', 'supervisor_call_monitor_register_handler', 'common_supervisor_call_monitor_handler'], 'description': 'Core handler registration and execution logic'}, {'package_id': 'supervisorCallMonitoring', 'children': ['g_svc_addr_array', 'supervisor_call_monitor_register_svc', 'DobbyInstrument', 'MonitoringSystem'], 'description': 'Supervisor call address registration and instrumentation'}, {'package_id': 'supervisorCallRegistration', 'children': ['supervisor_call_monitor_init', 'supervisor_call_monitor_register_image', 'supervisor_call_monitor_register_main_app', 'supervisor_call_monitor_register_system_kernel', 'fast_get_main_app_bundle_udid'], 'description': 'Registration of supervisor calls from different sources'}]}",
    "version": "full",
    "text_answer": "Supervisor call handlers are registered using supervisor_call_monitor_register_handler which stores them in g_supervisor_call_handlers vector. When a supervisor call occurs, common_supervisor_call_monitor_handler is invoked, which then executes all registered handlers sequentially.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Kotlin",
    "code": "\npackage org.http4k.security.oauth.server.request\n\nimport dev.forkhandles.result4k.Failure\nimport dev.forkhandles.result4k.Result\nimport dev.forkhandles.result4k.Success\nimport dev.forkhandles.result4k.map\nimport org.http4k.core.Uri\nimport org.http4k.security.ResponseMode\nimport org.http4k.security.ResponseType\nimport org.http4k.security.State\nimport org.http4k.security.oauth.format.OAuthMoshi\nimport org.http4k.security.oauth.format.boolean\nimport org.http4k.security.oauth.format.long\nimport org.http4k.security.oauth.format.map\nimport org.http4k.security.oauth.format.string\nimport org.http4k.security.oauth.format.strings\nimport org.http4k.security.oauth.format.value\nimport org.http4k.security.oauth.server.ClientId\nimport org.http4k.security.oauth.server.InvalidRequestObject\nimport java.util.Base64\n\nobject RequestObjectExtractor {\n\n    fun extractRequestJwtClaimsAsMap(value: String): Result<Map<*, *>, InvalidRequestObject> =\n        parseJsonFromJWT(value)\n\n    fun extractRequestObjectFromJwt(value: String): Result<RequestObject, InvalidRequestObject> =\n        parseJsonFromJWT(value)\n            .map { jsonFromJWT ->\n                with(jsonFromJWT) {\n                    RequestObject(\n                        client = value(\"client_id\", ::ClientId),\n                        redirectUri = value(\"redirect_uri\", Uri::of),\n                        audience = toAudience(this[\"aud\"]),\n                        issuer = string(\"iss\"),\n                        scope = string(\"scope\")?.split(\" \") ?: emptyList(),\n                        responseMode = value(\"response_mode\", ResponseMode::fromQueryParameterValue),\n                        responseType = value(\"response_type\", ResponseType::fromQueryParameterValue),\n                        state = value(\"state\", ::State),\n                        nonce = value(\"nonce\") { org.http4k.security.Nonce(it) },\n                        magAge = long(\"max_age\"),\n                        expiry = long(\"exp\"),\n                        claims = toClaims(this[\"claims\"])\n                    )\n                }\n            }\n\n    private fun toClaims(claims: Any?) = when (claims) {\n        is Map<*, *> -> Claims(\n            asClaims(claims.map(\"userinfo\")),\n            asClaims(claims.map(\"id_token\"))\n        )\n        else -> Claims()\n    }\n\n    @Suppress(\"UNCHECKED_CAST\")\n    private fun asClaims(claims: Map<String, Any>?) = claims\n        ?.mapValues {\n            val claim = it.value as Map<String, Any>\n            Claim(\n                claim.boolean(\"essential\") ?: false,\n                claim.string(\"value\"),\n                claim.strings(\"values\")\n            )\n        }\n\n    private fun toAudience(audience: Any?): List<String> = when (audience) {\n        is List<*> -> audience.map { it.toString() }\n        is String -> listOf(audience)\n        else -> emptyList()\n    }\n\n    private val moshi = OAuthMoshi\n\n    private fun parseJsonFromJWT(value: String) = try {\n        val jwtParts = value.split(\".\")\n        when {\n            jwtParts.size != 3 -> Failure(InvalidRequestObject)\n            else -> Success(moshi.asA<Map<String, Any>>(String(Base64.getUrlDecoder().decode(jwtParts[1]))))\n        }\n    } catch (e: Exception) {\n        Failure(InvalidRequestObject)\n    }\n}",
    "repo": "http4k/http4k",
    "path": "./datasets/diagrams-repos/http4k/http4k/core/security/oauth/src/main/kotlin/org/http4k/security/oauth/server/request/RequestObjectExtractor.kt",
    "query": "Visualize the interaction between RequestObjectExtractor and the OAuthMoshi parser when extracting JWT claims.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'RequestObjectExtractor', 'node_id': 'RequestObjectExtractor', 'description': 'Extracts and parses JWT claims and request objects', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'extractRequestJwtClaimsAsMap', 'node_id': 'extractRequestJwtClaimsAsMap', 'description': 'Extracts JWT claims as a map', 'visibility': 'public', 'return_type': 'Result<Map<*, *>, InvalidRequestObject>', 'params': 'value: String', 'source_class_id': 'RequestObjectExtractor'}, {'type': 'method', 'name': 'parseJsonFromJWT', 'node_id': 'parseJsonFromJWT', 'description': 'Parses JWT string into JSON map', 'visibility': 'private', 'return_type': 'Result<Map<String, Any>, InvalidRequestObject>', 'params': 'value: String', 'source_class_id': 'RequestObjectExtractor'}, {'type': 'variable', 'name': 'moshi', 'node_id': 'moshi', 'description': 'OAuth JSON parser instance', 'visibility': 'private', 'return_type': 'OAuthMoshi', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'extractRequestJwtClaimsAsMap', 'node_id_to': 'parseJsonFromJWT', 'description': 'calls'}, {'node_id_from': 'parseJsonFromJWT', 'node_id_to': 'moshi', 'description': 'uses'}, {'node_id_from': 'RequestObjectExtractor', 'node_id_to': 'extractRequestJwtClaimsAsMap', 'description': ''}, {'node_id_from': 'RequestObjectExtractor', 'node_id_to': 'parseJsonFromJWT', 'description': ''}], 'packages': [{'package_id': 'jwtParsing', 'children': ['RequestObjectExtractor', 'extractRequestJwtClaimsAsMap', 'parseJsonFromJWT', 'moshi'], 'description': 'JWT parsing functionality'}]}",
    "version": "minimal",
    "text_answer": "The RequestObjectExtractor splits the JWT string into parts, decodes the payload using Base64, and then uses OAuthMoshi to parse the JSON into a map structure. This process is encapsulated in the parseJsonFromJWT method, which is called by both public extraction methods.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Kotlin",
    "code": "\npackage org.http4k.security.oauth.server.request\n\nimport dev.forkhandles.result4k.Failure\nimport dev.forkhandles.result4k.Result\nimport dev.forkhandles.result4k.Success\nimport dev.forkhandles.result4k.map\nimport org.http4k.core.Uri\nimport org.http4k.security.ResponseMode\nimport org.http4k.security.ResponseType\nimport org.http4k.security.State\nimport org.http4k.security.oauth.format.OAuthMoshi\nimport org.http4k.security.oauth.format.boolean\nimport org.http4k.security.oauth.format.long\nimport org.http4k.security.oauth.format.map\nimport org.http4k.security.oauth.format.string\nimport org.http4k.security.oauth.format.strings\nimport org.http4k.security.oauth.format.value\nimport org.http4k.security.oauth.server.ClientId\nimport org.http4k.security.oauth.server.InvalidRequestObject\nimport java.util.Base64\n\nobject RequestObjectExtractor {\n\n    fun extractRequestJwtClaimsAsMap(value: String): Result<Map<*, *>, InvalidRequestObject> =\n        parseJsonFromJWT(value)\n\n    fun extractRequestObjectFromJwt(value: String): Result<RequestObject, InvalidRequestObject> =\n        parseJsonFromJWT(value)\n            .map { jsonFromJWT ->\n                with(jsonFromJWT) {\n                    RequestObject(\n                        client = value(\"client_id\", ::ClientId),\n                        redirectUri = value(\"redirect_uri\", Uri::of),\n                        audience = toAudience(this[\"aud\"]),\n                        issuer = string(\"iss\"),\n                        scope = string(\"scope\")?.split(\" \") ?: emptyList(),\n                        responseMode = value(\"response_mode\", ResponseMode::fromQueryParameterValue),\n                        responseType = value(\"response_type\", ResponseType::fromQueryParameterValue),\n                        state = value(\"state\", ::State),\n                        nonce = value(\"nonce\") { org.http4k.security.Nonce(it) },\n                        magAge = long(\"max_age\"),\n                        expiry = long(\"exp\"),\n                        claims = toClaims(this[\"claims\"])\n                    )\n                }\n            }\n\n    private fun toClaims(claims: Any?) = when (claims) {\n        is Map<*, *> -> Claims(\n            asClaims(claims.map(\"userinfo\")),\n            asClaims(claims.map(\"id_token\"))\n        )\n        else -> Claims()\n    }\n\n    @Suppress(\"UNCHECKED_CAST\")\n    private fun asClaims(claims: Map<String, Any>?) = claims\n        ?.mapValues {\n            val claim = it.value as Map<String, Any>\n            Claim(\n                claim.boolean(\"essential\") ?: false,\n                claim.string(\"value\"),\n                claim.strings(\"values\")\n            )\n        }\n\n    private fun toAudience(audience: Any?): List<String> = when (audience) {\n        is List<*> -> audience.map { it.toString() }\n        is String -> listOf(audience)\n        else -> emptyList()\n    }\n\n    private val moshi = OAuthMoshi\n\n    private fun parseJsonFromJWT(value: String) = try {\n        val jwtParts = value.split(\".\")\n        when {\n            jwtParts.size != 3 -> Failure(InvalidRequestObject)\n            else -> Success(moshi.asA<Map<String, Any>>(String(Base64.getUrlDecoder().decode(jwtParts[1]))))\n        }\n    } catch (e: Exception) {\n        Failure(InvalidRequestObject)\n    }\n}",
    "repo": "http4k/http4k",
    "path": "./datasets/diagrams-repos/http4k/http4k/core/security/oauth/src/main/kotlin/org/http4k/security/oauth/server/request/RequestObjectExtractor.kt",
    "query": "Visualize the interaction between RequestObjectExtractor and the OAuthMoshi parser when extracting JWT claims.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'RequestObjectExtractor', 'node_id': 'RequestObjectExtractor', 'description': 'Extracts and parses JWT claims and request objects', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'extractRequestJwtClaimsAsMap', 'node_id': 'extractRequestJwtClaimsAsMap', 'description': 'Extracts JWT claims as a map', 'visibility': 'public', 'return_type': 'Result<Map<*, *>, InvalidRequestObject>', 'params': 'value: String', 'source_class_id': 'RequestObjectExtractor'}, {'type': 'method', 'name': 'extractRequestObjectFromJwt', 'node_id': 'extractRequestObjectFromJwt', 'description': 'Extracts full request object from JWT', 'visibility': 'public', 'return_type': 'Result<RequestObject, InvalidRequestObject>', 'params': 'value: String', 'source_class_id': 'RequestObjectExtractor'}, {'type': 'method', 'name': 'parseJsonFromJWT', 'node_id': 'parseJsonFromJWT', 'description': 'Parses JWT string into JSON map', 'visibility': 'private', 'return_type': 'Result<Map<String, Any>, InvalidRequestObject>', 'params': 'value: String', 'source_class_id': 'RequestObjectExtractor'}, {'type': 'variable', 'name': 'moshi', 'node_id': 'moshi', 'description': 'OAuth JSON parser instance', 'visibility': 'private', 'return_type': 'OAuthMoshi', 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'Base64Decoder', 'node_id': 'Base64Decoder', 'description': 'Decodes Base64 URL-encoded strings', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'extractRequestJwtClaimsAsMap', 'node_id_to': 'parseJsonFromJWT', 'description': 'calls'}, {'node_id_from': 'extractRequestObjectFromJwt', 'node_id_to': 'parseJsonFromJWT', 'description': 'calls'}, {'node_id_from': 'parseJsonFromJWT', 'node_id_to': 'moshi', 'description': 'uses'}, {'node_id_from': 'parseJsonFromJWT', 'node_id_to': 'Base64Decoder', 'description': 'uses'}, {'node_id_from': 'RequestObjectExtractor', 'node_id_to': 'extractRequestJwtClaimsAsMap', 'description': ''}, {'node_id_from': 'RequestObjectExtractor', 'node_id_to': 'parseJsonFromJWT', 'description': ''}, {'node_id_from': 'RequestObjectExtractor', 'node_id_to': 'extractRequestObjectFromJwt', 'description': ''}], 'packages': [{'package_id': 'jwtParsing', 'children': ['RequestObjectExtractor', 'extractRequestJwtClaimsAsMap', 'extractRequestObjectFromJwt', 'parseJsonFromJWT', 'moshi'], 'description': 'JWT parsing functionality'}]}",
    "version": "medium",
    "text_answer": "The RequestObjectExtractor splits the JWT string into parts, decodes the payload using Base64, and then uses OAuthMoshi to parse the JSON into a map structure. This process is encapsulated in the parseJsonFromJWT method, which is called by both public extraction methods.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Kotlin",
    "code": "\npackage org.http4k.security.oauth.server.request\n\nimport dev.forkhandles.result4k.Failure\nimport dev.forkhandles.result4k.Result\nimport dev.forkhandles.result4k.Success\nimport dev.forkhandles.result4k.map\nimport org.http4k.core.Uri\nimport org.http4k.security.ResponseMode\nimport org.http4k.security.ResponseType\nimport org.http4k.security.State\nimport org.http4k.security.oauth.format.OAuthMoshi\nimport org.http4k.security.oauth.format.boolean\nimport org.http4k.security.oauth.format.long\nimport org.http4k.security.oauth.format.map\nimport org.http4k.security.oauth.format.string\nimport org.http4k.security.oauth.format.strings\nimport org.http4k.security.oauth.format.value\nimport org.http4k.security.oauth.server.ClientId\nimport org.http4k.security.oauth.server.InvalidRequestObject\nimport java.util.Base64\n\nobject RequestObjectExtractor {\n\n    fun extractRequestJwtClaimsAsMap(value: String): Result<Map<*, *>, InvalidRequestObject> =\n        parseJsonFromJWT(value)\n\n    fun extractRequestObjectFromJwt(value: String): Result<RequestObject, InvalidRequestObject> =\n        parseJsonFromJWT(value)\n            .map { jsonFromJWT ->\n                with(jsonFromJWT) {\n                    RequestObject(\n                        client = value(\"client_id\", ::ClientId),\n                        redirectUri = value(\"redirect_uri\", Uri::of),\n                        audience = toAudience(this[\"aud\"]),\n                        issuer = string(\"iss\"),\n                        scope = string(\"scope\")?.split(\" \") ?: emptyList(),\n                        responseMode = value(\"response_mode\", ResponseMode::fromQueryParameterValue),\n                        responseType = value(\"response_type\", ResponseType::fromQueryParameterValue),\n                        state = value(\"state\", ::State),\n                        nonce = value(\"nonce\") { org.http4k.security.Nonce(it) },\n                        magAge = long(\"max_age\"),\n                        expiry = long(\"exp\"),\n                        claims = toClaims(this[\"claims\"])\n                    )\n                }\n            }\n\n    private fun toClaims(claims: Any?) = when (claims) {\n        is Map<*, *> -> Claims(\n            asClaims(claims.map(\"userinfo\")),\n            asClaims(claims.map(\"id_token\"))\n        )\n        else -> Claims()\n    }\n\n    @Suppress(\"UNCHECKED_CAST\")\n    private fun asClaims(claims: Map<String, Any>?) = claims\n        ?.mapValues {\n            val claim = it.value as Map<String, Any>\n            Claim(\n                claim.boolean(\"essential\") ?: false,\n                claim.string(\"value\"),\n                claim.strings(\"values\")\n            )\n        }\n\n    private fun toAudience(audience: Any?): List<String> = when (audience) {\n        is List<*> -> audience.map { it.toString() }\n        is String -> listOf(audience)\n        else -> emptyList()\n    }\n\n    private val moshi = OAuthMoshi\n\n    private fun parseJsonFromJWT(value: String) = try {\n        val jwtParts = value.split(\".\")\n        when {\n            jwtParts.size != 3 -> Failure(InvalidRequestObject)\n            else -> Success(moshi.asA<Map<String, Any>>(String(Base64.getUrlDecoder().decode(jwtParts[1]))))\n        }\n    } catch (e: Exception) {\n        Failure(InvalidRequestObject)\n    }\n}",
    "repo": "http4k/http4k",
    "path": "./datasets/diagrams-repos/http4k/http4k/core/security/oauth/src/main/kotlin/org/http4k/security/oauth/server/request/RequestObjectExtractor.kt",
    "query": "Visualize the interaction between RequestObjectExtractor and the OAuthMoshi parser when extracting JWT claims.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'RequestObjectExtractor', 'node_id': 'RequestObjectExtractor', 'description': 'Extracts and parses JWT claims and request objects', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'extractRequestJwtClaimsAsMap', 'node_id': 'extractRequestJwtClaimsAsMap', 'description': 'Extracts JWT claims as a map', 'visibility': 'public', 'return_type': 'Result<Map<*, *>, InvalidRequestObject>', 'params': 'value: String', 'source_class_id': 'RequestObjectExtractor'}, {'type': 'method', 'name': 'extractRequestObjectFromJwt', 'node_id': 'extractRequestObjectFromJwt', 'description': 'Extracts full request object from JWT', 'visibility': 'public', 'return_type': 'Result<RequestObject, InvalidRequestObject>', 'params': 'value: String', 'source_class_id': 'RequestObjectExtractor'}, {'type': 'method', 'name': 'parseJsonFromJWT', 'node_id': 'parseJsonFromJWT', 'description': 'Parses JWT string into JSON map', 'visibility': 'private', 'return_type': 'Result<Map<String, Any>, InvalidRequestObject>', 'params': 'value: String', 'source_class_id': 'RequestObjectExtractor'}, {'type': 'method', 'name': 'toClaims', 'node_id': 'toClaims', 'description': 'Converts raw claims to Claims object', 'visibility': 'private', 'return_type': 'Claims', 'params': 'claims: Any?', 'source_class_id': 'RequestObjectExtractor'}, {'type': 'method', 'name': 'asClaims', 'node_id': 'asClaims', 'description': 'Converts map to claims', 'visibility': 'private', 'return_type': 'Map<String, Claim>?', 'params': 'claims: Map<String, Any>?', 'source_class_id': 'RequestObjectExtractor'}, {'type': 'method', 'name': 'toAudience', 'node_id': 'toAudience', 'description': 'Converts audience to list of strings', 'visibility': 'private', 'return_type': 'List<String>', 'params': 'audience: Any?', 'source_class_id': 'RequestObjectExtractor'}, {'type': 'variable', 'name': 'moshi', 'node_id': 'moshi', 'description': 'OAuth JSON parser instance', 'visibility': 'private', 'return_type': 'OAuthMoshi', 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'Base64Decoder', 'node_id': 'Base64Decoder', 'description': 'Decodes Base64 URL-encoded strings', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'extractRequestJwtClaimsAsMap', 'node_id_to': 'parseJsonFromJWT', 'description': 'calls'}, {'node_id_from': 'extractRequestObjectFromJwt', 'node_id_to': 'parseJsonFromJWT', 'description': 'calls'}, {'node_id_from': 'extractRequestObjectFromJwt', 'node_id_to': 'toClaims', 'description': 'calls'}, {'node_id_from': 'toClaims', 'node_id_to': 'asClaims', 'description': 'calls'}, {'node_id_from': 'extractRequestObjectFromJwt', 'node_id_to': 'toAudience', 'description': 'calls'}, {'node_id_from': 'parseJsonFromJWT', 'node_id_to': 'moshi', 'description': 'uses'}, {'node_id_from': 'parseJsonFromJWT', 'node_id_to': 'Base64Decoder', 'description': 'uses'}, {'node_id_from': 'RequestObjectExtractor', 'node_id_to': 'extractRequestJwtClaimsAsMap', 'description': ''}, {'node_id_from': 'RequestObjectExtractor', 'node_id_to': 'parseJsonFromJWT', 'description': ''}, {'node_id_from': 'RequestObjectExtractor', 'node_id_to': 'toClaims', 'description': ''}, {'node_id_from': 'RequestObjectExtractor', 'node_id_to': 'asClaims', 'description': ''}, {'node_id_from': 'RequestObjectExtractor', 'node_id_to': 'toAudience', 'description': ''}, {'node_id_from': 'RequestObjectExtractor', 'node_id_to': 'extractRequestObjectFromJwt', 'description': ''}], 'packages': [{'package_id': 'jwtParsing', 'children': ['RequestObjectExtractor', 'extractRequestJwtClaimsAsMap', 'extractRequestObjectFromJwt', 'parseJsonFromJWT', 'moshi', 'claimsProcessing'], 'description': 'JWT parsing functionality'}, {'package_id': 'claimsProcessing', 'children': ['toClaims', 'asClaims', 'toAudience'], 'description': 'Claims processing functionality'}]}",
    "version": "full",
    "text_answer": "The RequestObjectExtractor splits the JWT string into parts, decodes the payload using Base64, and then uses OAuthMoshi to parse the JSON into a map structure. This process is encapsulated in the parseJsonFromJWT method, which is called by both public extraction methods.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nimport { moduleFor, ApplicationTestCase, strip, runTask } from 'internal-test-helpers';\n\nimport Service, { service } from '@ember/service';\nimport { Component, Helper } from '@ember/-internals/glimmer';\nimport { expect } from '@glimmer/util';\n\n// This simuates what the template hot-reloading would do in development mode\n// to avoid regressions\n\nmoduleFor(\n  'Appliation test: template hot reloading',\n  class extends ApplicationTestCase {\n    constructor() {\n      super(...arguments);\n\n      let didCreateReloader = (reloader) => {\n        this.reloader = reloader;\n      };\n\n      this.add(\n        'service:reloader',\n        Service.extend({\n          init() {\n            this._super(...arguments);\n            this.revisions = {};\n            this.callbacks = [];\n\n            didCreateReloader(this);\n          },\n\n          onReload(callback) {\n            this.callbacks.push(callback);\n          },\n\n          revisionFor(name) {\n            return this.revisions[name];\n          },\n\n          invalidate(name) {\n            let revision = this.revisions[name];\n\n            if (revision === undefined) {\n              revision = 0;\n            }\n\n            this.revisions[name] = ++revision;\n\n            this.callbacks.forEach((callback) => callback());\n          },\n        })\n      );\n\n      this.add(\n        'helper:hot-reload',\n        Helper.extend({\n          reloader: service(),\n\n          init() {\n            this._super(...arguments);\n            this.reloader.onReload(() => this.recompute());\n          },\n\n          compute([name]) {\n            let revision = this.reloader.revisionFor(name);\n\n            if (revision === undefined) {\n              return name;\n            } else {\n              return `${name}--hot-reload-${revision}`;\n            }\n          },\n        })\n      );\n    }\n\n    hotReload(name, template) {\n      let reloader = expect(this.reloader);\n      let revision = (reloader.revisionFor(name) || 0) + 1;\n      let ComponentClass =\n        this.applicationInstance.resolveRegistration(`component:${name}`) || null;\n\n      this.addComponent(`${name}--hot-reload-${revision}`, {\n        ComponentClass,\n        template,\n      });\n\n      reloader.invalidate(name);\n    }\n\n    ['@test hot reloading template-only components']() {\n      this.addTemplate(\n        'application',\n        strip`\n          [{{component (hot-reload \"x-foo\") name=\"first\"}}]\n          [{{component (hot-reload \"x-foo\") name=\"second\"}}]\n          [{{component (hot-reload \"x-bar\")}}]\n        `\n      );\n\n      this.addComponent('x-foo', {\n        ComponentClass: null,\n        template: 'x-foo: {{@name}}',\n      });\n\n      this.addComponent('x-bar', {\n        ComponentClass: null,\n        template: 'x-bar',\n      });\n\n      return this.visit('/').then(() => {\n        this.assertInnerHTML(strip`\n          [x-foo: first]\n          [x-foo: second]\n          [x-bar]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-foo', '<h1>{{@name}}</h1>');\n        });\n\n        this.assertInnerHTML(strip`\n          [<h1>first</h1>]\n          [<h1>second</h1>]\n          [x-bar]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-bar', '<h2>wow</h2>');\n        });\n\n        this.assertInnerHTML(strip`\n          [<h1>first</h1>]\n          [<h1>second</h1>]\n          [<h2>wow</h2>]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-foo', '<strong>x-foo</strong> <em>{{@name}}</em>');\n        });\n\n        this.assertInnerHTML(strip`\n          [<strong>x-foo</strong> <em>first</em>]\n          [<strong>x-foo</strong> <em>second</em>]\n          [<h2>wow</h2>]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-foo', 'x-foo: {{@name}}');\n          this.hotReload('x-bar', 'x-bar');\n        });\n\n        this.assertInnerHTML(strip`\n          [x-foo: first]\n          [x-foo: second]\n          [x-bar]\n        `);\n      });\n    }\n\n    ['@test hot reloading class-based components']() {\n      this.addTemplate(\n        'application',\n        strip`\n          [{{component (hot-reload \"x-foo\") name=\"first\"}}]\n          [{{component (hot-reload \"x-foo\") name=\"second\"}}]\n          [{{component (hot-reload \"x-bar\")}}]\n        `\n      );\n\n      let id = 0;\n\n      this.addComponent('x-foo', {\n        ComponentClass: Component.extend({\n          tagName: '',\n          init() {\n            this._super(...arguments);\n            this.set('id', id++);\n          },\n        }),\n        template: 'x-foo: {{@name}} ({{this.id}})',\n      });\n\n      this.addComponent('x-bar', {\n        ComponentClass: Component.extend({\n          tagName: '',\n          init() {\n            this._super(...arguments);\n            this.set('id', id++);\n          },\n        }),\n        template: 'x-bar ({{this.id}})',\n      });\n\n      return this.visit('/').then(() => {\n        this.assertInnerHTML(strip`\n          [x-foo: first (0)]\n          [x-foo: second (1)]\n          [x-bar (2)]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-foo', '<h1>{{@name}} ({{this.id}})</h1>');\n        });\n\n        this.assertInnerHTML(strip`\n          [<h1>first (3)</h1>]\n          [<h1>second (4)</h1>]\n          [x-bar (2)]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-bar', '<h2>wow ({{this.id}})</h2>');\n        });\n\n        this.assertInnerHTML(strip`\n          [<h1>first (3)</h1>]\n          [<h1>second (4)</h1>]\n          [<h2>wow (5)</h2>]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-foo', '<strong>x-foo</strong> <em>{{@name}} ({{this.id}})</em>');\n        });\n\n        this.assertInnerHTML(strip`\n          [<strong>x-foo</strong> <em>first (6)</em>]\n          [<strong>x-foo</strong> <em>second (7)</em>]\n          [<h2>wow (5)</h2>]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-foo', 'x-foo: {{@name}} ({{this.id}})');\n          this.hotReload('x-bar', 'x-bar ({{this.id}})');\n        });\n\n        this.assertInnerHTML(strip`\n          [x-foo: first (8)]\n          [x-foo: second (9)]\n          [x-bar (10)]\n        `);\n      });\n    }\n  }\n);",
    "repo": "emberjs/ember.js",
    "path": "./datasets/diagrams-repos/emberjs/ember.js/packages/@ember/-internals/glimmer/tests/integration/application/hot-reload-test.js",
    "query": "How does the reloader service track revisions for different components?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'reloader', 'node_id': 'reloader', 'description': 'Service managing component revisions and reload callbacks', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'revisions', 'node_id': 'revisions', 'description': 'Map storing revision numbers for components', 'visibility': 'private', 'return_type': 'object', 'params': None, 'source_class_id': 'reloader'}, {'type': 'method', 'name': 'revisionFor', 'node_id': 'revisionFor', 'description': 'Gets current revision for a component', 'visibility': 'public', 'return_type': 'number', 'params': 'name', 'source_class_id': 'reloader'}, {'type': 'method', 'name': 'invalidate', 'node_id': 'invalidate', 'description': 'Increments revision for a component and triggers callbacks', 'visibility': 'public', 'return_type': 'void', 'params': 'name', 'source_class_id': 'reloader'}], 'edges': [{'node_id_from': 'reloader', 'node_id_to': 'revisions', 'description': ''}, {'node_id_from': 'reloader', 'node_id_to': 'revisionFor', 'description': ''}, {'node_id_from': 'reloader', 'node_id_to': 'invalidate', 'description': ''}, {'node_id_from': 'revisionFor', 'node_id_to': 'revisions', 'description': 'reads'}, {'node_id_from': 'invalidate', 'node_id_to': 'revisions', 'description': 'updates'}], 'packages': [{'package_id': 'reloaderCore', 'children': ['reloader', 'revisions', 'revisionFor', 'invalidate'], 'description': 'Core reloader functionality'}]}",
    "version": "minimal",
    "text_answer": "The reloader service maintains a 'revisions' map that stores version numbers for components. When a component is reloaded, the 'invalidate' method increments its revision number and triggers registered callbacks. The current revision can be retrieved using 'revisionFor' method.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nimport { moduleFor, ApplicationTestCase, strip, runTask } from 'internal-test-helpers';\n\nimport Service, { service } from '@ember/service';\nimport { Component, Helper } from '@ember/-internals/glimmer';\nimport { expect } from '@glimmer/util';\n\n// This simuates what the template hot-reloading would do in development mode\n// to avoid regressions\n\nmoduleFor(\n  'Appliation test: template hot reloading',\n  class extends ApplicationTestCase {\n    constructor() {\n      super(...arguments);\n\n      let didCreateReloader = (reloader) => {\n        this.reloader = reloader;\n      };\n\n      this.add(\n        'service:reloader',\n        Service.extend({\n          init() {\n            this._super(...arguments);\n            this.revisions = {};\n            this.callbacks = [];\n\n            didCreateReloader(this);\n          },\n\n          onReload(callback) {\n            this.callbacks.push(callback);\n          },\n\n          revisionFor(name) {\n            return this.revisions[name];\n          },\n\n          invalidate(name) {\n            let revision = this.revisions[name];\n\n            if (revision === undefined) {\n              revision = 0;\n            }\n\n            this.revisions[name] = ++revision;\n\n            this.callbacks.forEach((callback) => callback());\n          },\n        })\n      );\n\n      this.add(\n        'helper:hot-reload',\n        Helper.extend({\n          reloader: service(),\n\n          init() {\n            this._super(...arguments);\n            this.reloader.onReload(() => this.recompute());\n          },\n\n          compute([name]) {\n            let revision = this.reloader.revisionFor(name);\n\n            if (revision === undefined) {\n              return name;\n            } else {\n              return `${name}--hot-reload-${revision}`;\n            }\n          },\n        })\n      );\n    }\n\n    hotReload(name, template) {\n      let reloader = expect(this.reloader);\n      let revision = (reloader.revisionFor(name) || 0) + 1;\n      let ComponentClass =\n        this.applicationInstance.resolveRegistration(`component:${name}`) || null;\n\n      this.addComponent(`${name}--hot-reload-${revision}`, {\n        ComponentClass,\n        template,\n      });\n\n      reloader.invalidate(name);\n    }\n\n    ['@test hot reloading template-only components']() {\n      this.addTemplate(\n        'application',\n        strip`\n          [{{component (hot-reload \"x-foo\") name=\"first\"}}]\n          [{{component (hot-reload \"x-foo\") name=\"second\"}}]\n          [{{component (hot-reload \"x-bar\")}}]\n        `\n      );\n\n      this.addComponent('x-foo', {\n        ComponentClass: null,\n        template: 'x-foo: {{@name}}',\n      });\n\n      this.addComponent('x-bar', {\n        ComponentClass: null,\n        template: 'x-bar',\n      });\n\n      return this.visit('/').then(() => {\n        this.assertInnerHTML(strip`\n          [x-foo: first]\n          [x-foo: second]\n          [x-bar]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-foo', '<h1>{{@name}}</h1>');\n        });\n\n        this.assertInnerHTML(strip`\n          [<h1>first</h1>]\n          [<h1>second</h1>]\n          [x-bar]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-bar', '<h2>wow</h2>');\n        });\n\n        this.assertInnerHTML(strip`\n          [<h1>first</h1>]\n          [<h1>second</h1>]\n          [<h2>wow</h2>]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-foo', '<strong>x-foo</strong> <em>{{@name}}</em>');\n        });\n\n        this.assertInnerHTML(strip`\n          [<strong>x-foo</strong> <em>first</em>]\n          [<strong>x-foo</strong> <em>second</em>]\n          [<h2>wow</h2>]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-foo', 'x-foo: {{@name}}');\n          this.hotReload('x-bar', 'x-bar');\n        });\n\n        this.assertInnerHTML(strip`\n          [x-foo: first]\n          [x-foo: second]\n          [x-bar]\n        `);\n      });\n    }\n\n    ['@test hot reloading class-based components']() {\n      this.addTemplate(\n        'application',\n        strip`\n          [{{component (hot-reload \"x-foo\") name=\"first\"}}]\n          [{{component (hot-reload \"x-foo\") name=\"second\"}}]\n          [{{component (hot-reload \"x-bar\")}}]\n        `\n      );\n\n      let id = 0;\n\n      this.addComponent('x-foo', {\n        ComponentClass: Component.extend({\n          tagName: '',\n          init() {\n            this._super(...arguments);\n            this.set('id', id++);\n          },\n        }),\n        template: 'x-foo: {{@name}} ({{this.id}})',\n      });\n\n      this.addComponent('x-bar', {\n        ComponentClass: Component.extend({\n          tagName: '',\n          init() {\n            this._super(...arguments);\n            this.set('id', id++);\n          },\n        }),\n        template: 'x-bar ({{this.id}})',\n      });\n\n      return this.visit('/').then(() => {\n        this.assertInnerHTML(strip`\n          [x-foo: first (0)]\n          [x-foo: second (1)]\n          [x-bar (2)]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-foo', '<h1>{{@name}} ({{this.id}})</h1>');\n        });\n\n        this.assertInnerHTML(strip`\n          [<h1>first (3)</h1>]\n          [<h1>second (4)</h1>]\n          [x-bar (2)]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-bar', '<h2>wow ({{this.id}})</h2>');\n        });\n\n        this.assertInnerHTML(strip`\n          [<h1>first (3)</h1>]\n          [<h1>second (4)</h1>]\n          [<h2>wow (5)</h2>]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-foo', '<strong>x-foo</strong> <em>{{@name}} ({{this.id}})</em>');\n        });\n\n        this.assertInnerHTML(strip`\n          [<strong>x-foo</strong> <em>first (6)</em>]\n          [<strong>x-foo</strong> <em>second (7)</em>]\n          [<h2>wow (5)</h2>]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-foo', 'x-foo: {{@name}} ({{this.id}})');\n          this.hotReload('x-bar', 'x-bar ({{this.id}})');\n        });\n\n        this.assertInnerHTML(strip`\n          [x-foo: first (8)]\n          [x-foo: second (9)]\n          [x-bar (10)]\n        `);\n      });\n    }\n  }\n);",
    "repo": "emberjs/ember.js",
    "path": "./datasets/diagrams-repos/emberjs/ember.js/packages/@ember/-internals/glimmer/tests/integration/application/hot-reload-test.js",
    "query": "How does the reloader service track revisions for different components?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'reloader', 'node_id': 'reloader', 'description': 'Service managing component revisions and reload callbacks', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'revisions', 'node_id': 'revisions', 'description': 'Map storing revision numbers for components', 'visibility': 'private', 'return_type': 'object', 'params': None, 'source_class_id': 'reloader'}, {'type': 'field', 'name': 'callbacks', 'node_id': 'callbacks', 'description': 'Array of callbacks to execute on reload', 'visibility': 'private', 'return_type': 'array', 'params': None, 'source_class_id': 'reloader'}, {'type': 'method', 'name': 'init', 'node_id': 'init', 'description': 'Initializes service with empty revisions and callbacks', 'visibility': 'public', 'return_type': 'void', 'params': '', 'source_class_id': 'reloader'}, {'type': 'method', 'name': 'onReload', 'node_id': 'onReload', 'description': 'Registers callback for reload events', 'visibility': 'public', 'return_type': 'void', 'params': 'callback', 'source_class_id': 'reloader'}, {'type': 'method', 'name': 'revisionFor', 'node_id': 'revisionFor', 'description': 'Gets current revision for a component', 'visibility': 'public', 'return_type': 'number', 'params': 'name', 'source_class_id': 'reloader'}, {'type': 'method', 'name': 'invalidate', 'node_id': 'invalidate', 'description': 'Increments revision for a component and triggers callbacks', 'visibility': 'public', 'return_type': 'void', 'params': 'name', 'source_class_id': 'reloader'}], 'edges': [{'node_id_from': 'reloader', 'node_id_to': 'revisions', 'description': ''}, {'node_id_from': 'reloader', 'node_id_to': 'callbacks', 'description': ''}, {'node_id_from': 'reloader', 'node_id_to': 'init', 'description': ''}, {'node_id_from': 'reloader', 'node_id_to': 'onReload', 'description': ''}, {'node_id_from': 'reloader', 'node_id_to': 'revisionFor', 'description': ''}, {'node_id_from': 'reloader', 'node_id_to': 'invalidate', 'description': ''}, {'node_id_from': 'init', 'node_id_to': 'revisions', 'description': 'initializes'}, {'node_id_from': 'init', 'node_id_to': 'callbacks', 'description': 'initializes'}, {'node_id_from': 'onReload', 'node_id_to': 'callbacks', 'description': 'adds'}, {'node_id_from': 'revisionFor', 'node_id_to': 'revisions', 'description': 'reads'}, {'node_id_from': 'invalidate', 'node_id_to': 'revisions', 'description': 'updates'}, {'node_id_from': 'invalidate', 'node_id_to': 'callbacks', 'description': 'executes'}], 'packages': [{'package_id': 'reloaderCore', 'children': ['reloader', 'revisions', 'callbacks', 'init', 'onReload', 'revisionFor', 'invalidate'], 'description': 'Core reloader functionality'}]}",
    "version": "medium",
    "text_answer": "The reloader service maintains a 'revisions' map that stores version numbers for components. When a component is reloaded, the 'invalidate' method increments its revision number and triggers registered callbacks. The current revision can be retrieved using 'revisionFor' method.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nimport { moduleFor, ApplicationTestCase, strip, runTask } from 'internal-test-helpers';\n\nimport Service, { service } from '@ember/service';\nimport { Component, Helper } from '@ember/-internals/glimmer';\nimport { expect } from '@glimmer/util';\n\n// This simuates what the template hot-reloading would do in development mode\n// to avoid regressions\n\nmoduleFor(\n  'Appliation test: template hot reloading',\n  class extends ApplicationTestCase {\n    constructor() {\n      super(...arguments);\n\n      let didCreateReloader = (reloader) => {\n        this.reloader = reloader;\n      };\n\n      this.add(\n        'service:reloader',\n        Service.extend({\n          init() {\n            this._super(...arguments);\n            this.revisions = {};\n            this.callbacks = [];\n\n            didCreateReloader(this);\n          },\n\n          onReload(callback) {\n            this.callbacks.push(callback);\n          },\n\n          revisionFor(name) {\n            return this.revisions[name];\n          },\n\n          invalidate(name) {\n            let revision = this.revisions[name];\n\n            if (revision === undefined) {\n              revision = 0;\n            }\n\n            this.revisions[name] = ++revision;\n\n            this.callbacks.forEach((callback) => callback());\n          },\n        })\n      );\n\n      this.add(\n        'helper:hot-reload',\n        Helper.extend({\n          reloader: service(),\n\n          init() {\n            this._super(...arguments);\n            this.reloader.onReload(() => this.recompute());\n          },\n\n          compute([name]) {\n            let revision = this.reloader.revisionFor(name);\n\n            if (revision === undefined) {\n              return name;\n            } else {\n              return `${name}--hot-reload-${revision}`;\n            }\n          },\n        })\n      );\n    }\n\n    hotReload(name, template) {\n      let reloader = expect(this.reloader);\n      let revision = (reloader.revisionFor(name) || 0) + 1;\n      let ComponentClass =\n        this.applicationInstance.resolveRegistration(`component:${name}`) || null;\n\n      this.addComponent(`${name}--hot-reload-${revision}`, {\n        ComponentClass,\n        template,\n      });\n\n      reloader.invalidate(name);\n    }\n\n    ['@test hot reloading template-only components']() {\n      this.addTemplate(\n        'application',\n        strip`\n          [{{component (hot-reload \"x-foo\") name=\"first\"}}]\n          [{{component (hot-reload \"x-foo\") name=\"second\"}}]\n          [{{component (hot-reload \"x-bar\")}}]\n        `\n      );\n\n      this.addComponent('x-foo', {\n        ComponentClass: null,\n        template: 'x-foo: {{@name}}',\n      });\n\n      this.addComponent('x-bar', {\n        ComponentClass: null,\n        template: 'x-bar',\n      });\n\n      return this.visit('/').then(() => {\n        this.assertInnerHTML(strip`\n          [x-foo: first]\n          [x-foo: second]\n          [x-bar]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-foo', '<h1>{{@name}}</h1>');\n        });\n\n        this.assertInnerHTML(strip`\n          [<h1>first</h1>]\n          [<h1>second</h1>]\n          [x-bar]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-bar', '<h2>wow</h2>');\n        });\n\n        this.assertInnerHTML(strip`\n          [<h1>first</h1>]\n          [<h1>second</h1>]\n          [<h2>wow</h2>]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-foo', '<strong>x-foo</strong> <em>{{@name}}</em>');\n        });\n\n        this.assertInnerHTML(strip`\n          [<strong>x-foo</strong> <em>first</em>]\n          [<strong>x-foo</strong> <em>second</em>]\n          [<h2>wow</h2>]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-foo', 'x-foo: {{@name}}');\n          this.hotReload('x-bar', 'x-bar');\n        });\n\n        this.assertInnerHTML(strip`\n          [x-foo: first]\n          [x-foo: second]\n          [x-bar]\n        `);\n      });\n    }\n\n    ['@test hot reloading class-based components']() {\n      this.addTemplate(\n        'application',\n        strip`\n          [{{component (hot-reload \"x-foo\") name=\"first\"}}]\n          [{{component (hot-reload \"x-foo\") name=\"second\"}}]\n          [{{component (hot-reload \"x-bar\")}}]\n        `\n      );\n\n      let id = 0;\n\n      this.addComponent('x-foo', {\n        ComponentClass: Component.extend({\n          tagName: '',\n          init() {\n            this._super(...arguments);\n            this.set('id', id++);\n          },\n        }),\n        template: 'x-foo: {{@name}} ({{this.id}})',\n      });\n\n      this.addComponent('x-bar', {\n        ComponentClass: Component.extend({\n          tagName: '',\n          init() {\n            this._super(...arguments);\n            this.set('id', id++);\n          },\n        }),\n        template: 'x-bar ({{this.id}})',\n      });\n\n      return this.visit('/').then(() => {\n        this.assertInnerHTML(strip`\n          [x-foo: first (0)]\n          [x-foo: second (1)]\n          [x-bar (2)]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-foo', '<h1>{{@name}} ({{this.id}})</h1>');\n        });\n\n        this.assertInnerHTML(strip`\n          [<h1>first (3)</h1>]\n          [<h1>second (4)</h1>]\n          [x-bar (2)]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-bar', '<h2>wow ({{this.id}})</h2>');\n        });\n\n        this.assertInnerHTML(strip`\n          [<h1>first (3)</h1>]\n          [<h1>second (4)</h1>]\n          [<h2>wow (5)</h2>]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-foo', '<strong>x-foo</strong> <em>{{@name}} ({{this.id}})</em>');\n        });\n\n        this.assertInnerHTML(strip`\n          [<strong>x-foo</strong> <em>first (6)</em>]\n          [<strong>x-foo</strong> <em>second (7)</em>]\n          [<h2>wow (5)</h2>]\n        `);\n\n        runTask(() => {\n          this.hotReload('x-foo', 'x-foo: {{@name}} ({{this.id}})');\n          this.hotReload('x-bar', 'x-bar ({{this.id}})');\n        });\n\n        this.assertInnerHTML(strip`\n          [x-foo: first (8)]\n          [x-foo: second (9)]\n          [x-bar (10)]\n        `);\n      });\n    }\n  }\n);",
    "repo": "emberjs/ember.js",
    "path": "./datasets/diagrams-repos/emberjs/ember.js/packages/@ember/-internals/glimmer/tests/integration/application/hot-reload-test.js",
    "query": "How does the reloader service track revisions for different components?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'ApplicationTestCase', 'node_id': 'ApplicationTestCase', 'description': 'Appliation test case for template hot reloading', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'reloader', 'node_id': 'reloader', 'description': 'Service managing component revisions and reload callbacks', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'revisions', 'node_id': 'revisions', 'description': 'Map storing revision numbers for components', 'visibility': 'private', 'return_type': 'object', 'params': None, 'source_class_id': 'reloader'}, {'type': 'field', 'name': 'callbacks', 'node_id': 'callbacks', 'description': 'Array of callbacks to execute on reload', 'visibility': 'private', 'return_type': 'array', 'params': None, 'source_class_id': 'reloader'}, {'type': 'method', 'name': 'init', 'node_id': 'init', 'description': 'Initializes service with empty revisions and callbacks', 'visibility': 'public', 'return_type': 'void', 'params': '', 'source_class_id': 'reloader'}, {'type': 'method', 'name': 'onReload', 'node_id': 'onReload', 'description': 'Registers callback for reload events', 'visibility': 'public', 'return_type': 'void', 'params': 'callback', 'source_class_id': 'reloader'}, {'type': 'method', 'name': 'revisionFor', 'node_id': 'revisionFor', 'description': 'Gets current revision for a component', 'visibility': 'public', 'return_type': 'number', 'params': 'name', 'source_class_id': 'reloader'}, {'type': 'method', 'name': 'invalidate', 'node_id': 'invalidate', 'description': 'Increments revision for a component and triggers callbacks', 'visibility': 'public', 'return_type': 'void', 'params': 'name', 'source_class_id': 'reloader'}, {'type': 'class', 'name': 'hot-reload', 'node_id': 'hot-reload', 'description': 'Helper that generates component names with revision numbers', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'compute', 'node_id': 'compute', 'description': 'Computes component name with revision', 'visibility': 'public', 'return_type': 'string', 'params': '[name]', 'source_class_id': 'hot-reload'}, {'type': 'method', 'name': 'hotReload', 'node_id': 'hotReload', 'description': 'Updates component template and triggers reloader', 'visibility': 'public', 'return_type': 'void', 'params': 'name, template', 'source_class_id': 'ApplicationTestCase'}], 'edges': [{'node_id_from': 'reloader', 'node_id_to': 'revisions', 'description': ''}, {'node_id_from': 'reloader', 'node_id_to': 'callbacks', 'description': ''}, {'node_id_from': 'reloader', 'node_id_to': 'init', 'description': ''}, {'node_id_from': 'reloader', 'node_id_to': 'onReload', 'description': ''}, {'node_id_from': 'reloader', 'node_id_to': 'revisionFor', 'description': ''}, {'node_id_from': 'reloader', 'node_id_to': 'invalidate', 'description': ''}, {'node_id_from': 'init', 'node_id_to': 'revisions', 'description': 'initializes'}, {'node_id_from': 'init', 'node_id_to': 'callbacks', 'description': 'initializes'}, {'node_id_from': 'onReload', 'node_id_to': 'callbacks', 'description': 'adds'}, {'node_id_from': 'revisionFor', 'node_id_to': 'revisions', 'description': 'reads'}, {'node_id_from': 'invalidate', 'node_id_to': 'revisions', 'description': 'updates'}, {'node_id_from': 'invalidate', 'node_id_to': 'callbacks', 'description': 'executes'}, {'node_id_from': 'hot-reload', 'node_id_to': 'reloader', 'description': 'uses'}, {'node_id_from': 'hot-reload', 'node_id_to': 'compute', 'description': ''}, {'node_id_from': 'compute', 'node_id_to': 'revisionFor', 'description': 'calls'}, {'node_id_from': 'hotReload', 'node_id_to': 'invalidate', 'description': 'calls'}, {'node_id_from': 'ApplicationTestCase', 'node_id_to': 'hotReload', 'description': ''}, {'node_id_from': 'ApplicationTestCase', 'node_id_to': 'reloader', 'description': ''}, {'node_id_from': 'ApplicationTestCase', 'node_id_to': 'hot-reload', 'description': ''}], 'packages': [{'package_id': 'reloaderTestCase', 'children': ['ApplicationTestCase', 'reloaderCore', 'hotReload', 'hot-reload', 'compute'], 'description': 'Hot reloading functionality'}, {'package_id': 'reloaderCore', 'children': ['reloader', 'revisions', 'callbacks', 'init', 'onReload', 'revisionFor', 'invalidate'], 'description': 'Core reloader functionality'}]}",
    "version": "full",
    "text_answer": "The reloader service maintains a 'revisions' map that stores version numbers for components. When a component is reloaded, the 'invalidate' method increments its revision number and triggers registered callbacks. The current revision can be retrieved using 'revisionFor' method.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\n'use strict';\n\n$(document).ready(function () {\n  var $accordionToggler = $(this).find('[data-toggle=\"collapseAccordion\"]');\n  $accordionToggler.off('click').on('click', function (event) {\n    var $this = $(this);\n    $this.siblings('.panel-body').slideToggle(500);\n    $this.children().children('.panel-toggle').toggleClass('fa-angle-down fa-angle-up');\n    event.stopPropagation();\n    return false;\n  });\n});\n'use strict';\n\n(function ($) {\n\n  /**\n   * jQuery plugin for navigation bars\n   * Usage:\n   * <pre>\n   *   $('.navigation-bar').navigationBar();\n   * </pre>\n   *\n   * @param {object} options see <code>$.fn.navigationBar.defaults</code>\n   * @returns {$}\n   */\n\n  $.fn.navigationBar = function (options) {\n\n    var settings = $.extend({}, $.fn.navigationBar.defaults, options);\n\n    return this.each(function () {\n      var _this = this;\n\n      var containerSelector = '.navigation-bar-container';\n      var $navigationContainer = $(this).find(containerSelector);\n      var $sideNavToggler = $(this).find('[data-toggle=' + settings.navBarToggleDataAttr + ']');\n      var $subMenuToggler = $(this).find('[data-toggle=' + settings.subMenuNavToggleDataAttr + ']');\n      var firstLvlMenuItemsSelector = '.side-nav-menu>li';\n      var secondLvlMenuItemsSelector = '.side-nav-menu>li>ul>li';\n      var $moreActions = $(this).find('.more-actions');\n      var $dropdownMenu = $moreActions.children('.dropdown-menu');\n\n      $subMenuToggler.each(function (index, toggler) {\n        return $(toggler).parent().addClass('has-sub-menu');\n      });\n\n      if (settings.fitHeight) {\n        $(this).addClass('navigation-bar-fit-height');\n\n        // make scrolling effect on side nav ONLY, i.e. not effected on ambari main contents\n        $(this).find('.side-nav-menu').on('DOMMouseScroll mousewheel', function (ev) {\n          var $this = $(this),\n              scrollTop = this.scrollTop,\n              scrollHeight = this.scrollHeight,\n              height = $this.innerHeight(),\n              delta = ev.originalEvent.wheelDelta,\n              up = delta > 0;\n          var prevent = function prevent() {\n            ev.stopPropagation();\n            ev.preventDefault();\n            ev.returnValue = false;\n            return false;\n          };\n\n          if (!up && -delta > scrollHeight - height - scrollTop) {\n            // Scrolling down, but this will take us past the bottom.\n            $this.scrollTop(scrollHeight);\n            return prevent();\n          } else if (up && delta > scrollTop) {\n            // Scrolling up, but this will take us past the top.\n            $this.scrollTop(0);\n            return prevent();\n          }\n        });\n      }\n\n      //set main content left margin based on the width of side-nav\n      var containerWidth = $navigationContainer.width();\n      if (settings.moveLeftContent) {\n        $(settings.content).css('margin-left', containerWidth);\n      }\n      if (settings.moveLeftFooter) {\n        $(settings.footer).css('margin-left', containerWidth);\n      }\n\n      function popStateHandler() {\n        var path = window.location.pathname + window.location.hash;\n        $navigationContainer.find('li a').each(function (index, link) {\n          var $link = $(link);\n          var href = $link.attr('data-href') || $link.attr('href');\n          if (path.indexOf(href) !== -1 && ['', '#'].indexOf(href) === -1) {\n            $link.parent().addClass('active');\n          } else {\n            $link.parent().removeClass('active');\n          }\n        });\n      }\n\n      if (settings.handlePopState) {\n        popStateHandler();\n        $(window).bind('popstate', popStateHandler);\n      }\n\n      function clickHandler(el) {\n        var $li = $(el).parent();\n        var activeClass = settings.activeClass;\n\n        var activeMenuItems = firstLvlMenuItemsSelector + '.' + activeClass;\n        var activeSubMenuItems = secondLvlMenuItemsSelector + '.' + activeClass;\n        $navigationContainer.find(activeMenuItems).removeClass(activeClass);\n        $navigationContainer.find(activeSubMenuItems).removeClass(activeClass);\n        $li.addClass(activeClass);\n      }\n\n      /**\n       * Click on menu item\n       */\n      $(firstLvlMenuItemsSelector + '>a').on('click', function () {\n        clickHandler(this);\n      });\n\n      /**\n       * Click on sub menu item\n       */\n      $(secondLvlMenuItemsSelector + '>a').on('click', function () {\n        clickHandler(this);\n        $(this).parent().parent().parent().addClass(settings.activeClass);\n      });\n\n      /**\n       * Slider for sub menu\n       */\n      $subMenuToggler.off('click').on('click', function (event) {\n        // ignore click if navigation-bar is collapsed\n        if ($navigationContainer.hasClass('collapsed')) {\n          return false;\n        }\n        var $this = $(this);\n        $this.siblings('.sub-menu').slideToggle(600, function () {\n          var $topMenuItem = $this.parent();\n          var $subMenu = $topMenuItem.find('ul');\n          return $subMenu.is(':visible') ? $topMenuItem.removeClass('collapsed') : $topMenuItem.addClass('collapsed');\n        });\n        $this.children('.toggle-icon').toggleClass(settings.menuLeftClass + ' ' + settings.menuDownClass);\n        event.stopPropagation();\n        return false;\n      });\n\n      /**\n       * Hovering effects for \"more actions icon\": \"...\"\n       */\n      $(this).find('.mainmenu-li>a').hover(function () {\n        var $moreIcon = $(this).siblings('.more-actions');\n        if ($moreIcon.length && !$navigationContainer.hasClass('collapsed')) {\n          $moreIcon.css('display', 'inline-block');\n        }\n      }, function () {\n        var $moreIcon = $(this).siblings('.more-actions');\n        if ($moreIcon.length && !$navigationContainer.hasClass('collapsed')) {\n          $moreIcon.hide();\n        }\n      });\n      $moreActions.hover(function () {\n        $(this).css('display', 'inline-block');\n      });\n      if (settings.fitHeight) {\n        $moreActions.on('click', function () {\n          // set actions submenu position\n          var $moreIcon = $(this);\n          var $header = $('.side-nav-header');\n          $dropdownMenu.css({\n            top: $moreIcon.offset().top - $header.offset().top + 20 + 'px',\n            left: $moreIcon.offset().left + 'px'\n          });\n        });\n      }\n      $dropdownMenu.on('click', function () {\n        // some action was triggered, should hide this icon\n        var moreIcon = $(this).parent();\n        setTimeout(function () {\n          moreIcon.hide();\n        }, 1000);\n      });\n      $navigationContainer.children('.side-nav-menu').scroll(function () {\n        $moreActions.removeClass('open');\n      });\n\n      /**\n       * Expand/collapse navigation bar\n       */\n      $sideNavToggler.click(function () {\n\n        $navigationContainer.toggleClass('collapsed').promise().done(function () {\n          var subMenuSelector = 'ul.sub-menu';\n          var $subMenus = $navigationContainer.find(subMenuSelector);\n          var $subMenuItems = $navigationContainer.find('.side-nav-menu>li');\n          if ($navigationContainer.hasClass('collapsed')) {\n            // set sub menu invisible when collapsed\n            $subMenus.hide();\n            $moreActions.hide();\n            // set the hover effect when collapsed, should show sub-menu on hovering\n            $subMenuItems.hover(function () {\n              $(this).find(subMenuSelector).show();\n              // set sub-menu position\n              var $parent = $(this);\n              var $header = $('.side-nav-header');\n              if (settings.fitHeight) {\n                $(this).find(subMenuSelector).css({\n                  position: 'fixed',\n                  top: $parent.offset().top - $header.offset().top + 'px',\n                  left: 50 + 'px'\n                });\n              }\n            }, function () {\n              $(this).find(subMenuSelector).hide();\n            });\n          } else {\n            // keep showing all sub menu\n            $subMenus.show().each(function (index, item) {\n              return $(item).parent().removeClass('collapsed');\n            });\n            $subMenuItems.unbind('mouseenter mouseleave');\n            $navigationContainer.find('.toggle-icon').removeClass(settings.menuLeftClass).addClass(settings.menuDownClass);\n            // set sub-menu position\n            if (settings.fitHeight) {\n              $(_this).find(subMenuSelector).css({\n                position: 'relative',\n                top: 0,\n                left: 0\n              });\n            }\n          }\n\n          $navigationContainer.on('transitionend', function () {\n            //set main content left margin based on the width of side-nav\n            var containerWidth = $navigationContainer.width();\n            if (settings.moveLeftContent) {\n              $(settings.content).css('margin-left', containerWidth);\n            }\n            if (settings.moveLeftFooter) {\n              $(settings.footer).css('margin-left', containerWidth);\n            }\n          });\n          $sideNavToggler.find('span').toggleClass(settings.collapseNavBarClass + ' ' + settings.expandNavBarClass);\n        });\n        return false;\n      });\n    });\n  };\n\n  $.fn.navigationBar.defaults = {\n    handlePopState: true,\n    fitHeight: false,\n    content: '#main',\n    footer: 'footer',\n    moveLeftContent: true,\n    moveLeftFooter: true,\n    menuLeftClass: 'glyphicon-menu-right',\n    menuDownClass: 'glyphicon-menu-down',\n    collapseNavBarClass: 'fa-angle-double-left',\n    expandNavBarClass: 'fa-angle-double-right',\n    activeClass: 'active',\n    navBarToggleDataAttr: 'collapse-side-nav',\n    subMenuNavToggleDataAttr: 'collapse-sub-menu'\n  };\n})(jQuery);",
    "repo": "apache/hadoop",
    "path": "./datasets/diagrams-repos/apache/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp/src/main/webapp/js/bootstrap-hadoop.js",
    "query": "What is the structure of the navigation bar, including the main menu and submenus?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'navigationBar', 'node_id': 'navigationBar', 'description': 'Main jQuery plugin for navigation bars', 'visibility': 'public', 'return_type': 'jQuery', 'params': 'options', 'source_class_id': None}, {'type': 'entity', 'name': 'mainMenu', 'node_id': 'mainMenu', 'description': 'First level navigation menu', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'subMenu', 'node_id': 'subMenu', 'description': 'Second level navigation menu', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'navigationBar', 'node_id_to': 'mainMenu', 'description': 'manages'}, {'node_id_from': 'mainMenu', 'node_id_to': 'subMenu', 'description': 'contains'}], 'packages': [{'package_id': 'navigationStructure', 'children': ['navigationBar', 'mainMenu', 'subMenu'], 'description': 'Core navigation components'}]}",
    "version": "minimal",
    "text_answer": "The navigation bar consists of a main menu with first-level items and submenus for second-level navigation. It includes collapsible sections, more actions dropdown, and supports both click and hover interactions. The structure can be expanded/collapsed, and submenus can be toggled independently.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\n'use strict';\n\n$(document).ready(function () {\n  var $accordionToggler = $(this).find('[data-toggle=\"collapseAccordion\"]');\n  $accordionToggler.off('click').on('click', function (event) {\n    var $this = $(this);\n    $this.siblings('.panel-body').slideToggle(500);\n    $this.children().children('.panel-toggle').toggleClass('fa-angle-down fa-angle-up');\n    event.stopPropagation();\n    return false;\n  });\n});\n'use strict';\n\n(function ($) {\n\n  /**\n   * jQuery plugin for navigation bars\n   * Usage:\n   * <pre>\n   *   $('.navigation-bar').navigationBar();\n   * </pre>\n   *\n   * @param {object} options see <code>$.fn.navigationBar.defaults</code>\n   * @returns {$}\n   */\n\n  $.fn.navigationBar = function (options) {\n\n    var settings = $.extend({}, $.fn.navigationBar.defaults, options);\n\n    return this.each(function () {\n      var _this = this;\n\n      var containerSelector = '.navigation-bar-container';\n      var $navigationContainer = $(this).find(containerSelector);\n      var $sideNavToggler = $(this).find('[data-toggle=' + settings.navBarToggleDataAttr + ']');\n      var $subMenuToggler = $(this).find('[data-toggle=' + settings.subMenuNavToggleDataAttr + ']');\n      var firstLvlMenuItemsSelector = '.side-nav-menu>li';\n      var secondLvlMenuItemsSelector = '.side-nav-menu>li>ul>li';\n      var $moreActions = $(this).find('.more-actions');\n      var $dropdownMenu = $moreActions.children('.dropdown-menu');\n\n      $subMenuToggler.each(function (index, toggler) {\n        return $(toggler).parent().addClass('has-sub-menu');\n      });\n\n      if (settings.fitHeight) {\n        $(this).addClass('navigation-bar-fit-height');\n\n        // make scrolling effect on side nav ONLY, i.e. not effected on ambari main contents\n        $(this).find('.side-nav-menu').on('DOMMouseScroll mousewheel', function (ev) {\n          var $this = $(this),\n              scrollTop = this.scrollTop,\n              scrollHeight = this.scrollHeight,\n              height = $this.innerHeight(),\n              delta = ev.originalEvent.wheelDelta,\n              up = delta > 0;\n          var prevent = function prevent() {\n            ev.stopPropagation();\n            ev.preventDefault();\n            ev.returnValue = false;\n            return false;\n          };\n\n          if (!up && -delta > scrollHeight - height - scrollTop) {\n            // Scrolling down, but this will take us past the bottom.\n            $this.scrollTop(scrollHeight);\n            return prevent();\n          } else if (up && delta > scrollTop) {\n            // Scrolling up, but this will take us past the top.\n            $this.scrollTop(0);\n            return prevent();\n          }\n        });\n      }\n\n      //set main content left margin based on the width of side-nav\n      var containerWidth = $navigationContainer.width();\n      if (settings.moveLeftContent) {\n        $(settings.content).css('margin-left', containerWidth);\n      }\n      if (settings.moveLeftFooter) {\n        $(settings.footer).css('margin-left', containerWidth);\n      }\n\n      function popStateHandler() {\n        var path = window.location.pathname + window.location.hash;\n        $navigationContainer.find('li a').each(function (index, link) {\n          var $link = $(link);\n          var href = $link.attr('data-href') || $link.attr('href');\n          if (path.indexOf(href) !== -1 && ['', '#'].indexOf(href) === -1) {\n            $link.parent().addClass('active');\n          } else {\n            $link.parent().removeClass('active');\n          }\n        });\n      }\n\n      if (settings.handlePopState) {\n        popStateHandler();\n        $(window).bind('popstate', popStateHandler);\n      }\n\n      function clickHandler(el) {\n        var $li = $(el).parent();\n        var activeClass = settings.activeClass;\n\n        var activeMenuItems = firstLvlMenuItemsSelector + '.' + activeClass;\n        var activeSubMenuItems = secondLvlMenuItemsSelector + '.' + activeClass;\n        $navigationContainer.find(activeMenuItems).removeClass(activeClass);\n        $navigationContainer.find(activeSubMenuItems).removeClass(activeClass);\n        $li.addClass(activeClass);\n      }\n\n      /**\n       * Click on menu item\n       */\n      $(firstLvlMenuItemsSelector + '>a').on('click', function () {\n        clickHandler(this);\n      });\n\n      /**\n       * Click on sub menu item\n       */\n      $(secondLvlMenuItemsSelector + '>a').on('click', function () {\n        clickHandler(this);\n        $(this).parent().parent().parent().addClass(settings.activeClass);\n      });\n\n      /**\n       * Slider for sub menu\n       */\n      $subMenuToggler.off('click').on('click', function (event) {\n        // ignore click if navigation-bar is collapsed\n        if ($navigationContainer.hasClass('collapsed')) {\n          return false;\n        }\n        var $this = $(this);\n        $this.siblings('.sub-menu').slideToggle(600, function () {\n          var $topMenuItem = $this.parent();\n          var $subMenu = $topMenuItem.find('ul');\n          return $subMenu.is(':visible') ? $topMenuItem.removeClass('collapsed') : $topMenuItem.addClass('collapsed');\n        });\n        $this.children('.toggle-icon').toggleClass(settings.menuLeftClass + ' ' + settings.menuDownClass);\n        event.stopPropagation();\n        return false;\n      });\n\n      /**\n       * Hovering effects for \"more actions icon\": \"...\"\n       */\n      $(this).find('.mainmenu-li>a').hover(function () {\n        var $moreIcon = $(this).siblings('.more-actions');\n        if ($moreIcon.length && !$navigationContainer.hasClass('collapsed')) {\n          $moreIcon.css('display', 'inline-block');\n        }\n      }, function () {\n        var $moreIcon = $(this).siblings('.more-actions');\n        if ($moreIcon.length && !$navigationContainer.hasClass('collapsed')) {\n          $moreIcon.hide();\n        }\n      });\n      $moreActions.hover(function () {\n        $(this).css('display', 'inline-block');\n      });\n      if (settings.fitHeight) {\n        $moreActions.on('click', function () {\n          // set actions submenu position\n          var $moreIcon = $(this);\n          var $header = $('.side-nav-header');\n          $dropdownMenu.css({\n            top: $moreIcon.offset().top - $header.offset().top + 20 + 'px',\n            left: $moreIcon.offset().left + 'px'\n          });\n        });\n      }\n      $dropdownMenu.on('click', function () {\n        // some action was triggered, should hide this icon\n        var moreIcon = $(this).parent();\n        setTimeout(function () {\n          moreIcon.hide();\n        }, 1000);\n      });\n      $navigationContainer.children('.side-nav-menu').scroll(function () {\n        $moreActions.removeClass('open');\n      });\n\n      /**\n       * Expand/collapse navigation bar\n       */\n      $sideNavToggler.click(function () {\n\n        $navigationContainer.toggleClass('collapsed').promise().done(function () {\n          var subMenuSelector = 'ul.sub-menu';\n          var $subMenus = $navigationContainer.find(subMenuSelector);\n          var $subMenuItems = $navigationContainer.find('.side-nav-menu>li');\n          if ($navigationContainer.hasClass('collapsed')) {\n            // set sub menu invisible when collapsed\n            $subMenus.hide();\n            $moreActions.hide();\n            // set the hover effect when collapsed, should show sub-menu on hovering\n            $subMenuItems.hover(function () {\n              $(this).find(subMenuSelector).show();\n              // set sub-menu position\n              var $parent = $(this);\n              var $header = $('.side-nav-header');\n              if (settings.fitHeight) {\n                $(this).find(subMenuSelector).css({\n                  position: 'fixed',\n                  top: $parent.offset().top - $header.offset().top + 'px',\n                  left: 50 + 'px'\n                });\n              }\n            }, function () {\n              $(this).find(subMenuSelector).hide();\n            });\n          } else {\n            // keep showing all sub menu\n            $subMenus.show().each(function (index, item) {\n              return $(item).parent().removeClass('collapsed');\n            });\n            $subMenuItems.unbind('mouseenter mouseleave');\n            $navigationContainer.find('.toggle-icon').removeClass(settings.menuLeftClass).addClass(settings.menuDownClass);\n            // set sub-menu position\n            if (settings.fitHeight) {\n              $(_this).find(subMenuSelector).css({\n                position: 'relative',\n                top: 0,\n                left: 0\n              });\n            }\n          }\n\n          $navigationContainer.on('transitionend', function () {\n            //set main content left margin based on the width of side-nav\n            var containerWidth = $navigationContainer.width();\n            if (settings.moveLeftContent) {\n              $(settings.content).css('margin-left', containerWidth);\n            }\n            if (settings.moveLeftFooter) {\n              $(settings.footer).css('margin-left', containerWidth);\n            }\n          });\n          $sideNavToggler.find('span').toggleClass(settings.collapseNavBarClass + ' ' + settings.expandNavBarClass);\n        });\n        return false;\n      });\n    });\n  };\n\n  $.fn.navigationBar.defaults = {\n    handlePopState: true,\n    fitHeight: false,\n    content: '#main',\n    footer: 'footer',\n    moveLeftContent: true,\n    moveLeftFooter: true,\n    menuLeftClass: 'glyphicon-menu-right',\n    menuDownClass: 'glyphicon-menu-down',\n    collapseNavBarClass: 'fa-angle-double-left',\n    expandNavBarClass: 'fa-angle-double-right',\n    activeClass: 'active',\n    navBarToggleDataAttr: 'collapse-side-nav',\n    subMenuNavToggleDataAttr: 'collapse-sub-menu'\n  };\n})(jQuery);",
    "repo": "apache/hadoop",
    "path": "./datasets/diagrams-repos/apache/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp/src/main/webapp/js/bootstrap-hadoop.js",
    "query": "What is the structure of the navigation bar, including the main menu and submenus?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'navigationBar', 'node_id': 'navigationBar', 'description': 'Main jQuery plugin for navigation bars', 'visibility': 'public', 'return_type': 'jQuery', 'params': 'options', 'source_class_id': None}, {'type': 'entity', 'name': 'mainMenu', 'node_id': 'mainMenu', 'description': 'First level navigation menu', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'subMenu', 'node_id': 'subMenu', 'description': 'Second level navigation menu', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'clickHandler', 'node_id': 'clickHandler', 'description': 'Handles menu item clicks', 'visibility': 'private', 'return_type': 'void', 'params': 'el', 'source_class_id': None}, {'type': 'entity', 'name': 'moreActions', 'node_id': 'moreActions', 'description': 'Additional menu actions dropdown', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'navigationBar', 'node_id_to': 'mainMenu', 'description': 'manages'}, {'node_id_from': 'mainMenu', 'node_id_to': 'subMenu', 'description': 'contains'}, {'node_id_from': 'clickHandler', 'node_id_to': 'mainMenu', 'description': 'handles clicks'}, {'node_id_from': 'clickHandler', 'node_id_to': 'subMenu', 'description': 'handles clicks'}, {'node_id_from': 'mainMenu', 'node_id_to': 'moreActions', 'description': 'contains'}], 'packages': [{'package_id': 'navigationStructure', 'children': ['navigationBar', 'mainMenu', 'subMenu', 'moreActions'], 'description': 'Core navigation components'}]}",
    "version": "medium",
    "text_answer": "The navigation bar consists of a main menu with first-level items and submenus for second-level navigation. It includes collapsible sections, more actions dropdown, and supports both click and hover interactions. The structure can be expanded/collapsed, and submenus can be toggled independently.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\n'use strict';\n\n$(document).ready(function () {\n  var $accordionToggler = $(this).find('[data-toggle=\"collapseAccordion\"]');\n  $accordionToggler.off('click').on('click', function (event) {\n    var $this = $(this);\n    $this.siblings('.panel-body').slideToggle(500);\n    $this.children().children('.panel-toggle').toggleClass('fa-angle-down fa-angle-up');\n    event.stopPropagation();\n    return false;\n  });\n});\n'use strict';\n\n(function ($) {\n\n  /**\n   * jQuery plugin for navigation bars\n   * Usage:\n   * <pre>\n   *   $('.navigation-bar').navigationBar();\n   * </pre>\n   *\n   * @param {object} options see <code>$.fn.navigationBar.defaults</code>\n   * @returns {$}\n   */\n\n  $.fn.navigationBar = function (options) {\n\n    var settings = $.extend({}, $.fn.navigationBar.defaults, options);\n\n    return this.each(function () {\n      var _this = this;\n\n      var containerSelector = '.navigation-bar-container';\n      var $navigationContainer = $(this).find(containerSelector);\n      var $sideNavToggler = $(this).find('[data-toggle=' + settings.navBarToggleDataAttr + ']');\n      var $subMenuToggler = $(this).find('[data-toggle=' + settings.subMenuNavToggleDataAttr + ']');\n      var firstLvlMenuItemsSelector = '.side-nav-menu>li';\n      var secondLvlMenuItemsSelector = '.side-nav-menu>li>ul>li';\n      var $moreActions = $(this).find('.more-actions');\n      var $dropdownMenu = $moreActions.children('.dropdown-menu');\n\n      $subMenuToggler.each(function (index, toggler) {\n        return $(toggler).parent().addClass('has-sub-menu');\n      });\n\n      if (settings.fitHeight) {\n        $(this).addClass('navigation-bar-fit-height');\n\n        // make scrolling effect on side nav ONLY, i.e. not effected on ambari main contents\n        $(this).find('.side-nav-menu').on('DOMMouseScroll mousewheel', function (ev) {\n          var $this = $(this),\n              scrollTop = this.scrollTop,\n              scrollHeight = this.scrollHeight,\n              height = $this.innerHeight(),\n              delta = ev.originalEvent.wheelDelta,\n              up = delta > 0;\n          var prevent = function prevent() {\n            ev.stopPropagation();\n            ev.preventDefault();\n            ev.returnValue = false;\n            return false;\n          };\n\n          if (!up && -delta > scrollHeight - height - scrollTop) {\n            // Scrolling down, but this will take us past the bottom.\n            $this.scrollTop(scrollHeight);\n            return prevent();\n          } else if (up && delta > scrollTop) {\n            // Scrolling up, but this will take us past the top.\n            $this.scrollTop(0);\n            return prevent();\n          }\n        });\n      }\n\n      //set main content left margin based on the width of side-nav\n      var containerWidth = $navigationContainer.width();\n      if (settings.moveLeftContent) {\n        $(settings.content).css('margin-left', containerWidth);\n      }\n      if (settings.moveLeftFooter) {\n        $(settings.footer).css('margin-left', containerWidth);\n      }\n\n      function popStateHandler() {\n        var path = window.location.pathname + window.location.hash;\n        $navigationContainer.find('li a').each(function (index, link) {\n          var $link = $(link);\n          var href = $link.attr('data-href') || $link.attr('href');\n          if (path.indexOf(href) !== -1 && ['', '#'].indexOf(href) === -1) {\n            $link.parent().addClass('active');\n          } else {\n            $link.parent().removeClass('active');\n          }\n        });\n      }\n\n      if (settings.handlePopState) {\n        popStateHandler();\n        $(window).bind('popstate', popStateHandler);\n      }\n\n      function clickHandler(el) {\n        var $li = $(el).parent();\n        var activeClass = settings.activeClass;\n\n        var activeMenuItems = firstLvlMenuItemsSelector + '.' + activeClass;\n        var activeSubMenuItems = secondLvlMenuItemsSelector + '.' + activeClass;\n        $navigationContainer.find(activeMenuItems).removeClass(activeClass);\n        $navigationContainer.find(activeSubMenuItems).removeClass(activeClass);\n        $li.addClass(activeClass);\n      }\n\n      /**\n       * Click on menu item\n       */\n      $(firstLvlMenuItemsSelector + '>a').on('click', function () {\n        clickHandler(this);\n      });\n\n      /**\n       * Click on sub menu item\n       */\n      $(secondLvlMenuItemsSelector + '>a').on('click', function () {\n        clickHandler(this);\n        $(this).parent().parent().parent().addClass(settings.activeClass);\n      });\n\n      /**\n       * Slider for sub menu\n       */\n      $subMenuToggler.off('click').on('click', function (event) {\n        // ignore click if navigation-bar is collapsed\n        if ($navigationContainer.hasClass('collapsed')) {\n          return false;\n        }\n        var $this = $(this);\n        $this.siblings('.sub-menu').slideToggle(600, function () {\n          var $topMenuItem = $this.parent();\n          var $subMenu = $topMenuItem.find('ul');\n          return $subMenu.is(':visible') ? $topMenuItem.removeClass('collapsed') : $topMenuItem.addClass('collapsed');\n        });\n        $this.children('.toggle-icon').toggleClass(settings.menuLeftClass + ' ' + settings.menuDownClass);\n        event.stopPropagation();\n        return false;\n      });\n\n      /**\n       * Hovering effects for \"more actions icon\": \"...\"\n       */\n      $(this).find('.mainmenu-li>a').hover(function () {\n        var $moreIcon = $(this).siblings('.more-actions');\n        if ($moreIcon.length && !$navigationContainer.hasClass('collapsed')) {\n          $moreIcon.css('display', 'inline-block');\n        }\n      }, function () {\n        var $moreIcon = $(this).siblings('.more-actions');\n        if ($moreIcon.length && !$navigationContainer.hasClass('collapsed')) {\n          $moreIcon.hide();\n        }\n      });\n      $moreActions.hover(function () {\n        $(this).css('display', 'inline-block');\n      });\n      if (settings.fitHeight) {\n        $moreActions.on('click', function () {\n          // set actions submenu position\n          var $moreIcon = $(this);\n          var $header = $('.side-nav-header');\n          $dropdownMenu.css({\n            top: $moreIcon.offset().top - $header.offset().top + 20 + 'px',\n            left: $moreIcon.offset().left + 'px'\n          });\n        });\n      }\n      $dropdownMenu.on('click', function () {\n        // some action was triggered, should hide this icon\n        var moreIcon = $(this).parent();\n        setTimeout(function () {\n          moreIcon.hide();\n        }, 1000);\n      });\n      $navigationContainer.children('.side-nav-menu').scroll(function () {\n        $moreActions.removeClass('open');\n      });\n\n      /**\n       * Expand/collapse navigation bar\n       */\n      $sideNavToggler.click(function () {\n\n        $navigationContainer.toggleClass('collapsed').promise().done(function () {\n          var subMenuSelector = 'ul.sub-menu';\n          var $subMenus = $navigationContainer.find(subMenuSelector);\n          var $subMenuItems = $navigationContainer.find('.side-nav-menu>li');\n          if ($navigationContainer.hasClass('collapsed')) {\n            // set sub menu invisible when collapsed\n            $subMenus.hide();\n            $moreActions.hide();\n            // set the hover effect when collapsed, should show sub-menu on hovering\n            $subMenuItems.hover(function () {\n              $(this).find(subMenuSelector).show();\n              // set sub-menu position\n              var $parent = $(this);\n              var $header = $('.side-nav-header');\n              if (settings.fitHeight) {\n                $(this).find(subMenuSelector).css({\n                  position: 'fixed',\n                  top: $parent.offset().top - $header.offset().top + 'px',\n                  left: 50 + 'px'\n                });\n              }\n            }, function () {\n              $(this).find(subMenuSelector).hide();\n            });\n          } else {\n            // keep showing all sub menu\n            $subMenus.show().each(function (index, item) {\n              return $(item).parent().removeClass('collapsed');\n            });\n            $subMenuItems.unbind('mouseenter mouseleave');\n            $navigationContainer.find('.toggle-icon').removeClass(settings.menuLeftClass).addClass(settings.menuDownClass);\n            // set sub-menu position\n            if (settings.fitHeight) {\n              $(_this).find(subMenuSelector).css({\n                position: 'relative',\n                top: 0,\n                left: 0\n              });\n            }\n          }\n\n          $navigationContainer.on('transitionend', function () {\n            //set main content left margin based on the width of side-nav\n            var containerWidth = $navigationContainer.width();\n            if (settings.moveLeftContent) {\n              $(settings.content).css('margin-left', containerWidth);\n            }\n            if (settings.moveLeftFooter) {\n              $(settings.footer).css('margin-left', containerWidth);\n            }\n          });\n          $sideNavToggler.find('span').toggleClass(settings.collapseNavBarClass + ' ' + settings.expandNavBarClass);\n        });\n        return false;\n      });\n    });\n  };\n\n  $.fn.navigationBar.defaults = {\n    handlePopState: true,\n    fitHeight: false,\n    content: '#main',\n    footer: 'footer',\n    moveLeftContent: true,\n    moveLeftFooter: true,\n    menuLeftClass: 'glyphicon-menu-right',\n    menuDownClass: 'glyphicon-menu-down',\n    collapseNavBarClass: 'fa-angle-double-left',\n    expandNavBarClass: 'fa-angle-double-right',\n    activeClass: 'active',\n    navBarToggleDataAttr: 'collapse-side-nav',\n    subMenuNavToggleDataAttr: 'collapse-sub-menu'\n  };\n})(jQuery);",
    "repo": "apache/hadoop",
    "path": "./datasets/diagrams-repos/apache/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp/src/main/webapp/js/bootstrap-hadoop.js",
    "query": "What is the structure of the navigation bar, including the main menu and submenus?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'navigationBar', 'node_id': 'navigationBar', 'description': 'Main jQuery plugin for navigation bars', 'visibility': 'public', 'return_type': 'jQuery', 'params': 'options', 'source_class_id': None}, {'type': 'entity', 'name': 'mainMenu', 'node_id': 'mainMenu', 'description': 'First level navigation menu', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'subMenu', 'node_id': 'subMenu', 'description': 'Second level navigation menu', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'clickHandler', 'node_id': 'clickHandler', 'description': 'Handles menu item clicks', 'visibility': 'private', 'return_type': 'void', 'params': 'el', 'source_class_id': None}, {'type': 'entity', 'name': 'moreActions', 'node_id': 'moreActions', 'description': 'Additional menu actions dropdown', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'popStateHandler', 'node_id': 'popStateHandler', 'description': 'Handles browser navigation state', 'visibility': 'private', 'return_type': 'void', 'params': '', 'source_class_id': None}, {'type': 'entity', 'name': 'navigationSettings', 'node_id': 'navigationSettings', 'description': 'Navigation bar configuration options', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'subMenuToggler', 'node_id': 'subMenuToggler', 'description': 'Handles submenu expansion/collapse', 'visibility': 'private', 'return_type': 'boolean', 'params': 'event', 'source_class_id': None}, {'type': 'function', 'name': 'sideNavToggler', 'node_id': 'sideNavToggler', 'description': 'Handles main navigation bar collapse/expand', 'visibility': 'private', 'return_type': 'boolean', 'params': '', 'source_class_id': None}], 'edges': [{'node_id_from': 'navigationBar', 'node_id_to': 'mainMenu', 'description': 'manages'}, {'node_id_from': 'mainMenu', 'node_id_to': 'subMenu', 'description': 'contains'}, {'node_id_from': 'clickHandler', 'node_id_to': 'mainMenu', 'description': 'handles clicks'}, {'node_id_from': 'clickHandler', 'node_id_to': 'subMenu', 'description': 'handles clicks'}, {'node_id_from': 'mainMenu', 'node_id_to': 'moreActions', 'description': 'contains'}, {'node_id_from': 'navigationBar', 'node_id_to': 'navigationSettings', 'description': 'uses'}, {'node_id_from': 'subMenuToggler', 'node_id_to': 'subMenu', 'description': 'controls'}, {'node_id_from': 'sideNavToggler', 'node_id_to': 'mainMenu', 'description': 'controls'}, {'node_id_from': 'popStateHandler', 'node_id_to': 'mainMenu', 'description': 'updates'}], 'packages': [{'package_id': 'navigationStructure', 'children': ['navigationBar', 'mainMenu', 'subMenu', 'moreActions', 'navigationSettings'], 'description': 'Core navigation components'}, {'package_id': 'handlers', 'children': ['clickHandler', 'popStateHandler', 'subMenuToggler', 'sideNavToggler'], 'description': 'Event handlers'}]}",
    "version": "full",
    "text_answer": "The navigation bar consists of a main menu with first-level items and submenus for second-level navigation. It includes collapsible sections, more actions dropdown, and supports both click and hover interactions. The structure can be expanded/collapsed, and submenus can be toggled independently.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Python",
    "code": "\nimport argparse\nimport os\nimport subprocess\nimport sys\nfrom pathlib import Path\nfrom urllib.parse import SplitResult, urlsplit, urlunsplit\n\n\ndef resolve(x: Path) -> Path:\n    return x.expanduser().resolve()\n\n\ndef path_equals(a: Path, b: Path) -> bool:\n    return resolve(a) == resolve(b)\n\n\ndef compute_s3_url(*, s3_bucket: str, prefix: str, artifact: str) -> str:\n    if prefix == \"\":\n        return f\"s3://{s3_bucket}/{artifact}\"\n    return f\"s3://{s3_bucket}/{prefix}/{artifact}\"\n\n\ndef aws_s3_upload(*, src: Path, dest: str, make_public: bool) -> None:\n    cli_args = [\"aws\", \"s3\", \"cp\", \"--no-progress\", str(src), dest]\n    if make_public:\n        cli_args.extend([\"--acl\", \"public-read\"])\n    print(\" \".join(cli_args))\n    subprocess.run(\n        cli_args,\n        check=True,\n        encoding=\"utf-8\",\n    )\n\n\ndef aws_s3_download(*, src: str, dest_dir: Path) -> None:\n    cli_args = [\"aws\", \"s3\", \"cp\", \"--no-progress\", src, str(dest_dir)]\n    print(\" \".join(cli_args))\n    subprocess.run(\n        cli_args,\n        check=True,\n        encoding=\"utf-8\",\n    )\n\n\ndef aws_s3_download_with_wildcard(*, src: str, dest_dir: Path) -> None:\n    parsed_src = urlsplit(src)\n    src_dir = urlunsplit(\n        SplitResult(\n            scheme=\"s3\",\n            netloc=parsed_src.netloc,\n            path=os.path.dirname(parsed_src.path),\n            query=\"\",\n            fragment=\"\",\n        )\n    )\n    src_glob = os.path.basename(parsed_src.path)\n    cli_args = [\n        \"aws\",\n        \"s3\",\n        \"cp\",\n        \"--recursive\",\n        \"--no-progress\",\n        \"--exclude\",\n        \"'*'\",\n        \"--include\",\n        src_glob,\n        src_dir,\n        str(dest_dir),\n    ]\n    print(\" \".join(cli_args))\n    subprocess.run(\n        cli_args,\n        check=True,\n        encoding=\"utf-8\",\n    )\n\n\ndef upload(*, args: argparse.Namespace) -> None:\n    print(f\"Uploading artifacts to prefix {args.prefix}...\")\n    for artifact in args.artifacts:\n        artifact_path = Path(artifact)\n        s3_url = compute_s3_url(\n            s3_bucket=args.s3_bucket, prefix=args.prefix, artifact=artifact_path.name\n        )\n        aws_s3_upload(src=artifact_path, dest=s3_url, make_public=args.make_public)\n\n\ndef download(*, args: argparse.Namespace) -> None:\n    print(f\"Downloading artifacts from prefix {args.prefix}...\")\n    dest_dir = Path(args.dest_dir)\n    print(f\"mkdir -p {str(dest_dir)}\")\n    dest_dir.mkdir(parents=True, exist_ok=True)\n    for artifact in args.artifacts:\n        s3_url = compute_s3_url(\n            s3_bucket=args.s3_bucket, prefix=args.prefix, artifact=artifact\n        )\n        if \"*\" in artifact:\n            aws_s3_download_with_wildcard(src=s3_url, dest_dir=dest_dir)\n        else:\n            aws_s3_download(src=s3_url, dest_dir=dest_dir)\n\n\nif __name__ == \"__main__\":\n    # Ensure that the current working directory is the project root\n    if not (Path.cwd() / \"ops\").is_dir() or not path_equals(\n        Path(__file__).parent.parent, Path.cwd() / \"ops\"\n    ):\n        x = Path(__file__).name\n        raise RuntimeError(f\"Script {x} must be run at the project's root directory\")\n\n    root_parser = argparse.ArgumentParser()\n    subparser_factory = root_parser.add_subparsers(required=True, dest=\"command\")\n    parsers = {}\n    for command in [\"upload\", \"download\"]:\n        parsers[command] = subparser_factory.add_parser(command)\n        parsers[command].add_argument(\n            \"--s3-bucket\",\n            type=str,\n            required=True,\n            help=\"Name of the S3 bucket to store the artifact\",\n        )\n        parsers[command].add_argument(\n            \"--prefix\",\n            type=str,\n            required=True,\n            help=(\n                \"Where the artifact(s) would be stored. The artifact(s) will be stored at \"\n                \"s3://[s3-bucket]/[prefix]/[filename].\"\n            ),\n        )\n        parsers[command].add_argument(\n            \"artifacts\",\n            type=str,\n            nargs=\"+\",\n            metavar=\"artifact\",\n            help=f\"Artifact(s) to {command}\",\n        )\n\n    parsers[\"upload\"].add_argument(\n        \"--make-public\", action=\"store_true\", help=\"Make artifact publicly accessible\"\n    )\n    parsers[\"download\"].add_argument(\n        \"--dest-dir\", type=str, required=True, help=\"Where to download artifact(s)\"\n    )\n\n    if len(sys.argv) == 1:\n        print(\"1. Upload artifact(s)\")\n        parsers[\"upload\"].print_help()\n        print(\"\\n2. Download artifact(s)\")\n        parsers[\"download\"].print_help()\n        sys.exit(1)\n\n    parsed_args = root_parser.parse_args()\n    if parsed_args.command == \"upload\":\n        upload(args=parsed_args)\n    elif parsed_args.command == \"download\":\n        download(args=parsed_args)",
    "repo": "dmlc/xgboost",
    "path": "./datasets/diagrams-repos/dmlc/xgboost/ops/pipeline/manage-artifacts.py",
    "query": "Illustrate the relationship between the functions in the script and how they are called.",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'main', 'node_id': 'main', 'description': 'Main entry point of script', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'upload', 'node_id': 'upload', 'description': 'Main function to handle artifact upload to S3', 'visibility': 'public', 'return_type': 'None', 'params': 'args: argparse.Namespace', 'source_class_id': None}, {'type': 'function', 'name': 'download', 'node_id': 'download', 'description': 'Main function to handle artifact download from S3', 'visibility': 'public', 'return_type': 'None', 'params': 'args: argparse.Namespace', 'source_class_id': None}, {'type': 'function', 'name': 'aws_s3_upload', 'node_id': 'aws_s3_upload', 'description': 'Executes AWS CLI command to upload file to S3', 'visibility': 'public', 'return_type': 'None', 'params': 'src: Path, dest: str, make_public: bool', 'source_class_id': None}, {'type': 'function', 'name': 'aws_s3_download', 'node_id': 'aws_s3_download', 'description': 'Executes AWS CLI command to download file from S3', 'visibility': 'public', 'return_type': 'None', 'params': 'src: str, dest_dir: Path', 'source_class_id': None}, {'type': 'function', 'name': 'aws_s3_download_with_wildcard', 'node_id': 'aws_s3_download_with_wildcard', 'description': 'Downloads S3 files matching wildcard pattern', 'visibility': 'public', 'return_type': 'None', 'params': 'src: str, dest_dir: Path', 'source_class_id': None}, {'type': 'function', 'name': 'compute_s3_url', 'node_id': 'compute_s3_url', 'description': 'Constructs S3 URL from components', 'visibility': 'public', 'return_type': 'str', 'params': 's3_bucket: str, prefix: str, artifact: str', 'source_class_id': None}, {'type': 'function', 'name': 'resolve', 'node_id': 'resolve', 'description': 'Resolves and expands path', 'visibility': 'public', 'return_type': 'Path', 'params': 'x: Path', 'source_class_id': None}, {'type': 'function', 'name': 'path_equals', 'node_id': 'path_equals', 'description': 'Compares two paths for equality', 'visibility': 'public', 'return_type': 'bool', 'params': 'a: Path, b: Path', 'source_class_id': None}], 'edges': [{'node_id_from': 'main', 'node_id_to': 'path_equals', 'description': 'calls'}, {'node_id_from': 'main', 'node_id_to': 'download', 'description': 'calls'}, {'node_id_from': 'main', 'node_id_to': 'upload', 'description': 'calls'}, {'node_id_from': 'upload', 'node_id_to': 'aws_s3_upload', 'description': 'calls'}, {'node_id_from': 'download', 'node_id_to': 'aws_s3_download', 'description': 'calls'}, {'node_id_from': 'download', 'node_id_to': 'aws_s3_download_with_wildcard', 'description': 'calls for wildcard patterns'}, {'node_id_from': 'upload', 'node_id_to': 'compute_s3_url', 'description': 'calls'}, {'node_id_from': 'download', 'node_id_to': 'compute_s3_url', 'description': 'calls'}, {'node_id_from': 'path_equals', 'node_id_to': 'resolve', 'description': 'calls'}], 'packages': [{'package_id': 's3Operations', 'children': ['upload', 'download'], 'description': 'Main operations'}, {'package_id': 's3Utils', 'children': ['compute_s3_url', 'aws_s3_upload', 'aws_s3_download', 'aws_s3_download_with_wildcard'], 'description': 'S3 utility functions'}, {'package_id': 'pathUtils', 'children': ['resolve', 'path_equals'], 'description': 'Path manipulation utilities'}]}",
    "version": "full",
    "text_answer": "The script centers around two main functions: 'upload' and 'download', which handle S3 operations. These functions rely on utility functions like 'aws_s3_upload', 'aws_s3_download', and 'compute_s3_url' to perform their tasks. Additional support is provided by path manipulation utilities and specialized functions for handling wildcard downloads.",
    "possible_version": [
      "minimal",
      "medium",
      "full"
    ]
  },
  {
    "language": "Go",
    "code": "\npackage tcp\n\n/*\n // ref https://github.com/golang/go/issues/25832\n\n #cgo CFLAGS: -I../../../../../../../../../../../common/go/api -I../api\n #cgo linux LDFLAGS: -Wl,-unresolved-symbols=ignore-all\n #cgo darwin LDFLAGS: -Wl,-undefined,dynamic_lookup\n\n #include <stdlib.h>\n #include <string.h>\n\n #include \"api.h\"\n*/\nimport \"C\"\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"runtime/debug\"\n\t\"sync\"\n\n\t\"github.com/envoyproxy/envoy/contrib/golang/common/go/api\"\n)\n\nvar (\n\tErrDupRequestKey = errors.New(\"dup request key\")\n\n\tErrorInfoForPanic = \"error happened in golang http-tcp bridge\\r\\n\"\n)\n\nvar Requests = &requestMap{}\n\ntype requestMap struct {\n\trequests sync.Map // *C.httpRequest -> *httpRequest\n}\n\nfunc (f *requestMap) StoreReq(key *C.httpRequest, req *httpRequest) error {\n\tif _, loaded := f.requests.LoadOrStore(key, req); loaded {\n\t\treturn ErrDupRequestKey\n\t}\n\treturn nil\n}\n\n// TODO(duxin40): introduce the worker_id as PR#31987 to improve the performance when there are large envoy workers.\nfunc (f *requestMap) GetReq(key *C.httpRequest) *httpRequest {\n\tif v, ok := f.requests.Load(key); ok {\n\t\treturn v.(*httpRequest)\n\t}\n\treturn nil\n}\n\nfunc (f *requestMap) DeleteReq(key *C.httpRequest) {\n\tf.requests.Delete(key)\n}\n\nfunc (f *requestMap) Clear() {\n\tf.requests.Range(func(key, _ interface{}) bool {\n\t\tf.requests.Delete(key)\n\t\treturn true\n\t})\n}\n\nfunc getOrCreateState(s *C.processState) *processState {\n\tr := s.req\n\treq := getRequest(r)\n\tif req == nil {\n\t\treq = createRequest(r)\n\t}\n\tif s.is_encoding == 0 {\n\t\tif req.decodingState.processState == nil {\n\t\t\treq.decodingState.processState = s\n\t\t}\n\t\treturn &req.decodingState\n\t}\n\n\tif req.encodingState.processState == nil {\n\t\treq.encodingState.processState = s\n\t}\n\treturn &req.encodingState\n}\n\nfunc createRequest(r *C.httpRequest) *httpRequest {\n\treq := &httpRequest{\n\t\treq: r,\n\t}\n\treq.decodingState.request = req\n\treq.encodingState.request = req\n\n\terr := Requests.StoreReq(r, req)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"createRequest failed, err: %s\", err.Error()))\n\t}\n\n\tconfigId := uint64(r.configId)\n\n\tfilterFactory, config := getHttpTcpBridgeFactoryAndConfig(req.pluginName(), configId)\n\tf := filterFactory(config, req)\n\treq.httpTcpBridge = f\n\n\treturn req\n}\n\nfunc getRequest(r *C.httpRequest) *httpRequest {\n\treturn Requests.GetReq(r)\n}\n\n//export envoyGoHttpTcpBridgeOnEncodeHeader\nfunc envoyGoHttpTcpBridgeOnEncodeHeader(s *C.processState, endStream, headerNum, headerBytes, buffer, length uint64) (status uint64) {\n\tstate := getOrCreateState(s)\n\treq := state.request\n\tbuf := &httpBuffer{\n\t\tstate:               state,\n\t\tenvoyBufferInstance: buffer,\n\t\tlength:              length,\n\t}\n\n\tfilter := req.httpTcpBridge\n\theader := &requestHeaderMapImpl{\n\t\trequestOrResponseHeaderMapImpl{\n\t\t\theaderMapImpl{\n\t\t\t\tstate:       state,\n\t\t\t\theaderNum:   headerNum,\n\t\t\t\theaderBytes: headerBytes,\n\t\t\t},\n\t\t},\n\t}\n\n\tdefer func() {\n\t\tif e := recover(); e != nil {\n\t\t\tapi.LogErrorf(\"go side: golang http-tcp bridge: encodeHeader: panic serving: %v\\n%s\", e, debug.Stack())\n\t\t\tstatus = uint64(api.HttpTcpBridgeEndStream)\n\t\t\tbuf.SetString(ErrorInfoForPanic)\n\t\t}\n\t}()\n\n\treturn uint64(filter.EncodeHeaders(header, buf, endStream == uint64(api.EndStream)))\n}\n\n//export envoyGoHttpTcpBridgeOnEncodeData\nfunc envoyGoHttpTcpBridgeOnEncodeData(s *C.processState, endStream, buffer, length uint64) (status uint64) {\n\tstate := getOrCreateState(s)\n\treq := state.request\n\tbuf := &httpBuffer{\n\t\tstate:               state,\n\t\tenvoyBufferInstance: buffer,\n\t\tlength:              length,\n\t}\n\n\tfilter := req.httpTcpBridge\n\n\tdefer func() {\n\t\tif e := recover(); e != nil {\n\t\t\tapi.LogErrorf(\"go side: golang http-tcp bridge: encodeData: panic serving: %v\\n%s\", e, debug.Stack())\n\t\t\tstatus = uint64(api.HttpTcpBridgeEndStream)\n\t\t\tbuf.SetString(ErrorInfoForPanic)\n\t\t}\n\t}()\n\n\tstatus = uint64(filter.EncodeData(buf, endStream == uint64(api.EndStream)))\n\tif status == uint64(api.HttpTcpBridgeStopAndBuffer) && endStream == uint64(api.EndStream) {\n\t\tpanic(\"encodeData: HttpTcpBridgeStopAndBuffer is not allowed when endStream is true\")\n\t}\n\n\treturn\n}\n\n//export envoyGoHttpTcpBridgeOnUpstreamData\nfunc envoyGoHttpTcpBridgeOnUpstreamData(s *C.processState, endStream, headerNum, headerBytes, buffer, length uint64) (status uint64) {\n\n\tstate := getOrCreateState(s)\n\treq := state.request\n\tbuf := &httpBuffer{\n\t\tstate:               state,\n\t\tenvoyBufferInstance: buffer,\n\t\tlength:              length,\n\t}\n\n\tfilter := req.httpTcpBridge\n\theader := &responseHeaderMapImpl{\n\t\trequestOrResponseHeaderMapImpl{\n\t\t\theaderMapImpl{\n\t\t\t\tstate:       state,\n\t\t\t\theaderNum:   headerNum,\n\t\t\t\theaderBytes: headerBytes,\n\t\t\t},\n\t\t},\n\t}\n\n\tdefer func() {\n\t\tif e := recover(); e != nil {\n\t\t\tapi.LogErrorf(\"go side: golang http-tcp bridge: onUpstreamData: panic serving: %v\\n%s\", e, debug.Stack())\n\t\t\tstatus = uint64(api.HttpTcpBridgeEndStream)\n\t\t\tbuf.SetString(ErrorInfoForPanic)\n\t\t}\n\t}()\n\n\tstatus = uint64(filter.OnUpstreamData(header, buf, endStream == uint64(api.EndStream)))\n\tif status == uint64(api.HttpTcpBridgeStopAndBuffer) && endStream == uint64(api.EndStream) {\n\t\tpanic(\"onUpstreamData: HttpTcpBridgeStopAndBuffer is not allowed when endStream is true\")\n\t}\n\n\treturn\n}\n\n//export envoyGoHttpTcpBridgeOnDestroy\nfunc envoyGoHttpTcpBridgeOnDestroy(r *C.httpRequest) {\n\treq := getRequest(r)\n\t// do nothing even when get panic, since filter is already destroying.\n\tdefer func() {\n\t\tif e := recover(); e != nil {\n\t\t\tbuf := debug.Stack()\n\t\t\tapi.LogErrorf(\"go side: golang http-tcp bridge: httpRequest: panic serving: %v\\n%s\", e, buf)\n\t\t}\n\t}()\n\n\tf := req.httpTcpBridge\n\tf.OnDestroy()\n\n\treq.httpTcpBridge = nil\n\n\tRequests.DeleteReq(r)\n}",
    "repo": "envoyproxy/envoy",
    "path": "./datasets/diagrams-repos/envoyproxy/envoy/contrib/golang/upstreams/http/tcp/source/go/pkg/upstreams/http/tcp/shim.go",
    "query": "Explain the process of configuring and attaching filters to HTTP requests based on plugin names and config IDs.",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'createRequest', 'node_id': 'createRequest', 'description': 'Creates a new HTTP request with attached filter based on plugin name and config ID', 'visibility': 'private', 'return_type': '*httpRequest', 'params': 'r *C.httpRequest', 'source_class_id': None}, {'type': 'function', 'name': 'getHttpTcpBridgeFactoryAndConfig', 'node_id': 'getHttpTcpBridgeFactoryAndConfig', 'description': 'Retrieves filter factory and configuration based on plugin name and config ID', 'visibility': 'private', 'return_type': '(filterFactory, config)', 'params': 'pluginName string, configId uint64', 'source_class_id': None}, {'type': 'entity', 'name': 'httpTcpBridge', 'node_id': 'httpTcpBridge', 'description': 'Filter interface for HTTP/TCP processing', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'createRequest', 'node_id_to': 'getHttpTcpBridgeFactoryAndConfig', 'description': 'Gets filter factory and config'}, {'node_id_from': 'createRequest', 'node_id_to': 'httpTcpBridge', 'description': 'Creates and attaches filter'}], 'packages': [{'package_id': 'filterConfiguration', 'children': ['createRequest', 'getHttpTcpBridgeFactoryAndConfig', 'httpTcpBridge'], 'description': 'Core filter configuration components'}]}",
    "version": "minimal",
    "text_answer": "The process starts with createRequest function that obtains filter factory and configuration based on plugin name and config ID, then creates and attaches the appropriate HTTP/TCP bridge filter to the request. The request is stored in a synchronized map for lifecycle management.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Go",
    "code": "\npackage tcp\n\n/*\n // ref https://github.com/golang/go/issues/25832\n\n #cgo CFLAGS: -I../../../../../../../../../../../common/go/api -I../api\n #cgo linux LDFLAGS: -Wl,-unresolved-symbols=ignore-all\n #cgo darwin LDFLAGS: -Wl,-undefined,dynamic_lookup\n\n #include <stdlib.h>\n #include <string.h>\n\n #include \"api.h\"\n*/\nimport \"C\"\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"runtime/debug\"\n\t\"sync\"\n\n\t\"github.com/envoyproxy/envoy/contrib/golang/common/go/api\"\n)\n\nvar (\n\tErrDupRequestKey = errors.New(\"dup request key\")\n\n\tErrorInfoForPanic = \"error happened in golang http-tcp bridge\\r\\n\"\n)\n\nvar Requests = &requestMap{}\n\ntype requestMap struct {\n\trequests sync.Map // *C.httpRequest -> *httpRequest\n}\n\nfunc (f *requestMap) StoreReq(key *C.httpRequest, req *httpRequest) error {\n\tif _, loaded := f.requests.LoadOrStore(key, req); loaded {\n\t\treturn ErrDupRequestKey\n\t}\n\treturn nil\n}\n\n// TODO(duxin40): introduce the worker_id as PR#31987 to improve the performance when there are large envoy workers.\nfunc (f *requestMap) GetReq(key *C.httpRequest) *httpRequest {\n\tif v, ok := f.requests.Load(key); ok {\n\t\treturn v.(*httpRequest)\n\t}\n\treturn nil\n}\n\nfunc (f *requestMap) DeleteReq(key *C.httpRequest) {\n\tf.requests.Delete(key)\n}\n\nfunc (f *requestMap) Clear() {\n\tf.requests.Range(func(key, _ interface{}) bool {\n\t\tf.requests.Delete(key)\n\t\treturn true\n\t})\n}\n\nfunc getOrCreateState(s *C.processState) *processState {\n\tr := s.req\n\treq := getRequest(r)\n\tif req == nil {\n\t\treq = createRequest(r)\n\t}\n\tif s.is_encoding == 0 {\n\t\tif req.decodingState.processState == nil {\n\t\t\treq.decodingState.processState = s\n\t\t}\n\t\treturn &req.decodingState\n\t}\n\n\tif req.encodingState.processState == nil {\n\t\treq.encodingState.processState = s\n\t}\n\treturn &req.encodingState\n}\n\nfunc createRequest(r *C.httpRequest) *httpRequest {\n\treq := &httpRequest{\n\t\treq: r,\n\t}\n\treq.decodingState.request = req\n\treq.encodingState.request = req\n\n\terr := Requests.StoreReq(r, req)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"createRequest failed, err: %s\", err.Error()))\n\t}\n\n\tconfigId := uint64(r.configId)\n\n\tfilterFactory, config := getHttpTcpBridgeFactoryAndConfig(req.pluginName(), configId)\n\tf := filterFactory(config, req)\n\treq.httpTcpBridge = f\n\n\treturn req\n}\n\nfunc getRequest(r *C.httpRequest) *httpRequest {\n\treturn Requests.GetReq(r)\n}\n\n//export envoyGoHttpTcpBridgeOnEncodeHeader\nfunc envoyGoHttpTcpBridgeOnEncodeHeader(s *C.processState, endStream, headerNum, headerBytes, buffer, length uint64) (status uint64) {\n\tstate := getOrCreateState(s)\n\treq := state.request\n\tbuf := &httpBuffer{\n\t\tstate:               state,\n\t\tenvoyBufferInstance: buffer,\n\t\tlength:              length,\n\t}\n\n\tfilter := req.httpTcpBridge\n\theader := &requestHeaderMapImpl{\n\t\trequestOrResponseHeaderMapImpl{\n\t\t\theaderMapImpl{\n\t\t\t\tstate:       state,\n\t\t\t\theaderNum:   headerNum,\n\t\t\t\theaderBytes: headerBytes,\n\t\t\t},\n\t\t},\n\t}\n\n\tdefer func() {\n\t\tif e := recover(); e != nil {\n\t\t\tapi.LogErrorf(\"go side: golang http-tcp bridge: encodeHeader: panic serving: %v\\n%s\", e, debug.Stack())\n\t\t\tstatus = uint64(api.HttpTcpBridgeEndStream)\n\t\t\tbuf.SetString(ErrorInfoForPanic)\n\t\t}\n\t}()\n\n\treturn uint64(filter.EncodeHeaders(header, buf, endStream == uint64(api.EndStream)))\n}\n\n//export envoyGoHttpTcpBridgeOnEncodeData\nfunc envoyGoHttpTcpBridgeOnEncodeData(s *C.processState, endStream, buffer, length uint64) (status uint64) {\n\tstate := getOrCreateState(s)\n\treq := state.request\n\tbuf := &httpBuffer{\n\t\tstate:               state,\n\t\tenvoyBufferInstance: buffer,\n\t\tlength:              length,\n\t}\n\n\tfilter := req.httpTcpBridge\n\n\tdefer func() {\n\t\tif e := recover(); e != nil {\n\t\t\tapi.LogErrorf(\"go side: golang http-tcp bridge: encodeData: panic serving: %v\\n%s\", e, debug.Stack())\n\t\t\tstatus = uint64(api.HttpTcpBridgeEndStream)\n\t\t\tbuf.SetString(ErrorInfoForPanic)\n\t\t}\n\t}()\n\n\tstatus = uint64(filter.EncodeData(buf, endStream == uint64(api.EndStream)))\n\tif status == uint64(api.HttpTcpBridgeStopAndBuffer) && endStream == uint64(api.EndStream) {\n\t\tpanic(\"encodeData: HttpTcpBridgeStopAndBuffer is not allowed when endStream is true\")\n\t}\n\n\treturn\n}\n\n//export envoyGoHttpTcpBridgeOnUpstreamData\nfunc envoyGoHttpTcpBridgeOnUpstreamData(s *C.processState, endStream, headerNum, headerBytes, buffer, length uint64) (status uint64) {\n\n\tstate := getOrCreateState(s)\n\treq := state.request\n\tbuf := &httpBuffer{\n\t\tstate:               state,\n\t\tenvoyBufferInstance: buffer,\n\t\tlength:              length,\n\t}\n\n\tfilter := req.httpTcpBridge\n\theader := &responseHeaderMapImpl{\n\t\trequestOrResponseHeaderMapImpl{\n\t\t\theaderMapImpl{\n\t\t\t\tstate:       state,\n\t\t\t\theaderNum:   headerNum,\n\t\t\t\theaderBytes: headerBytes,\n\t\t\t},\n\t\t},\n\t}\n\n\tdefer func() {\n\t\tif e := recover(); e != nil {\n\t\t\tapi.LogErrorf(\"go side: golang http-tcp bridge: onUpstreamData: panic serving: %v\\n%s\", e, debug.Stack())\n\t\t\tstatus = uint64(api.HttpTcpBridgeEndStream)\n\t\t\tbuf.SetString(ErrorInfoForPanic)\n\t\t}\n\t}()\n\n\tstatus = uint64(filter.OnUpstreamData(header, buf, endStream == uint64(api.EndStream)))\n\tif status == uint64(api.HttpTcpBridgeStopAndBuffer) && endStream == uint64(api.EndStream) {\n\t\tpanic(\"onUpstreamData: HttpTcpBridgeStopAndBuffer is not allowed when endStream is true\")\n\t}\n\n\treturn\n}\n\n//export envoyGoHttpTcpBridgeOnDestroy\nfunc envoyGoHttpTcpBridgeOnDestroy(r *C.httpRequest) {\n\treq := getRequest(r)\n\t// do nothing even when get panic, since filter is already destroying.\n\tdefer func() {\n\t\tif e := recover(); e != nil {\n\t\t\tbuf := debug.Stack()\n\t\t\tapi.LogErrorf(\"go side: golang http-tcp bridge: httpRequest: panic serving: %v\\n%s\", e, buf)\n\t\t}\n\t}()\n\n\tf := req.httpTcpBridge\n\tf.OnDestroy()\n\n\treq.httpTcpBridge = nil\n\n\tRequests.DeleteReq(r)\n}",
    "repo": "envoyproxy/envoy",
    "path": "./datasets/diagrams-repos/envoyproxy/envoy/contrib/golang/upstreams/http/tcp/source/go/pkg/upstreams/http/tcp/shim.go",
    "query": "Explain the process of configuring and attaching filters to HTTP requests based on plugin names and config IDs.",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'createRequest', 'node_id': 'createRequest', 'description': 'Creates a new HTTP request with attached filter based on plugin name and config ID', 'visibility': 'private', 'return_type': '*httpRequest', 'params': 'r *C.httpRequest', 'source_class_id': None}, {'type': 'function', 'name': 'getHttpTcpBridgeFactoryAndConfig', 'node_id': 'getHttpTcpBridgeFactoryAndConfig', 'description': 'Retrieves filter factory and configuration based on plugin name and config ID', 'visibility': 'private', 'return_type': '(filterFactory, config)', 'params': 'pluginName string, configId uint64', 'source_class_id': None}, {'type': 'entity', 'name': 'httpTcpBridge', 'node_id': 'httpTcpBridge', 'description': 'Filter interface for HTTP/TCP processing', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'requestMap', 'node_id': 'requestMap', 'description': 'Manages HTTP request storage and retrieval', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'StoreReq', 'node_id': 'StoreReq', 'description': 'Stores HTTP request in request map', 'visibility': 'public', 'return_type': 'error', 'params': 'key *C.httpRequest, req *httpRequest', 'source_class_id': 'requestMap'}], 'edges': [{'node_id_from': 'createRequest', 'node_id_to': 'getHttpTcpBridgeFactoryAndConfig', 'description': 'Gets filter factory and config'}, {'node_id_from': 'createRequest', 'node_id_to': 'httpTcpBridge', 'description': 'Creates and attaches filter'}, {'node_id_from': 'createRequest', 'node_id_to': 'StoreReq', 'description': 'Stores created request'}, {'node_id_from': 'requestMap', 'node_id_to': 'StoreReq', 'description': ''}], 'packages': [{'package_id': 'filterConfiguration', 'children': ['createRequest', 'getHttpTcpBridgeFactoryAndConfig', 'httpTcpBridge'], 'description': 'Core filter configuration components'}, {'package_id': 'requestManagement', 'children': ['requestMap', 'StoreReq'], 'description': 'Request storage and management'}]}",
    "version": "medium",
    "text_answer": "The process starts with createRequest function that obtains filter factory and configuration based on plugin name and config ID, then creates and attaches the appropriate HTTP/TCP bridge filter to the request. The request is stored in a synchronized map for lifecycle management.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Go",
    "code": "\npackage tcp\n\n/*\n // ref https://github.com/golang/go/issues/25832\n\n #cgo CFLAGS: -I../../../../../../../../../../../common/go/api -I../api\n #cgo linux LDFLAGS: -Wl,-unresolved-symbols=ignore-all\n #cgo darwin LDFLAGS: -Wl,-undefined,dynamic_lookup\n\n #include <stdlib.h>\n #include <string.h>\n\n #include \"api.h\"\n*/\nimport \"C\"\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"runtime/debug\"\n\t\"sync\"\n\n\t\"github.com/envoyproxy/envoy/contrib/golang/common/go/api\"\n)\n\nvar (\n\tErrDupRequestKey = errors.New(\"dup request key\")\n\n\tErrorInfoForPanic = \"error happened in golang http-tcp bridge\\r\\n\"\n)\n\nvar Requests = &requestMap{}\n\ntype requestMap struct {\n\trequests sync.Map // *C.httpRequest -> *httpRequest\n}\n\nfunc (f *requestMap) StoreReq(key *C.httpRequest, req *httpRequest) error {\n\tif _, loaded := f.requests.LoadOrStore(key, req); loaded {\n\t\treturn ErrDupRequestKey\n\t}\n\treturn nil\n}\n\n// TODO(duxin40): introduce the worker_id as PR#31987 to improve the performance when there are large envoy workers.\nfunc (f *requestMap) GetReq(key *C.httpRequest) *httpRequest {\n\tif v, ok := f.requests.Load(key); ok {\n\t\treturn v.(*httpRequest)\n\t}\n\treturn nil\n}\n\nfunc (f *requestMap) DeleteReq(key *C.httpRequest) {\n\tf.requests.Delete(key)\n}\n\nfunc (f *requestMap) Clear() {\n\tf.requests.Range(func(key, _ interface{}) bool {\n\t\tf.requests.Delete(key)\n\t\treturn true\n\t})\n}\n\nfunc getOrCreateState(s *C.processState) *processState {\n\tr := s.req\n\treq := getRequest(r)\n\tif req == nil {\n\t\treq = createRequest(r)\n\t}\n\tif s.is_encoding == 0 {\n\t\tif req.decodingState.processState == nil {\n\t\t\treq.decodingState.processState = s\n\t\t}\n\t\treturn &req.decodingState\n\t}\n\n\tif req.encodingState.processState == nil {\n\t\treq.encodingState.processState = s\n\t}\n\treturn &req.encodingState\n}\n\nfunc createRequest(r *C.httpRequest) *httpRequest {\n\treq := &httpRequest{\n\t\treq: r,\n\t}\n\treq.decodingState.request = req\n\treq.encodingState.request = req\n\n\terr := Requests.StoreReq(r, req)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"createRequest failed, err: %s\", err.Error()))\n\t}\n\n\tconfigId := uint64(r.configId)\n\n\tfilterFactory, config := getHttpTcpBridgeFactoryAndConfig(req.pluginName(), configId)\n\tf := filterFactory(config, req)\n\treq.httpTcpBridge = f\n\n\treturn req\n}\n\nfunc getRequest(r *C.httpRequest) *httpRequest {\n\treturn Requests.GetReq(r)\n}\n\n//export envoyGoHttpTcpBridgeOnEncodeHeader\nfunc envoyGoHttpTcpBridgeOnEncodeHeader(s *C.processState, endStream, headerNum, headerBytes, buffer, length uint64) (status uint64) {\n\tstate := getOrCreateState(s)\n\treq := state.request\n\tbuf := &httpBuffer{\n\t\tstate:               state,\n\t\tenvoyBufferInstance: buffer,\n\t\tlength:              length,\n\t}\n\n\tfilter := req.httpTcpBridge\n\theader := &requestHeaderMapImpl{\n\t\trequestOrResponseHeaderMapImpl{\n\t\t\theaderMapImpl{\n\t\t\t\tstate:       state,\n\t\t\t\theaderNum:   headerNum,\n\t\t\t\theaderBytes: headerBytes,\n\t\t\t},\n\t\t},\n\t}\n\n\tdefer func() {\n\t\tif e := recover(); e != nil {\n\t\t\tapi.LogErrorf(\"go side: golang http-tcp bridge: encodeHeader: panic serving: %v\\n%s\", e, debug.Stack())\n\t\t\tstatus = uint64(api.HttpTcpBridgeEndStream)\n\t\t\tbuf.SetString(ErrorInfoForPanic)\n\t\t}\n\t}()\n\n\treturn uint64(filter.EncodeHeaders(header, buf, endStream == uint64(api.EndStream)))\n}\n\n//export envoyGoHttpTcpBridgeOnEncodeData\nfunc envoyGoHttpTcpBridgeOnEncodeData(s *C.processState, endStream, buffer, length uint64) (status uint64) {\n\tstate := getOrCreateState(s)\n\treq := state.request\n\tbuf := &httpBuffer{\n\t\tstate:               state,\n\t\tenvoyBufferInstance: buffer,\n\t\tlength:              length,\n\t}\n\n\tfilter := req.httpTcpBridge\n\n\tdefer func() {\n\t\tif e := recover(); e != nil {\n\t\t\tapi.LogErrorf(\"go side: golang http-tcp bridge: encodeData: panic serving: %v\\n%s\", e, debug.Stack())\n\t\t\tstatus = uint64(api.HttpTcpBridgeEndStream)\n\t\t\tbuf.SetString(ErrorInfoForPanic)\n\t\t}\n\t}()\n\n\tstatus = uint64(filter.EncodeData(buf, endStream == uint64(api.EndStream)))\n\tif status == uint64(api.HttpTcpBridgeStopAndBuffer) && endStream == uint64(api.EndStream) {\n\t\tpanic(\"encodeData: HttpTcpBridgeStopAndBuffer is not allowed when endStream is true\")\n\t}\n\n\treturn\n}\n\n//export envoyGoHttpTcpBridgeOnUpstreamData\nfunc envoyGoHttpTcpBridgeOnUpstreamData(s *C.processState, endStream, headerNum, headerBytes, buffer, length uint64) (status uint64) {\n\n\tstate := getOrCreateState(s)\n\treq := state.request\n\tbuf := &httpBuffer{\n\t\tstate:               state,\n\t\tenvoyBufferInstance: buffer,\n\t\tlength:              length,\n\t}\n\n\tfilter := req.httpTcpBridge\n\theader := &responseHeaderMapImpl{\n\t\trequestOrResponseHeaderMapImpl{\n\t\t\theaderMapImpl{\n\t\t\t\tstate:       state,\n\t\t\t\theaderNum:   headerNum,\n\t\t\t\theaderBytes: headerBytes,\n\t\t\t},\n\t\t},\n\t}\n\n\tdefer func() {\n\t\tif e := recover(); e != nil {\n\t\t\tapi.LogErrorf(\"go side: golang http-tcp bridge: onUpstreamData: panic serving: %v\\n%s\", e, debug.Stack())\n\t\t\tstatus = uint64(api.HttpTcpBridgeEndStream)\n\t\t\tbuf.SetString(ErrorInfoForPanic)\n\t\t}\n\t}()\n\n\tstatus = uint64(filter.OnUpstreamData(header, buf, endStream == uint64(api.EndStream)))\n\tif status == uint64(api.HttpTcpBridgeStopAndBuffer) && endStream == uint64(api.EndStream) {\n\t\tpanic(\"onUpstreamData: HttpTcpBridgeStopAndBuffer is not allowed when endStream is true\")\n\t}\n\n\treturn\n}\n\n//export envoyGoHttpTcpBridgeOnDestroy\nfunc envoyGoHttpTcpBridgeOnDestroy(r *C.httpRequest) {\n\treq := getRequest(r)\n\t// do nothing even when get panic, since filter is already destroying.\n\tdefer func() {\n\t\tif e := recover(); e != nil {\n\t\t\tbuf := debug.Stack()\n\t\t\tapi.LogErrorf(\"go side: golang http-tcp bridge: httpRequest: panic serving: %v\\n%s\", e, buf)\n\t\t}\n\t}()\n\n\tf := req.httpTcpBridge\n\tf.OnDestroy()\n\n\treq.httpTcpBridge = nil\n\n\tRequests.DeleteReq(r)\n}",
    "repo": "envoyproxy/envoy",
    "path": "./datasets/diagrams-repos/envoyproxy/envoy/contrib/golang/upstreams/http/tcp/source/go/pkg/upstreams/http/tcp/shim.go",
    "query": "Explain the process of configuring and attaching filters to HTTP requests based on plugin names and config IDs.",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'createRequest', 'node_id': 'createRequest', 'description': 'Creates a new HTTP request with attached filter based on plugin name and config ID', 'visibility': 'private', 'return_type': '*httpRequest', 'params': 'r *C.httpRequest', 'source_class_id': None}, {'type': 'function', 'name': 'getHttpTcpBridgeFactoryAndConfig', 'node_id': 'getHttpTcpBridgeFactoryAndConfig', 'description': 'Retrieves filter factory and configuration based on plugin name and config ID', 'visibility': 'private', 'return_type': '(filterFactory, config)', 'params': 'pluginName string, configId uint64', 'source_class_id': None}, {'type': 'entity', 'name': 'httpTcpBridge', 'node_id': 'httpTcpBridge', 'description': 'Filter interface for HTTP/TCP processing', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'requestMap', 'node_id': 'requestMap', 'description': 'Manages HTTP request storage and retrieval', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'StoreReq', 'node_id': 'StoreReq', 'description': 'Stores HTTP request in request map', 'visibility': 'public', 'return_type': 'error', 'params': 'key *C.httpRequest, req *httpRequest', 'source_class_id': 'requestMap'}, {'type': 'method', 'name': 'GetReq', 'node_id': 'GetReq', 'description': 'Retrieves HTTP request from request map', 'visibility': 'public', 'return_type': '*httpRequest', 'params': 'key *C.httpRequest', 'source_class_id': 'requestMap'}, {'type': 'method', 'name': 'DeleteReq', 'node_id': 'DeleteReq', 'description': 'Removes HTTP request from request map', 'visibility': 'public', 'return_type': 'void', 'params': 'key *C.httpRequest', 'source_class_id': 'requestMap'}, {'type': 'function', 'name': 'getOrCreateState', 'node_id': 'getOrCreateState', 'description': 'Gets or creates process state for request', 'visibility': 'private', 'return_type': '*processState', 'params': 's *C.processState', 'source_class_id': None}, {'type': 'function', 'name': 'envoyGoHttpTcpBridgeOnDestroy', 'node_id': 'envoyGoHttpTcpBridgeOnDestroy', 'description': 'Cleanup handler for HTTP request destruction', 'visibility': 'public', 'return_type': 'void', 'params': 'r *C.httpRequest', 'source_class_id': None}], 'edges': [{'node_id_from': 'createRequest', 'node_id_to': 'getHttpTcpBridgeFactoryAndConfig', 'description': 'Gets filter factory and config'}, {'node_id_from': 'createRequest', 'node_id_to': 'httpTcpBridge', 'description': 'Creates and attaches filter'}, {'node_id_from': 'createRequest', 'node_id_to': 'StoreReq', 'description': 'Stores created request'}, {'node_id_from': 'getOrCreateState', 'node_id_to': 'GetReq', 'description': 'Retrieves existing request'}, {'node_id_from': 'getOrCreateState', 'node_id_to': 'createRequest', 'description': 'Creates new request if not exists'}, {'node_id_from': 'envoyGoHttpTcpBridgeOnDestroy', 'node_id_to': 'GetReq', 'description': 'Gets request for cleanup'}, {'node_id_from': 'envoyGoHttpTcpBridgeOnDestroy', 'node_id_to': 'DeleteReq', 'description': 'Removes request after cleanup'}, {'node_id_from': 'requestMap', 'node_id_to': 'StoreReq', 'description': ''}, {'node_id_from': 'requestMap', 'node_id_to': 'GetReq', 'description': ''}, {'node_id_from': 'requestMap', 'node_id_to': 'DeleteReq', 'description': ''}], 'packages': [{'package_id': 'filterConfiguration', 'children': ['createRequest', 'getHttpTcpBridgeFactoryAndConfig', 'httpTcpBridge'], 'description': 'Core filter configuration components'}, {'package_id': 'requestManagement', 'children': ['requestMap', 'StoreReq', 'GetReq', 'DeleteReq'], 'description': 'Request storage and management'}, {'package_id': 'lifecycle', 'children': ['getOrCreateState', 'envoyGoHttpTcpBridgeOnDestroy'], 'description': 'Request lifecycle management'}]}",
    "version": "full",
    "text_answer": "The process starts with createRequest function that obtains filter factory and configuration based on plugin name and config ID, then creates and attaches the appropriate HTTP/TCP bridge filter to the request. The request is stored in a synchronized map for lifecycle management.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Python",
    "code": "\nimport unittest, sys\n\nfrom ctypes import *\nimport _ctypes_test\n\nctype_types = [c_byte, c_ubyte, c_short, c_ushort, c_int, c_uint,\n                 c_long, c_ulong, c_longlong, c_ulonglong, c_double, c_float]\npython_types = [int, int, int, int, int, int,\n                int, int, int, int, float, float]\n\nclass PointersTestCase(unittest.TestCase):\n\n    def test_pointer_crash(self):\n\n        class A(POINTER(c_ulong)):\n            pass\n\n        POINTER(c_ulong)(c_ulong(22))\n        # Pointer can't set contents: has no _type_\n        self.assertRaises(TypeError, A, c_ulong(33))\n\n    def test_pass_pointers(self):\n        dll = CDLL(_ctypes_test.__file__)\n        func = dll._testfunc_p_p\n        if sizeof(c_longlong) == sizeof(c_void_p):\n            func.restype = c_longlong\n        else:\n            func.restype = c_long\n\n        i = c_int(12345678)\n##        func.argtypes = (POINTER(c_int),)\n        address = func(byref(i))\n        self.assertEqual(c_int.from_address(address).value, 12345678)\n\n        func.restype = POINTER(c_int)\n        res = func(pointer(i))\n        self.assertEqual(res.contents.value, 12345678)\n        self.assertEqual(res[0], 12345678)\n\n    def test_change_pointers(self):\n        dll = CDLL(_ctypes_test.__file__)\n        func = dll._testfunc_p_p\n\n        i = c_int(87654)\n        func.restype = POINTER(c_int)\n        func.argtypes = (POINTER(c_int),)\n\n        res = func(pointer(i))\n        self.assertEqual(res[0], 87654)\n        self.assertEqual(res.contents.value, 87654)\n\n        # C code: *res = 54345\n        res[0] = 54345\n        self.assertEqual(i.value, 54345)\n\n        # C code:\n        #   int x = 12321;\n        #   res = &x\n        x = c_int(12321)\n        res.contents = x\n        self.assertEqual(i.value, 54345)\n\n        x.value = -99\n        self.assertEqual(res.contents.value, -99)\n\n    def test_callbacks_with_pointers(self):\n        # a function type receiving a pointer\n        PROTOTYPE = CFUNCTYPE(c_int, POINTER(c_int))\n\n        self.result = []\n\n        def func(arg):\n            for i in range(10):\n##                print arg[i],\n                self.result.append(arg[i])\n##            print\n            return 0\n        callback = PROTOTYPE(func)\n\n        dll = CDLL(_ctypes_test.__file__)\n        # This function expects a function pointer,\n        # and calls this with an integer pointer as parameter.\n        # The int pointer points to a table containing the numbers 1..10\n        doit = dll._testfunc_callback_with_pointer\n\n##        i = c_int(42)\n##        callback(byref(i))\n##        self.assertEqual(i.value, 84)\n\n        doit(callback)\n##        print self.result\n        doit(callback)\n##        print self.result\n\n    def test_basics(self):\n        from operator import delitem\n        for ct, pt in zip(ctype_types, python_types):\n            i = ct(42)\n            p = pointer(i)\n##            print type(p.contents), ct\n            self.assertIs(type(p.contents), ct)\n            # p.contents is the same as p[0]\n##            print p.contents\n##            self.assertEqual(p.contents, 42)\n##            self.assertEqual(p[0], 42)\n\n            self.assertRaises(TypeError, delitem, p, 0)\n\n    def test_from_address(self):\n        from array import array\n        a = array('i', [100, 200, 300, 400, 500])\n        addr = a.buffer_info()[0]\n\n        p = POINTER(POINTER(c_int))\n##        print dir(p)\n##        print p.from_address\n##        print p.from_address(addr)[0][0]\n\n    def test_other(self):\n        class Table(Structure):\n            _fields_ = [(\"a\", c_int),\n                        (\"b\", c_int),\n                        (\"c\", c_int)]\n\n        pt = pointer(Table(1, 2, 3))\n\n        self.assertEqual(pt.contents.a, 1)\n        self.assertEqual(pt.contents.b, 2)\n        self.assertEqual(pt.contents.c, 3)\n\n        pt.contents.c = 33\n\n        from ctypes import _pointer_type_cache\n        del _pointer_type_cache[Table]\n\n    def test_basic(self):\n        p = pointer(c_int(42))\n        # Although a pointer can be indexed, it has no length\n        self.assertRaises(TypeError, len, p)\n        self.assertEqual(p[0], 42)\n        self.assertEqual(p[0:1], [42])\n        self.assertEqual(p.contents.value, 42)\n\n    def test_charpp(self):\n        \"\"\"Test that a character pointer-to-pointer is correctly passed\"\"\"\n        dll = CDLL(_ctypes_test.__file__)\n        func = dll._testfunc_c_p_p\n        func.restype = c_char_p\n        argv = (c_char_p * 2)()\n        argc = c_int( 2 )\n        argv[0] = b'hello'\n        argv[1] = b'world'\n        result = func( byref(argc), argv )\n        self.assertEqual(result, b'world')\n\n    def test_bug_1467852(self):\n        # http://sourceforge.net/tracker/?func=detail&atid=532154&aid=1467852&group_id=71702\n        x = c_int(5)\n        dummy = []\n        for i in range(32000):\n            dummy.append(c_int(i))\n        y = c_int(6)\n        p = pointer(x)\n        pp = pointer(p)\n        q = pointer(y)\n        pp[0] = q         # <==\n        self.assertEqual(p[0], 6)\n    def test_c_void_p(self):\n        # http://sourceforge.net/tracker/?func=detail&aid=1518190&group_id=5470&atid=105470\n        if sizeof(c_void_p) == 4:\n            self.assertEqual(c_void_p(0xFFFFFFFF).value,\n                                 c_void_p(-1).value)\n            self.assertEqual(c_void_p(0xFFFFFFFFFFFFFFFF).value,\n                                 c_void_p(-1).value)\n        elif sizeof(c_void_p) == 8:\n            self.assertEqual(c_void_p(0xFFFFFFFF).value,\n                                 0xFFFFFFFF)\n            self.assertEqual(c_void_p(0xFFFFFFFFFFFFFFFF).value,\n                                 c_void_p(-1).value)\n            self.assertEqual(c_void_p(0xFFFFFFFFFFFFFFFFFFFFFFFF).value,\n                                 c_void_p(-1).value)\n\n        self.assertRaises(TypeError, c_void_p, 3.14) # make sure floats are NOT accepted\n        self.assertRaises(TypeError, c_void_p, object()) # nor other objects\n\n    def test_pointers_bool(self):\n        # NULL pointers have a boolean False value, non-NULL pointers True.\n        self.assertEqual(bool(POINTER(c_int)()), False)\n        self.assertEqual(bool(pointer(c_int())), True)\n\n        self.assertEqual(bool(CFUNCTYPE(None)(0)), False)\n        self.assertEqual(bool(CFUNCTYPE(None)(42)), True)\n\n        # COM methods are boolean True:\n        if sys.platform == \"win32\":\n            mth = WINFUNCTYPE(None)(42, \"name\", (), None)\n            self.assertEqual(bool(mth), True)\n\n    def test_pointer_type_name(self):\n        LargeNamedType = type('T' * 2 ** 25, (Structure,), {})\n        self.assertTrue(POINTER(LargeNamedType))\n\n        # to not leak references, we must clean _pointer_type_cache\n        from ctypes import _pointer_type_cache\n        del _pointer_type_cache[LargeNamedType]\n\n    def test_pointer_type_str_name(self):\n        large_string = 'T' * 2 ** 25\n        P = POINTER(large_string)\n        self.assertTrue(P)\n\n        # to not leak references, we must clean _pointer_type_cache\n        from ctypes import _pointer_type_cache\n        del _pointer_type_cache[id(P)]\n\n    def test_abstract(self):\n        from ctypes import _Pointer\n\n        self.assertRaises(TypeError, _Pointer.set_type, 42)\n\n\nif __name__ == '__main__':\n    unittest.main()",
    "repo": "RustPython/RustPython",
    "path": "./datasets/diagrams-repos/RustPython/RustPython/Lib/ctypes/test/test_pointers.py",
    "query": "For the test_pass_pointers method, illustrate the steps involved in passing a pointer to a function, modifying the pointed value, and verifying the changes in the original variable.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'PointersTestCase', 'node_id': 'PointersTestCase', 'description': 'Test case class for pointer operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'test_pass_pointers', 'node_id': 'test_pass_pointers', 'description': 'Tests passing pointers between Python and C', 'visibility': 'public', 'return_type': 'None', 'params': 'self', 'source_class_id': 'PointersTestCase'}, {'type': 'function', 'name': '_testfunc_p_p', 'node_id': '_testfunc_p_p', 'description': 'C function that accepts and returns pointers', 'visibility': 'public', 'return_type': 'POINTER', 'params': 'POINTER', 'source_class_id': None}, {'type': 'variable', 'name': 'i', 'node_id': 'i', 'description': 'Integer value to be modified', 'visibility': 'private', 'return_type': 'c_int', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'test_pass_pointers', 'node_id_to': '_testfunc_p_p', 'description': 'calls with pointer'}, {'node_id_from': '_testfunc_p_p', 'node_id_to': 'i', 'description': 'modifies value'}, {'node_id_from': 'PointersTestCase', 'node_id_to': 'test_pass_pointers', 'description': ''}], 'packages': [{'package_id': 'pointerTest', 'children': ['PointersTestCase', 'test_pass_pointers', '_testfunc_p_p', 'i'], 'description': 'Pointer manipulation test components'}]}",
    "version": "minimal",
    "text_answer": "The test_pass_pointers method demonstrates pointer passing between Python and C by creating an integer value, passing its pointer to a C function, and verifying the modifications. It uses both byref and pointer functions to create references, calls the C function _testfunc_p_p, and checks the results using direct pointer access and from_address method.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Python",
    "code": "\nimport unittest, sys\n\nfrom ctypes import *\nimport _ctypes_test\n\nctype_types = [c_byte, c_ubyte, c_short, c_ushort, c_int, c_uint,\n                 c_long, c_ulong, c_longlong, c_ulonglong, c_double, c_float]\npython_types = [int, int, int, int, int, int,\n                int, int, int, int, float, float]\n\nclass PointersTestCase(unittest.TestCase):\n\n    def test_pointer_crash(self):\n\n        class A(POINTER(c_ulong)):\n            pass\n\n        POINTER(c_ulong)(c_ulong(22))\n        # Pointer can't set contents: has no _type_\n        self.assertRaises(TypeError, A, c_ulong(33))\n\n    def test_pass_pointers(self):\n        dll = CDLL(_ctypes_test.__file__)\n        func = dll._testfunc_p_p\n        if sizeof(c_longlong) == sizeof(c_void_p):\n            func.restype = c_longlong\n        else:\n            func.restype = c_long\n\n        i = c_int(12345678)\n##        func.argtypes = (POINTER(c_int),)\n        address = func(byref(i))\n        self.assertEqual(c_int.from_address(address).value, 12345678)\n\n        func.restype = POINTER(c_int)\n        res = func(pointer(i))\n        self.assertEqual(res.contents.value, 12345678)\n        self.assertEqual(res[0], 12345678)\n\n    def test_change_pointers(self):\n        dll = CDLL(_ctypes_test.__file__)\n        func = dll._testfunc_p_p\n\n        i = c_int(87654)\n        func.restype = POINTER(c_int)\n        func.argtypes = (POINTER(c_int),)\n\n        res = func(pointer(i))\n        self.assertEqual(res[0], 87654)\n        self.assertEqual(res.contents.value, 87654)\n\n        # C code: *res = 54345\n        res[0] = 54345\n        self.assertEqual(i.value, 54345)\n\n        # C code:\n        #   int x = 12321;\n        #   res = &x\n        x = c_int(12321)\n        res.contents = x\n        self.assertEqual(i.value, 54345)\n\n        x.value = -99\n        self.assertEqual(res.contents.value, -99)\n\n    def test_callbacks_with_pointers(self):\n        # a function type receiving a pointer\n        PROTOTYPE = CFUNCTYPE(c_int, POINTER(c_int))\n\n        self.result = []\n\n        def func(arg):\n            for i in range(10):\n##                print arg[i],\n                self.result.append(arg[i])\n##            print\n            return 0\n        callback = PROTOTYPE(func)\n\n        dll = CDLL(_ctypes_test.__file__)\n        # This function expects a function pointer,\n        # and calls this with an integer pointer as parameter.\n        # The int pointer points to a table containing the numbers 1..10\n        doit = dll._testfunc_callback_with_pointer\n\n##        i = c_int(42)\n##        callback(byref(i))\n##        self.assertEqual(i.value, 84)\n\n        doit(callback)\n##        print self.result\n        doit(callback)\n##        print self.result\n\n    def test_basics(self):\n        from operator import delitem\n        for ct, pt in zip(ctype_types, python_types):\n            i = ct(42)\n            p = pointer(i)\n##            print type(p.contents), ct\n            self.assertIs(type(p.contents), ct)\n            # p.contents is the same as p[0]\n##            print p.contents\n##            self.assertEqual(p.contents, 42)\n##            self.assertEqual(p[0], 42)\n\n            self.assertRaises(TypeError, delitem, p, 0)\n\n    def test_from_address(self):\n        from array import array\n        a = array('i', [100, 200, 300, 400, 500])\n        addr = a.buffer_info()[0]\n\n        p = POINTER(POINTER(c_int))\n##        print dir(p)\n##        print p.from_address\n##        print p.from_address(addr)[0][0]\n\n    def test_other(self):\n        class Table(Structure):\n            _fields_ = [(\"a\", c_int),\n                        (\"b\", c_int),\n                        (\"c\", c_int)]\n\n        pt = pointer(Table(1, 2, 3))\n\n        self.assertEqual(pt.contents.a, 1)\n        self.assertEqual(pt.contents.b, 2)\n        self.assertEqual(pt.contents.c, 3)\n\n        pt.contents.c = 33\n\n        from ctypes import _pointer_type_cache\n        del _pointer_type_cache[Table]\n\n    def test_basic(self):\n        p = pointer(c_int(42))\n        # Although a pointer can be indexed, it has no length\n        self.assertRaises(TypeError, len, p)\n        self.assertEqual(p[0], 42)\n        self.assertEqual(p[0:1], [42])\n        self.assertEqual(p.contents.value, 42)\n\n    def test_charpp(self):\n        \"\"\"Test that a character pointer-to-pointer is correctly passed\"\"\"\n        dll = CDLL(_ctypes_test.__file__)\n        func = dll._testfunc_c_p_p\n        func.restype = c_char_p\n        argv = (c_char_p * 2)()\n        argc = c_int( 2 )\n        argv[0] = b'hello'\n        argv[1] = b'world'\n        result = func( byref(argc), argv )\n        self.assertEqual(result, b'world')\n\n    def test_bug_1467852(self):\n        # http://sourceforge.net/tracker/?func=detail&atid=532154&aid=1467852&group_id=71702\n        x = c_int(5)\n        dummy = []\n        for i in range(32000):\n            dummy.append(c_int(i))\n        y = c_int(6)\n        p = pointer(x)\n        pp = pointer(p)\n        q = pointer(y)\n        pp[0] = q         # <==\n        self.assertEqual(p[0], 6)\n    def test_c_void_p(self):\n        # http://sourceforge.net/tracker/?func=detail&aid=1518190&group_id=5470&atid=105470\n        if sizeof(c_void_p) == 4:\n            self.assertEqual(c_void_p(0xFFFFFFFF).value,\n                                 c_void_p(-1).value)\n            self.assertEqual(c_void_p(0xFFFFFFFFFFFFFFFF).value,\n                                 c_void_p(-1).value)\n        elif sizeof(c_void_p) == 8:\n            self.assertEqual(c_void_p(0xFFFFFFFF).value,\n                                 0xFFFFFFFF)\n            self.assertEqual(c_void_p(0xFFFFFFFFFFFFFFFF).value,\n                                 c_void_p(-1).value)\n            self.assertEqual(c_void_p(0xFFFFFFFFFFFFFFFFFFFFFFFF).value,\n                                 c_void_p(-1).value)\n\n        self.assertRaises(TypeError, c_void_p, 3.14) # make sure floats are NOT accepted\n        self.assertRaises(TypeError, c_void_p, object()) # nor other objects\n\n    def test_pointers_bool(self):\n        # NULL pointers have a boolean False value, non-NULL pointers True.\n        self.assertEqual(bool(POINTER(c_int)()), False)\n        self.assertEqual(bool(pointer(c_int())), True)\n\n        self.assertEqual(bool(CFUNCTYPE(None)(0)), False)\n        self.assertEqual(bool(CFUNCTYPE(None)(42)), True)\n\n        # COM methods are boolean True:\n        if sys.platform == \"win32\":\n            mth = WINFUNCTYPE(None)(42, \"name\", (), None)\n            self.assertEqual(bool(mth), True)\n\n    def test_pointer_type_name(self):\n        LargeNamedType = type('T' * 2 ** 25, (Structure,), {})\n        self.assertTrue(POINTER(LargeNamedType))\n\n        # to not leak references, we must clean _pointer_type_cache\n        from ctypes import _pointer_type_cache\n        del _pointer_type_cache[LargeNamedType]\n\n    def test_pointer_type_str_name(self):\n        large_string = 'T' * 2 ** 25\n        P = POINTER(large_string)\n        self.assertTrue(P)\n\n        # to not leak references, we must clean _pointer_type_cache\n        from ctypes import _pointer_type_cache\n        del _pointer_type_cache[id(P)]\n\n    def test_abstract(self):\n        from ctypes import _Pointer\n\n        self.assertRaises(TypeError, _Pointer.set_type, 42)\n\n\nif __name__ == '__main__':\n    unittest.main()",
    "repo": "RustPython/RustPython",
    "path": "./datasets/diagrams-repos/RustPython/RustPython/Lib/ctypes/test/test_pointers.py",
    "query": "For the test_pass_pointers method, illustrate the steps involved in passing a pointer to a function, modifying the pointed value, and verifying the changes in the original variable.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'PointersTestCase', 'node_id': 'PointersTestCase', 'description': 'Test case class for pointer operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'test_pass_pointers', 'node_id': 'test_pass_pointers', 'description': 'Tests passing pointers between Python and C', 'visibility': 'public', 'return_type': 'None', 'params': 'self', 'source_class_id': 'PointersTestCase'}, {'type': 'function', 'name': '_testfunc_p_p', 'node_id': '_testfunc_p_p', 'description': 'C function that accepts and returns pointers', 'visibility': 'public', 'return_type': 'POINTER', 'params': 'POINTER', 'source_class_id': None}, {'type': 'variable', 'name': 'i', 'node_id': 'i', 'description': 'Integer value to be modified', 'visibility': 'private', 'return_type': 'c_int', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'byref', 'node_id': 'byref', 'description': 'Creates reference to variable', 'visibility': 'public', 'return_type': 'POINTER', 'params': 'obj', 'source_class_id': None}, {'type': 'function', 'name': 'pointer', 'node_id': 'pointer', 'description': 'Creates pointer to variable', 'visibility': 'public', 'return_type': 'POINTER', 'params': 'obj', 'source_class_id': None}], 'edges': [{'node_id_from': 'test_pass_pointers', 'node_id_to': 'byref', 'description': 'creates reference'}, {'node_id_from': 'test_pass_pointers', 'node_id_to': 'pointer', 'description': 'creates pointer'}, {'node_id_from': 'test_pass_pointers', 'node_id_to': '_testfunc_p_p', 'description': 'calls with pointer'}, {'node_id_from': '_testfunc_p_p', 'node_id_to': 'i', 'description': 'modifies value'}, {'node_id_from': 'PointersTestCase', 'node_id_to': 'test_pass_pointers', 'description': ''}], 'packages': [{'package_id': 'pointerTest', 'children': ['PointersTestCase', 'test_pass_pointers', '_testfunc_p_p', 'i', 'byref', 'pointer'], 'description': 'Pointer manipulation test components'}]}",
    "version": "medium",
    "text_answer": "The test_pass_pointers method demonstrates pointer passing between Python and C by creating an integer value, passing its pointer to a C function, and verifying the modifications. It uses both byref and pointer functions to create references, calls the C function _testfunc_p_p, and checks the results using direct pointer access and from_address method.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Python",
    "code": "\nimport unittest, sys\n\nfrom ctypes import *\nimport _ctypes_test\n\nctype_types = [c_byte, c_ubyte, c_short, c_ushort, c_int, c_uint,\n                 c_long, c_ulong, c_longlong, c_ulonglong, c_double, c_float]\npython_types = [int, int, int, int, int, int,\n                int, int, int, int, float, float]\n\nclass PointersTestCase(unittest.TestCase):\n\n    def test_pointer_crash(self):\n\n        class A(POINTER(c_ulong)):\n            pass\n\n        POINTER(c_ulong)(c_ulong(22))\n        # Pointer can't set contents: has no _type_\n        self.assertRaises(TypeError, A, c_ulong(33))\n\n    def test_pass_pointers(self):\n        dll = CDLL(_ctypes_test.__file__)\n        func = dll._testfunc_p_p\n        if sizeof(c_longlong) == sizeof(c_void_p):\n            func.restype = c_longlong\n        else:\n            func.restype = c_long\n\n        i = c_int(12345678)\n##        func.argtypes = (POINTER(c_int),)\n        address = func(byref(i))\n        self.assertEqual(c_int.from_address(address).value, 12345678)\n\n        func.restype = POINTER(c_int)\n        res = func(pointer(i))\n        self.assertEqual(res.contents.value, 12345678)\n        self.assertEqual(res[0], 12345678)\n\n    def test_change_pointers(self):\n        dll = CDLL(_ctypes_test.__file__)\n        func = dll._testfunc_p_p\n\n        i = c_int(87654)\n        func.restype = POINTER(c_int)\n        func.argtypes = (POINTER(c_int),)\n\n        res = func(pointer(i))\n        self.assertEqual(res[0], 87654)\n        self.assertEqual(res.contents.value, 87654)\n\n        # C code: *res = 54345\n        res[0] = 54345\n        self.assertEqual(i.value, 54345)\n\n        # C code:\n        #   int x = 12321;\n        #   res = &x\n        x = c_int(12321)\n        res.contents = x\n        self.assertEqual(i.value, 54345)\n\n        x.value = -99\n        self.assertEqual(res.contents.value, -99)\n\n    def test_callbacks_with_pointers(self):\n        # a function type receiving a pointer\n        PROTOTYPE = CFUNCTYPE(c_int, POINTER(c_int))\n\n        self.result = []\n\n        def func(arg):\n            for i in range(10):\n##                print arg[i],\n                self.result.append(arg[i])\n##            print\n            return 0\n        callback = PROTOTYPE(func)\n\n        dll = CDLL(_ctypes_test.__file__)\n        # This function expects a function pointer,\n        # and calls this with an integer pointer as parameter.\n        # The int pointer points to a table containing the numbers 1..10\n        doit = dll._testfunc_callback_with_pointer\n\n##        i = c_int(42)\n##        callback(byref(i))\n##        self.assertEqual(i.value, 84)\n\n        doit(callback)\n##        print self.result\n        doit(callback)\n##        print self.result\n\n    def test_basics(self):\n        from operator import delitem\n        for ct, pt in zip(ctype_types, python_types):\n            i = ct(42)\n            p = pointer(i)\n##            print type(p.contents), ct\n            self.assertIs(type(p.contents), ct)\n            # p.contents is the same as p[0]\n##            print p.contents\n##            self.assertEqual(p.contents, 42)\n##            self.assertEqual(p[0], 42)\n\n            self.assertRaises(TypeError, delitem, p, 0)\n\n    def test_from_address(self):\n        from array import array\n        a = array('i', [100, 200, 300, 400, 500])\n        addr = a.buffer_info()[0]\n\n        p = POINTER(POINTER(c_int))\n##        print dir(p)\n##        print p.from_address\n##        print p.from_address(addr)[0][0]\n\n    def test_other(self):\n        class Table(Structure):\n            _fields_ = [(\"a\", c_int),\n                        (\"b\", c_int),\n                        (\"c\", c_int)]\n\n        pt = pointer(Table(1, 2, 3))\n\n        self.assertEqual(pt.contents.a, 1)\n        self.assertEqual(pt.contents.b, 2)\n        self.assertEqual(pt.contents.c, 3)\n\n        pt.contents.c = 33\n\n        from ctypes import _pointer_type_cache\n        del _pointer_type_cache[Table]\n\n    def test_basic(self):\n        p = pointer(c_int(42))\n        # Although a pointer can be indexed, it has no length\n        self.assertRaises(TypeError, len, p)\n        self.assertEqual(p[0], 42)\n        self.assertEqual(p[0:1], [42])\n        self.assertEqual(p.contents.value, 42)\n\n    def test_charpp(self):\n        \"\"\"Test that a character pointer-to-pointer is correctly passed\"\"\"\n        dll = CDLL(_ctypes_test.__file__)\n        func = dll._testfunc_c_p_p\n        func.restype = c_char_p\n        argv = (c_char_p * 2)()\n        argc = c_int( 2 )\n        argv[0] = b'hello'\n        argv[1] = b'world'\n        result = func( byref(argc), argv )\n        self.assertEqual(result, b'world')\n\n    def test_bug_1467852(self):\n        # http://sourceforge.net/tracker/?func=detail&atid=532154&aid=1467852&group_id=71702\n        x = c_int(5)\n        dummy = []\n        for i in range(32000):\n            dummy.append(c_int(i))\n        y = c_int(6)\n        p = pointer(x)\n        pp = pointer(p)\n        q = pointer(y)\n        pp[0] = q         # <==\n        self.assertEqual(p[0], 6)\n    def test_c_void_p(self):\n        # http://sourceforge.net/tracker/?func=detail&aid=1518190&group_id=5470&atid=105470\n        if sizeof(c_void_p) == 4:\n            self.assertEqual(c_void_p(0xFFFFFFFF).value,\n                                 c_void_p(-1).value)\n            self.assertEqual(c_void_p(0xFFFFFFFFFFFFFFFF).value,\n                                 c_void_p(-1).value)\n        elif sizeof(c_void_p) == 8:\n            self.assertEqual(c_void_p(0xFFFFFFFF).value,\n                                 0xFFFFFFFF)\n            self.assertEqual(c_void_p(0xFFFFFFFFFFFFFFFF).value,\n                                 c_void_p(-1).value)\n            self.assertEqual(c_void_p(0xFFFFFFFFFFFFFFFFFFFFFFFF).value,\n                                 c_void_p(-1).value)\n\n        self.assertRaises(TypeError, c_void_p, 3.14) # make sure floats are NOT accepted\n        self.assertRaises(TypeError, c_void_p, object()) # nor other objects\n\n    def test_pointers_bool(self):\n        # NULL pointers have a boolean False value, non-NULL pointers True.\n        self.assertEqual(bool(POINTER(c_int)()), False)\n        self.assertEqual(bool(pointer(c_int())), True)\n\n        self.assertEqual(bool(CFUNCTYPE(None)(0)), False)\n        self.assertEqual(bool(CFUNCTYPE(None)(42)), True)\n\n        # COM methods are boolean True:\n        if sys.platform == \"win32\":\n            mth = WINFUNCTYPE(None)(42, \"name\", (), None)\n            self.assertEqual(bool(mth), True)\n\n    def test_pointer_type_name(self):\n        LargeNamedType = type('T' * 2 ** 25, (Structure,), {})\n        self.assertTrue(POINTER(LargeNamedType))\n\n        # to not leak references, we must clean _pointer_type_cache\n        from ctypes import _pointer_type_cache\n        del _pointer_type_cache[LargeNamedType]\n\n    def test_pointer_type_str_name(self):\n        large_string = 'T' * 2 ** 25\n        P = POINTER(large_string)\n        self.assertTrue(P)\n\n        # to not leak references, we must clean _pointer_type_cache\n        from ctypes import _pointer_type_cache\n        del _pointer_type_cache[id(P)]\n\n    def test_abstract(self):\n        from ctypes import _Pointer\n\n        self.assertRaises(TypeError, _Pointer.set_type, 42)\n\n\nif __name__ == '__main__':\n    unittest.main()",
    "repo": "RustPython/RustPython",
    "path": "./datasets/diagrams-repos/RustPython/RustPython/Lib/ctypes/test/test_pointers.py",
    "query": "For the test_pass_pointers method, illustrate the steps involved in passing a pointer to a function, modifying the pointed value, and verifying the changes in the original variable.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'PointersTestCase', 'node_id': 'PointersTestCase', 'description': 'Test case class for pointer operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'test_pass_pointers', 'node_id': 'test_pass_pointers', 'description': 'Tests passing pointers between Python and C', 'visibility': 'public', 'return_type': 'None', 'params': 'self', 'source_class_id': 'PointersTestCase'}, {'type': 'function', 'name': '_testfunc_p_p', 'node_id': '_testfunc_p_p', 'description': 'C function that accepts and returns pointers', 'visibility': 'public', 'return_type': 'POINTER', 'params': 'POINTER', 'source_class_id': None}, {'type': 'variable', 'name': 'i', 'node_id': 'i', 'description': 'Integer value to be modified', 'visibility': 'private', 'return_type': 'c_int', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'byref', 'node_id': 'byref', 'description': 'Creates reference to variable', 'visibility': 'public', 'return_type': 'POINTER', 'params': 'obj', 'source_class_id': None}, {'type': 'function', 'name': 'pointer', 'node_id': 'pointer', 'description': 'Creates pointer to variable', 'visibility': 'public', 'return_type': 'POINTER', 'params': 'obj', 'source_class_id': None}, {'type': 'function', 'name': 'CDLL', 'node_id': 'CDLL', 'description': 'Loads shared library', 'visibility': 'public', 'return_type': 'CDLL', 'params': 'library_path', 'source_class_id': None}, {'type': 'function', 'name': 'from_address', 'node_id': 'from_address', 'description': 'Creates object from memory address', 'visibility': 'public', 'return_type': 'c_int', 'params': 'address', 'source_class_id': None}], 'edges': [{'node_id_from': 'PointersTestCase', 'node_id_to': 'test_pass_pointers', 'description': 'contains'}, {'node_id_from': 'test_pass_pointers', 'node_id_to': 'CDLL', 'description': 'loads library'}, {'node_id_from': 'test_pass_pointers', 'node_id_to': 'byref', 'description': 'creates reference'}, {'node_id_from': 'test_pass_pointers', 'node_id_to': 'pointer', 'description': 'creates pointer'}, {'node_id_from': 'test_pass_pointers', 'node_id_to': '_testfunc_p_p', 'description': 'calls with pointer'}, {'node_id_from': '_testfunc_p_p', 'node_id_to': 'i', 'description': 'modifies value'}, {'node_id_from': 'test_pass_pointers', 'node_id_to': 'from_address', 'description': 'verifies value'}], 'packages': [{'package_id': 'pointerTest', 'children': ['PointersTestCase', 'test_pass_pointers', '_testfunc_p_p', 'i', 'byref', 'pointer', 'CDLL', 'from_address'], 'description': 'Pointer manipulation test components'}]}",
    "version": "full",
    "text_answer": "The test_pass_pointers method demonstrates pointer passing between Python and C by creating an integer value, passing its pointer to a C function, and verifying the modifications. It uses both byref and pointer functions to create references, calls the C function _testfunc_p_p, and checks the results using direct pointer access and from_address method.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "PHP",
    "code": "\n<?php\n\n/**\n * @package    Grav\\Framework\\Uri\n *\n * @copyright  Copyright (c) 2015 - 2025 Trilby Media, LLC. All rights reserved.\n * @license    MIT License; see LICENSE file for details.\n */\n\nnamespace Grav\\Framework\\Uri;\n\nuse InvalidArgumentException;\nuse function is_string;\n\n/**\n * Class Uri\n * @package Grav\\Framework\\Uri\n */\nclass UriFactory\n{\n    /**\n     * @param array $env\n     * @return Uri\n     * @throws InvalidArgumentException\n     */\n    public static function createFromEnvironment(array $env)\n    {\n        return new Uri(static::parseUrlFromEnvironment($env));\n    }\n\n    /**\n     * @param string $uri\n     * @return Uri\n     * @throws InvalidArgumentException\n     */\n    public static function createFromString($uri)\n    {\n        return new Uri(static::parseUrl($uri));\n    }\n\n    /**\n     * Creates a URI from a array of `parse_url()` components.\n     *\n     * @param array $parts\n     * @return Uri\n     * @throws InvalidArgumentException\n     */\n    public static function createFromParts(array $parts)\n    {\n        return new Uri($parts);\n    }\n\n    /**\n     * @param array $env\n     * @return array\n     * @throws InvalidArgumentException\n     */\n    public static function parseUrlFromEnvironment(array $env)\n    {\n        // Build scheme.\n        if (isset($env['REQUEST_SCHEME'])) {\n            $scheme = strtolower($env['REQUEST_SCHEME']);\n        } else {\n            $https = $env['HTTPS'] ?? '';\n            $scheme = (empty($https) || strtolower($https) === 'off') ? 'http' : 'https';\n        }\n\n        // Build user and password.\n        $user = $env['PHP_AUTH_USER'] ?? '';\n        $pass = $env['PHP_AUTH_PW'] ?? '';\n\n        // Build host.\n        $host = 'localhost';\n        if (isset($env['HTTP_HOST'])) {\n            $host = $env['HTTP_HOST'];\n        } elseif (isset($env['SERVER_NAME'])) {\n            $host = $env['SERVER_NAME'];\n        }\n        // Remove port from HTTP_HOST generated $hostname\n        $host = explode(':', $host)[0];\n\n        // Build port.\n        $port = isset($env['SERVER_PORT']) ? (int)$env['SERVER_PORT'] : null;\n\n        // Build path.\n        $request_uri = $env['REQUEST_URI'] ?? '';\n        $path = parse_url('http://example.com' . $request_uri, PHP_URL_PATH);\n\n        // Build query string.\n        $query = $env['QUERY_STRING'] ?? '';\n        if ($query === '') {\n            $query = parse_url('http://example.com' . $request_uri, PHP_URL_QUERY);\n        }\n\n        // Support ngnix routes.\n        if (strpos((string) $query, '_url=') === 0) {\n            parse_str($query, $q);\n            unset($q['_url']);\n            $query = http_build_query($q);\n        }\n\n        return [\n            'scheme' => $scheme,\n            'user' => $user,\n            'pass' => $pass,\n            'host' => $host,\n            'port' => $port,\n            'path' => $path,\n            'query' => $query\n        ];\n    }\n\n    /**\n     * UTF-8 aware parse_url() implementation.\n     *\n     * @param string $url\n     * @return array\n     * @throws InvalidArgumentException\n     */\n    public static function parseUrl($url)\n    {\n        if (!is_string($url)) {\n            throw new InvalidArgumentException('URL must be a string');\n        }\n\n        $encodedUrl = preg_replace_callback(\n            '%[^:/@?&=#]+%u',\n            static function ($matches) {\n                return rawurlencode($matches[0]);\n            },\n            $url\n        );\n\n        $parts = is_string($encodedUrl) ? parse_url($encodedUrl) : false;\n        if ($parts === false) {\n            throw new InvalidArgumentException(\"Malformed URL: {$url}\");\n        }\n\n        return $parts;\n    }\n\n    /**\n     * Parse query string and return it as an array.\n     *\n     * @param string $query\n     * @return mixed\n     */\n    public static function parseQuery($query)\n    {\n        parse_str($query, $params);\n\n        return $params;\n    }\n\n    /**\n     * Build query string from variables.\n     *\n     * @param array $params\n     * @return string\n     */\n    public static function buildQuery(array $params)\n    {\n        if (!$params) {\n            return '';\n        }\n\n        $separator = ini_get('arg_separator.output') ?: '&';\n\n        return http_build_query($params, '', $separator, PHP_QUERY_RFC3986);\n    }\n}",
    "repo": "getgrav/grav",
    "path": "./datasets/diagrams-repos/getgrav/grav/system/src/Grav/Framework/Uri/UriFactory.php",
    "query": "How does the parseUrl method handle UTF-8 encoding in URLs?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'UriFactory', 'node_id': 'UriFactory', 'description': 'Factory class for creating and handling URIs', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'parseUrl', 'node_id': 'parseUrl', 'description': 'Parses URLs with UTF-8 support by encoding non-ASCII characters', 'visibility': 'public', 'return_type': 'array', 'params': 'string $url', 'source_class_id': 'UriFactory'}, {'type': 'entity', 'name': 'urlEncoding', 'node_id': 'urlEncoding', 'description': 'URL encoding process for non-ASCII characters', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'UriFactory', 'node_id_to': 'parseUrl', 'description': 'contains'}, {'node_id_from': 'parseUrl', 'node_id_to': 'urlEncoding', 'description': 'encodes special characters'}], 'packages': [{'package_id': 'urlProcessing', 'children': ['parseUrl', 'urlEncoding'], 'description': 'URL parsing and encoding functionality'}]}",
    "version": "minimal",
    "text_answer": "The parseUrl method handles UTF-8 encoding by first validating the input URL, then using a regex pattern to identify non-ASCII characters and encode them using rawurlencode before passing to PHP's native parse_url function.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "PHP",
    "code": "\n<?php\n\n/**\n * @package    Grav\\Framework\\Uri\n *\n * @copyright  Copyright (c) 2015 - 2025 Trilby Media, LLC. All rights reserved.\n * @license    MIT License; see LICENSE file for details.\n */\n\nnamespace Grav\\Framework\\Uri;\n\nuse InvalidArgumentException;\nuse function is_string;\n\n/**\n * Class Uri\n * @package Grav\\Framework\\Uri\n */\nclass UriFactory\n{\n    /**\n     * @param array $env\n     * @return Uri\n     * @throws InvalidArgumentException\n     */\n    public static function createFromEnvironment(array $env)\n    {\n        return new Uri(static::parseUrlFromEnvironment($env));\n    }\n\n    /**\n     * @param string $uri\n     * @return Uri\n     * @throws InvalidArgumentException\n     */\n    public static function createFromString($uri)\n    {\n        return new Uri(static::parseUrl($uri));\n    }\n\n    /**\n     * Creates a URI from a array of `parse_url()` components.\n     *\n     * @param array $parts\n     * @return Uri\n     * @throws InvalidArgumentException\n     */\n    public static function createFromParts(array $parts)\n    {\n        return new Uri($parts);\n    }\n\n    /**\n     * @param array $env\n     * @return array\n     * @throws InvalidArgumentException\n     */\n    public static function parseUrlFromEnvironment(array $env)\n    {\n        // Build scheme.\n        if (isset($env['REQUEST_SCHEME'])) {\n            $scheme = strtolower($env['REQUEST_SCHEME']);\n        } else {\n            $https = $env['HTTPS'] ?? '';\n            $scheme = (empty($https) || strtolower($https) === 'off') ? 'http' : 'https';\n        }\n\n        // Build user and password.\n        $user = $env['PHP_AUTH_USER'] ?? '';\n        $pass = $env['PHP_AUTH_PW'] ?? '';\n\n        // Build host.\n        $host = 'localhost';\n        if (isset($env['HTTP_HOST'])) {\n            $host = $env['HTTP_HOST'];\n        } elseif (isset($env['SERVER_NAME'])) {\n            $host = $env['SERVER_NAME'];\n        }\n        // Remove port from HTTP_HOST generated $hostname\n        $host = explode(':', $host)[0];\n\n        // Build port.\n        $port = isset($env['SERVER_PORT']) ? (int)$env['SERVER_PORT'] : null;\n\n        // Build path.\n        $request_uri = $env['REQUEST_URI'] ?? '';\n        $path = parse_url('http://example.com' . $request_uri, PHP_URL_PATH);\n\n        // Build query string.\n        $query = $env['QUERY_STRING'] ?? '';\n        if ($query === '') {\n            $query = parse_url('http://example.com' . $request_uri, PHP_URL_QUERY);\n        }\n\n        // Support ngnix routes.\n        if (strpos((string) $query, '_url=') === 0) {\n            parse_str($query, $q);\n            unset($q['_url']);\n            $query = http_build_query($q);\n        }\n\n        return [\n            'scheme' => $scheme,\n            'user' => $user,\n            'pass' => $pass,\n            'host' => $host,\n            'port' => $port,\n            'path' => $path,\n            'query' => $query\n        ];\n    }\n\n    /**\n     * UTF-8 aware parse_url() implementation.\n     *\n     * @param string $url\n     * @return array\n     * @throws InvalidArgumentException\n     */\n    public static function parseUrl($url)\n    {\n        if (!is_string($url)) {\n            throw new InvalidArgumentException('URL must be a string');\n        }\n\n        $encodedUrl = preg_replace_callback(\n            '%[^:/@?&=#]+%u',\n            static function ($matches) {\n                return rawurlencode($matches[0]);\n            },\n            $url\n        );\n\n        $parts = is_string($encodedUrl) ? parse_url($encodedUrl) : false;\n        if ($parts === false) {\n            throw new InvalidArgumentException(\"Malformed URL: {$url}\");\n        }\n\n        return $parts;\n    }\n\n    /**\n     * Parse query string and return it as an array.\n     *\n     * @param string $query\n     * @return mixed\n     */\n    public static function parseQuery($query)\n    {\n        parse_str($query, $params);\n\n        return $params;\n    }\n\n    /**\n     * Build query string from variables.\n     *\n     * @param array $params\n     * @return string\n     */\n    public static function buildQuery(array $params)\n    {\n        if (!$params) {\n            return '';\n        }\n\n        $separator = ini_get('arg_separator.output') ?: '&';\n\n        return http_build_query($params, '', $separator, PHP_QUERY_RFC3986);\n    }\n}",
    "repo": "getgrav/grav",
    "path": "./datasets/diagrams-repos/getgrav/grav/system/src/Grav/Framework/Uri/UriFactory.php",
    "query": "How does the parseUrl method handle UTF-8 encoding in URLs?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'UriFactory', 'node_id': 'UriFactory', 'description': 'Factory class for creating and handling URIs', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'parseUrl', 'node_id': 'parseUrl', 'description': 'Parses URLs with UTF-8 support by encoding non-ASCII characters', 'visibility': 'public', 'return_type': 'array', 'params': 'string $url', 'source_class_id': 'UriFactory'}, {'type': 'entity', 'name': 'urlEncoding', 'node_id': 'urlEncoding', 'description': 'URL encoding process for non-ASCII characters', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'urlValidation', 'node_id': 'urlValidation', 'description': 'Validates URL string input', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'UriFactory', 'node_id_to': 'parseUrl', 'description': 'contains'}, {'node_id_from': 'parseUrl', 'node_id_to': 'urlValidation', 'description': 'validates input'}, {'node_id_from': 'parseUrl', 'node_id_to': 'urlEncoding', 'description': 'encodes special characters'}], 'packages': [{'package_id': 'urlProcessing', 'children': ['parseUrl', 'urlEncoding', 'urlValidation'], 'description': 'URL parsing and encoding functionality'}]}",
    "version": "medium",
    "text_answer": "The parseUrl method handles UTF-8 encoding by first validating the input URL, then using a regex pattern to identify non-ASCII characters and encode them using rawurlencode before passing to PHP's native parse_url function.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "PHP",
    "code": "\n<?php\n\n/**\n * @package    Grav\\Framework\\Uri\n *\n * @copyright  Copyright (c) 2015 - 2025 Trilby Media, LLC. All rights reserved.\n * @license    MIT License; see LICENSE file for details.\n */\n\nnamespace Grav\\Framework\\Uri;\n\nuse InvalidArgumentException;\nuse function is_string;\n\n/**\n * Class Uri\n * @package Grav\\Framework\\Uri\n */\nclass UriFactory\n{\n    /**\n     * @param array $env\n     * @return Uri\n     * @throws InvalidArgumentException\n     */\n    public static function createFromEnvironment(array $env)\n    {\n        return new Uri(static::parseUrlFromEnvironment($env));\n    }\n\n    /**\n     * @param string $uri\n     * @return Uri\n     * @throws InvalidArgumentException\n     */\n    public static function createFromString($uri)\n    {\n        return new Uri(static::parseUrl($uri));\n    }\n\n    /**\n     * Creates a URI from a array of `parse_url()` components.\n     *\n     * @param array $parts\n     * @return Uri\n     * @throws InvalidArgumentException\n     */\n    public static function createFromParts(array $parts)\n    {\n        return new Uri($parts);\n    }\n\n    /**\n     * @param array $env\n     * @return array\n     * @throws InvalidArgumentException\n     */\n    public static function parseUrlFromEnvironment(array $env)\n    {\n        // Build scheme.\n        if (isset($env['REQUEST_SCHEME'])) {\n            $scheme = strtolower($env['REQUEST_SCHEME']);\n        } else {\n            $https = $env['HTTPS'] ?? '';\n            $scheme = (empty($https) || strtolower($https) === 'off') ? 'http' : 'https';\n        }\n\n        // Build user and password.\n        $user = $env['PHP_AUTH_USER'] ?? '';\n        $pass = $env['PHP_AUTH_PW'] ?? '';\n\n        // Build host.\n        $host = 'localhost';\n        if (isset($env['HTTP_HOST'])) {\n            $host = $env['HTTP_HOST'];\n        } elseif (isset($env['SERVER_NAME'])) {\n            $host = $env['SERVER_NAME'];\n        }\n        // Remove port from HTTP_HOST generated $hostname\n        $host = explode(':', $host)[0];\n\n        // Build port.\n        $port = isset($env['SERVER_PORT']) ? (int)$env['SERVER_PORT'] : null;\n\n        // Build path.\n        $request_uri = $env['REQUEST_URI'] ?? '';\n        $path = parse_url('http://example.com' . $request_uri, PHP_URL_PATH);\n\n        // Build query string.\n        $query = $env['QUERY_STRING'] ?? '';\n        if ($query === '') {\n            $query = parse_url('http://example.com' . $request_uri, PHP_URL_QUERY);\n        }\n\n        // Support ngnix routes.\n        if (strpos((string) $query, '_url=') === 0) {\n            parse_str($query, $q);\n            unset($q['_url']);\n            $query = http_build_query($q);\n        }\n\n        return [\n            'scheme' => $scheme,\n            'user' => $user,\n            'pass' => $pass,\n            'host' => $host,\n            'port' => $port,\n            'path' => $path,\n            'query' => $query\n        ];\n    }\n\n    /**\n     * UTF-8 aware parse_url() implementation.\n     *\n     * @param string $url\n     * @return array\n     * @throws InvalidArgumentException\n     */\n    public static function parseUrl($url)\n    {\n        if (!is_string($url)) {\n            throw new InvalidArgumentException('URL must be a string');\n        }\n\n        $encodedUrl = preg_replace_callback(\n            '%[^:/@?&=#]+%u',\n            static function ($matches) {\n                return rawurlencode($matches[0]);\n            },\n            $url\n        );\n\n        $parts = is_string($encodedUrl) ? parse_url($encodedUrl) : false;\n        if ($parts === false) {\n            throw new InvalidArgumentException(\"Malformed URL: {$url}\");\n        }\n\n        return $parts;\n    }\n\n    /**\n     * Parse query string and return it as an array.\n     *\n     * @param string $query\n     * @return mixed\n     */\n    public static function parseQuery($query)\n    {\n        parse_str($query, $params);\n\n        return $params;\n    }\n\n    /**\n     * Build query string from variables.\n     *\n     * @param array $params\n     * @return string\n     */\n    public static function buildQuery(array $params)\n    {\n        if (!$params) {\n            return '';\n        }\n\n        $separator = ini_get('arg_separator.output') ?: '&';\n\n        return http_build_query($params, '', $separator, PHP_QUERY_RFC3986);\n    }\n}",
    "repo": "getgrav/grav",
    "path": "./datasets/diagrams-repos/getgrav/grav/system/src/Grav/Framework/Uri/UriFactory.php",
    "query": "How does the parseUrl method handle UTF-8 encoding in URLs?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'UriFactory', 'node_id': 'UriFactory', 'description': 'Factory class for creating and handling URIs', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'parseUrl', 'node_id': 'parseUrl', 'description': 'Parses URLs with UTF-8 support by encoding non-ASCII characters', 'visibility': 'public', 'return_type': 'array', 'params': 'string $url', 'source_class_id': 'UriFactory'}, {'type': 'method', 'name': 'createFromString', 'node_id': 'createFromString', 'description': 'Creates URI instance from string', 'visibility': 'public', 'return_type': 'Uri', 'params': 'string $uri', 'source_class_id': 'UriFactory'}, {'type': 'entity', 'name': 'urlEncoding', 'node_id': 'urlEncoding', 'description': 'URL encoding process for non-ASCII characters', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'urlValidation', 'node_id': 'urlValidation', 'description': 'Validates URL string input', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'regexPattern', 'node_id': 'regexPattern', 'description': 'Pattern to match non-ASCII URL characters', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'InvalidArgumentException', 'node_id': 'InvalidArgumentException', 'description': 'Exception for invalid URL inputs', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'UriFactory', 'node_id_to': 'parseUrl', 'description': 'contains'}, {'node_id_from': 'createFromString', 'node_id_to': 'parseUrl', 'description': 'uses'}, {'node_id_from': 'parseUrl', 'node_id_to': 'urlValidation', 'description': 'validates input'}, {'node_id_from': 'parseUrl', 'node_id_to': 'urlEncoding', 'description': 'encodes special characters'}, {'node_id_from': 'urlEncoding', 'node_id_to': 'regexPattern', 'description': 'uses'}, {'node_id_from': 'parseUrl', 'node_id_to': 'InvalidArgumentException', 'description': 'throws'}, {'node_id_from': 'UriFactory', 'node_id_to': 'createFromString', 'description': ''}], 'packages': [{'package_id': 'urlProcessing', 'children': ['parseUrl', 'urlEncoding', 'urlValidation', 'regexPattern'], 'description': 'URL parsing and encoding functionality'}]}",
    "version": "full",
    "text_answer": "The parseUrl method handles UTF-8 encoding by first validating the input URL, then using a regex pattern to identify non-ASCII characters and encode them using rawurlencode before passing to PHP's native parse_url function.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Go",
    "code": "\npackage client\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"syscall\"\n\n\t\"github.com/containerd/containerd/api/types\"\n\t\"github.com/containerd/containerd/api/types/runc/options\"\n\t\"github.com/containerd/containerd/v2/core/images\"\n\t\"github.com/containerd/containerd/v2/core/mount\"\n\t\"github.com/containerd/errdefs\"\n\t\"github.com/opencontainers/runtime-spec/specs-go\"\n)\n\n// NewTaskOpts allows the caller to set options on a new task\ntype NewTaskOpts func(context.Context, *Client, *TaskInfo) error\n\n// WithRootFS allows a task to be created without a snapshot being allocated to its container\nfunc WithRootFS(mounts []mount.Mount) NewTaskOpts {\n\treturn func(ctx context.Context, c *Client, ti *TaskInfo) error {\n\t\tti.RootFS = mounts\n\t\treturn nil\n\t}\n}\n\n// WithRuntimePath will force task service to use a custom path to the runtime binary\n// instead of resolving it from runtime name.\nfunc WithRuntimePath(absRuntimePath string) NewTaskOpts {\n\treturn func(ctx context.Context, client *Client, info *TaskInfo) error {\n\t\tinfo.RuntimePath = absRuntimePath\n\t\treturn nil\n\t}\n}\n\n// WithTaskAPIEndpoint allow task service to manage a task through a given endpoint,\n// usually it is served inside a sandbox, and we can get it from sandbox status.\nfunc WithTaskAPIEndpoint(address string, version uint32) NewTaskOpts {\n\treturn func(ctx context.Context, client *Client, info *TaskInfo) error {\n\t\tif info.Options == nil {\n\t\t\tinfo.Options = &options.Options{}\n\t\t}\n\t\topts, ok := info.Options.(*options.Options)\n\t\tif !ok {\n\t\t\treturn errors.New(\"invalid runtime v2 options format\")\n\t\t}\n\t\topts.TaskApiAddress = address\n\t\topts.TaskApiVersion = version\n\t\treturn nil\n\t}\n}\n\n// WithTaskCheckpoint allows a task to be created with live runtime and memory data from a\n// previous checkpoint. Additional software such as CRIU may be required to\n// restore a task from a checkpoint\nfunc WithTaskCheckpoint(im Image) NewTaskOpts {\n\treturn func(ctx context.Context, c *Client, info *TaskInfo) error {\n\t\tdesc := im.Target()\n\t\tid := desc.Digest\n\t\tindex, err := decodeIndex(ctx, c.ContentStore(), desc)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfor _, m := range index.Manifests {\n\t\t\tif m.MediaType == images.MediaTypeContainerd1Checkpoint {\n\t\t\t\tinfo.Checkpoint = &types.Descriptor{\n\t\t\t\t\tMediaType:   m.MediaType,\n\t\t\t\t\tSize:        m.Size,\n\t\t\t\t\tDigest:      m.Digest.String(),\n\t\t\t\t\tAnnotations: m.Annotations,\n\t\t\t\t}\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\treturn fmt.Errorf(\"checkpoint not found in index %s\", id)\n\t}\n}\n\n// WithCheckpointName sets the image name for the checkpoint\nfunc WithCheckpointName(name string) CheckpointTaskOpts {\n\treturn func(r *CheckpointTaskInfo) error {\n\t\tr.Name = name\n\t\treturn nil\n\t}\n}\n\n// WithCheckpointImagePath sets image path for checkpoint option\nfunc WithCheckpointImagePath(path string) CheckpointTaskOpts {\n\treturn func(r *CheckpointTaskInfo) error {\n\t\tif r.Options == nil {\n\t\t\tr.Options = &options.CheckpointOptions{}\n\t\t}\n\t\topts, ok := r.Options.(*options.CheckpointOptions)\n\t\tif !ok {\n\t\t\treturn errors.New(\"invalid runtime v2 checkpoint options format\")\n\t\t}\n\t\topts.ImagePath = path\n\t\treturn nil\n\t}\n}\n\n// WithRestoreImagePath sets image path for create option\nfunc WithRestoreImagePath(path string) NewTaskOpts {\n\treturn func(ctx context.Context, c *Client, ti *TaskInfo) error {\n\t\tif ti.Options == nil {\n\t\t\tti.Options = &options.Options{}\n\t\t}\n\t\topts, ok := ti.Options.(*options.Options)\n\t\tif !ok {\n\t\t\treturn errors.New(\"invalid runtime v2 options format\")\n\t\t}\n\t\topts.CriuImagePath = path\n\t\treturn nil\n\t}\n}\n\n// WithRestoreWorkPath sets criu work path for create option\nfunc WithRestoreWorkPath(path string) NewTaskOpts {\n\treturn func(ctx context.Context, c *Client, ti *TaskInfo) error {\n\t\tif ti.Options == nil {\n\t\t\tti.Options = &options.Options{}\n\t\t}\n\t\topts, ok := ti.Options.(*options.Options)\n\t\tif !ok {\n\t\t\treturn errors.New(\"invalid runtime v2 options format\")\n\t\t}\n\t\topts.CriuWorkPath = path\n\t\treturn nil\n\t}\n}\n\n// ProcessDeleteOpts allows the caller to set options for the deletion of a task\ntype ProcessDeleteOpts func(context.Context, Process) error\n\n// WithProcessKill will forcefully kill and delete a process\nfunc WithProcessKill(ctx context.Context, p Process) error {\n\t// Skip killing tasks with PID 0\n\t// https://github.com/containerd/containerd/issues/10441\n\tif p.Pid() == 0 {\n\t\treturn nil\n\t}\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\t// ignore errors to wait and kill as we are forcefully killing\n\t// the process and don't care about the exit status\n\ts, err := p.Wait(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif err := p.Kill(ctx, syscall.SIGKILL, WithKillAll); err != nil {\n\t\t// Kill might still return an IsNotFound error, even if it actually\n\t\t// killed the process.\n\t\tif errdefs.IsNotFound(err) {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn ctx.Err()\n\t\t\tcase <-s:\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tif errdefs.IsFailedPrecondition(err) {\n\t\t\treturn nil\n\t\t}\n\t\treturn err\n\t}\n\t// wait for the process to fully stop before letting the rest of the deletion complete\n\t<-s\n\treturn nil\n}\n\n// KillInfo contains information on how to process a Kill action\ntype KillInfo struct {\n\t// All kills all processes inside the task\n\t// only valid on tasks, ignored on processes\n\tAll bool\n\t// ExecID is the ID of a process to kill\n\tExecID string\n}\n\n// KillOpts allows options to be set for the killing of a process\ntype KillOpts func(context.Context, *KillInfo) error\n\n// WithKillAll kills all processes for a task\nfunc WithKillAll(ctx context.Context, i *KillInfo) error {\n\ti.All = true\n\treturn nil\n}\n\n// WithKillExecID specifies the process ID\nfunc WithKillExecID(execID string) KillOpts {\n\treturn func(ctx context.Context, i *KillInfo) error {\n\t\ti.ExecID = execID\n\t\treturn nil\n\t}\n}\n\n// WithResources sets the provided resources for task updates. Resources must be\n// either a *specs.LinuxResources or a *specs.WindowsResources\nfunc WithResources(resources interface{}) UpdateTaskOpts {\n\treturn func(ctx context.Context, client *Client, r *UpdateTaskInfo) error {\n\t\tswitch resources.(type) {\n\t\tcase *specs.LinuxResources:\n\t\tcase *specs.WindowsResources:\n\t\tdefault:\n\t\t\treturn errors.New(\"WithResources requires a *specs.LinuxResources or *specs.WindowsResources\")\n\t\t}\n\n\t\tr.Resources = resources\n\t\treturn nil\n\t}\n}\n\n// WithAnnotations sets the provided annotations for task updates.\nfunc WithAnnotations(annotations map[string]string) UpdateTaskOpts {\n\treturn func(ctx context.Context, client *Client, r *UpdateTaskInfo) error {\n\t\tr.Annotations = annotations\n\t\treturn nil\n\t}\n}",
    "repo": "moby/moby",
    "path": "./datasets/diagrams-repos/moby/moby/vendor/github.com/containerd/containerd/v2/client/task_opts.go",
    "query": "Can you illustrate the process of creating a task from a checkpoint, including the role of the WithTaskCheckpoint option and how it interacts with the image and descriptor?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'WithTaskCheckpoint', 'node_id': 'WithTaskCheckpoint', 'description': 'Creates a task from a checkpoint image', 'visibility': 'public', 'return_type': 'NewTaskOpts', 'params': 'im Image', 'source_class_id': None}, {'type': 'entity', 'name': 'Image', 'node_id': 'Image', 'description': 'Represents a container image with checkpoint data', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'TaskInfo', 'node_id': 'TaskInfo', 'description': 'Contains task configuration including checkpoint information', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'Descriptor', 'node_id': 'Descriptor', 'description': 'Contains metadata about checkpoint content', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'WithTaskCheckpoint', 'node_id_to': 'Image', 'description': 'uses'}, {'node_id_from': 'WithTaskCheckpoint', 'node_id_to': 'TaskInfo', 'description': 'configures'}, {'node_id_from': 'TaskInfo', 'node_id_to': 'Descriptor', 'description': 'contains'}], 'packages': [{'package_id': 'checkpointCreation', 'children': ['WithTaskCheckpoint', 'Image', 'TaskInfo', 'Descriptor'], 'description': 'Core components for checkpoint-based task creation'}]}",
    "version": "minimal",
    "text_answer": "WithTaskCheckpoint creates a task from a checkpoint by using an Image to locate the checkpoint data, decoding its index to find the checkpoint manifest, and configuring TaskInfo with the appropriate Descriptor metadata.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Go",
    "code": "\npackage client\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"syscall\"\n\n\t\"github.com/containerd/containerd/api/types\"\n\t\"github.com/containerd/containerd/api/types/runc/options\"\n\t\"github.com/containerd/containerd/v2/core/images\"\n\t\"github.com/containerd/containerd/v2/core/mount\"\n\t\"github.com/containerd/errdefs\"\n\t\"github.com/opencontainers/runtime-spec/specs-go\"\n)\n\n// NewTaskOpts allows the caller to set options on a new task\ntype NewTaskOpts func(context.Context, *Client, *TaskInfo) error\n\n// WithRootFS allows a task to be created without a snapshot being allocated to its container\nfunc WithRootFS(mounts []mount.Mount) NewTaskOpts {\n\treturn func(ctx context.Context, c *Client, ti *TaskInfo) error {\n\t\tti.RootFS = mounts\n\t\treturn nil\n\t}\n}\n\n// WithRuntimePath will force task service to use a custom path to the runtime binary\n// instead of resolving it from runtime name.\nfunc WithRuntimePath(absRuntimePath string) NewTaskOpts {\n\treturn func(ctx context.Context, client *Client, info *TaskInfo) error {\n\t\tinfo.RuntimePath = absRuntimePath\n\t\treturn nil\n\t}\n}\n\n// WithTaskAPIEndpoint allow task service to manage a task through a given endpoint,\n// usually it is served inside a sandbox, and we can get it from sandbox status.\nfunc WithTaskAPIEndpoint(address string, version uint32) NewTaskOpts {\n\treturn func(ctx context.Context, client *Client, info *TaskInfo) error {\n\t\tif info.Options == nil {\n\t\t\tinfo.Options = &options.Options{}\n\t\t}\n\t\topts, ok := info.Options.(*options.Options)\n\t\tif !ok {\n\t\t\treturn errors.New(\"invalid runtime v2 options format\")\n\t\t}\n\t\topts.TaskApiAddress = address\n\t\topts.TaskApiVersion = version\n\t\treturn nil\n\t}\n}\n\n// WithTaskCheckpoint allows a task to be created with live runtime and memory data from a\n// previous checkpoint. Additional software such as CRIU may be required to\n// restore a task from a checkpoint\nfunc WithTaskCheckpoint(im Image) NewTaskOpts {\n\treturn func(ctx context.Context, c *Client, info *TaskInfo) error {\n\t\tdesc := im.Target()\n\t\tid := desc.Digest\n\t\tindex, err := decodeIndex(ctx, c.ContentStore(), desc)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfor _, m := range index.Manifests {\n\t\t\tif m.MediaType == images.MediaTypeContainerd1Checkpoint {\n\t\t\t\tinfo.Checkpoint = &types.Descriptor{\n\t\t\t\t\tMediaType:   m.MediaType,\n\t\t\t\t\tSize:        m.Size,\n\t\t\t\t\tDigest:      m.Digest.String(),\n\t\t\t\t\tAnnotations: m.Annotations,\n\t\t\t\t}\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\treturn fmt.Errorf(\"checkpoint not found in index %s\", id)\n\t}\n}\n\n// WithCheckpointName sets the image name for the checkpoint\nfunc WithCheckpointName(name string) CheckpointTaskOpts {\n\treturn func(r *CheckpointTaskInfo) error {\n\t\tr.Name = name\n\t\treturn nil\n\t}\n}\n\n// WithCheckpointImagePath sets image path for checkpoint option\nfunc WithCheckpointImagePath(path string) CheckpointTaskOpts {\n\treturn func(r *CheckpointTaskInfo) error {\n\t\tif r.Options == nil {\n\t\t\tr.Options = &options.CheckpointOptions{}\n\t\t}\n\t\topts, ok := r.Options.(*options.CheckpointOptions)\n\t\tif !ok {\n\t\t\treturn errors.New(\"invalid runtime v2 checkpoint options format\")\n\t\t}\n\t\topts.ImagePath = path\n\t\treturn nil\n\t}\n}\n\n// WithRestoreImagePath sets image path for create option\nfunc WithRestoreImagePath(path string) NewTaskOpts {\n\treturn func(ctx context.Context, c *Client, ti *TaskInfo) error {\n\t\tif ti.Options == nil {\n\t\t\tti.Options = &options.Options{}\n\t\t}\n\t\topts, ok := ti.Options.(*options.Options)\n\t\tif !ok {\n\t\t\treturn errors.New(\"invalid runtime v2 options format\")\n\t\t}\n\t\topts.CriuImagePath = path\n\t\treturn nil\n\t}\n}\n\n// WithRestoreWorkPath sets criu work path for create option\nfunc WithRestoreWorkPath(path string) NewTaskOpts {\n\treturn func(ctx context.Context, c *Client, ti *TaskInfo) error {\n\t\tif ti.Options == nil {\n\t\t\tti.Options = &options.Options{}\n\t\t}\n\t\topts, ok := ti.Options.(*options.Options)\n\t\tif !ok {\n\t\t\treturn errors.New(\"invalid runtime v2 options format\")\n\t\t}\n\t\topts.CriuWorkPath = path\n\t\treturn nil\n\t}\n}\n\n// ProcessDeleteOpts allows the caller to set options for the deletion of a task\ntype ProcessDeleteOpts func(context.Context, Process) error\n\n// WithProcessKill will forcefully kill and delete a process\nfunc WithProcessKill(ctx context.Context, p Process) error {\n\t// Skip killing tasks with PID 0\n\t// https://github.com/containerd/containerd/issues/10441\n\tif p.Pid() == 0 {\n\t\treturn nil\n\t}\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\t// ignore errors to wait and kill as we are forcefully killing\n\t// the process and don't care about the exit status\n\ts, err := p.Wait(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif err := p.Kill(ctx, syscall.SIGKILL, WithKillAll); err != nil {\n\t\t// Kill might still return an IsNotFound error, even if it actually\n\t\t// killed the process.\n\t\tif errdefs.IsNotFound(err) {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn ctx.Err()\n\t\t\tcase <-s:\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tif errdefs.IsFailedPrecondition(err) {\n\t\t\treturn nil\n\t\t}\n\t\treturn err\n\t}\n\t// wait for the process to fully stop before letting the rest of the deletion complete\n\t<-s\n\treturn nil\n}\n\n// KillInfo contains information on how to process a Kill action\ntype KillInfo struct {\n\t// All kills all processes inside the task\n\t// only valid on tasks, ignored on processes\n\tAll bool\n\t// ExecID is the ID of a process to kill\n\tExecID string\n}\n\n// KillOpts allows options to be set for the killing of a process\ntype KillOpts func(context.Context, *KillInfo) error\n\n// WithKillAll kills all processes for a task\nfunc WithKillAll(ctx context.Context, i *KillInfo) error {\n\ti.All = true\n\treturn nil\n}\n\n// WithKillExecID specifies the process ID\nfunc WithKillExecID(execID string) KillOpts {\n\treturn func(ctx context.Context, i *KillInfo) error {\n\t\ti.ExecID = execID\n\t\treturn nil\n\t}\n}\n\n// WithResources sets the provided resources for task updates. Resources must be\n// either a *specs.LinuxResources or a *specs.WindowsResources\nfunc WithResources(resources interface{}) UpdateTaskOpts {\n\treturn func(ctx context.Context, client *Client, r *UpdateTaskInfo) error {\n\t\tswitch resources.(type) {\n\t\tcase *specs.LinuxResources:\n\t\tcase *specs.WindowsResources:\n\t\tdefault:\n\t\t\treturn errors.New(\"WithResources requires a *specs.LinuxResources or *specs.WindowsResources\")\n\t\t}\n\n\t\tr.Resources = resources\n\t\treturn nil\n\t}\n}\n\n// WithAnnotations sets the provided annotations for task updates.\nfunc WithAnnotations(annotations map[string]string) UpdateTaskOpts {\n\treturn func(ctx context.Context, client *Client, r *UpdateTaskInfo) error {\n\t\tr.Annotations = annotations\n\t\treturn nil\n\t}\n}",
    "repo": "moby/moby",
    "path": "./datasets/diagrams-repos/moby/moby/vendor/github.com/containerd/containerd/v2/client/task_opts.go",
    "query": "Can you illustrate the process of creating a task from a checkpoint, including the role of the WithTaskCheckpoint option and how it interacts with the image and descriptor?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'WithTaskCheckpoint', 'node_id': 'WithTaskCheckpoint', 'description': 'Creates a task from a checkpoint image', 'visibility': 'public', 'return_type': 'NewTaskOpts', 'params': 'im Image', 'source_class_id': None}, {'type': 'entity', 'name': 'Image', 'node_id': 'Image', 'description': 'Represents a container image with checkpoint data', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'TaskInfo', 'node_id': 'TaskInfo', 'description': 'Contains task configuration including checkpoint information', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'Descriptor', 'node_id': 'Descriptor', 'description': 'Contains metadata about checkpoint content', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'decodeIndex', 'node_id': 'decodeIndex', 'description': 'Decodes image index to find checkpoint manifest', 'visibility': 'private', 'return_type': 'Index', 'params': 'ctx context.Context, store ContentStore, desc Descriptor', 'source_class_id': None}, {'type': 'entity', 'name': 'ContentStore', 'node_id': 'ContentStore', 'description': 'Stores and manages container image content', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'WithTaskCheckpoint', 'node_id_to': 'Image', 'description': 'uses'}, {'node_id_from': 'WithTaskCheckpoint', 'node_id_to': 'TaskInfo', 'description': 'configures'}, {'node_id_from': 'WithTaskCheckpoint', 'node_id_to': 'decodeIndex', 'description': 'calls'}, {'node_id_from': 'decodeIndex', 'node_id_to': 'ContentStore', 'description': 'reads from'}, {'node_id_from': 'TaskInfo', 'node_id_to': 'Descriptor', 'description': 'contains'}], 'packages': [{'package_id': 'checkpointCreation', 'children': ['WithTaskCheckpoint', 'Image', 'TaskInfo', 'Descriptor', 'decodeIndex', 'ContentStore'], 'description': 'Components for checkpoint-based task creation'}]}",
    "version": "medium",
    "text_answer": "WithTaskCheckpoint creates a task from a checkpoint by using an Image to locate the checkpoint data, decoding its index to find the checkpoint manifest, and configuring TaskInfo with the appropriate Descriptor metadata.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Go",
    "code": "\npackage client\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"syscall\"\n\n\t\"github.com/containerd/containerd/api/types\"\n\t\"github.com/containerd/containerd/api/types/runc/options\"\n\t\"github.com/containerd/containerd/v2/core/images\"\n\t\"github.com/containerd/containerd/v2/core/mount\"\n\t\"github.com/containerd/errdefs\"\n\t\"github.com/opencontainers/runtime-spec/specs-go\"\n)\n\n// NewTaskOpts allows the caller to set options on a new task\ntype NewTaskOpts func(context.Context, *Client, *TaskInfo) error\n\n// WithRootFS allows a task to be created without a snapshot being allocated to its container\nfunc WithRootFS(mounts []mount.Mount) NewTaskOpts {\n\treturn func(ctx context.Context, c *Client, ti *TaskInfo) error {\n\t\tti.RootFS = mounts\n\t\treturn nil\n\t}\n}\n\n// WithRuntimePath will force task service to use a custom path to the runtime binary\n// instead of resolving it from runtime name.\nfunc WithRuntimePath(absRuntimePath string) NewTaskOpts {\n\treturn func(ctx context.Context, client *Client, info *TaskInfo) error {\n\t\tinfo.RuntimePath = absRuntimePath\n\t\treturn nil\n\t}\n}\n\n// WithTaskAPIEndpoint allow task service to manage a task through a given endpoint,\n// usually it is served inside a sandbox, and we can get it from sandbox status.\nfunc WithTaskAPIEndpoint(address string, version uint32) NewTaskOpts {\n\treturn func(ctx context.Context, client *Client, info *TaskInfo) error {\n\t\tif info.Options == nil {\n\t\t\tinfo.Options = &options.Options{}\n\t\t}\n\t\topts, ok := info.Options.(*options.Options)\n\t\tif !ok {\n\t\t\treturn errors.New(\"invalid runtime v2 options format\")\n\t\t}\n\t\topts.TaskApiAddress = address\n\t\topts.TaskApiVersion = version\n\t\treturn nil\n\t}\n}\n\n// WithTaskCheckpoint allows a task to be created with live runtime and memory data from a\n// previous checkpoint. Additional software such as CRIU may be required to\n// restore a task from a checkpoint\nfunc WithTaskCheckpoint(im Image) NewTaskOpts {\n\treturn func(ctx context.Context, c *Client, info *TaskInfo) error {\n\t\tdesc := im.Target()\n\t\tid := desc.Digest\n\t\tindex, err := decodeIndex(ctx, c.ContentStore(), desc)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfor _, m := range index.Manifests {\n\t\t\tif m.MediaType == images.MediaTypeContainerd1Checkpoint {\n\t\t\t\tinfo.Checkpoint = &types.Descriptor{\n\t\t\t\t\tMediaType:   m.MediaType,\n\t\t\t\t\tSize:        m.Size,\n\t\t\t\t\tDigest:      m.Digest.String(),\n\t\t\t\t\tAnnotations: m.Annotations,\n\t\t\t\t}\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\treturn fmt.Errorf(\"checkpoint not found in index %s\", id)\n\t}\n}\n\n// WithCheckpointName sets the image name for the checkpoint\nfunc WithCheckpointName(name string) CheckpointTaskOpts {\n\treturn func(r *CheckpointTaskInfo) error {\n\t\tr.Name = name\n\t\treturn nil\n\t}\n}\n\n// WithCheckpointImagePath sets image path for checkpoint option\nfunc WithCheckpointImagePath(path string) CheckpointTaskOpts {\n\treturn func(r *CheckpointTaskInfo) error {\n\t\tif r.Options == nil {\n\t\t\tr.Options = &options.CheckpointOptions{}\n\t\t}\n\t\topts, ok := r.Options.(*options.CheckpointOptions)\n\t\tif !ok {\n\t\t\treturn errors.New(\"invalid runtime v2 checkpoint options format\")\n\t\t}\n\t\topts.ImagePath = path\n\t\treturn nil\n\t}\n}\n\n// WithRestoreImagePath sets image path for create option\nfunc WithRestoreImagePath(path string) NewTaskOpts {\n\treturn func(ctx context.Context, c *Client, ti *TaskInfo) error {\n\t\tif ti.Options == nil {\n\t\t\tti.Options = &options.Options{}\n\t\t}\n\t\topts, ok := ti.Options.(*options.Options)\n\t\tif !ok {\n\t\t\treturn errors.New(\"invalid runtime v2 options format\")\n\t\t}\n\t\topts.CriuImagePath = path\n\t\treturn nil\n\t}\n}\n\n// WithRestoreWorkPath sets criu work path for create option\nfunc WithRestoreWorkPath(path string) NewTaskOpts {\n\treturn func(ctx context.Context, c *Client, ti *TaskInfo) error {\n\t\tif ti.Options == nil {\n\t\t\tti.Options = &options.Options{}\n\t\t}\n\t\topts, ok := ti.Options.(*options.Options)\n\t\tif !ok {\n\t\t\treturn errors.New(\"invalid runtime v2 options format\")\n\t\t}\n\t\topts.CriuWorkPath = path\n\t\treturn nil\n\t}\n}\n\n// ProcessDeleteOpts allows the caller to set options for the deletion of a task\ntype ProcessDeleteOpts func(context.Context, Process) error\n\n// WithProcessKill will forcefully kill and delete a process\nfunc WithProcessKill(ctx context.Context, p Process) error {\n\t// Skip killing tasks with PID 0\n\t// https://github.com/containerd/containerd/issues/10441\n\tif p.Pid() == 0 {\n\t\treturn nil\n\t}\n\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\t// ignore errors to wait and kill as we are forcefully killing\n\t// the process and don't care about the exit status\n\ts, err := p.Wait(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif err := p.Kill(ctx, syscall.SIGKILL, WithKillAll); err != nil {\n\t\t// Kill might still return an IsNotFound error, even if it actually\n\t\t// killed the process.\n\t\tif errdefs.IsNotFound(err) {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn ctx.Err()\n\t\t\tcase <-s:\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tif errdefs.IsFailedPrecondition(err) {\n\t\t\treturn nil\n\t\t}\n\t\treturn err\n\t}\n\t// wait for the process to fully stop before letting the rest of the deletion complete\n\t<-s\n\treturn nil\n}\n\n// KillInfo contains information on how to process a Kill action\ntype KillInfo struct {\n\t// All kills all processes inside the task\n\t// only valid on tasks, ignored on processes\n\tAll bool\n\t// ExecID is the ID of a process to kill\n\tExecID string\n}\n\n// KillOpts allows options to be set for the killing of a process\ntype KillOpts func(context.Context, *KillInfo) error\n\n// WithKillAll kills all processes for a task\nfunc WithKillAll(ctx context.Context, i *KillInfo) error {\n\ti.All = true\n\treturn nil\n}\n\n// WithKillExecID specifies the process ID\nfunc WithKillExecID(execID string) KillOpts {\n\treturn func(ctx context.Context, i *KillInfo) error {\n\t\ti.ExecID = execID\n\t\treturn nil\n\t}\n}\n\n// WithResources sets the provided resources for task updates. Resources must be\n// either a *specs.LinuxResources or a *specs.WindowsResources\nfunc WithResources(resources interface{}) UpdateTaskOpts {\n\treturn func(ctx context.Context, client *Client, r *UpdateTaskInfo) error {\n\t\tswitch resources.(type) {\n\t\tcase *specs.LinuxResources:\n\t\tcase *specs.WindowsResources:\n\t\tdefault:\n\t\t\treturn errors.New(\"WithResources requires a *specs.LinuxResources or *specs.WindowsResources\")\n\t\t}\n\n\t\tr.Resources = resources\n\t\treturn nil\n\t}\n}\n\n// WithAnnotations sets the provided annotations for task updates.\nfunc WithAnnotations(annotations map[string]string) UpdateTaskOpts {\n\treturn func(ctx context.Context, client *Client, r *UpdateTaskInfo) error {\n\t\tr.Annotations = annotations\n\t\treturn nil\n\t}\n}",
    "repo": "moby/moby",
    "path": "./datasets/diagrams-repos/moby/moby/vendor/github.com/containerd/containerd/v2/client/task_opts.go",
    "query": "Can you illustrate the process of creating a task from a checkpoint, including the role of the WithTaskCheckpoint option and how it interacts with the image and descriptor?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'WithTaskCheckpoint', 'node_id': 'WithTaskCheckpoint', 'description': 'Creates a task from a checkpoint image', 'visibility': 'public', 'return_type': 'NewTaskOpts', 'params': 'im Image', 'source_class_id': None}, {'type': 'entity', 'name': 'Image', 'node_id': 'Image', 'description': 'Represents a container image with checkpoint data', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'TaskInfo', 'node_id': 'TaskInfo', 'description': 'Contains task configuration including checkpoint information', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'Descriptor', 'node_id': 'Descriptor', 'description': 'Contains metadata about checkpoint content', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'decodeIndex', 'node_id': 'decodeIndex', 'description': 'Decodes image index to find checkpoint manifest', 'visibility': 'private', 'return_type': 'Index', 'params': 'ctx context.Context, store ContentStore, desc Descriptor', 'source_class_id': None}, {'type': 'entity', 'name': 'ContentStore', 'node_id': 'ContentStore', 'description': 'Stores and manages container image content', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'WithCheckpointName', 'node_id': 'WithCheckpointName', 'description': 'Sets the image name for the checkpoint', 'visibility': 'public', 'return_type': 'CheckpointTaskOpts', 'params': 'name string', 'source_class_id': None}, {'type': 'function', 'name': 'WithCheckpointImagePath', 'node_id': 'WithCheckpointImagePath', 'description': 'Sets image path for checkpoint option', 'visibility': 'public', 'return_type': 'CheckpointTaskOpts', 'params': 'path string', 'source_class_id': None}, {'type': 'entity', 'name': 'CheckpointTaskInfo', 'node_id': 'CheckpointTaskInfo', 'description': 'Contains information for checkpoint creation', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'WithTaskCheckpoint', 'node_id_to': 'Image', 'description': 'uses'}, {'node_id_from': 'WithTaskCheckpoint', 'node_id_to': 'TaskInfo', 'description': 'configures'}, {'node_id_from': 'WithTaskCheckpoint', 'node_id_to': 'decodeIndex', 'description': 'calls'}, {'node_id_from': 'decodeIndex', 'node_id_to': 'ContentStore', 'description': 'reads from'}, {'node_id_from': 'TaskInfo', 'node_id_to': 'Descriptor', 'description': 'contains'}, {'node_id_from': 'WithCheckpointName', 'node_id_to': 'CheckpointTaskInfo', 'description': 'configures'}, {'node_id_from': 'WithCheckpointImagePath', 'node_id_to': 'CheckpointTaskInfo', 'description': 'configures'}], 'packages': [{'package_id': 'checkpointManagement', 'children': ['checkpointCreation', 'checkpointConfiguration'], 'description': 'Complete checkpoint management system'}, {'package_id': 'checkpointCreation', 'children': ['WithTaskCheckpoint', 'Image', 'TaskInfo', 'Descriptor', 'decodeIndex', 'ContentStore'], 'description': 'Components for checkpoint-based task creation'}, {'package_id': 'checkpointConfiguration', 'children': ['WithCheckpointName', 'WithCheckpointImagePath', 'CheckpointTaskInfo'], 'description': 'Checkpoint configuration components'}]}",
    "version": "full",
    "text_answer": "WithTaskCheckpoint creates a task from a checkpoint by using an Image to locate the checkpoint data, decoding its index to find the checkpoint manifest, and configuring TaskInfo with the appropriate Descriptor metadata.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\n\"use client\"\n\nimport * as SheetPrimitive from \"@radix-ui/react-dialog\"\nimport { cva, type VariantProps } from \"class-variance-authority\"\nimport * as React from \"react\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst Sheet = SheetPrimitive.Root\n\nconst SheetTrigger = SheetPrimitive.Trigger\n\nconst SheetClose = SheetPrimitive.Close\n\nconst SheetPortal = SheetPrimitive.Portal\n\nconst SheetOverlay = React.forwardRef<\n  React.ElementRef<typeof SheetPrimitive.Overlay>,\n  React.ComponentPropsWithoutRef<typeof SheetPrimitive.Overlay>\n>(({ className, ...props }, ref) => (\n  <SheetPrimitive.Overlay\n    className={cn(\n      \"bg-background/80 data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 fixed inset-0 z-50 backdrop-blur-sm\",\n      className\n    )}\n    {...props}\n    ref={ref}\n  />\n))\nSheetOverlay.displayName = SheetPrimitive.Overlay.displayName\n\nconst sheetVariants = cva(\n  \"bg-background data-[state=open]:animate-in data-[state=closed]:animate-out fixed z-50 gap-4 p-6 shadow-lg transition ease-in-out data-[state=closed]:duration-300 data-[state=open]:duration-500\",\n  {\n    variants: {\n      side: {\n        top: \"data-[state=closed]:slide-out-to-top data-[state=open]:slide-in-from-top inset-x-0 top-0 border-b\",\n        bottom:\n          \"data-[state=closed]:slide-out-to-bottom data-[state=open]:slide-in-from-bottom inset-x-0 bottom-0 border-t\",\n        left: \"data-[state=closed]:slide-out-to-left data-[state=open]:slide-in-from-left inset-y-0 left-0 h-full w-3/4 border-r sm:max-w-sm\",\n        right:\n          \"data-[state=closed]:slide-out-to-right data-[state=open]:slide-in-from-right inset-y-0 right-0  h-full w-3/4 border-l sm:max-w-sm\"\n      }\n    },\n    defaultVariants: {\n      side: \"right\"\n    }\n  }\n)\n\ninterface SheetContentProps\n  extends React.ComponentPropsWithoutRef<typeof SheetPrimitive.Content>,\n    VariantProps<typeof sheetVariants> {}\n\nconst SheetContent = React.forwardRef<\n  React.ElementRef<typeof SheetPrimitive.Content>,\n  SheetContentProps\n>(({ side = \"right\", className, children, ...props }, ref) => (\n  <SheetPortal>\n    <SheetOverlay />\n    <SheetPrimitive.Content\n      ref={ref}\n      className={cn(sheetVariants({ side }), className)}\n      {...props}\n    >\n      {children}\n      {/* <SheetPrimitive.Close className=\"ring-offset-background focus:ring-ring data-[state=open]:bg-secondary absolute right-4 top-4 rounded-sm opacity-70 transition-opacity hover:opacity-100 focus:outline-none focus:ring-2 focus:ring-offset-2 disabled:pointer-events-none\">\n        <X className=\"h-4 w-4\" />\n        <span className=\"sr-only\">Close</span>\n      </SheetPrimitive.Close> */}\n    </SheetPrimitive.Content>\n  </SheetPortal>\n))\nSheetContent.displayName = SheetPrimitive.Content.displayName\n\nconst SheetHeader = ({\n  className,\n  ...props\n}: React.HTMLAttributes<HTMLDivElement>) => (\n  <div\n    className={cn(\n      \"flex flex-col space-y-2 text-center sm:text-left\",\n      className\n    )}\n    {...props}\n  />\n)\nSheetHeader.displayName = \"SheetHeader\"\n\nconst SheetFooter = ({\n  className,\n  ...props\n}: React.HTMLAttributes<HTMLDivElement>) => (\n  <div\n    className={cn(\n      \"flex flex-col-reverse sm:flex-row sm:justify-end sm:space-x-2\",\n      className\n    )}\n    {...props}\n  />\n)\nSheetFooter.displayName = \"SheetFooter\"\n\nconst SheetTitle = React.forwardRef<\n  React.ElementRef<typeof SheetPrimitive.Title>,\n  React.ComponentPropsWithoutRef<typeof SheetPrimitive.Title>\n>(({ className, ...props }, ref) => (\n  <SheetPrimitive.Title\n    ref={ref}\n    className={cn(\"text-foreground text-lg font-semibold\", className)}\n    {...props}\n  />\n))\nSheetTitle.displayName = SheetPrimitive.Title.displayName\n\nconst SheetDescription = React.forwardRef<\n  React.ElementRef<typeof SheetPrimitive.Description>,\n  React.ComponentPropsWithoutRef<typeof SheetPrimitive.Description>\n>(({ className, ...props }, ref) => (\n  <SheetPrimitive.Description\n    ref={ref}\n    className={cn(\"text-muted-foreground text-sm\", className)}\n    {...props}\n  />\n))\nSheetDescription.displayName = SheetPrimitive.Description.displayName\n\nexport {\n  Sheet,\n  SheetClose,\n  SheetContent,\n  SheetDescription,\n  SheetFooter,\n  SheetHeader,\n  SheetOverlay,\n  SheetPortal,\n  SheetTitle,\n  SheetTrigger\n}",
    "repo": "mckaywrigley/chatbot-ui",
    "path": "./datasets/diagrams-repos/mckaywrigley/chatbot-ui/components/ui/sheet.tsx",
    "query": "What is the flow of events when the SheetTrigger is activated and the dialog is opened?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'SheetTrigger', 'node_id': 'SheetTrigger', 'description': 'Component that triggers the sheet dialog to open', 'visibility': 'public', 'return_type': 'ReactElement', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SheetPortal', 'node_id': 'SheetPortal', 'description': 'Portal component that renders sheet content outside of parent hierarchy', 'visibility': 'public', 'return_type': 'ReactElement', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SheetOverlay', 'node_id': 'SheetOverlay', 'description': 'Renders a backdrop behind the sheet content', 'visibility': 'public', 'return_type': 'ReactElement', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SheetContent', 'node_id': 'SheetContent', 'description': 'Main content container of the sheet dialog', 'visibility': 'public', 'return_type': 'ReactElement', 'params': 'side, className, children, ...props', 'source_class_id': None}], 'edges': [{'node_id_from': 'SheetTrigger', 'node_id_to': 'SheetPortal', 'description': 'Opens portal on trigger'}, {'node_id_from': 'SheetPortal', 'node_id_to': 'SheetOverlay', 'description': 'Renders overlay'}, {'node_id_from': 'SheetPortal', 'node_id_to': 'SheetContent', 'description': 'Renders content'}], 'packages': [{'package_id': 'sheetDialog', 'children': ['SheetTrigger', 'SheetPortal', 'SheetOverlay', 'SheetContent'], 'description': 'Core sheet dialog components'}]}",
    "version": "minimal",
    "text_answer": "When SheetTrigger is activated, it triggers the Sheet dialog to open. This creates a SheetPortal that renders outside the parent hierarchy. The portal simultaneously displays a SheetOverlay (backdrop) and SheetContent (main dialog content). The content appears with animations based on the specified side position (right by default).",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\n\"use client\"\n\nimport * as SheetPrimitive from \"@radix-ui/react-dialog\"\nimport { cva, type VariantProps } from \"class-variance-authority\"\nimport * as React from \"react\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst Sheet = SheetPrimitive.Root\n\nconst SheetTrigger = SheetPrimitive.Trigger\n\nconst SheetClose = SheetPrimitive.Close\n\nconst SheetPortal = SheetPrimitive.Portal\n\nconst SheetOverlay = React.forwardRef<\n  React.ElementRef<typeof SheetPrimitive.Overlay>,\n  React.ComponentPropsWithoutRef<typeof SheetPrimitive.Overlay>\n>(({ className, ...props }, ref) => (\n  <SheetPrimitive.Overlay\n    className={cn(\n      \"bg-background/80 data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 fixed inset-0 z-50 backdrop-blur-sm\",\n      className\n    )}\n    {...props}\n    ref={ref}\n  />\n))\nSheetOverlay.displayName = SheetPrimitive.Overlay.displayName\n\nconst sheetVariants = cva(\n  \"bg-background data-[state=open]:animate-in data-[state=closed]:animate-out fixed z-50 gap-4 p-6 shadow-lg transition ease-in-out data-[state=closed]:duration-300 data-[state=open]:duration-500\",\n  {\n    variants: {\n      side: {\n        top: \"data-[state=closed]:slide-out-to-top data-[state=open]:slide-in-from-top inset-x-0 top-0 border-b\",\n        bottom:\n          \"data-[state=closed]:slide-out-to-bottom data-[state=open]:slide-in-from-bottom inset-x-0 bottom-0 border-t\",\n        left: \"data-[state=closed]:slide-out-to-left data-[state=open]:slide-in-from-left inset-y-0 left-0 h-full w-3/4 border-r sm:max-w-sm\",\n        right:\n          \"data-[state=closed]:slide-out-to-right data-[state=open]:slide-in-from-right inset-y-0 right-0  h-full w-3/4 border-l sm:max-w-sm\"\n      }\n    },\n    defaultVariants: {\n      side: \"right\"\n    }\n  }\n)\n\ninterface SheetContentProps\n  extends React.ComponentPropsWithoutRef<typeof SheetPrimitive.Content>,\n    VariantProps<typeof sheetVariants> {}\n\nconst SheetContent = React.forwardRef<\n  React.ElementRef<typeof SheetPrimitive.Content>,\n  SheetContentProps\n>(({ side = \"right\", className, children, ...props }, ref) => (\n  <SheetPortal>\n    <SheetOverlay />\n    <SheetPrimitive.Content\n      ref={ref}\n      className={cn(sheetVariants({ side }), className)}\n      {...props}\n    >\n      {children}\n      {/* <SheetPrimitive.Close className=\"ring-offset-background focus:ring-ring data-[state=open]:bg-secondary absolute right-4 top-4 rounded-sm opacity-70 transition-opacity hover:opacity-100 focus:outline-none focus:ring-2 focus:ring-offset-2 disabled:pointer-events-none\">\n        <X className=\"h-4 w-4\" />\n        <span className=\"sr-only\">Close</span>\n      </SheetPrimitive.Close> */}\n    </SheetPrimitive.Content>\n  </SheetPortal>\n))\nSheetContent.displayName = SheetPrimitive.Content.displayName\n\nconst SheetHeader = ({\n  className,\n  ...props\n}: React.HTMLAttributes<HTMLDivElement>) => (\n  <div\n    className={cn(\n      \"flex flex-col space-y-2 text-center sm:text-left\",\n      className\n    )}\n    {...props}\n  />\n)\nSheetHeader.displayName = \"SheetHeader\"\n\nconst SheetFooter = ({\n  className,\n  ...props\n}: React.HTMLAttributes<HTMLDivElement>) => (\n  <div\n    className={cn(\n      \"flex flex-col-reverse sm:flex-row sm:justify-end sm:space-x-2\",\n      className\n    )}\n    {...props}\n  />\n)\nSheetFooter.displayName = \"SheetFooter\"\n\nconst SheetTitle = React.forwardRef<\n  React.ElementRef<typeof SheetPrimitive.Title>,\n  React.ComponentPropsWithoutRef<typeof SheetPrimitive.Title>\n>(({ className, ...props }, ref) => (\n  <SheetPrimitive.Title\n    ref={ref}\n    className={cn(\"text-foreground text-lg font-semibold\", className)}\n    {...props}\n  />\n))\nSheetTitle.displayName = SheetPrimitive.Title.displayName\n\nconst SheetDescription = React.forwardRef<\n  React.ElementRef<typeof SheetPrimitive.Description>,\n  React.ComponentPropsWithoutRef<typeof SheetPrimitive.Description>\n>(({ className, ...props }, ref) => (\n  <SheetPrimitive.Description\n    ref={ref}\n    className={cn(\"text-muted-foreground text-sm\", className)}\n    {...props}\n  />\n))\nSheetDescription.displayName = SheetPrimitive.Description.displayName\n\nexport {\n  Sheet,\n  SheetClose,\n  SheetContent,\n  SheetDescription,\n  SheetFooter,\n  SheetHeader,\n  SheetOverlay,\n  SheetPortal,\n  SheetTitle,\n  SheetTrigger\n}",
    "repo": "mckaywrigley/chatbot-ui",
    "path": "./datasets/diagrams-repos/mckaywrigley/chatbot-ui/components/ui/sheet.tsx",
    "query": "What is the flow of events when the SheetTrigger is activated and the dialog is opened?",
    "diagram": "{'nodes': [{'type': 'variable', 'name': 'Sheet', 'node_id': 'Sheet', 'description': 'Root component managing sheet state', 'visibility': 'public', 'return_type': 'ReactElement', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SheetTrigger', 'node_id': 'SheetTrigger', 'description': 'Component that triggers the sheet dialog to open', 'visibility': 'public', 'return_type': 'ReactElement', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SheetPortal', 'node_id': 'SheetPortal', 'description': 'Portal component that renders sheet content outside of parent hierarchy', 'visibility': 'public', 'return_type': 'ReactElement', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SheetOverlay', 'node_id': 'SheetOverlay', 'description': 'Renders a backdrop behind the sheet content', 'visibility': 'public', 'return_type': 'ReactElement', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SheetContent', 'node_id': 'SheetContent', 'description': 'Main content container of the sheet dialog', 'visibility': 'public', 'return_type': 'ReactElement', 'params': 'side, className, children, ...props', 'source_class_id': None}, {'type': 'variable', 'name': 'sheetVariants', 'node_id': 'sheetVariants', 'description': 'Styles configuration for different sheet positions', 'visibility': 'private', 'return_type': 'object', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'Sheet', 'node_id_to': 'SheetTrigger', 'description': 'Contains trigger'}, {'node_id_from': 'SheetTrigger', 'node_id_to': 'SheetPortal', 'description': 'Opens portal on trigger'}, {'node_id_from': 'SheetPortal', 'node_id_to': 'SheetOverlay', 'description': 'Renders overlay'}, {'node_id_from': 'SheetPortal', 'node_id_to': 'SheetContent', 'description': 'Renders content'}, {'node_id_from': 'sheetVariants', 'node_id_to': 'SheetContent', 'description': 'Applies styles'}], 'packages': [{'package_id': 'sheetDialog', 'children': ['Sheet', 'SheetTrigger', 'SheetPortal', 'SheetOverlay', 'SheetContent', 'sheetVariants'], 'description': 'Sheet dialog components and utilities'}]}",
    "version": "medium",
    "text_answer": "When SheetTrigger is activated, it triggers the Sheet dialog to open. This creates a SheetPortal that renders outside the parent hierarchy. The portal simultaneously displays a SheetOverlay (backdrop) and SheetContent (main dialog content). The content appears with animations based on the specified side position (right by default).",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\n\"use client\"\n\nimport * as SheetPrimitive from \"@radix-ui/react-dialog\"\nimport { cva, type VariantProps } from \"class-variance-authority\"\nimport * as React from \"react\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst Sheet = SheetPrimitive.Root\n\nconst SheetTrigger = SheetPrimitive.Trigger\n\nconst SheetClose = SheetPrimitive.Close\n\nconst SheetPortal = SheetPrimitive.Portal\n\nconst SheetOverlay = React.forwardRef<\n  React.ElementRef<typeof SheetPrimitive.Overlay>,\n  React.ComponentPropsWithoutRef<typeof SheetPrimitive.Overlay>\n>(({ className, ...props }, ref) => (\n  <SheetPrimitive.Overlay\n    className={cn(\n      \"bg-background/80 data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 fixed inset-0 z-50 backdrop-blur-sm\",\n      className\n    )}\n    {...props}\n    ref={ref}\n  />\n))\nSheetOverlay.displayName = SheetPrimitive.Overlay.displayName\n\nconst sheetVariants = cva(\n  \"bg-background data-[state=open]:animate-in data-[state=closed]:animate-out fixed z-50 gap-4 p-6 shadow-lg transition ease-in-out data-[state=closed]:duration-300 data-[state=open]:duration-500\",\n  {\n    variants: {\n      side: {\n        top: \"data-[state=closed]:slide-out-to-top data-[state=open]:slide-in-from-top inset-x-0 top-0 border-b\",\n        bottom:\n          \"data-[state=closed]:slide-out-to-bottom data-[state=open]:slide-in-from-bottom inset-x-0 bottom-0 border-t\",\n        left: \"data-[state=closed]:slide-out-to-left data-[state=open]:slide-in-from-left inset-y-0 left-0 h-full w-3/4 border-r sm:max-w-sm\",\n        right:\n          \"data-[state=closed]:slide-out-to-right data-[state=open]:slide-in-from-right inset-y-0 right-0  h-full w-3/4 border-l sm:max-w-sm\"\n      }\n    },\n    defaultVariants: {\n      side: \"right\"\n    }\n  }\n)\n\ninterface SheetContentProps\n  extends React.ComponentPropsWithoutRef<typeof SheetPrimitive.Content>,\n    VariantProps<typeof sheetVariants> {}\n\nconst SheetContent = React.forwardRef<\n  React.ElementRef<typeof SheetPrimitive.Content>,\n  SheetContentProps\n>(({ side = \"right\", className, children, ...props }, ref) => (\n  <SheetPortal>\n    <SheetOverlay />\n    <SheetPrimitive.Content\n      ref={ref}\n      className={cn(sheetVariants({ side }), className)}\n      {...props}\n    >\n      {children}\n      {/* <SheetPrimitive.Close className=\"ring-offset-background focus:ring-ring data-[state=open]:bg-secondary absolute right-4 top-4 rounded-sm opacity-70 transition-opacity hover:opacity-100 focus:outline-none focus:ring-2 focus:ring-offset-2 disabled:pointer-events-none\">\n        <X className=\"h-4 w-4\" />\n        <span className=\"sr-only\">Close</span>\n      </SheetPrimitive.Close> */}\n    </SheetPrimitive.Content>\n  </SheetPortal>\n))\nSheetContent.displayName = SheetPrimitive.Content.displayName\n\nconst SheetHeader = ({\n  className,\n  ...props\n}: React.HTMLAttributes<HTMLDivElement>) => (\n  <div\n    className={cn(\n      \"flex flex-col space-y-2 text-center sm:text-left\",\n      className\n    )}\n    {...props}\n  />\n)\nSheetHeader.displayName = \"SheetHeader\"\n\nconst SheetFooter = ({\n  className,\n  ...props\n}: React.HTMLAttributes<HTMLDivElement>) => (\n  <div\n    className={cn(\n      \"flex flex-col-reverse sm:flex-row sm:justify-end sm:space-x-2\",\n      className\n    )}\n    {...props}\n  />\n)\nSheetFooter.displayName = \"SheetFooter\"\n\nconst SheetTitle = React.forwardRef<\n  React.ElementRef<typeof SheetPrimitive.Title>,\n  React.ComponentPropsWithoutRef<typeof SheetPrimitive.Title>\n>(({ className, ...props }, ref) => (\n  <SheetPrimitive.Title\n    ref={ref}\n    className={cn(\"text-foreground text-lg font-semibold\", className)}\n    {...props}\n  />\n))\nSheetTitle.displayName = SheetPrimitive.Title.displayName\n\nconst SheetDescription = React.forwardRef<\n  React.ElementRef<typeof SheetPrimitive.Description>,\n  React.ComponentPropsWithoutRef<typeof SheetPrimitive.Description>\n>(({ className, ...props }, ref) => (\n  <SheetPrimitive.Description\n    ref={ref}\n    className={cn(\"text-muted-foreground text-sm\", className)}\n    {...props}\n  />\n))\nSheetDescription.displayName = SheetPrimitive.Description.displayName\n\nexport {\n  Sheet,\n  SheetClose,\n  SheetContent,\n  SheetDescription,\n  SheetFooter,\n  SheetHeader,\n  SheetOverlay,\n  SheetPortal,\n  SheetTitle,\n  SheetTrigger\n}",
    "repo": "mckaywrigley/chatbot-ui",
    "path": "./datasets/diagrams-repos/mckaywrigley/chatbot-ui/components/ui/sheet.tsx",
    "query": "What is the flow of events when the SheetTrigger is activated and the dialog is opened?",
    "diagram": "{'nodes': [{'type': 'variable', 'name': 'Sheet', 'node_id': 'Sheet', 'description': 'Root component managing sheet state', 'visibility': 'public', 'return_type': 'ReactElement', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SheetTrigger', 'node_id': 'SheetTrigger', 'description': 'Component that triggers the sheet dialog to open', 'visibility': 'public', 'return_type': 'ReactElement', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SheetPortal', 'node_id': 'SheetPortal', 'description': 'Portal component that renders sheet content outside of parent hierarchy', 'visibility': 'public', 'return_type': 'ReactElement', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SheetOverlay', 'node_id': 'SheetOverlay', 'description': 'Renders a backdrop behind the sheet content', 'visibility': 'public', 'return_type': 'ReactElement', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SheetContent', 'node_id': 'SheetContent', 'description': 'Main content container of the sheet dialog', 'visibility': 'public', 'return_type': 'ReactElement', 'params': 'side, className, children, ...props', 'source_class_id': None}, {'type': 'variable', 'name': 'sheetVariants', 'node_id': 'sheetVariants', 'description': 'Styles configuration for different sheet positions', 'visibility': 'private', 'return_type': 'object', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SheetHeader', 'node_id': 'SheetHeader', 'description': 'Header section of sheet content', 'visibility': 'public', 'return_type': 'ReactElement', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SheetFooter', 'node_id': 'SheetFooter', 'description': 'Footer section of sheet content', 'visibility': 'public', 'return_type': 'ReactElement', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SheetTitle', 'node_id': 'SheetTitle', 'description': 'Title component for sheet', 'visibility': 'public', 'return_type': 'ReactElement', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SheetDescription', 'node_id': 'SheetDescription', 'description': 'Description component for sheet', 'visibility': 'public', 'return_type': 'ReactElement', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SheetClose', 'node_id': 'SheetClose', 'description': 'Component to close the sheet', 'visibility': 'public', 'return_type': 'ReactElement', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'Sheet', 'node_id_to': 'SheetTrigger', 'description': 'Contains trigger'}, {'node_id_from': 'SheetTrigger', 'node_id_to': 'SheetPortal', 'description': 'Opens portal on trigger'}, {'node_id_from': 'SheetPortal', 'node_id_to': 'SheetOverlay', 'description': 'Renders overlay'}, {'node_id_from': 'SheetPortal', 'node_id_to': 'SheetContent', 'description': 'Renders content'}, {'node_id_from': 'sheetVariants', 'node_id_to': 'SheetContent', 'description': 'Applies styles'}, {'node_id_from': 'SheetContent', 'node_id_to': 'SheetHeader', 'description': 'Can contain header'}, {'node_id_from': 'SheetContent', 'node_id_to': 'SheetFooter', 'description': 'Can contain footer'}, {'node_id_from': 'SheetHeader', 'node_id_to': 'SheetTitle', 'description': 'Can contain title'}, {'node_id_from': 'SheetHeader', 'node_id_to': 'SheetDescription', 'description': 'Can contain description'}, {'node_id_from': 'SheetContent', 'node_id_to': 'SheetClose', 'description': 'Can contain close button'}], 'packages': [{'package_id': 'sheetDialog', 'children': ['core', 'layout', 'content'], 'description': 'All sheet dialog components'}, {'package_id': 'core', 'children': ['Sheet', 'SheetTrigger', 'SheetPortal', 'SheetOverlay', 'SheetContent', 'sheetVariants'], 'description': 'Core sheet functionality'}, {'package_id': 'layout', 'children': ['SheetHeader', 'SheetFooter'], 'description': 'Layout components'}, {'package_id': 'content', 'children': ['SheetTitle', 'SheetDescription', 'SheetClose'], 'description': 'Content components'}]}",
    "version": "full",
    "text_answer": "When SheetTrigger is activated, it triggers the Sheet dialog to open. This creates a SheetPortal that renders outside the parent hierarchy. The portal simultaneously displays a SheetOverlay (backdrop) and SheetContent (main dialog content). The content appears with animations based on the specified side position (right by default).",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { type GrpcRequest, isGrpcRequest } from '../models/grpc-request';\nimport { isRequest, type Request } from '../models/request';\nimport { isRequestGroup, type RequestGroup } from '../models/request-group';\nimport {\n  HTTP_METHODS,\n  SORT_CREATED_ASC,\n  SORT_CREATED_DESC,\n  SORT_HTTP_METHOD,\n  SORT_MODIFIED_ASC,\n  SORT_MODIFIED_DESC,\n  SORT_NAME_ASC,\n  SORT_NAME_DESC,\n  SORT_TYPE_ASC,\n  SORT_TYPE_DESC,\n  SORT_TYPE_MANUAL,\n} from './constants';\n\ntype SortableModel = Request | RequestGroup | GrpcRequest;\ntype SortFunction<SortableType> = (a: SortableType, b: SortableType) => number;\n\nexport const ascendingNameSort: SortFunction<{name: string}> = (a, b) => {\n  return a.name.localeCompare(b.name);\n};\n\nexport const descendingNameSort: SortFunction<{name: string}> = (a, b) => {\n  return b.name.localeCompare(a.name);\n};\n\nexport const createdFirstSort: SortFunction<{created: number}> = (a, b) => {\n  if (a.created === b.created) {\n    return 0;\n  }\n\n  return a.created < b.created ? -1 : 1;\n};\n\nexport const createdLastSort: SortFunction<{created: number}> = (a, b) => {\n  if (a.created === b.created) {\n    return 0;\n  }\n\n  return a.created > b.created ? -1 : 1;\n};\n\nexport const ascendingModifiedSort: SortFunction<{lastModifiedTimestamp: number}> = (a, b) => {\n  if (a.lastModifiedTimestamp === b.lastModifiedTimestamp) {\n    return 0;\n  }\n\n  return a.lastModifiedTimestamp < b.lastModifiedTimestamp ? -1 : 1;\n};\n\nexport const descendingModifiedSort: SortFunction<{lastModifiedTimestamp: number}> = (a, b) => {\n  if (a.lastModifiedTimestamp === b.lastModifiedTimestamp) {\n    return 0;\n  }\n\n  return a.lastModifiedTimestamp > b.lastModifiedTimestamp ? -1 : 1;\n};\n\nexport const httpMethodSort: SortFunction<Pick<SortableModel, 'type' | 'metaSortKey' | '_id'>> = (a, b) => {\n  // Sort Requests and GrpcRequests to top, in that order\n  if (a.type !== b.type) {\n    if (isRequest(a) || isRequest(b)) {\n      return isRequest(a) ? -1 : 1;\n    }\n\n    if (isGrpcRequest(a) || isGrpcRequest(b)) {\n      return isGrpcRequest(a) ? -1 : 1;\n    }\n  }\n\n  // Sort Requests by HTTP method\n  if (isRequest(a)) {\n    const aIndex = HTTP_METHODS.indexOf(a.method);\n    // @ts-expect-error -- TSCONVERSION\n    const bIndex = HTTP_METHODS.indexOf(b.method);\n\n    if (aIndex !== bIndex) {\n      return aIndex < bIndex ? -1 : 1;\n    }\n\n    // Sort by ascending method name if comparing two custom methods\n    // @ts-expect-error -- TSCONVERSION\n    if (aIndex === -1 && a.method.localeCompare(b.method) !== 0) {\n      // @ts-expect-error -- TSCONVERSION\n      return a.method.localeCompare(b.method);\n    }\n  }\n\n  // Sort by metaSortKey if comparing two Requests with the same method,\n  // two GrpcRequests, or two RequestGroups\n  return metaSortKeySort(a, b);\n};\n\nexport const ascendingTypeSort: SortFunction<Pick<SortableModel, 'type' | 'metaSortKey' | '_id'>> = (a, b) => {\n  if (a.type !== b.type && (isRequestGroup(a) || isRequestGroup(b))) {\n    return isRequestGroup(b) ? -1 : 1;\n  }\n\n  return metaSortKeySort(a, b);\n};\n\nexport const descendingTypeSort: SortFunction<Pick<SortableModel, 'type' | 'metaSortKey' | '_id'>> = (a, b) => {\n  if (a.type !== b.type && (isRequestGroup(a) || isRequestGroup(b))) {\n    return isRequestGroup(a) ? -1 : 1;\n  }\n\n  return metaSortKeySort(a, b);\n};\n\nexport const metaSortKeySort: SortFunction<Pick<SortableModel, '_id' | 'metaSortKey'>> = (a, b) => {\n  if (a.metaSortKey === b.metaSortKey) {\n    return a._id > b._id ? -1 : 1;\n  }\n\n  return a.metaSortKey < b.metaSortKey ? -1 : 1;\n};\n\nexport const ascendingNumberSort: SortFunction<number> = (a, b) => {\n  return a < b ? -1 : 1;\n};\n\nexport const descendingNumberSort: SortFunction<number> = (a, b) => {\n  return ascendingNumberSort(b, a);\n};\n\nexport const sortMethodMap = {\n  [SORT_NAME_ASC]: ascendingNameSort,\n  [SORT_NAME_DESC]: descendingNameSort,\n  [SORT_CREATED_ASC]: createdFirstSort,\n  [SORT_CREATED_DESC]: createdLastSort,\n  [SORT_MODIFIED_ASC]: ascendingModifiedSort,\n  [SORT_MODIFIED_DESC]: descendingModifiedSort,\n  [SORT_HTTP_METHOD]: httpMethodSort,\n  [SORT_TYPE_DESC]: descendingTypeSort,\n  [SORT_TYPE_ASC]: ascendingTypeSort,\n  [SORT_TYPE_MANUAL]: metaSortKeySort,\n};",
    "repo": "Kong/insomnia",
    "path": "./datasets/diagrams-repos/Kong/insomnia/packages/insomnia/src/common/sorting.ts",
    "query": "Show the decision process within the httpMethodSort function.",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'httpMethodSort', 'node_id': 'httpMethodSort', 'description': 'Sorts requests based on type and HTTP method', 'visibility': 'public', 'return_type': 'number', 'params': '(a, b)', 'source_class_id': None}, {'type': 'function', 'name': 'isRequest', 'node_id': 'isRequest', 'description': 'Checks if item is HTTP request', 'visibility': 'public', 'return_type': 'boolean', 'params': '(item)', 'source_class_id': None}, {'type': 'function', 'name': 'isGrpcRequest', 'node_id': 'isGrpcRequest', 'description': 'Checks if item is gRPC request', 'visibility': 'public', 'return_type': 'boolean', 'params': '(item)', 'source_class_id': None}, {'type': 'function', 'name': 'metaSortKeySort', 'node_id': 'metaSortKeySort', 'description': 'Sorts by metaSortKey or _id', 'visibility': 'public', 'return_type': 'number', 'params': '(a, b)', 'source_class_id': None}], 'edges': [{'node_id_from': 'httpMethodSort', 'node_id_to': 'isRequest', 'description': 'checks type'}, {'node_id_from': 'httpMethodSort', 'node_id_to': 'isGrpcRequest', 'description': 'checks type'}, {'node_id_from': 'httpMethodSort', 'node_id_to': 'metaSortKeySort', 'description': 'fallback sort'}], 'packages': [{'package_id': 'sortingLogic', 'children': ['httpMethodSort', 'isRequest', 'isGrpcRequest', 'metaSortKeySort'], 'description': 'Core sorting logic components'}]}",
    "version": "minimal",
    "text_answer": "The httpMethodSort function follows a three-step decision process: first, it compares request types (HTTP vs gRPC), then sorts HTTP requests by method (standard methods first, then custom methods), and finally falls back to metaSortKey comparison for equal cases.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { type GrpcRequest, isGrpcRequest } from '../models/grpc-request';\nimport { isRequest, type Request } from '../models/request';\nimport { isRequestGroup, type RequestGroup } from '../models/request-group';\nimport {\n  HTTP_METHODS,\n  SORT_CREATED_ASC,\n  SORT_CREATED_DESC,\n  SORT_HTTP_METHOD,\n  SORT_MODIFIED_ASC,\n  SORT_MODIFIED_DESC,\n  SORT_NAME_ASC,\n  SORT_NAME_DESC,\n  SORT_TYPE_ASC,\n  SORT_TYPE_DESC,\n  SORT_TYPE_MANUAL,\n} from './constants';\n\ntype SortableModel = Request | RequestGroup | GrpcRequest;\ntype SortFunction<SortableType> = (a: SortableType, b: SortableType) => number;\n\nexport const ascendingNameSort: SortFunction<{name: string}> = (a, b) => {\n  return a.name.localeCompare(b.name);\n};\n\nexport const descendingNameSort: SortFunction<{name: string}> = (a, b) => {\n  return b.name.localeCompare(a.name);\n};\n\nexport const createdFirstSort: SortFunction<{created: number}> = (a, b) => {\n  if (a.created === b.created) {\n    return 0;\n  }\n\n  return a.created < b.created ? -1 : 1;\n};\n\nexport const createdLastSort: SortFunction<{created: number}> = (a, b) => {\n  if (a.created === b.created) {\n    return 0;\n  }\n\n  return a.created > b.created ? -1 : 1;\n};\n\nexport const ascendingModifiedSort: SortFunction<{lastModifiedTimestamp: number}> = (a, b) => {\n  if (a.lastModifiedTimestamp === b.lastModifiedTimestamp) {\n    return 0;\n  }\n\n  return a.lastModifiedTimestamp < b.lastModifiedTimestamp ? -1 : 1;\n};\n\nexport const descendingModifiedSort: SortFunction<{lastModifiedTimestamp: number}> = (a, b) => {\n  if (a.lastModifiedTimestamp === b.lastModifiedTimestamp) {\n    return 0;\n  }\n\n  return a.lastModifiedTimestamp > b.lastModifiedTimestamp ? -1 : 1;\n};\n\nexport const httpMethodSort: SortFunction<Pick<SortableModel, 'type' | 'metaSortKey' | '_id'>> = (a, b) => {\n  // Sort Requests and GrpcRequests to top, in that order\n  if (a.type !== b.type) {\n    if (isRequest(a) || isRequest(b)) {\n      return isRequest(a) ? -1 : 1;\n    }\n\n    if (isGrpcRequest(a) || isGrpcRequest(b)) {\n      return isGrpcRequest(a) ? -1 : 1;\n    }\n  }\n\n  // Sort Requests by HTTP method\n  if (isRequest(a)) {\n    const aIndex = HTTP_METHODS.indexOf(a.method);\n    // @ts-expect-error -- TSCONVERSION\n    const bIndex = HTTP_METHODS.indexOf(b.method);\n\n    if (aIndex !== bIndex) {\n      return aIndex < bIndex ? -1 : 1;\n    }\n\n    // Sort by ascending method name if comparing two custom methods\n    // @ts-expect-error -- TSCONVERSION\n    if (aIndex === -1 && a.method.localeCompare(b.method) !== 0) {\n      // @ts-expect-error -- TSCONVERSION\n      return a.method.localeCompare(b.method);\n    }\n  }\n\n  // Sort by metaSortKey if comparing two Requests with the same method,\n  // two GrpcRequests, or two RequestGroups\n  return metaSortKeySort(a, b);\n};\n\nexport const ascendingTypeSort: SortFunction<Pick<SortableModel, 'type' | 'metaSortKey' | '_id'>> = (a, b) => {\n  if (a.type !== b.type && (isRequestGroup(a) || isRequestGroup(b))) {\n    return isRequestGroup(b) ? -1 : 1;\n  }\n\n  return metaSortKeySort(a, b);\n};\n\nexport const descendingTypeSort: SortFunction<Pick<SortableModel, 'type' | 'metaSortKey' | '_id'>> = (a, b) => {\n  if (a.type !== b.type && (isRequestGroup(a) || isRequestGroup(b))) {\n    return isRequestGroup(a) ? -1 : 1;\n  }\n\n  return metaSortKeySort(a, b);\n};\n\nexport const metaSortKeySort: SortFunction<Pick<SortableModel, '_id' | 'metaSortKey'>> = (a, b) => {\n  if (a.metaSortKey === b.metaSortKey) {\n    return a._id > b._id ? -1 : 1;\n  }\n\n  return a.metaSortKey < b.metaSortKey ? -1 : 1;\n};\n\nexport const ascendingNumberSort: SortFunction<number> = (a, b) => {\n  return a < b ? -1 : 1;\n};\n\nexport const descendingNumberSort: SortFunction<number> = (a, b) => {\n  return ascendingNumberSort(b, a);\n};\n\nexport const sortMethodMap = {\n  [SORT_NAME_ASC]: ascendingNameSort,\n  [SORT_NAME_DESC]: descendingNameSort,\n  [SORT_CREATED_ASC]: createdFirstSort,\n  [SORT_CREATED_DESC]: createdLastSort,\n  [SORT_MODIFIED_ASC]: ascendingModifiedSort,\n  [SORT_MODIFIED_DESC]: descendingModifiedSort,\n  [SORT_HTTP_METHOD]: httpMethodSort,\n  [SORT_TYPE_DESC]: descendingTypeSort,\n  [SORT_TYPE_ASC]: ascendingTypeSort,\n  [SORT_TYPE_MANUAL]: metaSortKeySort,\n};",
    "repo": "Kong/insomnia",
    "path": "./datasets/diagrams-repos/Kong/insomnia/packages/insomnia/src/common/sorting.ts",
    "query": "Show the decision process within the httpMethodSort function.",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'httpMethodSort', 'node_id': 'httpMethodSort', 'description': 'Sorts requests based on type and HTTP method', 'visibility': 'public', 'return_type': 'number', 'params': '(a, b)', 'source_class_id': None}, {'type': 'function', 'name': 'isRequest', 'node_id': 'isRequest', 'description': 'Checks if item is HTTP request', 'visibility': 'public', 'return_type': 'boolean', 'params': '(item)', 'source_class_id': None}, {'type': 'function', 'name': 'isGrpcRequest', 'node_id': 'isGrpcRequest', 'description': 'Checks if item is gRPC request', 'visibility': 'public', 'return_type': 'boolean', 'params': '(item)', 'source_class_id': None}, {'type': 'function', 'name': 'metaSortKeySort', 'node_id': 'metaSortKeySort', 'description': 'Sorts by metaSortKey or _id', 'visibility': 'public', 'return_type': 'number', 'params': '(a, b)', 'source_class_id': None}, {'type': 'variable', 'name': 'HTTP_METHODS', 'node_id': 'HTTP_METHODS', 'description': 'Array of standard HTTP methods', 'visibility': 'public', 'return_type': 'array', 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'typeComparison', 'node_id': 'typeComparison', 'description': 'Type comparison logic', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'methodComparison', 'node_id': 'methodComparison', 'description': 'HTTP method comparison logic', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'httpMethodSort', 'node_id_to': 'typeComparison', 'description': 'first step'}, {'node_id_from': 'typeComparison', 'node_id_to': 'isRequest', 'description': 'check type'}, {'node_id_from': 'typeComparison', 'node_id_to': 'isGrpcRequest', 'description': 'check type'}, {'node_id_from': 'httpMethodSort', 'node_id_to': 'methodComparison', 'description': 'second step'}, {'node_id_from': 'methodComparison', 'node_id_to': 'HTTP_METHODS', 'description': 'uses'}, {'node_id_from': 'httpMethodSort', 'node_id_to': 'metaSortKeySort', 'description': 'final step'}], 'packages': [{'package_id': 'sortingLogic', 'children': ['httpMethodSort', 'typeComparison', 'methodComparison'], 'description': 'Main sorting logic'}, {'package_id': 'typeChecks', 'children': ['isRequest', 'isGrpcRequest'], 'description': 'Type checking functions'}]}",
    "version": "medium",
    "text_answer": "The httpMethodSort function follows a three-step decision process: first, it compares request types (HTTP vs gRPC), then sorts HTTP requests by method (standard methods first, then custom methods), and finally falls back to metaSortKey comparison for equal cases.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { type GrpcRequest, isGrpcRequest } from '../models/grpc-request';\nimport { isRequest, type Request } from '../models/request';\nimport { isRequestGroup, type RequestGroup } from '../models/request-group';\nimport {\n  HTTP_METHODS,\n  SORT_CREATED_ASC,\n  SORT_CREATED_DESC,\n  SORT_HTTP_METHOD,\n  SORT_MODIFIED_ASC,\n  SORT_MODIFIED_DESC,\n  SORT_NAME_ASC,\n  SORT_NAME_DESC,\n  SORT_TYPE_ASC,\n  SORT_TYPE_DESC,\n  SORT_TYPE_MANUAL,\n} from './constants';\n\ntype SortableModel = Request | RequestGroup | GrpcRequest;\ntype SortFunction<SortableType> = (a: SortableType, b: SortableType) => number;\n\nexport const ascendingNameSort: SortFunction<{name: string}> = (a, b) => {\n  return a.name.localeCompare(b.name);\n};\n\nexport const descendingNameSort: SortFunction<{name: string}> = (a, b) => {\n  return b.name.localeCompare(a.name);\n};\n\nexport const createdFirstSort: SortFunction<{created: number}> = (a, b) => {\n  if (a.created === b.created) {\n    return 0;\n  }\n\n  return a.created < b.created ? -1 : 1;\n};\n\nexport const createdLastSort: SortFunction<{created: number}> = (a, b) => {\n  if (a.created === b.created) {\n    return 0;\n  }\n\n  return a.created > b.created ? -1 : 1;\n};\n\nexport const ascendingModifiedSort: SortFunction<{lastModifiedTimestamp: number}> = (a, b) => {\n  if (a.lastModifiedTimestamp === b.lastModifiedTimestamp) {\n    return 0;\n  }\n\n  return a.lastModifiedTimestamp < b.lastModifiedTimestamp ? -1 : 1;\n};\n\nexport const descendingModifiedSort: SortFunction<{lastModifiedTimestamp: number}> = (a, b) => {\n  if (a.lastModifiedTimestamp === b.lastModifiedTimestamp) {\n    return 0;\n  }\n\n  return a.lastModifiedTimestamp > b.lastModifiedTimestamp ? -1 : 1;\n};\n\nexport const httpMethodSort: SortFunction<Pick<SortableModel, 'type' | 'metaSortKey' | '_id'>> = (a, b) => {\n  // Sort Requests and GrpcRequests to top, in that order\n  if (a.type !== b.type) {\n    if (isRequest(a) || isRequest(b)) {\n      return isRequest(a) ? -1 : 1;\n    }\n\n    if (isGrpcRequest(a) || isGrpcRequest(b)) {\n      return isGrpcRequest(a) ? -1 : 1;\n    }\n  }\n\n  // Sort Requests by HTTP method\n  if (isRequest(a)) {\n    const aIndex = HTTP_METHODS.indexOf(a.method);\n    // @ts-expect-error -- TSCONVERSION\n    const bIndex = HTTP_METHODS.indexOf(b.method);\n\n    if (aIndex !== bIndex) {\n      return aIndex < bIndex ? -1 : 1;\n    }\n\n    // Sort by ascending method name if comparing two custom methods\n    // @ts-expect-error -- TSCONVERSION\n    if (aIndex === -1 && a.method.localeCompare(b.method) !== 0) {\n      // @ts-expect-error -- TSCONVERSION\n      return a.method.localeCompare(b.method);\n    }\n  }\n\n  // Sort by metaSortKey if comparing two Requests with the same method,\n  // two GrpcRequests, or two RequestGroups\n  return metaSortKeySort(a, b);\n};\n\nexport const ascendingTypeSort: SortFunction<Pick<SortableModel, 'type' | 'metaSortKey' | '_id'>> = (a, b) => {\n  if (a.type !== b.type && (isRequestGroup(a) || isRequestGroup(b))) {\n    return isRequestGroup(b) ? -1 : 1;\n  }\n\n  return metaSortKeySort(a, b);\n};\n\nexport const descendingTypeSort: SortFunction<Pick<SortableModel, 'type' | 'metaSortKey' | '_id'>> = (a, b) => {\n  if (a.type !== b.type && (isRequestGroup(a) || isRequestGroup(b))) {\n    return isRequestGroup(a) ? -1 : 1;\n  }\n\n  return metaSortKeySort(a, b);\n};\n\nexport const metaSortKeySort: SortFunction<Pick<SortableModel, '_id' | 'metaSortKey'>> = (a, b) => {\n  if (a.metaSortKey === b.metaSortKey) {\n    return a._id > b._id ? -1 : 1;\n  }\n\n  return a.metaSortKey < b.metaSortKey ? -1 : 1;\n};\n\nexport const ascendingNumberSort: SortFunction<number> = (a, b) => {\n  return a < b ? -1 : 1;\n};\n\nexport const descendingNumberSort: SortFunction<number> = (a, b) => {\n  return ascendingNumberSort(b, a);\n};\n\nexport const sortMethodMap = {\n  [SORT_NAME_ASC]: ascendingNameSort,\n  [SORT_NAME_DESC]: descendingNameSort,\n  [SORT_CREATED_ASC]: createdFirstSort,\n  [SORT_CREATED_DESC]: createdLastSort,\n  [SORT_MODIFIED_ASC]: ascendingModifiedSort,\n  [SORT_MODIFIED_DESC]: descendingModifiedSort,\n  [SORT_HTTP_METHOD]: httpMethodSort,\n  [SORT_TYPE_DESC]: descendingTypeSort,\n  [SORT_TYPE_ASC]: ascendingTypeSort,\n  [SORT_TYPE_MANUAL]: metaSortKeySort,\n};",
    "repo": "Kong/insomnia",
    "path": "./datasets/diagrams-repos/Kong/insomnia/packages/insomnia/src/common/sorting.ts",
    "query": "Show the decision process within the httpMethodSort function.",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'httpMethodSort', 'node_id': 'httpMethodSort', 'description': 'Sorts requests based on type and HTTP method', 'visibility': 'public', 'return_type': 'number', 'params': '(a, b)', 'source_class_id': None}, {'type': 'function', 'name': 'isRequest', 'node_id': 'isRequest', 'description': 'Checks if item is HTTP request', 'visibility': 'public', 'return_type': 'boolean', 'params': '(item)', 'source_class_id': None}, {'type': 'function', 'name': 'isGrpcRequest', 'node_id': 'isGrpcRequest', 'description': 'Checks if item is gRPC request', 'visibility': 'public', 'return_type': 'boolean', 'params': '(item)', 'source_class_id': None}, {'type': 'function', 'name': 'metaSortKeySort', 'node_id': 'metaSortKeySort', 'description': 'Sorts by metaSortKey or _id', 'visibility': 'public', 'return_type': 'number', 'params': '(a, b)', 'source_class_id': None}, {'type': 'variable', 'name': 'HTTP_METHODS', 'node_id': 'HTTP_METHODS', 'description': 'Array of standard HTTP methods', 'visibility': 'public', 'return_type': 'array', 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'typeComparison', 'node_id': 'typeComparison', 'description': 'Type comparison logic', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'methodComparison', 'node_id': 'methodComparison', 'description': 'HTTP method comparison logic', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'customMethodComparison', 'node_id': 'customMethodComparison', 'description': 'Custom method comparison logic', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'SortableModel', 'node_id': 'SortableModel', 'description': 'Union type of sortable request types', 'visibility': 'public', 'return_type': 'Request | RequestGroup | GrpcRequest', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'SortFunction', 'node_id': 'SortFunction', 'description': 'Generic type for sort functions', 'visibility': 'public', 'return_type': '(a: SortableType, b: SortableType) => number', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'httpMethodSort', 'node_id_to': 'typeComparison', 'description': 'first step'}, {'node_id_from': 'typeComparison', 'node_id_to': 'isRequest', 'description': 'check type'}, {'node_id_from': 'typeComparison', 'node_id_to': 'isGrpcRequest', 'description': 'check type'}, {'node_id_from': 'httpMethodSort', 'node_id_to': 'methodComparison', 'description': 'second step'}, {'node_id_from': 'methodComparison', 'node_id_to': 'HTTP_METHODS', 'description': 'uses'}, {'node_id_from': 'methodComparison', 'node_id_to': 'customMethodComparison', 'description': 'if custom method'}, {'node_id_from': 'httpMethodSort', 'node_id_to': 'metaSortKeySort', 'description': 'final step'}, {'node_id_from': 'httpMethodSort', 'node_id_to': 'SortableModel', 'description': 'uses type'}, {'node_id_from': 'httpMethodSort', 'node_id_to': 'SortFunction', 'description': 'implements'}], 'packages': [{'package_id': 'sortingLogic', 'children': ['httpMethodSort', 'typeComparison', 'methodComparison', 'customMethodComparison'], 'description': 'Main sorting logic'}, {'package_id': 'typeChecks', 'children': ['isRequest', 'isGrpcRequest'], 'description': 'Type checking functions'}, {'package_id': 'types', 'children': ['SortableModel', 'SortFunction'], 'description': 'Type definitions'}]}",
    "version": "full",
    "text_answer": "The httpMethodSort function follows a three-step decision process: first, it compares request types (HTTP vs gRPC), then sorts HTTP requests by method (standard methods first, then custom methods), and finally falls back to metaSortKey comparison for equal cases.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Kotlin",
    "code": "\npackage com.facebook.react.common.mapbuffer\n\nimport android.util.SparseArray\nimport com.facebook.proguard.annotations.DoNotStrip\nimport com.facebook.react.common.annotations.StableReactNativeAPI\nimport com.facebook.react.common.mapbuffer.MapBuffer.Companion.KEY_RANGE\nimport com.facebook.react.common.mapbuffer.MapBuffer.DataType\nimport javax.annotation.concurrent.NotThreadSafe\n\n/**\n * Implementation of writeable Java-only MapBuffer, which can be used to send information through\n * JNI.\n *\n * See [MapBuffer] for more details\n */\n@StableReactNativeAPI\n@NotThreadSafe\n@DoNotStrip\npublic class WritableMapBuffer : MapBuffer {\n  private val values: SparseArray<Any> = SparseArray<Any>()\n\n  /*\n   * Write methods\n   */\n\n  /**\n   * Adds a boolean value for given key to the MapBuffer.\n   *\n   * @param key entry key\n   * @param value entry value\n   * @throws IllegalArgumentException if key is out of [UShort] range\n   */\n  public fun put(key: Int, value: Boolean): WritableMapBuffer = putInternal(key, value)\n\n  /**\n   * Adds an int value for given key to the MapBuffer.\n   *\n   * @param key entry key\n   * @param value entry value\n   * @throws IllegalArgumentException if key is out of [UShort] range\n   */\n  public fun put(key: Int, value: Int): WritableMapBuffer = putInternal(key, value)\n\n  /**\n   * Adds a long value for given key to the MapBuffer.\n   *\n   * @param key entry key\n   * @param value entry value\n   * @throws IllegalArgumentException if key is out of [UShort] range\n   */\n  public fun put(key: Int, value: Long): WritableMapBuffer = putInternal(key, value)\n\n  /**\n   * Adds a double value for given key to the MapBuffer.\n   *\n   * @param key entry key\n   * @param value entry value\n   * @throws IllegalArgumentException if key is out of [UShort] range\n   */\n  public fun put(key: Int, value: Double): WritableMapBuffer = putInternal(key, value)\n\n  /**\n   * Adds a string value for given key to the MapBuffer.\n   *\n   * @param key entry key\n   * @param value entry value\n   * @throws IllegalArgumentException if key is out of [UShort] range\n   */\n  public fun put(key: Int, value: String): WritableMapBuffer = putInternal(key, value)\n\n  /**\n   * Adds a [MapBuffer] value for given key to the current MapBuffer.\n   *\n   * @param key entry key\n   * @param value entry value\n   * @throws IllegalArgumentException if key is out of [UShort] range\n   */\n  public fun put(key: Int, value: MapBuffer): WritableMapBuffer = putInternal(key, value)\n\n  private fun putInternal(key: Int, value: Any): WritableMapBuffer {\n    require(key in KEY_RANGE) {\n      \"Only integers in [${UShort.MIN_VALUE};${UShort.MAX_VALUE}] range are allowed for keys.\"\n    }\n\n    values.put(key, value)\n    return this\n  }\n\n  /*\n   * Read methods\n   */\n\n  override val count: Int\n    get() = values.size()\n\n  override fun contains(key: Int): Boolean = values.get(key) != null\n\n  override fun getKeyOffset(key: Int): Int = values.indexOfKey(key)\n\n  override fun entryAt(offset: Int): MapBuffer.Entry = MapBufferEntry(offset)\n\n  override fun getType(key: Int): DataType {\n    val value = values.get(key)\n    require(value != null) { \"Key not found: $key\" }\n    return value.dataType(key)\n  }\n\n  override fun getBoolean(key: Int): Boolean = verifyValue(key, values.get(key))\n\n  override fun getInt(key: Int): Int = verifyValue(key, values.get(key))\n\n  override fun getLong(key: Int): Long = verifyValue(key, values.get(key))\n\n  override fun getDouble(key: Int): Double = verifyValue(key, values.get(key))\n\n  override fun getString(key: Int): String = verifyValue(key, values.get(key))\n\n  override fun getMapBuffer(key: Int): MapBuffer = verifyValue(key, values.get(key))\n\n  override fun getMapBufferList(key: Int): List<MapBuffer> = verifyValue(key, values.get(key))\n\n  /** Generalizes verification of the value types based on the requested type. */\n  private inline fun <reified T> verifyValue(key: Int, value: Any?): T {\n    require(value != null) { \"Key not found: $key\" }\n    check(value is T) {\n      \"Expected ${T::class.java} for key: $key, found ${value.javaClass} instead.\"\n    }\n    return value\n  }\n\n  private fun Any.dataType(key: Int): DataType {\n    return when (val value = this) {\n      is Boolean -> DataType.BOOL\n      is Int -> DataType.INT\n      is Long -> DataType.LONG\n      is Double -> DataType.DOUBLE\n      is String -> DataType.STRING\n      is MapBuffer -> DataType.MAP\n      else -> throw IllegalStateException(\"Key $key has value of unknown type: ${value.javaClass}\")\n    }\n  }\n\n  override fun iterator(): Iterator<MapBuffer.Entry> =\n      object : Iterator<MapBuffer.Entry> {\n        var count = 0\n\n        override fun hasNext(): Boolean = count < values.size()\n\n        override fun next(): MapBuffer.Entry = MapBufferEntry(count++)\n      }\n\n  private inner class MapBufferEntry(private val index: Int) : MapBuffer.Entry {\n    override val key: Int = values.keyAt(index)\n    override val type: DataType = values.valueAt(index).dataType(key)\n    override val booleanValue: Boolean\n      get() = verifyValue(key, values.valueAt(index))\n\n    override val intValue: Int\n      get() = verifyValue(key, values.valueAt(index))\n\n    override val longValue: Long\n      get() = verifyValue(key, values.valueAt(index))\n\n    override val doubleValue: Double\n      get() = verifyValue(key, values.valueAt(index))\n\n    override val stringValue: String\n      get() = verifyValue(key, values.valueAt(index))\n\n    override val mapBufferValue: MapBuffer\n      get() = verifyValue(key, values.valueAt(index))\n  }\n\n  /*\n   * JNI hooks\n   */\n\n  @DoNotStrip\n  @Suppress(\"UNUSED\")\n  /** JNI hook for MapBuffer to retrieve sorted keys from this class. */\n  private fun getKeys(): IntArray = IntArray(values.size()) { values.keyAt(it) }\n\n  @DoNotStrip\n  @Suppress(\"UNUSED\")\n  /** JNI hook for MapBuffer to retrieve sorted values from this class. */\n  private fun getValues(): Array<Any> = Array(values.size()) { values.valueAt(it) }\n\n  private companion object {\n    init {\n      MapBufferSoLoader.staticInit()\n    }\n  }\n}",
    "repo": "facebook/react-native",
    "path": "./datasets/diagrams-repos/facebook/react-native/packages/react-native/ReactAndroid/src/main/java/com/facebook/react/common/mapbuffer/WritableMapBuffer.kt",
    "query": "Show the data flow when adding a new entry to the `WritableMapBuffer` using the `put` method.",
    "diagram": "{'nodes': [{'type': 'method', 'name': 'put', 'node_id': 'put', 'description': 'Public method to add entries of different types to MapBuffer', 'visibility': 'public', 'return_type': 'WritableMapBuffer', 'params': '(key: Int, value: Any)', 'source_class_id': 'WritableMapBuffer'}, {'type': 'method', 'name': 'putInternal', 'node_id': 'putInternal', 'description': 'Internal method that validates key and stores value in SparseArray', 'visibility': 'private', 'return_type': 'WritableMapBuffer', 'params': '(key: Int, value: Any)', 'source_class_id': 'WritableMapBuffer'}, {'type': 'field', 'name': 'values', 'node_id': 'values', 'description': 'SparseArray storing key-value pairs', 'visibility': 'private', 'return_type': 'SparseArray<Any>', 'params': None, 'source_class_id': 'WritableMapBuffer'}, {'type': 'class', 'name': 'WritableMapBuffer', 'node_id': 'WritableMapBuffer', 'description': 'Implementation of writable MapBuffer for JNI communication', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'put', 'node_id_to': 'putInternal', 'description': 'delegates actual storage'}, {'node_id_from': 'putInternal', 'node_id_to': 'values', 'description': 'stores value'}, {'node_id_from': 'WritableMapBuffer', 'node_id_to': 'put', 'description': ''}, {'node_id_from': 'WritableMapBuffer', 'node_id_to': 'putInternal', 'description': ''}, {'node_id_from': 'WritableMapBuffer', 'node_id_to': 'values', 'description': ''}], 'packages': [{'package_id': 'writableMapBuffer', 'children': ['put', 'putInternal', 'values'], 'description': 'Core components for writing to MapBuffer'}]}",
    "version": "minimal",
    "text_answer": "When adding a new entry to WritableMapBuffer, the public put method delegates to putInternal, which validates the key against KEY_RANGE and stores the value in the internal SparseArray.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Kotlin",
    "code": "\npackage com.facebook.react.common.mapbuffer\n\nimport android.util.SparseArray\nimport com.facebook.proguard.annotations.DoNotStrip\nimport com.facebook.react.common.annotations.StableReactNativeAPI\nimport com.facebook.react.common.mapbuffer.MapBuffer.Companion.KEY_RANGE\nimport com.facebook.react.common.mapbuffer.MapBuffer.DataType\nimport javax.annotation.concurrent.NotThreadSafe\n\n/**\n * Implementation of writeable Java-only MapBuffer, which can be used to send information through\n * JNI.\n *\n * See [MapBuffer] for more details\n */\n@StableReactNativeAPI\n@NotThreadSafe\n@DoNotStrip\npublic class WritableMapBuffer : MapBuffer {\n  private val values: SparseArray<Any> = SparseArray<Any>()\n\n  /*\n   * Write methods\n   */\n\n  /**\n   * Adds a boolean value for given key to the MapBuffer.\n   *\n   * @param key entry key\n   * @param value entry value\n   * @throws IllegalArgumentException if key is out of [UShort] range\n   */\n  public fun put(key: Int, value: Boolean): WritableMapBuffer = putInternal(key, value)\n\n  /**\n   * Adds an int value for given key to the MapBuffer.\n   *\n   * @param key entry key\n   * @param value entry value\n   * @throws IllegalArgumentException if key is out of [UShort] range\n   */\n  public fun put(key: Int, value: Int): WritableMapBuffer = putInternal(key, value)\n\n  /**\n   * Adds a long value for given key to the MapBuffer.\n   *\n   * @param key entry key\n   * @param value entry value\n   * @throws IllegalArgumentException if key is out of [UShort] range\n   */\n  public fun put(key: Int, value: Long): WritableMapBuffer = putInternal(key, value)\n\n  /**\n   * Adds a double value for given key to the MapBuffer.\n   *\n   * @param key entry key\n   * @param value entry value\n   * @throws IllegalArgumentException if key is out of [UShort] range\n   */\n  public fun put(key: Int, value: Double): WritableMapBuffer = putInternal(key, value)\n\n  /**\n   * Adds a string value for given key to the MapBuffer.\n   *\n   * @param key entry key\n   * @param value entry value\n   * @throws IllegalArgumentException if key is out of [UShort] range\n   */\n  public fun put(key: Int, value: String): WritableMapBuffer = putInternal(key, value)\n\n  /**\n   * Adds a [MapBuffer] value for given key to the current MapBuffer.\n   *\n   * @param key entry key\n   * @param value entry value\n   * @throws IllegalArgumentException if key is out of [UShort] range\n   */\n  public fun put(key: Int, value: MapBuffer): WritableMapBuffer = putInternal(key, value)\n\n  private fun putInternal(key: Int, value: Any): WritableMapBuffer {\n    require(key in KEY_RANGE) {\n      \"Only integers in [${UShort.MIN_VALUE};${UShort.MAX_VALUE}] range are allowed for keys.\"\n    }\n\n    values.put(key, value)\n    return this\n  }\n\n  /*\n   * Read methods\n   */\n\n  override val count: Int\n    get() = values.size()\n\n  override fun contains(key: Int): Boolean = values.get(key) != null\n\n  override fun getKeyOffset(key: Int): Int = values.indexOfKey(key)\n\n  override fun entryAt(offset: Int): MapBuffer.Entry = MapBufferEntry(offset)\n\n  override fun getType(key: Int): DataType {\n    val value = values.get(key)\n    require(value != null) { \"Key not found: $key\" }\n    return value.dataType(key)\n  }\n\n  override fun getBoolean(key: Int): Boolean = verifyValue(key, values.get(key))\n\n  override fun getInt(key: Int): Int = verifyValue(key, values.get(key))\n\n  override fun getLong(key: Int): Long = verifyValue(key, values.get(key))\n\n  override fun getDouble(key: Int): Double = verifyValue(key, values.get(key))\n\n  override fun getString(key: Int): String = verifyValue(key, values.get(key))\n\n  override fun getMapBuffer(key: Int): MapBuffer = verifyValue(key, values.get(key))\n\n  override fun getMapBufferList(key: Int): List<MapBuffer> = verifyValue(key, values.get(key))\n\n  /** Generalizes verification of the value types based on the requested type. */\n  private inline fun <reified T> verifyValue(key: Int, value: Any?): T {\n    require(value != null) { \"Key not found: $key\" }\n    check(value is T) {\n      \"Expected ${T::class.java} for key: $key, found ${value.javaClass} instead.\"\n    }\n    return value\n  }\n\n  private fun Any.dataType(key: Int): DataType {\n    return when (val value = this) {\n      is Boolean -> DataType.BOOL\n      is Int -> DataType.INT\n      is Long -> DataType.LONG\n      is Double -> DataType.DOUBLE\n      is String -> DataType.STRING\n      is MapBuffer -> DataType.MAP\n      else -> throw IllegalStateException(\"Key $key has value of unknown type: ${value.javaClass}\")\n    }\n  }\n\n  override fun iterator(): Iterator<MapBuffer.Entry> =\n      object : Iterator<MapBuffer.Entry> {\n        var count = 0\n\n        override fun hasNext(): Boolean = count < values.size()\n\n        override fun next(): MapBuffer.Entry = MapBufferEntry(count++)\n      }\n\n  private inner class MapBufferEntry(private val index: Int) : MapBuffer.Entry {\n    override val key: Int = values.keyAt(index)\n    override val type: DataType = values.valueAt(index).dataType(key)\n    override val booleanValue: Boolean\n      get() = verifyValue(key, values.valueAt(index))\n\n    override val intValue: Int\n      get() = verifyValue(key, values.valueAt(index))\n\n    override val longValue: Long\n      get() = verifyValue(key, values.valueAt(index))\n\n    override val doubleValue: Double\n      get() = verifyValue(key, values.valueAt(index))\n\n    override val stringValue: String\n      get() = verifyValue(key, values.valueAt(index))\n\n    override val mapBufferValue: MapBuffer\n      get() = verifyValue(key, values.valueAt(index))\n  }\n\n  /*\n   * JNI hooks\n   */\n\n  @DoNotStrip\n  @Suppress(\"UNUSED\")\n  /** JNI hook for MapBuffer to retrieve sorted keys from this class. */\n  private fun getKeys(): IntArray = IntArray(values.size()) { values.keyAt(it) }\n\n  @DoNotStrip\n  @Suppress(\"UNUSED\")\n  /** JNI hook for MapBuffer to retrieve sorted values from this class. */\n  private fun getValues(): Array<Any> = Array(values.size()) { values.valueAt(it) }\n\n  private companion object {\n    init {\n      MapBufferSoLoader.staticInit()\n    }\n  }\n}",
    "repo": "facebook/react-native",
    "path": "./datasets/diagrams-repos/facebook/react-native/packages/react-native/ReactAndroid/src/main/java/com/facebook/react/common/mapbuffer/WritableMapBuffer.kt",
    "query": "Show the data flow when adding a new entry to the `WritableMapBuffer` using the `put` method.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'WritableMapBuffer', 'node_id': 'WritableMapBuffer', 'description': 'Implementation of writable MapBuffer for JNI communication', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'put', 'node_id': 'put', 'description': 'Public method to add entries of different types to MapBuffer', 'visibility': 'public', 'return_type': 'WritableMapBuffer', 'params': '(key: Int, value: Any)', 'source_class_id': 'WritableMapBuffer'}, {'type': 'method', 'name': 'putInternal', 'node_id': 'putInternal', 'description': 'Internal method that validates key and stores value in SparseArray', 'visibility': 'private', 'return_type': 'WritableMapBuffer', 'params': '(key: Int, value: Any)', 'source_class_id': 'WritableMapBuffer'}, {'type': 'field', 'name': 'values', 'node_id': 'values', 'description': 'SparseArray storing key-value pairs', 'visibility': 'private', 'return_type': 'SparseArray<Any>', 'params': None, 'source_class_id': 'WritableMapBuffer'}, {'type': 'entity', 'name': 'KEY_RANGE', 'node_id': 'KEY_RANGE', 'description': 'Valid range for keys (UShort range)', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'put', 'node_id_to': 'putInternal', 'description': 'delegates storage'}, {'node_id_from': 'putInternal', 'node_id_to': 'KEY_RANGE', 'description': 'validates key'}, {'node_id_from': 'putInternal', 'node_id_to': 'values', 'description': 'stores value'}, {'node_id_from': 'WritableMapBuffer', 'node_id_to': 'put', 'description': ''}, {'node_id_from': 'WritableMapBuffer', 'node_id_to': 'putInternal', 'description': ''}, {'node_id_from': 'WritableMapBuffer', 'node_id_to': 'values', 'description': ''}], 'packages': [{'package_id': 'writableMapBuffer', 'children': ['WritableMapBuffer', 'put', 'putInternal', 'values', 'KEY_RANGE'], 'description': 'Components for writing to MapBuffer'}]}",
    "version": "medium",
    "text_answer": "When adding a new entry to WritableMapBuffer, the public put method delegates to putInternal, which validates the key against KEY_RANGE and stores the value in the internal SparseArray.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Kotlin",
    "code": "\npackage com.facebook.react.common.mapbuffer\n\nimport android.util.SparseArray\nimport com.facebook.proguard.annotations.DoNotStrip\nimport com.facebook.react.common.annotations.StableReactNativeAPI\nimport com.facebook.react.common.mapbuffer.MapBuffer.Companion.KEY_RANGE\nimport com.facebook.react.common.mapbuffer.MapBuffer.DataType\nimport javax.annotation.concurrent.NotThreadSafe\n\n/**\n * Implementation of writeable Java-only MapBuffer, which can be used to send information through\n * JNI.\n *\n * See [MapBuffer] for more details\n */\n@StableReactNativeAPI\n@NotThreadSafe\n@DoNotStrip\npublic class WritableMapBuffer : MapBuffer {\n  private val values: SparseArray<Any> = SparseArray<Any>()\n\n  /*\n   * Write methods\n   */\n\n  /**\n   * Adds a boolean value for given key to the MapBuffer.\n   *\n   * @param key entry key\n   * @param value entry value\n   * @throws IllegalArgumentException if key is out of [UShort] range\n   */\n  public fun put(key: Int, value: Boolean): WritableMapBuffer = putInternal(key, value)\n\n  /**\n   * Adds an int value for given key to the MapBuffer.\n   *\n   * @param key entry key\n   * @param value entry value\n   * @throws IllegalArgumentException if key is out of [UShort] range\n   */\n  public fun put(key: Int, value: Int): WritableMapBuffer = putInternal(key, value)\n\n  /**\n   * Adds a long value for given key to the MapBuffer.\n   *\n   * @param key entry key\n   * @param value entry value\n   * @throws IllegalArgumentException if key is out of [UShort] range\n   */\n  public fun put(key: Int, value: Long): WritableMapBuffer = putInternal(key, value)\n\n  /**\n   * Adds a double value for given key to the MapBuffer.\n   *\n   * @param key entry key\n   * @param value entry value\n   * @throws IllegalArgumentException if key is out of [UShort] range\n   */\n  public fun put(key: Int, value: Double): WritableMapBuffer = putInternal(key, value)\n\n  /**\n   * Adds a string value for given key to the MapBuffer.\n   *\n   * @param key entry key\n   * @param value entry value\n   * @throws IllegalArgumentException if key is out of [UShort] range\n   */\n  public fun put(key: Int, value: String): WritableMapBuffer = putInternal(key, value)\n\n  /**\n   * Adds a [MapBuffer] value for given key to the current MapBuffer.\n   *\n   * @param key entry key\n   * @param value entry value\n   * @throws IllegalArgumentException if key is out of [UShort] range\n   */\n  public fun put(key: Int, value: MapBuffer): WritableMapBuffer = putInternal(key, value)\n\n  private fun putInternal(key: Int, value: Any): WritableMapBuffer {\n    require(key in KEY_RANGE) {\n      \"Only integers in [${UShort.MIN_VALUE};${UShort.MAX_VALUE}] range are allowed for keys.\"\n    }\n\n    values.put(key, value)\n    return this\n  }\n\n  /*\n   * Read methods\n   */\n\n  override val count: Int\n    get() = values.size()\n\n  override fun contains(key: Int): Boolean = values.get(key) != null\n\n  override fun getKeyOffset(key: Int): Int = values.indexOfKey(key)\n\n  override fun entryAt(offset: Int): MapBuffer.Entry = MapBufferEntry(offset)\n\n  override fun getType(key: Int): DataType {\n    val value = values.get(key)\n    require(value != null) { \"Key not found: $key\" }\n    return value.dataType(key)\n  }\n\n  override fun getBoolean(key: Int): Boolean = verifyValue(key, values.get(key))\n\n  override fun getInt(key: Int): Int = verifyValue(key, values.get(key))\n\n  override fun getLong(key: Int): Long = verifyValue(key, values.get(key))\n\n  override fun getDouble(key: Int): Double = verifyValue(key, values.get(key))\n\n  override fun getString(key: Int): String = verifyValue(key, values.get(key))\n\n  override fun getMapBuffer(key: Int): MapBuffer = verifyValue(key, values.get(key))\n\n  override fun getMapBufferList(key: Int): List<MapBuffer> = verifyValue(key, values.get(key))\n\n  /** Generalizes verification of the value types based on the requested type. */\n  private inline fun <reified T> verifyValue(key: Int, value: Any?): T {\n    require(value != null) { \"Key not found: $key\" }\n    check(value is T) {\n      \"Expected ${T::class.java} for key: $key, found ${value.javaClass} instead.\"\n    }\n    return value\n  }\n\n  private fun Any.dataType(key: Int): DataType {\n    return when (val value = this) {\n      is Boolean -> DataType.BOOL\n      is Int -> DataType.INT\n      is Long -> DataType.LONG\n      is Double -> DataType.DOUBLE\n      is String -> DataType.STRING\n      is MapBuffer -> DataType.MAP\n      else -> throw IllegalStateException(\"Key $key has value of unknown type: ${value.javaClass}\")\n    }\n  }\n\n  override fun iterator(): Iterator<MapBuffer.Entry> =\n      object : Iterator<MapBuffer.Entry> {\n        var count = 0\n\n        override fun hasNext(): Boolean = count < values.size()\n\n        override fun next(): MapBuffer.Entry = MapBufferEntry(count++)\n      }\n\n  private inner class MapBufferEntry(private val index: Int) : MapBuffer.Entry {\n    override val key: Int = values.keyAt(index)\n    override val type: DataType = values.valueAt(index).dataType(key)\n    override val booleanValue: Boolean\n      get() = verifyValue(key, values.valueAt(index))\n\n    override val intValue: Int\n      get() = verifyValue(key, values.valueAt(index))\n\n    override val longValue: Long\n      get() = verifyValue(key, values.valueAt(index))\n\n    override val doubleValue: Double\n      get() = verifyValue(key, values.valueAt(index))\n\n    override val stringValue: String\n      get() = verifyValue(key, values.valueAt(index))\n\n    override val mapBufferValue: MapBuffer\n      get() = verifyValue(key, values.valueAt(index))\n  }\n\n  /*\n   * JNI hooks\n   */\n\n  @DoNotStrip\n  @Suppress(\"UNUSED\")\n  /** JNI hook for MapBuffer to retrieve sorted keys from this class. */\n  private fun getKeys(): IntArray = IntArray(values.size()) { values.keyAt(it) }\n\n  @DoNotStrip\n  @Suppress(\"UNUSED\")\n  /** JNI hook for MapBuffer to retrieve sorted values from this class. */\n  private fun getValues(): Array<Any> = Array(values.size()) { values.valueAt(it) }\n\n  private companion object {\n    init {\n      MapBufferSoLoader.staticInit()\n    }\n  }\n}",
    "repo": "facebook/react-native",
    "path": "./datasets/diagrams-repos/facebook/react-native/packages/react-native/ReactAndroid/src/main/java/com/facebook/react/common/mapbuffer/WritableMapBuffer.kt",
    "query": "Show the data flow when adding a new entry to the `WritableMapBuffer` using the `put` method.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'WritableMapBuffer', 'node_id': 'WritableMapBuffer', 'description': 'Implementation of writable MapBuffer for JNI communication', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'put', 'node_id': 'put_boolean', 'description': 'Adds boolean value to MapBuffer', 'visibility': 'public', 'return_type': 'WritableMapBuffer', 'params': '(key: Int, value: Boolean)', 'source_class_id': 'WritableMapBuffer'}, {'type': 'method', 'name': 'put', 'node_id': 'put_int', 'description': 'Adds int value to MapBuffer', 'visibility': 'public', 'return_type': 'WritableMapBuffer', 'params': '(key: Int, value: Int)', 'source_class_id': 'WritableMapBuffer'}, {'type': 'method', 'name': 'put', 'node_id': 'put_double', 'description': 'Adds double value to MapBuffer', 'visibility': 'public', 'return_type': 'WritableMapBuffer', 'params': '(key: Int, value: Double)', 'source_class_id': 'WritableMapBuffer'}, {'type': 'method', 'name': 'put', 'node_id': 'put_string', 'description': 'Adds string value to MapBuffer', 'visibility': 'public', 'return_type': 'WritableMapBuffer', 'params': '(key: Int, value: String)', 'source_class_id': 'WritableMapBuffer'}, {'type': 'method', 'name': 'putInternal', 'node_id': 'putInternal', 'description': 'Internal method that validates key and stores value in SparseArray', 'visibility': 'private', 'return_type': 'WritableMapBuffer', 'params': '(key: Int, value: Any)', 'source_class_id': 'WritableMapBuffer'}, {'type': 'field', 'name': 'values', 'node_id': 'values', 'description': 'SparseArray storing key-value pairs', 'visibility': 'private', 'return_type': 'SparseArray<Any>', 'params': None, 'source_class_id': 'WritableMapBuffer'}, {'type': 'entity', 'name': 'KEY_RANGE', 'node_id': 'KEY_RANGE', 'description': 'Valid range for keys (UShort range)', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'MapBufferSoLoader', 'node_id': 'MapBufferSoLoader', 'description': 'Native code loader for MapBuffer', 'visibility': 'package private', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'put_boolean', 'node_id_to': 'putInternal', 'description': 'delegates boolean storage'}, {'node_id_from': 'put_int', 'node_id_to': 'putInternal', 'description': 'delegates int storage'}, {'node_id_from': 'put_double', 'node_id_to': 'putInternal', 'description': 'delegates double storage'}, {'node_id_from': 'put_string', 'node_id_to': 'putInternal', 'description': 'delegates string storage'}, {'node_id_from': 'putInternal', 'node_id_to': 'KEY_RANGE', 'description': 'validates key'}, {'node_id_from': 'putInternal', 'node_id_to': 'values', 'description': 'stores value'}, {'node_id_from': 'WritableMapBuffer', 'node_id_to': 'MapBufferSoLoader', 'description': 'initializes native code'}, {'node_id_from': 'WritableMapBuffer', 'node_id_to': 'put_boolean', 'description': ''}, {'node_id_from': 'WritableMapBuffer', 'node_id_to': 'put_int', 'description': ''}, {'node_id_from': 'WritableMapBuffer', 'node_id_to': 'put_double', 'description': ''}, {'node_id_from': 'WritableMapBuffer', 'node_id_to': 'put_string', 'description': ''}, {'node_id_from': 'WritableMapBuffer', 'node_id_to': 'putInternal', 'description': ''}, {'node_id_from': 'WritableMapBuffer', 'node_id_to': 'values', 'description': ''}], 'packages': [{'package_id': 'writableMapBuffer', 'children': ['WritableMapBuffer', 'put_boolean', 'put_int', 'put_double', 'put_string', 'putInternal', 'values', 'KEY_RANGE', 'MapBufferSoLoader'], 'description': 'Complete system for writing to MapBuffer'}]}",
    "version": "full",
    "text_answer": "When adding a new entry to WritableMapBuffer, the public put method delegates to putInternal, which validates the key against KEY_RANGE and stores the value in the internal SparseArray.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport {MDCList} from '../../mdc-list/index';\nimport {createFixture, html} from '../../../testing/dom';\nimport {emitEvent} from '../../../testing/dom/events';\nimport {createMockFoundation} from '../../../testing/helpers/foundation';\nimport {setUpMdcTestEnvironment} from '../../../testing/helpers/setup';\nimport {cssClasses, strings} from '../constants';\nimport {MDCDismissibleDrawerFoundation} from '../dismissible/foundation';\nimport {MDCDrawer} from '../index';\nimport {MDCModalDrawerFoundation} from '../modal/foundation';\n\ninterface DrawerSetupOptions {\n  variantClass: string;\n  shadowRoot: boolean;\n  hasList: boolean;\n}\n\nconst defaultSetupOptions = {\n  variantClass: cssClasses.DISMISSIBLE,\n  shadowRoot: false,\n  hasList: true\n};\n\nfunction getDrawerFixture(options: Partial<DrawerSetupOptions>): HTMLElement|\n    DocumentFragment {\n  const listContent = html`\n    <div class=\"mdc-deprecated-list-group\">\n      <nav class=\"mdc-deprecated-list\">\n        <a class=\"mdc-deprecated-list-item mdc-deprecated-list-item--activated\" href=\"#\" aria-current=\"page\">\n          <i class=\"material-icons mdc-deprecated-list-item__graphic\" aria-hidden=\"true\">inbox</i>Inbox\n        </a>\n      </nav>\n    </div>\n    `;\n  const drawerContent = html`\n    <div class=\"mdc-drawer ${options.variantClass}\">\n      <div class=\"mdc-drawer__content\">\n        ${options.hasList ? listContent : ''}\n      </div>\n    </div>\n    `;\n  const scrimContent = html`<div class=\"mdc-drawer-scrim\"></div>`;\n  const isModal = options.variantClass === cssClasses.MODAL;\n  const drawerEl = createFixture(drawerContent);\n  const scrimEl = createFixture(scrimContent);\n\n  if (options.shadowRoot) {\n    const fragment = document.createDocumentFragment();\n    fragment.appendChild(drawerEl);\n    if (isModal) {\n      fragment.appendChild(scrimEl);\n    }\n    return fragment;\n  } else {\n    return createFixture(html`\n      <div class=\"body-content\">\n        ${drawerContent}\n        ${isModal ? scrimContent : ''}\n      </div>`);\n  }\n}\n\nfunction setupTest(options: Partial<DrawerSetupOptions> = defaultSetupOptions) {\n  const root = getDrawerFixture(options);\n  const drawer = root.querySelector<HTMLElement>('.mdc-drawer')!;\n  const component = new MDCDrawer(drawer);\n  return {root, drawer, component};\n}\n\nfunction setupTestWithMocks(\n    options: Partial<DrawerSetupOptions> = defaultSetupOptions) {\n  const root = getDrawerFixture(options);\n  const drawer = root.querySelector<HTMLElement>('.mdc-drawer')!;\n  const isModal = options.variantClass === cssClasses.MODAL;\n  const mockFoundation = createMockFoundation(\n      isModal ? MDCModalDrawerFoundation : MDCDismissibleDrawerFoundation);\n  const mockFocusTrapInstance =\n      jasmine.createSpyObj('FocusTrapInstance', ['trapFocus', 'releaseFocus']);\n  const mockList = jasmine.createSpyObj('MDCList', ['wrapFocus', 'destroy']);\n  const component = new MDCDrawer(\n      drawer, mockFoundation, () => mockFocusTrapInstance, () => mockList);\n  return {\n    root,\n    drawer,\n    component,\n    mockFoundation,\n    mockFocusTrapInstance,\n    mockList\n  };\n}\n\ndescribe('MDCDrawer', () => {\n  setUpMdcTestEnvironment();\n\n  it('attachTo initializes and returns a MDCDrawer instance', () => {\n    const root = getDrawerFixture({\n                   variantClass: cssClasses.DISMISSIBLE,\n                   hasList: false\n                 }).querySelector<HTMLElement>('.mdc-drawer')!;\n    expect(MDCDrawer.attachTo(root)).toEqual(jasmine.any(MDCDrawer));\n  });\n\n  it('#get open calls foundation.isOpen', () => {\n    const {component, mockFoundation} = setupTestWithMocks();\n    component.open;\n    expect(mockFoundation.isOpen).toHaveBeenCalledTimes(1);\n  });\n\n  it('#set open true calls foundation.open', () => {\n    const {component, mockFoundation} = setupTestWithMocks();\n    component.open = true;\n    expect(mockFoundation.open).toHaveBeenCalledTimes(1);\n  });\n\n  it('#set open false calls foundation.close', () => {\n    const {component, mockFoundation} = setupTestWithMocks();\n    component.open = false;\n    expect(mockFoundation.close).toHaveBeenCalledTimes(1);\n  });\n\n  it('#get list returns MDCList instance when DOM includes list', () => {\n    const {component} = setupTest();\n    expect(component.list).toEqual(jasmine.any(MDCList));\n  });\n\n  it('click event calls foundation.handleScrimClick method', () => {\n    const {root, mockFoundation} =\n        setupTestWithMocks({variantClass: cssClasses.MODAL});\n    const scrimEl = root.querySelector<HTMLElement>('.mdc-drawer-scrim')!;\n    emitEvent(scrimEl, 'click');\n    expect((mockFoundation as jasmine.SpyObj<MDCModalDrawerFoundation>)\n               .handleScrimClick)\n        .toHaveBeenCalledTimes(1);\n  });\n\n  it('keydown event calls foundation.handleKeydown method', () => {\n    const {drawer, mockFoundation} = setupTestWithMocks();\n    // TODO(b/182902089): use list constants once code is migrated to evolution.\n    (drawer.querySelector<HTMLElement>('.mdc-deprecated-list-item') as\n     HTMLElement)\n        .focus();\n    emitEvent(drawer, 'keydown');\n    expect(mockFoundation.handleKeydown)\n        .toHaveBeenCalledWith(jasmine.any(Object));\n    expect(mockFoundation.handleKeydown).toHaveBeenCalledTimes(1);\n  });\n\n  it('transitionend event calls foundation.handleTransitionEnd method', () => {\n    const {drawer, mockFoundation} = setupTestWithMocks();\n    emitEvent(drawer, 'transitionend');\n    expect(mockFoundation.handleTransitionEnd)\n        .toHaveBeenCalledWith(jasmine.any(Object));\n    expect(mockFoundation.handleTransitionEnd).toHaveBeenCalledTimes(1);\n  });\n\n  it('component should throw error when invalid variant class name is used or no variant specified',\n     () => {\n       expect(\n           () => setupTest({variantClass: 'mdc-drawer--test-invalid-variant'}))\n           .toThrow();\n       expect(() => setupTest({variantClass: ' '})).toThrow();\n     });\n\n  it('#destroy removes keydown event listener', () => {\n    const {component, drawer, mockFoundation} = setupTestWithMocks();\n    component.destroy();\n    // TODO(b/182902089): use list constants once code is migrated to evolution.\n    (drawer.querySelector<HTMLElement>('.mdc-deprecated-list-item') as\n     HTMLElement)\n        .focus();\n    emitEvent(drawer, 'keydown');\n    expect(mockFoundation.handleKeydown)\n        .not.toHaveBeenCalledWith(jasmine.any(Object));\n  });\n\n  it('#destroy removes transitionend event listener', () => {\n    const {component, drawer, mockFoundation} = setupTestWithMocks();\n    component.destroy();\n\n    emitEvent(drawer, 'transitionend');\n    expect(mockFoundation.handleTransitionEnd)\n        .not.toHaveBeenCalledWith(jasmine.any(Object));\n  });\n\n  it('#destroy calls destroy on list', () => {\n    const {component, mockList} = setupTestWithMocks();\n    component.destroy();\n\n    expect(mockList.destroy).toHaveBeenCalledTimes(1);\n  });\n\n  it('#destroy does not throw an error when list is not present', () => {\n    const {component, mockList} =\n        setupTestWithMocks({variantClass: cssClasses.MODAL, hasList: false});\n    component.destroy();\n\n    expect(mockList.destroy).not.toHaveBeenCalled();\n  });\n\n  it('adapter#addClass adds class to drawer', () => {\n    const {component, drawer} = setupTest();\n    (component.getDefaultFoundation() as any).adapter.addClass('test-class');\n    expect(drawer).toHaveClass('test-class');\n  });\n\n  it('adapter#removeClass removes class from drawer', () => {\n    const {component, drawer} = setupTest();\n    (component.getDefaultFoundation() as any).adapter.addClass('test-class');\n\n    (component.getDefaultFoundation() as any).adapter.removeClass('test-class');\n    expect(drawer).not.toHaveClass('test-class');\n  });\n\n  it('adapter#hasClass returns true when class is on drawer element', () => {\n    const {component} = setupTest();\n    (component.getDefaultFoundation() as any).adapter.addClass('test-class');\n    const hasClass = (component.getDefaultFoundation() as any)\n                         .adapter.hasClass('test-class');\n    expect(hasClass).toBe(true);\n  });\n\n  it('adapter#hasClass returns false when there is no class on drawer element',\n     () => {\n       const {component} = setupTest();\n       const hasClass = (component.getDefaultFoundation() as any)\n                            .adapter.hasClass('test-class');\n       expect(hasClass).toBe(false);\n     });\n\n  it('adapter#elementHasClass returns true when class is found on event target',\n     () => {\n       const {component} = setupTest();\n       const mockEventTarget = createFixture(html`<div class=\"foo\">bar</div>`);\n\n       expect((component.getDefaultFoundation() as any)\n                  .adapter.elementHasClass(mockEventTarget, 'foo'))\n           .toBe(true);\n     });\n\n  it('adapter#restoreFocus restores focus to previously saved focus', () => {\n    const {component, root} = setupTest();\n    const button = createFixture(html`<button>Foo</button>`);\n    document.body.appendChild(button);\n    document.body.appendChild(root);\n    button.focus();\n\n    (component.getDefaultFoundation() as any).adapter.saveFocus();\n    (root.querySelector<HTMLElement>(strings.LIST_ITEM_ACTIVATED_SELECTOR) as\n     HTMLElement)\n        .focus();\n    (component.getDefaultFoundation() as any).adapter.restoreFocus();\n\n    expect(button).toEqual(document.activeElement as HTMLElement);\n    document.body.removeChild(button);\n    document.body.removeChild(root);\n  });\n\n  it('adapter#restoreFocus focus shouldn\\'t restore if focus is not within root element',\n     () => {\n       const {component, root} = setupTest();\n       const navButtonEl = createFixture(html`<button>Foo</button>`);\n       const otherButtonEl = createFixture(html`<button>Bar</button>`);\n       document.body.appendChild(navButtonEl);\n       document.body.appendChild(otherButtonEl);\n       document.body.appendChild(root);\n       navButtonEl.focus();\n\n       (component.getDefaultFoundation() as any).adapter.saveFocus();\n       otherButtonEl.focus();\n       (component.getDefaultFoundation() as any).adapter.restoreFocus();\n\n       expect(navButtonEl).not.toBe(document.activeElement as HTMLElement);\n       document.body.removeChild(navButtonEl);\n       document.body.removeChild(otherButtonEl);\n       document.body.removeChild(root);\n     });\n\n  it('adapter#restoreFocus focus is not restored if saveFocus never called',\n     () => {\n       const {component, root} = setupTest();\n       const button = createFixture(html`<button>Foo</button>`);\n       document.body.appendChild(button);\n       document.body.appendChild(root);\n       button.focus();\n\n       const navItem = root.querySelector<HTMLElement>(\n           strings.LIST_ITEM_ACTIVATED_SELECTOR)!;\n       navItem.focus();\n       (component.getDefaultFoundation() as any).adapter.restoreFocus();\n\n       expect(document.activeElement).toEqual(navItem);\n       document.body.removeChild(button);\n       document.body.removeChild(root);\n     });\n\n  it('adapter#trapFocus traps focus on root element', () => {\n    const {component, mockFocusTrapInstance} =\n        setupTestWithMocks({variantClass: cssClasses.MODAL});\n    (component.getDefaultFoundation() as any).adapter.trapFocus();\n\n    expect(mockFocusTrapInstance.trapFocus).toHaveBeenCalled();\n  });\n\n  it('adapter#releaseFocus releases focus on root element after trap focus',\n     () => {\n       const {component, mockFocusTrapInstance} =\n           setupTestWithMocks({variantClass: cssClasses.MODAL});\n       (component.getDefaultFoundation() as any).adapter.releaseFocus();\n\n       expect(mockFocusTrapInstance.releaseFocus).toHaveBeenCalled();\n     });\n\n  it('adapter#notifyOpen emits drawer open event', () => {\n    const {component} = setupTest();\n\n    const handler = jasmine.createSpy('openHandler');\n\n    component.listen(strings.OPEN_EVENT, handler);\n    (component.getDefaultFoundation() as any).adapter.notifyOpen();\n\n    expect(handler).toHaveBeenCalledWith(jasmine.anything());\n  });\n\n  it('adapter#notifyClose emits drawer close event', () => {\n    const {component} = setupTest();\n\n    const handler = jasmine.createSpy('closeHandler');\n\n    component.listen(strings.CLOSE_EVENT, handler);\n    (component.getDefaultFoundation() as any).adapter.notifyClose();\n\n    expect(handler).toHaveBeenCalledWith(jasmine.anything());\n  });\n\n  it('adapter#focusActiveNavigationItem focuses on active navigation item',\n     () => {\n       const {component, root} = setupTest();\n       document.body.appendChild(root);\n       (component.getDefaultFoundation() as any)\n           .adapter.focusActiveNavigationItem();\n\n       const activatedNavigationItemEl = root.querySelector<HTMLElement>(\n           strings.LIST_ITEM_ACTIVATED_SELECTOR);\n       expect(document.activeElement).toEqual(activatedNavigationItemEl);\n       document.body.removeChild(root);\n     });\n\n  it('adapter#focusActiveNavigationItem does nothing if no active navigation item exists',\n     () => {\n       const {component, root} = setupTest();\n       const prevActiveElement = document.activeElement;\n       document.body.appendChild(root);\n       const activatedNavigationItemEl = root.querySelector<HTMLElement>(\n           strings.LIST_ITEM_ACTIVATED_SELECTOR)!;\n       // TODO(b/182902089): use list constants once code has been migrated.\n       activatedNavigationItemEl.classList.remove(\n           'mdc-deprecated-list-item--activated');\n       (component.getDefaultFoundation() as any)\n           .adapter.focusActiveNavigationItem();\n\n       expect(document.activeElement).toEqual(prevActiveElement);\n       document.body.removeChild(root);\n     });\n\n  it('#initialSyncWithDOM should not throw any errors when DOM rendered in DocumentFragment i.e., Shadow DOM',\n     () => {\n       const {component} =\n           setupTest({variantClass: cssClasses.MODAL, shadowRoot: true});\n       expect(() => component.initialSyncWithDOM).not.toThrow();\n     });\n});",
    "repo": "material-components/material-components-web",
    "path": "./datasets/diagrams-repos/material-components/material-components-web/packages/mdc-drawer/test/component.test.ts",
    "query": "Show how MDCDrawer interacts with MDCList and its foundation. Include the flow of methods and properties.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'MDCDrawer', 'node_id': 'MDCDrawer', 'description': 'Main drawer component class', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MDCList', 'node_id': 'MDCList', 'description': 'List component used within drawer', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MDCDismissibleDrawerFoundation', 'node_id': 'MDCDismissibleDrawerFoundation', 'description': 'Foundation class for dismissible drawer variant', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'list', 'node_id': 'list', 'description': 'Getter for MDCList instance', 'visibility': 'public', 'return_type': 'MDCList', 'params': None, 'source_class_id': 'MDCList'}], 'edges': [{'node_id_from': 'MDCDrawer', 'node_id_to': 'MDCList', 'description': 'contains'}, {'node_id_from': 'MDCDrawer', 'node_id_to': 'MDCDismissibleDrawerFoundation', 'description': 'uses'}, {'node_id_from': 'MDCList', 'node_id_to': 'list', 'description': ''}], 'packages': [{'package_id': 'drawerComponents', 'children': ['MDCDrawer', 'MDCDismissibleDrawerFoundation', 'list'], 'description': 'Core drawer components'}]}",
    "version": "minimal",
    "text_answer": "MDCDrawer contains an instance of MDCList and interacts with either MDCDismissibleDrawerFoundation or MDCModalDrawerFoundation. The drawer manages the list's lifecycle, including its creation and destruction. Event handling (keydown, transition) is delegated to the appropriate foundation.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport {MDCList} from '../../mdc-list/index';\nimport {createFixture, html} from '../../../testing/dom';\nimport {emitEvent} from '../../../testing/dom/events';\nimport {createMockFoundation} from '../../../testing/helpers/foundation';\nimport {setUpMdcTestEnvironment} from '../../../testing/helpers/setup';\nimport {cssClasses, strings} from '../constants';\nimport {MDCDismissibleDrawerFoundation} from '../dismissible/foundation';\nimport {MDCDrawer} from '../index';\nimport {MDCModalDrawerFoundation} from '../modal/foundation';\n\ninterface DrawerSetupOptions {\n  variantClass: string;\n  shadowRoot: boolean;\n  hasList: boolean;\n}\n\nconst defaultSetupOptions = {\n  variantClass: cssClasses.DISMISSIBLE,\n  shadowRoot: false,\n  hasList: true\n};\n\nfunction getDrawerFixture(options: Partial<DrawerSetupOptions>): HTMLElement|\n    DocumentFragment {\n  const listContent = html`\n    <div class=\"mdc-deprecated-list-group\">\n      <nav class=\"mdc-deprecated-list\">\n        <a class=\"mdc-deprecated-list-item mdc-deprecated-list-item--activated\" href=\"#\" aria-current=\"page\">\n          <i class=\"material-icons mdc-deprecated-list-item__graphic\" aria-hidden=\"true\">inbox</i>Inbox\n        </a>\n      </nav>\n    </div>\n    `;\n  const drawerContent = html`\n    <div class=\"mdc-drawer ${options.variantClass}\">\n      <div class=\"mdc-drawer__content\">\n        ${options.hasList ? listContent : ''}\n      </div>\n    </div>\n    `;\n  const scrimContent = html`<div class=\"mdc-drawer-scrim\"></div>`;\n  const isModal = options.variantClass === cssClasses.MODAL;\n  const drawerEl = createFixture(drawerContent);\n  const scrimEl = createFixture(scrimContent);\n\n  if (options.shadowRoot) {\n    const fragment = document.createDocumentFragment();\n    fragment.appendChild(drawerEl);\n    if (isModal) {\n      fragment.appendChild(scrimEl);\n    }\n    return fragment;\n  } else {\n    return createFixture(html`\n      <div class=\"body-content\">\n        ${drawerContent}\n        ${isModal ? scrimContent : ''}\n      </div>`);\n  }\n}\n\nfunction setupTest(options: Partial<DrawerSetupOptions> = defaultSetupOptions) {\n  const root = getDrawerFixture(options);\n  const drawer = root.querySelector<HTMLElement>('.mdc-drawer')!;\n  const component = new MDCDrawer(drawer);\n  return {root, drawer, component};\n}\n\nfunction setupTestWithMocks(\n    options: Partial<DrawerSetupOptions> = defaultSetupOptions) {\n  const root = getDrawerFixture(options);\n  const drawer = root.querySelector<HTMLElement>('.mdc-drawer')!;\n  const isModal = options.variantClass === cssClasses.MODAL;\n  const mockFoundation = createMockFoundation(\n      isModal ? MDCModalDrawerFoundation : MDCDismissibleDrawerFoundation);\n  const mockFocusTrapInstance =\n      jasmine.createSpyObj('FocusTrapInstance', ['trapFocus', 'releaseFocus']);\n  const mockList = jasmine.createSpyObj('MDCList', ['wrapFocus', 'destroy']);\n  const component = new MDCDrawer(\n      drawer, mockFoundation, () => mockFocusTrapInstance, () => mockList);\n  return {\n    root,\n    drawer,\n    component,\n    mockFoundation,\n    mockFocusTrapInstance,\n    mockList\n  };\n}\n\ndescribe('MDCDrawer', () => {\n  setUpMdcTestEnvironment();\n\n  it('attachTo initializes and returns a MDCDrawer instance', () => {\n    const root = getDrawerFixture({\n                   variantClass: cssClasses.DISMISSIBLE,\n                   hasList: false\n                 }).querySelector<HTMLElement>('.mdc-drawer')!;\n    expect(MDCDrawer.attachTo(root)).toEqual(jasmine.any(MDCDrawer));\n  });\n\n  it('#get open calls foundation.isOpen', () => {\n    const {component, mockFoundation} = setupTestWithMocks();\n    component.open;\n    expect(mockFoundation.isOpen).toHaveBeenCalledTimes(1);\n  });\n\n  it('#set open true calls foundation.open', () => {\n    const {component, mockFoundation} = setupTestWithMocks();\n    component.open = true;\n    expect(mockFoundation.open).toHaveBeenCalledTimes(1);\n  });\n\n  it('#set open false calls foundation.close', () => {\n    const {component, mockFoundation} = setupTestWithMocks();\n    component.open = false;\n    expect(mockFoundation.close).toHaveBeenCalledTimes(1);\n  });\n\n  it('#get list returns MDCList instance when DOM includes list', () => {\n    const {component} = setupTest();\n    expect(component.list).toEqual(jasmine.any(MDCList));\n  });\n\n  it('click event calls foundation.handleScrimClick method', () => {\n    const {root, mockFoundation} =\n        setupTestWithMocks({variantClass: cssClasses.MODAL});\n    const scrimEl = root.querySelector<HTMLElement>('.mdc-drawer-scrim')!;\n    emitEvent(scrimEl, 'click');\n    expect((mockFoundation as jasmine.SpyObj<MDCModalDrawerFoundation>)\n               .handleScrimClick)\n        .toHaveBeenCalledTimes(1);\n  });\n\n  it('keydown event calls foundation.handleKeydown method', () => {\n    const {drawer, mockFoundation} = setupTestWithMocks();\n    // TODO(b/182902089): use list constants once code is migrated to evolution.\n    (drawer.querySelector<HTMLElement>('.mdc-deprecated-list-item') as\n     HTMLElement)\n        .focus();\n    emitEvent(drawer, 'keydown');\n    expect(mockFoundation.handleKeydown)\n        .toHaveBeenCalledWith(jasmine.any(Object));\n    expect(mockFoundation.handleKeydown).toHaveBeenCalledTimes(1);\n  });\n\n  it('transitionend event calls foundation.handleTransitionEnd method', () => {\n    const {drawer, mockFoundation} = setupTestWithMocks();\n    emitEvent(drawer, 'transitionend');\n    expect(mockFoundation.handleTransitionEnd)\n        .toHaveBeenCalledWith(jasmine.any(Object));\n    expect(mockFoundation.handleTransitionEnd).toHaveBeenCalledTimes(1);\n  });\n\n  it('component should throw error when invalid variant class name is used or no variant specified',\n     () => {\n       expect(\n           () => setupTest({variantClass: 'mdc-drawer--test-invalid-variant'}))\n           .toThrow();\n       expect(() => setupTest({variantClass: ' '})).toThrow();\n     });\n\n  it('#destroy removes keydown event listener', () => {\n    const {component, drawer, mockFoundation} = setupTestWithMocks();\n    component.destroy();\n    // TODO(b/182902089): use list constants once code is migrated to evolution.\n    (drawer.querySelector<HTMLElement>('.mdc-deprecated-list-item') as\n     HTMLElement)\n        .focus();\n    emitEvent(drawer, 'keydown');\n    expect(mockFoundation.handleKeydown)\n        .not.toHaveBeenCalledWith(jasmine.any(Object));\n  });\n\n  it('#destroy removes transitionend event listener', () => {\n    const {component, drawer, mockFoundation} = setupTestWithMocks();\n    component.destroy();\n\n    emitEvent(drawer, 'transitionend');\n    expect(mockFoundation.handleTransitionEnd)\n        .not.toHaveBeenCalledWith(jasmine.any(Object));\n  });\n\n  it('#destroy calls destroy on list', () => {\n    const {component, mockList} = setupTestWithMocks();\n    component.destroy();\n\n    expect(mockList.destroy).toHaveBeenCalledTimes(1);\n  });\n\n  it('#destroy does not throw an error when list is not present', () => {\n    const {component, mockList} =\n        setupTestWithMocks({variantClass: cssClasses.MODAL, hasList: false});\n    component.destroy();\n\n    expect(mockList.destroy).not.toHaveBeenCalled();\n  });\n\n  it('adapter#addClass adds class to drawer', () => {\n    const {component, drawer} = setupTest();\n    (component.getDefaultFoundation() as any).adapter.addClass('test-class');\n    expect(drawer).toHaveClass('test-class');\n  });\n\n  it('adapter#removeClass removes class from drawer', () => {\n    const {component, drawer} = setupTest();\n    (component.getDefaultFoundation() as any).adapter.addClass('test-class');\n\n    (component.getDefaultFoundation() as any).adapter.removeClass('test-class');\n    expect(drawer).not.toHaveClass('test-class');\n  });\n\n  it('adapter#hasClass returns true when class is on drawer element', () => {\n    const {component} = setupTest();\n    (component.getDefaultFoundation() as any).adapter.addClass('test-class');\n    const hasClass = (component.getDefaultFoundation() as any)\n                         .adapter.hasClass('test-class');\n    expect(hasClass).toBe(true);\n  });\n\n  it('adapter#hasClass returns false when there is no class on drawer element',\n     () => {\n       const {component} = setupTest();\n       const hasClass = (component.getDefaultFoundation() as any)\n                            .adapter.hasClass('test-class');\n       expect(hasClass).toBe(false);\n     });\n\n  it('adapter#elementHasClass returns true when class is found on event target',\n     () => {\n       const {component} = setupTest();\n       const mockEventTarget = createFixture(html`<div class=\"foo\">bar</div>`);\n\n       expect((component.getDefaultFoundation() as any)\n                  .adapter.elementHasClass(mockEventTarget, 'foo'))\n           .toBe(true);\n     });\n\n  it('adapter#restoreFocus restores focus to previously saved focus', () => {\n    const {component, root} = setupTest();\n    const button = createFixture(html`<button>Foo</button>`);\n    document.body.appendChild(button);\n    document.body.appendChild(root);\n    button.focus();\n\n    (component.getDefaultFoundation() as any).adapter.saveFocus();\n    (root.querySelector<HTMLElement>(strings.LIST_ITEM_ACTIVATED_SELECTOR) as\n     HTMLElement)\n        .focus();\n    (component.getDefaultFoundation() as any).adapter.restoreFocus();\n\n    expect(button).toEqual(document.activeElement as HTMLElement);\n    document.body.removeChild(button);\n    document.body.removeChild(root);\n  });\n\n  it('adapter#restoreFocus focus shouldn\\'t restore if focus is not within root element',\n     () => {\n       const {component, root} = setupTest();\n       const navButtonEl = createFixture(html`<button>Foo</button>`);\n       const otherButtonEl = createFixture(html`<button>Bar</button>`);\n       document.body.appendChild(navButtonEl);\n       document.body.appendChild(otherButtonEl);\n       document.body.appendChild(root);\n       navButtonEl.focus();\n\n       (component.getDefaultFoundation() as any).adapter.saveFocus();\n       otherButtonEl.focus();\n       (component.getDefaultFoundation() as any).adapter.restoreFocus();\n\n       expect(navButtonEl).not.toBe(document.activeElement as HTMLElement);\n       document.body.removeChild(navButtonEl);\n       document.body.removeChild(otherButtonEl);\n       document.body.removeChild(root);\n     });\n\n  it('adapter#restoreFocus focus is not restored if saveFocus never called',\n     () => {\n       const {component, root} = setupTest();\n       const button = createFixture(html`<button>Foo</button>`);\n       document.body.appendChild(button);\n       document.body.appendChild(root);\n       button.focus();\n\n       const navItem = root.querySelector<HTMLElement>(\n           strings.LIST_ITEM_ACTIVATED_SELECTOR)!;\n       navItem.focus();\n       (component.getDefaultFoundation() as any).adapter.restoreFocus();\n\n       expect(document.activeElement).toEqual(navItem);\n       document.body.removeChild(button);\n       document.body.removeChild(root);\n     });\n\n  it('adapter#trapFocus traps focus on root element', () => {\n    const {component, mockFocusTrapInstance} =\n        setupTestWithMocks({variantClass: cssClasses.MODAL});\n    (component.getDefaultFoundation() as any).adapter.trapFocus();\n\n    expect(mockFocusTrapInstance.trapFocus).toHaveBeenCalled();\n  });\n\n  it('adapter#releaseFocus releases focus on root element after trap focus',\n     () => {\n       const {component, mockFocusTrapInstance} =\n           setupTestWithMocks({variantClass: cssClasses.MODAL});\n       (component.getDefaultFoundation() as any).adapter.releaseFocus();\n\n       expect(mockFocusTrapInstance.releaseFocus).toHaveBeenCalled();\n     });\n\n  it('adapter#notifyOpen emits drawer open event', () => {\n    const {component} = setupTest();\n\n    const handler = jasmine.createSpy('openHandler');\n\n    component.listen(strings.OPEN_EVENT, handler);\n    (component.getDefaultFoundation() as any).adapter.notifyOpen();\n\n    expect(handler).toHaveBeenCalledWith(jasmine.anything());\n  });\n\n  it('adapter#notifyClose emits drawer close event', () => {\n    const {component} = setupTest();\n\n    const handler = jasmine.createSpy('closeHandler');\n\n    component.listen(strings.CLOSE_EVENT, handler);\n    (component.getDefaultFoundation() as any).adapter.notifyClose();\n\n    expect(handler).toHaveBeenCalledWith(jasmine.anything());\n  });\n\n  it('adapter#focusActiveNavigationItem focuses on active navigation item',\n     () => {\n       const {component, root} = setupTest();\n       document.body.appendChild(root);\n       (component.getDefaultFoundation() as any)\n           .adapter.focusActiveNavigationItem();\n\n       const activatedNavigationItemEl = root.querySelector<HTMLElement>(\n           strings.LIST_ITEM_ACTIVATED_SELECTOR);\n       expect(document.activeElement).toEqual(activatedNavigationItemEl);\n       document.body.removeChild(root);\n     });\n\n  it('adapter#focusActiveNavigationItem does nothing if no active navigation item exists',\n     () => {\n       const {component, root} = setupTest();\n       const prevActiveElement = document.activeElement;\n       document.body.appendChild(root);\n       const activatedNavigationItemEl = root.querySelector<HTMLElement>(\n           strings.LIST_ITEM_ACTIVATED_SELECTOR)!;\n       // TODO(b/182902089): use list constants once code has been migrated.\n       activatedNavigationItemEl.classList.remove(\n           'mdc-deprecated-list-item--activated');\n       (component.getDefaultFoundation() as any)\n           .adapter.focusActiveNavigationItem();\n\n       expect(document.activeElement).toEqual(prevActiveElement);\n       document.body.removeChild(root);\n     });\n\n  it('#initialSyncWithDOM should not throw any errors when DOM rendered in DocumentFragment i.e., Shadow DOM',\n     () => {\n       const {component} =\n           setupTest({variantClass: cssClasses.MODAL, shadowRoot: true});\n       expect(() => component.initialSyncWithDOM).not.toThrow();\n     });\n});",
    "repo": "material-components/material-components-web",
    "path": "./datasets/diagrams-repos/material-components/material-components-web/packages/mdc-drawer/test/component.test.ts",
    "query": "Show how MDCDrawer interacts with MDCList and its foundation. Include the flow of methods and properties.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'MDCDrawer', 'node_id': 'MDCDrawer', 'description': 'Main drawer component class', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MDCList', 'node_id': 'MDCList', 'description': 'List component used within drawer', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MDCDismissibleDrawerFoundation', 'node_id': 'MDCDismissibleDrawerFoundation', 'description': 'Foundation class for dismissible drawer variant', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MDCModalDrawerFoundation', 'node_id': 'MDCModalDrawerFoundation', 'description': 'Foundation class for modal drawer variant', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'list', 'node_id': 'list', 'description': 'Getter for MDCList instance', 'visibility': 'public', 'return_type': 'MDCList', 'params': None, 'source_class_id': 'MDCList'}, {'type': 'method', 'name': 'destroy', 'node_id': 'destroy', 'description': 'Cleanup method that destroys list instance', 'visibility': 'public', 'return_type': 'void', 'params': None, 'source_class_id': 'MDCList'}], 'edges': [{'node_id_from': 'MDCDrawer', 'node_id_to': 'MDCList', 'description': 'contains'}, {'node_id_from': 'MDCDrawer', 'node_id_to': 'MDCDismissibleDrawerFoundation', 'description': 'uses'}, {'node_id_from': 'MDCDrawer', 'node_id_to': 'MDCModalDrawerFoundation', 'description': 'uses'}, {'node_id_from': 'MDCList', 'node_id_to': 'list', 'description': ''}, {'node_id_from': 'MDCList', 'node_id_to': 'destroy', 'description': ''}], 'packages': [{'package_id': 'drawerComponents', 'children': ['MDCDrawer', 'MDCDismissibleDrawerFoundation', 'MDCModalDrawerFoundation', 'list', 'destroy'], 'description': 'Core drawer components and methods'}]}",
    "version": "medium",
    "text_answer": "MDCDrawer contains an instance of MDCList and interacts with either MDCDismissibleDrawerFoundation or MDCModalDrawerFoundation. The drawer manages the list's lifecycle, including its creation and destruction. Event handling (keydown, transition) is delegated to the appropriate foundation.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport {MDCList} from '../../mdc-list/index';\nimport {createFixture, html} from '../../../testing/dom';\nimport {emitEvent} from '../../../testing/dom/events';\nimport {createMockFoundation} from '../../../testing/helpers/foundation';\nimport {setUpMdcTestEnvironment} from '../../../testing/helpers/setup';\nimport {cssClasses, strings} from '../constants';\nimport {MDCDismissibleDrawerFoundation} from '../dismissible/foundation';\nimport {MDCDrawer} from '../index';\nimport {MDCModalDrawerFoundation} from '../modal/foundation';\n\ninterface DrawerSetupOptions {\n  variantClass: string;\n  shadowRoot: boolean;\n  hasList: boolean;\n}\n\nconst defaultSetupOptions = {\n  variantClass: cssClasses.DISMISSIBLE,\n  shadowRoot: false,\n  hasList: true\n};\n\nfunction getDrawerFixture(options: Partial<DrawerSetupOptions>): HTMLElement|\n    DocumentFragment {\n  const listContent = html`\n    <div class=\"mdc-deprecated-list-group\">\n      <nav class=\"mdc-deprecated-list\">\n        <a class=\"mdc-deprecated-list-item mdc-deprecated-list-item--activated\" href=\"#\" aria-current=\"page\">\n          <i class=\"material-icons mdc-deprecated-list-item__graphic\" aria-hidden=\"true\">inbox</i>Inbox\n        </a>\n      </nav>\n    </div>\n    `;\n  const drawerContent = html`\n    <div class=\"mdc-drawer ${options.variantClass}\">\n      <div class=\"mdc-drawer__content\">\n        ${options.hasList ? listContent : ''}\n      </div>\n    </div>\n    `;\n  const scrimContent = html`<div class=\"mdc-drawer-scrim\"></div>`;\n  const isModal = options.variantClass === cssClasses.MODAL;\n  const drawerEl = createFixture(drawerContent);\n  const scrimEl = createFixture(scrimContent);\n\n  if (options.shadowRoot) {\n    const fragment = document.createDocumentFragment();\n    fragment.appendChild(drawerEl);\n    if (isModal) {\n      fragment.appendChild(scrimEl);\n    }\n    return fragment;\n  } else {\n    return createFixture(html`\n      <div class=\"body-content\">\n        ${drawerContent}\n        ${isModal ? scrimContent : ''}\n      </div>`);\n  }\n}\n\nfunction setupTest(options: Partial<DrawerSetupOptions> = defaultSetupOptions) {\n  const root = getDrawerFixture(options);\n  const drawer = root.querySelector<HTMLElement>('.mdc-drawer')!;\n  const component = new MDCDrawer(drawer);\n  return {root, drawer, component};\n}\n\nfunction setupTestWithMocks(\n    options: Partial<DrawerSetupOptions> = defaultSetupOptions) {\n  const root = getDrawerFixture(options);\n  const drawer = root.querySelector<HTMLElement>('.mdc-drawer')!;\n  const isModal = options.variantClass === cssClasses.MODAL;\n  const mockFoundation = createMockFoundation(\n      isModal ? MDCModalDrawerFoundation : MDCDismissibleDrawerFoundation);\n  const mockFocusTrapInstance =\n      jasmine.createSpyObj('FocusTrapInstance', ['trapFocus', 'releaseFocus']);\n  const mockList = jasmine.createSpyObj('MDCList', ['wrapFocus', 'destroy']);\n  const component = new MDCDrawer(\n      drawer, mockFoundation, () => mockFocusTrapInstance, () => mockList);\n  return {\n    root,\n    drawer,\n    component,\n    mockFoundation,\n    mockFocusTrapInstance,\n    mockList\n  };\n}\n\ndescribe('MDCDrawer', () => {\n  setUpMdcTestEnvironment();\n\n  it('attachTo initializes and returns a MDCDrawer instance', () => {\n    const root = getDrawerFixture({\n                   variantClass: cssClasses.DISMISSIBLE,\n                   hasList: false\n                 }).querySelector<HTMLElement>('.mdc-drawer')!;\n    expect(MDCDrawer.attachTo(root)).toEqual(jasmine.any(MDCDrawer));\n  });\n\n  it('#get open calls foundation.isOpen', () => {\n    const {component, mockFoundation} = setupTestWithMocks();\n    component.open;\n    expect(mockFoundation.isOpen).toHaveBeenCalledTimes(1);\n  });\n\n  it('#set open true calls foundation.open', () => {\n    const {component, mockFoundation} = setupTestWithMocks();\n    component.open = true;\n    expect(mockFoundation.open).toHaveBeenCalledTimes(1);\n  });\n\n  it('#set open false calls foundation.close', () => {\n    const {component, mockFoundation} = setupTestWithMocks();\n    component.open = false;\n    expect(mockFoundation.close).toHaveBeenCalledTimes(1);\n  });\n\n  it('#get list returns MDCList instance when DOM includes list', () => {\n    const {component} = setupTest();\n    expect(component.list).toEqual(jasmine.any(MDCList));\n  });\n\n  it('click event calls foundation.handleScrimClick method', () => {\n    const {root, mockFoundation} =\n        setupTestWithMocks({variantClass: cssClasses.MODAL});\n    const scrimEl = root.querySelector<HTMLElement>('.mdc-drawer-scrim')!;\n    emitEvent(scrimEl, 'click');\n    expect((mockFoundation as jasmine.SpyObj<MDCModalDrawerFoundation>)\n               .handleScrimClick)\n        .toHaveBeenCalledTimes(1);\n  });\n\n  it('keydown event calls foundation.handleKeydown method', () => {\n    const {drawer, mockFoundation} = setupTestWithMocks();\n    // TODO(b/182902089): use list constants once code is migrated to evolution.\n    (drawer.querySelector<HTMLElement>('.mdc-deprecated-list-item') as\n     HTMLElement)\n        .focus();\n    emitEvent(drawer, 'keydown');\n    expect(mockFoundation.handleKeydown)\n        .toHaveBeenCalledWith(jasmine.any(Object));\n    expect(mockFoundation.handleKeydown).toHaveBeenCalledTimes(1);\n  });\n\n  it('transitionend event calls foundation.handleTransitionEnd method', () => {\n    const {drawer, mockFoundation} = setupTestWithMocks();\n    emitEvent(drawer, 'transitionend');\n    expect(mockFoundation.handleTransitionEnd)\n        .toHaveBeenCalledWith(jasmine.any(Object));\n    expect(mockFoundation.handleTransitionEnd).toHaveBeenCalledTimes(1);\n  });\n\n  it('component should throw error when invalid variant class name is used or no variant specified',\n     () => {\n       expect(\n           () => setupTest({variantClass: 'mdc-drawer--test-invalid-variant'}))\n           .toThrow();\n       expect(() => setupTest({variantClass: ' '})).toThrow();\n     });\n\n  it('#destroy removes keydown event listener', () => {\n    const {component, drawer, mockFoundation} = setupTestWithMocks();\n    component.destroy();\n    // TODO(b/182902089): use list constants once code is migrated to evolution.\n    (drawer.querySelector<HTMLElement>('.mdc-deprecated-list-item') as\n     HTMLElement)\n        .focus();\n    emitEvent(drawer, 'keydown');\n    expect(mockFoundation.handleKeydown)\n        .not.toHaveBeenCalledWith(jasmine.any(Object));\n  });\n\n  it('#destroy removes transitionend event listener', () => {\n    const {component, drawer, mockFoundation} = setupTestWithMocks();\n    component.destroy();\n\n    emitEvent(drawer, 'transitionend');\n    expect(mockFoundation.handleTransitionEnd)\n        .not.toHaveBeenCalledWith(jasmine.any(Object));\n  });\n\n  it('#destroy calls destroy on list', () => {\n    const {component, mockList} = setupTestWithMocks();\n    component.destroy();\n\n    expect(mockList.destroy).toHaveBeenCalledTimes(1);\n  });\n\n  it('#destroy does not throw an error when list is not present', () => {\n    const {component, mockList} =\n        setupTestWithMocks({variantClass: cssClasses.MODAL, hasList: false});\n    component.destroy();\n\n    expect(mockList.destroy).not.toHaveBeenCalled();\n  });\n\n  it('adapter#addClass adds class to drawer', () => {\n    const {component, drawer} = setupTest();\n    (component.getDefaultFoundation() as any).adapter.addClass('test-class');\n    expect(drawer).toHaveClass('test-class');\n  });\n\n  it('adapter#removeClass removes class from drawer', () => {\n    const {component, drawer} = setupTest();\n    (component.getDefaultFoundation() as any).adapter.addClass('test-class');\n\n    (component.getDefaultFoundation() as any).adapter.removeClass('test-class');\n    expect(drawer).not.toHaveClass('test-class');\n  });\n\n  it('adapter#hasClass returns true when class is on drawer element', () => {\n    const {component} = setupTest();\n    (component.getDefaultFoundation() as any).adapter.addClass('test-class');\n    const hasClass = (component.getDefaultFoundation() as any)\n                         .adapter.hasClass('test-class');\n    expect(hasClass).toBe(true);\n  });\n\n  it('adapter#hasClass returns false when there is no class on drawer element',\n     () => {\n       const {component} = setupTest();\n       const hasClass = (component.getDefaultFoundation() as any)\n                            .adapter.hasClass('test-class');\n       expect(hasClass).toBe(false);\n     });\n\n  it('adapter#elementHasClass returns true when class is found on event target',\n     () => {\n       const {component} = setupTest();\n       const mockEventTarget = createFixture(html`<div class=\"foo\">bar</div>`);\n\n       expect((component.getDefaultFoundation() as any)\n                  .adapter.elementHasClass(mockEventTarget, 'foo'))\n           .toBe(true);\n     });\n\n  it('adapter#restoreFocus restores focus to previously saved focus', () => {\n    const {component, root} = setupTest();\n    const button = createFixture(html`<button>Foo</button>`);\n    document.body.appendChild(button);\n    document.body.appendChild(root);\n    button.focus();\n\n    (component.getDefaultFoundation() as any).adapter.saveFocus();\n    (root.querySelector<HTMLElement>(strings.LIST_ITEM_ACTIVATED_SELECTOR) as\n     HTMLElement)\n        .focus();\n    (component.getDefaultFoundation() as any).adapter.restoreFocus();\n\n    expect(button).toEqual(document.activeElement as HTMLElement);\n    document.body.removeChild(button);\n    document.body.removeChild(root);\n  });\n\n  it('adapter#restoreFocus focus shouldn\\'t restore if focus is not within root element',\n     () => {\n       const {component, root} = setupTest();\n       const navButtonEl = createFixture(html`<button>Foo</button>`);\n       const otherButtonEl = createFixture(html`<button>Bar</button>`);\n       document.body.appendChild(navButtonEl);\n       document.body.appendChild(otherButtonEl);\n       document.body.appendChild(root);\n       navButtonEl.focus();\n\n       (component.getDefaultFoundation() as any).adapter.saveFocus();\n       otherButtonEl.focus();\n       (component.getDefaultFoundation() as any).adapter.restoreFocus();\n\n       expect(navButtonEl).not.toBe(document.activeElement as HTMLElement);\n       document.body.removeChild(navButtonEl);\n       document.body.removeChild(otherButtonEl);\n       document.body.removeChild(root);\n     });\n\n  it('adapter#restoreFocus focus is not restored if saveFocus never called',\n     () => {\n       const {component, root} = setupTest();\n       const button = createFixture(html`<button>Foo</button>`);\n       document.body.appendChild(button);\n       document.body.appendChild(root);\n       button.focus();\n\n       const navItem = root.querySelector<HTMLElement>(\n           strings.LIST_ITEM_ACTIVATED_SELECTOR)!;\n       navItem.focus();\n       (component.getDefaultFoundation() as any).adapter.restoreFocus();\n\n       expect(document.activeElement).toEqual(navItem);\n       document.body.removeChild(button);\n       document.body.removeChild(root);\n     });\n\n  it('adapter#trapFocus traps focus on root element', () => {\n    const {component, mockFocusTrapInstance} =\n        setupTestWithMocks({variantClass: cssClasses.MODAL});\n    (component.getDefaultFoundation() as any).adapter.trapFocus();\n\n    expect(mockFocusTrapInstance.trapFocus).toHaveBeenCalled();\n  });\n\n  it('adapter#releaseFocus releases focus on root element after trap focus',\n     () => {\n       const {component, mockFocusTrapInstance} =\n           setupTestWithMocks({variantClass: cssClasses.MODAL});\n       (component.getDefaultFoundation() as any).adapter.releaseFocus();\n\n       expect(mockFocusTrapInstance.releaseFocus).toHaveBeenCalled();\n     });\n\n  it('adapter#notifyOpen emits drawer open event', () => {\n    const {component} = setupTest();\n\n    const handler = jasmine.createSpy('openHandler');\n\n    component.listen(strings.OPEN_EVENT, handler);\n    (component.getDefaultFoundation() as any).adapter.notifyOpen();\n\n    expect(handler).toHaveBeenCalledWith(jasmine.anything());\n  });\n\n  it('adapter#notifyClose emits drawer close event', () => {\n    const {component} = setupTest();\n\n    const handler = jasmine.createSpy('closeHandler');\n\n    component.listen(strings.CLOSE_EVENT, handler);\n    (component.getDefaultFoundation() as any).adapter.notifyClose();\n\n    expect(handler).toHaveBeenCalledWith(jasmine.anything());\n  });\n\n  it('adapter#focusActiveNavigationItem focuses on active navigation item',\n     () => {\n       const {component, root} = setupTest();\n       document.body.appendChild(root);\n       (component.getDefaultFoundation() as any)\n           .adapter.focusActiveNavigationItem();\n\n       const activatedNavigationItemEl = root.querySelector<HTMLElement>(\n           strings.LIST_ITEM_ACTIVATED_SELECTOR);\n       expect(document.activeElement).toEqual(activatedNavigationItemEl);\n       document.body.removeChild(root);\n     });\n\n  it('adapter#focusActiveNavigationItem does nothing if no active navigation item exists',\n     () => {\n       const {component, root} = setupTest();\n       const prevActiveElement = document.activeElement;\n       document.body.appendChild(root);\n       const activatedNavigationItemEl = root.querySelector<HTMLElement>(\n           strings.LIST_ITEM_ACTIVATED_SELECTOR)!;\n       // TODO(b/182902089): use list constants once code has been migrated.\n       activatedNavigationItemEl.classList.remove(\n           'mdc-deprecated-list-item--activated');\n       (component.getDefaultFoundation() as any)\n           .adapter.focusActiveNavigationItem();\n\n       expect(document.activeElement).toEqual(prevActiveElement);\n       document.body.removeChild(root);\n     });\n\n  it('#initialSyncWithDOM should not throw any errors when DOM rendered in DocumentFragment i.e., Shadow DOM',\n     () => {\n       const {component} =\n           setupTest({variantClass: cssClasses.MODAL, shadowRoot: true});\n       expect(() => component.initialSyncWithDOM).not.toThrow();\n     });\n});",
    "repo": "material-components/material-components-web",
    "path": "./datasets/diagrams-repos/material-components/material-components-web/packages/mdc-drawer/test/component.test.ts",
    "query": "Show how MDCDrawer interacts with MDCList and its foundation. Include the flow of methods and properties.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'MDCDrawer', 'node_id': 'MDCDrawer', 'description': 'Main drawer component class', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MDCList', 'node_id': 'MDCList', 'description': 'List component used within drawer', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MDCDismissibleDrawerFoundation', 'node_id': 'MDCDismissibleDrawerFoundation', 'description': 'Foundation class for dismissible drawer variant', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MDCModalDrawerFoundation', 'node_id': 'MDCModalDrawerFoundation', 'description': 'Foundation class for modal drawer variant', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'list', 'node_id': 'list', 'description': 'Getter for MDCList instance', 'visibility': 'public', 'return_type': 'MDCList', 'params': None, 'source_class_id': 'MDCList'}, {'type': 'method', 'name': 'destroy', 'node_id': 'destroy', 'description': 'Cleanup method that destroys list instance', 'visibility': 'public', 'return_type': 'void', 'params': None, 'source_class_id': 'MDCList'}, {'type': 'method', 'name': 'handleKeydown', 'node_id': 'handleKeydown', 'description': 'Handles keydown events', 'visibility': 'public', 'return_type': None, 'params': 'event: KeyboardEvent', 'source_class_id': 'mockFoundation'}, {'type': 'method', 'name': 'handleTransitionEnd', 'node_id': 'handleTransitionEnd', 'description': 'Handles transition end events', 'visibility': 'public', 'return_type': None, 'params': 'event: TransitionEvent', 'source_class_id': 'mockFoundation'}, {'type': 'method', 'name': 'initialSyncWithDOM', 'node_id': 'initialSyncWithDOM', 'description': 'Initial DOM synchronization', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': 'MDCList'}, {'type': 'class', 'name': 'mockFoundation', 'node_id': 'mockFoundation', 'description': 'Mock foundation class', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'MDCDrawer', 'node_id_to': 'MDCList', 'description': 'contains'}, {'node_id_from': 'MDCDrawer', 'node_id_to': 'MDCDismissibleDrawerFoundation', 'description': 'uses'}, {'node_id_from': 'MDCDrawer', 'node_id_to': 'MDCModalDrawerFoundation', 'description': 'uses'}, {'node_id_from': 'handleKeydown', 'node_id_to': 'MDCDismissibleDrawerFoundation', 'description': 'delegates to foundation'}, {'node_id_from': 'handleTransitionEnd', 'node_id_to': 'MDCDismissibleDrawerFoundation', 'description': 'delegates to foundation'}, {'node_id_from': 'MDCList', 'node_id_to': 'list', 'description': ''}, {'node_id_from': 'MDCList', 'node_id_to': 'destroy', 'description': ''}, {'node_id_from': 'MDCList', 'node_id_to': 'initialSyncWithDOM', 'description': ''}, {'node_id_from': 'mockFoundation', 'node_id_to': 'handleKeydown', 'description': ''}, {'node_id_from': 'mockFoundation', 'node_id_to': 'handleTransitionEnd', 'description': ''}, {'node_id_from': 'mockFoundation', 'node_id_to': 'MDCModalDrawerFoundation', 'description': 'isModal'}, {'node_id_from': 'mockFoundation', 'node_id_to': 'MDCDismissibleDrawerFoundation', 'description': '!isModal'}], 'packages': [{'package_id': 'drawerComponents', 'children': ['MDCDrawer', 'MDCDismissibleDrawerFoundation', 'MDCModalDrawerFoundation'], 'description': 'Core drawer components'}, {'package_id': 'drawerMethods', 'children': ['list', 'destroy', 'handleKeydown', 'handleTransitionEnd', 'initialSyncWithDOM'], 'description': 'Drawer methods'}]}",
    "version": "full",
    "text_answer": "MDCDrawer contains an instance of MDCList and interacts with either MDCDismissibleDrawerFoundation or MDCModalDrawerFoundation. The drawer manages the list's lifecycle, including its creation and destruction. Event handling (keydown, transition) is delegated to the appropriate foundation.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Python",
    "code": "\nfrom __future__ import annotations\n\nfrom abc import ABC, abstractmethod\nimport asyncio\nfrom collections.abc import Awaitable, Callable\nfrom http import HTTPStatus\nimport logging\n\nfrom aiohttp import web\nfrom google_nest_sdm.camera_traits import CameraClipPreviewTrait\nfrom google_nest_sdm.device import Device\nfrom google_nest_sdm.event import EventMessage\nfrom google_nest_sdm.event_media import Media\nfrom google_nest_sdm.exceptions import (\n    ApiException,\n    AuthException,\n    ConfigurationException,\n    DecodeException,\n    SubscriberException,\n)\nfrom google_nest_sdm.traits import TraitType\nimport voluptuous as vol\n\nfrom homeassistant.auth.permissions.const import POLICY_READ\nfrom homeassistant.components.camera import Image, img_util\nfrom homeassistant.components.http import KEY_HASS_USER\nfrom homeassistant.components.http.view import HomeAssistantView\nfrom homeassistant.const import (\n    CONF_BINARY_SENSORS,\n    CONF_CLIENT_ID,\n    CONF_CLIENT_SECRET,\n    CONF_MONITORED_CONDITIONS,\n    CONF_SENSORS,\n    CONF_STRUCTURE,\n    EVENT_HOMEASSISTANT_STOP,\n    Platform,\n)\nfrom homeassistant.core import Event, HomeAssistant, callback\nfrom homeassistant.exceptions import (\n    ConfigEntryAuthFailed,\n    ConfigEntryNotReady,\n    HomeAssistantError,\n    Unauthorized,\n)\nfrom homeassistant.helpers import (\n    config_validation as cv,\n    device_registry as dr,\n    entity_registry as er,\n)\nfrom homeassistant.helpers.entity_registry import async_entries_for_device\nfrom homeassistant.helpers.typing import ConfigType\n\nfrom . import api\nfrom .const import (\n    CONF_CLOUD_PROJECT_ID,\n    CONF_PROJECT_ID,\n    CONF_SUBSCRIBER_ID,\n    CONF_SUBSCRIBER_ID_IMPORTED,\n    CONF_SUBSCRIPTION_NAME,\n    DATA_SDM,\n    DOMAIN,\n)\nfrom .events import EVENT_NAME_MAP, NEST_EVENT\nfrom .media_source import (\n    EVENT_MEDIA_API_URL_FORMAT,\n    EVENT_THUMBNAIL_URL_FORMAT,\n    async_get_media_event_store,\n    async_get_media_source_devices,\n    async_get_transcoder,\n)\nfrom .types import NestConfigEntry, NestData\n\n_LOGGER = logging.getLogger(__name__)\n\n\nSENSOR_SCHEMA = vol.Schema(\n    {vol.Optional(CONF_MONITORED_CONDITIONS): vol.All(cv.ensure_list)}\n)\n\nCONFIG_SCHEMA = vol.Schema(\n    {\n        DOMAIN: vol.Schema(\n            {\n                vol.Required(CONF_CLIENT_ID): cv.string,\n                vol.Required(CONF_CLIENT_SECRET): cv.string,\n                # Required to use the new API (optional for compatibility)\n                vol.Optional(CONF_PROJECT_ID): cv.string,\n                vol.Optional(CONF_SUBSCRIBER_ID): cv.string,\n                # Config that only currently works on the old API\n                vol.Optional(CONF_STRUCTURE): vol.All(cv.ensure_list, [cv.string]),\n                vol.Optional(CONF_SENSORS): SENSOR_SCHEMA,\n                vol.Optional(CONF_BINARY_SENSORS): SENSOR_SCHEMA,\n            }\n        )\n    },\n    extra=vol.ALLOW_EXTRA,\n)\n\n# Platforms for SDM API\nPLATFORMS = [Platform.CAMERA, Platform.CLIMATE, Platform.EVENT, Platform.SENSOR]\n\n# Fetch media events with a disk backed cache, with a limit for each camera\n# device. The largest media items are mp4 clips at ~450kb each, and we target\n# ~125MB of storage per camera to try to balance a reasonable user experience\n# for event history not not filling the disk.\nEVENT_MEDIA_CACHE_SIZE = 256  # number of events\n\nTHUMBNAIL_SIZE_PX = 175\n\n\nasync def async_setup(hass: HomeAssistant, config: ConfigType) -> bool:\n    \"\"\"Set up Nest components with dispatch between old/new flows.\"\"\"\n    hass.http.register_view(NestEventMediaView(hass))\n    hass.http.register_view(NestEventMediaThumbnailView(hass))\n    return True\n\n\nclass SignalUpdateCallback:\n    \"\"\"An EventCallback invoked when new events arrive from subscriber.\"\"\"\n\n    def __init__(\n        self,\n        hass: HomeAssistant,\n        config_reload_cb: Callable[[], Awaitable[None]],\n        config_entry: NestConfigEntry,\n    ) -> None:\n        \"\"\"Initialize EventCallback.\"\"\"\n        self._hass = hass\n        self._config_reload_cb = config_reload_cb\n        self._config_entry = config_entry\n\n    async def async_handle_event(self, event_message: EventMessage) -> None:\n        \"\"\"Process an incoming EventMessage.\"\"\"\n        if event_message.relation_update:\n            _LOGGER.info(\"Devices or homes have changed; Need reload to take effect\")\n            return\n        if not event_message.resource_update_name:\n            return\n        device_id = event_message.resource_update_name\n        if not (events := event_message.resource_update_events):\n            return\n        _LOGGER.debug(\"Event Update %s\", events.keys())\n        device_registry = dr.async_get(self._hass)\n        device_entry = device_registry.async_get_device(\n            identifiers={(DOMAIN, device_id)}\n        )\n        if not device_entry:\n            return\n        supported_traits = self._supported_traits(device_id)\n        for api_event_type, image_event in events.items():\n            if not (event_type := EVENT_NAME_MAP.get(api_event_type)):\n                continue\n            nest_event_id = image_event.event_token\n            message = {\n                \"device_id\": device_entry.id,\n                \"type\": event_type,\n                \"timestamp\": event_message.timestamp,\n                \"nest_event_id\": nest_event_id,\n            }\n            if (\n                TraitType.CAMERA_EVENT_IMAGE in supported_traits\n                or TraitType.CAMERA_CLIP_PREVIEW in supported_traits\n            ):\n                attachment = {\n                    \"image\": EVENT_THUMBNAIL_URL_FORMAT.format(\n                        device_id=device_entry.id, event_token=image_event.event_token\n                    )\n                }\n                if TraitType.CAMERA_CLIP_PREVIEW in supported_traits:\n                    attachment[\"video\"] = EVENT_MEDIA_API_URL_FORMAT.format(\n                        device_id=device_entry.id, event_token=image_event.event_token\n                    )\n                message[\"attachment\"] = attachment\n            if image_event.zones:\n                message[\"zones\"] = image_event.zones\n            self._hass.bus.async_fire(NEST_EVENT, message)\n\n    def _supported_traits(self, device_id: str) -> list[str]:\n        if (\n            not self._config_entry.runtime_data\n            or not (device_manager := self._config_entry.runtime_data.device_manager)\n            or not (device := device_manager.devices.get(device_id))\n        ):\n            return []\n        return list(device.traits)\n\n\nasync def async_setup_entry(hass: HomeAssistant, entry: NestConfigEntry) -> bool:\n    \"\"\"Set up Nest from a config entry with dispatch between old/new flows.\"\"\"\n    if DATA_SDM not in entry.data:\n        hass.async_create_task(hass.config_entries.async_remove(entry.entry_id))\n        return False\n\n    if entry.unique_id != entry.data[CONF_PROJECT_ID]:\n        hass.config_entries.async_update_entry(\n            entry, unique_id=entry.data[CONF_PROJECT_ID]\n        )\n\n    subscriber = await api.new_subscriber(hass, entry)\n    if not subscriber:\n        return False\n    # Keep media for last N events in memory\n    subscriber.cache_policy.event_cache_size = EVENT_MEDIA_CACHE_SIZE\n    subscriber.cache_policy.fetch = True\n    # Use disk backed event media store\n    subscriber.cache_policy.store = await async_get_media_event_store(hass, subscriber)\n    subscriber.cache_policy.transcoder = await async_get_transcoder(hass)\n\n    async def async_config_reload() -> None:\n        await hass.config_entries.async_reload(entry.entry_id)\n\n    update_callback = SignalUpdateCallback(hass, async_config_reload, entry)\n    subscriber.set_update_callback(update_callback.async_handle_event)\n    try:\n        unsub = await subscriber.start_async()\n    except AuthException as err:\n        raise ConfigEntryAuthFailed(\n            f\"Subscriber authentication error: {err!s}\"\n        ) from err\n    except ConfigurationException as err:\n        _LOGGER.error(\"Configuration error: %s\", err)\n        return False\n    except SubscriberException as err:\n        raise ConfigEntryNotReady(f\"Subscriber error: {err!s}\") from err\n\n    try:\n        device_manager = await subscriber.async_get_device_manager()\n    except ApiException as err:\n        unsub()\n        raise ConfigEntryNotReady(f\"Device manager error: {err!s}\") from err\n\n    @callback\n    def on_hass_stop(_: Event) -> None:\n        \"\"\"Close connection when hass stops.\"\"\"\n        unsub()\n\n    entry.async_on_unload(\n        hass.bus.async_listen_once(EVENT_HOMEASSISTANT_STOP, on_hass_stop)\n    )\n\n    entry.async_on_unload(unsub)\n    entry.runtime_data = NestData(\n        subscriber=subscriber,\n        device_manager=device_manager,\n    )\n\n    await hass.config_entries.async_forward_entry_setups(entry, PLATFORMS)\n\n    return True\n\n\nasync def async_unload_entry(hass: HomeAssistant, entry: NestConfigEntry) -> bool:\n    \"\"\"Unload a config entry.\"\"\"\n    return await hass.config_entries.async_unload_platforms(entry, PLATFORMS)\n\n\nasync def async_remove_entry(hass: HomeAssistant, entry: NestConfigEntry) -> None:\n    \"\"\"Handle removal of pubsub subscriptions created during config flow.\"\"\"\n    if (\n        DATA_SDM not in entry.data\n        or not (\n            CONF_SUBSCRIPTION_NAME in entry.data or CONF_SUBSCRIBER_ID in entry.data\n        )\n        or CONF_SUBSCRIBER_ID_IMPORTED in entry.data\n    ):\n        return\n    if (subscription_name := entry.data.get(CONF_SUBSCRIPTION_NAME)) is None:\n        subscription_name = entry.data[CONF_SUBSCRIBER_ID]\n    admin_client = api.new_pubsub_admin_client(\n        hass,\n        access_token=entry.data[\"token\"][\"access_token\"],\n        cloud_project_id=entry.data[CONF_CLOUD_PROJECT_ID],\n    )\n    _LOGGER.debug(\"Deleting subscription '%s'\", subscription_name)\n    try:\n        await admin_client.delete_subscription(subscription_name)\n    except ApiException as err:\n        _LOGGER.warning(\n            (\n                \"Unable to delete subscription '%s'; Will be automatically cleaned up\"\n                \" by cloud console: %s\"\n            ),\n            subscription_name,\n            err,\n        )\n\n\nclass NestEventViewBase(HomeAssistantView, ABC):\n    \"\"\"Base class for media event APIs.\"\"\"\n\n    def __init__(self, hass: HomeAssistant) -> None:\n        \"\"\"Initialize NestEventViewBase.\"\"\"\n        self.hass = hass\n\n    async def get(\n        self, request: web.Request, device_id: str, event_token: str\n    ) -> web.StreamResponse:\n        \"\"\"Start a GET request.\"\"\"\n        user = request[KEY_HASS_USER]\n        entity_registry = er.async_get(self.hass)\n        for entry in async_entries_for_device(entity_registry, device_id):\n            if not user.permissions.check_entity(entry.entity_id, POLICY_READ):\n                raise Unauthorized(entity_id=entry.entity_id)\n\n        devices = async_get_media_source_devices(self.hass)\n        if not (nest_device := devices.get(device_id)):\n            return self._json_error(\n                f\"No Nest Device found for '{device_id}'\", HTTPStatus.NOT_FOUND\n            )\n        try:\n            media = await self.load_media(nest_device, event_token)\n        except DecodeException:\n            return self._json_error(\n                f\"Event token was invalid '{event_token}'\", HTTPStatus.NOT_FOUND\n            )\n        except ApiException as err:\n            raise HomeAssistantError(\"Unable to fetch media for event\") from err\n        if not media:\n            return self._json_error(\n                f\"No event found for event_id '{event_token}'\", HTTPStatus.NOT_FOUND\n            )\n        return await self.handle_media(media)\n\n    @abstractmethod\n    async def load_media(self, nest_device: Device, event_token: str) -> Media | None:\n        \"\"\"Load the specified media.\"\"\"\n\n    @abstractmethod\n    async def handle_media(self, media: Media) -> web.StreamResponse:\n        \"\"\"Process the specified media.\"\"\"\n\n    def _json_error(self, message: str, status: HTTPStatus) -> web.StreamResponse:\n        \"\"\"Return a json error message with additional logging.\"\"\"\n        _LOGGER.debug(message)\n        return self.json_message(message, status)\n\n\nclass NestEventMediaView(NestEventViewBase):\n    \"\"\"Returns media for related to events for a specific device.\n\n    This is primarily used to render media for events for MediaSource. The media type\n    depends on the specific device e.g. an image, or a movie clip preview.\n    \"\"\"\n\n    url = \"/api/nest/event_media/{device_id}/{event_token}\"\n    name = \"api:nest:event_media\"\n\n    async def load_media(self, nest_device: Device, event_token: str) -> Media | None:\n        \"\"\"Load the specified media.\"\"\"\n        return await nest_device.event_media_manager.get_media_from_token(event_token)\n\n    async def handle_media(self, media: Media) -> web.StreamResponse:\n        \"\"\"Process the specified media.\"\"\"\n        return web.Response(body=media.contents, content_type=media.content_type)\n\n\nclass NestEventMediaThumbnailView(NestEventViewBase):\n    \"\"\"Returns media for related to events for a specific device.\n\n    This is primarily used to render media for events for MediaSource. The media type\n    depends on the specific device e.g. an image, or a movie clip preview.\n\n    mp4 clips are transcoded and thumbnailed by the SDM transcoder. jpgs are thumbnailed\n    from the original in this view.\n    \"\"\"\n\n    url = \"/api/nest/event_media/{device_id}/{event_token}/thumbnail\"\n    name = \"api:nest:event_media\"\n\n    def __init__(self, hass: HomeAssistant) -> None:\n        \"\"\"Initialize NestEventMediaThumbnailView.\"\"\"\n        super().__init__(hass)\n        self._lock = asyncio.Lock()\n        self.hass = hass\n\n    async def load_media(self, nest_device: Device, event_token: str) -> Media | None:\n        \"\"\"Load the specified media.\"\"\"\n        if CameraClipPreviewTrait.NAME in nest_device.traits:\n            async with self._lock:  # Only one transcode subprocess at a time\n                return (\n                    await nest_device.event_media_manager.get_clip_thumbnail_from_token(\n                        event_token\n                    )\n                )\n        return await nest_device.event_media_manager.get_media_from_token(event_token)\n\n    async def handle_media(self, media: Media) -> web.StreamResponse:\n        \"\"\"Start a GET request.\"\"\"\n        contents = media.contents\n        if (content_type := media.content_type) == \"image/jpeg\":\n            image = Image(media.event_image_type.content_type, contents)\n            contents = img_util.scale_jpeg_camera_image(\n                image, THUMBNAIL_SIZE_PX, THUMBNAIL_SIZE_PX\n            )\n        return web.Response(body=contents, content_type=content_type)",
    "repo": "home-assistant/core",
    "path": "./datasets/diagrams-repos/home-assistant/core/homeassistant/components/nest/__init__.py",
    "query": "What is the structure of the NestEventViewBase and its subclasses, and how do they handle media requests?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'NestEventViewBase', 'node_id': 'NestEventViewBase', 'description': 'Abstract base class for handling Nest media event requests', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'get', 'node_id': 'get', 'description': 'Handles GET request for media events', 'visibility': 'public', 'return_type': 'web.StreamResponse', 'params': '(request, device_id, event_token)', 'source_class_id': 'NestEventViewBase'}, {'type': 'method', 'name': 'load_media', 'node_id': 'load_media', 'description': 'Abstract method to load media for specific event', 'visibility': 'public', 'return_type': 'Media | None', 'params': '(nest_device, event_token)', 'source_class_id': 'NestEventViewBase'}, {'type': 'method', 'name': 'handle_media', 'node_id': 'handle_media', 'description': 'Abstract method to process loaded media', 'visibility': 'public', 'return_type': 'web.StreamResponse', 'params': '(media)', 'source_class_id': 'NestEventViewBase'}, {'type': 'class', 'name': 'NestEventMediaView', 'node_id': 'NestEventMediaView', 'description': 'Handles media event requests for full media content', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'NestEventMediaThumbnailView', 'node_id': 'NestEventMediaThumbnailView', 'description': 'Handles media event requests for thumbnails', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'NestEventMediaView', 'node_id_to': 'NestEventViewBase', 'description': 'inherits'}, {'node_id_from': 'NestEventMediaThumbnailView', 'node_id_to': 'NestEventViewBase', 'description': 'inherits'}, {'node_id_from': 'NestEventViewBase', 'node_id_to': 'get', 'description': ''}, {'node_id_from': 'NestEventViewBase', 'node_id_to': 'load_media', 'description': ''}, {'node_id_from': 'NestEventViewBase', 'node_id_to': 'handle_media', 'description': ''}], 'packages': [{'package_id': 'mediaHandling', 'children': ['NestEventViewBase', 'NestEventMediaView', 'NestEventMediaThumbnailView', 'get', 'load_media', 'handle_media'], 'description': 'Classes for handling Nest media requests'}]}",
    "version": "minimal",
    "text_answer": "NestEventViewBase is an abstract base class that defines the structure for handling Nest media requests. It has two concrete implementations: NestEventMediaView for handling full media content and NestEventMediaThumbnailView for handling thumbnails. The base class implements a common GET request flow, while the subclasses provide specific implementations for loading and handling different types of media content.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Python",
    "code": "\nfrom __future__ import annotations\n\nfrom abc import ABC, abstractmethod\nimport asyncio\nfrom collections.abc import Awaitable, Callable\nfrom http import HTTPStatus\nimport logging\n\nfrom aiohttp import web\nfrom google_nest_sdm.camera_traits import CameraClipPreviewTrait\nfrom google_nest_sdm.device import Device\nfrom google_nest_sdm.event import EventMessage\nfrom google_nest_sdm.event_media import Media\nfrom google_nest_sdm.exceptions import (\n    ApiException,\n    AuthException,\n    ConfigurationException,\n    DecodeException,\n    SubscriberException,\n)\nfrom google_nest_sdm.traits import TraitType\nimport voluptuous as vol\n\nfrom homeassistant.auth.permissions.const import POLICY_READ\nfrom homeassistant.components.camera import Image, img_util\nfrom homeassistant.components.http import KEY_HASS_USER\nfrom homeassistant.components.http.view import HomeAssistantView\nfrom homeassistant.const import (\n    CONF_BINARY_SENSORS,\n    CONF_CLIENT_ID,\n    CONF_CLIENT_SECRET,\n    CONF_MONITORED_CONDITIONS,\n    CONF_SENSORS,\n    CONF_STRUCTURE,\n    EVENT_HOMEASSISTANT_STOP,\n    Platform,\n)\nfrom homeassistant.core import Event, HomeAssistant, callback\nfrom homeassistant.exceptions import (\n    ConfigEntryAuthFailed,\n    ConfigEntryNotReady,\n    HomeAssistantError,\n    Unauthorized,\n)\nfrom homeassistant.helpers import (\n    config_validation as cv,\n    device_registry as dr,\n    entity_registry as er,\n)\nfrom homeassistant.helpers.entity_registry import async_entries_for_device\nfrom homeassistant.helpers.typing import ConfigType\n\nfrom . import api\nfrom .const import (\n    CONF_CLOUD_PROJECT_ID,\n    CONF_PROJECT_ID,\n    CONF_SUBSCRIBER_ID,\n    CONF_SUBSCRIBER_ID_IMPORTED,\n    CONF_SUBSCRIPTION_NAME,\n    DATA_SDM,\n    DOMAIN,\n)\nfrom .events import EVENT_NAME_MAP, NEST_EVENT\nfrom .media_source import (\n    EVENT_MEDIA_API_URL_FORMAT,\n    EVENT_THUMBNAIL_URL_FORMAT,\n    async_get_media_event_store,\n    async_get_media_source_devices,\n    async_get_transcoder,\n)\nfrom .types import NestConfigEntry, NestData\n\n_LOGGER = logging.getLogger(__name__)\n\n\nSENSOR_SCHEMA = vol.Schema(\n    {vol.Optional(CONF_MONITORED_CONDITIONS): vol.All(cv.ensure_list)}\n)\n\nCONFIG_SCHEMA = vol.Schema(\n    {\n        DOMAIN: vol.Schema(\n            {\n                vol.Required(CONF_CLIENT_ID): cv.string,\n                vol.Required(CONF_CLIENT_SECRET): cv.string,\n                # Required to use the new API (optional for compatibility)\n                vol.Optional(CONF_PROJECT_ID): cv.string,\n                vol.Optional(CONF_SUBSCRIBER_ID): cv.string,\n                # Config that only currently works on the old API\n                vol.Optional(CONF_STRUCTURE): vol.All(cv.ensure_list, [cv.string]),\n                vol.Optional(CONF_SENSORS): SENSOR_SCHEMA,\n                vol.Optional(CONF_BINARY_SENSORS): SENSOR_SCHEMA,\n            }\n        )\n    },\n    extra=vol.ALLOW_EXTRA,\n)\n\n# Platforms for SDM API\nPLATFORMS = [Platform.CAMERA, Platform.CLIMATE, Platform.EVENT, Platform.SENSOR]\n\n# Fetch media events with a disk backed cache, with a limit for each camera\n# device. The largest media items are mp4 clips at ~450kb each, and we target\n# ~125MB of storage per camera to try to balance a reasonable user experience\n# for event history not not filling the disk.\nEVENT_MEDIA_CACHE_SIZE = 256  # number of events\n\nTHUMBNAIL_SIZE_PX = 175\n\n\nasync def async_setup(hass: HomeAssistant, config: ConfigType) -> bool:\n    \"\"\"Set up Nest components with dispatch between old/new flows.\"\"\"\n    hass.http.register_view(NestEventMediaView(hass))\n    hass.http.register_view(NestEventMediaThumbnailView(hass))\n    return True\n\n\nclass SignalUpdateCallback:\n    \"\"\"An EventCallback invoked when new events arrive from subscriber.\"\"\"\n\n    def __init__(\n        self,\n        hass: HomeAssistant,\n        config_reload_cb: Callable[[], Awaitable[None]],\n        config_entry: NestConfigEntry,\n    ) -> None:\n        \"\"\"Initialize EventCallback.\"\"\"\n        self._hass = hass\n        self._config_reload_cb = config_reload_cb\n        self._config_entry = config_entry\n\n    async def async_handle_event(self, event_message: EventMessage) -> None:\n        \"\"\"Process an incoming EventMessage.\"\"\"\n        if event_message.relation_update:\n            _LOGGER.info(\"Devices or homes have changed; Need reload to take effect\")\n            return\n        if not event_message.resource_update_name:\n            return\n        device_id = event_message.resource_update_name\n        if not (events := event_message.resource_update_events):\n            return\n        _LOGGER.debug(\"Event Update %s\", events.keys())\n        device_registry = dr.async_get(self._hass)\n        device_entry = device_registry.async_get_device(\n            identifiers={(DOMAIN, device_id)}\n        )\n        if not device_entry:\n            return\n        supported_traits = self._supported_traits(device_id)\n        for api_event_type, image_event in events.items():\n            if not (event_type := EVENT_NAME_MAP.get(api_event_type)):\n                continue\n            nest_event_id = image_event.event_token\n            message = {\n                \"device_id\": device_entry.id,\n                \"type\": event_type,\n                \"timestamp\": event_message.timestamp,\n                \"nest_event_id\": nest_event_id,\n            }\n            if (\n                TraitType.CAMERA_EVENT_IMAGE in supported_traits\n                or TraitType.CAMERA_CLIP_PREVIEW in supported_traits\n            ):\n                attachment = {\n                    \"image\": EVENT_THUMBNAIL_URL_FORMAT.format(\n                        device_id=device_entry.id, event_token=image_event.event_token\n                    )\n                }\n                if TraitType.CAMERA_CLIP_PREVIEW in supported_traits:\n                    attachment[\"video\"] = EVENT_MEDIA_API_URL_FORMAT.format(\n                        device_id=device_entry.id, event_token=image_event.event_token\n                    )\n                message[\"attachment\"] = attachment\n            if image_event.zones:\n                message[\"zones\"] = image_event.zones\n            self._hass.bus.async_fire(NEST_EVENT, message)\n\n    def _supported_traits(self, device_id: str) -> list[str]:\n        if (\n            not self._config_entry.runtime_data\n            or not (device_manager := self._config_entry.runtime_data.device_manager)\n            or not (device := device_manager.devices.get(device_id))\n        ):\n            return []\n        return list(device.traits)\n\n\nasync def async_setup_entry(hass: HomeAssistant, entry: NestConfigEntry) -> bool:\n    \"\"\"Set up Nest from a config entry with dispatch between old/new flows.\"\"\"\n    if DATA_SDM not in entry.data:\n        hass.async_create_task(hass.config_entries.async_remove(entry.entry_id))\n        return False\n\n    if entry.unique_id != entry.data[CONF_PROJECT_ID]:\n        hass.config_entries.async_update_entry(\n            entry, unique_id=entry.data[CONF_PROJECT_ID]\n        )\n\n    subscriber = await api.new_subscriber(hass, entry)\n    if not subscriber:\n        return False\n    # Keep media for last N events in memory\n    subscriber.cache_policy.event_cache_size = EVENT_MEDIA_CACHE_SIZE\n    subscriber.cache_policy.fetch = True\n    # Use disk backed event media store\n    subscriber.cache_policy.store = await async_get_media_event_store(hass, subscriber)\n    subscriber.cache_policy.transcoder = await async_get_transcoder(hass)\n\n    async def async_config_reload() -> None:\n        await hass.config_entries.async_reload(entry.entry_id)\n\n    update_callback = SignalUpdateCallback(hass, async_config_reload, entry)\n    subscriber.set_update_callback(update_callback.async_handle_event)\n    try:\n        unsub = await subscriber.start_async()\n    except AuthException as err:\n        raise ConfigEntryAuthFailed(\n            f\"Subscriber authentication error: {err!s}\"\n        ) from err\n    except ConfigurationException as err:\n        _LOGGER.error(\"Configuration error: %s\", err)\n        return False\n    except SubscriberException as err:\n        raise ConfigEntryNotReady(f\"Subscriber error: {err!s}\") from err\n\n    try:\n        device_manager = await subscriber.async_get_device_manager()\n    except ApiException as err:\n        unsub()\n        raise ConfigEntryNotReady(f\"Device manager error: {err!s}\") from err\n\n    @callback\n    def on_hass_stop(_: Event) -> None:\n        \"\"\"Close connection when hass stops.\"\"\"\n        unsub()\n\n    entry.async_on_unload(\n        hass.bus.async_listen_once(EVENT_HOMEASSISTANT_STOP, on_hass_stop)\n    )\n\n    entry.async_on_unload(unsub)\n    entry.runtime_data = NestData(\n        subscriber=subscriber,\n        device_manager=device_manager,\n    )\n\n    await hass.config_entries.async_forward_entry_setups(entry, PLATFORMS)\n\n    return True\n\n\nasync def async_unload_entry(hass: HomeAssistant, entry: NestConfigEntry) -> bool:\n    \"\"\"Unload a config entry.\"\"\"\n    return await hass.config_entries.async_unload_platforms(entry, PLATFORMS)\n\n\nasync def async_remove_entry(hass: HomeAssistant, entry: NestConfigEntry) -> None:\n    \"\"\"Handle removal of pubsub subscriptions created during config flow.\"\"\"\n    if (\n        DATA_SDM not in entry.data\n        or not (\n            CONF_SUBSCRIPTION_NAME in entry.data or CONF_SUBSCRIBER_ID in entry.data\n        )\n        or CONF_SUBSCRIBER_ID_IMPORTED in entry.data\n    ):\n        return\n    if (subscription_name := entry.data.get(CONF_SUBSCRIPTION_NAME)) is None:\n        subscription_name = entry.data[CONF_SUBSCRIBER_ID]\n    admin_client = api.new_pubsub_admin_client(\n        hass,\n        access_token=entry.data[\"token\"][\"access_token\"],\n        cloud_project_id=entry.data[CONF_CLOUD_PROJECT_ID],\n    )\n    _LOGGER.debug(\"Deleting subscription '%s'\", subscription_name)\n    try:\n        await admin_client.delete_subscription(subscription_name)\n    except ApiException as err:\n        _LOGGER.warning(\n            (\n                \"Unable to delete subscription '%s'; Will be automatically cleaned up\"\n                \" by cloud console: %s\"\n            ),\n            subscription_name,\n            err,\n        )\n\n\nclass NestEventViewBase(HomeAssistantView, ABC):\n    \"\"\"Base class for media event APIs.\"\"\"\n\n    def __init__(self, hass: HomeAssistant) -> None:\n        \"\"\"Initialize NestEventViewBase.\"\"\"\n        self.hass = hass\n\n    async def get(\n        self, request: web.Request, device_id: str, event_token: str\n    ) -> web.StreamResponse:\n        \"\"\"Start a GET request.\"\"\"\n        user = request[KEY_HASS_USER]\n        entity_registry = er.async_get(self.hass)\n        for entry in async_entries_for_device(entity_registry, device_id):\n            if not user.permissions.check_entity(entry.entity_id, POLICY_READ):\n                raise Unauthorized(entity_id=entry.entity_id)\n\n        devices = async_get_media_source_devices(self.hass)\n        if not (nest_device := devices.get(device_id)):\n            return self._json_error(\n                f\"No Nest Device found for '{device_id}'\", HTTPStatus.NOT_FOUND\n            )\n        try:\n            media = await self.load_media(nest_device, event_token)\n        except DecodeException:\n            return self._json_error(\n                f\"Event token was invalid '{event_token}'\", HTTPStatus.NOT_FOUND\n            )\n        except ApiException as err:\n            raise HomeAssistantError(\"Unable to fetch media for event\") from err\n        if not media:\n            return self._json_error(\n                f\"No event found for event_id '{event_token}'\", HTTPStatus.NOT_FOUND\n            )\n        return await self.handle_media(media)\n\n    @abstractmethod\n    async def load_media(self, nest_device: Device, event_token: str) -> Media | None:\n        \"\"\"Load the specified media.\"\"\"\n\n    @abstractmethod\n    async def handle_media(self, media: Media) -> web.StreamResponse:\n        \"\"\"Process the specified media.\"\"\"\n\n    def _json_error(self, message: str, status: HTTPStatus) -> web.StreamResponse:\n        \"\"\"Return a json error message with additional logging.\"\"\"\n        _LOGGER.debug(message)\n        return self.json_message(message, status)\n\n\nclass NestEventMediaView(NestEventViewBase):\n    \"\"\"Returns media for related to events for a specific device.\n\n    This is primarily used to render media for events for MediaSource. The media type\n    depends on the specific device e.g. an image, or a movie clip preview.\n    \"\"\"\n\n    url = \"/api/nest/event_media/{device_id}/{event_token}\"\n    name = \"api:nest:event_media\"\n\n    async def load_media(self, nest_device: Device, event_token: str) -> Media | None:\n        \"\"\"Load the specified media.\"\"\"\n        return await nest_device.event_media_manager.get_media_from_token(event_token)\n\n    async def handle_media(self, media: Media) -> web.StreamResponse:\n        \"\"\"Process the specified media.\"\"\"\n        return web.Response(body=media.contents, content_type=media.content_type)\n\n\nclass NestEventMediaThumbnailView(NestEventViewBase):\n    \"\"\"Returns media for related to events for a specific device.\n\n    This is primarily used to render media for events for MediaSource. The media type\n    depends on the specific device e.g. an image, or a movie clip preview.\n\n    mp4 clips are transcoded and thumbnailed by the SDM transcoder. jpgs are thumbnailed\n    from the original in this view.\n    \"\"\"\n\n    url = \"/api/nest/event_media/{device_id}/{event_token}/thumbnail\"\n    name = \"api:nest:event_media\"\n\n    def __init__(self, hass: HomeAssistant) -> None:\n        \"\"\"Initialize NestEventMediaThumbnailView.\"\"\"\n        super().__init__(hass)\n        self._lock = asyncio.Lock()\n        self.hass = hass\n\n    async def load_media(self, nest_device: Device, event_token: str) -> Media | None:\n        \"\"\"Load the specified media.\"\"\"\n        if CameraClipPreviewTrait.NAME in nest_device.traits:\n            async with self._lock:  # Only one transcode subprocess at a time\n                return (\n                    await nest_device.event_media_manager.get_clip_thumbnail_from_token(\n                        event_token\n                    )\n                )\n        return await nest_device.event_media_manager.get_media_from_token(event_token)\n\n    async def handle_media(self, media: Media) -> web.StreamResponse:\n        \"\"\"Start a GET request.\"\"\"\n        contents = media.contents\n        if (content_type := media.content_type) == \"image/jpeg\":\n            image = Image(media.event_image_type.content_type, contents)\n            contents = img_util.scale_jpeg_camera_image(\n                image, THUMBNAIL_SIZE_PX, THUMBNAIL_SIZE_PX\n            )\n        return web.Response(body=contents, content_type=content_type)",
    "repo": "home-assistant/core",
    "path": "./datasets/diagrams-repos/home-assistant/core/homeassistant/components/nest/__init__.py",
    "query": "What is the structure of the NestEventViewBase and its subclasses, and how do they handle media requests?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'NestEventViewBase', 'node_id': 'NestEventViewBase', 'description': 'Abstract base class for handling Nest media event requests', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'get', 'node_id': 'get', 'description': 'Handles GET request for media events', 'visibility': 'public', 'return_type': 'web.StreamResponse', 'params': '(request, device_id, event_token)', 'source_class_id': 'NestEventViewBase'}, {'type': 'method', 'name': 'load_media', 'node_id': 'load_media', 'description': 'Abstract method to load media for specific event', 'visibility': 'public', 'return_type': 'Media | None', 'params': '(nest_device, event_token)', 'source_class_id': 'NestEventViewBase'}, {'type': 'method', 'name': 'handle_media', 'node_id': 'handle_media', 'description': 'Abstract method to process loaded media', 'visibility': 'public', 'return_type': 'web.StreamResponse', 'params': '(media)', 'source_class_id': 'NestEventViewBase'}, {'type': 'method', 'name': '_json_error', 'node_id': '_json_error', 'description': 'Returns JSON error response', 'visibility': 'private', 'return_type': 'web.StreamResponse', 'params': '(message, status)', 'source_class_id': 'NestEventViewBase'}, {'type': 'class', 'name': 'NestEventMediaView', 'node_id': 'NestEventMediaView', 'description': 'Handles media event requests for full media content', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'NestEventMediaThumbnailView', 'node_id': 'NestEventMediaThumbnailView', 'description': 'Handles media event requests for thumbnails', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'url', 'node_id': 'url', 'description': 'URL pattern for media requests', 'visibility': 'public', 'return_type': 'str', 'params': None, 'source_class_id': 'NestEventViewBase'}, {'type': 'field', 'name': 'name', 'node_id': 'name', 'description': 'API endpoint name', 'visibility': 'public', 'return_type': 'str', 'params': None, 'source_class_id': 'NestEventViewBase'}], 'edges': [{'node_id_from': 'NestEventMediaView', 'node_id_to': 'NestEventViewBase', 'description': 'inherits'}, {'node_id_from': 'NestEventMediaThumbnailView', 'node_id_to': 'NestEventViewBase', 'description': 'inherits'}, {'node_id_from': 'get', 'node_id_to': 'load_media', 'description': 'calls'}, {'node_id_from': 'get', 'node_id_to': 'handle_media', 'description': 'calls'}, {'node_id_from': 'NestEventViewBase', 'node_id_to': 'get', 'description': ''}, {'node_id_from': 'NestEventViewBase', 'node_id_to': '_json_error', 'description': ''}, {'node_id_from': 'NestEventViewBase', 'node_id_to': 'url', 'description': ''}, {'node_id_from': 'NestEventViewBase', 'node_id_to': 'name', 'description': ''}, {'node_id_from': 'NestEventViewBase', 'node_id_to': 'load_media', 'description': ''}, {'node_id_from': 'NestEventViewBase', 'node_id_to': 'handle_media', 'description': ''}], 'packages': [{'package_id': 'mediaHandling', 'children': ['NestEventViewBase', 'NestEventMediaView', 'NestEventMediaThumbnailView', 'get', 'load_media', 'handle_media', '_json_error', 'url', 'name'], 'description': 'Classes for handling Nest media requests'}]}",
    "version": "medium",
    "text_answer": "NestEventViewBase is an abstract base class that defines the structure for handling Nest media requests. It has two concrete implementations: NestEventMediaView for handling full media content and NestEventMediaThumbnailView for handling thumbnails. The base class implements a common GET request flow, while the subclasses provide specific implementations for loading and handling different types of media content.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Python",
    "code": "\nfrom __future__ import annotations\n\nfrom abc import ABC, abstractmethod\nimport asyncio\nfrom collections.abc import Awaitable, Callable\nfrom http import HTTPStatus\nimport logging\n\nfrom aiohttp import web\nfrom google_nest_sdm.camera_traits import CameraClipPreviewTrait\nfrom google_nest_sdm.device import Device\nfrom google_nest_sdm.event import EventMessage\nfrom google_nest_sdm.event_media import Media\nfrom google_nest_sdm.exceptions import (\n    ApiException,\n    AuthException,\n    ConfigurationException,\n    DecodeException,\n    SubscriberException,\n)\nfrom google_nest_sdm.traits import TraitType\nimport voluptuous as vol\n\nfrom homeassistant.auth.permissions.const import POLICY_READ\nfrom homeassistant.components.camera import Image, img_util\nfrom homeassistant.components.http import KEY_HASS_USER\nfrom homeassistant.components.http.view import HomeAssistantView\nfrom homeassistant.const import (\n    CONF_BINARY_SENSORS,\n    CONF_CLIENT_ID,\n    CONF_CLIENT_SECRET,\n    CONF_MONITORED_CONDITIONS,\n    CONF_SENSORS,\n    CONF_STRUCTURE,\n    EVENT_HOMEASSISTANT_STOP,\n    Platform,\n)\nfrom homeassistant.core import Event, HomeAssistant, callback\nfrom homeassistant.exceptions import (\n    ConfigEntryAuthFailed,\n    ConfigEntryNotReady,\n    HomeAssistantError,\n    Unauthorized,\n)\nfrom homeassistant.helpers import (\n    config_validation as cv,\n    device_registry as dr,\n    entity_registry as er,\n)\nfrom homeassistant.helpers.entity_registry import async_entries_for_device\nfrom homeassistant.helpers.typing import ConfigType\n\nfrom . import api\nfrom .const import (\n    CONF_CLOUD_PROJECT_ID,\n    CONF_PROJECT_ID,\n    CONF_SUBSCRIBER_ID,\n    CONF_SUBSCRIBER_ID_IMPORTED,\n    CONF_SUBSCRIPTION_NAME,\n    DATA_SDM,\n    DOMAIN,\n)\nfrom .events import EVENT_NAME_MAP, NEST_EVENT\nfrom .media_source import (\n    EVENT_MEDIA_API_URL_FORMAT,\n    EVENT_THUMBNAIL_URL_FORMAT,\n    async_get_media_event_store,\n    async_get_media_source_devices,\n    async_get_transcoder,\n)\nfrom .types import NestConfigEntry, NestData\n\n_LOGGER = logging.getLogger(__name__)\n\n\nSENSOR_SCHEMA = vol.Schema(\n    {vol.Optional(CONF_MONITORED_CONDITIONS): vol.All(cv.ensure_list)}\n)\n\nCONFIG_SCHEMA = vol.Schema(\n    {\n        DOMAIN: vol.Schema(\n            {\n                vol.Required(CONF_CLIENT_ID): cv.string,\n                vol.Required(CONF_CLIENT_SECRET): cv.string,\n                # Required to use the new API (optional for compatibility)\n                vol.Optional(CONF_PROJECT_ID): cv.string,\n                vol.Optional(CONF_SUBSCRIBER_ID): cv.string,\n                # Config that only currently works on the old API\n                vol.Optional(CONF_STRUCTURE): vol.All(cv.ensure_list, [cv.string]),\n                vol.Optional(CONF_SENSORS): SENSOR_SCHEMA,\n                vol.Optional(CONF_BINARY_SENSORS): SENSOR_SCHEMA,\n            }\n        )\n    },\n    extra=vol.ALLOW_EXTRA,\n)\n\n# Platforms for SDM API\nPLATFORMS = [Platform.CAMERA, Platform.CLIMATE, Platform.EVENT, Platform.SENSOR]\n\n# Fetch media events with a disk backed cache, with a limit for each camera\n# device. The largest media items are mp4 clips at ~450kb each, and we target\n# ~125MB of storage per camera to try to balance a reasonable user experience\n# for event history not not filling the disk.\nEVENT_MEDIA_CACHE_SIZE = 256  # number of events\n\nTHUMBNAIL_SIZE_PX = 175\n\n\nasync def async_setup(hass: HomeAssistant, config: ConfigType) -> bool:\n    \"\"\"Set up Nest components with dispatch between old/new flows.\"\"\"\n    hass.http.register_view(NestEventMediaView(hass))\n    hass.http.register_view(NestEventMediaThumbnailView(hass))\n    return True\n\n\nclass SignalUpdateCallback:\n    \"\"\"An EventCallback invoked when new events arrive from subscriber.\"\"\"\n\n    def __init__(\n        self,\n        hass: HomeAssistant,\n        config_reload_cb: Callable[[], Awaitable[None]],\n        config_entry: NestConfigEntry,\n    ) -> None:\n        \"\"\"Initialize EventCallback.\"\"\"\n        self._hass = hass\n        self._config_reload_cb = config_reload_cb\n        self._config_entry = config_entry\n\n    async def async_handle_event(self, event_message: EventMessage) -> None:\n        \"\"\"Process an incoming EventMessage.\"\"\"\n        if event_message.relation_update:\n            _LOGGER.info(\"Devices or homes have changed; Need reload to take effect\")\n            return\n        if not event_message.resource_update_name:\n            return\n        device_id = event_message.resource_update_name\n        if not (events := event_message.resource_update_events):\n            return\n        _LOGGER.debug(\"Event Update %s\", events.keys())\n        device_registry = dr.async_get(self._hass)\n        device_entry = device_registry.async_get_device(\n            identifiers={(DOMAIN, device_id)}\n        )\n        if not device_entry:\n            return\n        supported_traits = self._supported_traits(device_id)\n        for api_event_type, image_event in events.items():\n            if not (event_type := EVENT_NAME_MAP.get(api_event_type)):\n                continue\n            nest_event_id = image_event.event_token\n            message = {\n                \"device_id\": device_entry.id,\n                \"type\": event_type,\n                \"timestamp\": event_message.timestamp,\n                \"nest_event_id\": nest_event_id,\n            }\n            if (\n                TraitType.CAMERA_EVENT_IMAGE in supported_traits\n                or TraitType.CAMERA_CLIP_PREVIEW in supported_traits\n            ):\n                attachment = {\n                    \"image\": EVENT_THUMBNAIL_URL_FORMAT.format(\n                        device_id=device_entry.id, event_token=image_event.event_token\n                    )\n                }\n                if TraitType.CAMERA_CLIP_PREVIEW in supported_traits:\n                    attachment[\"video\"] = EVENT_MEDIA_API_URL_FORMAT.format(\n                        device_id=device_entry.id, event_token=image_event.event_token\n                    )\n                message[\"attachment\"] = attachment\n            if image_event.zones:\n                message[\"zones\"] = image_event.zones\n            self._hass.bus.async_fire(NEST_EVENT, message)\n\n    def _supported_traits(self, device_id: str) -> list[str]:\n        if (\n            not self._config_entry.runtime_data\n            or not (device_manager := self._config_entry.runtime_data.device_manager)\n            or not (device := device_manager.devices.get(device_id))\n        ):\n            return []\n        return list(device.traits)\n\n\nasync def async_setup_entry(hass: HomeAssistant, entry: NestConfigEntry) -> bool:\n    \"\"\"Set up Nest from a config entry with dispatch between old/new flows.\"\"\"\n    if DATA_SDM not in entry.data:\n        hass.async_create_task(hass.config_entries.async_remove(entry.entry_id))\n        return False\n\n    if entry.unique_id != entry.data[CONF_PROJECT_ID]:\n        hass.config_entries.async_update_entry(\n            entry, unique_id=entry.data[CONF_PROJECT_ID]\n        )\n\n    subscriber = await api.new_subscriber(hass, entry)\n    if not subscriber:\n        return False\n    # Keep media for last N events in memory\n    subscriber.cache_policy.event_cache_size = EVENT_MEDIA_CACHE_SIZE\n    subscriber.cache_policy.fetch = True\n    # Use disk backed event media store\n    subscriber.cache_policy.store = await async_get_media_event_store(hass, subscriber)\n    subscriber.cache_policy.transcoder = await async_get_transcoder(hass)\n\n    async def async_config_reload() -> None:\n        await hass.config_entries.async_reload(entry.entry_id)\n\n    update_callback = SignalUpdateCallback(hass, async_config_reload, entry)\n    subscriber.set_update_callback(update_callback.async_handle_event)\n    try:\n        unsub = await subscriber.start_async()\n    except AuthException as err:\n        raise ConfigEntryAuthFailed(\n            f\"Subscriber authentication error: {err!s}\"\n        ) from err\n    except ConfigurationException as err:\n        _LOGGER.error(\"Configuration error: %s\", err)\n        return False\n    except SubscriberException as err:\n        raise ConfigEntryNotReady(f\"Subscriber error: {err!s}\") from err\n\n    try:\n        device_manager = await subscriber.async_get_device_manager()\n    except ApiException as err:\n        unsub()\n        raise ConfigEntryNotReady(f\"Device manager error: {err!s}\") from err\n\n    @callback\n    def on_hass_stop(_: Event) -> None:\n        \"\"\"Close connection when hass stops.\"\"\"\n        unsub()\n\n    entry.async_on_unload(\n        hass.bus.async_listen_once(EVENT_HOMEASSISTANT_STOP, on_hass_stop)\n    )\n\n    entry.async_on_unload(unsub)\n    entry.runtime_data = NestData(\n        subscriber=subscriber,\n        device_manager=device_manager,\n    )\n\n    await hass.config_entries.async_forward_entry_setups(entry, PLATFORMS)\n\n    return True\n\n\nasync def async_unload_entry(hass: HomeAssistant, entry: NestConfigEntry) -> bool:\n    \"\"\"Unload a config entry.\"\"\"\n    return await hass.config_entries.async_unload_platforms(entry, PLATFORMS)\n\n\nasync def async_remove_entry(hass: HomeAssistant, entry: NestConfigEntry) -> None:\n    \"\"\"Handle removal of pubsub subscriptions created during config flow.\"\"\"\n    if (\n        DATA_SDM not in entry.data\n        or not (\n            CONF_SUBSCRIPTION_NAME in entry.data or CONF_SUBSCRIBER_ID in entry.data\n        )\n        or CONF_SUBSCRIBER_ID_IMPORTED in entry.data\n    ):\n        return\n    if (subscription_name := entry.data.get(CONF_SUBSCRIPTION_NAME)) is None:\n        subscription_name = entry.data[CONF_SUBSCRIBER_ID]\n    admin_client = api.new_pubsub_admin_client(\n        hass,\n        access_token=entry.data[\"token\"][\"access_token\"],\n        cloud_project_id=entry.data[CONF_CLOUD_PROJECT_ID],\n    )\n    _LOGGER.debug(\"Deleting subscription '%s'\", subscription_name)\n    try:\n        await admin_client.delete_subscription(subscription_name)\n    except ApiException as err:\n        _LOGGER.warning(\n            (\n                \"Unable to delete subscription '%s'; Will be automatically cleaned up\"\n                \" by cloud console: %s\"\n            ),\n            subscription_name,\n            err,\n        )\n\n\nclass NestEventViewBase(HomeAssistantView, ABC):\n    \"\"\"Base class for media event APIs.\"\"\"\n\n    def __init__(self, hass: HomeAssistant) -> None:\n        \"\"\"Initialize NestEventViewBase.\"\"\"\n        self.hass = hass\n\n    async def get(\n        self, request: web.Request, device_id: str, event_token: str\n    ) -> web.StreamResponse:\n        \"\"\"Start a GET request.\"\"\"\n        user = request[KEY_HASS_USER]\n        entity_registry = er.async_get(self.hass)\n        for entry in async_entries_for_device(entity_registry, device_id):\n            if not user.permissions.check_entity(entry.entity_id, POLICY_READ):\n                raise Unauthorized(entity_id=entry.entity_id)\n\n        devices = async_get_media_source_devices(self.hass)\n        if not (nest_device := devices.get(device_id)):\n            return self._json_error(\n                f\"No Nest Device found for '{device_id}'\", HTTPStatus.NOT_FOUND\n            )\n        try:\n            media = await self.load_media(nest_device, event_token)\n        except DecodeException:\n            return self._json_error(\n                f\"Event token was invalid '{event_token}'\", HTTPStatus.NOT_FOUND\n            )\n        except ApiException as err:\n            raise HomeAssistantError(\"Unable to fetch media for event\") from err\n        if not media:\n            return self._json_error(\n                f\"No event found for event_id '{event_token}'\", HTTPStatus.NOT_FOUND\n            )\n        return await self.handle_media(media)\n\n    @abstractmethod\n    async def load_media(self, nest_device: Device, event_token: str) -> Media | None:\n        \"\"\"Load the specified media.\"\"\"\n\n    @abstractmethod\n    async def handle_media(self, media: Media) -> web.StreamResponse:\n        \"\"\"Process the specified media.\"\"\"\n\n    def _json_error(self, message: str, status: HTTPStatus) -> web.StreamResponse:\n        \"\"\"Return a json error message with additional logging.\"\"\"\n        _LOGGER.debug(message)\n        return self.json_message(message, status)\n\n\nclass NestEventMediaView(NestEventViewBase):\n    \"\"\"Returns media for related to events for a specific device.\n\n    This is primarily used to render media for events for MediaSource. The media type\n    depends on the specific device e.g. an image, or a movie clip preview.\n    \"\"\"\n\n    url = \"/api/nest/event_media/{device_id}/{event_token}\"\n    name = \"api:nest:event_media\"\n\n    async def load_media(self, nest_device: Device, event_token: str) -> Media | None:\n        \"\"\"Load the specified media.\"\"\"\n        return await nest_device.event_media_manager.get_media_from_token(event_token)\n\n    async def handle_media(self, media: Media) -> web.StreamResponse:\n        \"\"\"Process the specified media.\"\"\"\n        return web.Response(body=media.contents, content_type=media.content_type)\n\n\nclass NestEventMediaThumbnailView(NestEventViewBase):\n    \"\"\"Returns media for related to events for a specific device.\n\n    This is primarily used to render media for events for MediaSource. The media type\n    depends on the specific device e.g. an image, or a movie clip preview.\n\n    mp4 clips are transcoded and thumbnailed by the SDM transcoder. jpgs are thumbnailed\n    from the original in this view.\n    \"\"\"\n\n    url = \"/api/nest/event_media/{device_id}/{event_token}/thumbnail\"\n    name = \"api:nest:event_media\"\n\n    def __init__(self, hass: HomeAssistant) -> None:\n        \"\"\"Initialize NestEventMediaThumbnailView.\"\"\"\n        super().__init__(hass)\n        self._lock = asyncio.Lock()\n        self.hass = hass\n\n    async def load_media(self, nest_device: Device, event_token: str) -> Media | None:\n        \"\"\"Load the specified media.\"\"\"\n        if CameraClipPreviewTrait.NAME in nest_device.traits:\n            async with self._lock:  # Only one transcode subprocess at a time\n                return (\n                    await nest_device.event_media_manager.get_clip_thumbnail_from_token(\n                        event_token\n                    )\n                )\n        return await nest_device.event_media_manager.get_media_from_token(event_token)\n\n    async def handle_media(self, media: Media) -> web.StreamResponse:\n        \"\"\"Start a GET request.\"\"\"\n        contents = media.contents\n        if (content_type := media.content_type) == \"image/jpeg\":\n            image = Image(media.event_image_type.content_type, contents)\n            contents = img_util.scale_jpeg_camera_image(\n                image, THUMBNAIL_SIZE_PX, THUMBNAIL_SIZE_PX\n            )\n        return web.Response(body=contents, content_type=content_type)",
    "repo": "home-assistant/core",
    "path": "./datasets/diagrams-repos/home-assistant/core/homeassistant/components/nest/__init__.py",
    "query": "What is the structure of the NestEventViewBase and its subclasses, and how do they handle media requests?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'NestEventViewBase', 'node_id': 'NestEventViewBase', 'description': 'Abstract base class for handling Nest media event requests', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'get', 'node_id': 'get', 'description': 'Handles GET request for media events', 'visibility': 'public', 'return_type': 'web.StreamResponse', 'params': '(request, device_id, event_token)', 'source_class_id': 'NestEventViewBase'}, {'type': 'method', 'name': 'load_media', 'node_id': 'load_media', 'description': 'Abstract method to load media for specific event', 'visibility': 'public', 'return_type': 'Media | None', 'params': '(nest_device, event_token)', 'source_class_id': 'NestEventViewBase'}, {'type': 'method', 'name': 'handle_media', 'node_id': 'handle_media', 'description': 'Abstract method to process loaded media', 'visibility': 'public', 'return_type': 'web.StreamResponse', 'params': '(media)', 'source_class_id': 'NestEventViewBase'}, {'type': 'method', 'name': '_json_error', 'node_id': '_json_error', 'description': 'Returns JSON error response', 'visibility': 'private', 'return_type': 'web.StreamResponse', 'params': '(message, status)', 'source_class_id': 'NestEventViewBase'}, {'type': 'class', 'name': 'NestEventMediaView', 'node_id': 'NestEventMediaView', 'description': 'Handles media event requests for full media content', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'NestEventMediaThumbnailView', 'node_id': 'NestEventMediaThumbnailView', 'description': 'Handles media event requests for thumbnails', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'url', 'node_id': 'url', 'description': 'URL pattern for media requests', 'visibility': 'public', 'return_type': 'str', 'params': None, 'source_class_id': 'NestEventViewBase'}, {'type': 'field', 'name': 'name', 'node_id': 'name', 'description': 'API endpoint name', 'visibility': 'public', 'return_type': 'str', 'params': None, 'source_class_id': 'NestEventViewBase'}, {'type': 'field', 'name': '_lock', 'node_id': '_lock', 'description': 'Lock for thumbnail processing', 'visibility': 'private', 'return_type': 'asyncio.Lock', 'params': None, 'source_class_id': 'NestEventMediaThumbnailView'}, {'type': 'field', 'name': 'hass', 'node_id': 'hass', 'description': 'HomeAssistant instance', 'visibility': 'protected', 'return_type': 'HomeAssistant', 'params': None, 'source_class_id': 'NestEventViewBase'}, {'type': 'entity', 'name': 'THUMBNAIL_SIZE_PX', 'node_id': 'THUMBNAIL_SIZE_PX', 'description': 'Thumbnail size in pixels', 'visibility': 'public', 'return_type': 'int', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'NestEventMediaView', 'node_id_to': 'NestEventViewBase', 'description': 'inherits'}, {'node_id_from': 'NestEventMediaThumbnailView', 'node_id_to': 'NestEventViewBase', 'description': 'inherits'}, {'node_id_from': 'get', 'node_id_to': 'load_media', 'description': 'calls'}, {'node_id_from': 'get', 'node_id_to': 'handle_media', 'description': 'calls'}, {'node_id_from': 'get', 'node_id_to': '_json_error', 'description': 'calls on error'}, {'node_id_from': 'handle_media', 'node_id_to': 'THUMBNAIL_SIZE_PX', 'description': ''}, {'node_id_from': 'NestEventViewBase', 'node_id_to': 'get', 'description': ''}, {'node_id_from': 'NestEventViewBase', 'node_id_to': 'url', 'description': ''}, {'node_id_from': 'NestEventViewBase', 'node_id_to': 'name', 'description': ''}, {'node_id_from': 'NestEventViewBase', 'node_id_to': 'hass', 'description': ''}, {'node_id_from': 'NestEventViewBase', 'node_id_to': '_json_error', 'description': ''}, {'node_id_from': 'NestEventViewBase', 'node_id_to': 'load_media', 'description': ''}, {'node_id_from': 'NestEventViewBase', 'node_id_to': 'handle_media', 'description': ''}, {'node_id_from': 'NestEventMediaThumbnailView', 'node_id_to': '_lock', 'description': ''}], 'packages': [{'package_id': 'mediaHandling', 'children': ['NestEventViewBase', 'NestEventMediaView', 'NestEventMediaThumbnailView', 'THUMBNAIL_SIZE_PX', 'get', 'load_media', 'handle_media', '_json_error', 'url', 'name', '_lock', 'hass'], 'description': 'Classes for handling Nest media requests'}]}",
    "version": "full",
    "text_answer": "NestEventViewBase is an abstract base class that defines the structure for handling Nest media requests. It has two concrete implementations: NestEventMediaView for handling full media content and NestEventMediaThumbnailView for handling thumbnails. The base class implements a common GET request flow, while the subclasses provide specific implementations for loading and handling different types of media content.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C++",
    "code": "\n#pragma once\n\n#include \"AuxiliaryBarrierInlines.h\"\n#include \"Error.h\"\n#include \"JSObject.h\"\n#include \"Lookup.h\"\n\nnamespace JSC {\n\n// Section 7.3.17 of the spec.\ntemplate <typename AddFunction> // Add function should have a type like: (JSValue, RuntimeType) -> bool\nvoid createListFromArrayLike(ExecState* exec, JSValue arrayLikeValue, RuntimeTypeMask legalTypesFilter, const String& errorMessage, AddFunction addFunction)\n{\n    VM& vm = exec->vm();\n    auto scope = DECLARE_THROW_SCOPE(vm);\n    \n    Vector<JSValue> result;\n    JSValue lengthProperty = arrayLikeValue.get(exec, vm.propertyNames->length);\n    RETURN_IF_EXCEPTION(scope, void());\n    double lengthAsDouble = lengthProperty.toLength(exec);\n    RETURN_IF_EXCEPTION(scope, void());\n    RELEASE_ASSERT(lengthAsDouble >= 0.0 && lengthAsDouble == std::trunc(lengthAsDouble));\n    uint64_t length = static_cast<uint64_t>(lengthAsDouble);\n    for (uint64_t index = 0; index < length; index++) {\n        JSValue next = arrayLikeValue.get(exec, index);\n        RETURN_IF_EXCEPTION(scope, void());\n        \n        RuntimeType type = runtimeTypeForValue(next);\n        if (!(type & legalTypesFilter)) {\n            throwTypeError(exec, scope, errorMessage);\n            return;\n        }\n        \n        bool exitEarly = addFunction(next, type);\n        if (exitEarly)\n            return;\n    }\n}\n\nALWAYS_INLINE bool JSObject::canPerformFastPutInline(ExecState* exec, VM& vm, PropertyName propertyName)\n{\n    if (UNLIKELY(propertyName == exec->propertyNames().underscoreProto))\n        return false;\n\n    // Check if there are any setters or getters in the prototype chain\n    JSValue prototype;\n    JSObject* obj = this;\n    while (true) {\n        if (obj->structure(vm)->hasReadOnlyOrGetterSetterPropertiesExcludingProto() || obj->type() == ProxyObjectType)\n            return false;\n\n        prototype = obj->getPrototypeDirect();\n        if (prototype.isNull())\n            return true;\n\n        obj = asObject(prototype);\n    }\n\n    ASSERT_NOT_REACHED();\n}\n\ntemplate<typename CallbackWhenNoException>\nALWAYS_INLINE typename std::result_of<CallbackWhenNoException(bool, PropertySlot&)>::type JSObject::getPropertySlot(ExecState* exec, PropertyName propertyName, CallbackWhenNoException callback) const\n{\n    PropertySlot slot(this, PropertySlot::InternalMethodType::Get);\n    return getPropertySlot(exec, propertyName, slot, callback);\n}\n\ntemplate<typename CallbackWhenNoException>\nALWAYS_INLINE typename std::result_of<CallbackWhenNoException(bool, PropertySlot&)>::type JSObject::getPropertySlot(ExecState* exec, PropertyName propertyName, PropertySlot& slot, CallbackWhenNoException callback) const\n{\n    VM& vm = exec->vm();\n    auto scope = DECLARE_THROW_SCOPE(vm);\n    bool found = const_cast<JSObject*>(this)->getPropertySlot(exec, propertyName, slot);\n    RETURN_IF_EXCEPTION(scope, { });\n    return callback(found, slot);\n}\n\nALWAYS_INLINE bool JSObject::getPropertySlot(ExecState* exec, unsigned propertyName, PropertySlot& slot)\n{\n    VM& vm = exec->vm();\n    auto scope = DECLARE_THROW_SCOPE(vm);\n    auto& structureIDTable = vm.heap.structureIDTable();\n    JSObject* object = this;\n    MethodTable::GetPrototypeFunctionPtr defaultGetPrototype = JSObject::getPrototype;\n    while (true) {\n        Structure* structure = structureIDTable.get(object->structureID());\n        if (structure->classInfo()->methodTable.getOwnPropertySlotByIndex(object, exec, propertyName, slot))\n            return true;\n        RETURN_IF_EXCEPTION(scope, false);\n        JSValue prototype;\n        if (LIKELY(structure->classInfo()->methodTable.getPrototype == defaultGetPrototype || slot.internalMethodType() == PropertySlot::InternalMethodType::VMInquiry))\n            prototype = structure->storedPrototype();\n        else {\n            prototype = object->getPrototype(vm, exec);\n            RETURN_IF_EXCEPTION(scope, false);\n        }\n        if (!prototype.isObject())\n            return false;\n        object = asObject(prototype);\n    }\n}\n\nALWAYS_INLINE bool JSObject::getNonIndexPropertySlot(ExecState* exec, PropertyName propertyName, PropertySlot& slot)\n{\n    // This method only supports non-index PropertyNames.\n    ASSERT(!parseIndex(propertyName));\n\n    VM& vm = exec->vm();\n    auto scope = DECLARE_THROW_SCOPE(vm);\n    auto& structureIDTable = vm.heap.structureIDTable();\n    JSObject* object = this;\n    MethodTable::GetPrototypeFunctionPtr defaultGetPrototype = JSObject::getPrototype;\n    while (true) {\n        Structure* structure = structureIDTable.get(object->structureID());\n        if (LIKELY(!TypeInfo::overridesGetOwnPropertySlot(object->inlineTypeFlags()))) {\n            if (object->getOwnNonIndexPropertySlot(vm, structure, propertyName, slot))\n                return true;\n        } else {\n            if (structure->classInfo()->methodTable.getOwnPropertySlot(object, exec, propertyName, slot))\n                return true;\n            RETURN_IF_EXCEPTION(scope, false);\n        }\n        JSValue prototype;\n        if (LIKELY(structure->classInfo()->methodTable.getPrototype == defaultGetPrototype || slot.internalMethodType() == PropertySlot::InternalMethodType::VMInquiry))\n            prototype = structure->storedPrototype();\n        else {\n            prototype = object->getPrototype(vm, exec);\n            RETURN_IF_EXCEPTION(scope, false);\n        }\n        if (!prototype.isObject())\n            return false;\n        object = asObject(prototype);\n    }\n}\n\ninline void JSObject::putDirectWithoutTransition(VM& vm, PropertyName propertyName, JSValue value, unsigned attributes)\n{\n    ASSERT(!value.isGetterSetter() && !(attributes & Accessor));\n    ASSERT(!value.isCustomGetterSetter());\n    StructureID structureID = this->structureID();\n    Structure* structure = vm.heap.structureIDTable().get(structureID);\n    PropertyOffset offset = prepareToPutDirectWithoutTransition(vm, propertyName, attributes, structureID, structure);\n    bool shouldOptimize = false;\n    structure->willStoreValueForNewTransition(vm, propertyName, value, shouldOptimize);\n    putDirect(vm, offset, value);\n    if (attributes & ReadOnly)\n        structure->setContainsReadOnlyProperties();\n}\n\nALWAYS_INLINE PropertyOffset JSObject::prepareToPutDirectWithoutTransition(VM& vm, PropertyName propertyName, unsigned attributes, StructureID structureID, Structure* structure)\n{\n    unsigned oldOutOfLineCapacity = structure->outOfLineCapacity();\n    PropertyOffset result;\n    structure->addPropertyWithoutTransition(\n        vm, propertyName, attributes,\n        [&] (const GCSafeConcurrentJSLocker&, PropertyOffset offset, PropertyOffset newLastOffset) {\n            unsigned newOutOfLineCapacity = Structure::outOfLineCapacity(newLastOffset);\n            if (newOutOfLineCapacity != oldOutOfLineCapacity) {\n                Butterfly* butterfly = allocateMoreOutOfLineStorage(vm, oldOutOfLineCapacity, newOutOfLineCapacity);\n                nukeStructureAndSetButterfly(vm, structureID, butterfly);\n                structure->setLastOffset(newLastOffset);\n                WTF::storeStoreFence();\n                setStructureIDDirectly(structureID);\n            } else\n                structure->setLastOffset(newLastOffset);\n            result = offset;\n        });\n    return result;\n}\n\n// ECMA 8.6.2.2\nALWAYS_INLINE bool JSObject::putInline(JSCell* cell, ExecState* exec, PropertyName propertyName, JSValue value, PutPropertySlot& slot)\n{\n    VM& vm = exec->vm();\n    auto scope = DECLARE_THROW_SCOPE(vm);\n\n    JSObject* thisObject = jsCast<JSObject*>(cell);\n    ASSERT(value);\n    ASSERT(!Heap::heap(value) || Heap::heap(value) == Heap::heap(thisObject));\n\n    if (UNLIKELY(isThisValueAltered(slot, thisObject)))\n        return ordinarySetSlow(exec, thisObject, propertyName, value, slot.thisValue(), slot.isStrictMode());\n\n    // Try indexed put first. This is required for correctness, since loads on property names that appear like\n    // valid indices will never look in the named property storage.\n    if (std::optional<uint32_t> index = parseIndex(propertyName))\n        return putByIndex(thisObject, exec, index.value(), value, slot.isStrictMode());\n\n    if (thisObject->canPerformFastPutInline(exec, vm, propertyName)) {\n        ASSERT(!thisObject->structure(vm)->prototypeChainMayInterceptStoreTo(vm, propertyName));\n        if (!thisObject->putDirectInternal<PutModePut>(vm, propertyName, value, 0, slot))\n            return typeError(exec, scope, slot.isStrictMode(), ASCIILiteral(ReadonlyPropertyWriteError));\n        return true;\n    }\n\n    return thisObject->putInlineSlow(exec, propertyName, value, slot);\n}\n\n// HasOwnProperty(O, P) from section 7.3.11 in the spec.\n// http://www.ecma-international.org/ecma-262/6.0/index.html#sec-hasownproperty\nALWAYS_INLINE bool JSObject::hasOwnProperty(ExecState* exec, PropertyName propertyName, PropertySlot& slot) const\n{\n    ASSERT(slot.internalMethodType() == PropertySlot::InternalMethodType::GetOwnProperty);\n    if (LIKELY(const_cast<JSObject*>(this)->methodTable(exec->vm())->getOwnPropertySlot == JSObject::getOwnPropertySlot))\n        return JSObject::getOwnPropertySlot(const_cast<JSObject*>(this), exec, propertyName, slot);\n    return const_cast<JSObject*>(this)->methodTable(exec->vm())->getOwnPropertySlot(const_cast<JSObject*>(this), exec, propertyName, slot);\n}\n\nALWAYS_INLINE bool JSObject::hasOwnProperty(ExecState* exec, PropertyName propertyName) const\n{\n    PropertySlot slot(this, PropertySlot::InternalMethodType::GetOwnProperty);\n    return hasOwnProperty(exec, propertyName, slot);\n}\n\nALWAYS_INLINE bool JSObject::hasOwnProperty(ExecState* exec, unsigned propertyName) const\n{\n    PropertySlot slot(this, PropertySlot::InternalMethodType::GetOwnProperty);\n    return const_cast<JSObject*>(this)->methodTable(exec->vm())->getOwnPropertySlotByIndex(const_cast<JSObject*>(this), exec, propertyName, slot);\n}\n\ntemplate<JSObject::PutMode mode>\nALWAYS_INLINE bool JSObject::putDirectInternal(VM& vm, PropertyName propertyName, JSValue value, unsigned attributes, PutPropertySlot& slot)\n{\n    ASSERT(value);\n    ASSERT(value.isGetterSetter() == !!(attributes & Accessor));\n    ASSERT(!Heap::heap(value) || Heap::heap(value) == Heap::heap(this));\n    ASSERT(!parseIndex(propertyName));\n\n    StructureID structureID = this->structureID();\n    Structure* structure = vm.heap.structureIDTable().get(structureID);\n    if (structure->isDictionary()) {\n        ASSERT(!structure->hasInferredTypes());\n        \n        unsigned currentAttributes;\n        PropertyOffset offset = structure->get(vm, propertyName, currentAttributes);\n        if (offset != invalidOffset) {\n            if ((mode == PutModePut) && currentAttributes & ReadOnly)\n                return false;\n\n            putDirect(vm, offset, value);\n            structure->didReplaceProperty(offset);\n            slot.setExistingProperty(this, offset);\n\n            if ((attributes & Accessor) != (currentAttributes & Accessor) || (attributes & CustomAccessor) != (currentAttributes & CustomAccessor)) {\n                ASSERT(!(attributes & ReadOnly));\n                setStructure(vm, Structure::attributeChangeTransition(vm, structure, propertyName, attributes));\n            }\n            return true;\n        }\n\n        if ((mode == PutModePut) && !isStructureExtensible())\n            return false;\n\n        offset = prepareToPutDirectWithoutTransition(vm, propertyName, attributes, structureID, structure);\n        validateOffset(offset);\n        putDirect(vm, offset, value);\n        slot.setNewProperty(this, offset);\n        if (attributes & ReadOnly)\n            this->structure()->setContainsReadOnlyProperties();\n        return true;\n    }\n\n    PropertyOffset offset;\n    size_t currentCapacity = this->structure()->outOfLineCapacity();\n    Structure* newStructure = Structure::addPropertyTransitionToExistingStructure(\n        structure, propertyName, attributes, offset);\n    if (newStructure) {\n        newStructure->willStoreValueForExistingTransition(\n            vm, propertyName, value, slot.context() == PutPropertySlot::PutById);\n        \n        Butterfly* newButterfly = butterfly();\n        if (currentCapacity != newStructure->outOfLineCapacity()) {\n            ASSERT(newStructure != this->structure());\n            newButterfly = allocateMoreOutOfLineStorage(vm, currentCapacity, newStructure->outOfLineCapacity());\n            nukeStructureAndSetButterfly(vm, structureID, newButterfly);\n        }\n\n        validateOffset(offset);\n        ASSERT(newStructure->isValidOffset(offset));\n        putDirect(vm, offset, value);\n        setStructure(vm, newStructure);\n        slot.setNewProperty(this, offset);\n        return true;\n    }\n\n    unsigned currentAttributes;\n    bool hasInferredType;\n    offset = structure->get(vm, propertyName, currentAttributes, hasInferredType);\n    if (offset != invalidOffset) {\n        if ((mode == PutModePut) && currentAttributes & ReadOnly)\n            return false;\n\n        structure->didReplaceProperty(offset);\n        if (UNLIKELY(hasInferredType)) {\n            structure->willStoreValueForReplace(\n                vm, propertyName, value, slot.context() == PutPropertySlot::PutById);\n        }\n\n        slot.setExistingProperty(this, offset);\n        putDirect(vm, offset, value);\n\n        if ((attributes & Accessor) != (currentAttributes & Accessor) || (attributes & CustomAccessor) != (currentAttributes & CustomAccessor)) {\n            ASSERT(!(attributes & ReadOnly));\n            setStructure(vm, Structure::attributeChangeTransition(vm, structure, propertyName, attributes));\n        }\n        return true;\n    }\n\n    if ((mode == PutModePut) && !isStructureExtensible())\n        return false;\n\n    // We want the structure transition watchpoint to fire after this object has switched\n    // structure. This allows adaptive watchpoints to observe if the new structure is the one\n    // we want.\n    DeferredStructureTransitionWatchpointFire deferredWatchpointFire;\n    \n    newStructure = Structure::addNewPropertyTransition(\n        vm, structure, propertyName, attributes, offset, slot.context(), &deferredWatchpointFire);\n    newStructure->willStoreValueForNewTransition(\n        vm, propertyName, value, slot.context() == PutPropertySlot::PutById);\n    \n    validateOffset(offset);\n    ASSERT(newStructure->isValidOffset(offset));\n    size_t oldCapacity = structure->outOfLineCapacity();\n    size_t newCapacity = newStructure->outOfLineCapacity();\n    ASSERT(oldCapacity <= newCapacity);\n    if (oldCapacity != newCapacity) {\n        Butterfly* newButterfly = allocateMoreOutOfLineStorage(vm, oldCapacity, newCapacity);\n        nukeStructureAndSetButterfly(vm, structureID, newButterfly);\n    }\n    putDirect(vm, offset, value);\n    setStructure(vm, newStructure);\n    slot.setNewProperty(this, offset);\n    if (attributes & ReadOnly)\n        newStructure->setContainsReadOnlyProperties();\n    return true;\n}\n\n} // namespace JSC",
    "repo": "alibaba/weex",
    "path": "./datasets/diagrams-repos/alibaba/weex/weex_core/Source/include/JavaScriptCore/runtime/JSObjectInlines.h",
    "query": "What is the relationship between JSObject, Structure, and Butterfly in terms of memory layout?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'JSObject', 'node_id': 'JSObject', 'description': 'Base class for JavaScript objects', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'Structure', 'node_id': 'Structure', 'description': \"Holds object's shape information and property metadata\", 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'Butterfly', 'node_id': 'Butterfly', 'description': 'Flexible storage for object properties and array elements', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'structureID', 'node_id': 'structureID', 'description': \"Returns unique ID of object's Structure\", 'visibility': 'public', 'return_type': 'StructureID', 'params': '()', 'source_class_id': 'JSObject'}], 'edges': [{'node_id_from': 'JSObject', 'node_id_to': 'Structure', 'description': 'has-a via structureID'}, {'node_id_from': 'JSObject', 'node_id_to': 'Butterfly', 'description': 'has-a for property storage'}, {'node_id_from': 'JSObject', 'node_id_to': 'structureID', 'description': ''}], 'packages': [{'package_id': 'memoryLayout', 'children': ['JSObject', 'Structure', 'Butterfly', 'structureID'], 'description': 'Core components of JSC object memory layout'}]}",
    "version": "minimal",
    "text_answer": "JSObject maintains its shape information in Structure (referenced by structureID) and stores properties using a combination of inline storage (within JSObject itself) and out-of-line storage managed by Butterfly. Structure defines the layout of properties while Butterfly provides flexible storage that can grow as needed.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C++",
    "code": "\n#pragma once\n\n#include \"AuxiliaryBarrierInlines.h\"\n#include \"Error.h\"\n#include \"JSObject.h\"\n#include \"Lookup.h\"\n\nnamespace JSC {\n\n// Section 7.3.17 of the spec.\ntemplate <typename AddFunction> // Add function should have a type like: (JSValue, RuntimeType) -> bool\nvoid createListFromArrayLike(ExecState* exec, JSValue arrayLikeValue, RuntimeTypeMask legalTypesFilter, const String& errorMessage, AddFunction addFunction)\n{\n    VM& vm = exec->vm();\n    auto scope = DECLARE_THROW_SCOPE(vm);\n    \n    Vector<JSValue> result;\n    JSValue lengthProperty = arrayLikeValue.get(exec, vm.propertyNames->length);\n    RETURN_IF_EXCEPTION(scope, void());\n    double lengthAsDouble = lengthProperty.toLength(exec);\n    RETURN_IF_EXCEPTION(scope, void());\n    RELEASE_ASSERT(lengthAsDouble >= 0.0 && lengthAsDouble == std::trunc(lengthAsDouble));\n    uint64_t length = static_cast<uint64_t>(lengthAsDouble);\n    for (uint64_t index = 0; index < length; index++) {\n        JSValue next = arrayLikeValue.get(exec, index);\n        RETURN_IF_EXCEPTION(scope, void());\n        \n        RuntimeType type = runtimeTypeForValue(next);\n        if (!(type & legalTypesFilter)) {\n            throwTypeError(exec, scope, errorMessage);\n            return;\n        }\n        \n        bool exitEarly = addFunction(next, type);\n        if (exitEarly)\n            return;\n    }\n}\n\nALWAYS_INLINE bool JSObject::canPerformFastPutInline(ExecState* exec, VM& vm, PropertyName propertyName)\n{\n    if (UNLIKELY(propertyName == exec->propertyNames().underscoreProto))\n        return false;\n\n    // Check if there are any setters or getters in the prototype chain\n    JSValue prototype;\n    JSObject* obj = this;\n    while (true) {\n        if (obj->structure(vm)->hasReadOnlyOrGetterSetterPropertiesExcludingProto() || obj->type() == ProxyObjectType)\n            return false;\n\n        prototype = obj->getPrototypeDirect();\n        if (prototype.isNull())\n            return true;\n\n        obj = asObject(prototype);\n    }\n\n    ASSERT_NOT_REACHED();\n}\n\ntemplate<typename CallbackWhenNoException>\nALWAYS_INLINE typename std::result_of<CallbackWhenNoException(bool, PropertySlot&)>::type JSObject::getPropertySlot(ExecState* exec, PropertyName propertyName, CallbackWhenNoException callback) const\n{\n    PropertySlot slot(this, PropertySlot::InternalMethodType::Get);\n    return getPropertySlot(exec, propertyName, slot, callback);\n}\n\ntemplate<typename CallbackWhenNoException>\nALWAYS_INLINE typename std::result_of<CallbackWhenNoException(bool, PropertySlot&)>::type JSObject::getPropertySlot(ExecState* exec, PropertyName propertyName, PropertySlot& slot, CallbackWhenNoException callback) const\n{\n    VM& vm = exec->vm();\n    auto scope = DECLARE_THROW_SCOPE(vm);\n    bool found = const_cast<JSObject*>(this)->getPropertySlot(exec, propertyName, slot);\n    RETURN_IF_EXCEPTION(scope, { });\n    return callback(found, slot);\n}\n\nALWAYS_INLINE bool JSObject::getPropertySlot(ExecState* exec, unsigned propertyName, PropertySlot& slot)\n{\n    VM& vm = exec->vm();\n    auto scope = DECLARE_THROW_SCOPE(vm);\n    auto& structureIDTable = vm.heap.structureIDTable();\n    JSObject* object = this;\n    MethodTable::GetPrototypeFunctionPtr defaultGetPrototype = JSObject::getPrototype;\n    while (true) {\n        Structure* structure = structureIDTable.get(object->structureID());\n        if (structure->classInfo()->methodTable.getOwnPropertySlotByIndex(object, exec, propertyName, slot))\n            return true;\n        RETURN_IF_EXCEPTION(scope, false);\n        JSValue prototype;\n        if (LIKELY(structure->classInfo()->methodTable.getPrototype == defaultGetPrototype || slot.internalMethodType() == PropertySlot::InternalMethodType::VMInquiry))\n            prototype = structure->storedPrototype();\n        else {\n            prototype = object->getPrototype(vm, exec);\n            RETURN_IF_EXCEPTION(scope, false);\n        }\n        if (!prototype.isObject())\n            return false;\n        object = asObject(prototype);\n    }\n}\n\nALWAYS_INLINE bool JSObject::getNonIndexPropertySlot(ExecState* exec, PropertyName propertyName, PropertySlot& slot)\n{\n    // This method only supports non-index PropertyNames.\n    ASSERT(!parseIndex(propertyName));\n\n    VM& vm = exec->vm();\n    auto scope = DECLARE_THROW_SCOPE(vm);\n    auto& structureIDTable = vm.heap.structureIDTable();\n    JSObject* object = this;\n    MethodTable::GetPrototypeFunctionPtr defaultGetPrototype = JSObject::getPrototype;\n    while (true) {\n        Structure* structure = structureIDTable.get(object->structureID());\n        if (LIKELY(!TypeInfo::overridesGetOwnPropertySlot(object->inlineTypeFlags()))) {\n            if (object->getOwnNonIndexPropertySlot(vm, structure, propertyName, slot))\n                return true;\n        } else {\n            if (structure->classInfo()->methodTable.getOwnPropertySlot(object, exec, propertyName, slot))\n                return true;\n            RETURN_IF_EXCEPTION(scope, false);\n        }\n        JSValue prototype;\n        if (LIKELY(structure->classInfo()->methodTable.getPrototype == defaultGetPrototype || slot.internalMethodType() == PropertySlot::InternalMethodType::VMInquiry))\n            prototype = structure->storedPrototype();\n        else {\n            prototype = object->getPrototype(vm, exec);\n            RETURN_IF_EXCEPTION(scope, false);\n        }\n        if (!prototype.isObject())\n            return false;\n        object = asObject(prototype);\n    }\n}\n\ninline void JSObject::putDirectWithoutTransition(VM& vm, PropertyName propertyName, JSValue value, unsigned attributes)\n{\n    ASSERT(!value.isGetterSetter() && !(attributes & Accessor));\n    ASSERT(!value.isCustomGetterSetter());\n    StructureID structureID = this->structureID();\n    Structure* structure = vm.heap.structureIDTable().get(structureID);\n    PropertyOffset offset = prepareToPutDirectWithoutTransition(vm, propertyName, attributes, structureID, structure);\n    bool shouldOptimize = false;\n    structure->willStoreValueForNewTransition(vm, propertyName, value, shouldOptimize);\n    putDirect(vm, offset, value);\n    if (attributes & ReadOnly)\n        structure->setContainsReadOnlyProperties();\n}\n\nALWAYS_INLINE PropertyOffset JSObject::prepareToPutDirectWithoutTransition(VM& vm, PropertyName propertyName, unsigned attributes, StructureID structureID, Structure* structure)\n{\n    unsigned oldOutOfLineCapacity = structure->outOfLineCapacity();\n    PropertyOffset result;\n    structure->addPropertyWithoutTransition(\n        vm, propertyName, attributes,\n        [&] (const GCSafeConcurrentJSLocker&, PropertyOffset offset, PropertyOffset newLastOffset) {\n            unsigned newOutOfLineCapacity = Structure::outOfLineCapacity(newLastOffset);\n            if (newOutOfLineCapacity != oldOutOfLineCapacity) {\n                Butterfly* butterfly = allocateMoreOutOfLineStorage(vm, oldOutOfLineCapacity, newOutOfLineCapacity);\n                nukeStructureAndSetButterfly(vm, structureID, butterfly);\n                structure->setLastOffset(newLastOffset);\n                WTF::storeStoreFence();\n                setStructureIDDirectly(structureID);\n            } else\n                structure->setLastOffset(newLastOffset);\n            result = offset;\n        });\n    return result;\n}\n\n// ECMA 8.6.2.2\nALWAYS_INLINE bool JSObject::putInline(JSCell* cell, ExecState* exec, PropertyName propertyName, JSValue value, PutPropertySlot& slot)\n{\n    VM& vm = exec->vm();\n    auto scope = DECLARE_THROW_SCOPE(vm);\n\n    JSObject* thisObject = jsCast<JSObject*>(cell);\n    ASSERT(value);\n    ASSERT(!Heap::heap(value) || Heap::heap(value) == Heap::heap(thisObject));\n\n    if (UNLIKELY(isThisValueAltered(slot, thisObject)))\n        return ordinarySetSlow(exec, thisObject, propertyName, value, slot.thisValue(), slot.isStrictMode());\n\n    // Try indexed put first. This is required for correctness, since loads on property names that appear like\n    // valid indices will never look in the named property storage.\n    if (std::optional<uint32_t> index = parseIndex(propertyName))\n        return putByIndex(thisObject, exec, index.value(), value, slot.isStrictMode());\n\n    if (thisObject->canPerformFastPutInline(exec, vm, propertyName)) {\n        ASSERT(!thisObject->structure(vm)->prototypeChainMayInterceptStoreTo(vm, propertyName));\n        if (!thisObject->putDirectInternal<PutModePut>(vm, propertyName, value, 0, slot))\n            return typeError(exec, scope, slot.isStrictMode(), ASCIILiteral(ReadonlyPropertyWriteError));\n        return true;\n    }\n\n    return thisObject->putInlineSlow(exec, propertyName, value, slot);\n}\n\n// HasOwnProperty(O, P) from section 7.3.11 in the spec.\n// http://www.ecma-international.org/ecma-262/6.0/index.html#sec-hasownproperty\nALWAYS_INLINE bool JSObject::hasOwnProperty(ExecState* exec, PropertyName propertyName, PropertySlot& slot) const\n{\n    ASSERT(slot.internalMethodType() == PropertySlot::InternalMethodType::GetOwnProperty);\n    if (LIKELY(const_cast<JSObject*>(this)->methodTable(exec->vm())->getOwnPropertySlot == JSObject::getOwnPropertySlot))\n        return JSObject::getOwnPropertySlot(const_cast<JSObject*>(this), exec, propertyName, slot);\n    return const_cast<JSObject*>(this)->methodTable(exec->vm())->getOwnPropertySlot(const_cast<JSObject*>(this), exec, propertyName, slot);\n}\n\nALWAYS_INLINE bool JSObject::hasOwnProperty(ExecState* exec, PropertyName propertyName) const\n{\n    PropertySlot slot(this, PropertySlot::InternalMethodType::GetOwnProperty);\n    return hasOwnProperty(exec, propertyName, slot);\n}\n\nALWAYS_INLINE bool JSObject::hasOwnProperty(ExecState* exec, unsigned propertyName) const\n{\n    PropertySlot slot(this, PropertySlot::InternalMethodType::GetOwnProperty);\n    return const_cast<JSObject*>(this)->methodTable(exec->vm())->getOwnPropertySlotByIndex(const_cast<JSObject*>(this), exec, propertyName, slot);\n}\n\ntemplate<JSObject::PutMode mode>\nALWAYS_INLINE bool JSObject::putDirectInternal(VM& vm, PropertyName propertyName, JSValue value, unsigned attributes, PutPropertySlot& slot)\n{\n    ASSERT(value);\n    ASSERT(value.isGetterSetter() == !!(attributes & Accessor));\n    ASSERT(!Heap::heap(value) || Heap::heap(value) == Heap::heap(this));\n    ASSERT(!parseIndex(propertyName));\n\n    StructureID structureID = this->structureID();\n    Structure* structure = vm.heap.structureIDTable().get(structureID);\n    if (structure->isDictionary()) {\n        ASSERT(!structure->hasInferredTypes());\n        \n        unsigned currentAttributes;\n        PropertyOffset offset = structure->get(vm, propertyName, currentAttributes);\n        if (offset != invalidOffset) {\n            if ((mode == PutModePut) && currentAttributes & ReadOnly)\n                return false;\n\n            putDirect(vm, offset, value);\n            structure->didReplaceProperty(offset);\n            slot.setExistingProperty(this, offset);\n\n            if ((attributes & Accessor) != (currentAttributes & Accessor) || (attributes & CustomAccessor) != (currentAttributes & CustomAccessor)) {\n                ASSERT(!(attributes & ReadOnly));\n                setStructure(vm, Structure::attributeChangeTransition(vm, structure, propertyName, attributes));\n            }\n            return true;\n        }\n\n        if ((mode == PutModePut) && !isStructureExtensible())\n            return false;\n\n        offset = prepareToPutDirectWithoutTransition(vm, propertyName, attributes, structureID, structure);\n        validateOffset(offset);\n        putDirect(vm, offset, value);\n        slot.setNewProperty(this, offset);\n        if (attributes & ReadOnly)\n            this->structure()->setContainsReadOnlyProperties();\n        return true;\n    }\n\n    PropertyOffset offset;\n    size_t currentCapacity = this->structure()->outOfLineCapacity();\n    Structure* newStructure = Structure::addPropertyTransitionToExistingStructure(\n        structure, propertyName, attributes, offset);\n    if (newStructure) {\n        newStructure->willStoreValueForExistingTransition(\n            vm, propertyName, value, slot.context() == PutPropertySlot::PutById);\n        \n        Butterfly* newButterfly = butterfly();\n        if (currentCapacity != newStructure->outOfLineCapacity()) {\n            ASSERT(newStructure != this->structure());\n            newButterfly = allocateMoreOutOfLineStorage(vm, currentCapacity, newStructure->outOfLineCapacity());\n            nukeStructureAndSetButterfly(vm, structureID, newButterfly);\n        }\n\n        validateOffset(offset);\n        ASSERT(newStructure->isValidOffset(offset));\n        putDirect(vm, offset, value);\n        setStructure(vm, newStructure);\n        slot.setNewProperty(this, offset);\n        return true;\n    }\n\n    unsigned currentAttributes;\n    bool hasInferredType;\n    offset = structure->get(vm, propertyName, currentAttributes, hasInferredType);\n    if (offset != invalidOffset) {\n        if ((mode == PutModePut) && currentAttributes & ReadOnly)\n            return false;\n\n        structure->didReplaceProperty(offset);\n        if (UNLIKELY(hasInferredType)) {\n            structure->willStoreValueForReplace(\n                vm, propertyName, value, slot.context() == PutPropertySlot::PutById);\n        }\n\n        slot.setExistingProperty(this, offset);\n        putDirect(vm, offset, value);\n\n        if ((attributes & Accessor) != (currentAttributes & Accessor) || (attributes & CustomAccessor) != (currentAttributes & CustomAccessor)) {\n            ASSERT(!(attributes & ReadOnly));\n            setStructure(vm, Structure::attributeChangeTransition(vm, structure, propertyName, attributes));\n        }\n        return true;\n    }\n\n    if ((mode == PutModePut) && !isStructureExtensible())\n        return false;\n\n    // We want the structure transition watchpoint to fire after this object has switched\n    // structure. This allows adaptive watchpoints to observe if the new structure is the one\n    // we want.\n    DeferredStructureTransitionWatchpointFire deferredWatchpointFire;\n    \n    newStructure = Structure::addNewPropertyTransition(\n        vm, structure, propertyName, attributes, offset, slot.context(), &deferredWatchpointFire);\n    newStructure->willStoreValueForNewTransition(\n        vm, propertyName, value, slot.context() == PutPropertySlot::PutById);\n    \n    validateOffset(offset);\n    ASSERT(newStructure->isValidOffset(offset));\n    size_t oldCapacity = structure->outOfLineCapacity();\n    size_t newCapacity = newStructure->outOfLineCapacity();\n    ASSERT(oldCapacity <= newCapacity);\n    if (oldCapacity != newCapacity) {\n        Butterfly* newButterfly = allocateMoreOutOfLineStorage(vm, oldCapacity, newCapacity);\n        nukeStructureAndSetButterfly(vm, structureID, newButterfly);\n    }\n    putDirect(vm, offset, value);\n    setStructure(vm, newStructure);\n    slot.setNewProperty(this, offset);\n    if (attributes & ReadOnly)\n        newStructure->setContainsReadOnlyProperties();\n    return true;\n}\n\n} // namespace JSC",
    "repo": "alibaba/weex",
    "path": "./datasets/diagrams-repos/alibaba/weex/weex_core/Source/include/JavaScriptCore/runtime/JSObjectInlines.h",
    "query": "What is the relationship between JSObject, Structure, and Butterfly in terms of memory layout?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'JSObject', 'node_id': 'JSObject', 'description': 'Base class for JavaScript objects', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'Structure', 'node_id': 'Structure', 'description': \"Holds object's shape information and property metadata\", 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'Butterfly', 'node_id': 'Butterfly', 'description': 'Flexible storage for object properties and array elements', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'structureID', 'node_id': 'structureID', 'description': \"Returns unique ID of object's Structure\", 'visibility': 'public', 'return_type': 'StructureID', 'params': '()', 'source_class_id': 'JSObject'}, {'type': 'method', 'name': 'putDirectWithoutTransition', 'node_id': 'putDirectWithoutTransition', 'description': 'Stores property without creating new Structure', 'visibility': 'public', 'return_type': 'void', 'params': '(VM&, PropertyName, JSValue, unsigned)', 'source_class_id': 'JSObject'}, {'type': 'method', 'name': 'allocateMoreOutOfLineStorage', 'node_id': 'allocateMoreOutOfLineStorage', 'description': 'Allocates additional Butterfly storage', 'visibility': 'private', 'return_type': 'Butterfly*', 'params': '(VM&, unsigned, unsigned)', 'source_class_id': 'JSObject'}], 'edges': [{'node_id_from': 'JSObject', 'node_id_to': 'Structure', 'description': 'has-a via structureID'}, {'node_id_from': 'JSObject', 'node_id_to': 'Butterfly', 'description': 'has-a for property storage'}, {'node_id_from': 'putDirectWithoutTransition', 'node_id_to': 'Butterfly', 'description': 'may allocate new'}, {'node_id_from': 'Structure', 'node_id_to': 'Butterfly', 'description': 'defines layout'}, {'node_id_from': 'JSObject', 'node_id_to': 'structureID', 'description': ''}, {'node_id_from': 'JSObject', 'node_id_to': 'putDirectWithoutTransition', 'description': ''}, {'node_id_from': 'JSObject', 'node_id_to': 'allocateMoreOutOfLineStorage', 'description': ''}], 'packages': [{'package_id': 'memoryLayout', 'children': ['JSObject', 'Structure', 'Butterfly', 'structureID', 'propertyOperations'], 'description': 'Core components of JSC object memory layout'}, {'package_id': 'propertyOperations', 'children': ['putDirectWithoutTransition', 'allocateMoreOutOfLineStorage'], 'description': 'Operations for managing properties and storage'}]}",
    "version": "medium",
    "text_answer": "JSObject maintains its shape information in Structure (referenced by structureID) and stores properties using a combination of inline storage (within JSObject itself) and out-of-line storage managed by Butterfly. Structure defines the layout of properties while Butterfly provides flexible storage that can grow as needed.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C++",
    "code": "\n#pragma once\n\n#include \"AuxiliaryBarrierInlines.h\"\n#include \"Error.h\"\n#include \"JSObject.h\"\n#include \"Lookup.h\"\n\nnamespace JSC {\n\n// Section 7.3.17 of the spec.\ntemplate <typename AddFunction> // Add function should have a type like: (JSValue, RuntimeType) -> bool\nvoid createListFromArrayLike(ExecState* exec, JSValue arrayLikeValue, RuntimeTypeMask legalTypesFilter, const String& errorMessage, AddFunction addFunction)\n{\n    VM& vm = exec->vm();\n    auto scope = DECLARE_THROW_SCOPE(vm);\n    \n    Vector<JSValue> result;\n    JSValue lengthProperty = arrayLikeValue.get(exec, vm.propertyNames->length);\n    RETURN_IF_EXCEPTION(scope, void());\n    double lengthAsDouble = lengthProperty.toLength(exec);\n    RETURN_IF_EXCEPTION(scope, void());\n    RELEASE_ASSERT(lengthAsDouble >= 0.0 && lengthAsDouble == std::trunc(lengthAsDouble));\n    uint64_t length = static_cast<uint64_t>(lengthAsDouble);\n    for (uint64_t index = 0; index < length; index++) {\n        JSValue next = arrayLikeValue.get(exec, index);\n        RETURN_IF_EXCEPTION(scope, void());\n        \n        RuntimeType type = runtimeTypeForValue(next);\n        if (!(type & legalTypesFilter)) {\n            throwTypeError(exec, scope, errorMessage);\n            return;\n        }\n        \n        bool exitEarly = addFunction(next, type);\n        if (exitEarly)\n            return;\n    }\n}\n\nALWAYS_INLINE bool JSObject::canPerformFastPutInline(ExecState* exec, VM& vm, PropertyName propertyName)\n{\n    if (UNLIKELY(propertyName == exec->propertyNames().underscoreProto))\n        return false;\n\n    // Check if there are any setters or getters in the prototype chain\n    JSValue prototype;\n    JSObject* obj = this;\n    while (true) {\n        if (obj->structure(vm)->hasReadOnlyOrGetterSetterPropertiesExcludingProto() || obj->type() == ProxyObjectType)\n            return false;\n\n        prototype = obj->getPrototypeDirect();\n        if (prototype.isNull())\n            return true;\n\n        obj = asObject(prototype);\n    }\n\n    ASSERT_NOT_REACHED();\n}\n\ntemplate<typename CallbackWhenNoException>\nALWAYS_INLINE typename std::result_of<CallbackWhenNoException(bool, PropertySlot&)>::type JSObject::getPropertySlot(ExecState* exec, PropertyName propertyName, CallbackWhenNoException callback) const\n{\n    PropertySlot slot(this, PropertySlot::InternalMethodType::Get);\n    return getPropertySlot(exec, propertyName, slot, callback);\n}\n\ntemplate<typename CallbackWhenNoException>\nALWAYS_INLINE typename std::result_of<CallbackWhenNoException(bool, PropertySlot&)>::type JSObject::getPropertySlot(ExecState* exec, PropertyName propertyName, PropertySlot& slot, CallbackWhenNoException callback) const\n{\n    VM& vm = exec->vm();\n    auto scope = DECLARE_THROW_SCOPE(vm);\n    bool found = const_cast<JSObject*>(this)->getPropertySlot(exec, propertyName, slot);\n    RETURN_IF_EXCEPTION(scope, { });\n    return callback(found, slot);\n}\n\nALWAYS_INLINE bool JSObject::getPropertySlot(ExecState* exec, unsigned propertyName, PropertySlot& slot)\n{\n    VM& vm = exec->vm();\n    auto scope = DECLARE_THROW_SCOPE(vm);\n    auto& structureIDTable = vm.heap.structureIDTable();\n    JSObject* object = this;\n    MethodTable::GetPrototypeFunctionPtr defaultGetPrototype = JSObject::getPrototype;\n    while (true) {\n        Structure* structure = structureIDTable.get(object->structureID());\n        if (structure->classInfo()->methodTable.getOwnPropertySlotByIndex(object, exec, propertyName, slot))\n            return true;\n        RETURN_IF_EXCEPTION(scope, false);\n        JSValue prototype;\n        if (LIKELY(structure->classInfo()->methodTable.getPrototype == defaultGetPrototype || slot.internalMethodType() == PropertySlot::InternalMethodType::VMInquiry))\n            prototype = structure->storedPrototype();\n        else {\n            prototype = object->getPrototype(vm, exec);\n            RETURN_IF_EXCEPTION(scope, false);\n        }\n        if (!prototype.isObject())\n            return false;\n        object = asObject(prototype);\n    }\n}\n\nALWAYS_INLINE bool JSObject::getNonIndexPropertySlot(ExecState* exec, PropertyName propertyName, PropertySlot& slot)\n{\n    // This method only supports non-index PropertyNames.\n    ASSERT(!parseIndex(propertyName));\n\n    VM& vm = exec->vm();\n    auto scope = DECLARE_THROW_SCOPE(vm);\n    auto& structureIDTable = vm.heap.structureIDTable();\n    JSObject* object = this;\n    MethodTable::GetPrototypeFunctionPtr defaultGetPrototype = JSObject::getPrototype;\n    while (true) {\n        Structure* structure = structureIDTable.get(object->structureID());\n        if (LIKELY(!TypeInfo::overridesGetOwnPropertySlot(object->inlineTypeFlags()))) {\n            if (object->getOwnNonIndexPropertySlot(vm, structure, propertyName, slot))\n                return true;\n        } else {\n            if (structure->classInfo()->methodTable.getOwnPropertySlot(object, exec, propertyName, slot))\n                return true;\n            RETURN_IF_EXCEPTION(scope, false);\n        }\n        JSValue prototype;\n        if (LIKELY(structure->classInfo()->methodTable.getPrototype == defaultGetPrototype || slot.internalMethodType() == PropertySlot::InternalMethodType::VMInquiry))\n            prototype = structure->storedPrototype();\n        else {\n            prototype = object->getPrototype(vm, exec);\n            RETURN_IF_EXCEPTION(scope, false);\n        }\n        if (!prototype.isObject())\n            return false;\n        object = asObject(prototype);\n    }\n}\n\ninline void JSObject::putDirectWithoutTransition(VM& vm, PropertyName propertyName, JSValue value, unsigned attributes)\n{\n    ASSERT(!value.isGetterSetter() && !(attributes & Accessor));\n    ASSERT(!value.isCustomGetterSetter());\n    StructureID structureID = this->structureID();\n    Structure* structure = vm.heap.structureIDTable().get(structureID);\n    PropertyOffset offset = prepareToPutDirectWithoutTransition(vm, propertyName, attributes, structureID, structure);\n    bool shouldOptimize = false;\n    structure->willStoreValueForNewTransition(vm, propertyName, value, shouldOptimize);\n    putDirect(vm, offset, value);\n    if (attributes & ReadOnly)\n        structure->setContainsReadOnlyProperties();\n}\n\nALWAYS_INLINE PropertyOffset JSObject::prepareToPutDirectWithoutTransition(VM& vm, PropertyName propertyName, unsigned attributes, StructureID structureID, Structure* structure)\n{\n    unsigned oldOutOfLineCapacity = structure->outOfLineCapacity();\n    PropertyOffset result;\n    structure->addPropertyWithoutTransition(\n        vm, propertyName, attributes,\n        [&] (const GCSafeConcurrentJSLocker&, PropertyOffset offset, PropertyOffset newLastOffset) {\n            unsigned newOutOfLineCapacity = Structure::outOfLineCapacity(newLastOffset);\n            if (newOutOfLineCapacity != oldOutOfLineCapacity) {\n                Butterfly* butterfly = allocateMoreOutOfLineStorage(vm, oldOutOfLineCapacity, newOutOfLineCapacity);\n                nukeStructureAndSetButterfly(vm, structureID, butterfly);\n                structure->setLastOffset(newLastOffset);\n                WTF::storeStoreFence();\n                setStructureIDDirectly(structureID);\n            } else\n                structure->setLastOffset(newLastOffset);\n            result = offset;\n        });\n    return result;\n}\n\n// ECMA 8.6.2.2\nALWAYS_INLINE bool JSObject::putInline(JSCell* cell, ExecState* exec, PropertyName propertyName, JSValue value, PutPropertySlot& slot)\n{\n    VM& vm = exec->vm();\n    auto scope = DECLARE_THROW_SCOPE(vm);\n\n    JSObject* thisObject = jsCast<JSObject*>(cell);\n    ASSERT(value);\n    ASSERT(!Heap::heap(value) || Heap::heap(value) == Heap::heap(thisObject));\n\n    if (UNLIKELY(isThisValueAltered(slot, thisObject)))\n        return ordinarySetSlow(exec, thisObject, propertyName, value, slot.thisValue(), slot.isStrictMode());\n\n    // Try indexed put first. This is required for correctness, since loads on property names that appear like\n    // valid indices will never look in the named property storage.\n    if (std::optional<uint32_t> index = parseIndex(propertyName))\n        return putByIndex(thisObject, exec, index.value(), value, slot.isStrictMode());\n\n    if (thisObject->canPerformFastPutInline(exec, vm, propertyName)) {\n        ASSERT(!thisObject->structure(vm)->prototypeChainMayInterceptStoreTo(vm, propertyName));\n        if (!thisObject->putDirectInternal<PutModePut>(vm, propertyName, value, 0, slot))\n            return typeError(exec, scope, slot.isStrictMode(), ASCIILiteral(ReadonlyPropertyWriteError));\n        return true;\n    }\n\n    return thisObject->putInlineSlow(exec, propertyName, value, slot);\n}\n\n// HasOwnProperty(O, P) from section 7.3.11 in the spec.\n// http://www.ecma-international.org/ecma-262/6.0/index.html#sec-hasownproperty\nALWAYS_INLINE bool JSObject::hasOwnProperty(ExecState* exec, PropertyName propertyName, PropertySlot& slot) const\n{\n    ASSERT(slot.internalMethodType() == PropertySlot::InternalMethodType::GetOwnProperty);\n    if (LIKELY(const_cast<JSObject*>(this)->methodTable(exec->vm())->getOwnPropertySlot == JSObject::getOwnPropertySlot))\n        return JSObject::getOwnPropertySlot(const_cast<JSObject*>(this), exec, propertyName, slot);\n    return const_cast<JSObject*>(this)->methodTable(exec->vm())->getOwnPropertySlot(const_cast<JSObject*>(this), exec, propertyName, slot);\n}\n\nALWAYS_INLINE bool JSObject::hasOwnProperty(ExecState* exec, PropertyName propertyName) const\n{\n    PropertySlot slot(this, PropertySlot::InternalMethodType::GetOwnProperty);\n    return hasOwnProperty(exec, propertyName, slot);\n}\n\nALWAYS_INLINE bool JSObject::hasOwnProperty(ExecState* exec, unsigned propertyName) const\n{\n    PropertySlot slot(this, PropertySlot::InternalMethodType::GetOwnProperty);\n    return const_cast<JSObject*>(this)->methodTable(exec->vm())->getOwnPropertySlotByIndex(const_cast<JSObject*>(this), exec, propertyName, slot);\n}\n\ntemplate<JSObject::PutMode mode>\nALWAYS_INLINE bool JSObject::putDirectInternal(VM& vm, PropertyName propertyName, JSValue value, unsigned attributes, PutPropertySlot& slot)\n{\n    ASSERT(value);\n    ASSERT(value.isGetterSetter() == !!(attributes & Accessor));\n    ASSERT(!Heap::heap(value) || Heap::heap(value) == Heap::heap(this));\n    ASSERT(!parseIndex(propertyName));\n\n    StructureID structureID = this->structureID();\n    Structure* structure = vm.heap.structureIDTable().get(structureID);\n    if (structure->isDictionary()) {\n        ASSERT(!structure->hasInferredTypes());\n        \n        unsigned currentAttributes;\n        PropertyOffset offset = structure->get(vm, propertyName, currentAttributes);\n        if (offset != invalidOffset) {\n            if ((mode == PutModePut) && currentAttributes & ReadOnly)\n                return false;\n\n            putDirect(vm, offset, value);\n            structure->didReplaceProperty(offset);\n            slot.setExistingProperty(this, offset);\n\n            if ((attributes & Accessor) != (currentAttributes & Accessor) || (attributes & CustomAccessor) != (currentAttributes & CustomAccessor)) {\n                ASSERT(!(attributes & ReadOnly));\n                setStructure(vm, Structure::attributeChangeTransition(vm, structure, propertyName, attributes));\n            }\n            return true;\n        }\n\n        if ((mode == PutModePut) && !isStructureExtensible())\n            return false;\n\n        offset = prepareToPutDirectWithoutTransition(vm, propertyName, attributes, structureID, structure);\n        validateOffset(offset);\n        putDirect(vm, offset, value);\n        slot.setNewProperty(this, offset);\n        if (attributes & ReadOnly)\n            this->structure()->setContainsReadOnlyProperties();\n        return true;\n    }\n\n    PropertyOffset offset;\n    size_t currentCapacity = this->structure()->outOfLineCapacity();\n    Structure* newStructure = Structure::addPropertyTransitionToExistingStructure(\n        structure, propertyName, attributes, offset);\n    if (newStructure) {\n        newStructure->willStoreValueForExistingTransition(\n            vm, propertyName, value, slot.context() == PutPropertySlot::PutById);\n        \n        Butterfly* newButterfly = butterfly();\n        if (currentCapacity != newStructure->outOfLineCapacity()) {\n            ASSERT(newStructure != this->structure());\n            newButterfly = allocateMoreOutOfLineStorage(vm, currentCapacity, newStructure->outOfLineCapacity());\n            nukeStructureAndSetButterfly(vm, structureID, newButterfly);\n        }\n\n        validateOffset(offset);\n        ASSERT(newStructure->isValidOffset(offset));\n        putDirect(vm, offset, value);\n        setStructure(vm, newStructure);\n        slot.setNewProperty(this, offset);\n        return true;\n    }\n\n    unsigned currentAttributes;\n    bool hasInferredType;\n    offset = structure->get(vm, propertyName, currentAttributes, hasInferredType);\n    if (offset != invalidOffset) {\n        if ((mode == PutModePut) && currentAttributes & ReadOnly)\n            return false;\n\n        structure->didReplaceProperty(offset);\n        if (UNLIKELY(hasInferredType)) {\n            structure->willStoreValueForReplace(\n                vm, propertyName, value, slot.context() == PutPropertySlot::PutById);\n        }\n\n        slot.setExistingProperty(this, offset);\n        putDirect(vm, offset, value);\n\n        if ((attributes & Accessor) != (currentAttributes & Accessor) || (attributes & CustomAccessor) != (currentAttributes & CustomAccessor)) {\n            ASSERT(!(attributes & ReadOnly));\n            setStructure(vm, Structure::attributeChangeTransition(vm, structure, propertyName, attributes));\n        }\n        return true;\n    }\n\n    if ((mode == PutModePut) && !isStructureExtensible())\n        return false;\n\n    // We want the structure transition watchpoint to fire after this object has switched\n    // structure. This allows adaptive watchpoints to observe if the new structure is the one\n    // we want.\n    DeferredStructureTransitionWatchpointFire deferredWatchpointFire;\n    \n    newStructure = Structure::addNewPropertyTransition(\n        vm, structure, propertyName, attributes, offset, slot.context(), &deferredWatchpointFire);\n    newStructure->willStoreValueForNewTransition(\n        vm, propertyName, value, slot.context() == PutPropertySlot::PutById);\n    \n    validateOffset(offset);\n    ASSERT(newStructure->isValidOffset(offset));\n    size_t oldCapacity = structure->outOfLineCapacity();\n    size_t newCapacity = newStructure->outOfLineCapacity();\n    ASSERT(oldCapacity <= newCapacity);\n    if (oldCapacity != newCapacity) {\n        Butterfly* newButterfly = allocateMoreOutOfLineStorage(vm, oldCapacity, newCapacity);\n        nukeStructureAndSetButterfly(vm, structureID, newButterfly);\n    }\n    putDirect(vm, offset, value);\n    setStructure(vm, newStructure);\n    slot.setNewProperty(this, offset);\n    if (attributes & ReadOnly)\n        newStructure->setContainsReadOnlyProperties();\n    return true;\n}\n\n} // namespace JSC",
    "repo": "alibaba/weex",
    "path": "./datasets/diagrams-repos/alibaba/weex/weex_core/Source/include/JavaScriptCore/runtime/JSObjectInlines.h",
    "query": "What is the relationship between JSObject, Structure, and Butterfly in terms of memory layout?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'JSObject', 'node_id': 'JSObject', 'description': 'Base class for JavaScript objects', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'Structure', 'node_id': 'Structure', 'description': \"Holds object's shape information and property metadata\", 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'Butterfly', 'node_id': 'Butterfly', 'description': 'Flexible storage for object properties and array elements', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'structureID', 'node_id': 'structureID', 'description': \"Returns unique ID of object's Structure\", 'visibility': 'public', 'return_type': 'StructureID', 'params': '()', 'source_class_id': 'JSObject'}, {'type': 'method', 'name': 'putDirectWithoutTransition', 'node_id': 'putDirectWithoutTransition', 'description': 'Stores property without creating new Structure', 'visibility': 'public', 'return_type': 'void', 'params': '(VM&, PropertyName, JSValue, unsigned)', 'source_class_id': 'JSObject'}, {'type': 'method', 'name': 'allocateMoreOutOfLineStorage', 'node_id': 'allocateMoreOutOfLineStorage', 'description': 'Allocates additional Butterfly storage', 'visibility': 'private', 'return_type': 'Butterfly*', 'params': '(VM&, unsigned, unsigned)', 'source_class_id': 'JSObject'}, {'type': 'method', 'name': 'putDirectInternal', 'node_id': 'putDirectInternal', 'description': 'Internal method for storing properties', 'visibility': 'private', 'return_type': 'bool', 'params': '(VM&, PropertyName, JSValue, unsigned, PutPropertySlot&)', 'source_class_id': 'JSObject'}, {'type': 'method', 'name': 'prepareToPutDirectWithoutTransition', 'node_id': 'prepareToPutDirectWithoutTransition', 'description': 'Prepares object for property storage', 'visibility': 'private', 'return_type': 'PropertyOffset', 'params': '(VM&, PropertyName, unsigned, StructureID, Structure*)', 'source_class_id': 'JSObject'}, {'type': 'entity', 'name': 'outOfLineStorage', 'node_id': 'outOfLineStorage', 'description': 'Additional property storage space in Butterfly', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'inlineStorage', 'node_id': 'inlineStorage', 'description': 'Direct property storage in JSObject', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'JSObject', 'node_id_to': 'Structure', 'description': 'has-a via structureID'}, {'node_id_from': 'JSObject', 'node_id_to': 'Butterfly', 'description': 'has-a for property storage'}, {'node_id_from': 'putDirectWithoutTransition', 'node_id_to': 'Butterfly', 'description': 'may allocate new'}, {'node_id_from': 'Structure', 'node_id_to': 'Butterfly', 'description': 'defines layout'}, {'node_id_from': 'JSObject', 'node_id_to': 'inlineStorage', 'description': 'contains'}, {'node_id_from': 'Butterfly', 'node_id_to': 'outOfLineStorage', 'description': 'manages'}, {'node_id_from': 'putDirectInternal', 'node_id_to': 'Structure', 'description': 'may create new'}, {'node_id_from': 'prepareToPutDirectWithoutTransition', 'node_id_to': 'Butterfly', 'description': 'may resize'}, {'node_id_from': 'JSObject', 'node_id_to': 'structureID', 'description': ''}, {'node_id_from': 'JSObject', 'node_id_to': 'putDirectWithoutTransition', 'description': ''}, {'node_id_from': 'JSObject', 'node_id_to': 'allocateMoreOutOfLineStorage', 'description': ''}, {'node_id_from': 'JSObject', 'node_id_to': 'putDirectInternal', 'description': ''}, {'node_id_from': 'JSObject', 'node_id_to': 'prepareToPutDirectWithoutTransition', 'description': ''}], 'packages': [{'package_id': 'memoryLayout', 'children': ['JSObject', 'Structure', 'Butterfly', 'inlineStorage', 'outOfLineStorage', 'structureID', 'propertyOperations'], 'description': 'Core components of JSC object memory layout'}, {'package_id': 'propertyOperations', 'children': ['putDirectWithoutTransition', 'putDirectInternal', 'prepareToPutDirectWithoutTransition', 'allocateMoreOutOfLineStorage'], 'description': 'Operations for managing properties and storage'}]}",
    "version": "full",
    "text_answer": "JSObject maintains its shape information in Structure (referenced by structureID) and stores properties using a combination of inline storage (within JSObject itself) and out-of-line storage managed by Butterfly. Structure defines the layout of properties while Butterfly provides flexible storage that can grow as needed.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.deeplearning4j.nn.params;\n\nimport lombok.val;\nimport org.deeplearning4j.nn.api.ParamInitializer;\nimport org.deeplearning4j.nn.conf.NeuralNetConfiguration;\nimport org.deeplearning4j.nn.conf.layers.BatchNormalization;\nimport org.deeplearning4j.nn.conf.layers.Layer;\nimport org.nd4j.linalg.api.ndarray.INDArray;\nimport org.nd4j.linalg.indexing.NDArrayIndex;\n\nimport java.util.*;\n\npublic class BatchNormalizationParamInitializer implements ParamInitializer {\n\n    private static final BatchNormalizationParamInitializer INSTANCE = new BatchNormalizationParamInitializer();\n\n    public static BatchNormalizationParamInitializer getInstance() {\n        return INSTANCE;\n    }\n\n    public static final String GAMMA = \"gamma\";\n    public static final String BETA = \"beta\";\n    public static final String GLOBAL_MEAN = \"mean\";\n    public static final String GLOBAL_VAR = \"var\";\n    public static final String GLOBAL_LOG_STD = \"log10stdev\";\n\n    @Override\n    public long numParams(NeuralNetConfiguration conf) {\n        return numParams(conf.getLayer());\n    }\n\n    @Override\n    public long numParams(Layer l) {\n        BatchNormalization layer = (BatchNormalization) l;\n        //Parameters in batch norm:\n        //gamma, beta, global mean estimate, global variance estimate\n        // latter 2 are treated as parameters, which greatly simplifies spark training and model serialization\n\n        if (layer.isLockGammaBeta()) {\n            //Special case: gamma and beta are fixed values for all outputs -> no parameters for gamma and  beta in this case\n            return 2 * layer.getNOut();\n        } else {\n            //Standard case: gamma and beta are learned per output; additional 2*nOut for global mean/variance estimate\n            return 4 * layer.getNOut();\n        }\n    }\n\n    @Override\n    public List<String> paramKeys(Layer layer) {\n        if(((BatchNormalization)layer).isUseLogStd()){\n            return Arrays.asList(GAMMA, BETA, GLOBAL_MEAN, GLOBAL_LOG_STD);\n        } else {\n            return Arrays.asList(GAMMA, BETA, GLOBAL_MEAN, GLOBAL_VAR);\n        }\n    }\n\n    @Override\n    public List<String> weightKeys(Layer layer) {\n        return Collections.emptyList();\n    }\n\n    @Override\n    public List<String> biasKeys(Layer layer) {\n        return Collections.emptyList();\n    }\n\n    @Override\n    public boolean isWeightParam(Layer layer, String key) {\n        return false;\n    }\n\n    @Override\n    public boolean isBiasParam(Layer layer, String key) {\n        return false;\n    }\n\n    @Override\n    public Map<String, INDArray> init(NeuralNetConfiguration conf, INDArray paramView, boolean initializeParams) {\n        Map<String, INDArray> params = Collections.synchronizedMap(new LinkedHashMap<String, INDArray>());\n        // TODO setup for RNN\n        BatchNormalization layer = (BatchNormalization) conf.getLayer();\n        val nOut = layer.getNOut();\n\n        long meanOffset = 0;\n        INDArray paramViewReshape = paramView.reshape(paramView.length());\n        if (!layer.isLockGammaBeta()) { //No gamma/beta parameters when gamma/beta are locked\n            INDArray gammaView = paramViewReshape.get( NDArrayIndex.interval(0, nOut));\n            INDArray betaView = paramViewReshape.get(NDArrayIndex.interval(nOut, 2 * nOut));\n\n            params.put(GAMMA, createGamma(conf, gammaView, initializeParams));\n            conf.addVariable(GAMMA);\n            params.put(BETA, createBeta(conf, betaView, initializeParams));\n            conf.addVariable(BETA);\n\n            meanOffset = 2 * nOut;\n        }\n\n        INDArray globalMeanView =\n                paramViewReshape.get( NDArrayIndex.interval(meanOffset, meanOffset + nOut));\n        INDArray globalVarView = paramViewReshape.get(\n                        NDArrayIndex.interval(meanOffset + nOut, meanOffset + 2 * nOut));\n\n        if (initializeParams) {\n            globalMeanView.assign(0);\n            if(layer.isUseLogStd()){\n                //Global log stdev: assign 0.0 as initial value (s=sqrt(v), and log10(s) = log10(sqrt(v)) -> log10(1) = 0\n                globalVarView.assign(0);\n            } else {\n                //Global variance view: assign 1.0 as initial value\n                globalVarView.assign(1);\n            }\n        }\n\n        params.put(GLOBAL_MEAN, globalMeanView);\n        conf.addVariable(GLOBAL_MEAN);\n        if(layer.isUseLogStd()){\n            params.put(GLOBAL_LOG_STD, globalVarView);\n            conf.addVariable(GLOBAL_LOG_STD);\n        } else {\n            params.put(GLOBAL_VAR, globalVarView);\n            conf.addVariable(GLOBAL_VAR);\n        }\n\n        return params;\n    }\n\n    @Override\n    public Map<String, INDArray> getGradientsFromFlattened(NeuralNetConfiguration conf, INDArray gradientView) {\n        BatchNormalization layer = (BatchNormalization) conf.getLayer();\n        val nOut = layer.getNOut();\n\n        INDArray gradientViewReshape = gradientView.reshape(gradientView.length());\n        Map<String, INDArray> out = new LinkedHashMap<>();\n        long meanOffset = 0;\n        if (!layer.isLockGammaBeta()) {\n            INDArray gammaView = gradientViewReshape.get(NDArrayIndex.interval(0, nOut));\n            INDArray betaView = gradientViewReshape.get(NDArrayIndex.interval(nOut, 2 * nOut));\n            out.put(GAMMA, gammaView);\n            out.put(BETA, betaView);\n            meanOffset = 2 * nOut;\n        }\n\n        out.put(GLOBAL_MEAN,\n                gradientViewReshape.get( NDArrayIndex.interval(meanOffset, meanOffset + nOut)));\n        if(layer.isUseLogStd()){\n            out.put(GLOBAL_LOG_STD, gradientViewReshape.get(\n                    NDArrayIndex.interval(meanOffset + nOut, meanOffset + 2 * nOut)));\n        } else {\n            out.put(GLOBAL_VAR, gradientViewReshape.get(\n                    NDArrayIndex.interval(meanOffset + nOut, meanOffset + 2 * nOut)));\n        }\n\n        return out;\n    }\n\n    private INDArray createBeta(NeuralNetConfiguration conf, INDArray betaView, boolean initializeParams) {\n        BatchNormalization layer = (BatchNormalization) conf.getLayer();\n        if (initializeParams)\n            betaView.assign(layer.getBeta());\n        return betaView;\n    }\n\n    private INDArray createGamma(NeuralNetConfiguration conf, INDArray gammaView, boolean initializeParams) {\n        BatchNormalization layer = (BatchNormalization) conf.getLayer();\n        if (initializeParams)\n            gammaView.assign(layer.getGamma());\n        return gammaView;\n    }\n}",
    "repo": "deeplearning4j/deeplearning4j",
    "path": "./datasets/diagrams-repos/deeplearning4j/deeplearning4j/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/params/BatchNormalizationParamInitializer.java",
    "query": "Can you show how the parameters are stored and accessed in the parameter map?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'BatchNormalizationParamInitializer', 'node_id': 'BatchNormalizationParamInitializer', 'description': 'Initializes and manages parameters for batch normalization layers', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'GAMMA', 'node_id': 'GAMMA', 'description': 'Parameter key for gamma values', 'visibility': 'public', 'return_type': 'String', 'params': None, 'source_class_id': 'BatchNormalizationParamInitializer'}, {'type': 'field', 'name': 'BETA', 'node_id': 'BETA', 'description': 'Parameter key for beta values', 'visibility': 'public', 'return_type': 'String', 'params': None, 'source_class_id': 'BatchNormalizationParamInitializer'}, {'type': 'method', 'name': 'init', 'node_id': 'init', 'description': 'Initializes parameter map with gamma, beta, mean and variance values', 'visibility': 'public', 'return_type': 'Map<String, INDArray>', 'params': 'NeuralNetConfiguration conf, INDArray paramView, boolean initializeParams', 'source_class_id': 'BatchNormalizationParamInitializer'}], 'edges': [{'node_id_from': 'init', 'node_id_to': 'GAMMA', 'description': 'stores gamma parameters'}, {'node_id_from': 'init', 'node_id_to': 'BETA', 'description': 'stores beta parameters'}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'init', 'description': ''}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'GAMMA', 'description': ''}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'BETA', 'description': ''}], 'packages': [{'package_id': 'parameterStorage', 'children': ['BatchNormalizationParamInitializer', 'GAMMA', 'BETA', 'init'], 'description': 'Core parameter storage functionality'}]}",
    "version": "minimal",
    "text_answer": "Parameters are stored in a Map<String, INDArray> using predefined keys (GAMMA, BETA, GLOBAL_MEAN, GLOBAL_VAR/GLOBAL_LOG_STD). The init method creates this map and initializes the parameters using views of a flat parameter array. Access is provided through parameter keys and gradient extraction methods.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.deeplearning4j.nn.params;\n\nimport lombok.val;\nimport org.deeplearning4j.nn.api.ParamInitializer;\nimport org.deeplearning4j.nn.conf.NeuralNetConfiguration;\nimport org.deeplearning4j.nn.conf.layers.BatchNormalization;\nimport org.deeplearning4j.nn.conf.layers.Layer;\nimport org.nd4j.linalg.api.ndarray.INDArray;\nimport org.nd4j.linalg.indexing.NDArrayIndex;\n\nimport java.util.*;\n\npublic class BatchNormalizationParamInitializer implements ParamInitializer {\n\n    private static final BatchNormalizationParamInitializer INSTANCE = new BatchNormalizationParamInitializer();\n\n    public static BatchNormalizationParamInitializer getInstance() {\n        return INSTANCE;\n    }\n\n    public static final String GAMMA = \"gamma\";\n    public static final String BETA = \"beta\";\n    public static final String GLOBAL_MEAN = \"mean\";\n    public static final String GLOBAL_VAR = \"var\";\n    public static final String GLOBAL_LOG_STD = \"log10stdev\";\n\n    @Override\n    public long numParams(NeuralNetConfiguration conf) {\n        return numParams(conf.getLayer());\n    }\n\n    @Override\n    public long numParams(Layer l) {\n        BatchNormalization layer = (BatchNormalization) l;\n        //Parameters in batch norm:\n        //gamma, beta, global mean estimate, global variance estimate\n        // latter 2 are treated as parameters, which greatly simplifies spark training and model serialization\n\n        if (layer.isLockGammaBeta()) {\n            //Special case: gamma and beta are fixed values for all outputs -> no parameters for gamma and  beta in this case\n            return 2 * layer.getNOut();\n        } else {\n            //Standard case: gamma and beta are learned per output; additional 2*nOut for global mean/variance estimate\n            return 4 * layer.getNOut();\n        }\n    }\n\n    @Override\n    public List<String> paramKeys(Layer layer) {\n        if(((BatchNormalization)layer).isUseLogStd()){\n            return Arrays.asList(GAMMA, BETA, GLOBAL_MEAN, GLOBAL_LOG_STD);\n        } else {\n            return Arrays.asList(GAMMA, BETA, GLOBAL_MEAN, GLOBAL_VAR);\n        }\n    }\n\n    @Override\n    public List<String> weightKeys(Layer layer) {\n        return Collections.emptyList();\n    }\n\n    @Override\n    public List<String> biasKeys(Layer layer) {\n        return Collections.emptyList();\n    }\n\n    @Override\n    public boolean isWeightParam(Layer layer, String key) {\n        return false;\n    }\n\n    @Override\n    public boolean isBiasParam(Layer layer, String key) {\n        return false;\n    }\n\n    @Override\n    public Map<String, INDArray> init(NeuralNetConfiguration conf, INDArray paramView, boolean initializeParams) {\n        Map<String, INDArray> params = Collections.synchronizedMap(new LinkedHashMap<String, INDArray>());\n        // TODO setup for RNN\n        BatchNormalization layer = (BatchNormalization) conf.getLayer();\n        val nOut = layer.getNOut();\n\n        long meanOffset = 0;\n        INDArray paramViewReshape = paramView.reshape(paramView.length());\n        if (!layer.isLockGammaBeta()) { //No gamma/beta parameters when gamma/beta are locked\n            INDArray gammaView = paramViewReshape.get( NDArrayIndex.interval(0, nOut));\n            INDArray betaView = paramViewReshape.get(NDArrayIndex.interval(nOut, 2 * nOut));\n\n            params.put(GAMMA, createGamma(conf, gammaView, initializeParams));\n            conf.addVariable(GAMMA);\n            params.put(BETA, createBeta(conf, betaView, initializeParams));\n            conf.addVariable(BETA);\n\n            meanOffset = 2 * nOut;\n        }\n\n        INDArray globalMeanView =\n                paramViewReshape.get( NDArrayIndex.interval(meanOffset, meanOffset + nOut));\n        INDArray globalVarView = paramViewReshape.get(\n                        NDArrayIndex.interval(meanOffset + nOut, meanOffset + 2 * nOut));\n\n        if (initializeParams) {\n            globalMeanView.assign(0);\n            if(layer.isUseLogStd()){\n                //Global log stdev: assign 0.0 as initial value (s=sqrt(v), and log10(s) = log10(sqrt(v)) -> log10(1) = 0\n                globalVarView.assign(0);\n            } else {\n                //Global variance view: assign 1.0 as initial value\n                globalVarView.assign(1);\n            }\n        }\n\n        params.put(GLOBAL_MEAN, globalMeanView);\n        conf.addVariable(GLOBAL_MEAN);\n        if(layer.isUseLogStd()){\n            params.put(GLOBAL_LOG_STD, globalVarView);\n            conf.addVariable(GLOBAL_LOG_STD);\n        } else {\n            params.put(GLOBAL_VAR, globalVarView);\n            conf.addVariable(GLOBAL_VAR);\n        }\n\n        return params;\n    }\n\n    @Override\n    public Map<String, INDArray> getGradientsFromFlattened(NeuralNetConfiguration conf, INDArray gradientView) {\n        BatchNormalization layer = (BatchNormalization) conf.getLayer();\n        val nOut = layer.getNOut();\n\n        INDArray gradientViewReshape = gradientView.reshape(gradientView.length());\n        Map<String, INDArray> out = new LinkedHashMap<>();\n        long meanOffset = 0;\n        if (!layer.isLockGammaBeta()) {\n            INDArray gammaView = gradientViewReshape.get(NDArrayIndex.interval(0, nOut));\n            INDArray betaView = gradientViewReshape.get(NDArrayIndex.interval(nOut, 2 * nOut));\n            out.put(GAMMA, gammaView);\n            out.put(BETA, betaView);\n            meanOffset = 2 * nOut;\n        }\n\n        out.put(GLOBAL_MEAN,\n                gradientViewReshape.get( NDArrayIndex.interval(meanOffset, meanOffset + nOut)));\n        if(layer.isUseLogStd()){\n            out.put(GLOBAL_LOG_STD, gradientViewReshape.get(\n                    NDArrayIndex.interval(meanOffset + nOut, meanOffset + 2 * nOut)));\n        } else {\n            out.put(GLOBAL_VAR, gradientViewReshape.get(\n                    NDArrayIndex.interval(meanOffset + nOut, meanOffset + 2 * nOut)));\n        }\n\n        return out;\n    }\n\n    private INDArray createBeta(NeuralNetConfiguration conf, INDArray betaView, boolean initializeParams) {\n        BatchNormalization layer = (BatchNormalization) conf.getLayer();\n        if (initializeParams)\n            betaView.assign(layer.getBeta());\n        return betaView;\n    }\n\n    private INDArray createGamma(NeuralNetConfiguration conf, INDArray gammaView, boolean initializeParams) {\n        BatchNormalization layer = (BatchNormalization) conf.getLayer();\n        if (initializeParams)\n            gammaView.assign(layer.getGamma());\n        return gammaView;\n    }\n}",
    "repo": "deeplearning4j/deeplearning4j",
    "path": "./datasets/diagrams-repos/deeplearning4j/deeplearning4j/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/params/BatchNormalizationParamInitializer.java",
    "query": "Can you show how the parameters are stored and accessed in the parameter map?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'BatchNormalizationParamInitializer', 'node_id': 'BatchNormalizationParamInitializer', 'description': 'Initializes and manages parameters for batch normalization layers', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'GAMMA', 'node_id': 'GAMMA', 'description': 'Parameter key for gamma values', 'visibility': 'public', 'return_type': 'String', 'params': None, 'source_class_id': 'BatchNormalizationParamInitializer'}, {'type': 'field', 'name': 'BETA', 'node_id': 'BETA', 'description': 'Parameter key for beta values', 'visibility': 'public', 'return_type': 'String', 'params': None, 'source_class_id': 'BatchNormalizationParamInitializer'}, {'type': 'field', 'name': 'GLOBAL_MEAN', 'node_id': 'GLOBAL_MEAN', 'description': 'Parameter key for mean values', 'visibility': 'public', 'return_type': 'String', 'params': None, 'source_class_id': 'BatchNormalizationParamInitializer'}, {'type': 'field', 'name': 'GLOBAL_VAR', 'node_id': 'GLOBAL_VAR', 'description': 'Parameter key for variance values', 'visibility': 'public', 'return_type': 'String', 'params': None, 'source_class_id': 'BatchNormalizationParamInitializer'}, {'type': 'method', 'name': 'init', 'node_id': 'init', 'description': 'Initializes parameter map with all required values', 'visibility': 'public', 'return_type': 'Map<String, INDArray>', 'params': 'NeuralNetConfiguration conf, INDArray paramView, boolean initializeParams', 'source_class_id': 'BatchNormalizationParamInitializer'}, {'type': 'method', 'name': 'createGamma', 'node_id': 'createGamma', 'description': 'Creates gamma parameter array', 'visibility': 'private', 'return_type': 'INDArray', 'params': 'NeuralNetConfiguration conf, INDArray gammaView, boolean initializeParams', 'source_class_id': 'BatchNormalizationParamInitializer'}, {'type': 'method', 'name': 'createBeta', 'node_id': 'createBeta', 'description': 'Creates beta parameter array', 'visibility': 'private', 'return_type': 'INDArray', 'params': 'NeuralNetConfiguration conf, INDArray betaView, boolean initializeParams', 'source_class_id': 'BatchNormalizationParamInitializer'}], 'edges': [{'node_id_from': 'init', 'node_id_to': 'GAMMA', 'description': 'stores gamma parameters'}, {'node_id_from': 'init', 'node_id_to': 'BETA', 'description': 'stores beta parameters'}, {'node_id_from': 'init', 'node_id_to': 'GLOBAL_MEAN', 'description': 'stores mean parameters'}, {'node_id_from': 'init', 'node_id_to': 'GLOBAL_VAR', 'description': 'stores variance parameters'}, {'node_id_from': 'init', 'node_id_to': 'createGamma', 'description': 'calls to initialize gamma'}, {'node_id_from': 'init', 'node_id_to': 'createBeta', 'description': 'calls to initialize beta'}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'init', 'description': ''}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'GAMMA', 'description': ''}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'BETA', 'description': ''}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'GLOBAL_MEAN', 'description': ''}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'GLOBAL_VAR', 'description': ''}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'createGamma', 'description': ''}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'createBeta', 'description': ''}], 'packages': [{'package_id': 'parameterStorage', 'children': ['BatchNormalizationParamInitializer', 'GAMMA', 'BETA', 'GLOBAL_MEAN', 'GLOBAL_VAR', 'parameterInitialization'], 'description': 'Parameter storage components'}, {'package_id': 'parameterInitialization', 'children': ['init', 'createGamma', 'createBeta'], 'description': 'Parameter initialization methods'}]}",
    "version": "medium",
    "text_answer": "Parameters are stored in a Map<String, INDArray> using predefined keys (GAMMA, BETA, GLOBAL_MEAN, GLOBAL_VAR/GLOBAL_LOG_STD). The init method creates this map and initializes the parameters using views of a flat parameter array. Access is provided through parameter keys and gradient extraction methods.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.deeplearning4j.nn.params;\n\nimport lombok.val;\nimport org.deeplearning4j.nn.api.ParamInitializer;\nimport org.deeplearning4j.nn.conf.NeuralNetConfiguration;\nimport org.deeplearning4j.nn.conf.layers.BatchNormalization;\nimport org.deeplearning4j.nn.conf.layers.Layer;\nimport org.nd4j.linalg.api.ndarray.INDArray;\nimport org.nd4j.linalg.indexing.NDArrayIndex;\n\nimport java.util.*;\n\npublic class BatchNormalizationParamInitializer implements ParamInitializer {\n\n    private static final BatchNormalizationParamInitializer INSTANCE = new BatchNormalizationParamInitializer();\n\n    public static BatchNormalizationParamInitializer getInstance() {\n        return INSTANCE;\n    }\n\n    public static final String GAMMA = \"gamma\";\n    public static final String BETA = \"beta\";\n    public static final String GLOBAL_MEAN = \"mean\";\n    public static final String GLOBAL_VAR = \"var\";\n    public static final String GLOBAL_LOG_STD = \"log10stdev\";\n\n    @Override\n    public long numParams(NeuralNetConfiguration conf) {\n        return numParams(conf.getLayer());\n    }\n\n    @Override\n    public long numParams(Layer l) {\n        BatchNormalization layer = (BatchNormalization) l;\n        //Parameters in batch norm:\n        //gamma, beta, global mean estimate, global variance estimate\n        // latter 2 are treated as parameters, which greatly simplifies spark training and model serialization\n\n        if (layer.isLockGammaBeta()) {\n            //Special case: gamma and beta are fixed values for all outputs -> no parameters for gamma and  beta in this case\n            return 2 * layer.getNOut();\n        } else {\n            //Standard case: gamma and beta are learned per output; additional 2*nOut for global mean/variance estimate\n            return 4 * layer.getNOut();\n        }\n    }\n\n    @Override\n    public List<String> paramKeys(Layer layer) {\n        if(((BatchNormalization)layer).isUseLogStd()){\n            return Arrays.asList(GAMMA, BETA, GLOBAL_MEAN, GLOBAL_LOG_STD);\n        } else {\n            return Arrays.asList(GAMMA, BETA, GLOBAL_MEAN, GLOBAL_VAR);\n        }\n    }\n\n    @Override\n    public List<String> weightKeys(Layer layer) {\n        return Collections.emptyList();\n    }\n\n    @Override\n    public List<String> biasKeys(Layer layer) {\n        return Collections.emptyList();\n    }\n\n    @Override\n    public boolean isWeightParam(Layer layer, String key) {\n        return false;\n    }\n\n    @Override\n    public boolean isBiasParam(Layer layer, String key) {\n        return false;\n    }\n\n    @Override\n    public Map<String, INDArray> init(NeuralNetConfiguration conf, INDArray paramView, boolean initializeParams) {\n        Map<String, INDArray> params = Collections.synchronizedMap(new LinkedHashMap<String, INDArray>());\n        // TODO setup for RNN\n        BatchNormalization layer = (BatchNormalization) conf.getLayer();\n        val nOut = layer.getNOut();\n\n        long meanOffset = 0;\n        INDArray paramViewReshape = paramView.reshape(paramView.length());\n        if (!layer.isLockGammaBeta()) { //No gamma/beta parameters when gamma/beta are locked\n            INDArray gammaView = paramViewReshape.get( NDArrayIndex.interval(0, nOut));\n            INDArray betaView = paramViewReshape.get(NDArrayIndex.interval(nOut, 2 * nOut));\n\n            params.put(GAMMA, createGamma(conf, gammaView, initializeParams));\n            conf.addVariable(GAMMA);\n            params.put(BETA, createBeta(conf, betaView, initializeParams));\n            conf.addVariable(BETA);\n\n            meanOffset = 2 * nOut;\n        }\n\n        INDArray globalMeanView =\n                paramViewReshape.get( NDArrayIndex.interval(meanOffset, meanOffset + nOut));\n        INDArray globalVarView = paramViewReshape.get(\n                        NDArrayIndex.interval(meanOffset + nOut, meanOffset + 2 * nOut));\n\n        if (initializeParams) {\n            globalMeanView.assign(0);\n            if(layer.isUseLogStd()){\n                //Global log stdev: assign 0.0 as initial value (s=sqrt(v), and log10(s) = log10(sqrt(v)) -> log10(1) = 0\n                globalVarView.assign(0);\n            } else {\n                //Global variance view: assign 1.0 as initial value\n                globalVarView.assign(1);\n            }\n        }\n\n        params.put(GLOBAL_MEAN, globalMeanView);\n        conf.addVariable(GLOBAL_MEAN);\n        if(layer.isUseLogStd()){\n            params.put(GLOBAL_LOG_STD, globalVarView);\n            conf.addVariable(GLOBAL_LOG_STD);\n        } else {\n            params.put(GLOBAL_VAR, globalVarView);\n            conf.addVariable(GLOBAL_VAR);\n        }\n\n        return params;\n    }\n\n    @Override\n    public Map<String, INDArray> getGradientsFromFlattened(NeuralNetConfiguration conf, INDArray gradientView) {\n        BatchNormalization layer = (BatchNormalization) conf.getLayer();\n        val nOut = layer.getNOut();\n\n        INDArray gradientViewReshape = gradientView.reshape(gradientView.length());\n        Map<String, INDArray> out = new LinkedHashMap<>();\n        long meanOffset = 0;\n        if (!layer.isLockGammaBeta()) {\n            INDArray gammaView = gradientViewReshape.get(NDArrayIndex.interval(0, nOut));\n            INDArray betaView = gradientViewReshape.get(NDArrayIndex.interval(nOut, 2 * nOut));\n            out.put(GAMMA, gammaView);\n            out.put(BETA, betaView);\n            meanOffset = 2 * nOut;\n        }\n\n        out.put(GLOBAL_MEAN,\n                gradientViewReshape.get( NDArrayIndex.interval(meanOffset, meanOffset + nOut)));\n        if(layer.isUseLogStd()){\n            out.put(GLOBAL_LOG_STD, gradientViewReshape.get(\n                    NDArrayIndex.interval(meanOffset + nOut, meanOffset + 2 * nOut)));\n        } else {\n            out.put(GLOBAL_VAR, gradientViewReshape.get(\n                    NDArrayIndex.interval(meanOffset + nOut, meanOffset + 2 * nOut)));\n        }\n\n        return out;\n    }\n\n    private INDArray createBeta(NeuralNetConfiguration conf, INDArray betaView, boolean initializeParams) {\n        BatchNormalization layer = (BatchNormalization) conf.getLayer();\n        if (initializeParams)\n            betaView.assign(layer.getBeta());\n        return betaView;\n    }\n\n    private INDArray createGamma(NeuralNetConfiguration conf, INDArray gammaView, boolean initializeParams) {\n        BatchNormalization layer = (BatchNormalization) conf.getLayer();\n        if (initializeParams)\n            gammaView.assign(layer.getGamma());\n        return gammaView;\n    }\n}",
    "repo": "deeplearning4j/deeplearning4j",
    "path": "./datasets/diagrams-repos/deeplearning4j/deeplearning4j/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/params/BatchNormalizationParamInitializer.java",
    "query": "Can you show how the parameters are stored and accessed in the parameter map?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'BatchNormalizationParamInitializer', 'node_id': 'BatchNormalizationParamInitializer', 'description': 'Initializes and manages parameters for batch normalization layers', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'INSTANCE', 'node_id': 'INSTANCE', 'description': 'Singleton instance', 'visibility': 'private', 'return_type': 'BatchNormalizationParamInitializer', 'params': None, 'source_class_id': 'BatchNormalizationParamInitializer'}, {'type': 'field', 'name': 'GAMMA', 'node_id': 'GAMMA', 'description': 'Parameter key for gamma values', 'visibility': 'public', 'return_type': 'String', 'params': None, 'source_class_id': 'BatchNormalizationParamInitializer'}, {'type': 'field', 'name': 'BETA', 'node_id': 'BETA', 'description': 'Parameter key for beta values', 'visibility': 'public', 'return_type': 'String', 'params': None, 'source_class_id': 'BatchNormalizationParamInitializer'}, {'type': 'field', 'name': 'GLOBAL_MEAN', 'node_id': 'GLOBAL_MEAN', 'description': 'Parameter key for mean values', 'visibility': 'public', 'return_type': 'String', 'params': None, 'source_class_id': 'BatchNormalizationParamInitializer'}, {'type': 'field', 'name': 'GLOBAL_VAR', 'node_id': 'GLOBAL_VAR', 'description': 'Parameter key for variance values', 'visibility': 'public', 'return_type': 'String', 'params': None, 'source_class_id': 'BatchNormalizationParamInitializer'}, {'type': 'field', 'name': 'GLOBAL_LOG_STD', 'node_id': 'GLOBAL_LOG_STD', 'description': 'Parameter key for log standard deviation', 'visibility': 'public', 'return_type': 'String', 'params': None, 'source_class_id': 'BatchNormalizationParamInitializer'}, {'type': 'method', 'name': 'getInstance', 'node_id': 'getInstance', 'description': 'Returns singleton instance', 'visibility': 'public', 'return_type': 'BatchNormalizationParamInitializer', 'params': '', 'source_class_id': 'BatchNormalizationParamInitializer'}, {'type': 'method', 'name': 'init', 'node_id': 'init', 'description': 'Initializes parameter map with all required values', 'visibility': 'public', 'return_type': 'Map<String, INDArray>', 'params': 'NeuralNetConfiguration conf, INDArray paramView, boolean initializeParams', 'source_class_id': 'BatchNormalizationParamInitializer'}, {'type': 'method', 'name': 'createGamma', 'node_id': 'createGamma', 'description': 'Creates gamma parameter array', 'visibility': 'private', 'return_type': 'INDArray', 'params': 'NeuralNetConfiguration conf, INDArray gammaView, boolean initializeParams', 'source_class_id': 'BatchNormalizationParamInitializer'}, {'type': 'method', 'name': 'createBeta', 'node_id': 'createBeta', 'description': 'Creates beta parameter array', 'visibility': 'private', 'return_type': 'INDArray', 'params': 'NeuralNetConfiguration conf, INDArray betaView, boolean initializeParams', 'source_class_id': 'BatchNormalizationParamInitializer'}, {'type': 'method', 'name': 'getGradientsFromFlattened', 'node_id': 'getGradientsFromFlattened', 'description': 'Extracts gradients from flattened array', 'visibility': 'public', 'return_type': 'Map<String, INDArray>', 'params': 'NeuralNetConfiguration conf, INDArray gradientView', 'source_class_id': 'BatchNormalizationParamInitializer'}, {'type': 'method', 'name': 'paramKeys', 'node_id': 'paramKeys', 'description': 'Returns list of parameter keys', 'visibility': 'public', 'return_type': 'List<String>', 'params': 'Layer layer', 'source_class_id': 'BatchNormalizationParamInitializer'}], 'edges': [{'node_id_from': 'getInstance', 'node_id_to': 'INSTANCE', 'description': 'returns singleton'}, {'node_id_from': 'init', 'node_id_to': 'GAMMA', 'description': 'stores gamma parameters'}, {'node_id_from': 'init', 'node_id_to': 'BETA', 'description': 'stores beta parameters'}, {'node_id_from': 'init', 'node_id_to': 'GLOBAL_MEAN', 'description': 'stores mean parameters'}, {'node_id_from': 'init', 'node_id_to': 'GLOBAL_VAR', 'description': 'stores variance parameters'}, {'node_id_from': 'init', 'node_id_to': 'GLOBAL_LOG_STD', 'description': 'stores log std parameters'}, {'node_id_from': 'init', 'node_id_to': 'createGamma', 'description': 'calls to initialize gamma'}, {'node_id_from': 'init', 'node_id_to': 'createBeta', 'description': 'calls to initialize beta'}, {'node_id_from': 'paramKeys', 'node_id_to': 'GAMMA', 'description': 'returns key'}, {'node_id_from': 'paramKeys', 'node_id_to': 'BETA', 'description': 'returns key'}, {'node_id_from': 'paramKeys', 'node_id_to': 'GLOBAL_MEAN', 'description': 'returns key'}, {'node_id_from': 'getGradientsFromFlattened', 'node_id_to': 'GAMMA', 'description': 'extracts gradient'}, {'node_id_from': 'getGradientsFromFlattened', 'node_id_to': 'BETA', 'description': 'extracts gradient'}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'init', 'description': ''}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'INSTANCE', 'description': ''}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'GAMMA', 'description': ''}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'BETA', 'description': ''}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'GLOBAL_MEAN', 'description': ''}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'GLOBAL_VAR', 'description': ''}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'GLOBAL_LOG_STD', 'description': ''}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'createGamma', 'description': ''}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'createBeta', 'description': ''}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'getInstance', 'description': ''}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'getGradientsFromFlattened', 'description': ''}, {'node_id_from': 'BatchNormalizationParamInitializer', 'node_id_to': 'paramKeys', 'description': ''}], 'packages': [{'package_id': 'parameterStorage', 'children': ['BatchNormalizationParamInitializer', 'INSTANCE', 'GAMMA', 'BETA', 'GLOBAL_MEAN', 'GLOBAL_VAR', 'GLOBAL_LOG_STD', 'parameterInitialization', 'parameterAccess'], 'description': 'Parameter storage components'}, {'package_id': 'parameterInitialization', 'children': ['init', 'createGamma', 'createBeta'], 'description': 'Parameter initialization methods'}, {'package_id': 'parameterAccess', 'children': ['getInstance', 'paramKeys', 'getGradientsFromFlattened'], 'description': 'Parameter access methods'}]}",
    "version": "full",
    "text_answer": "Parameters are stored in a Map<String, INDArray> using predefined keys (GAMMA, BETA, GLOBAL_MEAN, GLOBAL_VAR/GLOBAL_LOG_STD). The init method creates this map and initializes the parameters using views of a flat parameter array. Access is provided through parameter keys and gradient extraction methods.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage ghidra.feature.fid.debug;\n\nimport java.util.*;\n\nimport javax.swing.*;\n\nimport ghidra.feature.fid.db.FidQueryService;\nimport ghidra.feature.fid.db.FunctionRecord;\nimport ghidra.feature.fid.service.FidService;\nimport ghidra.util.NumericUtilities;\n\n/**\n * Utility class to handle some debug functions for the FID database.\n */\npublic class FidDebugUtils {\n\n\t/**\n\t * Search the FID system for function records by name substring.\n\t * @param name the name substring to search\n\t */\n\tpublic static FidSearchResultFrame searchByName(String name, FidService service,\n\t\t\tFidQueryService fidQueryService) {\n\t\tList<FunctionRecord> functionRecords = fidQueryService.findFunctionsByNameSubstring(name);\n\t\treturn new FidSearchResultFrame(\"Name: \" + name, functionRecords, service, fidQueryService);\n\t}\n\n\t/**\n\t * Search the FID system for function records by domain path substring.\n\t * @param domainPath the domain path substring to search\n\t */\n\tpublic static FidSearchResultFrame searchByDomainPath(String domainPath, FidService service,\n\t\t\tFidQueryService fidQueryService) {\n\t\tList<FunctionRecord> functionRecords =\n\t\t\tfidQueryService.findFunctionsByDomainPathSubstring(domainPath);\n\t\treturn new FidSearchResultFrame(\"Domain Path: \" + domainPath, functionRecords, service,\n\t\t\tfidQueryService);\n\t}\n\n\t/**\n\t * Search the FID system for function records by exact full hash.\n\t * @param fullHash the full hash to search\n\t */\n\tpublic static FidSearchResultFrame searchByFullHash(long fullHash, FidService service,\n\t\t\tFidQueryService fidQueryService) {\n\t\tList<FunctionRecord> functionRecords = fidQueryService.findFunctionsByFullHash(fullHash);\n\t\treturn new FidSearchResultFrame(String.format(\"FH: 0x%x\", fullHash), functionRecords,\n\t\t\tservice, fidQueryService);\n\t}\n\n\t/**\n\t * Search the FID system for function records by exact specific hash.\n\t * @param specificHash the specific hash to search\n\t */\n\tpublic static FidSearchResultFrame searchBySpecificHash(long specificHash, FidService service,\n\t\t\tFidQueryService fidQueryService) {\n\t\tList<FunctionRecord> functionRecords =\n\t\t\tfidQueryService.findFunctionsBySpecificHash(specificHash);\n\t\treturn new FidSearchResultFrame(String.format(\"XH: 0x%x\", specificHash), functionRecords,\n\t\t\tservice, fidQueryService);\n\t}\n\n\t/**\n\t * Opens a function record debug panel in a new window.\n\t * @param functionRecord the function record to debug\n\t */\n\tpublic static void openFunctionWindow(FunctionRecord functionRecord, FidService service,\n\t\t\tFidQueryService fidQueryService) {\n\t\tFidFunctionDebugPanel panel =\n\t\t\tnew FidFunctionDebugPanel(service, fidQueryService, functionRecord);\n\t\tJScrollPane scrollPane = new JScrollPane(panel);\n\n\t\tString title = String.format(\"0x%x - %s\", functionRecord.getID(), functionRecord.getName());\n\t\tJFrame frame = new JFrame(title);\n\t\tframe.setDefaultCloseOperation(WindowConstants.DISPOSE_ON_CLOSE);\n\t\tframe.setContentPane(scrollPane);\n\t\tframe.pack();\n\t\tframe.setVisible(true);\n\t\tfidQueryService.addCloseListener(listener -> frame.dispose());\n\t}\n\n\t/**\n\t * Searches for a function by primary key, then pops up a table with the result (or empty).\n\t * @param text the string representing the function record primary key\n\t */\n\tpublic static FidSearchResultFrame searchByFunctionID(long id, FidService service,\n\t\t\tFidQueryService fidQueryService) {\n\t\tFunctionRecord functionRecord = fidQueryService.getFunctionByID(id);\n\t\treturn new FidSearchResultFrame(String.format(\"Function ID: 0x%x\", id),\n\t\t\tfunctionRecord == null ? new ArrayList<FunctionRecord>()\n\t\t\t\t\t: new ArrayList<FunctionRecord>(Collections.singletonList(functionRecord)),\n\t\t\tservice, fidQueryService);\n\t}\n\n\t/**\n\t * Pops up an error dialog.\n\t * @param name the name of the parameter\n\t * @param text the text that does not parse as a number\n\t */\n\tprivate static void popupNumericParseError(String name, String text) {\n\t\tJOptionPane.showMessageDialog(null, \"Could not parse \" + name + \": \" + text);\n\t}\n\n\t/**\n\t * Tries to parse the text as a long numeric value.\n\t * @param text the text to parse\n\t * @return the value, or null in case of parse error\n\t */\n\tpublic static Long validateHashText(String text, String errorMessage) {\n\t\ttry {\n\t\t\tlong parseLong = NumericUtilities.parseLong(text);\n\t\t\treturn parseLong;\n\t\t}\n\t\tcatch (NumberFormatException e) {\n\t\t\tpopupNumericParseError(errorMessage, text);\n\t\t\treturn null;\n\t\t}\n\t}\n\n}",
    "repo": "NationalSecurityAgency/ghidra",
    "path": "./datasets/diagrams-repos/NationalSecurityAgency/ghidra/Ghidra/Features/FunctionID/src/main/java/ghidra/feature/fid/debug/FidDebugUtils.java",
    "query": "What is the relationship between FidService and FidQueryService in the context of FidDebugUtils?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'FidDebugUtils', 'node_id': 'FidDebugUtils', 'description': 'Utility class for debugging FID database', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'FidService', 'node_id': 'FidService', 'description': 'Service for FID functionality', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'FidQueryService', 'node_id': 'FidQueryService', 'description': 'Service for querying FID database', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'FidDebugUtils', 'node_id_to': 'FidService', 'description': 'uses'}, {'node_id_from': 'FidDebugUtils', 'node_id_to': 'FidQueryService', 'description': 'uses for database queries'}], 'packages': [{'package_id': 'debugPackage', 'children': ['FidDebugUtils', 'FidService', 'FidQueryService'], 'description': 'Debug-related components'}]}",
    "version": "minimal",
    "text_answer": "FidDebugUtils acts as a bridge between FidService and FidQueryService, where FidService provides general FID functionality while FidQueryService handles specific database queries. All debug utility methods require both services as parameters, with FidQueryService being used for actual database operations (searching, retrieving records) and FidService supporting higher-level functionality.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage ghidra.feature.fid.debug;\n\nimport java.util.*;\n\nimport javax.swing.*;\n\nimport ghidra.feature.fid.db.FidQueryService;\nimport ghidra.feature.fid.db.FunctionRecord;\nimport ghidra.feature.fid.service.FidService;\nimport ghidra.util.NumericUtilities;\n\n/**\n * Utility class to handle some debug functions for the FID database.\n */\npublic class FidDebugUtils {\n\n\t/**\n\t * Search the FID system for function records by name substring.\n\t * @param name the name substring to search\n\t */\n\tpublic static FidSearchResultFrame searchByName(String name, FidService service,\n\t\t\tFidQueryService fidQueryService) {\n\t\tList<FunctionRecord> functionRecords = fidQueryService.findFunctionsByNameSubstring(name);\n\t\treturn new FidSearchResultFrame(\"Name: \" + name, functionRecords, service, fidQueryService);\n\t}\n\n\t/**\n\t * Search the FID system for function records by domain path substring.\n\t * @param domainPath the domain path substring to search\n\t */\n\tpublic static FidSearchResultFrame searchByDomainPath(String domainPath, FidService service,\n\t\t\tFidQueryService fidQueryService) {\n\t\tList<FunctionRecord> functionRecords =\n\t\t\tfidQueryService.findFunctionsByDomainPathSubstring(domainPath);\n\t\treturn new FidSearchResultFrame(\"Domain Path: \" + domainPath, functionRecords, service,\n\t\t\tfidQueryService);\n\t}\n\n\t/**\n\t * Search the FID system for function records by exact full hash.\n\t * @param fullHash the full hash to search\n\t */\n\tpublic static FidSearchResultFrame searchByFullHash(long fullHash, FidService service,\n\t\t\tFidQueryService fidQueryService) {\n\t\tList<FunctionRecord> functionRecords = fidQueryService.findFunctionsByFullHash(fullHash);\n\t\treturn new FidSearchResultFrame(String.format(\"FH: 0x%x\", fullHash), functionRecords,\n\t\t\tservice, fidQueryService);\n\t}\n\n\t/**\n\t * Search the FID system for function records by exact specific hash.\n\t * @param specificHash the specific hash to search\n\t */\n\tpublic static FidSearchResultFrame searchBySpecificHash(long specificHash, FidService service,\n\t\t\tFidQueryService fidQueryService) {\n\t\tList<FunctionRecord> functionRecords =\n\t\t\tfidQueryService.findFunctionsBySpecificHash(specificHash);\n\t\treturn new FidSearchResultFrame(String.format(\"XH: 0x%x\", specificHash), functionRecords,\n\t\t\tservice, fidQueryService);\n\t}\n\n\t/**\n\t * Opens a function record debug panel in a new window.\n\t * @param functionRecord the function record to debug\n\t */\n\tpublic static void openFunctionWindow(FunctionRecord functionRecord, FidService service,\n\t\t\tFidQueryService fidQueryService) {\n\t\tFidFunctionDebugPanel panel =\n\t\t\tnew FidFunctionDebugPanel(service, fidQueryService, functionRecord);\n\t\tJScrollPane scrollPane = new JScrollPane(panel);\n\n\t\tString title = String.format(\"0x%x - %s\", functionRecord.getID(), functionRecord.getName());\n\t\tJFrame frame = new JFrame(title);\n\t\tframe.setDefaultCloseOperation(WindowConstants.DISPOSE_ON_CLOSE);\n\t\tframe.setContentPane(scrollPane);\n\t\tframe.pack();\n\t\tframe.setVisible(true);\n\t\tfidQueryService.addCloseListener(listener -> frame.dispose());\n\t}\n\n\t/**\n\t * Searches for a function by primary key, then pops up a table with the result (or empty).\n\t * @param text the string representing the function record primary key\n\t */\n\tpublic static FidSearchResultFrame searchByFunctionID(long id, FidService service,\n\t\t\tFidQueryService fidQueryService) {\n\t\tFunctionRecord functionRecord = fidQueryService.getFunctionByID(id);\n\t\treturn new FidSearchResultFrame(String.format(\"Function ID: 0x%x\", id),\n\t\t\tfunctionRecord == null ? new ArrayList<FunctionRecord>()\n\t\t\t\t\t: new ArrayList<FunctionRecord>(Collections.singletonList(functionRecord)),\n\t\t\tservice, fidQueryService);\n\t}\n\n\t/**\n\t * Pops up an error dialog.\n\t * @param name the name of the parameter\n\t * @param text the text that does not parse as a number\n\t */\n\tprivate static void popupNumericParseError(String name, String text) {\n\t\tJOptionPane.showMessageDialog(null, \"Could not parse \" + name + \": \" + text);\n\t}\n\n\t/**\n\t * Tries to parse the text as a long numeric value.\n\t * @param text the text to parse\n\t * @return the value, or null in case of parse error\n\t */\n\tpublic static Long validateHashText(String text, String errorMessage) {\n\t\ttry {\n\t\t\tlong parseLong = NumericUtilities.parseLong(text);\n\t\t\treturn parseLong;\n\t\t}\n\t\tcatch (NumberFormatException e) {\n\t\t\tpopupNumericParseError(errorMessage, text);\n\t\t\treturn null;\n\t\t}\n\t}\n\n}",
    "repo": "NationalSecurityAgency/ghidra",
    "path": "./datasets/diagrams-repos/NationalSecurityAgency/ghidra/Ghidra/Features/FunctionID/src/main/java/ghidra/feature/fid/debug/FidDebugUtils.java",
    "query": "What is the relationship between FidService and FidQueryService in the context of FidDebugUtils?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'FidDebugUtils', 'node_id': 'FidDebugUtils', 'description': 'Utility class for debugging FID database', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'FidService', 'node_id': 'FidService', 'description': 'Service for FID functionality', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'FidQueryService', 'node_id': 'FidQueryService', 'description': 'Service for querying FID database', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'searchByName', 'node_id': 'searchByName', 'description': 'Searches functions by name', 'visibility': 'public', 'return_type': 'FidSearchResultFrame', 'params': 'String name, FidService service, FidQueryService fidQueryService', 'source_class_id': 'FidDebugUtils'}, {'type': 'method', 'name': 'searchByFullHash', 'node_id': 'searchByFullHash', 'description': 'Searches functions by full hash', 'visibility': 'public', 'return_type': 'FidSearchResultFrame', 'params': 'long fullHash, FidService service, FidQueryService fidQueryService', 'source_class_id': 'FidDebugUtils'}], 'edges': [{'node_id_from': 'FidDebugUtils', 'node_id_to': 'FidService', 'description': 'uses'}, {'node_id_from': 'FidDebugUtils', 'node_id_to': 'FidQueryService', 'description': 'uses for database queries'}, {'node_id_from': 'searchByName', 'node_id_to': 'FidQueryService', 'description': 'calls findFunctionsByNameSubstring'}, {'node_id_from': 'searchByFullHash', 'node_id_to': 'FidQueryService', 'description': 'calls findFunctionsByFullHash'}, {'node_id_from': 'FidDebugUtils', 'node_id_to': 'searchByName', 'description': ''}, {'node_id_from': 'FidDebugUtils', 'node_id_to': 'searchByFullHash', 'description': ''}], 'packages': [{'package_id': 'debugPackage', 'children': ['FidDebugUtils', 'FidService', 'FidQueryService', 'searchByName', 'searchByFullHash'], 'description': 'Debug-related components'}]}",
    "version": "medium",
    "text_answer": "FidDebugUtils acts as a bridge between FidService and FidQueryService, where FidService provides general FID functionality while FidQueryService handles specific database queries. All debug utility methods require both services as parameters, with FidQueryService being used for actual database operations (searching, retrieving records) and FidService supporting higher-level functionality.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage ghidra.feature.fid.debug;\n\nimport java.util.*;\n\nimport javax.swing.*;\n\nimport ghidra.feature.fid.db.FidQueryService;\nimport ghidra.feature.fid.db.FunctionRecord;\nimport ghidra.feature.fid.service.FidService;\nimport ghidra.util.NumericUtilities;\n\n/**\n * Utility class to handle some debug functions for the FID database.\n */\npublic class FidDebugUtils {\n\n\t/**\n\t * Search the FID system for function records by name substring.\n\t * @param name the name substring to search\n\t */\n\tpublic static FidSearchResultFrame searchByName(String name, FidService service,\n\t\t\tFidQueryService fidQueryService) {\n\t\tList<FunctionRecord> functionRecords = fidQueryService.findFunctionsByNameSubstring(name);\n\t\treturn new FidSearchResultFrame(\"Name: \" + name, functionRecords, service, fidQueryService);\n\t}\n\n\t/**\n\t * Search the FID system for function records by domain path substring.\n\t * @param domainPath the domain path substring to search\n\t */\n\tpublic static FidSearchResultFrame searchByDomainPath(String domainPath, FidService service,\n\t\t\tFidQueryService fidQueryService) {\n\t\tList<FunctionRecord> functionRecords =\n\t\t\tfidQueryService.findFunctionsByDomainPathSubstring(domainPath);\n\t\treturn new FidSearchResultFrame(\"Domain Path: \" + domainPath, functionRecords, service,\n\t\t\tfidQueryService);\n\t}\n\n\t/**\n\t * Search the FID system for function records by exact full hash.\n\t * @param fullHash the full hash to search\n\t */\n\tpublic static FidSearchResultFrame searchByFullHash(long fullHash, FidService service,\n\t\t\tFidQueryService fidQueryService) {\n\t\tList<FunctionRecord> functionRecords = fidQueryService.findFunctionsByFullHash(fullHash);\n\t\treturn new FidSearchResultFrame(String.format(\"FH: 0x%x\", fullHash), functionRecords,\n\t\t\tservice, fidQueryService);\n\t}\n\n\t/**\n\t * Search the FID system for function records by exact specific hash.\n\t * @param specificHash the specific hash to search\n\t */\n\tpublic static FidSearchResultFrame searchBySpecificHash(long specificHash, FidService service,\n\t\t\tFidQueryService fidQueryService) {\n\t\tList<FunctionRecord> functionRecords =\n\t\t\tfidQueryService.findFunctionsBySpecificHash(specificHash);\n\t\treturn new FidSearchResultFrame(String.format(\"XH: 0x%x\", specificHash), functionRecords,\n\t\t\tservice, fidQueryService);\n\t}\n\n\t/**\n\t * Opens a function record debug panel in a new window.\n\t * @param functionRecord the function record to debug\n\t */\n\tpublic static void openFunctionWindow(FunctionRecord functionRecord, FidService service,\n\t\t\tFidQueryService fidQueryService) {\n\t\tFidFunctionDebugPanel panel =\n\t\t\tnew FidFunctionDebugPanel(service, fidQueryService, functionRecord);\n\t\tJScrollPane scrollPane = new JScrollPane(panel);\n\n\t\tString title = String.format(\"0x%x - %s\", functionRecord.getID(), functionRecord.getName());\n\t\tJFrame frame = new JFrame(title);\n\t\tframe.setDefaultCloseOperation(WindowConstants.DISPOSE_ON_CLOSE);\n\t\tframe.setContentPane(scrollPane);\n\t\tframe.pack();\n\t\tframe.setVisible(true);\n\t\tfidQueryService.addCloseListener(listener -> frame.dispose());\n\t}\n\n\t/**\n\t * Searches for a function by primary key, then pops up a table with the result (or empty).\n\t * @param text the string representing the function record primary key\n\t */\n\tpublic static FidSearchResultFrame searchByFunctionID(long id, FidService service,\n\t\t\tFidQueryService fidQueryService) {\n\t\tFunctionRecord functionRecord = fidQueryService.getFunctionByID(id);\n\t\treturn new FidSearchResultFrame(String.format(\"Function ID: 0x%x\", id),\n\t\t\tfunctionRecord == null ? new ArrayList<FunctionRecord>()\n\t\t\t\t\t: new ArrayList<FunctionRecord>(Collections.singletonList(functionRecord)),\n\t\t\tservice, fidQueryService);\n\t}\n\n\t/**\n\t * Pops up an error dialog.\n\t * @param name the name of the parameter\n\t * @param text the text that does not parse as a number\n\t */\n\tprivate static void popupNumericParseError(String name, String text) {\n\t\tJOptionPane.showMessageDialog(null, \"Could not parse \" + name + \": \" + text);\n\t}\n\n\t/**\n\t * Tries to parse the text as a long numeric value.\n\t * @param text the text to parse\n\t * @return the value, or null in case of parse error\n\t */\n\tpublic static Long validateHashText(String text, String errorMessage) {\n\t\ttry {\n\t\t\tlong parseLong = NumericUtilities.parseLong(text);\n\t\t\treturn parseLong;\n\t\t}\n\t\tcatch (NumberFormatException e) {\n\t\t\tpopupNumericParseError(errorMessage, text);\n\t\t\treturn null;\n\t\t}\n\t}\n\n}",
    "repo": "NationalSecurityAgency/ghidra",
    "path": "./datasets/diagrams-repos/NationalSecurityAgency/ghidra/Ghidra/Features/FunctionID/src/main/java/ghidra/feature/fid/debug/FidDebugUtils.java",
    "query": "What is the relationship between FidService and FidQueryService in the context of FidDebugUtils?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'FidDebugUtils', 'node_id': 'FidDebugUtils', 'description': 'Utility class for debugging FID database', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'FidService', 'node_id': 'FidService', 'description': 'Service for FID functionality', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'FidQueryService', 'node_id': 'FidQueryService', 'description': 'Service for querying FID database', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'searchByName', 'node_id': 'searchByName', 'description': 'Searches functions by name', 'visibility': 'public', 'return_type': 'FidSearchResultFrame', 'params': 'String name, FidService service, FidQueryService fidQueryService', 'source_class_id': 'FidDebugUtils'}, {'type': 'method', 'name': 'searchByDomainPath', 'node_id': 'searchByDomainPath', 'description': 'Searches functions by domain path', 'visibility': 'public', 'return_type': 'FidSearchResultFrame', 'params': 'String domainPath, FidService service, FidQueryService fidQueryService', 'source_class_id': 'FidDebugUtils'}, {'type': 'method', 'name': 'searchByFullHash', 'node_id': 'searchByFullHash', 'description': 'Searches functions by full hash', 'visibility': 'public', 'return_type': 'FidSearchResultFrame', 'params': 'long fullHash, FidService service, FidQueryService fidQueryService', 'source_class_id': 'FidDebugUtils'}, {'type': 'method', 'name': 'searchBySpecificHash', 'node_id': 'searchBySpecificHash', 'description': 'Searches functions by specific hash', 'visibility': 'public', 'return_type': 'FidSearchResultFrame', 'params': 'long specificHash, FidService service, FidQueryService fidQueryService', 'source_class_id': 'FidDebugUtils'}, {'type': 'method', 'name': 'searchByFunctionID', 'node_id': 'searchByFunctionID', 'description': 'Searches function by ID', 'visibility': 'public', 'return_type': 'FidSearchResultFrame', 'params': 'long id, FidService service, FidQueryService fidQueryService', 'source_class_id': 'FidDebugUtils'}, {'type': 'method', 'name': 'openFunctionWindow', 'node_id': 'openFunctionWindow', 'description': 'Opens debug panel for function', 'visibility': 'public', 'return_type': 'void', 'params': 'FunctionRecord functionRecord, FidService service, FidQueryService fidQueryService', 'source_class_id': 'FidDebugUtils'}], 'edges': [{'node_id_from': 'FidDebugUtils', 'node_id_to': 'FidService', 'description': 'uses'}, {'node_id_from': 'FidDebugUtils', 'node_id_to': 'FidQueryService', 'description': 'uses for database queries'}, {'node_id_from': 'searchByName', 'node_id_to': 'FidQueryService', 'description': 'calls findFunctionsByNameSubstring'}, {'node_id_from': 'searchByDomainPath', 'node_id_to': 'FidQueryService', 'description': 'calls findFunctionsByDomainPathSubstring'}, {'node_id_from': 'searchByFullHash', 'node_id_to': 'FidQueryService', 'description': 'calls findFunctionsByFullHash'}, {'node_id_from': 'searchBySpecificHash', 'node_id_to': 'FidQueryService', 'description': 'calls findFunctionsBySpecificHash'}, {'node_id_from': 'searchByFunctionID', 'node_id_to': 'FidQueryService', 'description': 'calls getFunctionByID'}, {'node_id_from': 'openFunctionWindow', 'node_id_to': 'FidQueryService', 'description': 'calls addCloseListener'}, {'node_id_from': 'FidDebugUtils', 'node_id_to': 'searchByName', 'description': ''}, {'node_id_from': 'FidDebugUtils', 'node_id_to': 'searchByFullHash', 'description': ''}, {'node_id_from': 'FidDebugUtils', 'node_id_to': 'searchByDomainPath', 'description': ''}, {'node_id_from': 'FidDebugUtils', 'node_id_to': 'searchBySpecificHash', 'description': ''}, {'node_id_from': 'FidDebugUtils', 'node_id_to': 'searchByFunctionID', 'description': ''}, {'node_id_from': 'FidDebugUtils', 'node_id_to': 'openFunctionWindow', 'description': ''}], 'packages': [{'package_id': 'debugPackage', 'children': ['FidDebugUtils', 'FidService', 'FidQueryService', 'searchByName', 'searchByDomainPath', 'searchByFullHash', 'searchBySpecificHash', 'searchByFunctionID', 'openFunctionWindow'], 'description': 'Debug-related components'}]}",
    "version": "full",
    "text_answer": "FidDebugUtils acts as a bridge between FidService and FidQueryService, where FidService provides general FID functionality while FidQueryService handles specific database queries. All debug utility methods require both services as parameters, with FidQueryService being used for actual database operations (searching, retrieving records) and FidService supporting higher-level functionality.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Python",
    "code": "\nfrom __future__ import annotations\n\nimport warnings\nfrom typing import Any, Dict, List, Mapping, Optional\n\nfrom langchain_core.callbacks import CallbackManagerForLLMRun\nfrom langchain_core.language_models.llms import LLM\nfrom pydantic import BaseModel\n\n\n# Ignoring type because below is valid pydantic code\n# Unexpected keyword argument \"extra\" for \"__init_subclass__\" of \"object\"\nclass Params(BaseModel, extra=\"allow\"):  # type: ignore[call-arg]\n    \"\"\"Parameters for the MLflow AI Gateway LLM.\"\"\"\n\n    temperature: float = 0.0\n    candidate_count: int = 1\n    \"\"\"The number of candidates to return.\"\"\"\n    stop: Optional[List[str]] = None\n    max_tokens: Optional[int] = None\n\n\nclass MlflowAIGateway(LLM):\n    \"\"\"MLflow AI Gateway LLMs.\n\n    To use, you should have the ``mlflow[gateway]`` python package installed.\n    For more information, see https://mlflow.org/docs/latest/gateway/index.html.\n\n    Example:\n        .. code-block:: python\n\n            from langchain_community.llms import MlflowAIGateway\n\n            completions = MlflowAIGateway(\n                gateway_uri=\"<your-mlflow-ai-gateway-uri>\",\n                route=\"<your-mlflow-ai-gateway-completions-route>\",\n                params={\n                    \"temperature\": 0.1\n                }\n            )\n    \"\"\"\n\n    route: str\n    gateway_uri: Optional[str] = None\n    params: Optional[Params] = None\n\n    def __init__(self, **kwargs: Any):\n        warnings.warn(\n            \"`MlflowAIGateway` is deprecated. Use `Mlflow` or `Databricks` instead.\",\n            DeprecationWarning,\n        )\n        try:\n            import mlflow.gateway\n        except ImportError as e:\n            raise ImportError(\n                \"Could not import `mlflow.gateway` module. \"\n                \"Please install it with `pip install mlflow[gateway]`.\"\n            ) from e\n\n        super().__init__(**kwargs)\n        if self.gateway_uri:\n            mlflow.gateway.set_gateway_uri(self.gateway_uri)\n\n    @property\n    def _default_params(self) -> Dict[str, Any]:\n        params: Dict[str, Any] = {\n            \"gateway_uri\": self.gateway_uri,\n            \"route\": self.route,\n            **(self.params.dict() if self.params else {}),\n        }\n        return params\n\n    @property\n    def _identifying_params(self) -> Mapping[str, Any]:\n        return self._default_params\n\n    def _call(\n        self,\n        prompt: str,\n        stop: Optional[List[str]] = None,\n        run_manager: Optional[CallbackManagerForLLMRun] = None,\n        **kwargs: Any,\n    ) -> str:\n        try:\n            import mlflow.gateway\n        except ImportError as e:\n            raise ImportError(\n                \"Could not import `mlflow.gateway` module. \"\n                \"Please install it with `pip install mlflow[gateway]`.\"\n            ) from e\n\n        data: Dict[str, Any] = {\n            \"prompt\": prompt,\n            **(self.params.dict() if self.params else {}),\n        }\n        if s := (stop or (self.params.stop if self.params else None)):\n            data[\"stop\"] = s\n        resp = mlflow.gateway.query(self.route, data=data)\n        return resp[\"candidates\"][0][\"text\"]\n\n    @property\n    def _llm_type(self) -> str:\n        return \"mlflow-ai-gateway\"",
    "repo": "langchain-ai/langchain",
    "path": "./datasets/diagrams-repos/langchain-ai/langchain/libs/community/langchain_community/llms/mlflow_ai_gateway.py",
    "query": "How does the MlflowAIGateway class inherit from the LLM class in langchain_core? What methods and properties does it override or implement?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'LLM', 'node_id': 'LLM', 'description': 'Base LLM class from langchain_core', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MlflowAIGateway', 'node_id': 'MlflowAIGateway', 'description': 'MLflow AI Gateway implementation of LLM', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': '_call', 'node_id': '_call', 'description': 'Core method to execute LLM inference', 'visibility': 'protected', 'return_type': 'str', 'params': '(self, prompt: str, stop: Optional[List[str]], run_manager: Optional[CallbackManagerForLLMRun], **kwargs: Any)', 'source_class_id': 'MlflowAIGateway'}, {'type': 'method', 'name': '_llm_type', 'node_id': '_llm_type', 'description': 'Property that returns LLM type identifier', 'visibility': 'protected', 'return_type': 'str', 'params': '(self)', 'source_class_id': 'MlflowAIGateway'}], 'edges': [{'node_id_from': 'MlflowAIGateway', 'node_id_to': 'LLM', 'description': 'inherits'}, {'node_id_from': 'MlflowAIGateway', 'node_id_to': '_call', 'description': 'implements'}, {'node_id_from': 'MlflowAIGateway', 'node_id_to': '_llm_type', 'description': 'implements'}], 'packages': [{'package_id': 'core_llm', 'children': ['LLM', '_call', '_llm_type'], 'description': 'Core LLM functionality'}]}",
    "version": "minimal",
    "text_answer": "MlflowAIGateway inherits from LLM and implements four key protected methods: _call (for executing LLM inference), _llm_type (returns identifier), _default_params (manages default parameters), and _identifying_params (provides identifying parameters). It also includes custom initialization and configuration through the Params class.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Python",
    "code": "\nfrom __future__ import annotations\n\nimport warnings\nfrom typing import Any, Dict, List, Mapping, Optional\n\nfrom langchain_core.callbacks import CallbackManagerForLLMRun\nfrom langchain_core.language_models.llms import LLM\nfrom pydantic import BaseModel\n\n\n# Ignoring type because below is valid pydantic code\n# Unexpected keyword argument \"extra\" for \"__init_subclass__\" of \"object\"\nclass Params(BaseModel, extra=\"allow\"):  # type: ignore[call-arg]\n    \"\"\"Parameters for the MLflow AI Gateway LLM.\"\"\"\n\n    temperature: float = 0.0\n    candidate_count: int = 1\n    \"\"\"The number of candidates to return.\"\"\"\n    stop: Optional[List[str]] = None\n    max_tokens: Optional[int] = None\n\n\nclass MlflowAIGateway(LLM):\n    \"\"\"MLflow AI Gateway LLMs.\n\n    To use, you should have the ``mlflow[gateway]`` python package installed.\n    For more information, see https://mlflow.org/docs/latest/gateway/index.html.\n\n    Example:\n        .. code-block:: python\n\n            from langchain_community.llms import MlflowAIGateway\n\n            completions = MlflowAIGateway(\n                gateway_uri=\"<your-mlflow-ai-gateway-uri>\",\n                route=\"<your-mlflow-ai-gateway-completions-route>\",\n                params={\n                    \"temperature\": 0.1\n                }\n            )\n    \"\"\"\n\n    route: str\n    gateway_uri: Optional[str] = None\n    params: Optional[Params] = None\n\n    def __init__(self, **kwargs: Any):\n        warnings.warn(\n            \"`MlflowAIGateway` is deprecated. Use `Mlflow` or `Databricks` instead.\",\n            DeprecationWarning,\n        )\n        try:\n            import mlflow.gateway\n        except ImportError as e:\n            raise ImportError(\n                \"Could not import `mlflow.gateway` module. \"\n                \"Please install it with `pip install mlflow[gateway]`.\"\n            ) from e\n\n        super().__init__(**kwargs)\n        if self.gateway_uri:\n            mlflow.gateway.set_gateway_uri(self.gateway_uri)\n\n    @property\n    def _default_params(self) -> Dict[str, Any]:\n        params: Dict[str, Any] = {\n            \"gateway_uri\": self.gateway_uri,\n            \"route\": self.route,\n            **(self.params.dict() if self.params else {}),\n        }\n        return params\n\n    @property\n    def _identifying_params(self) -> Mapping[str, Any]:\n        return self._default_params\n\n    def _call(\n        self,\n        prompt: str,\n        stop: Optional[List[str]] = None,\n        run_manager: Optional[CallbackManagerForLLMRun] = None,\n        **kwargs: Any,\n    ) -> str:\n        try:\n            import mlflow.gateway\n        except ImportError as e:\n            raise ImportError(\n                \"Could not import `mlflow.gateway` module. \"\n                \"Please install it with `pip install mlflow[gateway]`.\"\n            ) from e\n\n        data: Dict[str, Any] = {\n            \"prompt\": prompt,\n            **(self.params.dict() if self.params else {}),\n        }\n        if s := (stop or (self.params.stop if self.params else None)):\n            data[\"stop\"] = s\n        resp = mlflow.gateway.query(self.route, data=data)\n        return resp[\"candidates\"][0][\"text\"]\n\n    @property\n    def _llm_type(self) -> str:\n        return \"mlflow-ai-gateway\"",
    "repo": "langchain-ai/langchain",
    "path": "./datasets/diagrams-repos/langchain-ai/langchain/libs/community/langchain_community/llms/mlflow_ai_gateway.py",
    "query": "How does the MlflowAIGateway class inherit from the LLM class in langchain_core? What methods and properties does it override or implement?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'LLM', 'node_id': 'LLM', 'description': 'Base LLM class from langchain_core', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MlflowAIGateway', 'node_id': 'MlflowAIGateway', 'description': 'MLflow AI Gateway implementation of LLM', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'Params', 'node_id': 'Params', 'description': 'Parameters configuration for MLflow Gateway', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': '_call', 'node_id': '_call', 'description': 'Core method to execute LLM inference', 'visibility': 'protected', 'return_type': 'str', 'params': '(self, prompt: str, stop: Optional[List[str]], run_manager: Optional[CallbackManagerForLLMRun], **kwargs: Any)', 'source_class_id': 'MlflowAIGateway'}, {'type': 'method', 'name': '_llm_type', 'node_id': '_llm_type', 'description': 'Property that returns LLM type identifier', 'visibility': 'protected', 'return_type': 'str', 'params': '(self)', 'source_class_id': 'MlflowAIGateway'}, {'type': 'method', 'name': '_default_params', 'node_id': '_default_params', 'description': 'Property that returns default parameters', 'visibility': 'protected', 'return_type': 'Dict[str, Any]', 'params': '(self)', 'source_class_id': 'MlflowAIGateway'}, {'type': 'method', 'name': '_identifying_params', 'node_id': '_identifying_params', 'description': 'Property that returns identifying parameters', 'visibility': 'protected', 'return_type': 'Mapping[str, Any]', 'params': '(self)', 'source_class_id': 'MlflowAIGateway'}], 'edges': [{'node_id_from': 'MlflowAIGateway', 'node_id_to': 'LLM', 'description': 'inherits'}, {'node_id_from': 'MlflowAIGateway', 'node_id_to': '_call', 'description': 'implements'}, {'node_id_from': 'MlflowAIGateway', 'node_id_to': '_llm_type', 'description': 'implements'}, {'node_id_from': 'MlflowAIGateway', 'node_id_to': '_default_params', 'description': 'implements'}, {'node_id_from': 'MlflowAIGateway', 'node_id_to': '_identifying_params', 'description': 'implements'}, {'node_id_from': 'MlflowAIGateway', 'node_id_to': 'Params', 'description': 'uses'}], 'packages': [{'package_id': 'core_llm', 'children': ['LLM', '_call', '_llm_type', '_default_params', '_identifying_params'], 'description': 'Core LLM functionality'}, {'package_id': 'mlflow_gateway', 'children': ['MlflowAIGateway', 'Params', 'core_llm'], 'description': 'MLflow Gateway implementation'}]}",
    "version": "medium",
    "text_answer": "MlflowAIGateway inherits from LLM and implements four key protected methods: _call (for executing LLM inference), _llm_type (returns identifier), _default_params (manages default parameters), and _identifying_params (provides identifying parameters). It also includes custom initialization and configuration through the Params class.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Python",
    "code": "\nfrom __future__ import annotations\n\nimport warnings\nfrom typing import Any, Dict, List, Mapping, Optional\n\nfrom langchain_core.callbacks import CallbackManagerForLLMRun\nfrom langchain_core.language_models.llms import LLM\nfrom pydantic import BaseModel\n\n\n# Ignoring type because below is valid pydantic code\n# Unexpected keyword argument \"extra\" for \"__init_subclass__\" of \"object\"\nclass Params(BaseModel, extra=\"allow\"):  # type: ignore[call-arg]\n    \"\"\"Parameters for the MLflow AI Gateway LLM.\"\"\"\n\n    temperature: float = 0.0\n    candidate_count: int = 1\n    \"\"\"The number of candidates to return.\"\"\"\n    stop: Optional[List[str]] = None\n    max_tokens: Optional[int] = None\n\n\nclass MlflowAIGateway(LLM):\n    \"\"\"MLflow AI Gateway LLMs.\n\n    To use, you should have the ``mlflow[gateway]`` python package installed.\n    For more information, see https://mlflow.org/docs/latest/gateway/index.html.\n\n    Example:\n        .. code-block:: python\n\n            from langchain_community.llms import MlflowAIGateway\n\n            completions = MlflowAIGateway(\n                gateway_uri=\"<your-mlflow-ai-gateway-uri>\",\n                route=\"<your-mlflow-ai-gateway-completions-route>\",\n                params={\n                    \"temperature\": 0.1\n                }\n            )\n    \"\"\"\n\n    route: str\n    gateway_uri: Optional[str] = None\n    params: Optional[Params] = None\n\n    def __init__(self, **kwargs: Any):\n        warnings.warn(\n            \"`MlflowAIGateway` is deprecated. Use `Mlflow` or `Databricks` instead.\",\n            DeprecationWarning,\n        )\n        try:\n            import mlflow.gateway\n        except ImportError as e:\n            raise ImportError(\n                \"Could not import `mlflow.gateway` module. \"\n                \"Please install it with `pip install mlflow[gateway]`.\"\n            ) from e\n\n        super().__init__(**kwargs)\n        if self.gateway_uri:\n            mlflow.gateway.set_gateway_uri(self.gateway_uri)\n\n    @property\n    def _default_params(self) -> Dict[str, Any]:\n        params: Dict[str, Any] = {\n            \"gateway_uri\": self.gateway_uri,\n            \"route\": self.route,\n            **(self.params.dict() if self.params else {}),\n        }\n        return params\n\n    @property\n    def _identifying_params(self) -> Mapping[str, Any]:\n        return self._default_params\n\n    def _call(\n        self,\n        prompt: str,\n        stop: Optional[List[str]] = None,\n        run_manager: Optional[CallbackManagerForLLMRun] = None,\n        **kwargs: Any,\n    ) -> str:\n        try:\n            import mlflow.gateway\n        except ImportError as e:\n            raise ImportError(\n                \"Could not import `mlflow.gateway` module. \"\n                \"Please install it with `pip install mlflow[gateway]`.\"\n            ) from e\n\n        data: Dict[str, Any] = {\n            \"prompt\": prompt,\n            **(self.params.dict() if self.params else {}),\n        }\n        if s := (stop or (self.params.stop if self.params else None)):\n            data[\"stop\"] = s\n        resp = mlflow.gateway.query(self.route, data=data)\n        return resp[\"candidates\"][0][\"text\"]\n\n    @property\n    def _llm_type(self) -> str:\n        return \"mlflow-ai-gateway\"",
    "repo": "langchain-ai/langchain",
    "path": "./datasets/diagrams-repos/langchain-ai/langchain/libs/community/langchain_community/llms/mlflow_ai_gateway.py",
    "query": "How does the MlflowAIGateway class inherit from the LLM class in langchain_core? What methods and properties does it override or implement?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'LLM', 'node_id': 'LLM', 'description': 'Base LLM class from langchain_core', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MlflowAIGateway', 'node_id': 'MlflowAIGateway', 'description': 'MLflow AI Gateway implementation of LLM', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'Params', 'node_id': 'Params', 'description': 'Parameters configuration for MLflow Gateway', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': '_call', 'node_id': '_call', 'description': 'Core method to execute LLM inference', 'visibility': 'protected', 'return_type': 'str', 'params': '(self, prompt: str, stop: Optional[List[str]], run_manager: Optional[CallbackManagerForLLMRun], **kwargs: Any)', 'source_class_id': 'MlflowAIGateway'}, {'type': 'method', 'name': '_llm_type', 'node_id': '_llm_type', 'description': 'Property that returns LLM type identifier', 'visibility': 'protected', 'return_type': 'str', 'params': '(self)', 'source_class_id': 'MlflowAIGateway'}, {'type': 'method', 'name': '_default_params', 'node_id': '_default_params', 'description': 'Property that returns default parameters', 'visibility': 'protected', 'return_type': 'Dict[str, Any]', 'params': '(self)', 'source_class_id': 'MlflowAIGateway'}, {'type': 'method', 'name': '_identifying_params', 'node_id': '_identifying_params', 'description': 'Property that returns identifying parameters', 'visibility': 'protected', 'return_type': 'Mapping[str, Any]', 'params': '(self)', 'source_class_id': 'MlflowAIGateway'}, {'type': 'field', 'name': 'route', 'node_id': 'route', 'description': 'MLflow Gateway route', 'visibility': 'public', 'return_type': 'str', 'params': None, 'source_class_id': 'MlflowAIGateway'}, {'type': 'field', 'name': 'gateway_uri', 'node_id': 'gateway_uri', 'description': 'MLflow Gateway URI', 'visibility': 'public', 'return_type': 'Optional[str]', 'params': None, 'source_class_id': 'MlflowAIGateway'}, {'type': 'field', 'name': 'params', 'node_id': 'params', 'description': 'Gateway parameters', 'visibility': 'public', 'return_type': 'Optional[Params]', 'params': None, 'source_class_id': 'MlflowAIGateway'}, {'type': 'method', 'name': '__init__', 'node_id': '__init__', 'description': 'Initialize MLflow Gateway', 'visibility': 'public', 'return_type': 'None', 'params': '(self, **kwargs: Any)', 'source_class_id': 'MlflowAIGateway'}], 'edges': [{'node_id_from': 'MlflowAIGateway', 'node_id_to': 'LLM', 'description': 'inherits'}, {'node_id_from': 'MlflowAIGateway', 'node_id_to': '_call', 'description': 'implements'}, {'node_id_from': 'MlflowAIGateway', 'node_id_to': '_llm_type', 'description': 'implements'}, {'node_id_from': 'MlflowAIGateway', 'node_id_to': '_default_params', 'description': 'implements'}, {'node_id_from': 'MlflowAIGateway', 'node_id_to': '_identifying_params', 'description': 'implements'}, {'node_id_from': 'MlflowAIGateway', 'node_id_to': 'Params', 'description': 'uses'}, {'node_id_from': 'MlflowAIGateway', 'node_id_to': 'route', 'description': 'has'}, {'node_id_from': 'MlflowAIGateway', 'node_id_to': 'gateway_uri', 'description': 'has'}, {'node_id_from': 'MlflowAIGateway', 'node_id_to': 'params', 'description': 'has'}, {'node_id_from': 'MlflowAIGateway', 'node_id_to': '__init__', 'description': 'implements'}], 'packages': [{'package_id': 'core_llm', 'children': ['LLM', '_call', '_llm_type', '_default_params', '_identifying_params'], 'description': 'Core LLM functionality'}, {'package_id': 'mlflow_gateway', 'children': ['MlflowAIGateway', 'Params', 'route', 'gateway_uri', 'params', '__init__', 'core_llm'], 'description': 'MLflow Gateway implementation'}]}",
    "version": "full",
    "text_answer": "MlflowAIGateway inherits from LLM and implements four key protected methods: _call (for executing LLM inference), _llm_type (returns identifier), _default_params (manages default parameters), and _identifying_params (provides identifying parameters). It also includes custom initialization and configuration through the Params class.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nrole_module.controller('NamespaceRoleController',\n    ['$scope', '$location', '$window', '$translate', 'toastr', 'AppService', 'UserService', 'AppUtil', 'EnvService',\n        'PermissionService',\n        function ($scope, $location, $window, $translate, toastr, AppService, UserService, AppUtil, EnvService,\n            PermissionService) {\n\n            var params = AppUtil.parseParams($location.$$url);\n            $scope.pageContext = {\n                appId: params.appid,\n                namespaceName: params.namespaceName\n            };\n\n            $scope.modifyRoleSubmitBtnDisabled = false;\n            $scope.ReleaseRoleSubmitBtnDisabled = false;\n\n            $scope.releaseRoleWidgetId = 'releaseRoleWidgetId';\n            $scope.modifyRoleWidgetId = 'modifyRoleWidgetId';\n\n            $scope.modifyRoleSelectedEnv = \"\";\n            $scope.releaseRoleSelectedEnv = \"\";\n\n            PermissionService.init_app_namespace_permission($scope.pageContext.appId, $scope.pageContext.namespaceName)\n                .then(function (result) {\n\n                }, function (result) {\n                    toastr.warning(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.InitNamespacePermissionError'));\n                });\n\n            PermissionService.has_assign_user_permission($scope.pageContext.appId)\n                .then(function (result) {\n                    $scope.hasAssignUserPermission = result.hasPermission;\n                }, function (reslt) {\n\n                });\n\n            EnvService.find_all_envs()\n                .then(function (result) {\n                    $scope.envs = result;\n                    $scope.envRolesAssignedUsers = {};\n                    for (var iLoop = 0; iLoop < result.length; iLoop++) {\n                        var env = result[iLoop];\n                        PermissionService.get_namespace_env_role_users($scope.pageContext.appId, env, $scope.pageContext.namespaceName)\n                            .then(function (result) {\n                                $scope.envRolesAssignedUsers[result.env] = result;\n                            }, function (result) {\n                                toastr.error(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.GetEnvGrantUserError', { env }));\n                            });\n                    }\n                });\n\n            PermissionService.get_namespace_role_users($scope.pageContext.appId,\n                $scope.pageContext.namespaceName)\n                .then(function (result) {\n                    $scope.rolesAssignedUsers = result;\n                }, function (result) {\n                    toastr.error(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.GetGrantUserError'));\n                });\n\n            $scope.assignRoleToUser = function (roleType) {\n                if (\"ReleaseNamespace\" === roleType) {\n                    var user = $('.' + $scope.releaseRoleWidgetId).select2('data')[0];\n                    if (!user) {\n                        toastr.warning($translate.instant('Namespace.Role.PleaseChooseUser'));\n                        return;\n                    }\n                    $scope.ReleaseRoleSubmitBtnDisabled = true;\n                    var toAssignReleaseNamespaceRoleUser = user.id;\n\n                    var assignReleaseNamespaceRoleFunc = $scope.releaseRoleSelectedEnv === \"\" ?\n                        PermissionService.assign_release_namespace_role :\n                        function (appId, namespaceName, user) {\n                            return PermissionService.assign_release_namespace_env_role(appId, $scope.releaseRoleSelectedEnv, namespaceName, user);\n                        };\n\n                    assignReleaseNamespaceRoleFunc($scope.pageContext.appId,\n                        $scope.pageContext.namespaceName,\n                        toAssignReleaseNamespaceRoleUser)\n                        .then(function (result) {\n                            toastr.success($translate.instant('Namespace.Role.Added'));\n                            $scope.ReleaseRoleSubmitBtnDisabled = false;\n                            if ($scope.releaseRoleSelectedEnv === \"\") {\n                                $scope.rolesAssignedUsers.releaseRoleUsers.push(\n                                    { userId: toAssignReleaseNamespaceRoleUser });\n                            } else {\n                                $scope.envRolesAssignedUsers[$scope.releaseRoleSelectedEnv].releaseRoleUsers.push(\n                                    { userId: toAssignReleaseNamespaceRoleUser });\n                            }\n\n                            $('.' + $scope.releaseRoleWidgetId).select2(\"val\", \"\");\n                            $scope.releaseRoleSelectedEnv = \"\";\n                        }, function (result) {\n                            $scope.ReleaseRoleSubmitBtnDisabled = false;\n                            toastr.error(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.AddFailed'));\n                        });\n                } else {\n                    var user = $('.' + $scope.modifyRoleWidgetId).select2('data')[0];\n                    if (!user) {\n                        toastr.warning($translate.instant('Namespace.Role.PleaseChooseUser'));\n                        return;\n                    }\n                    $scope.modifyRoleSubmitBtnDisabled = true;\n                    var toAssignModifyNamespaceRoleUser = user.id;\n\n                    var assignModifyNamespaceRoleFunc = $scope.modifyRoleSelectedEnv === \"\" ?\n                        PermissionService.assign_modify_namespace_role :\n                        function (appId, namespaceName, user) {\n                            return PermissionService.assign_modify_namespace_env_role(appId, $scope.modifyRoleSelectedEnv, namespaceName, user);\n                        };\n\n                    assignModifyNamespaceRoleFunc($scope.pageContext.appId,\n                        $scope.pageContext.namespaceName,\n                        toAssignModifyNamespaceRoleUser)\n                        .then(function (result) {\n                            toastr.success($translate.instant('Namespace.Role.Added'));\n                            $scope.modifyRoleSubmitBtnDisabled = false;\n                            if ($scope.modifyRoleSelectedEnv === \"\") {\n                                $scope.rolesAssignedUsers.modifyRoleUsers.push(\n                                    { userId: toAssignModifyNamespaceRoleUser });\n                            } else {\n                                $scope.envRolesAssignedUsers[$scope.modifyRoleSelectedEnv].modifyRoleUsers.push(\n                                    { userId: toAssignModifyNamespaceRoleUser });\n                            }\n                            $('.' + $scope.modifyRoleWidgetId).select2(\"val\", \"\");\n                            $scope.modifyRoleSelectedEnv = \"\";\n                        }, function (result) {\n                            $scope.modifyRoleSubmitBtnDisabled = false;\n                            toastr.error(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.AddFailed'));\n                        });\n                }\n            };\n\n            $scope.removeUserRole = function (roleType, user, env) {\n                if (\"ReleaseNamespace\" === roleType) {\n                    var removeReleaseNamespaceRoleFunc = !env ?\n                        PermissionService.remove_release_namespace_role :\n                        function (appId, namespaceName, user) {\n                            return PermissionService.remove_release_namespace_env_role(appId, env, namespaceName, user);\n                        };\n\n                    removeReleaseNamespaceRoleFunc($scope.pageContext.appId,\n                        $scope.pageContext.namespaceName,\n                        user)\n                        .then(function (result) {\n                            toastr.success($translate.instant('Namespace.Role.Deleted'));\n                            if (!env) {\n                                removeUserFromList($scope.rolesAssignedUsers.releaseRoleUsers, user);\n                            } else {\n                                removeUserFromList($scope.envRolesAssignedUsers[env].releaseRoleUsers, user);\n                            }\n                        }, function (result) {\n                            toastr.error(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.DeleteFailed'));\n                        });\n                } else {\n                    var removeModifyNamespaceRoleFunc = !env ?\n                        PermissionService.remove_modify_namespace_role :\n                        function (appId, namespaceName, user) {\n                            return PermissionService.remove_modify_namespace_env_role(appId, env, namespaceName, user);\n                        };\n\n                    removeModifyNamespaceRoleFunc($scope.pageContext.appId,\n                        $scope.pageContext.namespaceName,\n                        user)\n                        .then(function (result) {\n                            toastr.success($translate.instant('Namespace.Role.Deleted'));\n                            if (!env) {\n                                removeUserFromList($scope.rolesAssignedUsers.modifyRoleUsers, user);\n                            } else {\n                                removeUserFromList($scope.envRolesAssignedUsers[env].modifyRoleUsers, user);\n                            }\n                        }, function (result) {\n                            toastr.error(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.DeleteFailed'));\n                        });\n                }\n            };\n\n            function removeUserFromList(list, user) {\n                var index = 0;\n                for (var i = 0; i < list.length; i++) {\n                    if (list[i].userId === user) {\n                        index = i;\n                        break;\n                    }\n                }\n                list.splice(index, 1);\n            }\n\n\n\n        }]);",
    "repo": "apolloconfig/apollo",
    "path": "./datasets/diagrams-repos/apolloconfig/apollo/apollo-portal/src/main/resources/static/scripts/controller/role/NamespaceRoleController.js",
    "query": "How are errors managed in service calls within the controller?",
    "diagram": "{'nodes': [{'type': 'method', 'name': 'errorMsg', 'node_id': 'errorMsg', 'description': 'Utility function to format error messages', 'visibility': 'public', 'return_type': 'string', 'params': 'result', 'source_class_id': 'AppUtil'}, {'type': 'class', 'name': 'toastr', 'node_id': 'toastr', 'description': 'Service for displaying notifications', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'AppUtil', 'node_id': 'AppUtil', 'description': 'Utility service containing error handling methods', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'errorMsg', 'node_id_to': 'toastr', 'description': 'Formats error before display'}, {'node_id_from': 'AppUtil', 'node_id_to': 'errorMsg', 'description': 'contains'}], 'packages': [{'package_id': 'errorHandling', 'children': ['errorMsg', 'toastr', 'AppUtil'], 'description': 'Core error handling components'}]}",
    "version": "minimal",
    "text_answer": "The controller manages errors in service calls through a combination of AppUtil.errorMsg for formatting error messages and toastr service for displaying notifications. Each service call includes error handling in its promise's rejection handler, where errors are formatted and displayed with appropriate translations.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nrole_module.controller('NamespaceRoleController',\n    ['$scope', '$location', '$window', '$translate', 'toastr', 'AppService', 'UserService', 'AppUtil', 'EnvService',\n        'PermissionService',\n        function ($scope, $location, $window, $translate, toastr, AppService, UserService, AppUtil, EnvService,\n            PermissionService) {\n\n            var params = AppUtil.parseParams($location.$$url);\n            $scope.pageContext = {\n                appId: params.appid,\n                namespaceName: params.namespaceName\n            };\n\n            $scope.modifyRoleSubmitBtnDisabled = false;\n            $scope.ReleaseRoleSubmitBtnDisabled = false;\n\n            $scope.releaseRoleWidgetId = 'releaseRoleWidgetId';\n            $scope.modifyRoleWidgetId = 'modifyRoleWidgetId';\n\n            $scope.modifyRoleSelectedEnv = \"\";\n            $scope.releaseRoleSelectedEnv = \"\";\n\n            PermissionService.init_app_namespace_permission($scope.pageContext.appId, $scope.pageContext.namespaceName)\n                .then(function (result) {\n\n                }, function (result) {\n                    toastr.warning(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.InitNamespacePermissionError'));\n                });\n\n            PermissionService.has_assign_user_permission($scope.pageContext.appId)\n                .then(function (result) {\n                    $scope.hasAssignUserPermission = result.hasPermission;\n                }, function (reslt) {\n\n                });\n\n            EnvService.find_all_envs()\n                .then(function (result) {\n                    $scope.envs = result;\n                    $scope.envRolesAssignedUsers = {};\n                    for (var iLoop = 0; iLoop < result.length; iLoop++) {\n                        var env = result[iLoop];\n                        PermissionService.get_namespace_env_role_users($scope.pageContext.appId, env, $scope.pageContext.namespaceName)\n                            .then(function (result) {\n                                $scope.envRolesAssignedUsers[result.env] = result;\n                            }, function (result) {\n                                toastr.error(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.GetEnvGrantUserError', { env }));\n                            });\n                    }\n                });\n\n            PermissionService.get_namespace_role_users($scope.pageContext.appId,\n                $scope.pageContext.namespaceName)\n                .then(function (result) {\n                    $scope.rolesAssignedUsers = result;\n                }, function (result) {\n                    toastr.error(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.GetGrantUserError'));\n                });\n\n            $scope.assignRoleToUser = function (roleType) {\n                if (\"ReleaseNamespace\" === roleType) {\n                    var user = $('.' + $scope.releaseRoleWidgetId).select2('data')[0];\n                    if (!user) {\n                        toastr.warning($translate.instant('Namespace.Role.PleaseChooseUser'));\n                        return;\n                    }\n                    $scope.ReleaseRoleSubmitBtnDisabled = true;\n                    var toAssignReleaseNamespaceRoleUser = user.id;\n\n                    var assignReleaseNamespaceRoleFunc = $scope.releaseRoleSelectedEnv === \"\" ?\n                        PermissionService.assign_release_namespace_role :\n                        function (appId, namespaceName, user) {\n                            return PermissionService.assign_release_namespace_env_role(appId, $scope.releaseRoleSelectedEnv, namespaceName, user);\n                        };\n\n                    assignReleaseNamespaceRoleFunc($scope.pageContext.appId,\n                        $scope.pageContext.namespaceName,\n                        toAssignReleaseNamespaceRoleUser)\n                        .then(function (result) {\n                            toastr.success($translate.instant('Namespace.Role.Added'));\n                            $scope.ReleaseRoleSubmitBtnDisabled = false;\n                            if ($scope.releaseRoleSelectedEnv === \"\") {\n                                $scope.rolesAssignedUsers.releaseRoleUsers.push(\n                                    { userId: toAssignReleaseNamespaceRoleUser });\n                            } else {\n                                $scope.envRolesAssignedUsers[$scope.releaseRoleSelectedEnv].releaseRoleUsers.push(\n                                    { userId: toAssignReleaseNamespaceRoleUser });\n                            }\n\n                            $('.' + $scope.releaseRoleWidgetId).select2(\"val\", \"\");\n                            $scope.releaseRoleSelectedEnv = \"\";\n                        }, function (result) {\n                            $scope.ReleaseRoleSubmitBtnDisabled = false;\n                            toastr.error(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.AddFailed'));\n                        });\n                } else {\n                    var user = $('.' + $scope.modifyRoleWidgetId).select2('data')[0];\n                    if (!user) {\n                        toastr.warning($translate.instant('Namespace.Role.PleaseChooseUser'));\n                        return;\n                    }\n                    $scope.modifyRoleSubmitBtnDisabled = true;\n                    var toAssignModifyNamespaceRoleUser = user.id;\n\n                    var assignModifyNamespaceRoleFunc = $scope.modifyRoleSelectedEnv === \"\" ?\n                        PermissionService.assign_modify_namespace_role :\n                        function (appId, namespaceName, user) {\n                            return PermissionService.assign_modify_namespace_env_role(appId, $scope.modifyRoleSelectedEnv, namespaceName, user);\n                        };\n\n                    assignModifyNamespaceRoleFunc($scope.pageContext.appId,\n                        $scope.pageContext.namespaceName,\n                        toAssignModifyNamespaceRoleUser)\n                        .then(function (result) {\n                            toastr.success($translate.instant('Namespace.Role.Added'));\n                            $scope.modifyRoleSubmitBtnDisabled = false;\n                            if ($scope.modifyRoleSelectedEnv === \"\") {\n                                $scope.rolesAssignedUsers.modifyRoleUsers.push(\n                                    { userId: toAssignModifyNamespaceRoleUser });\n                            } else {\n                                $scope.envRolesAssignedUsers[$scope.modifyRoleSelectedEnv].modifyRoleUsers.push(\n                                    { userId: toAssignModifyNamespaceRoleUser });\n                            }\n                            $('.' + $scope.modifyRoleWidgetId).select2(\"val\", \"\");\n                            $scope.modifyRoleSelectedEnv = \"\";\n                        }, function (result) {\n                            $scope.modifyRoleSubmitBtnDisabled = false;\n                            toastr.error(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.AddFailed'));\n                        });\n                }\n            };\n\n            $scope.removeUserRole = function (roleType, user, env) {\n                if (\"ReleaseNamespace\" === roleType) {\n                    var removeReleaseNamespaceRoleFunc = !env ?\n                        PermissionService.remove_release_namespace_role :\n                        function (appId, namespaceName, user) {\n                            return PermissionService.remove_release_namespace_env_role(appId, env, namespaceName, user);\n                        };\n\n                    removeReleaseNamespaceRoleFunc($scope.pageContext.appId,\n                        $scope.pageContext.namespaceName,\n                        user)\n                        .then(function (result) {\n                            toastr.success($translate.instant('Namespace.Role.Deleted'));\n                            if (!env) {\n                                removeUserFromList($scope.rolesAssignedUsers.releaseRoleUsers, user);\n                            } else {\n                                removeUserFromList($scope.envRolesAssignedUsers[env].releaseRoleUsers, user);\n                            }\n                        }, function (result) {\n                            toastr.error(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.DeleteFailed'));\n                        });\n                } else {\n                    var removeModifyNamespaceRoleFunc = !env ?\n                        PermissionService.remove_modify_namespace_role :\n                        function (appId, namespaceName, user) {\n                            return PermissionService.remove_modify_namespace_env_role(appId, env, namespaceName, user);\n                        };\n\n                    removeModifyNamespaceRoleFunc($scope.pageContext.appId,\n                        $scope.pageContext.namespaceName,\n                        user)\n                        .then(function (result) {\n                            toastr.success($translate.instant('Namespace.Role.Deleted'));\n                            if (!env) {\n                                removeUserFromList($scope.rolesAssignedUsers.modifyRoleUsers, user);\n                            } else {\n                                removeUserFromList($scope.envRolesAssignedUsers[env].modifyRoleUsers, user);\n                            }\n                        }, function (result) {\n                            toastr.error(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.DeleteFailed'));\n                        });\n                }\n            };\n\n            function removeUserFromList(list, user) {\n                var index = 0;\n                for (var i = 0; i < list.length; i++) {\n                    if (list[i].userId === user) {\n                        index = i;\n                        break;\n                    }\n                }\n                list.splice(index, 1);\n            }\n\n\n\n        }]);",
    "repo": "apolloconfig/apollo",
    "path": "./datasets/diagrams-repos/apolloconfig/apollo/apollo-portal/src/main/resources/static/scripts/controller/role/NamespaceRoleController.js",
    "query": "How are errors managed in service calls within the controller?",
    "diagram": "{'nodes': [{'type': 'method', 'name': 'errorMsg', 'node_id': 'errorMsg', 'description': 'Utility function to format error messages', 'visibility': 'public', 'return_type': 'string', 'params': 'result', 'source_class_id': 'AppUtil'}, {'type': 'class', 'name': 'toastr', 'node_id': 'toastr', 'description': 'Service for displaying notifications', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'translate', 'node_id': 'translate', 'description': 'Service for internationalization', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'AppUtil', 'node_id': 'AppUtil', 'description': 'Utility service containing error handling methods', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'errorMsg', 'node_id_to': 'toastr', 'description': 'Formats error before display'}, {'node_id_from': 'translate', 'node_id_to': 'toastr', 'description': 'Provides translated error messages'}, {'node_id_from': 'AppUtil', 'node_id_to': 'errorMsg', 'description': 'contains'}], 'packages': [{'package_id': 'errorHandling', 'children': ['errorMsg', 'toastr', 'translate', 'AppUtil'], 'description': 'Error handling and notification system'}]}",
    "version": "medium",
    "text_answer": "The controller manages errors in service calls through a combination of AppUtil.errorMsg for formatting error messages and toastr service for displaying notifications. Each service call includes error handling in its promise's rejection handler, where errors are formatted and displayed with appropriate translations.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nrole_module.controller('NamespaceRoleController',\n    ['$scope', '$location', '$window', '$translate', 'toastr', 'AppService', 'UserService', 'AppUtil', 'EnvService',\n        'PermissionService',\n        function ($scope, $location, $window, $translate, toastr, AppService, UserService, AppUtil, EnvService,\n            PermissionService) {\n\n            var params = AppUtil.parseParams($location.$$url);\n            $scope.pageContext = {\n                appId: params.appid,\n                namespaceName: params.namespaceName\n            };\n\n            $scope.modifyRoleSubmitBtnDisabled = false;\n            $scope.ReleaseRoleSubmitBtnDisabled = false;\n\n            $scope.releaseRoleWidgetId = 'releaseRoleWidgetId';\n            $scope.modifyRoleWidgetId = 'modifyRoleWidgetId';\n\n            $scope.modifyRoleSelectedEnv = \"\";\n            $scope.releaseRoleSelectedEnv = \"\";\n\n            PermissionService.init_app_namespace_permission($scope.pageContext.appId, $scope.pageContext.namespaceName)\n                .then(function (result) {\n\n                }, function (result) {\n                    toastr.warning(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.InitNamespacePermissionError'));\n                });\n\n            PermissionService.has_assign_user_permission($scope.pageContext.appId)\n                .then(function (result) {\n                    $scope.hasAssignUserPermission = result.hasPermission;\n                }, function (reslt) {\n\n                });\n\n            EnvService.find_all_envs()\n                .then(function (result) {\n                    $scope.envs = result;\n                    $scope.envRolesAssignedUsers = {};\n                    for (var iLoop = 0; iLoop < result.length; iLoop++) {\n                        var env = result[iLoop];\n                        PermissionService.get_namespace_env_role_users($scope.pageContext.appId, env, $scope.pageContext.namespaceName)\n                            .then(function (result) {\n                                $scope.envRolesAssignedUsers[result.env] = result;\n                            }, function (result) {\n                                toastr.error(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.GetEnvGrantUserError', { env }));\n                            });\n                    }\n                });\n\n            PermissionService.get_namespace_role_users($scope.pageContext.appId,\n                $scope.pageContext.namespaceName)\n                .then(function (result) {\n                    $scope.rolesAssignedUsers = result;\n                }, function (result) {\n                    toastr.error(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.GetGrantUserError'));\n                });\n\n            $scope.assignRoleToUser = function (roleType) {\n                if (\"ReleaseNamespace\" === roleType) {\n                    var user = $('.' + $scope.releaseRoleWidgetId).select2('data')[0];\n                    if (!user) {\n                        toastr.warning($translate.instant('Namespace.Role.PleaseChooseUser'));\n                        return;\n                    }\n                    $scope.ReleaseRoleSubmitBtnDisabled = true;\n                    var toAssignReleaseNamespaceRoleUser = user.id;\n\n                    var assignReleaseNamespaceRoleFunc = $scope.releaseRoleSelectedEnv === \"\" ?\n                        PermissionService.assign_release_namespace_role :\n                        function (appId, namespaceName, user) {\n                            return PermissionService.assign_release_namespace_env_role(appId, $scope.releaseRoleSelectedEnv, namespaceName, user);\n                        };\n\n                    assignReleaseNamespaceRoleFunc($scope.pageContext.appId,\n                        $scope.pageContext.namespaceName,\n                        toAssignReleaseNamespaceRoleUser)\n                        .then(function (result) {\n                            toastr.success($translate.instant('Namespace.Role.Added'));\n                            $scope.ReleaseRoleSubmitBtnDisabled = false;\n                            if ($scope.releaseRoleSelectedEnv === \"\") {\n                                $scope.rolesAssignedUsers.releaseRoleUsers.push(\n                                    { userId: toAssignReleaseNamespaceRoleUser });\n                            } else {\n                                $scope.envRolesAssignedUsers[$scope.releaseRoleSelectedEnv].releaseRoleUsers.push(\n                                    { userId: toAssignReleaseNamespaceRoleUser });\n                            }\n\n                            $('.' + $scope.releaseRoleWidgetId).select2(\"val\", \"\");\n                            $scope.releaseRoleSelectedEnv = \"\";\n                        }, function (result) {\n                            $scope.ReleaseRoleSubmitBtnDisabled = false;\n                            toastr.error(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.AddFailed'));\n                        });\n                } else {\n                    var user = $('.' + $scope.modifyRoleWidgetId).select2('data')[0];\n                    if (!user) {\n                        toastr.warning($translate.instant('Namespace.Role.PleaseChooseUser'));\n                        return;\n                    }\n                    $scope.modifyRoleSubmitBtnDisabled = true;\n                    var toAssignModifyNamespaceRoleUser = user.id;\n\n                    var assignModifyNamespaceRoleFunc = $scope.modifyRoleSelectedEnv === \"\" ?\n                        PermissionService.assign_modify_namespace_role :\n                        function (appId, namespaceName, user) {\n                            return PermissionService.assign_modify_namespace_env_role(appId, $scope.modifyRoleSelectedEnv, namespaceName, user);\n                        };\n\n                    assignModifyNamespaceRoleFunc($scope.pageContext.appId,\n                        $scope.pageContext.namespaceName,\n                        toAssignModifyNamespaceRoleUser)\n                        .then(function (result) {\n                            toastr.success($translate.instant('Namespace.Role.Added'));\n                            $scope.modifyRoleSubmitBtnDisabled = false;\n                            if ($scope.modifyRoleSelectedEnv === \"\") {\n                                $scope.rolesAssignedUsers.modifyRoleUsers.push(\n                                    { userId: toAssignModifyNamespaceRoleUser });\n                            } else {\n                                $scope.envRolesAssignedUsers[$scope.modifyRoleSelectedEnv].modifyRoleUsers.push(\n                                    { userId: toAssignModifyNamespaceRoleUser });\n                            }\n                            $('.' + $scope.modifyRoleWidgetId).select2(\"val\", \"\");\n                            $scope.modifyRoleSelectedEnv = \"\";\n                        }, function (result) {\n                            $scope.modifyRoleSubmitBtnDisabled = false;\n                            toastr.error(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.AddFailed'));\n                        });\n                }\n            };\n\n            $scope.removeUserRole = function (roleType, user, env) {\n                if (\"ReleaseNamespace\" === roleType) {\n                    var removeReleaseNamespaceRoleFunc = !env ?\n                        PermissionService.remove_release_namespace_role :\n                        function (appId, namespaceName, user) {\n                            return PermissionService.remove_release_namespace_env_role(appId, env, namespaceName, user);\n                        };\n\n                    removeReleaseNamespaceRoleFunc($scope.pageContext.appId,\n                        $scope.pageContext.namespaceName,\n                        user)\n                        .then(function (result) {\n                            toastr.success($translate.instant('Namespace.Role.Deleted'));\n                            if (!env) {\n                                removeUserFromList($scope.rolesAssignedUsers.releaseRoleUsers, user);\n                            } else {\n                                removeUserFromList($scope.envRolesAssignedUsers[env].releaseRoleUsers, user);\n                            }\n                        }, function (result) {\n                            toastr.error(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.DeleteFailed'));\n                        });\n                } else {\n                    var removeModifyNamespaceRoleFunc = !env ?\n                        PermissionService.remove_modify_namespace_role :\n                        function (appId, namespaceName, user) {\n                            return PermissionService.remove_modify_namespace_env_role(appId, env, namespaceName, user);\n                        };\n\n                    removeModifyNamespaceRoleFunc($scope.pageContext.appId,\n                        $scope.pageContext.namespaceName,\n                        user)\n                        .then(function (result) {\n                            toastr.success($translate.instant('Namespace.Role.Deleted'));\n                            if (!env) {\n                                removeUserFromList($scope.rolesAssignedUsers.modifyRoleUsers, user);\n                            } else {\n                                removeUserFromList($scope.envRolesAssignedUsers[env].modifyRoleUsers, user);\n                            }\n                        }, function (result) {\n                            toastr.error(AppUtil.errorMsg(result), $translate.instant('Namespace.Role.DeleteFailed'));\n                        });\n                }\n            };\n\n            function removeUserFromList(list, user) {\n                var index = 0;\n                for (var i = 0; i < list.length; i++) {\n                    if (list[i].userId === user) {\n                        index = i;\n                        break;\n                    }\n                }\n                list.splice(index, 1);\n            }\n\n\n\n        }]);",
    "repo": "apolloconfig/apollo",
    "path": "./datasets/diagrams-repos/apolloconfig/apollo/apollo-portal/src/main/resources/static/scripts/controller/role/NamespaceRoleController.js",
    "query": "How are errors managed in service calls within the controller?",
    "diagram": "{'nodes': [{'type': 'method', 'name': 'errorMsg', 'node_id': 'errorMsg', 'description': 'Utility function to format error messages', 'visibility': 'public', 'return_type': 'string', 'params': 'result', 'source_class_id': 'AppUtil'}, {'type': 'class', 'name': 'toastr', 'node_id': 'toastr', 'description': 'Service for displaying notifications', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'translate', 'node_id': 'translate', 'description': 'Service for internationalization', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'AppUtil', 'node_id': 'AppUtil', 'description': 'Utility service containing error handling methods', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'init_app_namespace_permission', 'node_id': 'init_app_namespace_permission', 'description': 'Initialize namespace permissions', 'visibility': 'public', 'return_type': 'Promise', 'params': 'appId, namespaceName', 'source_class_id': None}, {'type': 'function', 'name': 'find_all_envs', 'node_id': 'find_all_envs', 'description': 'Retrieve all environments', 'visibility': 'public', 'return_type': 'Promise', 'params': '', 'source_class_id': None}, {'type': 'function', 'name': 'get_namespace_env_role_users', 'node_id': 'get_namespace_env_role_users', 'description': 'Get namespace environment role users', 'visibility': 'public', 'return_type': 'Promise', 'params': 'appId, env, namespaceName', 'source_class_id': None}], 'edges': [{'node_id_from': 'errorMsg', 'node_id_to': 'toastr', 'description': 'Formats error before display'}, {'node_id_from': 'translate', 'node_id_to': 'toastr', 'description': 'Provides translated error messages'}, {'node_id_from': 'AppUtil', 'node_id_to': 'errorMsg', 'description': 'contains'}, {'node_id_from': 'init_app_namespace_permission', 'node_id_to': 'errorMsg', 'description': 'Handles initialization errors'}, {'node_id_from': 'find_all_envs', 'node_id_to': 'errorMsg', 'description': 'Handles environment retrieval errors'}, {'node_id_from': 'get_namespace_env_role_users', 'node_id_to': 'errorMsg', 'description': 'Handles user role errors'}], 'packages': [{'package_id': 'errorHandling', 'children': ['errorMsg', 'toastr', 'translate', 'AppUtil'], 'description': 'Error handling and notification system'}, {'package_id': 'serviceOperations', 'children': ['init_app_namespace_permission', 'find_all_envs', 'get_namespace_env_role_users'], 'description': 'Service operations that may produce errors'}]}",
    "version": "full",
    "text_answer": "The controller manages errors in service calls through a combination of AppUtil.errorMsg for formatting error messages and toastr service for displaying notifications. Each service call includes error handling in its promise's rejection handler, where errors are formatted and displayed with appropriate translations.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Python",
    "code": "\nimport re\n\nfrom .utils import object_attr_string_repr\n\n\nclass Enum:\n    \"\"\"Representation of enums info.\"\"\"\n\n    def __init__(self, name='', type_name='',\n                 items=None, header=None):\n        \"\"\"Constructs Enum info.\"\"\"\n        self.name = name\n        self.type_name = type_name\n        self.items = items if items is not None else []\n        self.header = header\n\n    @property\n    def name_text(self):\n        \"\"\"Returns a enum's name.\"\"\"\n        return object_attr_string_repr(self.name)\n\n    @property\n    def type_name_text(self):\n        \"\"\"Returns a textual representation of the typedefed name.\"\"\"\n        return object_attr_string_repr(self.type_name)\n\n    @property\n    def items_list(self):\n        \"\"\"Returns list of enum's parameters.\"\"\"\n        return self.items if self.items is not None else []\n\n    @property\n    def header_text(self):\n        \"\"\"Returns a textual representation of header file.\"\"\"\n        return object_attr_string_repr(self.header)\n\n    def __repr__(self):\n        return '{}({!r}, {!r})'.format(\n            self.__class__.__name__, self.name_text, self.items)\n\n    def repr_json(self):\n        return self.__dict__\n\n    def __eq__(self, other):\n        return (self.name == other.name and\n                self.type_name == other.type_name and\n                self.items == other.items)\n\n    def __ne__(self, other):\n        return not self == other\n\n\nclass EnumItem:\n    def __init__(self, name, value):\n        \"\"\"Constructs enum's item info.\"\"\"\n        self.name = name\n        self.value = value\n\n    def __repr__(self):\n        return '{!r} = {!r}'.format(self.name, self.value)\n\n    def repr_json(self):\n        return self.__dict__\n\n    def __eq__(self, other):\n        return (self.name == other.name and\n                self.value == other.value)\n\n    def __ne__(self, other):\n        return not self == other\n\n\ndef get_all_enums(text):\n    \"\"\"Gets all enums from text.\"\"\"\n    return re.findall(\n        r'(?:\\btypedef)?\\s*enum\\s*(?:[\\w]+)?\\s*\\{[^{}]+\\}[\\w\\s,\\*]*;',\n        text\n    )\n\n\ndef parse_enum(enum_str, hfile):\n    \"\"\"Returns enum object.\"\"\"\n    found = re.search(\n        r'(\\btypedef\\b)?\\s*enum\\s*([\\w]+)?(?::\\s*\\w*)?\\s*\\{(.+)\\}([\\w\\s,\\*]*);',\n        enum_str\n    )\n    if not found:\n        return Enum()\n    name = found.group(2)\n    enum_type_name = found.group(4).strip()\n    if not found.group(1):\n        enum_type_name = ''\n\n    enum_item = found.group(3).strip()\n    if not enum_item:\n        return Enum(name, enum_type_name, [], hfile)\n    if ',' == enum_item[-1]:\n        enum_item = enum_item[:-1]\n    enum_item = enum_item.split(', ')\n\n    items_list = []\n    value = 0\n    for item in enum_item:\n        if '=' in item:\n            explicit_value = re.search(\n                r'=\\s*([\\+\\-]?(?:0x[a-fA-F0-9]+|\\d+))', item)\n            item = re.sub(r'\\s*=.*', '', item)\n            if explicit_value is not None:\n                if 'x' in explicit_value.group(1):\n                    value = int(explicit_value.group(1), 16)\n                else:\n                    value = int(explicit_value.group(1), 10)\n                items_list.append(EnumItem(item.strip(), value))\n            else:\n                items_list.append(EnumItem(item.strip(), 'x'))\n        else:\n            items_list.append(EnumItem(item.strip(), value))\n        value = value + 1\n    return Enum(name, enum_type_name, items_list, hfile)",
    "repo": "avast/retdec",
    "path": "./datasets/diagrams-repos/avast/retdec/scripts/type_extractor/type_extractor/parse_enums.py",
    "query": "How does the `parse_enum` function process an enum string to create an `Enum` object?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'parse_enum', 'node_id': 'parse_enum', 'description': 'Parses enum string and creates Enum object', 'visibility': 'public', 'return_type': 'Enum', 'params': 'enum_str, hfile', 'source_class_id': None}, {'type': 'class', 'name': 'Enum', 'node_id': 'Enum', 'description': 'Represents enum information with name, type and items', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'EnumItem', 'node_id': 'EnumItem', 'description': 'Represents single enum item with name and value', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'parse_enum', 'node_id_to': 'Enum', 'description': 'creates'}, {'node_id_from': 'parse_enum', 'node_id_to': 'EnumItem', 'description': 'creates items'}], 'packages': [{'package_id': 'enumProcessing', 'children': ['parse_enum', 'Enum', 'EnumItem'], 'description': 'Core enum processing functionality'}]}",
    "version": "minimal",
    "text_answer": "The parse_enum function processes an enum string by first using regex to extract the enum structure, then handles typedef if present, splits the enum items, calculates their values (supporting both decimal and hex), and finally creates an Enum object containing EnumItem objects for each enum member.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Python",
    "code": "\nimport re\n\nfrom .utils import object_attr_string_repr\n\n\nclass Enum:\n    \"\"\"Representation of enums info.\"\"\"\n\n    def __init__(self, name='', type_name='',\n                 items=None, header=None):\n        \"\"\"Constructs Enum info.\"\"\"\n        self.name = name\n        self.type_name = type_name\n        self.items = items if items is not None else []\n        self.header = header\n\n    @property\n    def name_text(self):\n        \"\"\"Returns a enum's name.\"\"\"\n        return object_attr_string_repr(self.name)\n\n    @property\n    def type_name_text(self):\n        \"\"\"Returns a textual representation of the typedefed name.\"\"\"\n        return object_attr_string_repr(self.type_name)\n\n    @property\n    def items_list(self):\n        \"\"\"Returns list of enum's parameters.\"\"\"\n        return self.items if self.items is not None else []\n\n    @property\n    def header_text(self):\n        \"\"\"Returns a textual representation of header file.\"\"\"\n        return object_attr_string_repr(self.header)\n\n    def __repr__(self):\n        return '{}({!r}, {!r})'.format(\n            self.__class__.__name__, self.name_text, self.items)\n\n    def repr_json(self):\n        return self.__dict__\n\n    def __eq__(self, other):\n        return (self.name == other.name and\n                self.type_name == other.type_name and\n                self.items == other.items)\n\n    def __ne__(self, other):\n        return not self == other\n\n\nclass EnumItem:\n    def __init__(self, name, value):\n        \"\"\"Constructs enum's item info.\"\"\"\n        self.name = name\n        self.value = value\n\n    def __repr__(self):\n        return '{!r} = {!r}'.format(self.name, self.value)\n\n    def repr_json(self):\n        return self.__dict__\n\n    def __eq__(self, other):\n        return (self.name == other.name and\n                self.value == other.value)\n\n    def __ne__(self, other):\n        return not self == other\n\n\ndef get_all_enums(text):\n    \"\"\"Gets all enums from text.\"\"\"\n    return re.findall(\n        r'(?:\\btypedef)?\\s*enum\\s*(?:[\\w]+)?\\s*\\{[^{}]+\\}[\\w\\s,\\*]*;',\n        text\n    )\n\n\ndef parse_enum(enum_str, hfile):\n    \"\"\"Returns enum object.\"\"\"\n    found = re.search(\n        r'(\\btypedef\\b)?\\s*enum\\s*([\\w]+)?(?::\\s*\\w*)?\\s*\\{(.+)\\}([\\w\\s,\\*]*);',\n        enum_str\n    )\n    if not found:\n        return Enum()\n    name = found.group(2)\n    enum_type_name = found.group(4).strip()\n    if not found.group(1):\n        enum_type_name = ''\n\n    enum_item = found.group(3).strip()\n    if not enum_item:\n        return Enum(name, enum_type_name, [], hfile)\n    if ',' == enum_item[-1]:\n        enum_item = enum_item[:-1]\n    enum_item = enum_item.split(', ')\n\n    items_list = []\n    value = 0\n    for item in enum_item:\n        if '=' in item:\n            explicit_value = re.search(\n                r'=\\s*([\\+\\-]?(?:0x[a-fA-F0-9]+|\\d+))', item)\n            item = re.sub(r'\\s*=.*', '', item)\n            if explicit_value is not None:\n                if 'x' in explicit_value.group(1):\n                    value = int(explicit_value.group(1), 16)\n                else:\n                    value = int(explicit_value.group(1), 10)\n                items_list.append(EnumItem(item.strip(), value))\n            else:\n                items_list.append(EnumItem(item.strip(), 'x'))\n        else:\n            items_list.append(EnumItem(item.strip(), value))\n        value = value + 1\n    return Enum(name, enum_type_name, items_list, hfile)",
    "repo": "avast/retdec",
    "path": "./datasets/diagrams-repos/avast/retdec/scripts/type_extractor/type_extractor/parse_enums.py",
    "query": "How does the `parse_enum` function process an enum string to create an `Enum` object?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'parse_enum', 'node_id': 'parse_enum', 'description': 'Parses enum string and creates Enum object', 'visibility': 'public', 'return_type': 'Enum', 'params': 'enum_str, hfile', 'source_class_id': None}, {'type': 'class', 'name': 'Enum', 'node_id': 'Enum', 'description': 'Represents enum information with name, type and items', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'EnumItem', 'node_id': 'EnumItem', 'description': 'Represents single enum item with name and value', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'regexParsing', 'node_id': 'regexParsing', 'description': 'Regular expression parsing for enum structure', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'valueCalculation', 'node_id': 'valueCalculation', 'description': 'Calculation of enum values (decimal/hex)', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'parse_enum', 'node_id_to': 'Enum', 'description': 'creates'}, {'node_id_from': 'parse_enum', 'node_id_to': 'EnumItem', 'description': 'creates items'}, {'node_id_from': 'parse_enum', 'node_id_to': 'regexParsing', 'description': 'uses'}, {'node_id_from': 'parse_enum', 'node_id_to': 'valueCalculation', 'description': 'uses'}], 'packages': [{'package_id': 'enumProcessing', 'children': ['parse_enum', 'Enum', 'EnumItem'], 'description': 'Core enum processing functionality'}, {'package_id': 'parsingUtils', 'children': ['regexParsing', 'valueCalculation'], 'description': 'Utility functions for parsing'}]}",
    "version": "medium",
    "text_answer": "The parse_enum function processes an enum string by first using regex to extract the enum structure, then handles typedef if present, splits the enum items, calculates their values (supporting both decimal and hex), and finally creates an Enum object containing EnumItem objects for each enum member.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Python",
    "code": "\nimport re\n\nfrom .utils import object_attr_string_repr\n\n\nclass Enum:\n    \"\"\"Representation of enums info.\"\"\"\n\n    def __init__(self, name='', type_name='',\n                 items=None, header=None):\n        \"\"\"Constructs Enum info.\"\"\"\n        self.name = name\n        self.type_name = type_name\n        self.items = items if items is not None else []\n        self.header = header\n\n    @property\n    def name_text(self):\n        \"\"\"Returns a enum's name.\"\"\"\n        return object_attr_string_repr(self.name)\n\n    @property\n    def type_name_text(self):\n        \"\"\"Returns a textual representation of the typedefed name.\"\"\"\n        return object_attr_string_repr(self.type_name)\n\n    @property\n    def items_list(self):\n        \"\"\"Returns list of enum's parameters.\"\"\"\n        return self.items if self.items is not None else []\n\n    @property\n    def header_text(self):\n        \"\"\"Returns a textual representation of header file.\"\"\"\n        return object_attr_string_repr(self.header)\n\n    def __repr__(self):\n        return '{}({!r}, {!r})'.format(\n            self.__class__.__name__, self.name_text, self.items)\n\n    def repr_json(self):\n        return self.__dict__\n\n    def __eq__(self, other):\n        return (self.name == other.name and\n                self.type_name == other.type_name and\n                self.items == other.items)\n\n    def __ne__(self, other):\n        return not self == other\n\n\nclass EnumItem:\n    def __init__(self, name, value):\n        \"\"\"Constructs enum's item info.\"\"\"\n        self.name = name\n        self.value = value\n\n    def __repr__(self):\n        return '{!r} = {!r}'.format(self.name, self.value)\n\n    def repr_json(self):\n        return self.__dict__\n\n    def __eq__(self, other):\n        return (self.name == other.name and\n                self.value == other.value)\n\n    def __ne__(self, other):\n        return not self == other\n\n\ndef get_all_enums(text):\n    \"\"\"Gets all enums from text.\"\"\"\n    return re.findall(\n        r'(?:\\btypedef)?\\s*enum\\s*(?:[\\w]+)?\\s*\\{[^{}]+\\}[\\w\\s,\\*]*;',\n        text\n    )\n\n\ndef parse_enum(enum_str, hfile):\n    \"\"\"Returns enum object.\"\"\"\n    found = re.search(\n        r'(\\btypedef\\b)?\\s*enum\\s*([\\w]+)?(?::\\s*\\w*)?\\s*\\{(.+)\\}([\\w\\s,\\*]*);',\n        enum_str\n    )\n    if not found:\n        return Enum()\n    name = found.group(2)\n    enum_type_name = found.group(4).strip()\n    if not found.group(1):\n        enum_type_name = ''\n\n    enum_item = found.group(3).strip()\n    if not enum_item:\n        return Enum(name, enum_type_name, [], hfile)\n    if ',' == enum_item[-1]:\n        enum_item = enum_item[:-1]\n    enum_item = enum_item.split(', ')\n\n    items_list = []\n    value = 0\n    for item in enum_item:\n        if '=' in item:\n            explicit_value = re.search(\n                r'=\\s*([\\+\\-]?(?:0x[a-fA-F0-9]+|\\d+))', item)\n            item = re.sub(r'\\s*=.*', '', item)\n            if explicit_value is not None:\n                if 'x' in explicit_value.group(1):\n                    value = int(explicit_value.group(1), 16)\n                else:\n                    value = int(explicit_value.group(1), 10)\n                items_list.append(EnumItem(item.strip(), value))\n            else:\n                items_list.append(EnumItem(item.strip(), 'x'))\n        else:\n            items_list.append(EnumItem(item.strip(), value))\n        value = value + 1\n    return Enum(name, enum_type_name, items_list, hfile)",
    "repo": "avast/retdec",
    "path": "./datasets/diagrams-repos/avast/retdec/scripts/type_extractor/type_extractor/parse_enums.py",
    "query": "How does the `parse_enum` function process an enum string to create an `Enum` object?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'parse_enum', 'node_id': 'parse_enum', 'description': 'Parses enum string and creates Enum object', 'visibility': 'public', 'return_type': 'Enum', 'params': 'enum_str, hfile', 'source_class_id': None}, {'type': 'class', 'name': 'Enum', 'node_id': 'Enum', 'description': 'Represents enum information with name, type and items', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': '__init__', 'node_id': 'EnumInit', 'description': 'Initializes Enum object', 'visibility': 'public', 'return_type': None, 'params': 'name, type_name, items, header', 'source_class_id': 'Enum'}, {'type': 'class', 'name': 'EnumItem', 'node_id': 'EnumItem', 'description': 'Represents single enum item with name and value', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': '__init__', 'node_id': 'EnumItemInit', 'description': 'Initializes EnumItem object', 'visibility': 'public', 'return_type': None, 'params': 'name, value', 'source_class_id': 'EnumItem'}, {'type': 'entity', 'name': 'regexParsing', 'node_id': 'regexParsing', 'description': 'Regular expression parsing for enum structure', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'valueCalculation', 'node_id': 'valueCalculation', 'description': 'Calculation of enum values (decimal/hex)', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'typedefHandling', 'node_id': 'typedefHandling', 'description': 'Processing of typedef keyword in enums', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'itemSplitting', 'node_id': 'itemSplitting', 'description': 'Splitting enum items and handling commas', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'parse_enum', 'node_id_to': 'Enum', 'description': 'creates'}, {'node_id_from': 'parse_enum', 'node_id_to': 'EnumItem', 'description': 'creates items'}, {'node_id_from': 'parse_enum', 'node_id_to': 'regexParsing', 'description': 'uses'}, {'node_id_from': 'parse_enum', 'node_id_to': 'valueCalculation', 'description': 'uses'}, {'node_id_from': 'parse_enum', 'node_id_to': 'typedefHandling', 'description': 'uses'}, {'node_id_from': 'parse_enum', 'node_id_to': 'itemSplitting', 'description': 'uses'}, {'node_id_from': 'parse_enum', 'node_id_to': 'EnumInit', 'description': 'calls'}, {'node_id_from': 'parse_enum', 'node_id_to': 'EnumItemInit', 'description': 'calls'}, {'node_id_from': 'Enum', 'node_id_to': 'EnumInit', 'description': ''}, {'node_id_from': 'EnumItem', 'node_id_to': 'EnumItemInit', 'description': ''}], 'packages': [{'package_id': 'enumProcessing', 'children': ['parse_enum', 'Enum', 'EnumItem', 'EnumInit', 'EnumItemInit'], 'description': 'Core enum processing functionality'}, {'package_id': 'parsingUtils', 'children': ['regexParsing', 'valueCalculation', 'typedefHandling', 'itemSplitting'], 'description': 'Utility functions for parsing'}]}",
    "version": "full",
    "text_answer": "The parse_enum function processes an enum string by first using regex to extract the enum structure, then handles typedef if present, splits the enum items, calculates their values (supporting both decimal and hex), and finally creates an Enum object containing EnumItem objects for each enum member.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nexport default function transformer(file, api, options) {\n  const j = api.jscodeshift;\n  const root = j(file.source);\n  const printOptions = options.printOptions;\n\n  root\n    .find(j.ImportDeclaration)\n    .filter(({ node }) => {\n      const sourceVal = node.source.value;\n\n      return [\n        '@mui/joy', // Process only Joy UI components\n        '@mui/joy/Avatar', // Filter default imports of components other than `Avatar`\n      ].includes(sourceVal);\n    })\n    .forEach((path) => {\n      path.node.specifiers.forEach((elementNode) => {\n        if (\n          (elementNode.type === 'ImportSpecifier' && elementNode.imported?.name === 'Avatar') ||\n          elementNode.type === 'ImportDefaultSpecifier'\n        ) {\n          // Process only Joy `Avatar` component\n          root.findJSXElements(elementNode.local.name).forEach((elementPath) => {\n            if (elementPath.node.type !== 'JSXElement') {\n              return;\n            }\n\n            const slotPropsAttributeNode = elementPath.node.openingElement.attributes.find(\n              (attributeNode) =>\n                attributeNode.type === 'JSXAttribute' &&\n                attributeNode.name.name === 'slotProps' &&\n                attributeNode.value.expression?.type === 'ObjectExpression',\n            );\n            const newAttributeNodes = [];\n            elementPath.node.openingElement.attributes.forEach((attributeNode) => {\n              if (attributeNode.type !== 'JSXAttribute') {\n                return;\n              }\n\n              if (attributeNode.name.name !== 'imgProps') {\n                newAttributeNodes.push(attributeNode);\n                return;\n              }\n\n              const val = attributeNode.value;\n              if (!val?.expression) {\n                return;\n              }\n\n              if (slotPropsAttributeNode) {\n                const imgObjInSlotProps = slotPropsAttributeNode.value.expression.properties.find(\n                  (propNode) =>\n                    propNode.key.name === 'img' && propNode.value.type === 'ObjectExpression',\n                );\n                if (imgObjInSlotProps) {\n                  const newProperties = [\n                    ...imgObjInSlotProps.value.properties,\n                    ...attributeNode.value.expression.properties,\n                  ];\n                  imgObjInSlotProps.value.properties = newProperties;\n                } else {\n                  slotPropsAttributeNode.value.expression.properties.push(\n                    j.objectProperty(j.identifier('img'), attributeNode.value),\n                  );\n                }\n              } else {\n                newAttributeNodes.push(\n                  j.jsxAttribute(\n                    j.jsxIdentifier('slotProps'),\n                    j.jsxExpressionContainer(\n                      j.objectExpression([\n                        j.objectProperty(j.identifier('img'), attributeNode.value.expression),\n                      ]),\n                    ),\n                  ),\n                );\n              }\n            });\n            elementPath.node.openingElement.attributes = newAttributeNodes;\n          });\n        }\n      });\n    });\n\n  const transformed = root.findJSXElements();\n\n  return transformed.toSource(printOptions);\n}",
    "repo": "mui/material-ui",
    "path": "./datasets/diagrams-repos/mui/material-ui/packages/mui-codemod/src/v5.0.0/joy-avatar-remove-imgProps.js",
    "query": "How does the code filter and process import statements related to '@mui/joy' and 'Avatar'?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'transformer', 'node_id': 'transformer', 'description': 'Main transformation function that processes import statements', 'visibility': 'public', 'return_type': 'string', 'params': 'file, api, options', 'source_class_id': None}, {'type': 'entity', 'name': 'findImports', 'node_id': 'findImports', 'description': 'Finds and filters import declarations for Joy UI components', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'processAvatarImports', 'node_id': 'processAvatarImports', 'description': 'Processes Avatar-specific imports and their usages', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'transformer', 'node_id_to': 'findImports', 'description': 'initiates import search'}, {'node_id_from': 'findImports', 'node_id_to': 'processAvatarImports', 'description': 'processes found Avatar imports'}], 'packages': [{'package_id': 'importProcessing', 'children': ['findImports', 'processAvatarImports'], 'description': 'Import statement processing logic'}]}",
    "version": "minimal",
    "text_answer": "The code filters import statements by searching for '@mui/joy' and '@mui/joy/Avatar' imports, then processes only the Avatar component by transforming its JSX attributes, specifically converting imgProps to the new slotProps format.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nexport default function transformer(file, api, options) {\n  const j = api.jscodeshift;\n  const root = j(file.source);\n  const printOptions = options.printOptions;\n\n  root\n    .find(j.ImportDeclaration)\n    .filter(({ node }) => {\n      const sourceVal = node.source.value;\n\n      return [\n        '@mui/joy', // Process only Joy UI components\n        '@mui/joy/Avatar', // Filter default imports of components other than `Avatar`\n      ].includes(sourceVal);\n    })\n    .forEach((path) => {\n      path.node.specifiers.forEach((elementNode) => {\n        if (\n          (elementNode.type === 'ImportSpecifier' && elementNode.imported?.name === 'Avatar') ||\n          elementNode.type === 'ImportDefaultSpecifier'\n        ) {\n          // Process only Joy `Avatar` component\n          root.findJSXElements(elementNode.local.name).forEach((elementPath) => {\n            if (elementPath.node.type !== 'JSXElement') {\n              return;\n            }\n\n            const slotPropsAttributeNode = elementPath.node.openingElement.attributes.find(\n              (attributeNode) =>\n                attributeNode.type === 'JSXAttribute' &&\n                attributeNode.name.name === 'slotProps' &&\n                attributeNode.value.expression?.type === 'ObjectExpression',\n            );\n            const newAttributeNodes = [];\n            elementPath.node.openingElement.attributes.forEach((attributeNode) => {\n              if (attributeNode.type !== 'JSXAttribute') {\n                return;\n              }\n\n              if (attributeNode.name.name !== 'imgProps') {\n                newAttributeNodes.push(attributeNode);\n                return;\n              }\n\n              const val = attributeNode.value;\n              if (!val?.expression) {\n                return;\n              }\n\n              if (slotPropsAttributeNode) {\n                const imgObjInSlotProps = slotPropsAttributeNode.value.expression.properties.find(\n                  (propNode) =>\n                    propNode.key.name === 'img' && propNode.value.type === 'ObjectExpression',\n                );\n                if (imgObjInSlotProps) {\n                  const newProperties = [\n                    ...imgObjInSlotProps.value.properties,\n                    ...attributeNode.value.expression.properties,\n                  ];\n                  imgObjInSlotProps.value.properties = newProperties;\n                } else {\n                  slotPropsAttributeNode.value.expression.properties.push(\n                    j.objectProperty(j.identifier('img'), attributeNode.value),\n                  );\n                }\n              } else {\n                newAttributeNodes.push(\n                  j.jsxAttribute(\n                    j.jsxIdentifier('slotProps'),\n                    j.jsxExpressionContainer(\n                      j.objectExpression([\n                        j.objectProperty(j.identifier('img'), attributeNode.value.expression),\n                      ]),\n                    ),\n                  ),\n                );\n              }\n            });\n            elementPath.node.openingElement.attributes = newAttributeNodes;\n          });\n        }\n      });\n    });\n\n  const transformed = root.findJSXElements();\n\n  return transformed.toSource(printOptions);\n}",
    "repo": "mui/material-ui",
    "path": "./datasets/diagrams-repos/mui/material-ui/packages/mui-codemod/src/v5.0.0/joy-avatar-remove-imgProps.js",
    "query": "How does the code filter and process import statements related to '@mui/joy' and 'Avatar'?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'transformer', 'node_id': 'transformer', 'description': 'Main transformation function that processes import statements', 'visibility': 'public', 'return_type': 'string', 'params': 'file, api, options', 'source_class_id': None}, {'type': 'entity', 'name': 'findImports', 'node_id': 'findImports', 'description': 'Finds and filters import declarations for Joy UI components', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'processAvatarImports', 'node_id': 'processAvatarImports', 'description': 'Processes Avatar-specific imports and their usages', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'importFilter', 'node_id': 'importFilter', 'description': 'Filter condition for Joy UI imports', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'avatarElementProcessor', 'node_id': 'avatarElementProcessor', 'description': 'Processes JSX elements for Avatar component', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'transformer', 'node_id_to': 'findImports', 'description': 'initiates import search'}, {'node_id_from': 'findImports', 'node_id_to': 'importFilter', 'description': 'uses filter condition'}, {'node_id_from': 'findImports', 'node_id_to': 'processAvatarImports', 'description': 'processes found Avatar imports'}, {'node_id_from': 'processAvatarImports', 'node_id_to': 'avatarElementProcessor', 'description': 'processes JSX elements'}], 'packages': [{'package_id': 'importProcessing', 'children': ['findImports', 'processAvatarImports', 'importFilter'], 'description': 'Import statement processing logic'}]}",
    "version": "medium",
    "text_answer": "The code filters import statements by searching for '@mui/joy' and '@mui/joy/Avatar' imports, then processes only the Avatar component by transforming its JSX attributes, specifically converting imgProps to the new slotProps format.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nexport default function transformer(file, api, options) {\n  const j = api.jscodeshift;\n  const root = j(file.source);\n  const printOptions = options.printOptions;\n\n  root\n    .find(j.ImportDeclaration)\n    .filter(({ node }) => {\n      const sourceVal = node.source.value;\n\n      return [\n        '@mui/joy', // Process only Joy UI components\n        '@mui/joy/Avatar', // Filter default imports of components other than `Avatar`\n      ].includes(sourceVal);\n    })\n    .forEach((path) => {\n      path.node.specifiers.forEach((elementNode) => {\n        if (\n          (elementNode.type === 'ImportSpecifier' && elementNode.imported?.name === 'Avatar') ||\n          elementNode.type === 'ImportDefaultSpecifier'\n        ) {\n          // Process only Joy `Avatar` component\n          root.findJSXElements(elementNode.local.name).forEach((elementPath) => {\n            if (elementPath.node.type !== 'JSXElement') {\n              return;\n            }\n\n            const slotPropsAttributeNode = elementPath.node.openingElement.attributes.find(\n              (attributeNode) =>\n                attributeNode.type === 'JSXAttribute' &&\n                attributeNode.name.name === 'slotProps' &&\n                attributeNode.value.expression?.type === 'ObjectExpression',\n            );\n            const newAttributeNodes = [];\n            elementPath.node.openingElement.attributes.forEach((attributeNode) => {\n              if (attributeNode.type !== 'JSXAttribute') {\n                return;\n              }\n\n              if (attributeNode.name.name !== 'imgProps') {\n                newAttributeNodes.push(attributeNode);\n                return;\n              }\n\n              const val = attributeNode.value;\n              if (!val?.expression) {\n                return;\n              }\n\n              if (slotPropsAttributeNode) {\n                const imgObjInSlotProps = slotPropsAttributeNode.value.expression.properties.find(\n                  (propNode) =>\n                    propNode.key.name === 'img' && propNode.value.type === 'ObjectExpression',\n                );\n                if (imgObjInSlotProps) {\n                  const newProperties = [\n                    ...imgObjInSlotProps.value.properties,\n                    ...attributeNode.value.expression.properties,\n                  ];\n                  imgObjInSlotProps.value.properties = newProperties;\n                } else {\n                  slotPropsAttributeNode.value.expression.properties.push(\n                    j.objectProperty(j.identifier('img'), attributeNode.value),\n                  );\n                }\n              } else {\n                newAttributeNodes.push(\n                  j.jsxAttribute(\n                    j.jsxIdentifier('slotProps'),\n                    j.jsxExpressionContainer(\n                      j.objectExpression([\n                        j.objectProperty(j.identifier('img'), attributeNode.value.expression),\n                      ]),\n                    ),\n                  ),\n                );\n              }\n            });\n            elementPath.node.openingElement.attributes = newAttributeNodes;\n          });\n        }\n      });\n    });\n\n  const transformed = root.findJSXElements();\n\n  return transformed.toSource(printOptions);\n}",
    "repo": "mui/material-ui",
    "path": "./datasets/diagrams-repos/mui/material-ui/packages/mui-codemod/src/v5.0.0/joy-avatar-remove-imgProps.js",
    "query": "How does the code filter and process import statements related to '@mui/joy' and 'Avatar'?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'transformer', 'node_id': 'transformer', 'description': 'Main transformation function that processes import statements', 'visibility': 'public', 'return_type': 'string', 'params': 'file, api, options', 'source_class_id': None}, {'type': 'entity', 'name': 'findImports', 'node_id': 'findImports', 'description': 'Finds and filters import declarations for Joy UI components', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'processAvatarImports', 'node_id': 'processAvatarImports', 'description': 'Processes Avatar-specific imports and their usages', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'importFilter', 'node_id': 'importFilter', 'description': 'Filter condition for Joy UI imports', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'avatarElementProcessor', 'node_id': 'avatarElementProcessor', 'description': 'Processes JSX elements for Avatar component', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'processSlotProps', 'node_id': 'processSlotProps', 'description': 'Processes slotProps attribute in Avatar JSX', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'processImgProps', 'node_id': 'processImgProps', 'description': 'Processes imgProps attribute in Avatar JSX', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'attributeProcessor', 'node_id': 'attributeProcessor', 'description': 'Processes JSX attributes', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'transformer', 'node_id_to': 'findImports', 'description': 'initiates import search'}, {'node_id_from': 'findImports', 'node_id_to': 'importFilter', 'description': 'uses filter condition'}, {'node_id_from': 'findImports', 'node_id_to': 'processAvatarImports', 'description': 'processes found Avatar imports'}, {'node_id_from': 'processAvatarImports', 'node_id_to': 'avatarElementProcessor', 'description': 'processes JSX elements'}, {'node_id_from': 'avatarElementProcessor', 'node_id_to': 'processSlotProps', 'description': 'handles slotProps'}, {'node_id_from': 'avatarElementProcessor', 'node_id_to': 'processImgProps', 'description': 'handles imgProps'}, {'node_id_from': 'processSlotProps', 'node_id_to': 'attributeProcessor', 'description': 'processes attributes'}, {'node_id_from': 'processImgProps', 'node_id_to': 'attributeProcessor', 'description': 'processes attributes'}], 'packages': [{'package_id': 'importProcessing', 'children': ['findImports', 'processAvatarImports', 'importFilter'], 'description': 'Import statement processing logic'}, {'package_id': 'jsxProcessing', 'children': ['avatarElementProcessor', 'processSlotProps', 'processImgProps', 'attributeProcessor'], 'description': 'JSX element processing logic'}]}",
    "version": "full",
    "text_answer": "The code filters import statements by searching for '@mui/joy' and '@mui/joy/Avatar' imports, then processes only the Avatar component by transforming its JSX attributes, specifically converting imgProps to the new slotProps format.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.nd4j.linalg.api.ops.impl.reduce.bp;\n\nimport lombok.NoArgsConstructor;\nimport org.nd4j.autodiff.samediff.SDVariable;\nimport org.nd4j.autodiff.samediff.SameDiff;\nimport org.nd4j.linalg.api.ndarray.INDArray;\n\n\n@NoArgsConstructor\npublic class VarianceBp extends BaseReductionBp {\n\n    private boolean biasCorrected;\n\n    public VarianceBp(SameDiff sameDiff, SDVariable origInput, SDVariable gradAtOutput, boolean biasCorrected, boolean keepDims, long... dimensions) {\n        super(sameDiff, origInput, gradAtOutput, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n\n    }\n\n    public VarianceBp(SameDiff sameDiff, SDVariable origInput1, SDVariable origInput2, SDVariable gradAtOutput, boolean keepDims, boolean biasCorrected, long... dimensions) {\n        super(sameDiff, origInput1, origInput2, gradAtOutput, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n\n    }\n\n    public VarianceBp(INDArray origInput, INDArray gradAtOutput, INDArray output, boolean biasCorrected, boolean keepDims, long... dimensions){\n        super(origInput, gradAtOutput, output, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n\n    }\n\n    public VarianceBp(INDArray origInput1, INDArray origInput2, INDArray gradAtOutput, INDArray output, boolean keepDims, boolean biasCorrected, long... dimensions) {\n        super(origInput1, origInput2, gradAtOutput, output, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n\n    }\n\n    public VarianceBp(INDArray origInput1, INDArray origInput2, INDArray gradAtOutput, INDArray output1, INDArray output2, boolean keepDims, boolean biasCorrected, long... dimensions) {\n        super(origInput1, origInput2, gradAtOutput, output1, output2, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n\n    }\n\n    public VarianceBp(INDArray origInput, INDArray gradAtOutput, INDArray output, boolean keepDims, INDArray dimensions, boolean biasCorrected) {\n        super(origInput, gradAtOutput, output, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n\n    }\n\n    public VarianceBp(SameDiff sameDiff, SDVariable origInput, SDVariable gradAtOutput, boolean keepDims, SDVariable dimensions, boolean biasCorrected) {\n        super(sameDiff, origInput, gradAtOutput, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n    }\n\n    public VarianceBp(SameDiff sameDiff, SDVariable arg, SDVariable dLdVar, boolean keepDims, boolean biasCorrected, SDVariable dimensions) {\n        super(sameDiff,arg,dLdVar,keepDims,dimensions);\n        addBArgument(biasCorrected);\n    }\n\n    @Override\n    protected void addArgs() {\n        super.addArgs();\n        addBArgument(biasCorrected);\n    }\n\n    public VarianceBp(boolean biasCorrected) {\n        this.biasCorrected = biasCorrected;\n    }\n\n    @Override\n    public String opName() {\n        return \"reduce_variance_bp\";\n    }\n}",
    "repo": "deeplearning4j/deeplearning4j",
    "path": "./datasets/diagrams-repos/deeplearning4j/deeplearning4j/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/api/ops/impl/reduce/bp/VarianceBp.java",
    "query": "Can you illustrate the different constructor overloads in the `VarianceBp` class and their parameters?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'VarianceBp', 'node_id': 'VarianceBp', 'description': 'Class for backpropagation of variance reduction operation', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'biasCorrected', 'node_id': 'biasCorrected', 'description': 'Flag indicating if variance should be bias corrected', 'visibility': 'private', 'return_type': 'boolean', 'params': None, 'source_class_id': 'VarianceBp'}, {'type': 'method', 'name': 'VarianceBp', 'node_id': 'VarianceBp_Constructor1', 'description': 'Basic constructor with bias correction parameter', 'visibility': 'public', 'return_type': None, 'params': '(boolean biasCorrected)', 'source_class_id': 'VarianceBp'}, {'type': 'method', 'name': 'VarianceBp', 'node_id': 'VarianceBp_Constructor2', 'description': 'Constructor for SameDiff with single input', 'visibility': 'public', 'return_type': None, 'params': '(SameDiff sameDiff, SDVariable origInput, SDVariable gradAtOutput, boolean biasCorrected, boolean keepDims, long... dimensions)', 'source_class_id': 'VarianceBp'}], 'edges': [{'node_id_from': 'VarianceBp_Constructor1', 'node_id_to': 'biasCorrected', 'description': 'initializes'}, {'node_id_from': 'VarianceBp_Constructor2', 'node_id_to': 'biasCorrected', 'description': 'initializes'}, {'node_id_from': 'VarianceBp', 'node_id_to': 'biasCorrected', 'description': ''}, {'node_id_from': 'VarianceBp', 'node_id_to': 'VarianceBp_Constructor1', 'description': ''}, {'node_id_from': 'VarianceBp', 'node_id_to': 'VarianceBp_Constructor2', 'description': ''}], 'packages': [{'package_id': 'constructors', 'children': ['VarianceBp_Constructor1', 'VarianceBp_Constructor2'], 'description': 'Basic constructors of VarianceBp class'}]}",
    "version": "minimal",
    "text_answer": "The VarianceBp class has 9 constructor overloads that can be grouped into three categories: basic constructor with just biasCorrected parameter, SameDiff-based constructors for automatic differentiation (4 variants), and INDArray-based constructors for direct array operations (4 variants). All constructors initialize the biasCorrected field and most include parameters for keepDims and dimensions specification.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.nd4j.linalg.api.ops.impl.reduce.bp;\n\nimport lombok.NoArgsConstructor;\nimport org.nd4j.autodiff.samediff.SDVariable;\nimport org.nd4j.autodiff.samediff.SameDiff;\nimport org.nd4j.linalg.api.ndarray.INDArray;\n\n\n@NoArgsConstructor\npublic class VarianceBp extends BaseReductionBp {\n\n    private boolean biasCorrected;\n\n    public VarianceBp(SameDiff sameDiff, SDVariable origInput, SDVariable gradAtOutput, boolean biasCorrected, boolean keepDims, long... dimensions) {\n        super(sameDiff, origInput, gradAtOutput, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n\n    }\n\n    public VarianceBp(SameDiff sameDiff, SDVariable origInput1, SDVariable origInput2, SDVariable gradAtOutput, boolean keepDims, boolean biasCorrected, long... dimensions) {\n        super(sameDiff, origInput1, origInput2, gradAtOutput, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n\n    }\n\n    public VarianceBp(INDArray origInput, INDArray gradAtOutput, INDArray output, boolean biasCorrected, boolean keepDims, long... dimensions){\n        super(origInput, gradAtOutput, output, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n\n    }\n\n    public VarianceBp(INDArray origInput1, INDArray origInput2, INDArray gradAtOutput, INDArray output, boolean keepDims, boolean biasCorrected, long... dimensions) {\n        super(origInput1, origInput2, gradAtOutput, output, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n\n    }\n\n    public VarianceBp(INDArray origInput1, INDArray origInput2, INDArray gradAtOutput, INDArray output1, INDArray output2, boolean keepDims, boolean biasCorrected, long... dimensions) {\n        super(origInput1, origInput2, gradAtOutput, output1, output2, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n\n    }\n\n    public VarianceBp(INDArray origInput, INDArray gradAtOutput, INDArray output, boolean keepDims, INDArray dimensions, boolean biasCorrected) {\n        super(origInput, gradAtOutput, output, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n\n    }\n\n    public VarianceBp(SameDiff sameDiff, SDVariable origInput, SDVariable gradAtOutput, boolean keepDims, SDVariable dimensions, boolean biasCorrected) {\n        super(sameDiff, origInput, gradAtOutput, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n    }\n\n    public VarianceBp(SameDiff sameDiff, SDVariable arg, SDVariable dLdVar, boolean keepDims, boolean biasCorrected, SDVariable dimensions) {\n        super(sameDiff,arg,dLdVar,keepDims,dimensions);\n        addBArgument(biasCorrected);\n    }\n\n    @Override\n    protected void addArgs() {\n        super.addArgs();\n        addBArgument(biasCorrected);\n    }\n\n    public VarianceBp(boolean biasCorrected) {\n        this.biasCorrected = biasCorrected;\n    }\n\n    @Override\n    public String opName() {\n        return \"reduce_variance_bp\";\n    }\n}",
    "repo": "deeplearning4j/deeplearning4j",
    "path": "./datasets/diagrams-repos/deeplearning4j/deeplearning4j/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/api/ops/impl/reduce/bp/VarianceBp.java",
    "query": "Can you illustrate the different constructor overloads in the `VarianceBp` class and their parameters?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'VarianceBp', 'node_id': 'VarianceBp', 'description': 'Class for backpropagation of variance reduction operation', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'biasCorrected', 'node_id': 'biasCorrected', 'description': 'Flag indicating if variance should be bias corrected', 'visibility': 'private', 'return_type': 'boolean', 'params': None, 'source_class_id': 'VarianceBp'}, {'type': 'method', 'name': 'VarianceBp', 'node_id': 'VarianceBp_Constructor1', 'description': 'Basic constructor with bias correction parameter', 'visibility': 'public', 'return_type': None, 'params': '(boolean biasCorrected)', 'source_class_id': 'VarianceBp'}, {'type': 'method', 'name': 'VarianceBp', 'node_id': 'VarianceBp_Constructor2', 'description': 'Constructor for SameDiff with single input', 'visibility': 'public', 'return_type': None, 'params': '(SameDiff sameDiff, SDVariable origInput, SDVariable gradAtOutput, boolean biasCorrected, boolean keepDims, long... dimensions)', 'source_class_id': 'VarianceBp'}, {'type': 'method', 'name': 'VarianceBp', 'node_id': 'VarianceBp_Constructor3', 'description': 'Constructor for SameDiff with two inputs', 'visibility': 'public', 'return_type': None, 'params': '(SameDiff sameDiff, SDVariable origInput1, SDVariable origInput2, SDVariable gradAtOutput, boolean keepDims, boolean biasCorrected, long... dimensions)', 'source_class_id': 'VarianceBp'}, {'type': 'method', 'name': 'VarianceBp', 'node_id': 'VarianceBp_Constructor4', 'description': 'Constructor for INDArray with single input', 'visibility': 'public', 'return_type': None, 'params': '(INDArray origInput, INDArray gradAtOutput, INDArray output, boolean biasCorrected, boolean keepDims, long... dimensions)', 'source_class_id': 'VarianceBp'}], 'edges': [{'node_id_from': 'VarianceBp_Constructor1', 'node_id_to': 'biasCorrected', 'description': 'initializes'}, {'node_id_from': 'VarianceBp_Constructor2', 'node_id_to': 'biasCorrected', 'description': 'initializes'}, {'node_id_from': 'VarianceBp_Constructor3', 'node_id_to': 'biasCorrected', 'description': 'initializes'}, {'node_id_from': 'VarianceBp_Constructor4', 'node_id_to': 'biasCorrected', 'description': 'initializes'}, {'node_id_from': 'VarianceBp', 'node_id_to': 'biasCorrected', 'description': ''}, {'node_id_from': 'VarianceBp', 'node_id_to': 'VarianceBp_Constructor1', 'description': ''}, {'node_id_from': 'VarianceBp', 'node_id_to': 'VarianceBp_Constructor2', 'description': ''}, {'node_id_from': 'VarianceBp', 'node_id_to': 'VarianceBp_Constructor3', 'description': ''}, {'node_id_from': 'VarianceBp', 'node_id_to': 'VarianceBp_Constructor4', 'description': ''}], 'packages': [{'package_id': 'sameDiffConstructors', 'children': ['VarianceBp_Constructor2', 'VarianceBp_Constructor3'], 'description': 'Constructors using SameDiff parameters'}]}",
    "version": "medium",
    "text_answer": "The VarianceBp class has 9 constructor overloads that can be grouped into three categories: basic constructor with just biasCorrected parameter, SameDiff-based constructors for automatic differentiation (4 variants), and INDArray-based constructors for direct array operations (4 variants). All constructors initialize the biasCorrected field and most include parameters for keepDims and dimensions specification.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.nd4j.linalg.api.ops.impl.reduce.bp;\n\nimport lombok.NoArgsConstructor;\nimport org.nd4j.autodiff.samediff.SDVariable;\nimport org.nd4j.autodiff.samediff.SameDiff;\nimport org.nd4j.linalg.api.ndarray.INDArray;\n\n\n@NoArgsConstructor\npublic class VarianceBp extends BaseReductionBp {\n\n    private boolean biasCorrected;\n\n    public VarianceBp(SameDiff sameDiff, SDVariable origInput, SDVariable gradAtOutput, boolean biasCorrected, boolean keepDims, long... dimensions) {\n        super(sameDiff, origInput, gradAtOutput, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n\n    }\n\n    public VarianceBp(SameDiff sameDiff, SDVariable origInput1, SDVariable origInput2, SDVariable gradAtOutput, boolean keepDims, boolean biasCorrected, long... dimensions) {\n        super(sameDiff, origInput1, origInput2, gradAtOutput, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n\n    }\n\n    public VarianceBp(INDArray origInput, INDArray gradAtOutput, INDArray output, boolean biasCorrected, boolean keepDims, long... dimensions){\n        super(origInput, gradAtOutput, output, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n\n    }\n\n    public VarianceBp(INDArray origInput1, INDArray origInput2, INDArray gradAtOutput, INDArray output, boolean keepDims, boolean biasCorrected, long... dimensions) {\n        super(origInput1, origInput2, gradAtOutput, output, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n\n    }\n\n    public VarianceBp(INDArray origInput1, INDArray origInput2, INDArray gradAtOutput, INDArray output1, INDArray output2, boolean keepDims, boolean biasCorrected, long... dimensions) {\n        super(origInput1, origInput2, gradAtOutput, output1, output2, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n\n    }\n\n    public VarianceBp(INDArray origInput, INDArray gradAtOutput, INDArray output, boolean keepDims, INDArray dimensions, boolean biasCorrected) {\n        super(origInput, gradAtOutput, output, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n\n    }\n\n    public VarianceBp(SameDiff sameDiff, SDVariable origInput, SDVariable gradAtOutput, boolean keepDims, SDVariable dimensions, boolean biasCorrected) {\n        super(sameDiff, origInput, gradAtOutput, keepDims, dimensions);\n        this.biasCorrected = biasCorrected;\n        addArgs();\n    }\n\n    public VarianceBp(SameDiff sameDiff, SDVariable arg, SDVariable dLdVar, boolean keepDims, boolean biasCorrected, SDVariable dimensions) {\n        super(sameDiff,arg,dLdVar,keepDims,dimensions);\n        addBArgument(biasCorrected);\n    }\n\n    @Override\n    protected void addArgs() {\n        super.addArgs();\n        addBArgument(biasCorrected);\n    }\n\n    public VarianceBp(boolean biasCorrected) {\n        this.biasCorrected = biasCorrected;\n    }\n\n    @Override\n    public String opName() {\n        return \"reduce_variance_bp\";\n    }\n}",
    "repo": "deeplearning4j/deeplearning4j",
    "path": "./datasets/diagrams-repos/deeplearning4j/deeplearning4j/nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/api/ops/impl/reduce/bp/VarianceBp.java",
    "query": "Can you illustrate the different constructor overloads in the `VarianceBp` class and their parameters?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'VarianceBp', 'node_id': 'VarianceBp', 'description': 'Class for backpropagation of variance reduction operation', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'biasCorrected', 'node_id': 'biasCorrected', 'description': 'Flag indicating if variance should be bias corrected', 'visibility': 'private', 'return_type': 'boolean', 'params': None, 'source_class_id': 'VarianceBp'}, {'type': 'method', 'name': 'VarianceBp', 'node_id': 'VarianceBp_Constructor1', 'description': 'Basic constructor with bias correction parameter', 'visibility': 'public', 'return_type': None, 'params': '(boolean biasCorrected)', 'source_class_id': 'VarianceBp'}, {'type': 'method', 'name': 'VarianceBp', 'node_id': 'VarianceBp_Constructor2', 'description': 'Constructor for SameDiff with single input', 'visibility': 'public', 'return_type': None, 'params': '(SameDiff sameDiff, SDVariable origInput, SDVariable gradAtOutput, boolean biasCorrected, boolean keepDims, long... dimensions)', 'source_class_id': 'VarianceBp'}, {'type': 'method', 'name': 'VarianceBp', 'node_id': 'VarianceBp_Constructor3', 'description': 'Constructor for SameDiff with two inputs', 'visibility': 'public', 'return_type': None, 'params': '(SameDiff sameDiff, SDVariable origInput1, SDVariable origInput2, SDVariable gradAtOutput, boolean keepDims, boolean biasCorrected, long... dimensions)', 'source_class_id': 'VarianceBp'}, {'type': 'method', 'name': 'VarianceBp', 'node_id': 'VarianceBp_Constructor4', 'description': 'Constructor for INDArray with single input', 'visibility': 'public', 'return_type': None, 'params': '(INDArray origInput, INDArray gradAtOutput, INDArray output, boolean biasCorrected, boolean keepDims, long... dimensions)', 'source_class_id': 'VarianceBp'}, {'type': 'method', 'name': 'VarianceBp', 'node_id': 'VarianceBp_Constructor5', 'description': 'Constructor for INDArray with two inputs', 'visibility': 'public', 'return_type': None, 'params': '(INDArray origInput1, INDArray origInput2, INDArray gradAtOutput, INDArray output, boolean keepDims, boolean biasCorrected, long... dimensions)', 'source_class_id': 'VarianceBp'}, {'type': 'method', 'name': 'VarianceBp', 'node_id': 'VarianceBp_Constructor6', 'description': 'Constructor for INDArray with two inputs and outputs', 'visibility': 'public', 'return_type': None, 'params': '(INDArray origInput1, INDArray origInput2, INDArray gradAtOutput, INDArray output1, INDArray output2, boolean keepDims, boolean biasCorrected, long... dimensions)', 'source_class_id': 'VarianceBp'}, {'type': 'method', 'name': 'VarianceBp', 'node_id': 'VarianceBp_Constructor7', 'description': 'Constructor with dimension array for INDArray', 'visibility': 'public', 'return_type': None, 'params': '(INDArray origInput, INDArray gradAtOutput, INDArray output, boolean keepDims, INDArray dimensions, boolean biasCorrected)', 'source_class_id': 'VarianceBp'}, {'type': 'method', 'name': 'VarianceBp', 'node_id': 'VarianceBp_Constructor8', 'description': 'Constructor with dimension variable for SameDiff', 'visibility': 'public', 'return_type': None, 'params': '(SameDiff sameDiff, SDVariable origInput, SDVariable gradAtOutput, boolean keepDims, SDVariable dimensions, boolean biasCorrected)', 'source_class_id': 'VarianceBp'}, {'type': 'method', 'name': 'VarianceBp', 'node_id': 'VarianceBp_Constructor9', 'description': 'Constructor with dimension variable and dLdVar', 'visibility': 'public', 'return_type': None, 'params': '(SameDiff sameDiff, SDVariable arg, SDVariable dLdVar, boolean keepDims, boolean biasCorrected, SDVariable dimensions)', 'source_class_id': 'VarianceBp'}], 'edges': [{'node_id_from': 'VarianceBp_Constructor1', 'node_id_to': 'biasCorrected', 'description': 'initializes'}, {'node_id_from': 'VarianceBp_Constructor2', 'node_id_to': 'biasCorrected', 'description': 'initializes'}, {'node_id_from': 'VarianceBp_Constructor3', 'node_id_to': 'biasCorrected', 'description': 'initializes'}, {'node_id_from': 'VarianceBp_Constructor4', 'node_id_to': 'biasCorrected', 'description': 'initializes'}, {'node_id_from': 'VarianceBp_Constructor5', 'node_id_to': 'biasCorrected', 'description': 'initializes'}, {'node_id_from': 'VarianceBp_Constructor6', 'node_id_to': 'biasCorrected', 'description': 'initializes'}, {'node_id_from': 'VarianceBp_Constructor7', 'node_id_to': 'biasCorrected', 'description': 'initializes'}, {'node_id_from': 'VarianceBp_Constructor8', 'node_id_to': 'biasCorrected', 'description': 'initializes'}, {'node_id_from': 'VarianceBp_Constructor9', 'node_id_to': 'biasCorrected', 'description': 'initializes'}, {'node_id_from': 'VarianceBp', 'node_id_to': 'biasCorrected', 'description': ''}, {'node_id_from': 'VarianceBp', 'node_id_to': 'VarianceBp_Constructor1', 'description': ''}, {'node_id_from': 'VarianceBp', 'node_id_to': 'VarianceBp_Constructor2', 'description': ''}, {'node_id_from': 'VarianceBp', 'node_id_to': 'VarianceBp_Constructor3', 'description': ''}, {'node_id_from': 'VarianceBp', 'node_id_to': 'VarianceBp_Constructor4', 'description': ''}, {'node_id_from': 'VarianceBp', 'node_id_to': 'VarianceBp_Constructor5', 'description': ''}, {'node_id_from': 'VarianceBp', 'node_id_to': 'VarianceBp_Constructor6', 'description': ''}, {'node_id_from': 'VarianceBp', 'node_id_to': 'VarianceBp_Constructor7', 'description': ''}, {'node_id_from': 'VarianceBp', 'node_id_to': 'VarianceBp_Constructor8', 'description': ''}, {'node_id_from': 'VarianceBp', 'node_id_to': 'VarianceBp_Constructor9', 'description': ''}], 'packages': [{'package_id': 'sameDiffConstructors', 'children': ['VarianceBp_Constructor2', 'VarianceBp_Constructor3', 'VarianceBp_Constructor8', 'VarianceBp_Constructor9'], 'description': 'Constructors using SameDiff parameters'}, {'package_id': 'arrayConstructors', 'children': ['VarianceBp_Constructor4', 'VarianceBp_Constructor5', 'VarianceBp_Constructor6', 'VarianceBp_Constructor7'], 'description': 'Constructors using INDArray parameters'}]}",
    "version": "full",
    "text_answer": "The VarianceBp class has 9 constructor overloads that can be grouped into three categories: basic constructor with just biasCorrected parameter, SameDiff-based constructors for automatic differentiation (4 variants), and INDArray-based constructors for direct array operations (4 variants). All constructors initialize the biasCorrected field and most include parameters for keepDims and dimensions specification.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport type * as tslibType from 'tslib';\nconst tslib: typeof tslibType = require('tslib');\nimport { Observable } from '../data/observable';\nimport { trace as profilingTrace, time, uptime, level as profilingLevel } from '../profiling';\n\ntype ModuleLoader = (name?: string) => any;\n\ninterface Context {\n\tkeys(): string[];\n\t(key: string): any;\n}\n\ninterface ExtensionMap {\n\t[originalFileExtension: string]: string;\n}\n\nfunction registerOnGlobalContext(moduleName: string, exportName: string): void {\n\tObject.defineProperty(global, exportName, {\n\t\tget: function () {\n\t\t\t// We do not need to cache require() call since it is already cached in the runtime.\n\t\t\tconst m = global.loadModule(moduleName);\n\n\t\t\t// Redefine the property to make sure the above code is executed only once.\n\t\t\tconst resolvedValue = m[exportName];\n\t\t\tObject.defineProperty(global, exportName, {\n\t\t\t\tvalue: resolvedValue,\n\t\t\t\tconfigurable: true,\n\t\t\t\twritable: true,\n\t\t\t});\n\n\t\t\treturn resolvedValue;\n\t\t},\n\t\tconfigurable: true,\n\t});\n}\n\n/**\n * Manages internal framework global state\n */\nexport class NativeScriptGlobalState {\n\tevents: Observable;\n\tlaunched = false;\n\t// used by various classes to setup callbacks to wire up global app event handling when the app instance is ready\n\tappEventWiring: Array<any>;\n\tprivate _appInstanceReady = false;\n\tprivate _setLaunched: () => void;\n\tconstructor() {\n\t\t// console.log('creating NativeScriptGlobals...')\n\t\tthis.events = new Observable();\n\t\tthis._setLaunched = this._setLaunchedFn.bind(this);\n\t\tthis.events.on('launch', this._setLaunched);\n\t\tif (profilingLevel() > 0) {\n\t\t\tthis.events.on('displayed', () => {\n\t\t\t\tconst duration = uptime();\n\t\t\t\tconst end = time();\n\t\t\t\tconst start = end - duration;\n\t\t\t\tprofilingTrace(`Displayed in ${duration.toFixed(2)}ms`, start, end);\n\t\t\t});\n\t\t}\n\t}\n\n\tget appInstanceReady() {\n\t\treturn this._appInstanceReady;\n\t}\n\n\tset appInstanceReady(value: boolean) {\n\t\tthis._appInstanceReady = value;\n\t\t// app instance ready, wire up any app events waiting in startup queue\n\t\tif (this.appEventWiring && this.appEventWiring.length) {\n\t\t\tfor (const callback of this.appEventWiring) {\n\t\t\t\tcallback();\n\t\t\t}\n\t\t\t// cleanup\n\t\t\tthis.appEventWiring = null;\n\t\t}\n\t}\n\n\t/**\n\t * Ability for classes to initialize app event handling early even before the app instance is ready during boot cycle avoiding boot race conditions\n\t * @param callback wire up any global event handling inside the callback\n\t */\n\taddEventWiring(callback: () => void) {\n\t\tif (this._appInstanceReady) {\n\t\t\tcallback();\n\t\t} else {\n\t\t\tif (!this.appEventWiring) {\n\t\t\t\tthis.appEventWiring = [];\n\t\t\t}\n\t\t\tthis.appEventWiring.push(callback);\n\t\t}\n\t}\n\n\tprivate _setLaunchedFn() {\n\t\t// console.log('NativeScriptGlobals launch fired!');\n\t\tthis.launched = true;\n\t\tthis.events.off('launch', this._setLaunched);\n\t\tthis._setLaunched = null;\n\t}\n}\n\nexport function installPolyfills(moduleName: string, exportNames: string[]) {\n\tif (global.__snapshot) {\n\t\tconst loadedModule = global.loadModule(moduleName);\n\t\texportNames.forEach((exportName) => (global[exportName] = loadedModule[exportName]));\n\t} else {\n\t\texportNames.forEach((exportName) => registerOnGlobalContext(moduleName, exportName));\n\t}\n}\n\nexport function initGlobal() {\n\tif (!global.NativeScriptHasInitGlobal) {\n\t\tglobal.NativeScriptHasInitGlobal = true;\n\t\t// init global state handler\n\t\tglobal.NativeScriptGlobals = new NativeScriptGlobalState();\n\n\t\t// ts-helpers\n\t\t// Required by V8 snapshot generator\n\t\tif (!global.__extends) {\n\t\t\tglobal.__extends = function (d, b) {\n\t\t\t\tfor (const p in b) {\n\t\t\t\t\tif (b.hasOwnProperty(p)) {\n\t\t\t\t\t\td[p] = b[p];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfunction __() {\n\t\t\t\t\tthis.constructor = d;\n\t\t\t\t}\n\t\t\t\td.prototype = b === null ? Object.create(b) : ((__.prototype = b.prototype), new __());\n\t\t\t};\n\t\t}\n\n\t\t// Bind the tslib helpers to global scope.\n\t\t// This is needed when we don't use importHelpers, which\n\t\t// breaks extending native-classes\n\t\tfor (const fnName of Object.getOwnPropertyNames(tslib)) {\n\t\t\tif (typeof tslib[fnName] !== 'function') {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (fnName in global) {\n\t\t\t\t// Don't override globals that are already defined (ex. __extends)\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tglobal[fnName] = tslib[fnName];\n\t\t}\n\n\t\t// module helpers\n\t\tconst modules: Map<string, { moduleId: string; loader: ModuleLoader }> = new Map<string, { moduleId: string; loader: ModuleLoader }>();\n\t\tconst modulesLoadedForUI = new Set<string>();\n\t\tconst defaultExtensionMap: ExtensionMap = {\n\t\t\t'.js': '.js',\n\t\t\t'.ts': '.js',\n\t\t\t'.kt': '.js',\n\t\t\t'.css': '.css',\n\t\t\t'.scss': '.css',\n\t\t\t'.less': '.css',\n\t\t\t'.sass': '.css',\n\t\t\t'.xml': '.xml',\n\t\t};\n\n\t\t// Cast to <any> because moduleResolvers is read-only in definitions\n\t\tglobal.moduleResolvers = [global.require];\n\n\t\tglobal.registerModule = function (name: string, loader: ModuleLoader): void {\n\t\t\tmodules.set(name, { loader, moduleId: name });\n\t\t};\n\n\t\tglobal._unregisterModule = function _unregisterModule(name: string): void {\n\t\t\tmodules.delete(name);\n\t\t};\n\n\t\tglobal._isModuleLoadedForUI = function _isModuleLoadedForUI(moduleName: string): boolean {\n\t\t\treturn modulesLoadedForUI.has(moduleName);\n\t\t};\n\n\t\tglobal.registerWebpackModules = function registerWebpackModules(context: Context, extensionMap: ExtensionMap = {}) {\n\t\t\tcontext.keys().forEach((moduleId) => {\n\t\t\t\tconst extDotIndex = moduleId.lastIndexOf('.');\n\t\t\t\tconst base = moduleId.substr(0, extDotIndex);\n\t\t\t\tconst originalExt = moduleId.substr(extDotIndex);\n\t\t\t\tconst registerExt = extensionMap[originalExt] || defaultExtensionMap[originalExt] || originalExt;\n\n\t\t\t\t// We prefer source files for webpack scenarios before compilation leftovers,\n\t\t\t\t// e. g. if we get a .js and .ts for the same module, the .js is probably the compiled version of the .ts file,\n\t\t\t\t// so we register the .ts with higher priority, similar is the case with us preferring the .scss to .css\n\t\t\t\tconst isSourceFile = originalExt !== registerExt;\n\t\t\t\tconst registerName = base + registerExt;\n\n\t\t\t\tconst registerWithName = (nickName: string) => {\n\t\t\t\t\tmodules.set(nickName, {\n\t\t\t\t\t\tmoduleId,\n\t\t\t\t\t\tloader: () => {\n\t\t\t\t\t\t\treturn context(moduleId);\n\t\t\t\t\t\t},\n\t\t\t\t\t});\n\t\t\t\t};\n\n\t\t\t\tif (registerName.startsWith('./') && registerName.endsWith('.js')) {\n\t\t\t\t\tconst jsNickNames = [\n\t\t\t\t\t\t// This is extremely short version like \"main-page\" that was promoted to be used with global.registerModule(\"module-name\", loaderFunc);\n\t\t\t\t\t\tregisterName.substr(2, registerName.length - 5),\n\t\t\t\t\t\t// This is for supporting module names like \"./main/main-page\"\n\t\t\t\t\t\tregisterName.substr(0, registerName.length - 3),\n\t\t\t\t\t\t// This is for supporting module names like \"main/main-page.js\"\n\t\t\t\t\t\tregisterName.substr(2),\n\t\t\t\t\t];\n\n\t\t\t\t\tjsNickNames.forEach((jsNickName) => {\n\t\t\t\t\t\tif (isSourceFile || !global.moduleExists(jsNickName)) {\n\t\t\t\t\t\t\tregisterWithName(jsNickName);\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t} else if (registerName.startsWith('./')) {\n\t\t\t\t\tconst moduleNickNames = [\n\t\t\t\t\t\t// This is for supporting module names like \"main/main-page.xml\"\n\t\t\t\t\t\tregisterName.substr(2),\n\t\t\t\t\t];\n\n\t\t\t\t\tmoduleNickNames.forEach((moduleNickName) => {\n\t\t\t\t\t\tif (!global.moduleExists(moduleNickName)) {\n\t\t\t\t\t\t\tregisterWithName(moduleNickName);\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t}\n\n\t\t\t\tif (isSourceFile || !global.moduleExists(registerName)) {\n\t\t\t\t\tregisterWithName(registerName);\n\t\t\t\t}\n\t\t\t});\n\t\t};\n\n\t\tglobal.moduleExists = function moduleExists(name: string): boolean {\n\t\t\treturn modules.has(name);\n\t\t};\n\n\t\tglobal.loadModule = function loadModule(name: string, isUIModule = false): any {\n\t\t\tconst moduleInfo = modules.get(name);\n\t\t\tif (moduleInfo) {\n\t\t\t\tif (isUIModule) {\n\t\t\t\t\tmodulesLoadedForUI.add(moduleInfo.moduleId);\n\t\t\t\t}\n\n\t\t\t\tconst result = moduleInfo.loader(name);\n\n\t\t\t\tif (result.enableAutoAccept) {\n\t\t\t\t\tresult.enableAutoAccept();\n\t\t\t\t}\n\n\t\t\t\treturn result;\n\t\t\t}\n\n\t\t\tfor (const resolver of global.moduleResolvers) {\n\t\t\t\tconst result = resolver(name);\n\t\t\t\tif (result) {\n\t\t\t\t\tmodules.set(name, { moduleId: name, loader: () => result });\n\n\t\t\t\t\treturn result;\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\n\t\tglobal.getRegisteredModules = function getRegisteredModules(): string[] {\n\t\t\treturn Array.from(modules.keys());\n\t\t};\n\n\t\t/**\n\t\t * Polyfills\n\t\t */\n\t\t// This method iterates all the keys in the source exports object and copies them to the destination exports one.\n\t\t// Note: the method will not check for naming collisions and will override any already existing entries in the destination exports.\n\t\tglobal.moduleMerge = function (sourceExports: any, destExports: any) {\n\t\t\tfor (const key in sourceExports) {\n\t\t\t\tdestExports[key] = sourceExports[key];\n\t\t\t}\n\t\t};\n\n\t\tglobal.zonedCallback = function (callback: Function): Function {\n\t\t\tif (global.zone) {\n\t\t\t\t// Zone v0.5.* style callback wrapping\n\t\t\t\treturn global.zone.bind(callback);\n\t\t\t}\n\t\t\tif (global.Zone) {\n\t\t\t\t// Zone v0.6.* style callback wrapping\n\t\t\t\treturn global.Zone.current.wrap(callback);\n\t\t\t} else {\n\t\t\t\treturn callback;\n\t\t\t}\n\t\t};\n\n\t\tglobal.System = {\n\t\t\timport(path) {\n\t\t\t\treturn new Promise((resolve, reject) => {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tresolve(global.require(path));\n\t\t\t\t\t} catch (e) {\n\t\t\t\t\t\treject(e);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t},\n\t\t};\n\n\t\t// DOM api polyfills\n\t\tglobal.registerModule('timer', () => require('../timer'));\n\t\tinstallPolyfills('timer', ['setTimeout', 'clearTimeout', 'setInterval', 'clearInterval']);\n\n\t\tglobal.registerModule('animation', () => require('../animation-frame'));\n\t\tinstallPolyfills('animation', ['requestAnimationFrame', 'cancelAnimationFrame']);\n\n\t\tglobal.registerModule('media-query-list', () => require('../media-query-list'));\n\t\tinstallPolyfills('media-query-list', ['matchMedia', 'MediaQueryList']);\n\n\t\tglobal.registerModule('ui-dialogs', () => require('../ui/dialogs'));\n\t\tinstallPolyfills('ui-dialogs', ['alert', 'confirm', 'prompt', 'login', 'action']);\n\n\t\tglobal.registerModule('text', () => require('../text'));\n\t\tinstallPolyfills('text', ['TextDecoder', 'TextEncoder']);\n\n\t\tglobal.registerModule('xhr', () => require('../xhr'));\n\t\tinstallPolyfills('xhr', ['XMLHttpRequest', 'FormData', 'Blob', 'File', 'FileReader']);\n\n\t\tglobal.registerModule('fetch', () => require('../fetch'));\n\t\tinstallPolyfills('fetch', ['fetch', 'Headers', 'Request', 'Response']);\n\n\t\tglobal.registerModule('wgc', () => require('../wgc'));\n\t\tinstallPolyfills('wgc', ['atob', 'btoa']);\n\n\t\tglobal.registerModule('crypto', () => require('../wgc/crypto'));\n\t\tinstallPolyfills('crypto', ['Crypto']);\n\n\t\tglobal.registerModule('subtle', () => require('../wgc/crypto/SubtleCrypto'));\n\t\tinstallPolyfills('subtle-crypto', ['Subtle']);\n\n\t\tglobal.crypto = new global.Crypto();\n\n\t\t// global.registerModule('abortcontroller', () => require('../abortcontroller'));\n\t\t// installPolyfills('abortcontroller', ['AbortController', 'AbortSignal']);\n\n\t\t// Custom decorators\n\n\t\tglobal.Deprecated = function (target: Object, key?: string | symbol, descriptor?: any) {\n\t\t\tif (descriptor) {\n\t\t\t\tconst originalMethod = descriptor.value;\n\n\t\t\t\tdescriptor.value = function (...args: any[]) {\n\t\t\t\t\tconsole.log(`${key.toString()} is deprecated`);\n\n\t\t\t\t\treturn originalMethod.apply(this, args);\n\t\t\t\t};\n\n\t\t\t\treturn descriptor;\n\t\t\t} else {\n\t\t\t\tconsole.log(`${(target && (<any>target).name) || target} is deprecated`);\n\n\t\t\t\treturn target;\n\t\t\t}\n\t\t};\n\n\t\tglobal.Experimental = function (target: Object, key?: string | symbol, descriptor?: any) {\n\t\t\tif (descriptor) {\n\t\t\t\tconst originalMethod = descriptor.value;\n\n\t\t\t\tdescriptor.value = function (...args: any[]) {\n\t\t\t\t\tconsole.log(`${key.toString()} is experimental`);\n\n\t\t\t\t\treturn originalMethod.apply(this, args);\n\t\t\t\t};\n\n\t\t\t\treturn descriptor;\n\t\t\t} else {\n\t\t\t\tconsole.log(`${(target && (<any>target).name) || target} is experimental`);\n\n\t\t\t\treturn target;\n\t\t\t}\n\t\t};\n\t}\n}\n\ndeclare const jest: any;\nfunction isTestingEnv() {\n\treturn typeof jest !== 'undefined' || global.__UNIT_TEST__;\n}\n\nif (!global.NativeScriptHasInitGlobal && !isTestingEnv()) {\n\tinitGlobal();\n}\n\nif (!isTestingEnv()) {\n\t// ensure the Application instance is initialized before any other module imports it.\n\trequire('@nativescript/core/application');\n}",
    "repo": "NativeScript/NativeScript",
    "path": "./datasets/diagrams-repos/NativeScript/NativeScript/packages/core/globals/index.ts",
    "query": "How are modules registered and loaded in the global context? Could you represent this process?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'registerModule', 'node_id': 'registerModule', 'description': 'Registers a module with its loader function', 'visibility': 'public', 'return_type': None, 'params': '(name: string, loader: ModuleLoader): void', 'source_class_id': None}, {'type': 'function', 'name': 'loadModule', 'node_id': 'loadModule', 'description': 'Loads a registered module by name', 'visibility': 'public', 'return_type': None, 'params': '(name: string, isUIModule = false): any', 'source_class_id': None}, {'type': 'variable', 'name': 'modules', 'node_id': 'modules', 'description': 'Map storing module information', 'visibility': 'private', 'return_type': 'Map<string, {moduleId: string, loader: ModuleLoader}>', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'registerModule', 'node_id_to': 'modules', 'description': 'stores module'}, {'node_id_from': 'loadModule', 'node_id_to': 'modules', 'description': 'retrieves module'}], 'packages': [{'package_id': 'moduleManagement', 'children': ['registerModule', 'loadModule', 'modules'], 'description': 'Core module management functionality'}]}",
    "version": "minimal",
    "text_answer": "Modules are managed through a central registry system where registerModule() stores module loaders in a Map, and loadModule() retrieves and executes them. The system supports both individual module registration and bulk registration via registerWebpackModules(), with special handling for UI modules tracked in a separate Set.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport type * as tslibType from 'tslib';\nconst tslib: typeof tslibType = require('tslib');\nimport { Observable } from '../data/observable';\nimport { trace as profilingTrace, time, uptime, level as profilingLevel } from '../profiling';\n\ntype ModuleLoader = (name?: string) => any;\n\ninterface Context {\n\tkeys(): string[];\n\t(key: string): any;\n}\n\ninterface ExtensionMap {\n\t[originalFileExtension: string]: string;\n}\n\nfunction registerOnGlobalContext(moduleName: string, exportName: string): void {\n\tObject.defineProperty(global, exportName, {\n\t\tget: function () {\n\t\t\t// We do not need to cache require() call since it is already cached in the runtime.\n\t\t\tconst m = global.loadModule(moduleName);\n\n\t\t\t// Redefine the property to make sure the above code is executed only once.\n\t\t\tconst resolvedValue = m[exportName];\n\t\t\tObject.defineProperty(global, exportName, {\n\t\t\t\tvalue: resolvedValue,\n\t\t\t\tconfigurable: true,\n\t\t\t\twritable: true,\n\t\t\t});\n\n\t\t\treturn resolvedValue;\n\t\t},\n\t\tconfigurable: true,\n\t});\n}\n\n/**\n * Manages internal framework global state\n */\nexport class NativeScriptGlobalState {\n\tevents: Observable;\n\tlaunched = false;\n\t// used by various classes to setup callbacks to wire up global app event handling when the app instance is ready\n\tappEventWiring: Array<any>;\n\tprivate _appInstanceReady = false;\n\tprivate _setLaunched: () => void;\n\tconstructor() {\n\t\t// console.log('creating NativeScriptGlobals...')\n\t\tthis.events = new Observable();\n\t\tthis._setLaunched = this._setLaunchedFn.bind(this);\n\t\tthis.events.on('launch', this._setLaunched);\n\t\tif (profilingLevel() > 0) {\n\t\t\tthis.events.on('displayed', () => {\n\t\t\t\tconst duration = uptime();\n\t\t\t\tconst end = time();\n\t\t\t\tconst start = end - duration;\n\t\t\t\tprofilingTrace(`Displayed in ${duration.toFixed(2)}ms`, start, end);\n\t\t\t});\n\t\t}\n\t}\n\n\tget appInstanceReady() {\n\t\treturn this._appInstanceReady;\n\t}\n\n\tset appInstanceReady(value: boolean) {\n\t\tthis._appInstanceReady = value;\n\t\t// app instance ready, wire up any app events waiting in startup queue\n\t\tif (this.appEventWiring && this.appEventWiring.length) {\n\t\t\tfor (const callback of this.appEventWiring) {\n\t\t\t\tcallback();\n\t\t\t}\n\t\t\t// cleanup\n\t\t\tthis.appEventWiring = null;\n\t\t}\n\t}\n\n\t/**\n\t * Ability for classes to initialize app event handling early even before the app instance is ready during boot cycle avoiding boot race conditions\n\t * @param callback wire up any global event handling inside the callback\n\t */\n\taddEventWiring(callback: () => void) {\n\t\tif (this._appInstanceReady) {\n\t\t\tcallback();\n\t\t} else {\n\t\t\tif (!this.appEventWiring) {\n\t\t\t\tthis.appEventWiring = [];\n\t\t\t}\n\t\t\tthis.appEventWiring.push(callback);\n\t\t}\n\t}\n\n\tprivate _setLaunchedFn() {\n\t\t// console.log('NativeScriptGlobals launch fired!');\n\t\tthis.launched = true;\n\t\tthis.events.off('launch', this._setLaunched);\n\t\tthis._setLaunched = null;\n\t}\n}\n\nexport function installPolyfills(moduleName: string, exportNames: string[]) {\n\tif (global.__snapshot) {\n\t\tconst loadedModule = global.loadModule(moduleName);\n\t\texportNames.forEach((exportName) => (global[exportName] = loadedModule[exportName]));\n\t} else {\n\t\texportNames.forEach((exportName) => registerOnGlobalContext(moduleName, exportName));\n\t}\n}\n\nexport function initGlobal() {\n\tif (!global.NativeScriptHasInitGlobal) {\n\t\tglobal.NativeScriptHasInitGlobal = true;\n\t\t// init global state handler\n\t\tglobal.NativeScriptGlobals = new NativeScriptGlobalState();\n\n\t\t// ts-helpers\n\t\t// Required by V8 snapshot generator\n\t\tif (!global.__extends) {\n\t\t\tglobal.__extends = function (d, b) {\n\t\t\t\tfor (const p in b) {\n\t\t\t\t\tif (b.hasOwnProperty(p)) {\n\t\t\t\t\t\td[p] = b[p];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfunction __() {\n\t\t\t\t\tthis.constructor = d;\n\t\t\t\t}\n\t\t\t\td.prototype = b === null ? Object.create(b) : ((__.prototype = b.prototype), new __());\n\t\t\t};\n\t\t}\n\n\t\t// Bind the tslib helpers to global scope.\n\t\t// This is needed when we don't use importHelpers, which\n\t\t// breaks extending native-classes\n\t\tfor (const fnName of Object.getOwnPropertyNames(tslib)) {\n\t\t\tif (typeof tslib[fnName] !== 'function') {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (fnName in global) {\n\t\t\t\t// Don't override globals that are already defined (ex. __extends)\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tglobal[fnName] = tslib[fnName];\n\t\t}\n\n\t\t// module helpers\n\t\tconst modules: Map<string, { moduleId: string; loader: ModuleLoader }> = new Map<string, { moduleId: string; loader: ModuleLoader }>();\n\t\tconst modulesLoadedForUI = new Set<string>();\n\t\tconst defaultExtensionMap: ExtensionMap = {\n\t\t\t'.js': '.js',\n\t\t\t'.ts': '.js',\n\t\t\t'.kt': '.js',\n\t\t\t'.css': '.css',\n\t\t\t'.scss': '.css',\n\t\t\t'.less': '.css',\n\t\t\t'.sass': '.css',\n\t\t\t'.xml': '.xml',\n\t\t};\n\n\t\t// Cast to <any> because moduleResolvers is read-only in definitions\n\t\tglobal.moduleResolvers = [global.require];\n\n\t\tglobal.registerModule = function (name: string, loader: ModuleLoader): void {\n\t\t\tmodules.set(name, { loader, moduleId: name });\n\t\t};\n\n\t\tglobal._unregisterModule = function _unregisterModule(name: string): void {\n\t\t\tmodules.delete(name);\n\t\t};\n\n\t\tglobal._isModuleLoadedForUI = function _isModuleLoadedForUI(moduleName: string): boolean {\n\t\t\treturn modulesLoadedForUI.has(moduleName);\n\t\t};\n\n\t\tglobal.registerWebpackModules = function registerWebpackModules(context: Context, extensionMap: ExtensionMap = {}) {\n\t\t\tcontext.keys().forEach((moduleId) => {\n\t\t\t\tconst extDotIndex = moduleId.lastIndexOf('.');\n\t\t\t\tconst base = moduleId.substr(0, extDotIndex);\n\t\t\t\tconst originalExt = moduleId.substr(extDotIndex);\n\t\t\t\tconst registerExt = extensionMap[originalExt] || defaultExtensionMap[originalExt] || originalExt;\n\n\t\t\t\t// We prefer source files for webpack scenarios before compilation leftovers,\n\t\t\t\t// e. g. if we get a .js and .ts for the same module, the .js is probably the compiled version of the .ts file,\n\t\t\t\t// so we register the .ts with higher priority, similar is the case with us preferring the .scss to .css\n\t\t\t\tconst isSourceFile = originalExt !== registerExt;\n\t\t\t\tconst registerName = base + registerExt;\n\n\t\t\t\tconst registerWithName = (nickName: string) => {\n\t\t\t\t\tmodules.set(nickName, {\n\t\t\t\t\t\tmoduleId,\n\t\t\t\t\t\tloader: () => {\n\t\t\t\t\t\t\treturn context(moduleId);\n\t\t\t\t\t\t},\n\t\t\t\t\t});\n\t\t\t\t};\n\n\t\t\t\tif (registerName.startsWith('./') && registerName.endsWith('.js')) {\n\t\t\t\t\tconst jsNickNames = [\n\t\t\t\t\t\t// This is extremely short version like \"main-page\" that was promoted to be used with global.registerModule(\"module-name\", loaderFunc);\n\t\t\t\t\t\tregisterName.substr(2, registerName.length - 5),\n\t\t\t\t\t\t// This is for supporting module names like \"./main/main-page\"\n\t\t\t\t\t\tregisterName.substr(0, registerName.length - 3),\n\t\t\t\t\t\t// This is for supporting module names like \"main/main-page.js\"\n\t\t\t\t\t\tregisterName.substr(2),\n\t\t\t\t\t];\n\n\t\t\t\t\tjsNickNames.forEach((jsNickName) => {\n\t\t\t\t\t\tif (isSourceFile || !global.moduleExists(jsNickName)) {\n\t\t\t\t\t\t\tregisterWithName(jsNickName);\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t} else if (registerName.startsWith('./')) {\n\t\t\t\t\tconst moduleNickNames = [\n\t\t\t\t\t\t// This is for supporting module names like \"main/main-page.xml\"\n\t\t\t\t\t\tregisterName.substr(2),\n\t\t\t\t\t];\n\n\t\t\t\t\tmoduleNickNames.forEach((moduleNickName) => {\n\t\t\t\t\t\tif (!global.moduleExists(moduleNickName)) {\n\t\t\t\t\t\t\tregisterWithName(moduleNickName);\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t}\n\n\t\t\t\tif (isSourceFile || !global.moduleExists(registerName)) {\n\t\t\t\t\tregisterWithName(registerName);\n\t\t\t\t}\n\t\t\t});\n\t\t};\n\n\t\tglobal.moduleExists = function moduleExists(name: string): boolean {\n\t\t\treturn modules.has(name);\n\t\t};\n\n\t\tglobal.loadModule = function loadModule(name: string, isUIModule = false): any {\n\t\t\tconst moduleInfo = modules.get(name);\n\t\t\tif (moduleInfo) {\n\t\t\t\tif (isUIModule) {\n\t\t\t\t\tmodulesLoadedForUI.add(moduleInfo.moduleId);\n\t\t\t\t}\n\n\t\t\t\tconst result = moduleInfo.loader(name);\n\n\t\t\t\tif (result.enableAutoAccept) {\n\t\t\t\t\tresult.enableAutoAccept();\n\t\t\t\t}\n\n\t\t\t\treturn result;\n\t\t\t}\n\n\t\t\tfor (const resolver of global.moduleResolvers) {\n\t\t\t\tconst result = resolver(name);\n\t\t\t\tif (result) {\n\t\t\t\t\tmodules.set(name, { moduleId: name, loader: () => result });\n\n\t\t\t\t\treturn result;\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\n\t\tglobal.getRegisteredModules = function getRegisteredModules(): string[] {\n\t\t\treturn Array.from(modules.keys());\n\t\t};\n\n\t\t/**\n\t\t * Polyfills\n\t\t */\n\t\t// This method iterates all the keys in the source exports object and copies them to the destination exports one.\n\t\t// Note: the method will not check for naming collisions and will override any already existing entries in the destination exports.\n\t\tglobal.moduleMerge = function (sourceExports: any, destExports: any) {\n\t\t\tfor (const key in sourceExports) {\n\t\t\t\tdestExports[key] = sourceExports[key];\n\t\t\t}\n\t\t};\n\n\t\tglobal.zonedCallback = function (callback: Function): Function {\n\t\t\tif (global.zone) {\n\t\t\t\t// Zone v0.5.* style callback wrapping\n\t\t\t\treturn global.zone.bind(callback);\n\t\t\t}\n\t\t\tif (global.Zone) {\n\t\t\t\t// Zone v0.6.* style callback wrapping\n\t\t\t\treturn global.Zone.current.wrap(callback);\n\t\t\t} else {\n\t\t\t\treturn callback;\n\t\t\t}\n\t\t};\n\n\t\tglobal.System = {\n\t\t\timport(path) {\n\t\t\t\treturn new Promise((resolve, reject) => {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tresolve(global.require(path));\n\t\t\t\t\t} catch (e) {\n\t\t\t\t\t\treject(e);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t},\n\t\t};\n\n\t\t// DOM api polyfills\n\t\tglobal.registerModule('timer', () => require('../timer'));\n\t\tinstallPolyfills('timer', ['setTimeout', 'clearTimeout', 'setInterval', 'clearInterval']);\n\n\t\tglobal.registerModule('animation', () => require('../animation-frame'));\n\t\tinstallPolyfills('animation', ['requestAnimationFrame', 'cancelAnimationFrame']);\n\n\t\tglobal.registerModule('media-query-list', () => require('../media-query-list'));\n\t\tinstallPolyfills('media-query-list', ['matchMedia', 'MediaQueryList']);\n\n\t\tglobal.registerModule('ui-dialogs', () => require('../ui/dialogs'));\n\t\tinstallPolyfills('ui-dialogs', ['alert', 'confirm', 'prompt', 'login', 'action']);\n\n\t\tglobal.registerModule('text', () => require('../text'));\n\t\tinstallPolyfills('text', ['TextDecoder', 'TextEncoder']);\n\n\t\tglobal.registerModule('xhr', () => require('../xhr'));\n\t\tinstallPolyfills('xhr', ['XMLHttpRequest', 'FormData', 'Blob', 'File', 'FileReader']);\n\n\t\tglobal.registerModule('fetch', () => require('../fetch'));\n\t\tinstallPolyfills('fetch', ['fetch', 'Headers', 'Request', 'Response']);\n\n\t\tglobal.registerModule('wgc', () => require('../wgc'));\n\t\tinstallPolyfills('wgc', ['atob', 'btoa']);\n\n\t\tglobal.registerModule('crypto', () => require('../wgc/crypto'));\n\t\tinstallPolyfills('crypto', ['Crypto']);\n\n\t\tglobal.registerModule('subtle', () => require('../wgc/crypto/SubtleCrypto'));\n\t\tinstallPolyfills('subtle-crypto', ['Subtle']);\n\n\t\tglobal.crypto = new global.Crypto();\n\n\t\t// global.registerModule('abortcontroller', () => require('../abortcontroller'));\n\t\t// installPolyfills('abortcontroller', ['AbortController', 'AbortSignal']);\n\n\t\t// Custom decorators\n\n\t\tglobal.Deprecated = function (target: Object, key?: string | symbol, descriptor?: any) {\n\t\t\tif (descriptor) {\n\t\t\t\tconst originalMethod = descriptor.value;\n\n\t\t\t\tdescriptor.value = function (...args: any[]) {\n\t\t\t\t\tconsole.log(`${key.toString()} is deprecated`);\n\n\t\t\t\t\treturn originalMethod.apply(this, args);\n\t\t\t\t};\n\n\t\t\t\treturn descriptor;\n\t\t\t} else {\n\t\t\t\tconsole.log(`${(target && (<any>target).name) || target} is deprecated`);\n\n\t\t\t\treturn target;\n\t\t\t}\n\t\t};\n\n\t\tglobal.Experimental = function (target: Object, key?: string | symbol, descriptor?: any) {\n\t\t\tif (descriptor) {\n\t\t\t\tconst originalMethod = descriptor.value;\n\n\t\t\t\tdescriptor.value = function (...args: any[]) {\n\t\t\t\t\tconsole.log(`${key.toString()} is experimental`);\n\n\t\t\t\t\treturn originalMethod.apply(this, args);\n\t\t\t\t};\n\n\t\t\t\treturn descriptor;\n\t\t\t} else {\n\t\t\t\tconsole.log(`${(target && (<any>target).name) || target} is experimental`);\n\n\t\t\t\treturn target;\n\t\t\t}\n\t\t};\n\t}\n}\n\ndeclare const jest: any;\nfunction isTestingEnv() {\n\treturn typeof jest !== 'undefined' || global.__UNIT_TEST__;\n}\n\nif (!global.NativeScriptHasInitGlobal && !isTestingEnv()) {\n\tinitGlobal();\n}\n\nif (!isTestingEnv()) {\n\t// ensure the Application instance is initialized before any other module imports it.\n\trequire('@nativescript/core/application');\n}",
    "repo": "NativeScript/NativeScript",
    "path": "./datasets/diagrams-repos/NativeScript/NativeScript/packages/core/globals/index.ts",
    "query": "How are modules registered and loaded in the global context? Could you represent this process?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'registerModule', 'node_id': 'registerModule', 'description': 'Registers a module with its loader function', 'visibility': 'public', 'return_type': None, 'params': '(name: string, loader: ModuleLoader): void', 'source_class_id': None}, {'type': 'function', 'name': 'loadModule', 'node_id': 'loadModule', 'description': 'Loads a registered module by name', 'visibility': 'public', 'return_type': None, 'params': '(name: string, isUIModule = false): any', 'source_class_id': None}, {'type': 'function', 'name': 'moduleExists', 'node_id': 'moduleExists', 'description': 'Checks if module is registered', 'visibility': 'public', 'return_type': None, 'params': '(name: string): boolean', 'source_class_id': None}, {'type': 'function', 'name': 'registerWebpackModules', 'node_id': 'registerWebpackModules', 'description': 'Registers multiple webpack modules', 'visibility': 'public', 'return_type': None, 'params': '(context: Context, extensionMap?: ExtensionMap)', 'source_class_id': None}, {'type': 'variable', 'name': 'modules', 'node_id': 'modules', 'description': 'Map storing module information', 'visibility': 'private', 'return_type': 'Map<string, {moduleId: string, loader: ModuleLoader}>', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'modulesLoadedForUI', 'node_id': 'modulesLoadedForUI', 'description': 'Set of UI modules that have been loaded', 'visibility': 'private', 'return_type': 'Set<string>', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'registerModule', 'node_id_to': 'modules', 'description': 'stores module'}, {'node_id_from': 'loadModule', 'node_id_to': 'modules', 'description': 'retrieves module'}, {'node_id_from': 'moduleExists', 'node_id_to': 'modules', 'description': 'checks module existence'}, {'node_id_from': 'registerWebpackModules', 'node_id_to': 'registerModule', 'description': 'registers individual modules'}, {'node_id_from': 'loadModule', 'node_id_to': 'modulesLoadedForUI', 'description': 'tracks UI modules'}], 'packages': [{'package_id': 'moduleManagement', 'children': ['registerModule', 'loadModule', 'moduleExists', 'registerWebpackModules', 'modules', 'modulesLoadedForUI'], 'description': 'Module management system'}]}",
    "version": "medium",
    "text_answer": "Modules are managed through a central registry system where registerModule() stores module loaders in a Map, and loadModule() retrieves and executes them. The system supports both individual module registration and bulk registration via registerWebpackModules(), with special handling for UI modules tracked in a separate Set.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport type * as tslibType from 'tslib';\nconst tslib: typeof tslibType = require('tslib');\nimport { Observable } from '../data/observable';\nimport { trace as profilingTrace, time, uptime, level as profilingLevel } from '../profiling';\n\ntype ModuleLoader = (name?: string) => any;\n\ninterface Context {\n\tkeys(): string[];\n\t(key: string): any;\n}\n\ninterface ExtensionMap {\n\t[originalFileExtension: string]: string;\n}\n\nfunction registerOnGlobalContext(moduleName: string, exportName: string): void {\n\tObject.defineProperty(global, exportName, {\n\t\tget: function () {\n\t\t\t// We do not need to cache require() call since it is already cached in the runtime.\n\t\t\tconst m = global.loadModule(moduleName);\n\n\t\t\t// Redefine the property to make sure the above code is executed only once.\n\t\t\tconst resolvedValue = m[exportName];\n\t\t\tObject.defineProperty(global, exportName, {\n\t\t\t\tvalue: resolvedValue,\n\t\t\t\tconfigurable: true,\n\t\t\t\twritable: true,\n\t\t\t});\n\n\t\t\treturn resolvedValue;\n\t\t},\n\t\tconfigurable: true,\n\t});\n}\n\n/**\n * Manages internal framework global state\n */\nexport class NativeScriptGlobalState {\n\tevents: Observable;\n\tlaunched = false;\n\t// used by various classes to setup callbacks to wire up global app event handling when the app instance is ready\n\tappEventWiring: Array<any>;\n\tprivate _appInstanceReady = false;\n\tprivate _setLaunched: () => void;\n\tconstructor() {\n\t\t// console.log('creating NativeScriptGlobals...')\n\t\tthis.events = new Observable();\n\t\tthis._setLaunched = this._setLaunchedFn.bind(this);\n\t\tthis.events.on('launch', this._setLaunched);\n\t\tif (profilingLevel() > 0) {\n\t\t\tthis.events.on('displayed', () => {\n\t\t\t\tconst duration = uptime();\n\t\t\t\tconst end = time();\n\t\t\t\tconst start = end - duration;\n\t\t\t\tprofilingTrace(`Displayed in ${duration.toFixed(2)}ms`, start, end);\n\t\t\t});\n\t\t}\n\t}\n\n\tget appInstanceReady() {\n\t\treturn this._appInstanceReady;\n\t}\n\n\tset appInstanceReady(value: boolean) {\n\t\tthis._appInstanceReady = value;\n\t\t// app instance ready, wire up any app events waiting in startup queue\n\t\tif (this.appEventWiring && this.appEventWiring.length) {\n\t\t\tfor (const callback of this.appEventWiring) {\n\t\t\t\tcallback();\n\t\t\t}\n\t\t\t// cleanup\n\t\t\tthis.appEventWiring = null;\n\t\t}\n\t}\n\n\t/**\n\t * Ability for classes to initialize app event handling early even before the app instance is ready during boot cycle avoiding boot race conditions\n\t * @param callback wire up any global event handling inside the callback\n\t */\n\taddEventWiring(callback: () => void) {\n\t\tif (this._appInstanceReady) {\n\t\t\tcallback();\n\t\t} else {\n\t\t\tif (!this.appEventWiring) {\n\t\t\t\tthis.appEventWiring = [];\n\t\t\t}\n\t\t\tthis.appEventWiring.push(callback);\n\t\t}\n\t}\n\n\tprivate _setLaunchedFn() {\n\t\t// console.log('NativeScriptGlobals launch fired!');\n\t\tthis.launched = true;\n\t\tthis.events.off('launch', this._setLaunched);\n\t\tthis._setLaunched = null;\n\t}\n}\n\nexport function installPolyfills(moduleName: string, exportNames: string[]) {\n\tif (global.__snapshot) {\n\t\tconst loadedModule = global.loadModule(moduleName);\n\t\texportNames.forEach((exportName) => (global[exportName] = loadedModule[exportName]));\n\t} else {\n\t\texportNames.forEach((exportName) => registerOnGlobalContext(moduleName, exportName));\n\t}\n}\n\nexport function initGlobal() {\n\tif (!global.NativeScriptHasInitGlobal) {\n\t\tglobal.NativeScriptHasInitGlobal = true;\n\t\t// init global state handler\n\t\tglobal.NativeScriptGlobals = new NativeScriptGlobalState();\n\n\t\t// ts-helpers\n\t\t// Required by V8 snapshot generator\n\t\tif (!global.__extends) {\n\t\t\tglobal.__extends = function (d, b) {\n\t\t\t\tfor (const p in b) {\n\t\t\t\t\tif (b.hasOwnProperty(p)) {\n\t\t\t\t\t\td[p] = b[p];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfunction __() {\n\t\t\t\t\tthis.constructor = d;\n\t\t\t\t}\n\t\t\t\td.prototype = b === null ? Object.create(b) : ((__.prototype = b.prototype), new __());\n\t\t\t};\n\t\t}\n\n\t\t// Bind the tslib helpers to global scope.\n\t\t// This is needed when we don't use importHelpers, which\n\t\t// breaks extending native-classes\n\t\tfor (const fnName of Object.getOwnPropertyNames(tslib)) {\n\t\t\tif (typeof tslib[fnName] !== 'function') {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (fnName in global) {\n\t\t\t\t// Don't override globals that are already defined (ex. __extends)\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tglobal[fnName] = tslib[fnName];\n\t\t}\n\n\t\t// module helpers\n\t\tconst modules: Map<string, { moduleId: string; loader: ModuleLoader }> = new Map<string, { moduleId: string; loader: ModuleLoader }>();\n\t\tconst modulesLoadedForUI = new Set<string>();\n\t\tconst defaultExtensionMap: ExtensionMap = {\n\t\t\t'.js': '.js',\n\t\t\t'.ts': '.js',\n\t\t\t'.kt': '.js',\n\t\t\t'.css': '.css',\n\t\t\t'.scss': '.css',\n\t\t\t'.less': '.css',\n\t\t\t'.sass': '.css',\n\t\t\t'.xml': '.xml',\n\t\t};\n\n\t\t// Cast to <any> because moduleResolvers is read-only in definitions\n\t\tglobal.moduleResolvers = [global.require];\n\n\t\tglobal.registerModule = function (name: string, loader: ModuleLoader): void {\n\t\t\tmodules.set(name, { loader, moduleId: name });\n\t\t};\n\n\t\tglobal._unregisterModule = function _unregisterModule(name: string): void {\n\t\t\tmodules.delete(name);\n\t\t};\n\n\t\tglobal._isModuleLoadedForUI = function _isModuleLoadedForUI(moduleName: string): boolean {\n\t\t\treturn modulesLoadedForUI.has(moduleName);\n\t\t};\n\n\t\tglobal.registerWebpackModules = function registerWebpackModules(context: Context, extensionMap: ExtensionMap = {}) {\n\t\t\tcontext.keys().forEach((moduleId) => {\n\t\t\t\tconst extDotIndex = moduleId.lastIndexOf('.');\n\t\t\t\tconst base = moduleId.substr(0, extDotIndex);\n\t\t\t\tconst originalExt = moduleId.substr(extDotIndex);\n\t\t\t\tconst registerExt = extensionMap[originalExt] || defaultExtensionMap[originalExt] || originalExt;\n\n\t\t\t\t// We prefer source files for webpack scenarios before compilation leftovers,\n\t\t\t\t// e. g. if we get a .js and .ts for the same module, the .js is probably the compiled version of the .ts file,\n\t\t\t\t// so we register the .ts with higher priority, similar is the case with us preferring the .scss to .css\n\t\t\t\tconst isSourceFile = originalExt !== registerExt;\n\t\t\t\tconst registerName = base + registerExt;\n\n\t\t\t\tconst registerWithName = (nickName: string) => {\n\t\t\t\t\tmodules.set(nickName, {\n\t\t\t\t\t\tmoduleId,\n\t\t\t\t\t\tloader: () => {\n\t\t\t\t\t\t\treturn context(moduleId);\n\t\t\t\t\t\t},\n\t\t\t\t\t});\n\t\t\t\t};\n\n\t\t\t\tif (registerName.startsWith('./') && registerName.endsWith('.js')) {\n\t\t\t\t\tconst jsNickNames = [\n\t\t\t\t\t\t// This is extremely short version like \"main-page\" that was promoted to be used with global.registerModule(\"module-name\", loaderFunc);\n\t\t\t\t\t\tregisterName.substr(2, registerName.length - 5),\n\t\t\t\t\t\t// This is for supporting module names like \"./main/main-page\"\n\t\t\t\t\t\tregisterName.substr(0, registerName.length - 3),\n\t\t\t\t\t\t// This is for supporting module names like \"main/main-page.js\"\n\t\t\t\t\t\tregisterName.substr(2),\n\t\t\t\t\t];\n\n\t\t\t\t\tjsNickNames.forEach((jsNickName) => {\n\t\t\t\t\t\tif (isSourceFile || !global.moduleExists(jsNickName)) {\n\t\t\t\t\t\t\tregisterWithName(jsNickName);\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t} else if (registerName.startsWith('./')) {\n\t\t\t\t\tconst moduleNickNames = [\n\t\t\t\t\t\t// This is for supporting module names like \"main/main-page.xml\"\n\t\t\t\t\t\tregisterName.substr(2),\n\t\t\t\t\t];\n\n\t\t\t\t\tmoduleNickNames.forEach((moduleNickName) => {\n\t\t\t\t\t\tif (!global.moduleExists(moduleNickName)) {\n\t\t\t\t\t\t\tregisterWithName(moduleNickName);\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t}\n\n\t\t\t\tif (isSourceFile || !global.moduleExists(registerName)) {\n\t\t\t\t\tregisterWithName(registerName);\n\t\t\t\t}\n\t\t\t});\n\t\t};\n\n\t\tglobal.moduleExists = function moduleExists(name: string): boolean {\n\t\t\treturn modules.has(name);\n\t\t};\n\n\t\tglobal.loadModule = function loadModule(name: string, isUIModule = false): any {\n\t\t\tconst moduleInfo = modules.get(name);\n\t\t\tif (moduleInfo) {\n\t\t\t\tif (isUIModule) {\n\t\t\t\t\tmodulesLoadedForUI.add(moduleInfo.moduleId);\n\t\t\t\t}\n\n\t\t\t\tconst result = moduleInfo.loader(name);\n\n\t\t\t\tif (result.enableAutoAccept) {\n\t\t\t\t\tresult.enableAutoAccept();\n\t\t\t\t}\n\n\t\t\t\treturn result;\n\t\t\t}\n\n\t\t\tfor (const resolver of global.moduleResolvers) {\n\t\t\t\tconst result = resolver(name);\n\t\t\t\tif (result) {\n\t\t\t\t\tmodules.set(name, { moduleId: name, loader: () => result });\n\n\t\t\t\t\treturn result;\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\n\t\tglobal.getRegisteredModules = function getRegisteredModules(): string[] {\n\t\t\treturn Array.from(modules.keys());\n\t\t};\n\n\t\t/**\n\t\t * Polyfills\n\t\t */\n\t\t// This method iterates all the keys in the source exports object and copies them to the destination exports one.\n\t\t// Note: the method will not check for naming collisions and will override any already existing entries in the destination exports.\n\t\tglobal.moduleMerge = function (sourceExports: any, destExports: any) {\n\t\t\tfor (const key in sourceExports) {\n\t\t\t\tdestExports[key] = sourceExports[key];\n\t\t\t}\n\t\t};\n\n\t\tglobal.zonedCallback = function (callback: Function): Function {\n\t\t\tif (global.zone) {\n\t\t\t\t// Zone v0.5.* style callback wrapping\n\t\t\t\treturn global.zone.bind(callback);\n\t\t\t}\n\t\t\tif (global.Zone) {\n\t\t\t\t// Zone v0.6.* style callback wrapping\n\t\t\t\treturn global.Zone.current.wrap(callback);\n\t\t\t} else {\n\t\t\t\treturn callback;\n\t\t\t}\n\t\t};\n\n\t\tglobal.System = {\n\t\t\timport(path) {\n\t\t\t\treturn new Promise((resolve, reject) => {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tresolve(global.require(path));\n\t\t\t\t\t} catch (e) {\n\t\t\t\t\t\treject(e);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t},\n\t\t};\n\n\t\t// DOM api polyfills\n\t\tglobal.registerModule('timer', () => require('../timer'));\n\t\tinstallPolyfills('timer', ['setTimeout', 'clearTimeout', 'setInterval', 'clearInterval']);\n\n\t\tglobal.registerModule('animation', () => require('../animation-frame'));\n\t\tinstallPolyfills('animation', ['requestAnimationFrame', 'cancelAnimationFrame']);\n\n\t\tglobal.registerModule('media-query-list', () => require('../media-query-list'));\n\t\tinstallPolyfills('media-query-list', ['matchMedia', 'MediaQueryList']);\n\n\t\tglobal.registerModule('ui-dialogs', () => require('../ui/dialogs'));\n\t\tinstallPolyfills('ui-dialogs', ['alert', 'confirm', 'prompt', 'login', 'action']);\n\n\t\tglobal.registerModule('text', () => require('../text'));\n\t\tinstallPolyfills('text', ['TextDecoder', 'TextEncoder']);\n\n\t\tglobal.registerModule('xhr', () => require('../xhr'));\n\t\tinstallPolyfills('xhr', ['XMLHttpRequest', 'FormData', 'Blob', 'File', 'FileReader']);\n\n\t\tglobal.registerModule('fetch', () => require('../fetch'));\n\t\tinstallPolyfills('fetch', ['fetch', 'Headers', 'Request', 'Response']);\n\n\t\tglobal.registerModule('wgc', () => require('../wgc'));\n\t\tinstallPolyfills('wgc', ['atob', 'btoa']);\n\n\t\tglobal.registerModule('crypto', () => require('../wgc/crypto'));\n\t\tinstallPolyfills('crypto', ['Crypto']);\n\n\t\tglobal.registerModule('subtle', () => require('../wgc/crypto/SubtleCrypto'));\n\t\tinstallPolyfills('subtle-crypto', ['Subtle']);\n\n\t\tglobal.crypto = new global.Crypto();\n\n\t\t// global.registerModule('abortcontroller', () => require('../abortcontroller'));\n\t\t// installPolyfills('abortcontroller', ['AbortController', 'AbortSignal']);\n\n\t\t// Custom decorators\n\n\t\tglobal.Deprecated = function (target: Object, key?: string | symbol, descriptor?: any) {\n\t\t\tif (descriptor) {\n\t\t\t\tconst originalMethod = descriptor.value;\n\n\t\t\t\tdescriptor.value = function (...args: any[]) {\n\t\t\t\t\tconsole.log(`${key.toString()} is deprecated`);\n\n\t\t\t\t\treturn originalMethod.apply(this, args);\n\t\t\t\t};\n\n\t\t\t\treturn descriptor;\n\t\t\t} else {\n\t\t\t\tconsole.log(`${(target && (<any>target).name) || target} is deprecated`);\n\n\t\t\t\treturn target;\n\t\t\t}\n\t\t};\n\n\t\tglobal.Experimental = function (target: Object, key?: string | symbol, descriptor?: any) {\n\t\t\tif (descriptor) {\n\t\t\t\tconst originalMethod = descriptor.value;\n\n\t\t\t\tdescriptor.value = function (...args: any[]) {\n\t\t\t\t\tconsole.log(`${key.toString()} is experimental`);\n\n\t\t\t\t\treturn originalMethod.apply(this, args);\n\t\t\t\t};\n\n\t\t\t\treturn descriptor;\n\t\t\t} else {\n\t\t\t\tconsole.log(`${(target && (<any>target).name) || target} is experimental`);\n\n\t\t\t\treturn target;\n\t\t\t}\n\t\t};\n\t}\n}\n\ndeclare const jest: any;\nfunction isTestingEnv() {\n\treturn typeof jest !== 'undefined' || global.__UNIT_TEST__;\n}\n\nif (!global.NativeScriptHasInitGlobal && !isTestingEnv()) {\n\tinitGlobal();\n}\n\nif (!isTestingEnv()) {\n\t// ensure the Application instance is initialized before any other module imports it.\n\trequire('@nativescript/core/application');\n}",
    "repo": "NativeScript/NativeScript",
    "path": "./datasets/diagrams-repos/NativeScript/NativeScript/packages/core/globals/index.ts",
    "query": "How are modules registered and loaded in the global context? Could you represent this process?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'registerModule', 'node_id': 'registerModule', 'description': 'Registers a module with its loader function', 'visibility': 'public', 'return_type': None, 'params': '(name: string, loader: ModuleLoader): void', 'source_class_id': None}, {'type': 'function', 'name': 'loadModule', 'node_id': 'loadModule', 'description': 'Loads a registered module by name', 'visibility': 'public', 'return_type': None, 'params': '(name: string, isUIModule = false): any', 'source_class_id': None}, {'type': 'function', 'name': 'moduleExists', 'node_id': 'moduleExists', 'description': 'Checks if module is registered', 'visibility': 'public', 'return_type': None, 'params': '(name: string): boolean', 'source_class_id': None}, {'type': 'function', 'name': 'registerWebpackModules', 'node_id': 'registerWebpackModules', 'description': 'Registers multiple webpack modules', 'visibility': 'public', 'return_type': None, 'params': '(context: Context, extensionMap?: ExtensionMap)', 'source_class_id': None}, {'type': 'function', 'name': '_unregisterModule', 'node_id': '_unregisterModule', 'description': 'Removes module registration', 'visibility': 'public', 'return_type': None, 'params': '(name: string): void', 'source_class_id': None}, {'type': 'function', 'name': '_isModuleLoadedForUI', 'node_id': '_isModuleLoadedForUI', 'description': 'Checks if module is loaded for UI', 'visibility': 'public', 'return_type': None, 'params': '(moduleName: string): boolean', 'source_class_id': None}, {'type': 'function', 'name': 'getRegisteredModules', 'node_id': 'getRegisteredModules', 'description': 'Returns list of registered modules', 'visibility': 'public', 'return_type': None, 'params': '(): string[]', 'source_class_id': None}, {'type': 'variable', 'name': 'modules', 'node_id': 'modules', 'description': 'Map storing module information', 'visibility': 'private', 'return_type': 'Map<string, {moduleId: string, loader: ModuleLoader}>', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'modulesLoadedForUI', 'node_id': 'modulesLoadedForUI', 'description': 'Set of UI modules that have been loaded', 'visibility': 'private', 'return_type': 'Set<string>', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'defaultExtensionMap', 'node_id': 'defaultExtensionMap', 'description': 'Default file extension mappings', 'visibility': 'private', 'return_type': 'ExtensionMap', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'moduleResolvers', 'node_id': 'moduleResolvers', 'description': 'Array of module resolver functions', 'visibility': 'public', 'return_type': 'Array<Function>', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'registerModule', 'node_id_to': 'modules', 'description': 'stores module'}, {'node_id_from': 'loadModule', 'node_id_to': 'modules', 'description': 'retrieves module'}, {'node_id_from': 'moduleExists', 'node_id_to': 'modules', 'description': 'checks module existence'}, {'node_id_from': 'registerWebpackModules', 'node_id_to': 'registerModule', 'description': 'registers individual modules'}, {'node_id_from': '_unregisterModule', 'node_id_to': 'modules', 'description': 'removes module'}, {'node_id_from': '_isModuleLoadedForUI', 'node_id_to': 'modulesLoadedForUI', 'description': 'checks UI module'}, {'node_id_from': 'getRegisteredModules', 'node_id_to': 'modules', 'description': 'lists modules'}, {'node_id_from': 'loadModule', 'node_id_to': 'moduleResolvers', 'description': 'uses resolvers'}, {'node_id_from': 'loadModule', 'node_id_to': 'modulesLoadedForUI', 'description': 'uses'}, {'node_id_from': 'registerWebpackModules', 'node_id_to': 'defaultExtensionMap', 'description': 'uses extensions'}], 'packages': [{'package_id': 'moduleManagement', 'children': ['registration', 'loading', 'utilities'], 'description': 'Complete module management system'}, {'package_id': 'registration', 'children': ['registerModule', 'registerWebpackModules', '_unregisterModule', 'modules'], 'description': 'Module registration functionality'}, {'package_id': 'loading', 'children': ['loadModule', 'moduleResolvers', 'modulesLoadedForUI'], 'description': 'Module loading functionality'}, {'package_id': 'utilities', 'children': ['moduleExists', '_isModuleLoadedForUI', 'getRegisteredModules', 'defaultExtensionMap'], 'description': 'Helper functions and configurations'}]}",
    "version": "full",
    "text_answer": "Modules are managed through a central registry system where registerModule() stores module loaders in a Map, and loadModule() retrieves and executes them. The system supports both individual module registration and bulk registration via registerWebpackModules(), with special handling for UI modules tracked in a separate Set.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nasync function convertTensorToData(tensor, needInfo = false) {\n  const data = await tensor.data();\n\n  tensor.dispose();\n  if (needInfo) {\n    return {value: data, shape: tensor.shape, dtype: tensor.dtype};\n  }\n  return data;\n}\n\nasync function getPredictionData(output, needInfo = false) {\n  if (output instanceof Promise) {\n    output = await output;\n  }\n\n  if (output instanceof tf.Tensor) {\n    output = [await convertTensorToData(output, needInfo)];\n  } else if (Array.isArray(output)) {\n    for (let i = 0; i < output.length; i++) {\n      if (output[i] instanceof tf.Tensor) {\n        output[i] = await convertTensorToData(output[i], needInfo);\n      }\n    }\n  } else if (output != null && typeof output === 'object') {\n    for (const property in output) {\n      if (output[property] instanceof tf.Tensor) {\n        output[property] =\n            await convertTensorToData(output[property], needInfo);\n      }\n    }\n  }\n  return output;\n}\n\nfunction printTime(elapsed) {\n  return elapsed.toFixed(1) + ' ms';\n}\n\nfunction printMemory(bytes) {\n  if (bytes < 1024) {\n    return bytes + ' B';\n  } else if (bytes < 1024 * 1024) {\n    return (bytes / 1024).toFixed(2) + ' KB';\n  } else {\n    return (bytes / (1024 * 1024)).toFixed(2) + ' MB';\n  }\n}\n\nfunction sleep(timeMs) {\n  return new Promise(resolve => setTimeout(resolve, timeMs));\n}\n\nfunction queryTimerIsEnabled() {\n  return _tfengine.ENV.getNumber(\n             'WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION') > 0;\n}\n\nfunction areClose(\n    a, e, epsilon, epsilonOfBigNumber = 0.1, relativeEpsilon = 0.01) {\n  if (!isFinite(a) && !isFinite(e)) {\n    return true;\n  } else if (isNaN(a) || isNaN(e)) {\n    return false;\n  }\n\n  const absoluteError = Math.abs(a - e);\n  if (Math.abs(a) >= 1) {\n    if ((absoluteError > epsilonOfBigNumber) ||\n        absoluteError / Math.min(Math.abs(a), Math.abs(e)) > relativeEpsilon) {\n      return false;\n    }\n  } else {\n    if (absoluteError > epsilon) {\n      return false;\n    }\n  }\n  return true;\n}\n\nfunction expectObjectsPredicate(actual, expected, epsilon, predicate) {\n  let actualKeys = Object.getOwnPropertyNames(actual);\n  let expectedKeys = Object.getOwnPropertyNames(expected);\n  if (actualKeys.length != expectedKeys.length) {\n    throw new Error(`Actual length ${\n        actualKeys.length} not equal Expected length ${expectedKeys.length}`);\n  }\n  for (let i = 0; i < actualKeys.length; i++) {\n    let key = actualKeys[i];\n    let isObject = typeof (actual[key]) === 'object' &&\n        typeof (expected[key]) === 'object';\n    let isArray = tf.util.isTypedArray(actual[key]) &&\n        tf.util.isTypedArray(expected[key]);\n    if (isArray) {\n      expectArraysClose(actual[key], expected[key], epsilon, key);\n    } else if (isObject) {\n      expectObjectsPredicate(actual[key], expected[key], epsilon, predicate);\n    } else {\n      if (!predicate(actual[key], expected[key])) {\n        throw new Error(`Objects differ: actual[${key}] = ${\n            JSON.stringify(actual[key])}, expected[${key}] = ${\n            JSON.stringify(expected[key])}!`);\n      }\n    }\n  }\n  return true;\n}\n\nfunction expectObjectsClose(actual, expected, epsilon = -1) {\n  if (epsilon === -1) {\n    epsilon = tf.test_util.testEpsilon();\n  }\n  expectObjectsPredicate(\n      actual, expected, epsilon, (a, b) => areClose(a, b, epsilon));\n}\n\nfunction expectArraysPredicateFuzzy(actual, expected, predicate, errorRate) {\n  if (tf.util.isTypedArray(actual) == false ||\n      tf.util.isTypedArray(expected) == false) {\n    throw new Error(`Actual and Expected are not arrays.`);\n  }\n\n  if (actual.length !== expected.length) {\n    throw new Error(\n        `Arrays have different lengths actual: ${actual.length} vs ` +\n        `expected: ${expected.length}.\\n` +\n        `Actual:   ${actual}.\\n` +\n        `Expected: ${expected}.`);\n  }\n  let mismatchCount = 0;\n  for (let i = 0; i < expected.length; ++i) {\n    const a = actual[i];\n    const e = expected[i];\n    if (!predicate(a, e)) {\n      mismatchCount++;\n      const maxMismatch = Math.floor(errorRate * expected.length);\n      if (mismatchCount > maxMismatch) {\n        throw new Error(\n            `Arrays data has more than ${maxMismatch} differs from ${\n                expected.length}: actual[${i}] = ${a}, expected[${i}] = ${\n                e}.\\n` +\n            `Actual:   ${actual}.\\n` +\n            `Expected: ${expected}.`);\n      }\n    }\n  }\n}\n\n// TODO: support relative comparison for array.\nfunction expectArraysClose(actual, expected, epsilon, key) {\n  if (epsilon === -1) {\n    epsilon = tf.test_util.testEpsilon();\n  }\n\n  if (key == 'data') {\n    // For bodypix, the value in data memeber means \"1 for the pixels that are\n    // part of the person, and 0 otherwise\".\n    // So for these models, we don't expect all data is exactly match. Default\n    // use error rate 0.001 (1/1000).\n    const ERROR_RATE = 0.001;\n    return expectArraysPredicateFuzzy(\n        actual, expected, (a, b) => areClose(a, b, epsilon), ERROR_RATE);\n  } else {\n    return tf.test_util.expectArraysClose(actual, expected, epsilon);\n  }\n}",
    "repo": "tensorflow/tfjs",
    "path": "./datasets/diagrams-repos/tensorflow/tfjs/e2e/benchmarks/local-benchmark/util.js",
    "query": "What is the flow of data in the `getPredictionData` function when the output is an array of tensors?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'getPredictionData', 'node_id': 'getPredictionData', 'description': 'Processes output data, handling arrays of tensors', 'visibility': 'public', 'return_type': 'Promise<any>', 'params': 'output, needInfo = false', 'source_class_id': None}, {'type': 'function', 'name': 'convertTensorToData', 'node_id': 'convertTensorToData', 'description': 'Converts tensor to raw data and optionally includes tensor metadata', 'visibility': 'public', 'return_type': 'Promise<any>', 'params': 'tensor, needInfo = false', 'source_class_id': None}], 'edges': [{'node_id_from': 'getPredictionData', 'node_id_to': 'convertTensorToData', 'description': 'Converts each tensor in array to data'}], 'packages': [{'package_id': 'tensorProcessing', 'children': ['getPredictionData', 'convertTensorToData'], 'description': 'Functions for tensor data processing'}]}",
    "version": "minimal",
    "text_answer": "When processing an array of tensors, getPredictionData iterates through each tensor in the array, converts each tensor to data using convertTensorToData (which extracts the raw data and optionally metadata), disposes the tensor, and returns the processed array.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nasync function convertTensorToData(tensor, needInfo = false) {\n  const data = await tensor.data();\n\n  tensor.dispose();\n  if (needInfo) {\n    return {value: data, shape: tensor.shape, dtype: tensor.dtype};\n  }\n  return data;\n}\n\nasync function getPredictionData(output, needInfo = false) {\n  if (output instanceof Promise) {\n    output = await output;\n  }\n\n  if (output instanceof tf.Tensor) {\n    output = [await convertTensorToData(output, needInfo)];\n  } else if (Array.isArray(output)) {\n    for (let i = 0; i < output.length; i++) {\n      if (output[i] instanceof tf.Tensor) {\n        output[i] = await convertTensorToData(output[i], needInfo);\n      }\n    }\n  } else if (output != null && typeof output === 'object') {\n    for (const property in output) {\n      if (output[property] instanceof tf.Tensor) {\n        output[property] =\n            await convertTensorToData(output[property], needInfo);\n      }\n    }\n  }\n  return output;\n}\n\nfunction printTime(elapsed) {\n  return elapsed.toFixed(1) + ' ms';\n}\n\nfunction printMemory(bytes) {\n  if (bytes < 1024) {\n    return bytes + ' B';\n  } else if (bytes < 1024 * 1024) {\n    return (bytes / 1024).toFixed(2) + ' KB';\n  } else {\n    return (bytes / (1024 * 1024)).toFixed(2) + ' MB';\n  }\n}\n\nfunction sleep(timeMs) {\n  return new Promise(resolve => setTimeout(resolve, timeMs));\n}\n\nfunction queryTimerIsEnabled() {\n  return _tfengine.ENV.getNumber(\n             'WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION') > 0;\n}\n\nfunction areClose(\n    a, e, epsilon, epsilonOfBigNumber = 0.1, relativeEpsilon = 0.01) {\n  if (!isFinite(a) && !isFinite(e)) {\n    return true;\n  } else if (isNaN(a) || isNaN(e)) {\n    return false;\n  }\n\n  const absoluteError = Math.abs(a - e);\n  if (Math.abs(a) >= 1) {\n    if ((absoluteError > epsilonOfBigNumber) ||\n        absoluteError / Math.min(Math.abs(a), Math.abs(e)) > relativeEpsilon) {\n      return false;\n    }\n  } else {\n    if (absoluteError > epsilon) {\n      return false;\n    }\n  }\n  return true;\n}\n\nfunction expectObjectsPredicate(actual, expected, epsilon, predicate) {\n  let actualKeys = Object.getOwnPropertyNames(actual);\n  let expectedKeys = Object.getOwnPropertyNames(expected);\n  if (actualKeys.length != expectedKeys.length) {\n    throw new Error(`Actual length ${\n        actualKeys.length} not equal Expected length ${expectedKeys.length}`);\n  }\n  for (let i = 0; i < actualKeys.length; i++) {\n    let key = actualKeys[i];\n    let isObject = typeof (actual[key]) === 'object' &&\n        typeof (expected[key]) === 'object';\n    let isArray = tf.util.isTypedArray(actual[key]) &&\n        tf.util.isTypedArray(expected[key]);\n    if (isArray) {\n      expectArraysClose(actual[key], expected[key], epsilon, key);\n    } else if (isObject) {\n      expectObjectsPredicate(actual[key], expected[key], epsilon, predicate);\n    } else {\n      if (!predicate(actual[key], expected[key])) {\n        throw new Error(`Objects differ: actual[${key}] = ${\n            JSON.stringify(actual[key])}, expected[${key}] = ${\n            JSON.stringify(expected[key])}!`);\n      }\n    }\n  }\n  return true;\n}\n\nfunction expectObjectsClose(actual, expected, epsilon = -1) {\n  if (epsilon === -1) {\n    epsilon = tf.test_util.testEpsilon();\n  }\n  expectObjectsPredicate(\n      actual, expected, epsilon, (a, b) => areClose(a, b, epsilon));\n}\n\nfunction expectArraysPredicateFuzzy(actual, expected, predicate, errorRate) {\n  if (tf.util.isTypedArray(actual) == false ||\n      tf.util.isTypedArray(expected) == false) {\n    throw new Error(`Actual and Expected are not arrays.`);\n  }\n\n  if (actual.length !== expected.length) {\n    throw new Error(\n        `Arrays have different lengths actual: ${actual.length} vs ` +\n        `expected: ${expected.length}.\\n` +\n        `Actual:   ${actual}.\\n` +\n        `Expected: ${expected}.`);\n  }\n  let mismatchCount = 0;\n  for (let i = 0; i < expected.length; ++i) {\n    const a = actual[i];\n    const e = expected[i];\n    if (!predicate(a, e)) {\n      mismatchCount++;\n      const maxMismatch = Math.floor(errorRate * expected.length);\n      if (mismatchCount > maxMismatch) {\n        throw new Error(\n            `Arrays data has more than ${maxMismatch} differs from ${\n                expected.length}: actual[${i}] = ${a}, expected[${i}] = ${\n                e}.\\n` +\n            `Actual:   ${actual}.\\n` +\n            `Expected: ${expected}.`);\n      }\n    }\n  }\n}\n\n// TODO: support relative comparison for array.\nfunction expectArraysClose(actual, expected, epsilon, key) {\n  if (epsilon === -1) {\n    epsilon = tf.test_util.testEpsilon();\n  }\n\n  if (key == 'data') {\n    // For bodypix, the value in data memeber means \"1 for the pixels that are\n    // part of the person, and 0 otherwise\".\n    // So for these models, we don't expect all data is exactly match. Default\n    // use error rate 0.001 (1/1000).\n    const ERROR_RATE = 0.001;\n    return expectArraysPredicateFuzzy(\n        actual, expected, (a, b) => areClose(a, b, epsilon), ERROR_RATE);\n  } else {\n    return tf.test_util.expectArraysClose(actual, expected, epsilon);\n  }\n}",
    "repo": "tensorflow/tfjs",
    "path": "./datasets/diagrams-repos/tensorflow/tfjs/e2e/benchmarks/local-benchmark/util.js",
    "query": "What is the flow of data in the `getPredictionData` function when the output is an array of tensors?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'getPredictionData', 'node_id': 'getPredictionData', 'description': 'Processes output data, handling arrays of tensors', 'visibility': 'public', 'return_type': 'Promise<any>', 'params': 'output, needInfo = false', 'source_class_id': None}, {'type': 'function', 'name': 'convertTensorToData', 'node_id': 'convertTensorToData', 'description': 'Converts tensor to raw data and optionally includes tensor metadata', 'visibility': 'public', 'return_type': 'Promise<any>', 'params': 'tensor, needInfo = false', 'source_class_id': None}, {'type': 'entity', 'name': 'tensorData', 'node_id': 'tensorData', 'description': 'Raw tensor data after conversion', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'tensorMetadata', 'node_id': 'tensorMetadata', 'description': 'Shape and dtype information of tensor', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'getPredictionData', 'node_id_to': 'convertTensorToData', 'description': 'Converts each tensor in array to data'}, {'node_id_from': 'convertTensorToData', 'node_id_to': 'tensorData', 'description': 'Extracts raw data'}, {'node_id_from': 'convertTensorToData', 'node_id_to': 'tensorMetadata', 'description': 'Extracts metadata if needInfo is true'}], 'packages': [{'package_id': 'tensorProcessing', 'children': ['getPredictionData', 'convertTensorToData'], 'description': 'Functions for tensor data processing'}, {'package_id': 'tensorOutput', 'children': ['tensorData', 'tensorMetadata'], 'description': 'Tensor output data structures'}]}",
    "version": "medium",
    "text_answer": "When processing an array of tensors, getPredictionData iterates through each tensor in the array, converts each tensor to data using convertTensorToData (which extracts the raw data and optionally metadata), disposes the tensor, and returns the processed array.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nasync function convertTensorToData(tensor, needInfo = false) {\n  const data = await tensor.data();\n\n  tensor.dispose();\n  if (needInfo) {\n    return {value: data, shape: tensor.shape, dtype: tensor.dtype};\n  }\n  return data;\n}\n\nasync function getPredictionData(output, needInfo = false) {\n  if (output instanceof Promise) {\n    output = await output;\n  }\n\n  if (output instanceof tf.Tensor) {\n    output = [await convertTensorToData(output, needInfo)];\n  } else if (Array.isArray(output)) {\n    for (let i = 0; i < output.length; i++) {\n      if (output[i] instanceof tf.Tensor) {\n        output[i] = await convertTensorToData(output[i], needInfo);\n      }\n    }\n  } else if (output != null && typeof output === 'object') {\n    for (const property in output) {\n      if (output[property] instanceof tf.Tensor) {\n        output[property] =\n            await convertTensorToData(output[property], needInfo);\n      }\n    }\n  }\n  return output;\n}\n\nfunction printTime(elapsed) {\n  return elapsed.toFixed(1) + ' ms';\n}\n\nfunction printMemory(bytes) {\n  if (bytes < 1024) {\n    return bytes + ' B';\n  } else if (bytes < 1024 * 1024) {\n    return (bytes / 1024).toFixed(2) + ' KB';\n  } else {\n    return (bytes / (1024 * 1024)).toFixed(2) + ' MB';\n  }\n}\n\nfunction sleep(timeMs) {\n  return new Promise(resolve => setTimeout(resolve, timeMs));\n}\n\nfunction queryTimerIsEnabled() {\n  return _tfengine.ENV.getNumber(\n             'WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION') > 0;\n}\n\nfunction areClose(\n    a, e, epsilon, epsilonOfBigNumber = 0.1, relativeEpsilon = 0.01) {\n  if (!isFinite(a) && !isFinite(e)) {\n    return true;\n  } else if (isNaN(a) || isNaN(e)) {\n    return false;\n  }\n\n  const absoluteError = Math.abs(a - e);\n  if (Math.abs(a) >= 1) {\n    if ((absoluteError > epsilonOfBigNumber) ||\n        absoluteError / Math.min(Math.abs(a), Math.abs(e)) > relativeEpsilon) {\n      return false;\n    }\n  } else {\n    if (absoluteError > epsilon) {\n      return false;\n    }\n  }\n  return true;\n}\n\nfunction expectObjectsPredicate(actual, expected, epsilon, predicate) {\n  let actualKeys = Object.getOwnPropertyNames(actual);\n  let expectedKeys = Object.getOwnPropertyNames(expected);\n  if (actualKeys.length != expectedKeys.length) {\n    throw new Error(`Actual length ${\n        actualKeys.length} not equal Expected length ${expectedKeys.length}`);\n  }\n  for (let i = 0; i < actualKeys.length; i++) {\n    let key = actualKeys[i];\n    let isObject = typeof (actual[key]) === 'object' &&\n        typeof (expected[key]) === 'object';\n    let isArray = tf.util.isTypedArray(actual[key]) &&\n        tf.util.isTypedArray(expected[key]);\n    if (isArray) {\n      expectArraysClose(actual[key], expected[key], epsilon, key);\n    } else if (isObject) {\n      expectObjectsPredicate(actual[key], expected[key], epsilon, predicate);\n    } else {\n      if (!predicate(actual[key], expected[key])) {\n        throw new Error(`Objects differ: actual[${key}] = ${\n            JSON.stringify(actual[key])}, expected[${key}] = ${\n            JSON.stringify(expected[key])}!`);\n      }\n    }\n  }\n  return true;\n}\n\nfunction expectObjectsClose(actual, expected, epsilon = -1) {\n  if (epsilon === -1) {\n    epsilon = tf.test_util.testEpsilon();\n  }\n  expectObjectsPredicate(\n      actual, expected, epsilon, (a, b) => areClose(a, b, epsilon));\n}\n\nfunction expectArraysPredicateFuzzy(actual, expected, predicate, errorRate) {\n  if (tf.util.isTypedArray(actual) == false ||\n      tf.util.isTypedArray(expected) == false) {\n    throw new Error(`Actual and Expected are not arrays.`);\n  }\n\n  if (actual.length !== expected.length) {\n    throw new Error(\n        `Arrays have different lengths actual: ${actual.length} vs ` +\n        `expected: ${expected.length}.\\n` +\n        `Actual:   ${actual}.\\n` +\n        `Expected: ${expected}.`);\n  }\n  let mismatchCount = 0;\n  for (let i = 0; i < expected.length; ++i) {\n    const a = actual[i];\n    const e = expected[i];\n    if (!predicate(a, e)) {\n      mismatchCount++;\n      const maxMismatch = Math.floor(errorRate * expected.length);\n      if (mismatchCount > maxMismatch) {\n        throw new Error(\n            `Arrays data has more than ${maxMismatch} differs from ${\n                expected.length}: actual[${i}] = ${a}, expected[${i}] = ${\n                e}.\\n` +\n            `Actual:   ${actual}.\\n` +\n            `Expected: ${expected}.`);\n      }\n    }\n  }\n}\n\n// TODO: support relative comparison for array.\nfunction expectArraysClose(actual, expected, epsilon, key) {\n  if (epsilon === -1) {\n    epsilon = tf.test_util.testEpsilon();\n  }\n\n  if (key == 'data') {\n    // For bodypix, the value in data memeber means \"1 for the pixels that are\n    // part of the person, and 0 otherwise\".\n    // So for these models, we don't expect all data is exactly match. Default\n    // use error rate 0.001 (1/1000).\n    const ERROR_RATE = 0.001;\n    return expectArraysPredicateFuzzy(\n        actual, expected, (a, b) => areClose(a, b, epsilon), ERROR_RATE);\n  } else {\n    return tf.test_util.expectArraysClose(actual, expected, epsilon);\n  }\n}",
    "repo": "tensorflow/tfjs",
    "path": "./datasets/diagrams-repos/tensorflow/tfjs/e2e/benchmarks/local-benchmark/util.js",
    "query": "What is the flow of data in the `getPredictionData` function when the output is an array of tensors?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'tensor', 'node_id': 'tensor', 'description': 'Tensorflow Tensor class', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'getPredictionData', 'node_id': 'getPredictionData', 'description': 'Processes output data, handling arrays of tensors', 'visibility': 'public', 'return_type': 'Promise<any>', 'params': 'output, needInfo = false', 'source_class_id': None}, {'type': 'function', 'name': 'convertTensorToData', 'node_id': 'convertTensorToData', 'description': 'Converts tensor to raw data and optionally includes tensor metadata', 'visibility': 'public', 'return_type': 'Promise<any>', 'params': 'tensor, needInfo = false', 'source_class_id': None}, {'type': 'entity', 'name': 'tensorData', 'node_id': 'tensorData', 'description': 'Raw tensor data after conversion', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'tensorMetadata', 'node_id': 'tensorMetadata', 'description': 'Shape and dtype information of tensor', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'inputArray', 'node_id': 'inputArray', 'description': 'Input array of tensors', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'outputArray', 'node_id': 'outputArray', 'description': 'Processed array of tensor data', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'data', 'node_id': 'data', 'description': 'TensorFlow.js method to get tensor data', 'visibility': 'public', 'return_type': 'Promise<TypedArray>', 'params': '', 'source_class_id': 'tensor'}, {'type': 'method', 'name': 'dispose', 'node_id': 'dispose', 'description': 'Releases memory associated with tensor', 'visibility': 'public', 'return_type': 'void', 'params': '', 'source_class_id': 'tensor'}], 'edges': [{'node_id_from': 'inputArray', 'node_id_to': 'getPredictionData', 'description': 'Input for processing'}, {'node_id_from': 'getPredictionData', 'node_id_to': 'convertTensorToData', 'description': 'Converts each tensor in array to data'}, {'node_id_from': 'convertTensorToData', 'node_id_to': 'tensorData', 'description': 'Extracts raw data from tensor'}, {'node_id_from': 'convertTensorToData', 'node_id_to': 'tensorMetadata', 'description': 'Extracts metadata if needInfo is true'}, {'node_id_from': 'getPredictionData', 'node_id_to': 'outputArray', 'description': 'Returns processed data'}, {'node_id_from': 'inputArray', 'node_id_to': 'tensor', 'description': ''}, {'node_id_from': 'tensor', 'node_id_to': 'data', 'description': 'Tensor data'}, {'node_id_from': 'tensor', 'node_id_to': 'dispose', 'description': 'Cleans up tensor memory'}], 'packages': [{'package_id': 'tensorProcessing', 'children': ['getPredictionData', 'convertTensorToData'], 'description': 'Functions for tensor data processing'}, {'package_id': 'tensorOutput', 'children': ['tensorData', 'tensorMetadata'], 'description': 'Tensor output data structures'}, {'package_id': 'tensorOperations', 'children': ['tensor', 'data', 'dispose'], 'description': 'TensorFlow.js tensor operations'}, {'package_id': 'dataFlow', 'children': ['inputArray', 'outputArray'], 'description': 'Input and output data structures'}]}",
    "version": "full",
    "text_answer": "When processing an array of tensors, getPredictionData iterates through each tensor in the array, converts each tensor to data using convertTensorToData (which extracts the raw data and optionally metadata), disposes the tensor, and returns the processed array.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C",
    "code": "\n#include \"ble_l2cap_struct_serialization.h\"\n#include \"ble_struct_serialization.h\"\n#include \"ble_serialization.h\"\n#include \"app_util.h\"\n#include \"cond_field_serialization.h\"\n#include <string.h>\n\n#if defined(NRF_SD_BLE_API_VERSION) && NRF_SD_BLE_API_VERSION < 4\nuint32_t ble_l2cap_header_t_enc(void const * const p_void_struct,\n                                uint8_t * const    p_buf,\n                                uint32_t           buf_len,\n                                uint32_t * const   p_index)\n{\n    SER_STRUCT_ENC_BEGIN(ble_l2cap_header_t);\n\n    SER_PUSH_uint16(&p_struct->len);\n    SER_PUSH_uint16(&p_struct->cid);\n\n    SER_STRUCT_ENC_END;\n}\n\nuint32_t ble_l2cap_header_t_dec(uint8_t const * const p_buf,\n                                uint32_t              buf_len,\n                                uint32_t * const      p_index,\n                                void * const          p_void_struct)\n{\n    SER_STRUCT_DEC_BEGIN(ble_l2cap_header_t);\n\n    SER_PULL_uint16(&p_struct->len);\n    SER_PULL_uint16(&p_struct->cid);\n\n    SER_STRUCT_DEC_END;\n}\n\nuint32_t ble_l2cap_evt_rx_t_enc(void const * const p_void_struct,\n                                uint8_t * const    p_buf,\n                                uint32_t           buf_len,\n                                uint32_t * const   p_index)\n{\n    SER_STRUCT_ENC_BEGIN(ble_l2cap_evt_rx_t);\n\n    SER_PUSH_FIELD(&p_struct->header, ble_l2cap_header_t_enc);\n    SER_PUSH_uint8array(p_struct->data, p_struct->header.len);\n\n    SER_STRUCT_ENC_END;\n}\n\nuint32_t ble_l2cap_evt_rx_t_dec(uint8_t const * const p_buf,\n                                uint32_t              buf_len,\n                                uint32_t * const      p_index,\n                                uint32_t * const      p_ext_len,\n                                void * const          p_void_struct)\n{\n    SER_STRUCT_DEC_BEGIN(ble_l2cap_evt_rx_t);\n\n    SER_PULL_FIELD(&p_struct->header, ble_l2cap_header_t_dec);\n\n    uint32_t data_len = (SUB1(p_struct->header.len));\n    SER_ASSERT_LENGTH_LEQ(data_len, *p_ext_len);\n\n    SER_PULL_uint8array(p_struct->data, p_struct->header.len);\n\n    *p_ext_len = data_len;\n    SER_STRUCT_DEC_END;\n}\n#endif\n\n#if NRF_SD_BLE_API_VERSION >= 5\nuint32_t ble_l2cap_conn_cfg_t_enc(void const * const p_void_struct,\n                                  uint8_t * const    p_buf,\n                                  uint32_t           buf_len,\n                                  uint32_t * const   p_index)\n{\n    SER_STRUCT_ENC_BEGIN(ble_l2cap_conn_cfg_t);\n\n    SER_PUSH_uint16(&p_struct->rx_mps);\n    SER_PUSH_uint16(&p_struct->tx_mps);\n    SER_PUSH_uint8(&p_struct->rx_queue_size);\n    SER_PUSH_uint8(&p_struct->tx_queue_size);\n    SER_PUSH_uint8(&p_struct->ch_count);\n\n    SER_STRUCT_ENC_END;\n}\n\nuint32_t ble_l2cap_conn_cfg_t_dec(uint8_t const * const p_buf,\n                                  uint32_t              buf_len,\n                                  uint32_t * const      p_index,\n                                  void * const          p_void_struct)\n{\n    SER_STRUCT_DEC_BEGIN(ble_l2cap_conn_cfg_t);\n\n    SER_PULL_uint16(&p_struct->rx_mps);\n    SER_PULL_uint16(&p_struct->tx_mps);\n    SER_PULL_uint8(&p_struct->rx_queue_size);\n    SER_PULL_uint8(&p_struct->tx_queue_size);\n    SER_PULL_uint8(&p_struct->ch_count);\n\n    SER_STRUCT_DEC_END;\n}\n\nuint32_t ble_l2cap_ch_rx_params_t_enc(void const * const p_void_struct,\n                                      uint8_t * const    p_buf,\n                                      uint32_t           buf_len,\n                                      uint32_t * const   p_index)\n{\n    SER_STRUCT_ENC_BEGIN(ble_l2cap_ch_rx_params_t);\n\n    SER_PUSH_uint16(&p_struct->rx_mtu);\n    SER_PUSH_uint16(&p_struct->rx_mps);\n    SER_PUSH_uint16(&p_struct->sdu_buf.len);\n    SER_PUSH_uint32(&p_struct->sdu_buf.p_data);\n\n    SER_STRUCT_ENC_END;\n}\n\nuint32_t ble_l2cap_ch_rx_params_t_dec(uint8_t const * const p_buf,\n                                      uint32_t              buf_len,\n                                      uint32_t * const      p_index,\n                                      void * const          p_void_struct)\n{\n    SER_STRUCT_DEC_BEGIN(ble_l2cap_ch_rx_params_t);\n\n    SER_PULL_uint16(&p_struct->rx_mtu);\n    SER_PULL_uint16(&p_struct->rx_mps);\n    SER_PULL_uint16(&p_struct->sdu_buf.len);\n    SER_PULL_uint32(&p_struct->sdu_buf.p_data);\n\n    SER_STRUCT_DEC_END;\n}\n\nuint32_t ble_l2cap_ch_setup_params_t_enc(void const * const p_void_struct,\n                                         uint8_t * const    p_buf,\n                                         uint32_t           buf_len,\n                                         uint32_t * const   p_index)\n{\n    SER_STRUCT_ENC_BEGIN(ble_l2cap_ch_setup_params_t);\n\n    SER_PUSH_FIELD(&p_struct->rx_params, ble_l2cap_ch_rx_params_t_enc);\n    SER_PUSH_uint16(&p_struct->le_psm);\n    SER_PUSH_uint16(&p_struct->status);\n\n    SER_STRUCT_ENC_END;\n}\n\nuint32_t ble_l2cap_ch_setup_params_t_dec(uint8_t const * const p_buf,\n                                         uint32_t              buf_len,\n                                         uint32_t * const      p_index,\n                                         void * const          p_void_struct)\n{\n    SER_STRUCT_DEC_BEGIN(ble_l2cap_ch_setup_params_t);\n\n    SER_PULL_FIELD(&p_struct->rx_params, ble_l2cap_ch_rx_params_t_dec);\n    SER_PULL_uint16(&p_struct->le_psm);\n    SER_PULL_uint16(&p_struct->status);\n\n    SER_STRUCT_DEC_END;\n}\n\nuint32_t ble_l2cap_ch_tx_params_t_enc(void const * const p_void_struct,\n                                      uint8_t * const    p_buf,\n                                      uint32_t           buf_len,\n                                      uint32_t * const   p_index)\n{\n    SER_STRUCT_ENC_BEGIN(ble_l2cap_ch_tx_params_t);\n\n    SER_PUSH_uint16(&p_struct->tx_mtu);\n    SER_PUSH_uint16(&p_struct->peer_mps);\n    SER_PUSH_uint16(&p_struct->tx_mps);\n    SER_PUSH_uint16(&p_struct->credits);\n\n    SER_STRUCT_ENC_END;\n}\n\nuint32_t ble_l2cap_ch_tx_params_t_dec(uint8_t const * const p_buf,\n                                      uint32_t              buf_len,\n                                      uint32_t * const      p_index,\n                                      void * const          p_void_struct)\n{\n    SER_STRUCT_DEC_BEGIN(ble_l2cap_ch_tx_params_t);\n\n    SER_PULL_uint16(&p_struct->tx_mtu);\n    SER_PULL_uint16(&p_struct->peer_mps);\n    SER_PULL_uint16(&p_struct->tx_mps);\n    SER_PULL_uint16(&p_struct->credits);\n\n    SER_STRUCT_DEC_END;\n}\n#endif //NRF_SD_BLE_API_VERSION >= 5",
    "repo": "aws/amazon-freertos",
    "path": "./datasets/diagrams-repos/aws/amazon-freertos/vendors/nordic/nRF5_SDK_15.2.0/components/serialization/common/struct_ser/ble/ble_l2cap_struct_serialization.c",
    "query": "What is the dependency graph showing which serialization functions depend on which structures and macros?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'DecoderFunctions', 'node_id': 'DecoderFunctions', 'description': 'Decodes L2CAP structure', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'EncoderFunctions', 'node_id': 'EncoderFunctions', 'description': 'Encodes L2CAP structure', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SER_STRUCT_MACROS', 'node_id': 'SER_STRUCT_MACROS', 'description': 'Core serialization macros for encoding/decoding', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'EncoderFunctions', 'node_id_to': 'SER_STRUCT_MACROS', 'description': 'uses for encoding'}, {'node_id_from': 'DecoderFunctions', 'node_id_to': 'SER_STRUCT_MACROS', 'description': 'uses for decoding'}], 'packages': [{'package_id': 'l2cap_serialization', 'children': ['EncoderFunctions', 'DecoderFunctions', 'SER_STRUCT_MACROS'], 'description': 'L2CAP serialization functionality'}]}",
    "version": "minimal",
    "text_answer": "All serialization functions depend on SER_STRUCT_MACROS for basic encoding/decoding operations. The ble_l2cap_evt_rx_t functions depend on ble_l2cap_header_t functions, and ble_l2cap_ch_setup_params_t functions depend on ble_l2cap_ch_rx_params_t functions for nested structure serialization.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C",
    "code": "\n#include \"ble_l2cap_struct_serialization.h\"\n#include \"ble_struct_serialization.h\"\n#include \"ble_serialization.h\"\n#include \"app_util.h\"\n#include \"cond_field_serialization.h\"\n#include <string.h>\n\n#if defined(NRF_SD_BLE_API_VERSION) && NRF_SD_BLE_API_VERSION < 4\nuint32_t ble_l2cap_header_t_enc(void const * const p_void_struct,\n                                uint8_t * const    p_buf,\n                                uint32_t           buf_len,\n                                uint32_t * const   p_index)\n{\n    SER_STRUCT_ENC_BEGIN(ble_l2cap_header_t);\n\n    SER_PUSH_uint16(&p_struct->len);\n    SER_PUSH_uint16(&p_struct->cid);\n\n    SER_STRUCT_ENC_END;\n}\n\nuint32_t ble_l2cap_header_t_dec(uint8_t const * const p_buf,\n                                uint32_t              buf_len,\n                                uint32_t * const      p_index,\n                                void * const          p_void_struct)\n{\n    SER_STRUCT_DEC_BEGIN(ble_l2cap_header_t);\n\n    SER_PULL_uint16(&p_struct->len);\n    SER_PULL_uint16(&p_struct->cid);\n\n    SER_STRUCT_DEC_END;\n}\n\nuint32_t ble_l2cap_evt_rx_t_enc(void const * const p_void_struct,\n                                uint8_t * const    p_buf,\n                                uint32_t           buf_len,\n                                uint32_t * const   p_index)\n{\n    SER_STRUCT_ENC_BEGIN(ble_l2cap_evt_rx_t);\n\n    SER_PUSH_FIELD(&p_struct->header, ble_l2cap_header_t_enc);\n    SER_PUSH_uint8array(p_struct->data, p_struct->header.len);\n\n    SER_STRUCT_ENC_END;\n}\n\nuint32_t ble_l2cap_evt_rx_t_dec(uint8_t const * const p_buf,\n                                uint32_t              buf_len,\n                                uint32_t * const      p_index,\n                                uint32_t * const      p_ext_len,\n                                void * const          p_void_struct)\n{\n    SER_STRUCT_DEC_BEGIN(ble_l2cap_evt_rx_t);\n\n    SER_PULL_FIELD(&p_struct->header, ble_l2cap_header_t_dec);\n\n    uint32_t data_len = (SUB1(p_struct->header.len));\n    SER_ASSERT_LENGTH_LEQ(data_len, *p_ext_len);\n\n    SER_PULL_uint8array(p_struct->data, p_struct->header.len);\n\n    *p_ext_len = data_len;\n    SER_STRUCT_DEC_END;\n}\n#endif\n\n#if NRF_SD_BLE_API_VERSION >= 5\nuint32_t ble_l2cap_conn_cfg_t_enc(void const * const p_void_struct,\n                                  uint8_t * const    p_buf,\n                                  uint32_t           buf_len,\n                                  uint32_t * const   p_index)\n{\n    SER_STRUCT_ENC_BEGIN(ble_l2cap_conn_cfg_t);\n\n    SER_PUSH_uint16(&p_struct->rx_mps);\n    SER_PUSH_uint16(&p_struct->tx_mps);\n    SER_PUSH_uint8(&p_struct->rx_queue_size);\n    SER_PUSH_uint8(&p_struct->tx_queue_size);\n    SER_PUSH_uint8(&p_struct->ch_count);\n\n    SER_STRUCT_ENC_END;\n}\n\nuint32_t ble_l2cap_conn_cfg_t_dec(uint8_t const * const p_buf,\n                                  uint32_t              buf_len,\n                                  uint32_t * const      p_index,\n                                  void * const          p_void_struct)\n{\n    SER_STRUCT_DEC_BEGIN(ble_l2cap_conn_cfg_t);\n\n    SER_PULL_uint16(&p_struct->rx_mps);\n    SER_PULL_uint16(&p_struct->tx_mps);\n    SER_PULL_uint8(&p_struct->rx_queue_size);\n    SER_PULL_uint8(&p_struct->tx_queue_size);\n    SER_PULL_uint8(&p_struct->ch_count);\n\n    SER_STRUCT_DEC_END;\n}\n\nuint32_t ble_l2cap_ch_rx_params_t_enc(void const * const p_void_struct,\n                                      uint8_t * const    p_buf,\n                                      uint32_t           buf_len,\n                                      uint32_t * const   p_index)\n{\n    SER_STRUCT_ENC_BEGIN(ble_l2cap_ch_rx_params_t);\n\n    SER_PUSH_uint16(&p_struct->rx_mtu);\n    SER_PUSH_uint16(&p_struct->rx_mps);\n    SER_PUSH_uint16(&p_struct->sdu_buf.len);\n    SER_PUSH_uint32(&p_struct->sdu_buf.p_data);\n\n    SER_STRUCT_ENC_END;\n}\n\nuint32_t ble_l2cap_ch_rx_params_t_dec(uint8_t const * const p_buf,\n                                      uint32_t              buf_len,\n                                      uint32_t * const      p_index,\n                                      void * const          p_void_struct)\n{\n    SER_STRUCT_DEC_BEGIN(ble_l2cap_ch_rx_params_t);\n\n    SER_PULL_uint16(&p_struct->rx_mtu);\n    SER_PULL_uint16(&p_struct->rx_mps);\n    SER_PULL_uint16(&p_struct->sdu_buf.len);\n    SER_PULL_uint32(&p_struct->sdu_buf.p_data);\n\n    SER_STRUCT_DEC_END;\n}\n\nuint32_t ble_l2cap_ch_setup_params_t_enc(void const * const p_void_struct,\n                                         uint8_t * const    p_buf,\n                                         uint32_t           buf_len,\n                                         uint32_t * const   p_index)\n{\n    SER_STRUCT_ENC_BEGIN(ble_l2cap_ch_setup_params_t);\n\n    SER_PUSH_FIELD(&p_struct->rx_params, ble_l2cap_ch_rx_params_t_enc);\n    SER_PUSH_uint16(&p_struct->le_psm);\n    SER_PUSH_uint16(&p_struct->status);\n\n    SER_STRUCT_ENC_END;\n}\n\nuint32_t ble_l2cap_ch_setup_params_t_dec(uint8_t const * const p_buf,\n                                         uint32_t              buf_len,\n                                         uint32_t * const      p_index,\n                                         void * const          p_void_struct)\n{\n    SER_STRUCT_DEC_BEGIN(ble_l2cap_ch_setup_params_t);\n\n    SER_PULL_FIELD(&p_struct->rx_params, ble_l2cap_ch_rx_params_t_dec);\n    SER_PULL_uint16(&p_struct->le_psm);\n    SER_PULL_uint16(&p_struct->status);\n\n    SER_STRUCT_DEC_END;\n}\n\nuint32_t ble_l2cap_ch_tx_params_t_enc(void const * const p_void_struct,\n                                      uint8_t * const    p_buf,\n                                      uint32_t           buf_len,\n                                      uint32_t * const   p_index)\n{\n    SER_STRUCT_ENC_BEGIN(ble_l2cap_ch_tx_params_t);\n\n    SER_PUSH_uint16(&p_struct->tx_mtu);\n    SER_PUSH_uint16(&p_struct->peer_mps);\n    SER_PUSH_uint16(&p_struct->tx_mps);\n    SER_PUSH_uint16(&p_struct->credits);\n\n    SER_STRUCT_ENC_END;\n}\n\nuint32_t ble_l2cap_ch_tx_params_t_dec(uint8_t const * const p_buf,\n                                      uint32_t              buf_len,\n                                      uint32_t * const      p_index,\n                                      void * const          p_void_struct)\n{\n    SER_STRUCT_DEC_BEGIN(ble_l2cap_ch_tx_params_t);\n\n    SER_PULL_uint16(&p_struct->tx_mtu);\n    SER_PULL_uint16(&p_struct->peer_mps);\n    SER_PULL_uint16(&p_struct->tx_mps);\n    SER_PULL_uint16(&p_struct->credits);\n\n    SER_STRUCT_DEC_END;\n}\n#endif //NRF_SD_BLE_API_VERSION >= 5",
    "repo": "aws/amazon-freertos",
    "path": "./datasets/diagrams-repos/aws/amazon-freertos/vendors/nordic/nRF5_SDK_15.2.0/components/serialization/common/struct_ser/ble/ble_l2cap_struct_serialization.c",
    "query": "What is the dependency graph showing which serialization functions depend on which structures and macros?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'ble_l2cap_header_t_enc', 'node_id': 'ble_l2cap_header_t_enc', 'description': 'Encodes L2CAP header structure', 'visibility': 'public', 'return_type': 'uint32_t', 'params': '(void const * const, uint8_t * const, uint32_t, uint32_t * const)', 'source_class_id': None}, {'type': 'function', 'name': 'ble_l2cap_header_t_dec', 'node_id': 'ble_l2cap_header_t_dec', 'description': 'Decodes L2CAP header structure', 'visibility': 'public', 'return_type': 'uint32_t', 'params': '(uint8_t const * const, uint32_t, uint32_t * const, void * const)', 'source_class_id': None}, {'type': 'function', 'name': 'ble_l2cap_evt_rx_t_enc', 'node_id': 'ble_l2cap_evt_rx_t_enc', 'description': 'Encodes L2CAP receive event structure', 'visibility': 'public', 'return_type': 'uint32_t', 'params': '(void const * const, uint8_t * const, uint32_t, uint32_t * const)', 'source_class_id': None}, {'type': 'function', 'name': 'ble_l2cap_evt_rx_t_dec', 'node_id': 'ble_l2cap_evt_rx_t_dec', 'description': 'Decodes L2CAP receive event structure', 'visibility': 'public', 'return_type': 'uint32_t', 'params': '(uint8_t const * const, uint32_t, uint32_t * const, uint32_t * const, void * const)', 'source_class_id': None}, {'type': 'function', 'name': 'ble_l2cap_conn_cfg_t_enc', 'node_id': 'ble_l2cap_conn_cfg_t_enc', 'description': 'Encodes L2CAP connection configuration', 'visibility': 'public', 'return_type': 'uint32_t', 'params': '(void const * const, uint8_t * const, uint32_t, uint32_t * const)', 'source_class_id': None}, {'type': 'function', 'name': 'ble_l2cap_conn_cfg_t_dec', 'node_id': 'ble_l2cap_conn_cfg_t_dec', 'description': 'Decodes L2CAP connection configuration', 'visibility': 'public', 'return_type': 'uint32_t', 'params': '(uint8_t const * const, uint32_t, uint32_t * const, void * const)', 'source_class_id': None}, {'type': 'function', 'name': 'ble_l2cap_ch_rx_params_t_enc', 'node_id': 'ble_l2cap_ch_rx_params_t_enc', 'description': 'Encodes L2CAP channel receive parameters', 'visibility': 'public', 'return_type': 'uint32_t', 'params': '(void const * const, uint8_t * const, uint32_t, uint32_t * const)', 'source_class_id': None}, {'type': 'function', 'name': 'ble_l2cap_ch_rx_params_t_dec', 'node_id': 'ble_l2cap_ch_rx_params_t_dec', 'description': 'Decodes L2CAP channel receive parameters', 'visibility': 'public', 'return_type': 'uint32_t', 'params': '(uint8_t const * const, uint32_t, uint32_t * const, void * const)', 'source_class_id': None}, {'type': 'function', 'name': 'ble_l2cap_ch_setup_params_t_enc', 'node_id': 'ble_l2cap_ch_setup_params_t_enc', 'description': 'Encodes L2CAP channel setup parameters', 'visibility': 'public', 'return_type': 'uint32_t', 'params': '(void const * const, uint8_t * const, uint32_t, uint32_t * const)', 'source_class_id': None}, {'type': 'function', 'name': 'ble_l2cap_ch_setup_params_t_dec', 'node_id': 'ble_l2cap_ch_setup_params_t_dec', 'description': 'Decodes L2CAP channel setup parameters', 'visibility': 'public', 'return_type': 'uint32_t', 'params': '(uint8_t const * const, uint32_t, uint32_t * const, void * const)', 'source_class_id': None}, {'type': 'function', 'name': 'ble_l2cap_ch_tx_params_t_enc', 'node_id': 'ble_l2cap_ch_tx_params_t_enc', 'description': 'Encodes L2CAP channel transmit parameters', 'visibility': 'public', 'return_type': 'uint32_t', 'params': '(void const * const, uint8_t * const, uint32_t, uint32_t * const)', 'source_class_id': None}, {'type': 'function', 'name': 'ble_l2cap_ch_tx_params_t_dec', 'node_id': 'ble_l2cap_ch_tx_params_t_dec', 'description': 'Decodes L2CAP channel transmit parameters', 'visibility': 'public', 'return_type': 'uint32_t', 'params': '(uint8_t const * const, uint32_t, uint32_t * const, void * const)', 'source_class_id': None}, {'type': 'entity', 'name': 'SER_STRUCT_MACROS', 'node_id': 'SER_STRUCT_MACROS', 'description': 'Core serialization macros for encoding/decoding', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SER_STRUCT_ENC_BEGIN', 'node_id': 'SER_STRUCT_ENC_BEGIN', 'description': 'Serialization macros for encoding', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SER_PUSH_uint16', 'node_id': 'SER_PUSH_uint16', 'description': 'Serializes a 16-bit unsigned integer to the buffer', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SER_PUSH_uint8', 'node_id': 'SER_PUSH_uint8', 'description': 'Serializes an 8-bit unsigned integer to the buffer', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SER_PUSH_FIELD', 'node_id': 'SER_PUSH_FIELD', 'description': 'Serializes a nested structure field using the provided encoder function', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SER_PUSH_uint8array', 'node_id': 'SER_PUSH_uint8array', 'description': 'Serializes an array of 8-bit unsigned integers to the buffer', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SER_PUSH_uint32', 'node_id': 'SER_PUSH_uint32', 'description': 'Serializes a 32-bit unsigned integer to the buffer', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SER_STRUCT_ENC_END', 'node_id': 'SER_STRUCT_ENC_END', 'description': 'Finalizes the encoding of a structure', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SER_STRUCT_DEC_BEGIN', 'node_id': 'SER_STRUCT_DEC_BEGIN', 'description': 'Begins the decoding of a structure, initializing necessary variables', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SER_PULL_uint16', 'node_id': 'SER_PULL_uint16', 'description': 'Deserializes a 16-bit unsigned integer from the buffer', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SER_PULL_uint8', 'node_id': 'SER_PULL_uint8', 'description': 'Deserializes an 8-bit unsigned integer from the buffer', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SER_PULL_FIELD', 'node_id': 'SER_PULL_FIELD', 'description': 'Deserializes a nested structure field using the provided decoder function', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SER_PULL_uint8array', 'node_id': 'SER_PULL_uint8array', 'description': 'Deserializes an array of 8-bit unsigned integers from the buffer', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SER_PULL_uint32', 'node_id': 'SER_PULL_uint32', 'description': 'Deserializes a 32-bit unsigned integer from the buffer', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SER_STRUCT_DEC_END', 'node_id': 'SER_STRUCT_DEC_END', 'description': 'Finalizes the decoding of a structure', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SER_ASSERT_LENGTH_LEQ', 'node_id': 'SER_ASSERT_LENGTH_LEQ', 'description': 'Asserts that a length is less than or equal to a maximum value', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SUB1', 'node_id': 'SUB1', 'description': 'Subtracts 1 from a value', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'ble_l2cap_evt_rx_t_enc', 'node_id_to': 'ble_l2cap_header_t_enc', 'description': 'uses for header encoding'}, {'node_id_from': 'ble_l2cap_evt_rx_t_dec', 'node_id_to': 'ble_l2cap_header_t_dec', 'description': 'uses for header decoding'}, {'node_id_from': 'ble_l2cap_ch_setup_params_t_enc', 'node_id_to': 'ble_l2cap_ch_rx_params_t_enc', 'description': 'uses for rx params encoding'}, {'node_id_from': 'ble_l2cap_ch_setup_params_t_dec', 'node_id_to': 'ble_l2cap_ch_rx_params_t_dec', 'description': 'uses for rx params decoding'}, {'node_id_from': 'ble_l2cap_header_t_enc', 'node_id_to': 'SER_STRUCT_MACROS', 'description': 'uses for encoding'}, {'node_id_from': 'ble_l2cap_header_t_dec', 'node_id_to': 'SER_STRUCT_MACROS', 'description': 'uses for decoding'}, {'node_id_from': 'ble_l2cap_conn_cfg_t_enc', 'node_id_to': 'SER_STRUCT_MACROS', 'description': 'uses for encoding'}, {'node_id_from': 'ble_l2cap_conn_cfg_t_dec', 'node_id_to': 'SER_STRUCT_MACROS', 'description': 'uses for decoding'}, {'node_id_from': 'ble_l2cap_ch_rx_params_t_enc', 'node_id_to': 'SER_STRUCT_MACROS', 'description': 'uses for encoding'}, {'node_id_from': 'ble_l2cap_ch_rx_params_t_dec', 'node_id_to': 'SER_STRUCT_MACROS', 'description': 'uses for decoding'}, {'node_id_from': 'ble_l2cap_ch_setup_params_t_enc', 'node_id_to': 'SER_STRUCT_MACROS', 'description': 'uses for encoding'}, {'node_id_from': 'ble_l2cap_ch_setup_params_t_dec', 'node_id_to': 'SER_STRUCT_MACROS', 'description': 'uses for decoding'}, {'node_id_from': 'ble_l2cap_ch_tx_params_t_enc', 'node_id_to': 'SER_STRUCT_MACROS', 'description': 'uses for encoding'}, {'node_id_from': 'ble_l2cap_ch_tx_params_t_dec', 'node_id_to': 'SER_STRUCT_MACROS', 'description': 'uses for decoding'}, {'node_id_from': 'SER_STRUCT_MACROS', 'node_id_to': 'SER_STRUCT_ENC_BEGIN', 'description': 'defines encoding initialization'}, {'node_id_from': 'SER_STRUCT_MACROS', 'node_id_to': 'SER_PUSH_uint16', 'description': 'defines uint16 serialization'}, {'node_id_from': 'SER_STRUCT_MACROS', 'node_id_to': 'SER_PUSH_uint8', 'description': 'defines uint8 serialization'}, {'node_id_from': 'SER_STRUCT_MACROS', 'node_id_to': 'SER_PUSH_FIELD', 'description': 'defines nested field serialization'}, {'node_id_from': 'SER_STRUCT_MACROS', 'node_id_to': 'SER_PUSH_uint8array', 'description': 'defines uint8 array serialization'}, {'node_id_from': 'SER_STRUCT_MACROS', 'node_id_to': 'SER_PUSH_uint32', 'description': 'defines uint32 serialization'}, {'node_id_from': 'SER_STRUCT_MACROS', 'node_id_to': 'SER_STRUCT_ENC_END', 'description': 'defines encoding finalization'}, {'node_id_from': 'SER_STRUCT_MACROS', 'node_id_to': 'SER_STRUCT_DEC_BEGIN', 'description': 'defines decoding initialization'}, {'node_id_from': 'SER_STRUCT_MACROS', 'node_id_to': 'SER_PULL_uint16', 'description': 'defines uint16 deserialization'}, {'node_id_from': 'SER_STRUCT_MACROS', 'node_id_to': 'SER_PULL_uint8', 'description': 'defines uint8 deserialization'}, {'node_id_from': 'SER_STRUCT_MACROS', 'node_id_to': 'SER_PULL_FIELD', 'description': 'defines nested field deserialization'}, {'node_id_from': 'SER_STRUCT_MACROS', 'node_id_to': 'SER_PULL_uint8array', 'description': 'defines uint8 array deserialization'}, {'node_id_from': 'SER_STRUCT_MACROS', 'node_id_to': 'SER_PULL_uint32', 'description': 'defines uint32 deserialization'}, {'node_id_from': 'SER_STRUCT_MACROS', 'node_id_to': 'SER_STRUCT_DEC_END', 'description': 'defines decoding finalization'}, {'node_id_from': 'SER_STRUCT_MACROS', 'node_id_to': 'SER_ASSERT_LENGTH_LEQ', 'description': 'defines length assertion'}, {'node_id_from': 'SER_STRUCT_MACROS', 'node_id_to': 'SUB1', 'description': 'defines subtraction by 1'}], 'packages': [{'package_id': 'l2cap_serialization', 'children': ['basic_serialization', 'channel_serialization'], 'description': 'L2CAP serialization functionality'}, {'package_id': 'basic_serialization', 'children': ['ble_l2cap_header_t_enc', 'ble_l2cap_header_t_dec', 'ble_l2cap_evt_rx_t_enc', 'ble_l2cap_evt_rx_t_dec', 'ble_l2cap_conn_cfg_t_enc', 'ble_l2cap_conn_cfg_t_dec'], 'description': 'Basic L2CAP structure serialization'}, {'package_id': 'channel_serialization', 'children': ['ble_l2cap_ch_rx_params_t_enc', 'ble_l2cap_ch_rx_params_t_dec', 'ble_l2cap_ch_setup_params_t_enc', 'ble_l2cap_ch_setup_params_t_dec', 'ble_l2cap_ch_tx_params_t_enc', 'ble_l2cap_ch_tx_params_t_dec'], 'description': 'L2CAP channel-related structure serialization'}]}",
    "version": "full",
    "text_answer": "All serialization functions depend on SER_STRUCT_MACROS for basic encoding/decoding operations. The ble_l2cap_evt_rx_t functions depend on ble_l2cap_header_t functions, and ble_l2cap_ch_setup_params_t functions depend on ble_l2cap_ch_rx_params_t functions for nested structure serialization.",
    "possible_version": [
      "medium",
      "full"
    ]
  },
  {
    "language": "Scala",
    "code": "\npackage org.apache.openwhisk.core.monitoring.metrics\n\nimport java.io.StringWriter\nimport java.util\nimport java.util.concurrent.TimeUnit\n\nimport akka.event.slf4j.SLF4JLogging\nimport akka.http.scaladsl.model.{HttpEntity, MessageEntity}\nimport akka.stream.scaladsl.{Concat, Source}\nimport akka.util.ByteString\nimport io.prometheus.client.exporter.common.TextFormat\nimport io.prometheus.client.{CollectorRegistry, Counter, Gauge, Histogram}\nimport kamon.prometheus.PrometheusReporter\nimport org.apache.openwhisk.core.connector.{Activation, Metric}\nimport org.apache.openwhisk.core.entity.{ActivationEntityLimit, ActivationResponse}\nimport org.apache.openwhisk.core.monitoring.metrics.OpenWhiskEvents.MetricConfig\n\nimport scala.collection.JavaConverters._\nimport scala.collection.concurrent.TrieMap\nimport scala.concurrent.duration.Duration\n\ntrait PrometheusMetricNames extends MetricNames {\n  val activationMetric = \"openwhisk_action_activations_total\"\n  val coldStartMetric = \"openwhisk_action_coldStarts_total\"\n  val waitTimeMetric = \"openwhisk_action_waitTime_seconds\"\n  val initTimeMetric = \"openwhisk_action_initTime_seconds\"\n  val durationMetric = \"openwhisk_action_duration_seconds\"\n  val responseSizeMetric = \"openwhisk_action_response_size_bytes\"\n  val statusMetric = \"openwhisk_action_status\"\n  val memoryMetric = \"openwhisk_action_memory\"\n  val userDefinedStatusCodeMetric = \"openwhisk_action_status_code\"\n\n  val concurrentLimitMetric = \"openwhisk_action_limit_concurrent_total\"\n  val timedLimitMetric = \"openwhisk_action_limit_timed_total\"\n}\n\ncase class PrometheusRecorder(kamon: PrometheusReporter, config: MetricConfig)\n    extends MetricRecorder\n    with PrometheusExporter\n    with SLF4JLogging {\n  private val activationMetrics = new TrieMap[String, ActivationPromMetrics]\n  private val limitMetrics = new TrieMap[String, LimitPromMetrics]\n  private val promMetrics = PrometheusMetrics()\n\n  override def processActivation(activation: Activation, initiator: String): Unit = {\n    lookup(activation, initiator).record(activation, initiator)\n  }\n\n  override def processMetric(metric: Metric, initiator: String): Unit = {\n    val limitMetric = limitMetrics.getOrElseUpdate(initiator, LimitPromMetrics(initiator))\n    limitMetric.record(metric)\n  }\n\n  override def getReport(): MessageEntity =\n    HttpEntity(PrometheusExporter.textV4, createSource())\n\n  private def lookup(activation: Activation, initiator: String): ActivationPromMetrics = {\n    //TODO Unregister unused actions\n    val name = activation.name\n    val kind = activation.kind\n    val memory = activation.memory.toString\n    val namespace = activation.namespace\n    val action = activation.action\n    activationMetrics.getOrElseUpdate(name, {\n      ActivationPromMetrics(namespace, action, kind, memory, initiator)\n    })\n  }\n\n  case class LimitPromMetrics(namespace: String) {\n    private val concurrentLimit = promMetrics.concurrentLimitCounter.labels(namespace)\n    private val timedLimit = promMetrics.timedLimitCounter.labels(namespace)\n\n    def record(m: Metric): Unit = {\n      m.metricName match {\n        case \"ConcurrentRateLimit\"   => concurrentLimit.inc()\n        case \"TimedRateLimit\"        => timedLimit.inc()\n        case \"ConcurrentInvocations\" => //TODO Handle ConcurrentInvocations\n        case x                       => log.warn(s\"Unknown limit $x\")\n      }\n    }\n  }\n\n  case class ActivationPromMetrics(namespace: String,\n                                   action: String,\n                                   kind: String,\n                                   memory: String,\n                                   initiatorNamespace: String) {\n\n    private val activations = promMetrics.activationCounter.labels(namespace, initiatorNamespace, action, kind, memory)\n    private val coldStarts = promMetrics.coldStartCounter.labels(namespace, initiatorNamespace, action)\n    private val waitTime = promMetrics.waitTimeHisto.labels(namespace, initiatorNamespace, action)\n    private val initTime = promMetrics.initTimeHisto.labels(namespace, initiatorNamespace, action)\n    private val duration = promMetrics.durationHisto.labels(namespace, initiatorNamespace, action)\n    private val responseSize = promMetrics.responseSizeHisto.labels(namespace, initiatorNamespace, action)\n\n    private val gauge = promMetrics.memoryGauge.labels(namespace, initiatorNamespace, action)\n\n    private val statusSuccess =\n      promMetrics.statusCounter.labels(namespace, initiatorNamespace, action, ActivationResponse.statusSuccess)\n    private val statusApplicationError =\n      promMetrics.statusCounter.labels(namespace, initiatorNamespace, action, ActivationResponse.statusApplicationError)\n    private val statusDeveloperError =\n      promMetrics.statusCounter.labels(namespace, initiatorNamespace, action, ActivationResponse.statusDeveloperError)\n    private val statusInternalError =\n      promMetrics.statusCounter.labels(namespace, initiatorNamespace, action, ActivationResponse.statusWhiskError)\n\n    def record(a: Activation, initiator: String): Unit = {\n      recordActivation(a, initiator)\n    }\n\n    def recordActivation(a: Activation, initiator: String): Unit = {\n      gauge.set(a.memory)\n\n      activations.inc()\n\n      if (a.isColdStart) {\n        coldStarts.inc()\n        initTime.observe(seconds(a.initTime))\n      }\n\n      //waitTime may be zero for activations which are part of sequence\n      waitTime.observe(seconds(a.waitTime))\n      duration.observe(seconds(a.duration))\n\n      a.status match {\n        case ActivationResponse.statusSuccess          => statusSuccess.inc()\n        case ActivationResponse.statusApplicationError => statusApplicationError.inc()\n        case ActivationResponse.statusDeveloperError   => statusDeveloperError.inc()\n        case ActivationResponse.statusWhiskError       => statusInternalError.inc()\n        case x                                         => promMetrics.statusCounter.labels(namespace, initiator, action, x).inc()\n      }\n\n      a.size.foreach(responseSize.observe(_))\n      a.userDefinedStatusCode.foreach(value =>\n        promMetrics.userDefinedStatusCodeCounter.labels(namespace, initiator, action, value.toString).inc())\n    }\n  }\n\n  case class PrometheusMetrics() extends PrometheusMetricNames {\n\n    private val namespace = config.renameTags.getOrElse(actionNamespace, actionNamespace)\n    private val initiator = config.renameTags.getOrElse(initiatorNamespace, initiatorNamespace)\n    private val action = config.renameTags.getOrElse(actionName, actionName)\n    private val kind = config.renameTags.getOrElse(actionKind, actionKind)\n    private val memory = config.renameTags.getOrElse(actionMemory, actionMemory)\n    private val status = config.renameTags.getOrElse(actionStatus, actionStatus)\n    private val statusCode = config.renameTags.getOrElse(userDefinedStatusCode, userDefinedStatusCode)\n\n    val activationCounter =\n      counter(activationMetric, \"Activation Count\", namespace, initiator, action, kind, memory)\n\n    val coldStartCounter =\n      counter(coldStartMetric, \"Cold start counts\", namespace, initiator, action)\n\n    val statusCounter =\n      counter(statusMetric, \"Activation failure status type\", namespace, initiator, action, status)\n\n    val userDefinedStatusCodeCounter =\n      counter(\n        userDefinedStatusCodeMetric,\n        \"status code returned in action result response set by developer\",\n        namespace,\n        initiator,\n        action,\n        statusCode)\n\n    val waitTimeHisto =\n      histogram(waitTimeMetric, \"Internal system hold time\", namespace, initiator, action)\n\n    val initTimeHisto =\n      histogram(initTimeMetric, \"Time it took to initialize an action, e.g. docker init\", namespace, initiator, action)\n\n    val durationHisto =\n      histogram(durationMetric, \"Actual time the action code was running\", namespace, initiator, action)\n\n    val responseSizeHisto =\n      Histogram\n        .build()\n        .name(responseSizeMetric)\n        .help(\"Activation Response size\")\n        .labelNames(namespace, initiator, action)\n        .linearBuckets(0, ActivationEntityLimit.MAX_ACTIVATION_ENTITY_LIMIT.toBytes.toDouble, 10)\n        .register()\n\n    val memoryGauge =\n      gauge(memoryMetric, \"Memory consumption of the action containers\", namespace, initiator, action)\n\n    val concurrentLimitCounter =\n      counter(concurrentLimitMetric, \"a user has exceeded its limit for concurrent invocations\", namespace)\n\n    val timedLimitCounter =\n      counter(timedLimitMetric, \"the user has reached its per minute limit for the number of invocations\", namespace)\n\n    private def counter(name: String, help: String, tags: String*) =\n      Counter\n        .build()\n        .name(name)\n        .help(help)\n        .labelNames(tags: _*)\n        .register()\n\n    private def gauge(name: String, help: String, tags: String*) =\n      Gauge\n        .build()\n        .name(name)\n        .help(help)\n        .labelNames(tags: _*)\n        .register()\n\n    private def histogram(name: String, help: String, tags: String*) =\n      Histogram\n        .build()\n        .name(name)\n        .help(help)\n        .labelNames(tags: _*)\n        .register()\n  }\n\n  //Returns a floating point number\n  private def seconds(time: Duration): Double = time.toUnit(TimeUnit.SECONDS)\n\n  private def createSource() =\n    Source.combine(createJavaClientSource(), createKamonSource())(Concat(_)).map(ByteString(_))\n\n  /**\n   * Enables streaming the prometheus metric data without building the whole report in memory\n   */\n  private def createJavaClientSource() =\n    Source\n      .fromIterator(() => CollectorRegistry.defaultRegistry.metricFamilySamples().asScala)\n      .map { sample =>\n        //Stream string representation of one sample at a time\n        val writer = new StringWriter()\n        TextFormat.write004(writer, singletonEnumeration(sample))\n        writer.toString\n      }\n\n  private def createKamonSource() = Source.single(kamon.scrapeData())\n\n  private def singletonEnumeration[A](value: A) = new util.Enumeration[A] {\n    private var done = false\n    override def hasMoreElements: Boolean = !done\n    override def nextElement(): A = {\n      if (done) throw new NoSuchElementException\n      done = true\n      value\n    }\n  }\n}",
    "repo": "apache/openwhisk",
    "path": "./datasets/diagrams-repos/apache/openwhisk/core/monitoring/user-events/src/main/scala/org/apache/openwhisk/core/monitoring/metrics/PrometheusRecorder.scala",
    "query": "What is the structure of the metric names and labels used in PrometheusMetrics?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'PrometheusMetricNames', 'node_id': 'PrometheusMetricNames', 'description': 'Trait defining metric name constants for Prometheus metrics', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'PrometheusMetrics', 'node_id': 'PrometheusMetrics', 'description': 'Class implementing metric collectors with labels', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'MetricLabels', 'node_id': 'MetricLabels', 'description': 'Common label names used across metrics', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'MetricTypes', 'node_id': 'MetricTypes', 'description': 'Different types of metrics', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'PrometheusMetrics', 'node_id_to': 'PrometheusMetricNames', 'description': 'extends'}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'MetricLabels', 'description': 'uses'}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'MetricTypes', 'description': 'uses'}], 'packages': [{'package_id': 'metrics', 'children': ['PrometheusMetricNames', 'PrometheusMetrics', 'MetricLabels', 'MetricTypes'], 'description': 'Core metrics components'}]}",
    "version": "minimal",
    "text_answer": "PrometheusMetrics defines a set of Prometheus metric collectors (counters, histograms, and gauges) that track various OpenWhisk action metrics. Each metric is labeled with namespace, initiator, and action name, with some metrics having additional labels like kind and memory. The metric names are defined in PrometheusMetricNames trait and include metrics for activations, cold starts, wait time, duration, and memory usage.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Scala",
    "code": "\npackage org.apache.openwhisk.core.monitoring.metrics\n\nimport java.io.StringWriter\nimport java.util\nimport java.util.concurrent.TimeUnit\n\nimport akka.event.slf4j.SLF4JLogging\nimport akka.http.scaladsl.model.{HttpEntity, MessageEntity}\nimport akka.stream.scaladsl.{Concat, Source}\nimport akka.util.ByteString\nimport io.prometheus.client.exporter.common.TextFormat\nimport io.prometheus.client.{CollectorRegistry, Counter, Gauge, Histogram}\nimport kamon.prometheus.PrometheusReporter\nimport org.apache.openwhisk.core.connector.{Activation, Metric}\nimport org.apache.openwhisk.core.entity.{ActivationEntityLimit, ActivationResponse}\nimport org.apache.openwhisk.core.monitoring.metrics.OpenWhiskEvents.MetricConfig\n\nimport scala.collection.JavaConverters._\nimport scala.collection.concurrent.TrieMap\nimport scala.concurrent.duration.Duration\n\ntrait PrometheusMetricNames extends MetricNames {\n  val activationMetric = \"openwhisk_action_activations_total\"\n  val coldStartMetric = \"openwhisk_action_coldStarts_total\"\n  val waitTimeMetric = \"openwhisk_action_waitTime_seconds\"\n  val initTimeMetric = \"openwhisk_action_initTime_seconds\"\n  val durationMetric = \"openwhisk_action_duration_seconds\"\n  val responseSizeMetric = \"openwhisk_action_response_size_bytes\"\n  val statusMetric = \"openwhisk_action_status\"\n  val memoryMetric = \"openwhisk_action_memory\"\n  val userDefinedStatusCodeMetric = \"openwhisk_action_status_code\"\n\n  val concurrentLimitMetric = \"openwhisk_action_limit_concurrent_total\"\n  val timedLimitMetric = \"openwhisk_action_limit_timed_total\"\n}\n\ncase class PrometheusRecorder(kamon: PrometheusReporter, config: MetricConfig)\n    extends MetricRecorder\n    with PrometheusExporter\n    with SLF4JLogging {\n  private val activationMetrics = new TrieMap[String, ActivationPromMetrics]\n  private val limitMetrics = new TrieMap[String, LimitPromMetrics]\n  private val promMetrics = PrometheusMetrics()\n\n  override def processActivation(activation: Activation, initiator: String): Unit = {\n    lookup(activation, initiator).record(activation, initiator)\n  }\n\n  override def processMetric(metric: Metric, initiator: String): Unit = {\n    val limitMetric = limitMetrics.getOrElseUpdate(initiator, LimitPromMetrics(initiator))\n    limitMetric.record(metric)\n  }\n\n  override def getReport(): MessageEntity =\n    HttpEntity(PrometheusExporter.textV4, createSource())\n\n  private def lookup(activation: Activation, initiator: String): ActivationPromMetrics = {\n    //TODO Unregister unused actions\n    val name = activation.name\n    val kind = activation.kind\n    val memory = activation.memory.toString\n    val namespace = activation.namespace\n    val action = activation.action\n    activationMetrics.getOrElseUpdate(name, {\n      ActivationPromMetrics(namespace, action, kind, memory, initiator)\n    })\n  }\n\n  case class LimitPromMetrics(namespace: String) {\n    private val concurrentLimit = promMetrics.concurrentLimitCounter.labels(namespace)\n    private val timedLimit = promMetrics.timedLimitCounter.labels(namespace)\n\n    def record(m: Metric): Unit = {\n      m.metricName match {\n        case \"ConcurrentRateLimit\"   => concurrentLimit.inc()\n        case \"TimedRateLimit\"        => timedLimit.inc()\n        case \"ConcurrentInvocations\" => //TODO Handle ConcurrentInvocations\n        case x                       => log.warn(s\"Unknown limit $x\")\n      }\n    }\n  }\n\n  case class ActivationPromMetrics(namespace: String,\n                                   action: String,\n                                   kind: String,\n                                   memory: String,\n                                   initiatorNamespace: String) {\n\n    private val activations = promMetrics.activationCounter.labels(namespace, initiatorNamespace, action, kind, memory)\n    private val coldStarts = promMetrics.coldStartCounter.labels(namespace, initiatorNamespace, action)\n    private val waitTime = promMetrics.waitTimeHisto.labels(namespace, initiatorNamespace, action)\n    private val initTime = promMetrics.initTimeHisto.labels(namespace, initiatorNamespace, action)\n    private val duration = promMetrics.durationHisto.labels(namespace, initiatorNamespace, action)\n    private val responseSize = promMetrics.responseSizeHisto.labels(namespace, initiatorNamespace, action)\n\n    private val gauge = promMetrics.memoryGauge.labels(namespace, initiatorNamespace, action)\n\n    private val statusSuccess =\n      promMetrics.statusCounter.labels(namespace, initiatorNamespace, action, ActivationResponse.statusSuccess)\n    private val statusApplicationError =\n      promMetrics.statusCounter.labels(namespace, initiatorNamespace, action, ActivationResponse.statusApplicationError)\n    private val statusDeveloperError =\n      promMetrics.statusCounter.labels(namespace, initiatorNamespace, action, ActivationResponse.statusDeveloperError)\n    private val statusInternalError =\n      promMetrics.statusCounter.labels(namespace, initiatorNamespace, action, ActivationResponse.statusWhiskError)\n\n    def record(a: Activation, initiator: String): Unit = {\n      recordActivation(a, initiator)\n    }\n\n    def recordActivation(a: Activation, initiator: String): Unit = {\n      gauge.set(a.memory)\n\n      activations.inc()\n\n      if (a.isColdStart) {\n        coldStarts.inc()\n        initTime.observe(seconds(a.initTime))\n      }\n\n      //waitTime may be zero for activations which are part of sequence\n      waitTime.observe(seconds(a.waitTime))\n      duration.observe(seconds(a.duration))\n\n      a.status match {\n        case ActivationResponse.statusSuccess          => statusSuccess.inc()\n        case ActivationResponse.statusApplicationError => statusApplicationError.inc()\n        case ActivationResponse.statusDeveloperError   => statusDeveloperError.inc()\n        case ActivationResponse.statusWhiskError       => statusInternalError.inc()\n        case x                                         => promMetrics.statusCounter.labels(namespace, initiator, action, x).inc()\n      }\n\n      a.size.foreach(responseSize.observe(_))\n      a.userDefinedStatusCode.foreach(value =>\n        promMetrics.userDefinedStatusCodeCounter.labels(namespace, initiator, action, value.toString).inc())\n    }\n  }\n\n  case class PrometheusMetrics() extends PrometheusMetricNames {\n\n    private val namespace = config.renameTags.getOrElse(actionNamespace, actionNamespace)\n    private val initiator = config.renameTags.getOrElse(initiatorNamespace, initiatorNamespace)\n    private val action = config.renameTags.getOrElse(actionName, actionName)\n    private val kind = config.renameTags.getOrElse(actionKind, actionKind)\n    private val memory = config.renameTags.getOrElse(actionMemory, actionMemory)\n    private val status = config.renameTags.getOrElse(actionStatus, actionStatus)\n    private val statusCode = config.renameTags.getOrElse(userDefinedStatusCode, userDefinedStatusCode)\n\n    val activationCounter =\n      counter(activationMetric, \"Activation Count\", namespace, initiator, action, kind, memory)\n\n    val coldStartCounter =\n      counter(coldStartMetric, \"Cold start counts\", namespace, initiator, action)\n\n    val statusCounter =\n      counter(statusMetric, \"Activation failure status type\", namespace, initiator, action, status)\n\n    val userDefinedStatusCodeCounter =\n      counter(\n        userDefinedStatusCodeMetric,\n        \"status code returned in action result response set by developer\",\n        namespace,\n        initiator,\n        action,\n        statusCode)\n\n    val waitTimeHisto =\n      histogram(waitTimeMetric, \"Internal system hold time\", namespace, initiator, action)\n\n    val initTimeHisto =\n      histogram(initTimeMetric, \"Time it took to initialize an action, e.g. docker init\", namespace, initiator, action)\n\n    val durationHisto =\n      histogram(durationMetric, \"Actual time the action code was running\", namespace, initiator, action)\n\n    val responseSizeHisto =\n      Histogram\n        .build()\n        .name(responseSizeMetric)\n        .help(\"Activation Response size\")\n        .labelNames(namespace, initiator, action)\n        .linearBuckets(0, ActivationEntityLimit.MAX_ACTIVATION_ENTITY_LIMIT.toBytes.toDouble, 10)\n        .register()\n\n    val memoryGauge =\n      gauge(memoryMetric, \"Memory consumption of the action containers\", namespace, initiator, action)\n\n    val concurrentLimitCounter =\n      counter(concurrentLimitMetric, \"a user has exceeded its limit for concurrent invocations\", namespace)\n\n    val timedLimitCounter =\n      counter(timedLimitMetric, \"the user has reached its per minute limit for the number of invocations\", namespace)\n\n    private def counter(name: String, help: String, tags: String*) =\n      Counter\n        .build()\n        .name(name)\n        .help(help)\n        .labelNames(tags: _*)\n        .register()\n\n    private def gauge(name: String, help: String, tags: String*) =\n      Gauge\n        .build()\n        .name(name)\n        .help(help)\n        .labelNames(tags: _*)\n        .register()\n\n    private def histogram(name: String, help: String, tags: String*) =\n      Histogram\n        .build()\n        .name(name)\n        .help(help)\n        .labelNames(tags: _*)\n        .register()\n  }\n\n  //Returns a floating point number\n  private def seconds(time: Duration): Double = time.toUnit(TimeUnit.SECONDS)\n\n  private def createSource() =\n    Source.combine(createJavaClientSource(), createKamonSource())(Concat(_)).map(ByteString(_))\n\n  /**\n   * Enables streaming the prometheus metric data without building the whole report in memory\n   */\n  private def createJavaClientSource() =\n    Source\n      .fromIterator(() => CollectorRegistry.defaultRegistry.metricFamilySamples().asScala)\n      .map { sample =>\n        //Stream string representation of one sample at a time\n        val writer = new StringWriter()\n        TextFormat.write004(writer, singletonEnumeration(sample))\n        writer.toString\n      }\n\n  private def createKamonSource() = Source.single(kamon.scrapeData())\n\n  private def singletonEnumeration[A](value: A) = new util.Enumeration[A] {\n    private var done = false\n    override def hasMoreElements: Boolean = !done\n    override def nextElement(): A = {\n      if (done) throw new NoSuchElementException\n      done = true\n      value\n    }\n  }\n}",
    "repo": "apache/openwhisk",
    "path": "./datasets/diagrams-repos/apache/openwhisk/core/monitoring/user-events/src/main/scala/org/apache/openwhisk/core/monitoring/metrics/PrometheusRecorder.scala",
    "query": "What is the structure of the metric names and labels used in PrometheusMetrics?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'PrometheusMetricNames', 'node_id': 'PrometheusMetricNames', 'description': 'Trait defining metric name constants for Prometheus metrics', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'PrometheusMetrics', 'node_id': 'PrometheusMetrics', 'description': 'Class implementing metric collectors with labels', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'namespace', 'node_id': 'namespace', 'description': 'Label for action namespace', 'visibility': 'private', 'return_type': 'String', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'initiator', 'node_id': 'initiator', 'description': 'Label for initiator namespace', 'visibility': 'private', 'return_type': 'String', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'action', 'node_id': 'action', 'description': 'Label for action name', 'visibility': 'private', 'return_type': 'String', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'activationCounter', 'node_id': 'activationCounter', 'description': 'Counter for tracking activation count', 'visibility': 'public', 'return_type': 'Counter', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'coldStartCounter', 'node_id': 'coldStartCounter', 'description': 'Counter for tracking cold starts', 'visibility': 'public', 'return_type': 'Counter', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'statusCounter', 'node_id': 'statusCounter', 'description': 'Counter for tracking activation status', 'visibility': 'public', 'return_type': 'Counter', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'waitTimeHisto', 'node_id': 'waitTimeHisto', 'description': 'Histogram for system hold time', 'visibility': 'public', 'return_type': 'Histogram', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'initTimeHisto', 'node_id': 'initTimeHisto', 'description': 'Histogram for initialization time', 'visibility': 'public', 'return_type': 'Histogram', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'durationHisto', 'node_id': 'durationHisto', 'description': 'Histogram for action duration', 'visibility': 'public', 'return_type': 'Histogram', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'responseSizeHisto', 'node_id': 'responseSizeHisto', 'description': 'Histogram for response size', 'visibility': 'public', 'return_type': 'Histogram', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'memoryGauge', 'node_id': 'memoryGauge', 'description': 'Gauge for memory consumption', 'visibility': 'public', 'return_type': 'Gauge', 'params': None, 'source_class_id': 'PrometheusMetrics'}], 'edges': [{'node_id_from': 'PrometheusMetrics', 'node_id_to': 'PrometheusMetricNames', 'description': 'extends'}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'activationCounter', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'statusCounter', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'coldStartCounter', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'waitTimeHisto', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'memoryGauge', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'namespace', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'initiator', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'action', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'initTimeHisto', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'durationHisto', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'responseSizeHisto', 'description': ''}], 'packages': [{'package_id': 'metrics', 'children': ['PrometheusMetricNames', 'PrometheusMetrics', 'labels', 'metricTypes'], 'description': 'Core metrics components'}, {'package_id': 'metricTypes', 'children': ['activationCounter', 'coldStartCounter', 'statusCounter', 'waitTimeHisto', 'initTimeHisto', 'durationHisto', 'responseSizeHisto', 'memoryGauge'], 'description': 'Different types of metrics'}, {'package_id': 'labels', 'children': ['namespace', 'initiator', 'action'], 'description': 'Label definitions'}]}",
    "version": "medium",
    "text_answer": "PrometheusMetrics defines a set of Prometheus metric collectors (counters, histograms, and gauges) that track various OpenWhisk action metrics. Each metric is labeled with namespace, initiator, and action name, with some metrics having additional labels like kind and memory. The metric names are defined in PrometheusMetricNames trait and include metrics for activations, cold starts, wait time, duration, and memory usage.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Scala",
    "code": "\npackage org.apache.openwhisk.core.monitoring.metrics\n\nimport java.io.StringWriter\nimport java.util\nimport java.util.concurrent.TimeUnit\n\nimport akka.event.slf4j.SLF4JLogging\nimport akka.http.scaladsl.model.{HttpEntity, MessageEntity}\nimport akka.stream.scaladsl.{Concat, Source}\nimport akka.util.ByteString\nimport io.prometheus.client.exporter.common.TextFormat\nimport io.prometheus.client.{CollectorRegistry, Counter, Gauge, Histogram}\nimport kamon.prometheus.PrometheusReporter\nimport org.apache.openwhisk.core.connector.{Activation, Metric}\nimport org.apache.openwhisk.core.entity.{ActivationEntityLimit, ActivationResponse}\nimport org.apache.openwhisk.core.monitoring.metrics.OpenWhiskEvents.MetricConfig\n\nimport scala.collection.JavaConverters._\nimport scala.collection.concurrent.TrieMap\nimport scala.concurrent.duration.Duration\n\ntrait PrometheusMetricNames extends MetricNames {\n  val activationMetric = \"openwhisk_action_activations_total\"\n  val coldStartMetric = \"openwhisk_action_coldStarts_total\"\n  val waitTimeMetric = \"openwhisk_action_waitTime_seconds\"\n  val initTimeMetric = \"openwhisk_action_initTime_seconds\"\n  val durationMetric = \"openwhisk_action_duration_seconds\"\n  val responseSizeMetric = \"openwhisk_action_response_size_bytes\"\n  val statusMetric = \"openwhisk_action_status\"\n  val memoryMetric = \"openwhisk_action_memory\"\n  val userDefinedStatusCodeMetric = \"openwhisk_action_status_code\"\n\n  val concurrentLimitMetric = \"openwhisk_action_limit_concurrent_total\"\n  val timedLimitMetric = \"openwhisk_action_limit_timed_total\"\n}\n\ncase class PrometheusRecorder(kamon: PrometheusReporter, config: MetricConfig)\n    extends MetricRecorder\n    with PrometheusExporter\n    with SLF4JLogging {\n  private val activationMetrics = new TrieMap[String, ActivationPromMetrics]\n  private val limitMetrics = new TrieMap[String, LimitPromMetrics]\n  private val promMetrics = PrometheusMetrics()\n\n  override def processActivation(activation: Activation, initiator: String): Unit = {\n    lookup(activation, initiator).record(activation, initiator)\n  }\n\n  override def processMetric(metric: Metric, initiator: String): Unit = {\n    val limitMetric = limitMetrics.getOrElseUpdate(initiator, LimitPromMetrics(initiator))\n    limitMetric.record(metric)\n  }\n\n  override def getReport(): MessageEntity =\n    HttpEntity(PrometheusExporter.textV4, createSource())\n\n  private def lookup(activation: Activation, initiator: String): ActivationPromMetrics = {\n    //TODO Unregister unused actions\n    val name = activation.name\n    val kind = activation.kind\n    val memory = activation.memory.toString\n    val namespace = activation.namespace\n    val action = activation.action\n    activationMetrics.getOrElseUpdate(name, {\n      ActivationPromMetrics(namespace, action, kind, memory, initiator)\n    })\n  }\n\n  case class LimitPromMetrics(namespace: String) {\n    private val concurrentLimit = promMetrics.concurrentLimitCounter.labels(namespace)\n    private val timedLimit = promMetrics.timedLimitCounter.labels(namespace)\n\n    def record(m: Metric): Unit = {\n      m.metricName match {\n        case \"ConcurrentRateLimit\"   => concurrentLimit.inc()\n        case \"TimedRateLimit\"        => timedLimit.inc()\n        case \"ConcurrentInvocations\" => //TODO Handle ConcurrentInvocations\n        case x                       => log.warn(s\"Unknown limit $x\")\n      }\n    }\n  }\n\n  case class ActivationPromMetrics(namespace: String,\n                                   action: String,\n                                   kind: String,\n                                   memory: String,\n                                   initiatorNamespace: String) {\n\n    private val activations = promMetrics.activationCounter.labels(namespace, initiatorNamespace, action, kind, memory)\n    private val coldStarts = promMetrics.coldStartCounter.labels(namespace, initiatorNamespace, action)\n    private val waitTime = promMetrics.waitTimeHisto.labels(namespace, initiatorNamespace, action)\n    private val initTime = promMetrics.initTimeHisto.labels(namespace, initiatorNamespace, action)\n    private val duration = promMetrics.durationHisto.labels(namespace, initiatorNamespace, action)\n    private val responseSize = promMetrics.responseSizeHisto.labels(namespace, initiatorNamespace, action)\n\n    private val gauge = promMetrics.memoryGauge.labels(namespace, initiatorNamespace, action)\n\n    private val statusSuccess =\n      promMetrics.statusCounter.labels(namespace, initiatorNamespace, action, ActivationResponse.statusSuccess)\n    private val statusApplicationError =\n      promMetrics.statusCounter.labels(namespace, initiatorNamespace, action, ActivationResponse.statusApplicationError)\n    private val statusDeveloperError =\n      promMetrics.statusCounter.labels(namespace, initiatorNamespace, action, ActivationResponse.statusDeveloperError)\n    private val statusInternalError =\n      promMetrics.statusCounter.labels(namespace, initiatorNamespace, action, ActivationResponse.statusWhiskError)\n\n    def record(a: Activation, initiator: String): Unit = {\n      recordActivation(a, initiator)\n    }\n\n    def recordActivation(a: Activation, initiator: String): Unit = {\n      gauge.set(a.memory)\n\n      activations.inc()\n\n      if (a.isColdStart) {\n        coldStarts.inc()\n        initTime.observe(seconds(a.initTime))\n      }\n\n      //waitTime may be zero for activations which are part of sequence\n      waitTime.observe(seconds(a.waitTime))\n      duration.observe(seconds(a.duration))\n\n      a.status match {\n        case ActivationResponse.statusSuccess          => statusSuccess.inc()\n        case ActivationResponse.statusApplicationError => statusApplicationError.inc()\n        case ActivationResponse.statusDeveloperError   => statusDeveloperError.inc()\n        case ActivationResponse.statusWhiskError       => statusInternalError.inc()\n        case x                                         => promMetrics.statusCounter.labels(namespace, initiator, action, x).inc()\n      }\n\n      a.size.foreach(responseSize.observe(_))\n      a.userDefinedStatusCode.foreach(value =>\n        promMetrics.userDefinedStatusCodeCounter.labels(namespace, initiator, action, value.toString).inc())\n    }\n  }\n\n  case class PrometheusMetrics() extends PrometheusMetricNames {\n\n    private val namespace = config.renameTags.getOrElse(actionNamespace, actionNamespace)\n    private val initiator = config.renameTags.getOrElse(initiatorNamespace, initiatorNamespace)\n    private val action = config.renameTags.getOrElse(actionName, actionName)\n    private val kind = config.renameTags.getOrElse(actionKind, actionKind)\n    private val memory = config.renameTags.getOrElse(actionMemory, actionMemory)\n    private val status = config.renameTags.getOrElse(actionStatus, actionStatus)\n    private val statusCode = config.renameTags.getOrElse(userDefinedStatusCode, userDefinedStatusCode)\n\n    val activationCounter =\n      counter(activationMetric, \"Activation Count\", namespace, initiator, action, kind, memory)\n\n    val coldStartCounter =\n      counter(coldStartMetric, \"Cold start counts\", namespace, initiator, action)\n\n    val statusCounter =\n      counter(statusMetric, \"Activation failure status type\", namespace, initiator, action, status)\n\n    val userDefinedStatusCodeCounter =\n      counter(\n        userDefinedStatusCodeMetric,\n        \"status code returned in action result response set by developer\",\n        namespace,\n        initiator,\n        action,\n        statusCode)\n\n    val waitTimeHisto =\n      histogram(waitTimeMetric, \"Internal system hold time\", namespace, initiator, action)\n\n    val initTimeHisto =\n      histogram(initTimeMetric, \"Time it took to initialize an action, e.g. docker init\", namespace, initiator, action)\n\n    val durationHisto =\n      histogram(durationMetric, \"Actual time the action code was running\", namespace, initiator, action)\n\n    val responseSizeHisto =\n      Histogram\n        .build()\n        .name(responseSizeMetric)\n        .help(\"Activation Response size\")\n        .labelNames(namespace, initiator, action)\n        .linearBuckets(0, ActivationEntityLimit.MAX_ACTIVATION_ENTITY_LIMIT.toBytes.toDouble, 10)\n        .register()\n\n    val memoryGauge =\n      gauge(memoryMetric, \"Memory consumption of the action containers\", namespace, initiator, action)\n\n    val concurrentLimitCounter =\n      counter(concurrentLimitMetric, \"a user has exceeded its limit for concurrent invocations\", namespace)\n\n    val timedLimitCounter =\n      counter(timedLimitMetric, \"the user has reached its per minute limit for the number of invocations\", namespace)\n\n    private def counter(name: String, help: String, tags: String*) =\n      Counter\n        .build()\n        .name(name)\n        .help(help)\n        .labelNames(tags: _*)\n        .register()\n\n    private def gauge(name: String, help: String, tags: String*) =\n      Gauge\n        .build()\n        .name(name)\n        .help(help)\n        .labelNames(tags: _*)\n        .register()\n\n    private def histogram(name: String, help: String, tags: String*) =\n      Histogram\n        .build()\n        .name(name)\n        .help(help)\n        .labelNames(tags: _*)\n        .register()\n  }\n\n  //Returns a floating point number\n  private def seconds(time: Duration): Double = time.toUnit(TimeUnit.SECONDS)\n\n  private def createSource() =\n    Source.combine(createJavaClientSource(), createKamonSource())(Concat(_)).map(ByteString(_))\n\n  /**\n   * Enables streaming the prometheus metric data without building the whole report in memory\n   */\n  private def createJavaClientSource() =\n    Source\n      .fromIterator(() => CollectorRegistry.defaultRegistry.metricFamilySamples().asScala)\n      .map { sample =>\n        //Stream string representation of one sample at a time\n        val writer = new StringWriter()\n        TextFormat.write004(writer, singletonEnumeration(sample))\n        writer.toString\n      }\n\n  private def createKamonSource() = Source.single(kamon.scrapeData())\n\n  private def singletonEnumeration[A](value: A) = new util.Enumeration[A] {\n    private var done = false\n    override def hasMoreElements: Boolean = !done\n    override def nextElement(): A = {\n      if (done) throw new NoSuchElementException\n      done = true\n      value\n    }\n  }\n}",
    "repo": "apache/openwhisk",
    "path": "./datasets/diagrams-repos/apache/openwhisk/core/monitoring/user-events/src/main/scala/org/apache/openwhisk/core/monitoring/metrics/PrometheusRecorder.scala",
    "query": "What is the structure of the metric names and labels used in PrometheusMetrics?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'PrometheusMetricNames', 'node_id': 'PrometheusMetricNames', 'description': 'Trait defining metric name constants for Prometheus metrics', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'activationMetric', 'node_id': 'activationMetric', 'description': 'Metric name for activations', 'visibility': 'public', 'return_type': 'String', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'coldStartMetric', 'node_id': 'coldStartMetric', 'description': 'Metric name for cold starts', 'visibility': 'public', 'return_type': 'String', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'class', 'name': 'PrometheusMetrics', 'node_id': 'PrometheusMetrics', 'description': 'Class implementing metric collectors with labels', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'namespace', 'node_id': 'namespace', 'description': 'Label for action namespace', 'visibility': 'private', 'return_type': 'String', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'initiator', 'node_id': 'initiator', 'description': 'Label for initiator namespace', 'visibility': 'private', 'return_type': 'String', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'action', 'node_id': 'action', 'description': 'Label for action name', 'visibility': 'private', 'return_type': 'String', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'activationCounter', 'node_id': 'activationCounter', 'description': 'Counter for tracking activation count', 'visibility': 'public', 'return_type': 'Counter', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'coldStartCounter', 'node_id': 'coldStartCounter', 'description': 'Counter for tracking cold starts', 'visibility': 'public', 'return_type': 'Counter', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'statusCounter', 'node_id': 'statusCounter', 'description': 'Counter for tracking activation status', 'visibility': 'public', 'return_type': 'Counter', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'waitTimeHisto', 'node_id': 'waitTimeHisto', 'description': 'Histogram for system hold time', 'visibility': 'public', 'return_type': 'Histogram', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'initTimeHisto', 'node_id': 'initTimeHisto', 'description': 'Histogram for initialization time', 'visibility': 'public', 'return_type': 'Histogram', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'durationHisto', 'node_id': 'durationHisto', 'description': 'Histogram for action duration', 'visibility': 'public', 'return_type': 'Histogram', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'responseSizeHisto', 'node_id': 'responseSizeHisto', 'description': 'Histogram for response size', 'visibility': 'public', 'return_type': 'Histogram', 'params': None, 'source_class_id': 'PrometheusMetrics'}, {'type': 'field', 'name': 'memoryGauge', 'node_id': 'memoryGauge', 'description': 'Gauge for memory consumption', 'visibility': 'public', 'return_type': 'Gauge', 'params': None, 'source_class_id': 'PrometheusMetrics'}], 'edges': [{'node_id_from': 'PrometheusMetrics', 'node_id_to': 'PrometheusMetricNames', 'description': 'extends'}, {'node_id_from': 'activationCounter', 'node_id_to': 'activationMetric', 'description': 'uses name'}, {'node_id_from': 'coldStartCounter', 'node_id_to': 'coldStartMetric', 'description': 'uses name'}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'activationCounter', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'statusCounter', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'coldStartCounter', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'waitTimeHisto', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'memoryGauge', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'namespace', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'initiator', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'action', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'initTimeHisto', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'durationHisto', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'responseSizeHisto', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'activationMetric', 'description': ''}, {'node_id_from': 'PrometheusMetrics', 'node_id_to': 'coldStartMetric', 'description': ''}], 'packages': [{'package_id': 'metrics', 'children': ['PrometheusMetricNames', 'PrometheusMetrics', 'labels', 'metricTypes'], 'description': 'Core metrics components'}, {'package_id': 'metricTypes', 'children': ['activationCounter', 'coldStartCounter', 'statusCounter', 'waitTimeHisto', 'initTimeHisto', 'durationHisto', 'responseSizeHisto', 'memoryGauge', 'activationMetric', 'coldStartMetric'], 'description': 'Different types of metrics'}, {'package_id': 'labels', 'children': ['namespace', 'initiator', 'action'], 'description': 'Label definitions'}]}",
    "version": "full",
    "text_answer": "PrometheusMetrics defines a set of Prometheus metric collectors (counters, histograms, and gauges) that track various OpenWhisk action metrics. Each metric is labeled with namespace, initiator, and action name, with some metrics having additional labels like kind and memory. The metric names are defined in PrometheusMetricNames trait and include metrics for activations, cold starts, wait time, duration, and memory usage.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Rust",
    "code": "\nuse std::num::{NonZeroU32, NonZeroU64};\n\nuse wgpu::*;\nuse wgpu_test::{gpu_test, GpuTestConfiguration, TestParameters, TestingContext};\n\n#[gpu_test]\nstatic BINDING_ARRAY_SAMPLERS: GpuTestConfiguration = GpuTestConfiguration::new()\n    .parameters(\n        TestParameters::default()\n            .features(\n                Features::TEXTURE_BINDING_ARRAY\n                    | Features::SAMPLED_TEXTURE_AND_STORAGE_BUFFER_ARRAY_NON_UNIFORM_INDEXING,\n            )\n            .limits(Limits {\n                max_samplers_per_shader_stage: 2,\n                ..Limits::default()\n            }),\n    )\n    .run_async(|ctx| async move { binding_array_samplers(ctx, false).await });\n\n#[gpu_test]\nstatic PARTIAL_BINDING_ARRAY_SAMPLERS: GpuTestConfiguration = GpuTestConfiguration::new()\n    .parameters(\n        TestParameters::default()\n            .features(\n                Features::TEXTURE_BINDING_ARRAY\n                    | Features::SAMPLED_TEXTURE_AND_STORAGE_BUFFER_ARRAY_NON_UNIFORM_INDEXING\n                    | Features::PARTIALLY_BOUND_BINDING_ARRAY,\n            )\n            .limits(Limits {\n                max_samplers_per_shader_stage: 4,\n                ..Limits::default()\n            }),\n    )\n    .run_async(|ctx| async move { binding_array_samplers(ctx, true).await });\n\nasync fn binding_array_samplers(ctx: TestingContext, partially_bound: bool) {\n    let shader = r#\"\n        @group(0) @binding(0)\n        var samplers: binding_array<sampler>;\n        @group(0) @binding(1)\n        var texture: texture_2d<f32>;\n        @group(0) @binding(2)\n        var<storage, read_write> output_values: array<u32>;\n\n        @compute\n        @workgroup_size(2, 1, 1)\n        fn compMain(@builtin(global_invocation_id) id: vec3u) {\n            output_values[id.x] = pack4x8unorm(textureSampleLevel(texture, samplers[id.x], vec2f(0.25 + (0.5 * 0.25), 0.5), 0.0));\n        }\n    \"#;\n\n    let module = ctx\n        .device\n        .create_shader_module(wgpu::ShaderModuleDescriptor {\n            label: Some(\"Binding Array Texture\"),\n            source: wgpu::ShaderSource::Wgsl(shader.into()),\n        });\n\n    let input_image: [u8; 8] = [\n        255, 0, 0, 255, //\n        0, 255, 0, 255, //\n    ];\n\n    let expected_output: [u8; 8] = [\n        191, 64, 0, 255, //\n        255, 0, 0, 255, //\n    ];\n\n    let texture = ctx.device.create_texture(&wgpu::TextureDescriptor {\n        label: None,\n        size: Extent3d {\n            width: 2,\n            height: 1,\n            depth_or_array_layers: 1,\n        },\n        mip_level_count: 1,\n        sample_count: 1,\n        dimension: TextureDimension::D2,\n        format: TextureFormat::Rgba8Unorm,\n        usage: TextureUsages::TEXTURE_BINDING | TextureUsages::COPY_DST,\n        view_formats: &[],\n    });\n\n    ctx.queue.write_texture(\n        TexelCopyTextureInfo {\n            texture: &texture,\n            mip_level: 0,\n            origin: Origin3d::ZERO,\n            aspect: TextureAspect::All,\n        },\n        &input_image,\n        TexelCopyBufferLayout {\n            offset: 0,\n            bytes_per_row: Some(8),\n            rows_per_image: Some(1),\n        },\n        Extent3d {\n            width: 2,\n            height: 1,\n            depth_or_array_layers: 1,\n        },\n    );\n\n    let input_view = texture.create_view(&TextureViewDescriptor::default());\n\n    let samplers = [\n        ctx.device.create_sampler(&SamplerDescriptor {\n            label: None,\n            address_mode_u: AddressMode::ClampToEdge,\n            address_mode_v: AddressMode::ClampToEdge,\n            address_mode_w: AddressMode::ClampToEdge,\n            mag_filter: FilterMode::Linear,\n            min_filter: FilterMode::Linear,\n            mipmap_filter: FilterMode::Linear,\n            lod_min_clamp: 0.0,\n            lod_max_clamp: 1000.0,\n            compare: None,\n            anisotropy_clamp: 1,\n            border_color: None,\n        }),\n        ctx.device.create_sampler(&SamplerDescriptor {\n            label: None,\n            address_mode_u: AddressMode::ClampToEdge,\n            address_mode_v: AddressMode::ClampToEdge,\n            address_mode_w: AddressMode::ClampToEdge,\n            mag_filter: FilterMode::Nearest,\n            min_filter: FilterMode::Nearest,\n            mipmap_filter: FilterMode::Nearest,\n            lod_min_clamp: 0.0,\n            lod_max_clamp: 1000.0,\n            compare: None,\n            anisotropy_clamp: 1,\n            border_color: None,\n        }),\n    ];\n\n    let output_buffer = ctx.device.create_buffer(&BufferDescriptor {\n        label: None,\n        size: 4 * 2,\n        usage: BufferUsages::STORAGE | BufferUsages::COPY_SRC,\n        mapped_at_creation: false,\n    });\n\n    let multiplier = if partially_bound { 2 } else { 1 };\n\n    let bind_group_layout = ctx\n        .device\n        .create_bind_group_layout(&BindGroupLayoutDescriptor {\n            label: Some(\"Bind Group Layout\"),\n            entries: &[\n                BindGroupLayoutEntry {\n                    binding: 0,\n                    visibility: ShaderStages::COMPUTE,\n                    ty: BindingType::Sampler(SamplerBindingType::Filtering),\n                    count: Some(NonZeroU32::new(2 * multiplier).unwrap()),\n                },\n                BindGroupLayoutEntry {\n                    binding: 1,\n                    visibility: ShaderStages::COMPUTE,\n                    ty: BindingType::Texture {\n                        sample_type: wgpu::TextureSampleType::Float { filterable: true },\n                        view_dimension: wgpu::TextureViewDimension::D2,\n                        multisampled: false,\n                    },\n                    count: None,\n                },\n                BindGroupLayoutEntry {\n                    binding: 2,\n                    visibility: ShaderStages::COMPUTE,\n                    ty: BindingType::Buffer {\n                        ty: BufferBindingType::Storage { read_only: false },\n                        has_dynamic_offset: false,\n                        min_binding_size: Some(NonZeroU64::new(4).unwrap()),\n                    },\n                    count: None,\n                },\n            ],\n        });\n\n    let sampler_references: Vec<_> = samplers.iter().collect();\n\n    let bind_group = ctx.device.create_bind_group(&BindGroupDescriptor {\n        label: Some(\"Bind Group\"),\n        layout: &bind_group_layout,\n        entries: &[\n            BindGroupEntry {\n                binding: 0,\n                resource: BindingResource::SamplerArray(&sampler_references),\n            },\n            BindGroupEntry {\n                binding: 1,\n                resource: BindingResource::TextureView(&input_view),\n            },\n            BindGroupEntry {\n                binding: 2,\n                resource: output_buffer.as_entire_binding(),\n            },\n        ],\n    });\n\n    let pipeline_layout = ctx\n        .device\n        .create_pipeline_layout(&PipelineLayoutDescriptor {\n            label: Some(\"Pipeline Layout\"),\n            bind_group_layouts: &[&bind_group_layout],\n            push_constant_ranges: &[],\n        });\n\n    let pipeline = ctx\n        .device\n        .create_compute_pipeline(&ComputePipelineDescriptor {\n            label: Some(\"Compute Pipeline\"),\n            layout: Some(&pipeline_layout),\n            module: &module,\n            entry_point: Some(\"compMain\"),\n            compilation_options: Default::default(),\n            cache: None,\n        });\n\n    let mut encoder = ctx\n        .device\n        .create_command_encoder(&CommandEncoderDescriptor { label: None });\n    {\n        let mut render_pass = encoder.begin_compute_pass(&ComputePassDescriptor {\n            label: None,\n            timestamp_writes: None,\n        });\n        render_pass.set_pipeline(&pipeline);\n        render_pass.set_bind_group(0, &bind_group, &[]);\n        render_pass.dispatch_workgroups(1, 1, 1);\n    }\n\n    let readback_buffer = ctx.device.create_buffer(&BufferDescriptor {\n        label: None,\n        size: 4 * 2,\n        usage: BufferUsages::MAP_READ | BufferUsages::COPY_DST,\n        mapped_at_creation: false,\n    });\n\n    encoder.copy_buffer_to_buffer(&output_buffer, 0, &readback_buffer, 0, 4 * 2);\n\n    ctx.queue.submit(Some(encoder.finish()));\n\n    readback_buffer.slice(..).map_async(MapMode::Read, |_| {});\n    ctx.device.poll(Maintain::Wait);\n\n    let readback_buffer_slice = readback_buffer.slice(..).get_mapped_range();\n\n    assert_eq!(&readback_buffer_slice[0..8], &expected_output[..]);\n}",
    "repo": "gfx-rs/wgpu",
    "path": "./datasets/diagrams-repos/gfx-rs/wgpu/tests/tests/binding_array/samplers.rs",
    "query": "What is the structure of the bind group layout and how do its entries correspond to shader bindings?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'bindGroupLayout', 'node_id': 'bindGroupLayout', 'description': 'Main bind group layout structure', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'samplerEntry', 'node_id': 'samplerEntry', 'description': 'Binding entry for sampler array', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'textureEntry', 'node_id': 'textureEntry', 'description': 'Binding entry for 2D texture', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'storageBufferEntry', 'node_id': 'storageBufferEntry', 'description': 'Binding entry for storage buffer', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'shaderBindings', 'node_id': 'shaderBindings', 'description': 'WGSL shader binding declarations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'bindGroupLayout', 'node_id_to': 'samplerEntry', 'description': 'contains'}, {'node_id_from': 'bindGroupLayout', 'node_id_to': 'textureEntry', 'description': 'contains'}, {'node_id_from': 'bindGroupLayout', 'node_id_to': 'storageBufferEntry', 'description': 'contains'}, {'node_id_from': 'shaderBindings', 'node_id_to': 'bindGroupLayout', 'description': 'corresponds to'}], 'packages': [{'package_id': 'bindingStructure', 'children': ['bindGroupLayout', 'samplerEntry', 'textureEntry', 'storageBufferEntry', 'shaderBindings'], 'description': 'Core binding structure components'}]}",
    "version": "minimal",
    "text_answer": "The bind group layout contains three entries that directly correspond to shader bindings: a sampler array at binding 0, a 2D texture at binding 1, and a storage buffer at binding 2. All entries are visible to the compute shader stage. The sampler array has a configurable size, while texture and storage buffer are single bindings.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Rust",
    "code": "\nuse std::num::{NonZeroU32, NonZeroU64};\n\nuse wgpu::*;\nuse wgpu_test::{gpu_test, GpuTestConfiguration, TestParameters, TestingContext};\n\n#[gpu_test]\nstatic BINDING_ARRAY_SAMPLERS: GpuTestConfiguration = GpuTestConfiguration::new()\n    .parameters(\n        TestParameters::default()\n            .features(\n                Features::TEXTURE_BINDING_ARRAY\n                    | Features::SAMPLED_TEXTURE_AND_STORAGE_BUFFER_ARRAY_NON_UNIFORM_INDEXING,\n            )\n            .limits(Limits {\n                max_samplers_per_shader_stage: 2,\n                ..Limits::default()\n            }),\n    )\n    .run_async(|ctx| async move { binding_array_samplers(ctx, false).await });\n\n#[gpu_test]\nstatic PARTIAL_BINDING_ARRAY_SAMPLERS: GpuTestConfiguration = GpuTestConfiguration::new()\n    .parameters(\n        TestParameters::default()\n            .features(\n                Features::TEXTURE_BINDING_ARRAY\n                    | Features::SAMPLED_TEXTURE_AND_STORAGE_BUFFER_ARRAY_NON_UNIFORM_INDEXING\n                    | Features::PARTIALLY_BOUND_BINDING_ARRAY,\n            )\n            .limits(Limits {\n                max_samplers_per_shader_stage: 4,\n                ..Limits::default()\n            }),\n    )\n    .run_async(|ctx| async move { binding_array_samplers(ctx, true).await });\n\nasync fn binding_array_samplers(ctx: TestingContext, partially_bound: bool) {\n    let shader = r#\"\n        @group(0) @binding(0)\n        var samplers: binding_array<sampler>;\n        @group(0) @binding(1)\n        var texture: texture_2d<f32>;\n        @group(0) @binding(2)\n        var<storage, read_write> output_values: array<u32>;\n\n        @compute\n        @workgroup_size(2, 1, 1)\n        fn compMain(@builtin(global_invocation_id) id: vec3u) {\n            output_values[id.x] = pack4x8unorm(textureSampleLevel(texture, samplers[id.x], vec2f(0.25 + (0.5 * 0.25), 0.5), 0.0));\n        }\n    \"#;\n\n    let module = ctx\n        .device\n        .create_shader_module(wgpu::ShaderModuleDescriptor {\n            label: Some(\"Binding Array Texture\"),\n            source: wgpu::ShaderSource::Wgsl(shader.into()),\n        });\n\n    let input_image: [u8; 8] = [\n        255, 0, 0, 255, //\n        0, 255, 0, 255, //\n    ];\n\n    let expected_output: [u8; 8] = [\n        191, 64, 0, 255, //\n        255, 0, 0, 255, //\n    ];\n\n    let texture = ctx.device.create_texture(&wgpu::TextureDescriptor {\n        label: None,\n        size: Extent3d {\n            width: 2,\n            height: 1,\n            depth_or_array_layers: 1,\n        },\n        mip_level_count: 1,\n        sample_count: 1,\n        dimension: TextureDimension::D2,\n        format: TextureFormat::Rgba8Unorm,\n        usage: TextureUsages::TEXTURE_BINDING | TextureUsages::COPY_DST,\n        view_formats: &[],\n    });\n\n    ctx.queue.write_texture(\n        TexelCopyTextureInfo {\n            texture: &texture,\n            mip_level: 0,\n            origin: Origin3d::ZERO,\n            aspect: TextureAspect::All,\n        },\n        &input_image,\n        TexelCopyBufferLayout {\n            offset: 0,\n            bytes_per_row: Some(8),\n            rows_per_image: Some(1),\n        },\n        Extent3d {\n            width: 2,\n            height: 1,\n            depth_or_array_layers: 1,\n        },\n    );\n\n    let input_view = texture.create_view(&TextureViewDescriptor::default());\n\n    let samplers = [\n        ctx.device.create_sampler(&SamplerDescriptor {\n            label: None,\n            address_mode_u: AddressMode::ClampToEdge,\n            address_mode_v: AddressMode::ClampToEdge,\n            address_mode_w: AddressMode::ClampToEdge,\n            mag_filter: FilterMode::Linear,\n            min_filter: FilterMode::Linear,\n            mipmap_filter: FilterMode::Linear,\n            lod_min_clamp: 0.0,\n            lod_max_clamp: 1000.0,\n            compare: None,\n            anisotropy_clamp: 1,\n            border_color: None,\n        }),\n        ctx.device.create_sampler(&SamplerDescriptor {\n            label: None,\n            address_mode_u: AddressMode::ClampToEdge,\n            address_mode_v: AddressMode::ClampToEdge,\n            address_mode_w: AddressMode::ClampToEdge,\n            mag_filter: FilterMode::Nearest,\n            min_filter: FilterMode::Nearest,\n            mipmap_filter: FilterMode::Nearest,\n            lod_min_clamp: 0.0,\n            lod_max_clamp: 1000.0,\n            compare: None,\n            anisotropy_clamp: 1,\n            border_color: None,\n        }),\n    ];\n\n    let output_buffer = ctx.device.create_buffer(&BufferDescriptor {\n        label: None,\n        size: 4 * 2,\n        usage: BufferUsages::STORAGE | BufferUsages::COPY_SRC,\n        mapped_at_creation: false,\n    });\n\n    let multiplier = if partially_bound { 2 } else { 1 };\n\n    let bind_group_layout = ctx\n        .device\n        .create_bind_group_layout(&BindGroupLayoutDescriptor {\n            label: Some(\"Bind Group Layout\"),\n            entries: &[\n                BindGroupLayoutEntry {\n                    binding: 0,\n                    visibility: ShaderStages::COMPUTE,\n                    ty: BindingType::Sampler(SamplerBindingType::Filtering),\n                    count: Some(NonZeroU32::new(2 * multiplier).unwrap()),\n                },\n                BindGroupLayoutEntry {\n                    binding: 1,\n                    visibility: ShaderStages::COMPUTE,\n                    ty: BindingType::Texture {\n                        sample_type: wgpu::TextureSampleType::Float { filterable: true },\n                        view_dimension: wgpu::TextureViewDimension::D2,\n                        multisampled: false,\n                    },\n                    count: None,\n                },\n                BindGroupLayoutEntry {\n                    binding: 2,\n                    visibility: ShaderStages::COMPUTE,\n                    ty: BindingType::Buffer {\n                        ty: BufferBindingType::Storage { read_only: false },\n                        has_dynamic_offset: false,\n                        min_binding_size: Some(NonZeroU64::new(4).unwrap()),\n                    },\n                    count: None,\n                },\n            ],\n        });\n\n    let sampler_references: Vec<_> = samplers.iter().collect();\n\n    let bind_group = ctx.device.create_bind_group(&BindGroupDescriptor {\n        label: Some(\"Bind Group\"),\n        layout: &bind_group_layout,\n        entries: &[\n            BindGroupEntry {\n                binding: 0,\n                resource: BindingResource::SamplerArray(&sampler_references),\n            },\n            BindGroupEntry {\n                binding: 1,\n                resource: BindingResource::TextureView(&input_view),\n            },\n            BindGroupEntry {\n                binding: 2,\n                resource: output_buffer.as_entire_binding(),\n            },\n        ],\n    });\n\n    let pipeline_layout = ctx\n        .device\n        .create_pipeline_layout(&PipelineLayoutDescriptor {\n            label: Some(\"Pipeline Layout\"),\n            bind_group_layouts: &[&bind_group_layout],\n            push_constant_ranges: &[],\n        });\n\n    let pipeline = ctx\n        .device\n        .create_compute_pipeline(&ComputePipelineDescriptor {\n            label: Some(\"Compute Pipeline\"),\n            layout: Some(&pipeline_layout),\n            module: &module,\n            entry_point: Some(\"compMain\"),\n            compilation_options: Default::default(),\n            cache: None,\n        });\n\n    let mut encoder = ctx\n        .device\n        .create_command_encoder(&CommandEncoderDescriptor { label: None });\n    {\n        let mut render_pass = encoder.begin_compute_pass(&ComputePassDescriptor {\n            label: None,\n            timestamp_writes: None,\n        });\n        render_pass.set_pipeline(&pipeline);\n        render_pass.set_bind_group(0, &bind_group, &[]);\n        render_pass.dispatch_workgroups(1, 1, 1);\n    }\n\n    let readback_buffer = ctx.device.create_buffer(&BufferDescriptor {\n        label: None,\n        size: 4 * 2,\n        usage: BufferUsages::MAP_READ | BufferUsages::COPY_DST,\n        mapped_at_creation: false,\n    });\n\n    encoder.copy_buffer_to_buffer(&output_buffer, 0, &readback_buffer, 0, 4 * 2);\n\n    ctx.queue.submit(Some(encoder.finish()));\n\n    readback_buffer.slice(..).map_async(MapMode::Read, |_| {});\n    ctx.device.poll(Maintain::Wait);\n\n    let readback_buffer_slice = readback_buffer.slice(..).get_mapped_range();\n\n    assert_eq!(&readback_buffer_slice[0..8], &expected_output[..]);\n}",
    "repo": "gfx-rs/wgpu",
    "path": "./datasets/diagrams-repos/gfx-rs/wgpu/tests/tests/binding_array/samplers.rs",
    "query": "What is the structure of the bind group layout and how do its entries correspond to shader bindings?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'bindGroupLayout', 'node_id': 'bindGroupLayout', 'description': 'Main bind group layout structure', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'samplerEntry', 'node_id': 'samplerEntry', 'description': 'Binding entry for sampler array at binding 0', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'textureEntry', 'node_id': 'textureEntry', 'description': 'Binding entry for 2D texture at binding 1', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'storageBufferEntry', 'node_id': 'storageBufferEntry', 'description': 'Binding entry for storage buffer at binding 2', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'shaderBindings', 'node_id': 'shaderBindings', 'description': 'WGSL shader binding declarations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'samplerArrayType', 'node_id': 'samplerArrayType', 'description': 'Sampler array binding type with filtering', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'textureType', 'node_id': 'textureType', 'description': '2D texture binding type with float sampling', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'storageBufferType', 'node_id': 'storageBufferType', 'description': 'Storage buffer binding type with read/write access', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'bindGroupLayout', 'node_id_to': 'samplerEntry', 'description': 'contains'}, {'node_id_from': 'bindGroupLayout', 'node_id_to': 'textureEntry', 'description': 'contains'}, {'node_id_from': 'bindGroupLayout', 'node_id_to': 'storageBufferEntry', 'description': 'contains'}, {'node_id_from': 'samplerEntry', 'node_id_to': 'samplerArrayType', 'description': 'uses'}, {'node_id_from': 'textureEntry', 'node_id_to': 'textureType', 'description': 'uses'}, {'node_id_from': 'storageBufferEntry', 'node_id_to': 'storageBufferType', 'description': 'uses'}, {'node_id_from': 'shaderBindings', 'node_id_to': 'bindGroupLayout', 'description': 'corresponds to'}], 'packages': [{'package_id': 'bindingTypes', 'children': ['samplerArrayType', 'textureType', 'storageBufferType'], 'description': 'Binding type definitions'}, {'package_id': 'bindingStructure', 'children': ['bindGroupLayout', 'samplerEntry', 'textureEntry', 'storageBufferEntry', 'shaderBindings'], 'description': 'Core binding structure components'}]}",
    "version": "medium",
    "text_answer": "The bind group layout contains three entries that directly correspond to shader bindings: a sampler array at binding 0, a 2D texture at binding 1, and a storage buffer at binding 2. All entries are visible to the compute shader stage. The sampler array has a configurable size, while texture and storage buffer are single bindings.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Rust",
    "code": "\nuse std::num::{NonZeroU32, NonZeroU64};\n\nuse wgpu::*;\nuse wgpu_test::{gpu_test, GpuTestConfiguration, TestParameters, TestingContext};\n\n#[gpu_test]\nstatic BINDING_ARRAY_SAMPLERS: GpuTestConfiguration = GpuTestConfiguration::new()\n    .parameters(\n        TestParameters::default()\n            .features(\n                Features::TEXTURE_BINDING_ARRAY\n                    | Features::SAMPLED_TEXTURE_AND_STORAGE_BUFFER_ARRAY_NON_UNIFORM_INDEXING,\n            )\n            .limits(Limits {\n                max_samplers_per_shader_stage: 2,\n                ..Limits::default()\n            }),\n    )\n    .run_async(|ctx| async move { binding_array_samplers(ctx, false).await });\n\n#[gpu_test]\nstatic PARTIAL_BINDING_ARRAY_SAMPLERS: GpuTestConfiguration = GpuTestConfiguration::new()\n    .parameters(\n        TestParameters::default()\n            .features(\n                Features::TEXTURE_BINDING_ARRAY\n                    | Features::SAMPLED_TEXTURE_AND_STORAGE_BUFFER_ARRAY_NON_UNIFORM_INDEXING\n                    | Features::PARTIALLY_BOUND_BINDING_ARRAY,\n            )\n            .limits(Limits {\n                max_samplers_per_shader_stage: 4,\n                ..Limits::default()\n            }),\n    )\n    .run_async(|ctx| async move { binding_array_samplers(ctx, true).await });\n\nasync fn binding_array_samplers(ctx: TestingContext, partially_bound: bool) {\n    let shader = r#\"\n        @group(0) @binding(0)\n        var samplers: binding_array<sampler>;\n        @group(0) @binding(1)\n        var texture: texture_2d<f32>;\n        @group(0) @binding(2)\n        var<storage, read_write> output_values: array<u32>;\n\n        @compute\n        @workgroup_size(2, 1, 1)\n        fn compMain(@builtin(global_invocation_id) id: vec3u) {\n            output_values[id.x] = pack4x8unorm(textureSampleLevel(texture, samplers[id.x], vec2f(0.25 + (0.5 * 0.25), 0.5), 0.0));\n        }\n    \"#;\n\n    let module = ctx\n        .device\n        .create_shader_module(wgpu::ShaderModuleDescriptor {\n            label: Some(\"Binding Array Texture\"),\n            source: wgpu::ShaderSource::Wgsl(shader.into()),\n        });\n\n    let input_image: [u8; 8] = [\n        255, 0, 0, 255, //\n        0, 255, 0, 255, //\n    ];\n\n    let expected_output: [u8; 8] = [\n        191, 64, 0, 255, //\n        255, 0, 0, 255, //\n    ];\n\n    let texture = ctx.device.create_texture(&wgpu::TextureDescriptor {\n        label: None,\n        size: Extent3d {\n            width: 2,\n            height: 1,\n            depth_or_array_layers: 1,\n        },\n        mip_level_count: 1,\n        sample_count: 1,\n        dimension: TextureDimension::D2,\n        format: TextureFormat::Rgba8Unorm,\n        usage: TextureUsages::TEXTURE_BINDING | TextureUsages::COPY_DST,\n        view_formats: &[],\n    });\n\n    ctx.queue.write_texture(\n        TexelCopyTextureInfo {\n            texture: &texture,\n            mip_level: 0,\n            origin: Origin3d::ZERO,\n            aspect: TextureAspect::All,\n        },\n        &input_image,\n        TexelCopyBufferLayout {\n            offset: 0,\n            bytes_per_row: Some(8),\n            rows_per_image: Some(1),\n        },\n        Extent3d {\n            width: 2,\n            height: 1,\n            depth_or_array_layers: 1,\n        },\n    );\n\n    let input_view = texture.create_view(&TextureViewDescriptor::default());\n\n    let samplers = [\n        ctx.device.create_sampler(&SamplerDescriptor {\n            label: None,\n            address_mode_u: AddressMode::ClampToEdge,\n            address_mode_v: AddressMode::ClampToEdge,\n            address_mode_w: AddressMode::ClampToEdge,\n            mag_filter: FilterMode::Linear,\n            min_filter: FilterMode::Linear,\n            mipmap_filter: FilterMode::Linear,\n            lod_min_clamp: 0.0,\n            lod_max_clamp: 1000.0,\n            compare: None,\n            anisotropy_clamp: 1,\n            border_color: None,\n        }),\n        ctx.device.create_sampler(&SamplerDescriptor {\n            label: None,\n            address_mode_u: AddressMode::ClampToEdge,\n            address_mode_v: AddressMode::ClampToEdge,\n            address_mode_w: AddressMode::ClampToEdge,\n            mag_filter: FilterMode::Nearest,\n            min_filter: FilterMode::Nearest,\n            mipmap_filter: FilterMode::Nearest,\n            lod_min_clamp: 0.0,\n            lod_max_clamp: 1000.0,\n            compare: None,\n            anisotropy_clamp: 1,\n            border_color: None,\n        }),\n    ];\n\n    let output_buffer = ctx.device.create_buffer(&BufferDescriptor {\n        label: None,\n        size: 4 * 2,\n        usage: BufferUsages::STORAGE | BufferUsages::COPY_SRC,\n        mapped_at_creation: false,\n    });\n\n    let multiplier = if partially_bound { 2 } else { 1 };\n\n    let bind_group_layout = ctx\n        .device\n        .create_bind_group_layout(&BindGroupLayoutDescriptor {\n            label: Some(\"Bind Group Layout\"),\n            entries: &[\n                BindGroupLayoutEntry {\n                    binding: 0,\n                    visibility: ShaderStages::COMPUTE,\n                    ty: BindingType::Sampler(SamplerBindingType::Filtering),\n                    count: Some(NonZeroU32::new(2 * multiplier).unwrap()),\n                },\n                BindGroupLayoutEntry {\n                    binding: 1,\n                    visibility: ShaderStages::COMPUTE,\n                    ty: BindingType::Texture {\n                        sample_type: wgpu::TextureSampleType::Float { filterable: true },\n                        view_dimension: wgpu::TextureViewDimension::D2,\n                        multisampled: false,\n                    },\n                    count: None,\n                },\n                BindGroupLayoutEntry {\n                    binding: 2,\n                    visibility: ShaderStages::COMPUTE,\n                    ty: BindingType::Buffer {\n                        ty: BufferBindingType::Storage { read_only: false },\n                        has_dynamic_offset: false,\n                        min_binding_size: Some(NonZeroU64::new(4).unwrap()),\n                    },\n                    count: None,\n                },\n            ],\n        });\n\n    let sampler_references: Vec<_> = samplers.iter().collect();\n\n    let bind_group = ctx.device.create_bind_group(&BindGroupDescriptor {\n        label: Some(\"Bind Group\"),\n        layout: &bind_group_layout,\n        entries: &[\n            BindGroupEntry {\n                binding: 0,\n                resource: BindingResource::SamplerArray(&sampler_references),\n            },\n            BindGroupEntry {\n                binding: 1,\n                resource: BindingResource::TextureView(&input_view),\n            },\n            BindGroupEntry {\n                binding: 2,\n                resource: output_buffer.as_entire_binding(),\n            },\n        ],\n    });\n\n    let pipeline_layout = ctx\n        .device\n        .create_pipeline_layout(&PipelineLayoutDescriptor {\n            label: Some(\"Pipeline Layout\"),\n            bind_group_layouts: &[&bind_group_layout],\n            push_constant_ranges: &[],\n        });\n\n    let pipeline = ctx\n        .device\n        .create_compute_pipeline(&ComputePipelineDescriptor {\n            label: Some(\"Compute Pipeline\"),\n            layout: Some(&pipeline_layout),\n            module: &module,\n            entry_point: Some(\"compMain\"),\n            compilation_options: Default::default(),\n            cache: None,\n        });\n\n    let mut encoder = ctx\n        .device\n        .create_command_encoder(&CommandEncoderDescriptor { label: None });\n    {\n        let mut render_pass = encoder.begin_compute_pass(&ComputePassDescriptor {\n            label: None,\n            timestamp_writes: None,\n        });\n        render_pass.set_pipeline(&pipeline);\n        render_pass.set_bind_group(0, &bind_group, &[]);\n        render_pass.dispatch_workgroups(1, 1, 1);\n    }\n\n    let readback_buffer = ctx.device.create_buffer(&BufferDescriptor {\n        label: None,\n        size: 4 * 2,\n        usage: BufferUsages::MAP_READ | BufferUsages::COPY_DST,\n        mapped_at_creation: false,\n    });\n\n    encoder.copy_buffer_to_buffer(&output_buffer, 0, &readback_buffer, 0, 4 * 2);\n\n    ctx.queue.submit(Some(encoder.finish()));\n\n    readback_buffer.slice(..).map_async(MapMode::Read, |_| {});\n    ctx.device.poll(Maintain::Wait);\n\n    let readback_buffer_slice = readback_buffer.slice(..).get_mapped_range();\n\n    assert_eq!(&readback_buffer_slice[0..8], &expected_output[..]);\n}",
    "repo": "gfx-rs/wgpu",
    "path": "./datasets/diagrams-repos/gfx-rs/wgpu/tests/tests/binding_array/samplers.rs",
    "query": "What is the structure of the bind group layout and how do its entries correspond to shader bindings?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'bindGroupLayout', 'node_id': 'bindGroupLayout', 'description': 'Main bind group layout structure', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'samplerEntry', 'node_id': 'samplerEntry', 'description': 'Binding entry for sampler array at binding 0', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'textureEntry', 'node_id': 'textureEntry', 'description': 'Binding entry for 2D texture at binding 1', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'storageBufferEntry', 'node_id': 'storageBufferEntry', 'description': 'Binding entry for storage buffer at binding 2', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'shaderBindings', 'node_id': 'shaderBindings', 'description': 'WGSL shader binding declarations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'samplerArrayType', 'node_id': 'samplerArrayType', 'description': 'Sampler array binding type with filtering', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'textureType', 'node_id': 'textureType', 'description': '2D texture binding type with float sampling', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'storageBufferType', 'node_id': 'storageBufferType', 'description': 'Storage buffer binding type with read/write access', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'shaderSamplerDecl', 'node_id': 'shaderSamplerDecl', 'description': 'Shader sampler array declaration', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'shaderTextureDecl', 'node_id': 'shaderTextureDecl', 'description': 'Shader texture declaration', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'shaderStorageDecl', 'node_id': 'shaderStorageDecl', 'description': 'Shader storage buffer declaration', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'bindGroupVisibility', 'node_id': 'bindGroupVisibility', 'description': 'Shader stage visibility (Compute)', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'bindingCounts', 'node_id': 'bindingCounts', 'description': 'Optional binding array sizes', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'bindGroupLayout', 'node_id_to': 'samplerEntry', 'description': 'contains'}, {'node_id_from': 'bindGroupLayout', 'node_id_to': 'textureEntry', 'description': 'contains'}, {'node_id_from': 'bindGroupLayout', 'node_id_to': 'storageBufferEntry', 'description': 'contains'}, {'node_id_from': 'samplerEntry', 'node_id_to': 'samplerArrayType', 'description': 'uses'}, {'node_id_from': 'textureEntry', 'node_id_to': 'textureType', 'description': 'uses'}, {'node_id_from': 'storageBufferEntry', 'node_id_to': 'storageBufferType', 'description': 'uses'}, {'node_id_from': 'shaderBindings', 'node_id_to': 'shaderSamplerDecl', 'description': 'contains'}, {'node_id_from': 'shaderBindings', 'node_id_to': 'shaderTextureDecl', 'description': 'contains'}, {'node_id_from': 'shaderBindings', 'node_id_to': 'shaderStorageDecl', 'description': 'contains'}, {'node_id_from': 'samplerEntry', 'node_id_to': 'bindGroupVisibility', 'description': 'specifies'}, {'node_id_from': 'textureEntry', 'node_id_to': 'bindGroupVisibility', 'description': 'specifies'}, {'node_id_from': 'storageBufferEntry', 'node_id_to': 'bindGroupVisibility', 'description': 'specifies'}, {'node_id_from': 'samplerEntry', 'node_id_to': 'bindingCounts', 'description': 'defines'}, {'node_id_from': 'shaderSamplerDecl', 'node_id_to': 'samplerEntry', 'description': 'corresponds to'}, {'node_id_from': 'shaderTextureDecl', 'node_id_to': 'textureEntry', 'description': 'corresponds to'}, {'node_id_from': 'shaderStorageDecl', 'node_id_to': 'storageBufferEntry', 'description': 'corresponds to'}], 'packages': [{'package_id': 'bindingTypes', 'children': ['samplerArrayType', 'textureType', 'storageBufferType'], 'description': 'Binding type definitions'}, {'package_id': 'shaderDeclarations', 'children': ['shaderSamplerDecl', 'shaderTextureDecl', 'shaderStorageDecl'], 'description': 'WGSL shader declarations'}, {'package_id': 'bindingConfiguration', 'children': ['bindGroupVisibility', 'bindingCounts'], 'description': 'Binding configuration parameters'}, {'package_id': 'bindingStructure', 'children': ['bindGroupLayout', 'samplerEntry', 'textureEntry', 'storageBufferEntry', 'shaderBindings'], 'description': 'Core binding structure components'}]}",
    "version": "full",
    "text_answer": "The bind group layout contains three entries that directly correspond to shader bindings: a sampler array at binding 0, a 2D texture at binding 1, and a storage buffer at binding 2. All entries are visible to the compute shader stage. The sampler array has a configurable size, while texture and storage buffer are single bindings.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C++",
    "code": "\n#ifndef REGION_COMMON_LGTWEAKS_LGTWEAKS_H_\n#define REGION_COMMON_LGTWEAKS_LGTWEAKS_H_\n\n#include <llvm-c/Types.h>\n#include \"../../../metal/types.h\"\n#include \"../../../globalstate.h\"\n#include \"../../../function/function.h\"\n#include \"../fatweaks/fatweaks.h\"\n\nclass LgtWeaks {\npublic:\n  LgtWeaks(\n      GlobalState* globalState,\n      KindStructs* kindStructsSource,\n      KindStructs* weakRefStructsSource,\n      bool elideChecksForKnownLive);\n\n  Ref assembleWeakRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* sourceType,\n      Reference* targetType,\n      Ref sourceRef);\n\n  WeakFatPtrLE weakStructPtrToLgtiWeakInterfacePtr(\n      FunctionState *functionState,\n      LLVMBuilderRef builder,\n      WeakFatPtrLE sourceRefLE,\n      StructKind *sourceStructKindM,\n      Reference *sourceStructTypeM,\n      InterfaceKind *targetInterfaceKindM,\n      Reference *targetInterfaceTypeM);\n\n  // Makes a non-weak interface ref into a weak interface ref\n  WeakFatPtrLE assembleInterfaceWeakRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* sourceType,\n      Reference* targetType,\n      InterfaceKind* interfaceKindM,\n      InterfaceFatPtrLE sourceInterfaceFatPtrLE);\n\n  WeakFatPtrLE assembleStructWeakRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* structTypeM,\n      Reference* targetTypeM,\n      StructKind* structKindM,\n      WrapperPtrLE objPtrLE);\n\n  WeakFatPtrLE assembleStaticSizedArrayWeakRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* sourceSSAMT,\n      StaticSizedArrayT* staticSizedArrayMT,\n      Reference* targetSSAWeakRefMT,\n      WrapperPtrLE objPtrLE);\n\n  WeakFatPtrLE assembleRuntimeSizedArrayWeakRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* sourceType,\n      RuntimeSizedArrayT* runtimeSizedArrayMT,\n      Reference* targetRSAWeakRefMT,\n      WrapperPtrLE sourceRefLE);\n\n  LLVMValueRef lockLgtiFatPtr(\n      AreaAndFileAndLine from,\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* refM,\n      WeakFatPtrLE weakRefLE,\n      bool knownLive);\n\n  void innerNoteWeakableDestroyed(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* concreteRefM,\n      ControlBlockPtrLE controlBlockPtrLE);\n\n\n  void aliasWeakRef(\n      AreaAndFileAndLine from,\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* weakRefMT,\n      Ref weakRef);\n\n  void discardWeakRef(\n      AreaAndFileAndLine from,\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* weakRefMT,\n      Ref weakRef);\n\n  LLVMValueRef getIsAliveFromWeakFatPtr(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* weakRefM,\n      WeakFatPtrLE weakFatPtrLE,\n      bool knownLive);\n\n  Ref getIsAliveFromWeakRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* weakRefM,\n      Ref weakRef,\n      bool knownLive);\n\n  LLVMValueRef fillWeakableControlBlock(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      KindStructs* structs,\n      Kind* kindM,\n      LLVMValueRef controlBlockLE);\n\n  WeakFatPtrLE weakInterfaceRefToWeakStructRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* weakInterfaceRefMT,\n      WeakFatPtrLE weakInterfaceFatPtrLE);\n\n  void buildCheckWeakRef(\n      AreaAndFileAndLine checkerAFL,\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      bool expectLive,\n      Reference* weakRefM,\n      Ref weakRef);\n\n\n  static LLVMTypeRef makeWeakRefHeaderStruct(GlobalState* globalState, RegionId* regionId);\n\n  void mainSetup(FunctionState* functionState, LLVMBuilderRef builder);\n  void mainCleanup(FunctionState* functionState, LLVMBuilderRef builder);\n\nprivate:\n  LLVMValueRef getTargetGenFromWeakRef(\n      LLVMBuilderRef builder,\n      KindStructs* weakRefStructsSource,\n      Kind* kind,\n      WeakFatPtrLE weakRefLE);\n\n  LLVMValueRef getLgtiFromWeakRef(\n      LLVMBuilderRef builder,\n      WeakFatPtrLE weakRefLE);\n\n  void buildCheckLgti(\n      LLVMBuilderRef builder,\n      LLVMValueRef lgtiLE);\n\n  LLVMValueRef getNewLgti(\n      FunctionState* functionState,\n      LLVMBuilderRef builder);\n\n  LLVMValueRef getLGTEntryGenPtr(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      LLVMValueRef lgtiLE);\n\n  LLVMValueRef getLGTEntryNextFreePtr(\n      LLVMBuilderRef builder,\n      LLVMValueRef lgtiLE);\n\n  LLVMValueRef getActualGenFromLGT(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      LLVMValueRef lgtiLE);\n\n  GlobalState* globalState = nullptr;\n  FatWeaks fatWeaks_;\n  KindStructs* kindStructsSource;\n  KindStructs* weakRefStructsSource;\n  bool elideChecksForKnownLive;\n\n  LLVMValueRef lgtTablePtrLE = nullptr;\n\n  LLVMValueRef getLgtCapacityPtr(LLVMBuilderRef builder);\n  LLVMValueRef getLgtFirstFreeLgtiPtr(LLVMBuilderRef builder);\n  LLVMValueRef getLgtEntriesArrayPtr(LLVMBuilderRef builder);\n\n};\n\n#endif",
    "repo": "ValeLang/Vale",
    "path": "./datasets/diagrams-repos/ValeLang/Vale/Backend/src/region/common/lgtweaks/lgtweaks.h",
    "query": "Show the relationships between LgtWeaks, GlobalState, FunctionState, and KindStructs.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'LgtWeaks', 'node_id': 'LgtWeaks', 'description': 'Main class for managing weak references', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'GlobalState', 'node_id': 'GlobalState', 'description': 'Global program state container', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'FunctionState', 'node_id': 'FunctionState', 'description': 'State for function execution', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'KindStructs', 'node_id': 'KindStructs', 'description': 'Container for type structures', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'LgtWeaks', 'node_id_to': 'GlobalState', 'description': 'has'}, {'node_id_from': 'LgtWeaks', 'node_id_to': 'KindStructs', 'description': 'uses'}, {'node_id_from': 'LgtWeaks', 'node_id_to': 'FunctionState', 'description': 'uses in methods'}], 'packages': []}",
    "version": "minimal",
    "text_answer": "LgtWeaks class manages weak references and depends on GlobalState (stored as a member), uses two KindStructs instances (for kind and weak ref structures), and interacts with FunctionState in its methods.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C++",
    "code": "\n#ifndef REGION_COMMON_LGTWEAKS_LGTWEAKS_H_\n#define REGION_COMMON_LGTWEAKS_LGTWEAKS_H_\n\n#include <llvm-c/Types.h>\n#include \"../../../metal/types.h\"\n#include \"../../../globalstate.h\"\n#include \"../../../function/function.h\"\n#include \"../fatweaks/fatweaks.h\"\n\nclass LgtWeaks {\npublic:\n  LgtWeaks(\n      GlobalState* globalState,\n      KindStructs* kindStructsSource,\n      KindStructs* weakRefStructsSource,\n      bool elideChecksForKnownLive);\n\n  Ref assembleWeakRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* sourceType,\n      Reference* targetType,\n      Ref sourceRef);\n\n  WeakFatPtrLE weakStructPtrToLgtiWeakInterfacePtr(\n      FunctionState *functionState,\n      LLVMBuilderRef builder,\n      WeakFatPtrLE sourceRefLE,\n      StructKind *sourceStructKindM,\n      Reference *sourceStructTypeM,\n      InterfaceKind *targetInterfaceKindM,\n      Reference *targetInterfaceTypeM);\n\n  // Makes a non-weak interface ref into a weak interface ref\n  WeakFatPtrLE assembleInterfaceWeakRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* sourceType,\n      Reference* targetType,\n      InterfaceKind* interfaceKindM,\n      InterfaceFatPtrLE sourceInterfaceFatPtrLE);\n\n  WeakFatPtrLE assembleStructWeakRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* structTypeM,\n      Reference* targetTypeM,\n      StructKind* structKindM,\n      WrapperPtrLE objPtrLE);\n\n  WeakFatPtrLE assembleStaticSizedArrayWeakRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* sourceSSAMT,\n      StaticSizedArrayT* staticSizedArrayMT,\n      Reference* targetSSAWeakRefMT,\n      WrapperPtrLE objPtrLE);\n\n  WeakFatPtrLE assembleRuntimeSizedArrayWeakRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* sourceType,\n      RuntimeSizedArrayT* runtimeSizedArrayMT,\n      Reference* targetRSAWeakRefMT,\n      WrapperPtrLE sourceRefLE);\n\n  LLVMValueRef lockLgtiFatPtr(\n      AreaAndFileAndLine from,\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* refM,\n      WeakFatPtrLE weakRefLE,\n      bool knownLive);\n\n  void innerNoteWeakableDestroyed(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* concreteRefM,\n      ControlBlockPtrLE controlBlockPtrLE);\n\n\n  void aliasWeakRef(\n      AreaAndFileAndLine from,\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* weakRefMT,\n      Ref weakRef);\n\n  void discardWeakRef(\n      AreaAndFileAndLine from,\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* weakRefMT,\n      Ref weakRef);\n\n  LLVMValueRef getIsAliveFromWeakFatPtr(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* weakRefM,\n      WeakFatPtrLE weakFatPtrLE,\n      bool knownLive);\n\n  Ref getIsAliveFromWeakRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* weakRefM,\n      Ref weakRef,\n      bool knownLive);\n\n  LLVMValueRef fillWeakableControlBlock(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      KindStructs* structs,\n      Kind* kindM,\n      LLVMValueRef controlBlockLE);\n\n  WeakFatPtrLE weakInterfaceRefToWeakStructRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* weakInterfaceRefMT,\n      WeakFatPtrLE weakInterfaceFatPtrLE);\n\n  void buildCheckWeakRef(\n      AreaAndFileAndLine checkerAFL,\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      bool expectLive,\n      Reference* weakRefM,\n      Ref weakRef);\n\n\n  static LLVMTypeRef makeWeakRefHeaderStruct(GlobalState* globalState, RegionId* regionId);\n\n  void mainSetup(FunctionState* functionState, LLVMBuilderRef builder);\n  void mainCleanup(FunctionState* functionState, LLVMBuilderRef builder);\n\nprivate:\n  LLVMValueRef getTargetGenFromWeakRef(\n      LLVMBuilderRef builder,\n      KindStructs* weakRefStructsSource,\n      Kind* kind,\n      WeakFatPtrLE weakRefLE);\n\n  LLVMValueRef getLgtiFromWeakRef(\n      LLVMBuilderRef builder,\n      WeakFatPtrLE weakRefLE);\n\n  void buildCheckLgti(\n      LLVMBuilderRef builder,\n      LLVMValueRef lgtiLE);\n\n  LLVMValueRef getNewLgti(\n      FunctionState* functionState,\n      LLVMBuilderRef builder);\n\n  LLVMValueRef getLGTEntryGenPtr(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      LLVMValueRef lgtiLE);\n\n  LLVMValueRef getLGTEntryNextFreePtr(\n      LLVMBuilderRef builder,\n      LLVMValueRef lgtiLE);\n\n  LLVMValueRef getActualGenFromLGT(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      LLVMValueRef lgtiLE);\n\n  GlobalState* globalState = nullptr;\n  FatWeaks fatWeaks_;\n  KindStructs* kindStructsSource;\n  KindStructs* weakRefStructsSource;\n  bool elideChecksForKnownLive;\n\n  LLVMValueRef lgtTablePtrLE = nullptr;\n\n  LLVMValueRef getLgtCapacityPtr(LLVMBuilderRef builder);\n  LLVMValueRef getLgtFirstFreeLgtiPtr(LLVMBuilderRef builder);\n  LLVMValueRef getLgtEntriesArrayPtr(LLVMBuilderRef builder);\n\n};\n\n#endif",
    "repo": "ValeLang/Vale",
    "path": "./datasets/diagrams-repos/ValeLang/Vale/Backend/src/region/common/lgtweaks/lgtweaks.h",
    "query": "Show the relationships between LgtWeaks, GlobalState, FunctionState, and KindStructs.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'LgtWeaks', 'node_id': 'LgtWeaks', 'description': 'Main class for managing weak references', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'globalState', 'node_id': 'globalState', 'description': 'Global state reference', 'visibility': 'private', 'return_type': 'GlobalState*', 'params': None, 'source_class_id': 'LgtWeaks'}, {'type': 'field', 'name': 'kindStructsSource', 'node_id': 'kindStructsSource', 'description': 'Source of kind structures', 'visibility': 'private', 'return_type': 'KindStructs*', 'params': None, 'source_class_id': 'LgtWeaks'}, {'type': 'field', 'name': 'weakRefStructsSource', 'node_id': 'weakRefStructsSource', 'description': 'Source of weak reference structures', 'visibility': 'private', 'return_type': 'KindStructs*', 'params': None, 'source_class_id': 'LgtWeaks'}, {'type': 'class', 'name': 'GlobalState', 'node_id': 'GlobalState', 'description': 'Global program state container', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'FunctionState', 'node_id': 'FunctionState', 'description': 'State for function execution', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'KindStructs', 'node_id': 'KindStructs', 'description': 'Container for type structures', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'LgtWeaks', 'node_id_to': 'GlobalState', 'description': 'has'}, {'node_id_from': 'LgtWeaks', 'node_id_to': 'kindStructsSource', 'description': 'uses for kind structures'}, {'node_id_from': 'LgtWeaks', 'node_id_to': 'weakRefStructsSource', 'description': 'uses for weak ref structures'}, {'node_id_from': 'LgtWeaks', 'node_id_to': 'FunctionState', 'description': 'uses in methods'}, {'node_id_from': 'LgtWeaks', 'node_id_to': 'KindStructs', 'description': 'uses'}, {'node_id_from': 'LgtWeaks', 'node_id_to': 'globalState', 'description': ''}], 'packages': [{'package_id': 'weakRefs', 'children': ['LgtWeaks', 'globalState', 'kindStructsSource', 'weakRefStructsSource'], 'description': 'Weak references management'}]}",
    "version": "medium",
    "text_answer": "LgtWeaks class manages weak references and depends on GlobalState (stored as a member), uses two KindStructs instances (for kind and weak ref structures), and interacts with FunctionState in its methods.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C++",
    "code": "\n#ifndef REGION_COMMON_LGTWEAKS_LGTWEAKS_H_\n#define REGION_COMMON_LGTWEAKS_LGTWEAKS_H_\n\n#include <llvm-c/Types.h>\n#include \"../../../metal/types.h\"\n#include \"../../../globalstate.h\"\n#include \"../../../function/function.h\"\n#include \"../fatweaks/fatweaks.h\"\n\nclass LgtWeaks {\npublic:\n  LgtWeaks(\n      GlobalState* globalState,\n      KindStructs* kindStructsSource,\n      KindStructs* weakRefStructsSource,\n      bool elideChecksForKnownLive);\n\n  Ref assembleWeakRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* sourceType,\n      Reference* targetType,\n      Ref sourceRef);\n\n  WeakFatPtrLE weakStructPtrToLgtiWeakInterfacePtr(\n      FunctionState *functionState,\n      LLVMBuilderRef builder,\n      WeakFatPtrLE sourceRefLE,\n      StructKind *sourceStructKindM,\n      Reference *sourceStructTypeM,\n      InterfaceKind *targetInterfaceKindM,\n      Reference *targetInterfaceTypeM);\n\n  // Makes a non-weak interface ref into a weak interface ref\n  WeakFatPtrLE assembleInterfaceWeakRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* sourceType,\n      Reference* targetType,\n      InterfaceKind* interfaceKindM,\n      InterfaceFatPtrLE sourceInterfaceFatPtrLE);\n\n  WeakFatPtrLE assembleStructWeakRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* structTypeM,\n      Reference* targetTypeM,\n      StructKind* structKindM,\n      WrapperPtrLE objPtrLE);\n\n  WeakFatPtrLE assembleStaticSizedArrayWeakRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* sourceSSAMT,\n      StaticSizedArrayT* staticSizedArrayMT,\n      Reference* targetSSAWeakRefMT,\n      WrapperPtrLE objPtrLE);\n\n  WeakFatPtrLE assembleRuntimeSizedArrayWeakRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* sourceType,\n      RuntimeSizedArrayT* runtimeSizedArrayMT,\n      Reference* targetRSAWeakRefMT,\n      WrapperPtrLE sourceRefLE);\n\n  LLVMValueRef lockLgtiFatPtr(\n      AreaAndFileAndLine from,\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* refM,\n      WeakFatPtrLE weakRefLE,\n      bool knownLive);\n\n  void innerNoteWeakableDestroyed(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* concreteRefM,\n      ControlBlockPtrLE controlBlockPtrLE);\n\n\n  void aliasWeakRef(\n      AreaAndFileAndLine from,\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* weakRefMT,\n      Ref weakRef);\n\n  void discardWeakRef(\n      AreaAndFileAndLine from,\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* weakRefMT,\n      Ref weakRef);\n\n  LLVMValueRef getIsAliveFromWeakFatPtr(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* weakRefM,\n      WeakFatPtrLE weakFatPtrLE,\n      bool knownLive);\n\n  Ref getIsAliveFromWeakRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* weakRefM,\n      Ref weakRef,\n      bool knownLive);\n\n  LLVMValueRef fillWeakableControlBlock(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      KindStructs* structs,\n      Kind* kindM,\n      LLVMValueRef controlBlockLE);\n\n  WeakFatPtrLE weakInterfaceRefToWeakStructRef(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      Reference* weakInterfaceRefMT,\n      WeakFatPtrLE weakInterfaceFatPtrLE);\n\n  void buildCheckWeakRef(\n      AreaAndFileAndLine checkerAFL,\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      bool expectLive,\n      Reference* weakRefM,\n      Ref weakRef);\n\n\n  static LLVMTypeRef makeWeakRefHeaderStruct(GlobalState* globalState, RegionId* regionId);\n\n  void mainSetup(FunctionState* functionState, LLVMBuilderRef builder);\n  void mainCleanup(FunctionState* functionState, LLVMBuilderRef builder);\n\nprivate:\n  LLVMValueRef getTargetGenFromWeakRef(\n      LLVMBuilderRef builder,\n      KindStructs* weakRefStructsSource,\n      Kind* kind,\n      WeakFatPtrLE weakRefLE);\n\n  LLVMValueRef getLgtiFromWeakRef(\n      LLVMBuilderRef builder,\n      WeakFatPtrLE weakRefLE);\n\n  void buildCheckLgti(\n      LLVMBuilderRef builder,\n      LLVMValueRef lgtiLE);\n\n  LLVMValueRef getNewLgti(\n      FunctionState* functionState,\n      LLVMBuilderRef builder);\n\n  LLVMValueRef getLGTEntryGenPtr(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      LLVMValueRef lgtiLE);\n\n  LLVMValueRef getLGTEntryNextFreePtr(\n      LLVMBuilderRef builder,\n      LLVMValueRef lgtiLE);\n\n  LLVMValueRef getActualGenFromLGT(\n      FunctionState* functionState,\n      LLVMBuilderRef builder,\n      LLVMValueRef lgtiLE);\n\n  GlobalState* globalState = nullptr;\n  FatWeaks fatWeaks_;\n  KindStructs* kindStructsSource;\n  KindStructs* weakRefStructsSource;\n  bool elideChecksForKnownLive;\n\n  LLVMValueRef lgtTablePtrLE = nullptr;\n\n  LLVMValueRef getLgtCapacityPtr(LLVMBuilderRef builder);\n  LLVMValueRef getLgtFirstFreeLgtiPtr(LLVMBuilderRef builder);\n  LLVMValueRef getLgtEntriesArrayPtr(LLVMBuilderRef builder);\n\n};\n\n#endif",
    "repo": "ValeLang/Vale",
    "path": "./datasets/diagrams-repos/ValeLang/Vale/Backend/src/region/common/lgtweaks/lgtweaks.h",
    "query": "Show the relationships between LgtWeaks, GlobalState, FunctionState, and KindStructs.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'LgtWeaks', 'node_id': 'LgtWeaks', 'description': 'Main class for managing weak references', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'globalState', 'node_id': 'globalState', 'description': 'Global state reference', 'visibility': 'private', 'return_type': 'GlobalState*', 'params': None, 'source_class_id': 'LgtWeaks'}, {'type': 'field', 'name': 'kindStructsSource', 'node_id': 'kindStructsSource', 'description': 'Source of kind structures', 'visibility': 'private', 'return_type': 'KindStructs*', 'params': None, 'source_class_id': 'LgtWeaks'}, {'type': 'field', 'name': 'weakRefStructsSource', 'node_id': 'weakRefStructsSource', 'description': 'Source of weak reference structures', 'visibility': 'private', 'return_type': 'KindStructs*', 'params': None, 'source_class_id': 'LgtWeaks'}, {'type': 'field', 'name': 'elideChecksForKnownLive', 'node_id': 'elideChecksForKnownLive', 'description': 'Flag to skip checks for known live objects', 'visibility': 'private', 'return_type': 'bool', 'params': None, 'source_class_id': 'LgtWeaks'}, {'type': 'field', 'name': 'lgtTablePtrLE', 'node_id': 'lgtTablePtrLE', 'description': 'Pointer to LGT table', 'visibility': 'private', 'return_type': 'LLVMValueRef', 'params': None, 'source_class_id': 'LgtWeaks'}, {'type': 'method', 'name': 'LgtWeaks', 'node_id': 'LgtWeaksConstructor', 'description': 'Constructor', 'visibility': 'public', 'return_type': None, 'params': '(GlobalState*, KindStructs*, KindStructs*, bool)', 'source_class_id': 'LgtWeaks'}, {'type': 'class', 'name': 'GlobalState', 'node_id': 'GlobalState', 'description': 'Global program state container', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'FunctionState', 'node_id': 'FunctionState', 'description': 'State for function execution', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'KindStructs', 'node_id': 'KindStructs', 'description': 'Container for type structures', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'mainSetup', 'node_id': 'mainSetup', 'description': 'Setup main function', 'visibility': 'public', 'return_type': 'void', 'params': '(FunctionState*, LLVMBuilderRef)', 'source_class_id': 'LgtWeaks'}, {'type': 'method', 'name': 'mainCleanup', 'node_id': 'mainCleanup', 'description': 'Cleanup main function', 'visibility': 'public', 'return_type': 'void', 'params': '(FunctionState*, LLVMBuilderRef)', 'source_class_id': 'LgtWeaks'}], 'edges': [{'node_id_from': 'LgtWeaks', 'node_id_to': 'GlobalState', 'description': 'has'}, {'node_id_from': 'LgtWeaks', 'node_id_to': 'kindStructsSource', 'description': 'uses for kind structures'}, {'node_id_from': 'LgtWeaks', 'node_id_to': 'weakRefStructsSource', 'description': 'uses for weak ref structures'}, {'node_id_from': 'LgtWeaks', 'node_id_to': 'FunctionState', 'description': 'uses in methods'}, {'node_id_from': 'LgtWeaks', 'node_id_to': 'KindStructs', 'description': 'uses'}, {'node_id_from': 'mainSetup', 'node_id_to': 'FunctionState', 'description': 'uses'}, {'node_id_from': 'mainCleanup', 'node_id_to': 'FunctionState', 'description': 'uses'}, {'node_id_from': 'LgtWeaks', 'node_id_to': 'LgtWeaksConstructor', 'description': ''}, {'node_id_from': 'LgtWeaks', 'node_id_to': 'globalState', 'description': ''}, {'node_id_from': 'LgtWeaks', 'node_id_to': 'elideChecksForKnownLive', 'description': ''}, {'node_id_from': 'LgtWeaks', 'node_id_to': 'lgtTablePtrLE', 'description': ''}, {'node_id_from': 'LgtWeaks', 'node_id_to': 'mainSetup', 'description': ''}, {'node_id_from': 'LgtWeaks', 'node_id_to': 'mainCleanup', 'description': ''}], 'packages': [{'package_id': 'weakRefs', 'children': ['LgtWeaks', 'globalState', 'kindStructsSource', 'weakRefStructsSource', 'elideChecksForKnownLive', 'lgtTablePtrLE', 'LgtWeaksConstructor', 'mainSetup', 'mainCleanup'], 'description': 'Weak references management'}, {'package_id': 'state', 'children': ['GlobalState', 'FunctionState'], 'description': 'Program state management'}]}",
    "version": "full",
    "text_answer": "LgtWeaks class manages weak references and depends on GlobalState (stored as a member), uses two KindStructs instances (for kind and weak ref structures), and interacts with FunctionState in its methods.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C",
    "code": "\n#include <fcntl.h>\n#include <sys/ioctl.h>\n#include \"aos/vfs.h\"\n#if AOS_COMP_CLI\n#include \"aos/cli.h\"\n#endif\n#include <drivers/u_ld.h>\n#include <drivers/ddkc_log.h>\n#include <vfsdev/uart_dev.h>\n#include <drivers/char/u_device.h>\n\nstatic void uart_read_test(char *buf, int len, int argc, char **argv);\nstatic void uart_write_test(char *buf, int len, int argc, char **argv);\nstatic void uart_echo_test(char *buf, int len, int argc, char **argv);\n\nstatic void uart_test_usage(void) {\n    ddkc_info(\"uart test purpose, please follow the following commands format\\n\");\n    ddkc_info(\"\\tuartw <port_id> <string>\\n\");\n    ddkc_info(\"\\t\\t<port_id>: target UART's port id\\n\");\n    ddkc_info(\"\\t\\t<string>: target string to be sent via UART\\n\");\n    ddkc_info(\"\\tuartr <port_id>\\n\");\n    ddkc_info(\"\\t\\t<port_id>: target UART's port id\\n\");\n}\n\nstatic void uart_write_test(char *buf, int len, int argc, char **argv)\n{\n    int i = 0;\n    int j = 0;\n    int ret = 0;\n    int port_id = 0;\n    char *string = 0;\n    int fd = -1;\n    char buffer[50] = {0};\n    char dev_name[16] = {0};\n\n    ddkc_loud(\"buf:%s, len:%d\\n\", buf, len);\n    for (i = 0; i < argc; i++) {\n        ddkc_loud(\"argv[%d]:%s\\n\", i, *(argv + i));\n    }\n\n    if (argc <= 2) {\n        uart_test_usage();\n        return;\n    }\n\n    port_id = atoi(argv[1]);\n    string = argv[2];\n\n    snprintf(dev_name, sizeof(dev_name), \"/dev/ttyUART%d\", port_id );\n    ddkc_info(\"opening device:%s\\r\\n\", dev_name);\n    fd = open(dev_name, 0);\n\n    if (fd < 0) {\n        ddkc_err(\"open %s failed\\r\\n\", dev_name);\n        return;\n    }\n\n    ddkc_info(\"set baudrate to 1500000\\r\\n\");\n    ret = ioctl(fd, IOC_UART_SET_CFLAG, B1500000 | CS8);\n    if (ret) {\n        ddkc_err(\"ioctl on %s failed, ret:%d\\r\\n\", dev_name, ret);\n        close(fd);\n        return;\n    }\n    ddkc_info(\"set baudrate done\\r\\n\");\n\n    ddkc_info(\"writing %s\\r\\n\", string);\n    ret = write(fd, string, strlen(string));\n    ddkc_info(\"write return %d\\r\\n\", ret);\n\n    ddkc_info(\"closing %s\\r\\n\", dev_name);\n    close(fd);\n    ddkc_info(\"%s closed\\r\\n\", dev_name);\n\n    return;\n}\n\nstatic void uart_read_test(char *buf, int len, int argc, char **argv)\n{\n    int i = 0;\n    int j = 0;\n    int ret = 0;\n    int port_id = 0;\n    int ms = 0;\n    char *string = 0;\n    int fd = -1;\n    char buffer[50] = {0};\n    char dev_name[16] = {0};\n\n    ddkc_loud(\"buf:%s, len:%d\\n\", buf, len);\n    for (i = 0; i < argc; i++) {\n        ddkc_loud(\"argv[%d]:%s\\n\", i, *(argv + i));\n    }\n\n    if (argc <= 2) {\n        uart_test_usage();\n        return;\n    }\n\n    port_id = atoi(argv[1]);\n    ms = atoi(argv[2]);\n\n    snprintf(dev_name, sizeof(dev_name), \"/dev/ttyUART%d\", port_id );\n    ddkc_info(\"opening device:%s\\r\\n\", dev_name);\n    fd = open(dev_name, 0);\n\n    if (fd < 0) {\n        ddkc_err(\"open %s failed\\r\\n\", dev_name);\n        return;\n    }\n\n    ddkc_info(\"set baudrate to 1500000\\r\\n\");\n    ret = ioctl(fd, IOC_UART_SET_CFLAG, B1500000 | CS8);\n    if (ret) {\n        ddkc_err(\"ioctl on %s failed, ret:%d\\r\\n\", dev_name, ret);\n        close(fd);\n        return;\n    }\n    ddkc_info(\"set baudrate done\\r\\n\");\n\n    do {\n        ret = read(fd, buffer, sizeof(buffer));\n        if (ret > 0) {\n            for (i = 0; i < ret; i++)\n                printf(\"%c\", buffer[i]);\n            printf(\"\\r\\n\");\n        }\n\n        memset(buffer, 0, sizeof(buffer));\n        usleep(100000);\n        j++;\n    } while(j < (ms/100));\n\n    ddkc_info(\"closing %s\\r\\n\", dev_name);\n    close(fd);\n    ddkc_info(\"%s closed\\r\\n\", dev_name);\n\n    return;\n}\n\nstatic void uart_echo_test(char *buf, int len, int argc, char **argv)\n{\n    int i = 0;\n    int j = 0;\n    int ret = 0;\n    int port_id = 0;\n    int ms = 0;\n    char *string = 0;\n    int fd = -1;\n    char buffer[50] = {0};\n    char dev_name[16] = {0};\n\n    ddkc_loud(\"buf:%s, len:%d\\n\", buf, len);\n    for (i = 0; i < argc; i++) {\n        ddkc_loud(\"argv[%d]:%s\\n\", i, *(argv + i));\n    }\n\n    if (argc <= 2) {\n        uart_test_usage();\n        return;\n    }\n\n    port_id = atoi(argv[1]);\n    ms = atoi(argv[2]);\n\n    snprintf(dev_name, sizeof(dev_name), \"/dev/ttyUART%d\", port_id );\n    ddkc_info(\"opening device:%s\\r\\n\", dev_name);\n    fd = open(dev_name, 0);\n\n    if (fd < 0) {\n        ddkc_err(\"open %s failed\\r\\n\", dev_name);\n        return;\n    }\n    ddkc_info(\"set baudrate to 1500000\\r\\n\");\n    ret = ioctl(fd, IOC_UART_SET_CFLAG, B1500000 | CS8);\n    if (ret) {\n        ddkc_err(\"ioctl on %s failed, ret:%d\\r\\n\", dev_name, ret);\n        close(fd);\n        return;\n    }\n    ddkc_info(\"set baudrate done\\r\\n\");\n\n    do {\n        ret = read(fd, buffer, sizeof(buffer));\n        if (ret > 0) {\n            for (i = 0; i < ret; i++)\n                printf(\"%c\", buffer[i]);\n            printf(\"\\r\\n\");\n        }\n\n        ret = write(fd, buffer, sizeof(buffer));\n        if (ret != sizeof(buffer)) {\n            ddkc_warn(\"write error, ret:%d\\r\\n\", ret);\n        }\n        memset(buffer, 0, sizeof(buffer));\n        usleep(100000);\n        j++;\n    } while(j < (ms/100));\n\n    ddkc_info(\"closing %s\\r\\n\", dev_name);\n    close(fd);\n    ddkc_info(\"%s closed\\r\\n\", dev_name);\n\n    return;\n}\n\n#if AOS_COMP_CLI\nstruct cli_command vfs_uart_cli_cmds[] = {\n    { \"uartw\", \"uart tx test\", uart_write_test, },\n    { \"uartr\", \"uart rx test\", uart_read_test, },\n    { \"uarte\", \"uart echo test\", uart_echo_test, },\n};\n\nint vfs_uart_test_cmd_init(void)\n{\n    return aos_cli_register_commands(&vfs_uart_cli_cmds[0], sizeof(vfs_uart_cli_cmds) / sizeof(vfs_uart_cli_cmds[0]));\n}\n\nPOST_DRIVER_ENTRY(vfs_uart_test_cmd_init)\n#endif /* AOS_COMP_CLI */",
    "repo": "alibaba/AliOS-Things",
    "path": "./datasets/diagrams-repos/alibaba/AliOS-Things/components/drivers/peripheral/uart/example/uart_example.c",
    "query": "Explain how CLI commands are registered and executed in this system.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'cli_command', 'node_id': 'cli_command', 'description': 'Structure defining CLI command with name, help text and handler function', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'vfs_uart_cli_cmds', 'node_id': 'vfs_uart_cli_cmds', 'description': 'Array of CLI commands for UART operations', 'visibility': 'private', 'return_type': 'cli_command[]', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'vfs_uart_test_cmd_init', 'node_id': 'vfs_uart_test_cmd_init', 'description': 'Initializes and registers UART CLI commands', 'visibility': 'public', 'return_type': 'int', 'params': 'void', 'source_class_id': None}, {'type': 'function', 'name': 'aos_cli_register_commands', 'node_id': 'aos_cli_register_commands', 'description': 'System function to register CLI commands', 'visibility': 'public', 'return_type': 'int', 'params': '(cli_command* cmds, int num_cmds)', 'source_class_id': None}], 'edges': [{'node_id_from': 'vfs_uart_test_cmd_init', 'node_id_to': 'aos_cli_register_commands', 'description': 'registers commands'}, {'node_id_from': 'vfs_uart_test_cmd_init', 'node_id_to': 'vfs_uart_cli_cmds', 'description': 'uses'}, {'node_id_from': 'vfs_uart_cli_cmds', 'node_id_to': 'cli_command', 'description': 'contains'}], 'packages': [{'package_id': 'cliSystem', 'children': ['cli_command', 'vfs_uart_cli_cmds', 'vfs_uart_test_cmd_init', 'aos_cli_register_commands'], 'description': 'CLI command registration system'}]}",
    "version": "minimal",
    "text_answer": "CLI commands are registered during system initialization through POST_DRIVER_ENTRY, which calls vfs_uart_test_cmd_init. This function registers an array of command structures (vfs_uart_cli_cmds) using aos_cli_register_commands. Each command structure contains a command name, help text, and handler function pointer for UART operations (write, read, echo).",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C",
    "code": "\n#include <fcntl.h>\n#include <sys/ioctl.h>\n#include \"aos/vfs.h\"\n#if AOS_COMP_CLI\n#include \"aos/cli.h\"\n#endif\n#include <drivers/u_ld.h>\n#include <drivers/ddkc_log.h>\n#include <vfsdev/uart_dev.h>\n#include <drivers/char/u_device.h>\n\nstatic void uart_read_test(char *buf, int len, int argc, char **argv);\nstatic void uart_write_test(char *buf, int len, int argc, char **argv);\nstatic void uart_echo_test(char *buf, int len, int argc, char **argv);\n\nstatic void uart_test_usage(void) {\n    ddkc_info(\"uart test purpose, please follow the following commands format\\n\");\n    ddkc_info(\"\\tuartw <port_id> <string>\\n\");\n    ddkc_info(\"\\t\\t<port_id>: target UART's port id\\n\");\n    ddkc_info(\"\\t\\t<string>: target string to be sent via UART\\n\");\n    ddkc_info(\"\\tuartr <port_id>\\n\");\n    ddkc_info(\"\\t\\t<port_id>: target UART's port id\\n\");\n}\n\nstatic void uart_write_test(char *buf, int len, int argc, char **argv)\n{\n    int i = 0;\n    int j = 0;\n    int ret = 0;\n    int port_id = 0;\n    char *string = 0;\n    int fd = -1;\n    char buffer[50] = {0};\n    char dev_name[16] = {0};\n\n    ddkc_loud(\"buf:%s, len:%d\\n\", buf, len);\n    for (i = 0; i < argc; i++) {\n        ddkc_loud(\"argv[%d]:%s\\n\", i, *(argv + i));\n    }\n\n    if (argc <= 2) {\n        uart_test_usage();\n        return;\n    }\n\n    port_id = atoi(argv[1]);\n    string = argv[2];\n\n    snprintf(dev_name, sizeof(dev_name), \"/dev/ttyUART%d\", port_id );\n    ddkc_info(\"opening device:%s\\r\\n\", dev_name);\n    fd = open(dev_name, 0);\n\n    if (fd < 0) {\n        ddkc_err(\"open %s failed\\r\\n\", dev_name);\n        return;\n    }\n\n    ddkc_info(\"set baudrate to 1500000\\r\\n\");\n    ret = ioctl(fd, IOC_UART_SET_CFLAG, B1500000 | CS8);\n    if (ret) {\n        ddkc_err(\"ioctl on %s failed, ret:%d\\r\\n\", dev_name, ret);\n        close(fd);\n        return;\n    }\n    ddkc_info(\"set baudrate done\\r\\n\");\n\n    ddkc_info(\"writing %s\\r\\n\", string);\n    ret = write(fd, string, strlen(string));\n    ddkc_info(\"write return %d\\r\\n\", ret);\n\n    ddkc_info(\"closing %s\\r\\n\", dev_name);\n    close(fd);\n    ddkc_info(\"%s closed\\r\\n\", dev_name);\n\n    return;\n}\n\nstatic void uart_read_test(char *buf, int len, int argc, char **argv)\n{\n    int i = 0;\n    int j = 0;\n    int ret = 0;\n    int port_id = 0;\n    int ms = 0;\n    char *string = 0;\n    int fd = -1;\n    char buffer[50] = {0};\n    char dev_name[16] = {0};\n\n    ddkc_loud(\"buf:%s, len:%d\\n\", buf, len);\n    for (i = 0; i < argc; i++) {\n        ddkc_loud(\"argv[%d]:%s\\n\", i, *(argv + i));\n    }\n\n    if (argc <= 2) {\n        uart_test_usage();\n        return;\n    }\n\n    port_id = atoi(argv[1]);\n    ms = atoi(argv[2]);\n\n    snprintf(dev_name, sizeof(dev_name), \"/dev/ttyUART%d\", port_id );\n    ddkc_info(\"opening device:%s\\r\\n\", dev_name);\n    fd = open(dev_name, 0);\n\n    if (fd < 0) {\n        ddkc_err(\"open %s failed\\r\\n\", dev_name);\n        return;\n    }\n\n    ddkc_info(\"set baudrate to 1500000\\r\\n\");\n    ret = ioctl(fd, IOC_UART_SET_CFLAG, B1500000 | CS8);\n    if (ret) {\n        ddkc_err(\"ioctl on %s failed, ret:%d\\r\\n\", dev_name, ret);\n        close(fd);\n        return;\n    }\n    ddkc_info(\"set baudrate done\\r\\n\");\n\n    do {\n        ret = read(fd, buffer, sizeof(buffer));\n        if (ret > 0) {\n            for (i = 0; i < ret; i++)\n                printf(\"%c\", buffer[i]);\n            printf(\"\\r\\n\");\n        }\n\n        memset(buffer, 0, sizeof(buffer));\n        usleep(100000);\n        j++;\n    } while(j < (ms/100));\n\n    ddkc_info(\"closing %s\\r\\n\", dev_name);\n    close(fd);\n    ddkc_info(\"%s closed\\r\\n\", dev_name);\n\n    return;\n}\n\nstatic void uart_echo_test(char *buf, int len, int argc, char **argv)\n{\n    int i = 0;\n    int j = 0;\n    int ret = 0;\n    int port_id = 0;\n    int ms = 0;\n    char *string = 0;\n    int fd = -1;\n    char buffer[50] = {0};\n    char dev_name[16] = {0};\n\n    ddkc_loud(\"buf:%s, len:%d\\n\", buf, len);\n    for (i = 0; i < argc; i++) {\n        ddkc_loud(\"argv[%d]:%s\\n\", i, *(argv + i));\n    }\n\n    if (argc <= 2) {\n        uart_test_usage();\n        return;\n    }\n\n    port_id = atoi(argv[1]);\n    ms = atoi(argv[2]);\n\n    snprintf(dev_name, sizeof(dev_name), \"/dev/ttyUART%d\", port_id );\n    ddkc_info(\"opening device:%s\\r\\n\", dev_name);\n    fd = open(dev_name, 0);\n\n    if (fd < 0) {\n        ddkc_err(\"open %s failed\\r\\n\", dev_name);\n        return;\n    }\n    ddkc_info(\"set baudrate to 1500000\\r\\n\");\n    ret = ioctl(fd, IOC_UART_SET_CFLAG, B1500000 | CS8);\n    if (ret) {\n        ddkc_err(\"ioctl on %s failed, ret:%d\\r\\n\", dev_name, ret);\n        close(fd);\n        return;\n    }\n    ddkc_info(\"set baudrate done\\r\\n\");\n\n    do {\n        ret = read(fd, buffer, sizeof(buffer));\n        if (ret > 0) {\n            for (i = 0; i < ret; i++)\n                printf(\"%c\", buffer[i]);\n            printf(\"\\r\\n\");\n        }\n\n        ret = write(fd, buffer, sizeof(buffer));\n        if (ret != sizeof(buffer)) {\n            ddkc_warn(\"write error, ret:%d\\r\\n\", ret);\n        }\n        memset(buffer, 0, sizeof(buffer));\n        usleep(100000);\n        j++;\n    } while(j < (ms/100));\n\n    ddkc_info(\"closing %s\\r\\n\", dev_name);\n    close(fd);\n    ddkc_info(\"%s closed\\r\\n\", dev_name);\n\n    return;\n}\n\n#if AOS_COMP_CLI\nstruct cli_command vfs_uart_cli_cmds[] = {\n    { \"uartw\", \"uart tx test\", uart_write_test, },\n    { \"uartr\", \"uart rx test\", uart_read_test, },\n    { \"uarte\", \"uart echo test\", uart_echo_test, },\n};\n\nint vfs_uart_test_cmd_init(void)\n{\n    return aos_cli_register_commands(&vfs_uart_cli_cmds[0], sizeof(vfs_uart_cli_cmds) / sizeof(vfs_uart_cli_cmds[0]));\n}\n\nPOST_DRIVER_ENTRY(vfs_uart_test_cmd_init)\n#endif /* AOS_COMP_CLI */",
    "repo": "alibaba/AliOS-Things",
    "path": "./datasets/diagrams-repos/alibaba/AliOS-Things/components/drivers/peripheral/uart/example/uart_example.c",
    "query": "Explain how CLI commands are registered and executed in this system.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'cli_command', 'node_id': 'cli_command', 'description': 'Structure defining CLI command with name, help text and handler function', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'vfs_uart_cli_cmds', 'node_id': 'vfs_uart_cli_cmds', 'description': 'Array of CLI commands for UART operations', 'visibility': 'private', 'return_type': 'cli_command[]', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'vfs_uart_test_cmd_init', 'node_id': 'vfs_uart_test_cmd_init', 'description': 'Initializes and registers UART CLI commands', 'visibility': 'public', 'return_type': 'int', 'params': 'void', 'source_class_id': None}, {'type': 'function', 'name': 'aos_cli_register_commands', 'node_id': 'aos_cli_register_commands', 'description': 'System function to register CLI commands', 'visibility': 'public', 'return_type': 'int', 'params': '(cli_command* cmds, int num_cmds)', 'source_class_id': None}, {'type': 'function', 'name': 'uart_write_test', 'node_id': 'uart_write_test', 'description': 'Handler for UART write command', 'visibility': 'private', 'return_type': 'void', 'params': '(char *buf, int len, int argc, char **argv)', 'source_class_id': None}, {'type': 'function', 'name': 'uart_read_test', 'node_id': 'uart_read_test', 'description': 'Handler for UART read command', 'visibility': 'private', 'return_type': 'void', 'params': '(char *buf, int len, int argc, char **argv)', 'source_class_id': None}, {'type': 'function', 'name': 'uart_echo_test', 'node_id': 'uart_echo_test', 'description': 'Handler for UART echo command', 'visibility': 'private', 'return_type': 'void', 'params': '(char *buf, int len, int argc, char **argv)', 'source_class_id': None}], 'edges': [{'node_id_from': 'vfs_uart_test_cmd_init', 'node_id_to': 'aos_cli_register_commands', 'description': 'registers commands'}, {'node_id_from': 'vfs_uart_test_cmd_init', 'node_id_to': 'vfs_uart_cli_cmds', 'description': 'uses'}, {'node_id_from': 'vfs_uart_cli_cmds', 'node_id_to': 'cli_command', 'description': 'contains'}, {'node_id_from': 'cli_command', 'node_id_to': 'uart_write_test', 'description': ''}, {'node_id_from': 'cli_command', 'node_id_to': 'uart_read_test', 'description': ''}, {'node_id_from': 'cli_command', 'node_id_to': 'uart_echo_test', 'description': ''}], 'packages': [{'package_id': 'cliSystem', 'children': ['vfs_uart_cli_cmds', 'vfs_uart_test_cmd_init', 'aos_cli_register_commands', 'uartHandlers'], 'description': 'CLI command registration system'}, {'package_id': 'uartHandlers', 'children': ['cli_command', 'uart_write_test', 'uart_read_test', 'uart_echo_test'], 'description': 'UART command handlers'}]}",
    "version": "medium",
    "text_answer": "CLI commands are registered during system initialization through POST_DRIVER_ENTRY, which calls vfs_uart_test_cmd_init. This function registers an array of command structures (vfs_uart_cli_cmds) using aos_cli_register_commands. Each command structure contains a command name, help text, and handler function pointer for UART operations (write, read, echo).",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C",
    "code": "\n#include <fcntl.h>\n#include <sys/ioctl.h>\n#include \"aos/vfs.h\"\n#if AOS_COMP_CLI\n#include \"aos/cli.h\"\n#endif\n#include <drivers/u_ld.h>\n#include <drivers/ddkc_log.h>\n#include <vfsdev/uart_dev.h>\n#include <drivers/char/u_device.h>\n\nstatic void uart_read_test(char *buf, int len, int argc, char **argv);\nstatic void uart_write_test(char *buf, int len, int argc, char **argv);\nstatic void uart_echo_test(char *buf, int len, int argc, char **argv);\n\nstatic void uart_test_usage(void) {\n    ddkc_info(\"uart test purpose, please follow the following commands format\\n\");\n    ddkc_info(\"\\tuartw <port_id> <string>\\n\");\n    ddkc_info(\"\\t\\t<port_id>: target UART's port id\\n\");\n    ddkc_info(\"\\t\\t<string>: target string to be sent via UART\\n\");\n    ddkc_info(\"\\tuartr <port_id>\\n\");\n    ddkc_info(\"\\t\\t<port_id>: target UART's port id\\n\");\n}\n\nstatic void uart_write_test(char *buf, int len, int argc, char **argv)\n{\n    int i = 0;\n    int j = 0;\n    int ret = 0;\n    int port_id = 0;\n    char *string = 0;\n    int fd = -1;\n    char buffer[50] = {0};\n    char dev_name[16] = {0};\n\n    ddkc_loud(\"buf:%s, len:%d\\n\", buf, len);\n    for (i = 0; i < argc; i++) {\n        ddkc_loud(\"argv[%d]:%s\\n\", i, *(argv + i));\n    }\n\n    if (argc <= 2) {\n        uart_test_usage();\n        return;\n    }\n\n    port_id = atoi(argv[1]);\n    string = argv[2];\n\n    snprintf(dev_name, sizeof(dev_name), \"/dev/ttyUART%d\", port_id );\n    ddkc_info(\"opening device:%s\\r\\n\", dev_name);\n    fd = open(dev_name, 0);\n\n    if (fd < 0) {\n        ddkc_err(\"open %s failed\\r\\n\", dev_name);\n        return;\n    }\n\n    ddkc_info(\"set baudrate to 1500000\\r\\n\");\n    ret = ioctl(fd, IOC_UART_SET_CFLAG, B1500000 | CS8);\n    if (ret) {\n        ddkc_err(\"ioctl on %s failed, ret:%d\\r\\n\", dev_name, ret);\n        close(fd);\n        return;\n    }\n    ddkc_info(\"set baudrate done\\r\\n\");\n\n    ddkc_info(\"writing %s\\r\\n\", string);\n    ret = write(fd, string, strlen(string));\n    ddkc_info(\"write return %d\\r\\n\", ret);\n\n    ddkc_info(\"closing %s\\r\\n\", dev_name);\n    close(fd);\n    ddkc_info(\"%s closed\\r\\n\", dev_name);\n\n    return;\n}\n\nstatic void uart_read_test(char *buf, int len, int argc, char **argv)\n{\n    int i = 0;\n    int j = 0;\n    int ret = 0;\n    int port_id = 0;\n    int ms = 0;\n    char *string = 0;\n    int fd = -1;\n    char buffer[50] = {0};\n    char dev_name[16] = {0};\n\n    ddkc_loud(\"buf:%s, len:%d\\n\", buf, len);\n    for (i = 0; i < argc; i++) {\n        ddkc_loud(\"argv[%d]:%s\\n\", i, *(argv + i));\n    }\n\n    if (argc <= 2) {\n        uart_test_usage();\n        return;\n    }\n\n    port_id = atoi(argv[1]);\n    ms = atoi(argv[2]);\n\n    snprintf(dev_name, sizeof(dev_name), \"/dev/ttyUART%d\", port_id );\n    ddkc_info(\"opening device:%s\\r\\n\", dev_name);\n    fd = open(dev_name, 0);\n\n    if (fd < 0) {\n        ddkc_err(\"open %s failed\\r\\n\", dev_name);\n        return;\n    }\n\n    ddkc_info(\"set baudrate to 1500000\\r\\n\");\n    ret = ioctl(fd, IOC_UART_SET_CFLAG, B1500000 | CS8);\n    if (ret) {\n        ddkc_err(\"ioctl on %s failed, ret:%d\\r\\n\", dev_name, ret);\n        close(fd);\n        return;\n    }\n    ddkc_info(\"set baudrate done\\r\\n\");\n\n    do {\n        ret = read(fd, buffer, sizeof(buffer));\n        if (ret > 0) {\n            for (i = 0; i < ret; i++)\n                printf(\"%c\", buffer[i]);\n            printf(\"\\r\\n\");\n        }\n\n        memset(buffer, 0, sizeof(buffer));\n        usleep(100000);\n        j++;\n    } while(j < (ms/100));\n\n    ddkc_info(\"closing %s\\r\\n\", dev_name);\n    close(fd);\n    ddkc_info(\"%s closed\\r\\n\", dev_name);\n\n    return;\n}\n\nstatic void uart_echo_test(char *buf, int len, int argc, char **argv)\n{\n    int i = 0;\n    int j = 0;\n    int ret = 0;\n    int port_id = 0;\n    int ms = 0;\n    char *string = 0;\n    int fd = -1;\n    char buffer[50] = {0};\n    char dev_name[16] = {0};\n\n    ddkc_loud(\"buf:%s, len:%d\\n\", buf, len);\n    for (i = 0; i < argc; i++) {\n        ddkc_loud(\"argv[%d]:%s\\n\", i, *(argv + i));\n    }\n\n    if (argc <= 2) {\n        uart_test_usage();\n        return;\n    }\n\n    port_id = atoi(argv[1]);\n    ms = atoi(argv[2]);\n\n    snprintf(dev_name, sizeof(dev_name), \"/dev/ttyUART%d\", port_id );\n    ddkc_info(\"opening device:%s\\r\\n\", dev_name);\n    fd = open(dev_name, 0);\n\n    if (fd < 0) {\n        ddkc_err(\"open %s failed\\r\\n\", dev_name);\n        return;\n    }\n    ddkc_info(\"set baudrate to 1500000\\r\\n\");\n    ret = ioctl(fd, IOC_UART_SET_CFLAG, B1500000 | CS8);\n    if (ret) {\n        ddkc_err(\"ioctl on %s failed, ret:%d\\r\\n\", dev_name, ret);\n        close(fd);\n        return;\n    }\n    ddkc_info(\"set baudrate done\\r\\n\");\n\n    do {\n        ret = read(fd, buffer, sizeof(buffer));\n        if (ret > 0) {\n            for (i = 0; i < ret; i++)\n                printf(\"%c\", buffer[i]);\n            printf(\"\\r\\n\");\n        }\n\n        ret = write(fd, buffer, sizeof(buffer));\n        if (ret != sizeof(buffer)) {\n            ddkc_warn(\"write error, ret:%d\\r\\n\", ret);\n        }\n        memset(buffer, 0, sizeof(buffer));\n        usleep(100000);\n        j++;\n    } while(j < (ms/100));\n\n    ddkc_info(\"closing %s\\r\\n\", dev_name);\n    close(fd);\n    ddkc_info(\"%s closed\\r\\n\", dev_name);\n\n    return;\n}\n\n#if AOS_COMP_CLI\nstruct cli_command vfs_uart_cli_cmds[] = {\n    { \"uartw\", \"uart tx test\", uart_write_test, },\n    { \"uartr\", \"uart rx test\", uart_read_test, },\n    { \"uarte\", \"uart echo test\", uart_echo_test, },\n};\n\nint vfs_uart_test_cmd_init(void)\n{\n    return aos_cli_register_commands(&vfs_uart_cli_cmds[0], sizeof(vfs_uart_cli_cmds) / sizeof(vfs_uart_cli_cmds[0]));\n}\n\nPOST_DRIVER_ENTRY(vfs_uart_test_cmd_init)\n#endif /* AOS_COMP_CLI */",
    "repo": "alibaba/AliOS-Things",
    "path": "./datasets/diagrams-repos/alibaba/AliOS-Things/components/drivers/peripheral/uart/example/uart_example.c",
    "query": "Explain how CLI commands are registered and executed in this system.",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'cli_command', 'node_id': 'cli_command', 'description': 'Structure defining CLI command with name, help text and handler function', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'vfs_uart_cli_cmds', 'node_id': 'vfs_uart_cli_cmds', 'description': 'Array of CLI commands for UART operations', 'visibility': 'private', 'return_type': 'cli_command[]', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'vfs_uart_test_cmd_init', 'node_id': 'vfs_uart_test_cmd_init', 'description': 'Initializes and registers UART CLI commands', 'visibility': 'public', 'return_type': 'int', 'params': 'void', 'source_class_id': None}, {'type': 'function', 'name': 'aos_cli_register_commands', 'node_id': 'aos_cli_register_commands', 'description': 'System function to register CLI commands', 'visibility': 'public', 'return_type': 'int', 'params': '(cli_command* cmds, int num_cmds)', 'source_class_id': None}, {'type': 'function', 'name': 'uart_write_test', 'node_id': 'uart_write_test', 'description': 'Handler for UART write command', 'visibility': 'private', 'return_type': 'void', 'params': '(char *buf, int len, int argc, char **argv)', 'source_class_id': None}, {'type': 'function', 'name': 'uart_read_test', 'node_id': 'uart_read_test', 'description': 'Handler for UART read command', 'visibility': 'private', 'return_type': 'void', 'params': '(char *buf, int len, int argc, char **argv)', 'source_class_id': None}, {'type': 'function', 'name': 'uart_echo_test', 'node_id': 'uart_echo_test', 'description': 'Handler for UART echo command', 'visibility': 'private', 'return_type': 'void', 'params': '(char *buf, int len, int argc, char **argv)', 'source_class_id': None}, {'type': 'function', 'name': 'uart_test_usage', 'node_id': 'uart_test_usage', 'description': 'Displays usage information for UART commands', 'visibility': 'private', 'return_type': 'void', 'params': 'void', 'source_class_id': None}, {'type': 'entity', 'name': 'POST_DRIVER_ENTRY', 'node_id': 'POST_DRIVER_ENTRY', 'description': 'System macro for registering initialization function', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'vfs_uart_test_cmd_init', 'node_id_to': 'aos_cli_register_commands', 'description': 'registers commands'}, {'node_id_from': 'vfs_uart_test_cmd_init', 'node_id_to': 'vfs_uart_cli_cmds', 'description': 'uses'}, {'node_id_from': 'vfs_uart_cli_cmds', 'node_id_to': 'cli_command', 'description': 'contains'}, {'node_id_from': 'cli_command', 'node_id_to': 'uart_write_test', 'description': ''}, {'node_id_from': 'cli_command', 'node_id_to': 'uart_read_test', 'description': ''}, {'node_id_from': 'cli_command', 'node_id_to': 'uart_echo_test', 'description': ''}, {'node_id_from': 'POST_DRIVER_ENTRY', 'node_id_to': 'vfs_uart_test_cmd_init', 'description': 'registers initialization'}, {'node_id_from': 'uart_write_test', 'node_id_to': 'uart_test_usage', 'description': 'calls'}, {'node_id_from': 'uart_read_test', 'node_id_to': 'uart_test_usage', 'description': 'calls'}, {'node_id_from': 'uart_echo_test', 'node_id_to': 'uart_test_usage', 'description': 'calls'}], 'packages': [{'package_id': 'cliSystem', 'children': ['uartHandlers', 'vfs_uart_cli_cmds', 'vfs_uart_test_cmd_init', 'aos_cli_register_commands', 'POST_DRIVER_ENTRY'], 'description': 'CLI command registration system'}, {'package_id': 'uartHandlers', 'children': ['cli_command', 'uart_write_test', 'uart_read_test', 'uart_echo_test', 'uart_test_usage'], 'description': 'UART command handlers and utilities'}]}",
    "version": "full",
    "text_answer": "CLI commands are registered during system initialization through POST_DRIVER_ENTRY, which calls vfs_uart_test_cmd_init. This function registers an array of command structures (vfs_uart_cli_cmds) using aos_cli_register_commands. Each command structure contains a command name, help text, and handler function pointer for UART operations (write, read, echo).",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Python",
    "code": "\nimport copy\nimport logging\nfrom collections.abc import Mapping\n\nimport salt.utils.data\nfrom salt.defaults import DEFAULT_TARGET_DELIM\nfrom salt.exceptions import SaltInvocationError\nfrom salt.utils.decorators.jinja import jinja_filter\nfrom salt.utils.odict import OrderedDict\n\nlog = logging.getLogger(__name__)\n\n\ndef update(dest, upd, recursive_update=True, merge_lists=False):\n    \"\"\"\n    Recursive version of the default dict.update\n\n    Merges upd recursively into dest\n\n    If recursive_update=False, will use the classic dict.update, or fall back\n    on a manual merge (helpful for non-dict types like FunctionWrapper)\n\n    If merge_lists=True, will aggregate list object types instead of replace.\n    The list in ``upd`` is added to the list in ``dest``, so the resulting list\n    is ``dest[key] + upd[key]``. This behavior is only activated when\n    recursive_update=True. By default merge_lists=False.\n\n    .. versionchanged:: 2016.11.6\n        When merging lists, duplicate values are removed. Values already\n        present in the ``dest`` list are not added from the ``upd`` list.\n    \"\"\"\n    if (not isinstance(dest, Mapping)) or (not isinstance(upd, Mapping)):\n        raise TypeError(\"Cannot update using non-dict types in dictupdate.update()\")\n    updkeys = list(upd.keys())\n    if not set(list(dest.keys())) & set(updkeys):\n        recursive_update = False\n    if recursive_update:\n        for key in updkeys:\n            val = upd[key]\n            try:\n                dest_subkey = dest.get(key, None)\n            except AttributeError:\n                dest_subkey = None\n            if isinstance(dest_subkey, Mapping) and isinstance(val, Mapping):\n                ret = update(dest_subkey, val, merge_lists=merge_lists)\n                dest[key] = ret\n            elif isinstance(dest_subkey, list) and isinstance(val, list):\n                if merge_lists:\n                    merged = copy.deepcopy(dest_subkey)\n                    merged.extend([x for x in val if x not in merged])\n                    dest[key] = merged\n                else:\n                    dest[key] = upd[key]\n            else:\n                dest[key] = upd[key]\n        return dest\n    for k in upd:\n        dest[k] = upd[k]\n    return dest\n\n\ndef merge_list(obj_a, obj_b):\n    ret = {}\n    for key, val in obj_a.items():\n        if key in obj_b:\n            ret[key] = [val, obj_b[key]]\n        else:\n            ret[key] = val\n    return ret\n\n\ndef merge_recurse(obj_a, obj_b, merge_lists=False):\n    copied = copy.deepcopy(obj_a)\n    return update(copied, obj_b, merge_lists=merge_lists)\n\n\ndef merge_aggregate(obj_a, obj_b):\n    from salt.serializers.yamlex import merge_recursive as _yamlex_merge_recursive\n\n    return _yamlex_merge_recursive(obj_a, obj_b, level=1)\n\n\ndef merge_overwrite(obj_a, obj_b, merge_lists=False):\n    for obj in obj_b:\n        if obj in obj_a:\n            obj_a[obj] = obj_b[obj]\n    return merge_recurse(obj_a, obj_b, merge_lists=merge_lists)\n\n\ndef merge(obj_a, obj_b, strategy=\"smart\", renderer=\"yaml\", merge_lists=False):\n    if strategy == \"smart\":\n        if renderer.split(\"|\")[-1] == \"yamlex\" or renderer.startswith(\"yamlex_\"):\n            strategy = \"aggregate\"\n        else:\n            strategy = \"recurse\"\n\n    if strategy == \"list\":\n        merged = merge_list(obj_a, obj_b)\n    elif strategy == \"recurse\":\n        merged = merge_recurse(obj_a, obj_b, merge_lists)\n    elif strategy == \"aggregate\":\n        #: level = 1 merge at least root data\n        merged = merge_aggregate(obj_a, obj_b)\n    elif strategy == \"overwrite\":\n        merged = merge_overwrite(obj_a, obj_b, merge_lists)\n    elif strategy == \"none\":\n        # If we do not want to merge, there is only one pillar passed, so we can safely use the default recurse,\n        # we just do not want to log an error\n        merged = merge_recurse(obj_a, obj_b)\n    else:\n        log.warning(\"Unknown merging strategy '%s', fallback to recurse\", strategy)\n        merged = merge_recurse(obj_a, obj_b)\n\n    return merged\n\n\ndef ensure_dict_key(in_dict, keys, delimiter=DEFAULT_TARGET_DELIM, ordered_dict=False):\n    \"\"\"\n    Ensures that in_dict contains the series of recursive keys defined in keys.\n\n    :param dict in_dict: The dict to work with.\n    :param str keys: The delimited string with one or more keys.\n    :param str delimiter: The delimiter to use in `keys`. Defaults to ':'.\n    :param bool ordered_dict: Create OrderedDicts if keys are missing.\n                              Default: create regular dicts.\n    :rtype: dict\n    :return: Returns the modified in-place `in_dict`.\n    \"\"\"\n    if delimiter in keys:\n        a_keys = keys.split(delimiter)\n    else:\n        a_keys = [keys]\n    dict_pointer = in_dict\n    while a_keys:\n        current_key = a_keys.pop(0)\n        if current_key not in dict_pointer or not isinstance(\n            dict_pointer[current_key], dict\n        ):\n            dict_pointer[current_key] = OrderedDict() if ordered_dict else {}\n        dict_pointer = dict_pointer[current_key]\n    return in_dict\n\n\ndef _dict_rpartition(in_dict, keys, delimiter=DEFAULT_TARGET_DELIM, ordered_dict=False):\n    \"\"\"\n    Helper function to:\n    - Ensure all but the last key in `keys` exist recursively in `in_dict`.\n    - Return the dict at the one-to-last key, and the last key\n\n    :param dict in_dict: The dict to work with.\n    :param str keys: The delimited string with one or more keys.\n    :param str delimiter: The delimiter to use in `keys`. Defaults to ':'.\n    :param bool ordered_dict: Create OrderedDicts if keys are missing.\n                              Default: create regular dicts.\n    :rtype: tuple(dict, str)\n    :return: (The dict at the one-to-last key, the last key)\n    \"\"\"\n    if delimiter in keys:\n        all_but_last_keys, _, last_key = keys.rpartition(delimiter)\n        ensure_dict_key(\n            in_dict, all_but_last_keys, delimiter=delimiter, ordered_dict=ordered_dict\n        )\n        dict_pointer = salt.utils.data.traverse_dict(\n            in_dict, all_but_last_keys, default=None, delimiter=delimiter\n        )\n    else:\n        dict_pointer = in_dict\n        last_key = keys\n    return dict_pointer, last_key\n\n\n@jinja_filter(\"set_dict_key_value\")\ndef set_dict_key_value(\n    in_dict, keys, value, delimiter=DEFAULT_TARGET_DELIM, ordered_dict=False\n):\n    \"\"\"\n    Ensures that in_dict contains the series of recursive keys defined in keys.\n    Also sets whatever is at the end of `in_dict` traversed with `keys` to `value`.\n\n    :param dict in_dict: The dictionary to work with\n    :param str keys: The delimited string with one or more keys.\n    :param any value: The value to assign to the nested dict-key.\n    :param str delimiter: The delimiter to use in `keys`. Defaults to ':'.\n    :param bool ordered_dict: Create OrderedDicts if keys are missing.\n                              Default: create regular dicts.\n    :rtype: dict\n    :return: Returns the modified in-place `in_dict`.\n    \"\"\"\n    dict_pointer, last_key = _dict_rpartition(\n        in_dict, keys, delimiter=delimiter, ordered_dict=ordered_dict\n    )\n    dict_pointer[last_key] = value\n    return in_dict\n\n\n@jinja_filter(\"update_dict_key_value\")\ndef update_dict_key_value(\n    in_dict, keys, value, delimiter=DEFAULT_TARGET_DELIM, ordered_dict=False\n):\n    \"\"\"\n    Ensures that in_dict contains the series of recursive keys defined in keys.\n    Also updates the dict, that is at the end of `in_dict` traversed with `keys`,\n    with `value`.\n\n    :param dict in_dict: The dictionary to work with\n    :param str keys: The delimited string with one or more keys.\n    :param any value: The value to update the nested dict-key with.\n    :param str delimiter: The delimiter to use in `keys`. Defaults to ':'.\n    :param bool ordered_dict: Create OrderedDicts if keys are missing.\n                              Default: create regular dicts.\n    :rtype: dict\n    :return: Returns the modified in-place `in_dict`.\n    \"\"\"\n    dict_pointer, last_key = _dict_rpartition(\n        in_dict, keys, delimiter=delimiter, ordered_dict=ordered_dict\n    )\n    if last_key not in dict_pointer or dict_pointer[last_key] is None:\n        dict_pointer[last_key] = OrderedDict() if ordered_dict else {}\n    try:\n        dict_pointer[last_key].update(value)\n    except AttributeError:\n        raise SaltInvocationError(\n            \"The last key contains a {}, which cannot update.\".format(\n                type(dict_pointer[last_key])\n            )\n        )\n    except (ValueError, TypeError):\n        raise SaltInvocationError(\n            \"Cannot update {} with a {}.\".format(\n                type(dict_pointer[last_key]), type(value)\n            )\n        )\n    return in_dict\n\n\n@jinja_filter(\"append_dict_key_value\")\ndef append_dict_key_value(\n    in_dict, keys, value, delimiter=DEFAULT_TARGET_DELIM, ordered_dict=False\n):\n    \"\"\"\n    Ensures that in_dict contains the series of recursive keys defined in keys.\n    Also appends `value` to the list that is at the end of `in_dict` traversed\n    with `keys`.\n\n    :param dict in_dict: The dictionary to work with\n    :param str keys: The delimited string with one or more keys.\n    :param any value: The value to append to the nested dict-key.\n    :param str delimiter: The delimiter to use in `keys`. Defaults to ':'.\n    :param bool ordered_dict: Create OrderedDicts if keys are missing.\n                              Default: create regular dicts.\n    :rtype: dict\n    :return: Returns the modified in-place `in_dict`.\n    \"\"\"\n    dict_pointer, last_key = _dict_rpartition(\n        in_dict, keys, delimiter=delimiter, ordered_dict=ordered_dict\n    )\n    if last_key not in dict_pointer or dict_pointer[last_key] is None:\n        dict_pointer[last_key] = []\n    try:\n        dict_pointer[last_key].append(value)\n    except AttributeError:\n        raise SaltInvocationError(\n            \"The last key contains a {}, which cannot append.\".format(\n                type(dict_pointer[last_key])\n            )\n        )\n    return in_dict\n\n\n@jinja_filter(\"extend_dict_key_value\")\ndef extend_dict_key_value(\n    in_dict, keys, value, delimiter=DEFAULT_TARGET_DELIM, ordered_dict=False\n):\n    \"\"\"\n    Ensures that in_dict contains the series of recursive keys defined in keys.\n    Also extends the list, that is at the end of `in_dict` traversed with `keys`,\n    with `value`.\n\n    :param dict in_dict: The dictionary to work with\n    :param str keys: The delimited string with one or more keys.\n    :param any value: The value to extend the nested dict-key with.\n    :param str delimiter: The delimiter to use in `keys`. Defaults to ':'.\n    :param bool ordered_dict: Create OrderedDicts if keys are missing.\n                              Default: create regular dicts.\n    :rtype: dict\n    :return: Returns the modified in-place `in_dict`.\n    \"\"\"\n    dict_pointer, last_key = _dict_rpartition(\n        in_dict, keys, delimiter=delimiter, ordered_dict=ordered_dict\n    )\n    if last_key not in dict_pointer or dict_pointer[last_key] is None:\n        dict_pointer[last_key] = []\n    try:\n        dict_pointer[last_key].extend(value)\n    except AttributeError:\n        raise SaltInvocationError(\n            \"The last key contains a {}, which cannot extend.\".format(\n                type(dict_pointer[last_key])\n            )\n        )\n    except TypeError:\n        raise SaltInvocationError(\n            \"Cannot extend {} with a {}.\".format(\n                type(dict_pointer[last_key]), type(value)\n            )\n        )\n    return in_dict",
    "repo": "saltstack/salt",
    "path": "./datasets/diagrams-repos/saltstack/salt/salt/utils/dictupdate.py",
    "query": "How does the `update` function handle merging of dictionaries, especially when both dictionaries contain nested dictionaries or lists?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'update', 'node_id': 'update', 'description': 'Recursively merges two dictionaries with support for nested structures', 'visibility': 'public', 'return_type': 'dict', 'params': '(dest, upd, recursive_update=True, merge_lists=False)', 'source_class_id': None}, {'type': 'entity', 'name': 'recursiveMerge', 'node_id': 'recursiveMerge', 'description': 'Recursive merging of nested dictionaries', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'listMerging', 'node_id': 'listMerging', 'description': 'Special handling for merging lists in dictionaries', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'update', 'node_id_to': 'recursiveMerge', 'description': 'performs recursive merge'}, {'node_id_from': 'update', 'node_id_to': 'listMerging', 'description': 'handles list merging'}], 'packages': [{'package_id': 'dictMergeOperations', 'children': ['update', 'recursiveMerge', 'listMerging'], 'description': 'Core dictionary merging functionality'}]}",
    "version": "minimal",
    "text_answer": "The update function performs recursive dictionary merging by checking each key-value pair. For nested dictionaries, it recursively merges their contents. When encountering lists, it either replaces them or merges them while removing duplicates, depending on the merge_lists parameter. Type checking ensures both inputs are dictionary-like objects.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Python",
    "code": "\nimport copy\nimport logging\nfrom collections.abc import Mapping\n\nimport salt.utils.data\nfrom salt.defaults import DEFAULT_TARGET_DELIM\nfrom salt.exceptions import SaltInvocationError\nfrom salt.utils.decorators.jinja import jinja_filter\nfrom salt.utils.odict import OrderedDict\n\nlog = logging.getLogger(__name__)\n\n\ndef update(dest, upd, recursive_update=True, merge_lists=False):\n    \"\"\"\n    Recursive version of the default dict.update\n\n    Merges upd recursively into dest\n\n    If recursive_update=False, will use the classic dict.update, or fall back\n    on a manual merge (helpful for non-dict types like FunctionWrapper)\n\n    If merge_lists=True, will aggregate list object types instead of replace.\n    The list in ``upd`` is added to the list in ``dest``, so the resulting list\n    is ``dest[key] + upd[key]``. This behavior is only activated when\n    recursive_update=True. By default merge_lists=False.\n\n    .. versionchanged:: 2016.11.6\n        When merging lists, duplicate values are removed. Values already\n        present in the ``dest`` list are not added from the ``upd`` list.\n    \"\"\"\n    if (not isinstance(dest, Mapping)) or (not isinstance(upd, Mapping)):\n        raise TypeError(\"Cannot update using non-dict types in dictupdate.update()\")\n    updkeys = list(upd.keys())\n    if not set(list(dest.keys())) & set(updkeys):\n        recursive_update = False\n    if recursive_update:\n        for key in updkeys:\n            val = upd[key]\n            try:\n                dest_subkey = dest.get(key, None)\n            except AttributeError:\n                dest_subkey = None\n            if isinstance(dest_subkey, Mapping) and isinstance(val, Mapping):\n                ret = update(dest_subkey, val, merge_lists=merge_lists)\n                dest[key] = ret\n            elif isinstance(dest_subkey, list) and isinstance(val, list):\n                if merge_lists:\n                    merged = copy.deepcopy(dest_subkey)\n                    merged.extend([x for x in val if x not in merged])\n                    dest[key] = merged\n                else:\n                    dest[key] = upd[key]\n            else:\n                dest[key] = upd[key]\n        return dest\n    for k in upd:\n        dest[k] = upd[k]\n    return dest\n\n\ndef merge_list(obj_a, obj_b):\n    ret = {}\n    for key, val in obj_a.items():\n        if key in obj_b:\n            ret[key] = [val, obj_b[key]]\n        else:\n            ret[key] = val\n    return ret\n\n\ndef merge_recurse(obj_a, obj_b, merge_lists=False):\n    copied = copy.deepcopy(obj_a)\n    return update(copied, obj_b, merge_lists=merge_lists)\n\n\ndef merge_aggregate(obj_a, obj_b):\n    from salt.serializers.yamlex import merge_recursive as _yamlex_merge_recursive\n\n    return _yamlex_merge_recursive(obj_a, obj_b, level=1)\n\n\ndef merge_overwrite(obj_a, obj_b, merge_lists=False):\n    for obj in obj_b:\n        if obj in obj_a:\n            obj_a[obj] = obj_b[obj]\n    return merge_recurse(obj_a, obj_b, merge_lists=merge_lists)\n\n\ndef merge(obj_a, obj_b, strategy=\"smart\", renderer=\"yaml\", merge_lists=False):\n    if strategy == \"smart\":\n        if renderer.split(\"|\")[-1] == \"yamlex\" or renderer.startswith(\"yamlex_\"):\n            strategy = \"aggregate\"\n        else:\n            strategy = \"recurse\"\n\n    if strategy == \"list\":\n        merged = merge_list(obj_a, obj_b)\n    elif strategy == \"recurse\":\n        merged = merge_recurse(obj_a, obj_b, merge_lists)\n    elif strategy == \"aggregate\":\n        #: level = 1 merge at least root data\n        merged = merge_aggregate(obj_a, obj_b)\n    elif strategy == \"overwrite\":\n        merged = merge_overwrite(obj_a, obj_b, merge_lists)\n    elif strategy == \"none\":\n        # If we do not want to merge, there is only one pillar passed, so we can safely use the default recurse,\n        # we just do not want to log an error\n        merged = merge_recurse(obj_a, obj_b)\n    else:\n        log.warning(\"Unknown merging strategy '%s', fallback to recurse\", strategy)\n        merged = merge_recurse(obj_a, obj_b)\n\n    return merged\n\n\ndef ensure_dict_key(in_dict, keys, delimiter=DEFAULT_TARGET_DELIM, ordered_dict=False):\n    \"\"\"\n    Ensures that in_dict contains the series of recursive keys defined in keys.\n\n    :param dict in_dict: The dict to work with.\n    :param str keys: The delimited string with one or more keys.\n    :param str delimiter: The delimiter to use in `keys`. Defaults to ':'.\n    :param bool ordered_dict: Create OrderedDicts if keys are missing.\n                              Default: create regular dicts.\n    :rtype: dict\n    :return: Returns the modified in-place `in_dict`.\n    \"\"\"\n    if delimiter in keys:\n        a_keys = keys.split(delimiter)\n    else:\n        a_keys = [keys]\n    dict_pointer = in_dict\n    while a_keys:\n        current_key = a_keys.pop(0)\n        if current_key not in dict_pointer or not isinstance(\n            dict_pointer[current_key], dict\n        ):\n            dict_pointer[current_key] = OrderedDict() if ordered_dict else {}\n        dict_pointer = dict_pointer[current_key]\n    return in_dict\n\n\ndef _dict_rpartition(in_dict, keys, delimiter=DEFAULT_TARGET_DELIM, ordered_dict=False):\n    \"\"\"\n    Helper function to:\n    - Ensure all but the last key in `keys` exist recursively in `in_dict`.\n    - Return the dict at the one-to-last key, and the last key\n\n    :param dict in_dict: The dict to work with.\n    :param str keys: The delimited string with one or more keys.\n    :param str delimiter: The delimiter to use in `keys`. Defaults to ':'.\n    :param bool ordered_dict: Create OrderedDicts if keys are missing.\n                              Default: create regular dicts.\n    :rtype: tuple(dict, str)\n    :return: (The dict at the one-to-last key, the last key)\n    \"\"\"\n    if delimiter in keys:\n        all_but_last_keys, _, last_key = keys.rpartition(delimiter)\n        ensure_dict_key(\n            in_dict, all_but_last_keys, delimiter=delimiter, ordered_dict=ordered_dict\n        )\n        dict_pointer = salt.utils.data.traverse_dict(\n            in_dict, all_but_last_keys, default=None, delimiter=delimiter\n        )\n    else:\n        dict_pointer = in_dict\n        last_key = keys\n    return dict_pointer, last_key\n\n\n@jinja_filter(\"set_dict_key_value\")\ndef set_dict_key_value(\n    in_dict, keys, value, delimiter=DEFAULT_TARGET_DELIM, ordered_dict=False\n):\n    \"\"\"\n    Ensures that in_dict contains the series of recursive keys defined in keys.\n    Also sets whatever is at the end of `in_dict` traversed with `keys` to `value`.\n\n    :param dict in_dict: The dictionary to work with\n    :param str keys: The delimited string with one or more keys.\n    :param any value: The value to assign to the nested dict-key.\n    :param str delimiter: The delimiter to use in `keys`. Defaults to ':'.\n    :param bool ordered_dict: Create OrderedDicts if keys are missing.\n                              Default: create regular dicts.\n    :rtype: dict\n    :return: Returns the modified in-place `in_dict`.\n    \"\"\"\n    dict_pointer, last_key = _dict_rpartition(\n        in_dict, keys, delimiter=delimiter, ordered_dict=ordered_dict\n    )\n    dict_pointer[last_key] = value\n    return in_dict\n\n\n@jinja_filter(\"update_dict_key_value\")\ndef update_dict_key_value(\n    in_dict, keys, value, delimiter=DEFAULT_TARGET_DELIM, ordered_dict=False\n):\n    \"\"\"\n    Ensures that in_dict contains the series of recursive keys defined in keys.\n    Also updates the dict, that is at the end of `in_dict` traversed with `keys`,\n    with `value`.\n\n    :param dict in_dict: The dictionary to work with\n    :param str keys: The delimited string with one or more keys.\n    :param any value: The value to update the nested dict-key with.\n    :param str delimiter: The delimiter to use in `keys`. Defaults to ':'.\n    :param bool ordered_dict: Create OrderedDicts if keys are missing.\n                              Default: create regular dicts.\n    :rtype: dict\n    :return: Returns the modified in-place `in_dict`.\n    \"\"\"\n    dict_pointer, last_key = _dict_rpartition(\n        in_dict, keys, delimiter=delimiter, ordered_dict=ordered_dict\n    )\n    if last_key not in dict_pointer or dict_pointer[last_key] is None:\n        dict_pointer[last_key] = OrderedDict() if ordered_dict else {}\n    try:\n        dict_pointer[last_key].update(value)\n    except AttributeError:\n        raise SaltInvocationError(\n            \"The last key contains a {}, which cannot update.\".format(\n                type(dict_pointer[last_key])\n            )\n        )\n    except (ValueError, TypeError):\n        raise SaltInvocationError(\n            \"Cannot update {} with a {}.\".format(\n                type(dict_pointer[last_key]), type(value)\n            )\n        )\n    return in_dict\n\n\n@jinja_filter(\"append_dict_key_value\")\ndef append_dict_key_value(\n    in_dict, keys, value, delimiter=DEFAULT_TARGET_DELIM, ordered_dict=False\n):\n    \"\"\"\n    Ensures that in_dict contains the series of recursive keys defined in keys.\n    Also appends `value` to the list that is at the end of `in_dict` traversed\n    with `keys`.\n\n    :param dict in_dict: The dictionary to work with\n    :param str keys: The delimited string with one or more keys.\n    :param any value: The value to append to the nested dict-key.\n    :param str delimiter: The delimiter to use in `keys`. Defaults to ':'.\n    :param bool ordered_dict: Create OrderedDicts if keys are missing.\n                              Default: create regular dicts.\n    :rtype: dict\n    :return: Returns the modified in-place `in_dict`.\n    \"\"\"\n    dict_pointer, last_key = _dict_rpartition(\n        in_dict, keys, delimiter=delimiter, ordered_dict=ordered_dict\n    )\n    if last_key not in dict_pointer or dict_pointer[last_key] is None:\n        dict_pointer[last_key] = []\n    try:\n        dict_pointer[last_key].append(value)\n    except AttributeError:\n        raise SaltInvocationError(\n            \"The last key contains a {}, which cannot append.\".format(\n                type(dict_pointer[last_key])\n            )\n        )\n    return in_dict\n\n\n@jinja_filter(\"extend_dict_key_value\")\ndef extend_dict_key_value(\n    in_dict, keys, value, delimiter=DEFAULT_TARGET_DELIM, ordered_dict=False\n):\n    \"\"\"\n    Ensures that in_dict contains the series of recursive keys defined in keys.\n    Also extends the list, that is at the end of `in_dict` traversed with `keys`,\n    with `value`.\n\n    :param dict in_dict: The dictionary to work with\n    :param str keys: The delimited string with one or more keys.\n    :param any value: The value to extend the nested dict-key with.\n    :param str delimiter: The delimiter to use in `keys`. Defaults to ':'.\n    :param bool ordered_dict: Create OrderedDicts if keys are missing.\n                              Default: create regular dicts.\n    :rtype: dict\n    :return: Returns the modified in-place `in_dict`.\n    \"\"\"\n    dict_pointer, last_key = _dict_rpartition(\n        in_dict, keys, delimiter=delimiter, ordered_dict=ordered_dict\n    )\n    if last_key not in dict_pointer or dict_pointer[last_key] is None:\n        dict_pointer[last_key] = []\n    try:\n        dict_pointer[last_key].extend(value)\n    except AttributeError:\n        raise SaltInvocationError(\n            \"The last key contains a {}, which cannot extend.\".format(\n                type(dict_pointer[last_key])\n            )\n        )\n    except TypeError:\n        raise SaltInvocationError(\n            \"Cannot extend {} with a {}.\".format(\n                type(dict_pointer[last_key]), type(value)\n            )\n        )\n    return in_dict",
    "repo": "saltstack/salt",
    "path": "./datasets/diagrams-repos/saltstack/salt/salt/utils/dictupdate.py",
    "query": "How does the `update` function handle merging of dictionaries, especially when both dictionaries contain nested dictionaries or lists?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'update', 'node_id': 'update', 'description': 'Recursively merges two dictionaries with support for nested structures', 'visibility': 'public', 'return_type': 'dict', 'params': '(dest, upd, recursive_update=True, merge_lists=False)', 'source_class_id': None}, {'type': 'entity', 'name': 'recursiveMerge', 'node_id': 'recursiveMerge', 'description': 'Recursive merging of nested dictionaries', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'listMerging', 'node_id': 'listMerging', 'description': 'Special handling for merging lists in dictionaries', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'typeChecking', 'node_id': 'typeChecking', 'description': 'Validates input types for merging', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'keyHandling', 'node_id': 'keyHandling', 'description': 'Processes dictionary keys during merge', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'copy.deepcopy', 'node_id': 'copy.deepcopy', 'description': 'Creates deep copy of lists for merging', 'visibility': 'public', 'return_type': 'Any', 'params': '(obj)', 'source_class_id': None}], 'edges': [{'node_id_from': 'update', 'node_id_to': 'recursiveMerge', 'description': 'performs recursive merge'}, {'node_id_from': 'update', 'node_id_to': 'listMerging', 'description': 'handles list merging'}, {'node_id_from': 'update', 'node_id_to': 'typeChecking', 'description': 'validates inputs'}, {'node_id_from': 'update', 'node_id_to': 'keyHandling', 'description': 'processes keys'}, {'node_id_from': 'listMerging', 'node_id_to': 'copy.deepcopy', 'description': 'creates copy of lists'}], 'packages': [{'package_id': 'dictMergeOperations', 'children': ['update', 'recursiveMerge', 'listMerging', 'typeChecking', 'keyHandling'], 'description': 'Dictionary merging functionality'}]}",
    "version": "medium",
    "text_answer": "The update function performs recursive dictionary merging by checking each key-value pair. For nested dictionaries, it recursively merges their contents. When encountering lists, it either replaces them or merges them while removing duplicates, depending on the merge_lists parameter. Type checking ensures both inputs are dictionary-like objects.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Python",
    "code": "\nimport copy\nimport logging\nfrom collections.abc import Mapping\n\nimport salt.utils.data\nfrom salt.defaults import DEFAULT_TARGET_DELIM\nfrom salt.exceptions import SaltInvocationError\nfrom salt.utils.decorators.jinja import jinja_filter\nfrom salt.utils.odict import OrderedDict\n\nlog = logging.getLogger(__name__)\n\n\ndef update(dest, upd, recursive_update=True, merge_lists=False):\n    \"\"\"\n    Recursive version of the default dict.update\n\n    Merges upd recursively into dest\n\n    If recursive_update=False, will use the classic dict.update, or fall back\n    on a manual merge (helpful for non-dict types like FunctionWrapper)\n\n    If merge_lists=True, will aggregate list object types instead of replace.\n    The list in ``upd`` is added to the list in ``dest``, so the resulting list\n    is ``dest[key] + upd[key]``. This behavior is only activated when\n    recursive_update=True. By default merge_lists=False.\n\n    .. versionchanged:: 2016.11.6\n        When merging lists, duplicate values are removed. Values already\n        present in the ``dest`` list are not added from the ``upd`` list.\n    \"\"\"\n    if (not isinstance(dest, Mapping)) or (not isinstance(upd, Mapping)):\n        raise TypeError(\"Cannot update using non-dict types in dictupdate.update()\")\n    updkeys = list(upd.keys())\n    if not set(list(dest.keys())) & set(updkeys):\n        recursive_update = False\n    if recursive_update:\n        for key in updkeys:\n            val = upd[key]\n            try:\n                dest_subkey = dest.get(key, None)\n            except AttributeError:\n                dest_subkey = None\n            if isinstance(dest_subkey, Mapping) and isinstance(val, Mapping):\n                ret = update(dest_subkey, val, merge_lists=merge_lists)\n                dest[key] = ret\n            elif isinstance(dest_subkey, list) and isinstance(val, list):\n                if merge_lists:\n                    merged = copy.deepcopy(dest_subkey)\n                    merged.extend([x for x in val if x not in merged])\n                    dest[key] = merged\n                else:\n                    dest[key] = upd[key]\n            else:\n                dest[key] = upd[key]\n        return dest\n    for k in upd:\n        dest[k] = upd[k]\n    return dest\n\n\ndef merge_list(obj_a, obj_b):\n    ret = {}\n    for key, val in obj_a.items():\n        if key in obj_b:\n            ret[key] = [val, obj_b[key]]\n        else:\n            ret[key] = val\n    return ret\n\n\ndef merge_recurse(obj_a, obj_b, merge_lists=False):\n    copied = copy.deepcopy(obj_a)\n    return update(copied, obj_b, merge_lists=merge_lists)\n\n\ndef merge_aggregate(obj_a, obj_b):\n    from salt.serializers.yamlex import merge_recursive as _yamlex_merge_recursive\n\n    return _yamlex_merge_recursive(obj_a, obj_b, level=1)\n\n\ndef merge_overwrite(obj_a, obj_b, merge_lists=False):\n    for obj in obj_b:\n        if obj in obj_a:\n            obj_a[obj] = obj_b[obj]\n    return merge_recurse(obj_a, obj_b, merge_lists=merge_lists)\n\n\ndef merge(obj_a, obj_b, strategy=\"smart\", renderer=\"yaml\", merge_lists=False):\n    if strategy == \"smart\":\n        if renderer.split(\"|\")[-1] == \"yamlex\" or renderer.startswith(\"yamlex_\"):\n            strategy = \"aggregate\"\n        else:\n            strategy = \"recurse\"\n\n    if strategy == \"list\":\n        merged = merge_list(obj_a, obj_b)\n    elif strategy == \"recurse\":\n        merged = merge_recurse(obj_a, obj_b, merge_lists)\n    elif strategy == \"aggregate\":\n        #: level = 1 merge at least root data\n        merged = merge_aggregate(obj_a, obj_b)\n    elif strategy == \"overwrite\":\n        merged = merge_overwrite(obj_a, obj_b, merge_lists)\n    elif strategy == \"none\":\n        # If we do not want to merge, there is only one pillar passed, so we can safely use the default recurse,\n        # we just do not want to log an error\n        merged = merge_recurse(obj_a, obj_b)\n    else:\n        log.warning(\"Unknown merging strategy '%s', fallback to recurse\", strategy)\n        merged = merge_recurse(obj_a, obj_b)\n\n    return merged\n\n\ndef ensure_dict_key(in_dict, keys, delimiter=DEFAULT_TARGET_DELIM, ordered_dict=False):\n    \"\"\"\n    Ensures that in_dict contains the series of recursive keys defined in keys.\n\n    :param dict in_dict: The dict to work with.\n    :param str keys: The delimited string with one or more keys.\n    :param str delimiter: The delimiter to use in `keys`. Defaults to ':'.\n    :param bool ordered_dict: Create OrderedDicts if keys are missing.\n                              Default: create regular dicts.\n    :rtype: dict\n    :return: Returns the modified in-place `in_dict`.\n    \"\"\"\n    if delimiter in keys:\n        a_keys = keys.split(delimiter)\n    else:\n        a_keys = [keys]\n    dict_pointer = in_dict\n    while a_keys:\n        current_key = a_keys.pop(0)\n        if current_key not in dict_pointer or not isinstance(\n            dict_pointer[current_key], dict\n        ):\n            dict_pointer[current_key] = OrderedDict() if ordered_dict else {}\n        dict_pointer = dict_pointer[current_key]\n    return in_dict\n\n\ndef _dict_rpartition(in_dict, keys, delimiter=DEFAULT_TARGET_DELIM, ordered_dict=False):\n    \"\"\"\n    Helper function to:\n    - Ensure all but the last key in `keys` exist recursively in `in_dict`.\n    - Return the dict at the one-to-last key, and the last key\n\n    :param dict in_dict: The dict to work with.\n    :param str keys: The delimited string with one or more keys.\n    :param str delimiter: The delimiter to use in `keys`. Defaults to ':'.\n    :param bool ordered_dict: Create OrderedDicts if keys are missing.\n                              Default: create regular dicts.\n    :rtype: tuple(dict, str)\n    :return: (The dict at the one-to-last key, the last key)\n    \"\"\"\n    if delimiter in keys:\n        all_but_last_keys, _, last_key = keys.rpartition(delimiter)\n        ensure_dict_key(\n            in_dict, all_but_last_keys, delimiter=delimiter, ordered_dict=ordered_dict\n        )\n        dict_pointer = salt.utils.data.traverse_dict(\n            in_dict, all_but_last_keys, default=None, delimiter=delimiter\n        )\n    else:\n        dict_pointer = in_dict\n        last_key = keys\n    return dict_pointer, last_key\n\n\n@jinja_filter(\"set_dict_key_value\")\ndef set_dict_key_value(\n    in_dict, keys, value, delimiter=DEFAULT_TARGET_DELIM, ordered_dict=False\n):\n    \"\"\"\n    Ensures that in_dict contains the series of recursive keys defined in keys.\n    Also sets whatever is at the end of `in_dict` traversed with `keys` to `value`.\n\n    :param dict in_dict: The dictionary to work with\n    :param str keys: The delimited string with one or more keys.\n    :param any value: The value to assign to the nested dict-key.\n    :param str delimiter: The delimiter to use in `keys`. Defaults to ':'.\n    :param bool ordered_dict: Create OrderedDicts if keys are missing.\n                              Default: create regular dicts.\n    :rtype: dict\n    :return: Returns the modified in-place `in_dict`.\n    \"\"\"\n    dict_pointer, last_key = _dict_rpartition(\n        in_dict, keys, delimiter=delimiter, ordered_dict=ordered_dict\n    )\n    dict_pointer[last_key] = value\n    return in_dict\n\n\n@jinja_filter(\"update_dict_key_value\")\ndef update_dict_key_value(\n    in_dict, keys, value, delimiter=DEFAULT_TARGET_DELIM, ordered_dict=False\n):\n    \"\"\"\n    Ensures that in_dict contains the series of recursive keys defined in keys.\n    Also updates the dict, that is at the end of `in_dict` traversed with `keys`,\n    with `value`.\n\n    :param dict in_dict: The dictionary to work with\n    :param str keys: The delimited string with one or more keys.\n    :param any value: The value to update the nested dict-key with.\n    :param str delimiter: The delimiter to use in `keys`. Defaults to ':'.\n    :param bool ordered_dict: Create OrderedDicts if keys are missing.\n                              Default: create regular dicts.\n    :rtype: dict\n    :return: Returns the modified in-place `in_dict`.\n    \"\"\"\n    dict_pointer, last_key = _dict_rpartition(\n        in_dict, keys, delimiter=delimiter, ordered_dict=ordered_dict\n    )\n    if last_key not in dict_pointer or dict_pointer[last_key] is None:\n        dict_pointer[last_key] = OrderedDict() if ordered_dict else {}\n    try:\n        dict_pointer[last_key].update(value)\n    except AttributeError:\n        raise SaltInvocationError(\n            \"The last key contains a {}, which cannot update.\".format(\n                type(dict_pointer[last_key])\n            )\n        )\n    except (ValueError, TypeError):\n        raise SaltInvocationError(\n            \"Cannot update {} with a {}.\".format(\n                type(dict_pointer[last_key]), type(value)\n            )\n        )\n    return in_dict\n\n\n@jinja_filter(\"append_dict_key_value\")\ndef append_dict_key_value(\n    in_dict, keys, value, delimiter=DEFAULT_TARGET_DELIM, ordered_dict=False\n):\n    \"\"\"\n    Ensures that in_dict contains the series of recursive keys defined in keys.\n    Also appends `value` to the list that is at the end of `in_dict` traversed\n    with `keys`.\n\n    :param dict in_dict: The dictionary to work with\n    :param str keys: The delimited string with one or more keys.\n    :param any value: The value to append to the nested dict-key.\n    :param str delimiter: The delimiter to use in `keys`. Defaults to ':'.\n    :param bool ordered_dict: Create OrderedDicts if keys are missing.\n                              Default: create regular dicts.\n    :rtype: dict\n    :return: Returns the modified in-place `in_dict`.\n    \"\"\"\n    dict_pointer, last_key = _dict_rpartition(\n        in_dict, keys, delimiter=delimiter, ordered_dict=ordered_dict\n    )\n    if last_key not in dict_pointer or dict_pointer[last_key] is None:\n        dict_pointer[last_key] = []\n    try:\n        dict_pointer[last_key].append(value)\n    except AttributeError:\n        raise SaltInvocationError(\n            \"The last key contains a {}, which cannot append.\".format(\n                type(dict_pointer[last_key])\n            )\n        )\n    return in_dict\n\n\n@jinja_filter(\"extend_dict_key_value\")\ndef extend_dict_key_value(\n    in_dict, keys, value, delimiter=DEFAULT_TARGET_DELIM, ordered_dict=False\n):\n    \"\"\"\n    Ensures that in_dict contains the series of recursive keys defined in keys.\n    Also extends the list, that is at the end of `in_dict` traversed with `keys`,\n    with `value`.\n\n    :param dict in_dict: The dictionary to work with\n    :param str keys: The delimited string with one or more keys.\n    :param any value: The value to extend the nested dict-key with.\n    :param str delimiter: The delimiter to use in `keys`. Defaults to ':'.\n    :param bool ordered_dict: Create OrderedDicts if keys are missing.\n                              Default: create regular dicts.\n    :rtype: dict\n    :return: Returns the modified in-place `in_dict`.\n    \"\"\"\n    dict_pointer, last_key = _dict_rpartition(\n        in_dict, keys, delimiter=delimiter, ordered_dict=ordered_dict\n    )\n    if last_key not in dict_pointer or dict_pointer[last_key] is None:\n        dict_pointer[last_key] = []\n    try:\n        dict_pointer[last_key].extend(value)\n    except AttributeError:\n        raise SaltInvocationError(\n            \"The last key contains a {}, which cannot extend.\".format(\n                type(dict_pointer[last_key])\n            )\n        )\n    except TypeError:\n        raise SaltInvocationError(\n            \"Cannot extend {} with a {}.\".format(\n                type(dict_pointer[last_key]), type(value)\n            )\n        )\n    return in_dict",
    "repo": "saltstack/salt",
    "path": "./datasets/diagrams-repos/saltstack/salt/salt/utils/dictupdate.py",
    "query": "How does the `update` function handle merging of dictionaries, especially when both dictionaries contain nested dictionaries or lists?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'update', 'node_id': 'update', 'description': 'Recursively merges two dictionaries with support for nested structures', 'visibility': 'public', 'return_type': 'dict', 'params': '(dest, upd, recursive_update=True, merge_lists=False)', 'source_class_id': None}, {'type': 'entity', 'name': 'recursiveMerge', 'node_id': 'recursiveMerge', 'description': 'Recursive merging of nested dictionaries', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'listMerging', 'node_id': 'listMerging', 'description': 'Special handling for merging lists in dictionaries', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'typeChecking', 'node_id': 'typeChecking', 'description': 'Validates input types for merging', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'keyHandling', 'node_id': 'keyHandling', 'description': 'Processes dictionary keys during merge', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'copy.deepcopy', 'node_id': 'copy.deepcopy', 'description': 'Creates deep copy of lists for merging', 'visibility': 'public', 'return_type': 'Any', 'params': '(obj)', 'source_class_id': None}, {'type': 'class', 'name': 'Mapping', 'node_id': 'Mapping', 'description': 'Abstract base class for dictionary-like types', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'duplicateRemoval', 'node_id': 'duplicateRemoval', 'description': 'Removes duplicate values when merging lists', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'attributeError', 'node_id': 'attributeError', 'description': 'Handles attribute errors during key access', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'nonRecursiveUpdate', 'node_id': 'nonRecursiveUpdate', 'description': 'Performs simple dictionary update when recursive_update is False', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'update', 'node_id_to': 'recursiveMerge', 'description': 'performs recursive merge'}, {'node_id_from': 'update', 'node_id_to': 'listMerging', 'description': 'handles list merging'}, {'node_id_from': 'update', 'node_id_to': 'typeChecking', 'description': 'validates inputs'}, {'node_id_from': 'update', 'node_id_to': 'keyHandling', 'description': 'processes keys'}, {'node_id_from': 'listMerging', 'node_id_to': 'copy.deepcopy', 'description': 'creates copy of lists'}, {'node_id_from': 'typeChecking', 'node_id_to': 'Mapping', 'description': 'checks type'}, {'node_id_from': 'listMerging', 'node_id_to': 'duplicateRemoval', 'description': 'removes duplicates'}, {'node_id_from': 'keyHandling', 'node_id_to': 'attributeError', 'description': 'handles errors'}, {'node_id_from': 'update', 'node_id_to': 'nonRecursiveUpdate', 'description': 'performs simple update'}], 'packages': [{'package_id': 'dictMergeOperations', 'children': ['update', 'recursiveMerge', 'listMerging', 'typeChecking', 'keyHandling', 'duplicateRemoval', 'nonRecursiveUpdate'], 'description': 'Dictionary merging functionality'}, {'package_id': 'utilities', 'children': ['copy.deepcopy', 'Mapping'], 'description': 'Utility functions and classes'}]}",
    "version": "full",
    "text_answer": "The update function performs recursive dictionary merging by checking each key-value pair. For nested dictionaries, it recursively merges their contents. When encountering lists, it either replaces them or merges them while removing duplicates, depending on the merge_lists parameter. Type checking ensures both inputs are dictionary-like objects.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Scala",
    "code": "\npackage monix.reactive.observers.buffers\n\nimport monix.eval.Coeval\nimport monix.execution.Ack\nimport monix.execution.Ack.{ Continue, Stop }\nimport monix.execution.Scheduler\nimport monix.execution.atomic.PaddingStrategy.{ LeftRight128, LeftRight256 }\nimport monix.execution.atomic.{ Atomic, AtomicInt }\n\nimport scala.util.control.NonFatal\nimport monix.reactive.observers.{ BufferedSubscriber, Subscriber }\n\nimport scala.concurrent.Future\nimport scala.util.{ Failure, Success }\nimport scala.annotation.nowarn\n\n/** A high-performance and non-blocking [[BufferedSubscriber]]\n  * implementation for the [[monix.reactive.OverflowStrategy.DropNew DropNew]]\n  * and the [[monix.reactive.OverflowStrategy.DropNewAndSignal DropNewAndSignal]]\n  * overflow strategies.\n  */\nprivate[observers] final class DropNewBufferedSubscriber[A] private (\n  out: Subscriber[A],\n  bufferSize: Int,\n  @nowarn onOverflow: Long => Coeval[Option[A]] = null,\n) extends CommonBufferMembers with BufferedSubscriber[A] with Subscriber.Sync[A] {\n\n  require(bufferSize > 0, \"bufferSize must be a strictly positive number\")\n\n  implicit val scheduler: Scheduler = out.scheduler\n  private[this] val em = out.scheduler.executionModel\n\n  private[this] val itemsToPush =\n    Atomic.withPadding(0, LeftRight256)\n\n  private[this] val droppedCount: AtomicInt =\n    if (onOverflow != null) AtomicInt.withPadding(0, LeftRight128)\n    else null\n\n  private[this] val queue =\n    ConcurrentQueue.limited[A](bufferSize)\n\n  def onNext(elem: A): Ack = {\n    if (upstreamIsComplete || downstreamIsComplete) Stop\n    else {\n      if (elem == null) {\n        onError(new NullPointerException(\"Null not supported in onNext\"))\n        Stop\n      } else {\n        if (queue.offer(elem)) pushToConsumer()\n        else if (onOverflow != null) droppedCount.increment()\n        Continue\n      }\n    }\n  }\n\n  def onError(ex: Throwable): Unit = {\n    if (!upstreamIsComplete && !downstreamIsComplete) {\n      errorThrown = ex\n      upstreamIsComplete = true\n      pushToConsumer()\n    }\n  }\n\n  def onComplete(): Unit = {\n    if (!upstreamIsComplete && !downstreamIsComplete) {\n      upstreamIsComplete = true\n      pushToConsumer()\n    }\n  }\n\n  private[this] def pushToConsumer(): Unit = {\n    val currentNr = itemsToPush.getAndIncrement()\n\n    // If a run-loop isn't started, then go, go, go!\n    if (currentNr == 0) {\n      // Starting the run-loop, as at this point we can be sure\n      // that no other loop is active\n      scheduler.execute(consumerRunLoop)\n    }\n  }\n\n  private[this] val consumerRunLoop = new Runnable {\n    def run(): Unit = {\n      // This lastIterationAck is also being set by the consumer-loop,\n      // but it's important for the write to happen before `itemsToPush`,\n      // to ensure its visibility\n      fastLoop(lastIterationAck, 0, 0)\n    }\n\n    private final def signalNext(next: A): Future[Ack] =\n      try {\n        val ack = out.onNext(next)\n        // Tries flattening the Future[Ack] to a\n        // synchronous value\n        if (ack == Continue || ack == Stop)\n          ack\n        else\n          ack.value match {\n            case Some(Success(success)) =>\n              success\n            case Some(Failure(ex)) =>\n              signalError(ex)\n              Stop\n            case None =>\n              ack\n          }\n      } catch {\n        case ex if NonFatal(ex) =>\n          signalError(ex)\n          Stop\n      }\n\n    private final def signalComplete(): Unit =\n      try out.onComplete()\n      catch {\n        case ex if NonFatal(ex) =>\n          scheduler.reportFailure(ex)\n      }\n\n    private final def signalError(ex: Throwable): Unit =\n      try out.onError(ex)\n      catch {\n        case err if NonFatal(err) =>\n          scheduler.reportFailure(err)\n      }\n\n    private def goAsync(next: A, ack: Future[Ack], processed: Int, toProcess: Int): Unit =\n      ack.onComplete {\n        case Success(Continue) =>\n          val nextAck = signalNext(next)\n          val isSync = ack == Continue || ack == Stop\n          val nextFrame = if (isSync) em.nextFrameIndex(0) else 0\n          fastLoop(nextAck, processed + toProcess, nextFrame)\n\n        case Success(Stop) =>\n          // ending loop\n          downstreamIsComplete = true\n\n        case Failure(ex) =>\n          // ending loop\n          downstreamIsComplete = true\n          signalError(ex)\n      }\n\n    private def fastLoop(prevAck: Future[Ack], lastProcessed: Int, startIndex: Int): Unit = {\n      var ack = if (prevAck == null) Continue else prevAck\n      var isFirstIteration = ack == Continue\n      var processed = lastProcessed\n      var nextIndex = startIndex\n\n      while (!downstreamIsComplete) {\n        var streamErrors = true\n        try {\n          // The `processed` count is only for counting things processed\n          // from the queue, but not overflow messages, as these are\n          // not pushed to the queue - so we keep track of what to add\n          var toProcess = 0\n          val next = {\n            // Do we have an overflow message to send?\n            val overflowMessage =\n              if (onOverflow == null || droppedCount.get() == 0)\n                null.asInstanceOf[A]\n              else\n                onOverflow(droppedCount.getAndSet(0).toLong).value() match {\n                  case Some(value) => value\n                  case None => null.asInstanceOf[A]\n                }\n\n            if (overflowMessage != null) overflowMessage\n            else {\n              toProcess = 1\n              queue.poll()\n            }\n          }\n\n          // Threshold after which we are no longer allowed to\n          // stream errors downstream if they happen\n          streamErrors = false\n\n          if (next != null) {\n            if (nextIndex > 0 || isFirstIteration) {\n              isFirstIteration = false\n\n              ack match {\n                case Continue =>\n                  ack = signalNext(next)\n                  if (ack == Stop) {\n                    // ending loop\n                    downstreamIsComplete = true\n                    return\n                  } else {\n                    val isSync = ack == Continue\n                    nextIndex = if (isSync) em.nextFrameIndex(nextIndex) else 0\n                    processed += toProcess\n                  }\n\n                case Stop =>\n                  // ending loop\n                  downstreamIsComplete = true\n                  return\n\n                case _ =>\n                  goAsync(next, ack, processed, toProcess)\n                  return\n              }\n            } else {\n              goAsync(next, ack, processed, toProcess)\n              return\n            }\n          } else if (upstreamIsComplete) {\n            // Race-condition check, but if upstreamIsComplete=true is\n            // visible, then the queue should be fully published because\n            // there's a clear happens-before relationship between\n            // queue.offer() and upstreamIsComplete=true\n            if (queue.isEmpty && (onOverflow == null || droppedCount.get() == 0)) {\n              // ending loop\n              downstreamIsComplete = true\n\n              if (errorThrown ne null) signalError(errorThrown)\n              else signalComplete()\n              return\n            }\n          } else {\n            // Given we are writing in `itemsToPush` before this\n            // assignment, it means that writes will not get reordered,\n            // so when we observe that itemsToPush is zero on the\n            // producer side, we will also have the latest lastIterationAck\n            lastIterationAck = ack\n            val remaining = itemsToPush.decrementAndGet(processed)\n\n            processed = 0\n            // if the queue is non-empty (i.e. concurrent modifications\n            // just happened) then continue loop, otherwise stop\n            if (remaining <= 0) return\n          }\n        } catch {\n          case ex if NonFatal(ex) =>\n            if (streamErrors) {\n              // ending loop\n              downstreamIsComplete = true\n              signalError(ex)\n            } else {\n              scheduler.reportFailure(ex)\n            }\n        }\n      }\n    }\n  }\n}\n\nprivate[observers] object DropNewBufferedSubscriber {\n  /** Returns an instance of a [[DropNewBufferedSubscriber]]\n    * for the [[monix.reactive.OverflowStrategy.DropNew DropNew]]\n    * overflowStrategy.\n    */\n  def simple[A](underlying: Subscriber[A], bufferSize: Int): DropNewBufferedSubscriber[A] =\n    new DropNewBufferedSubscriber[A](underlying, bufferSize, null)\n\n  /** Returns an instance of a [[DropNewBufferedSubscriber]] for the\n    * [[monix.reactive.OverflowStrategy.DropNewAndSignal DropNewAndSignal]]\n    * overflowStrategy.\n    */\n  def withSignal[A](\n    underlying: Subscriber[A],\n    bufferSize: Int,\n    onOverflow: Long => Coeval[Option[A]]\n  ): DropNewBufferedSubscriber[A] =\n    new DropNewBufferedSubscriber[A](underlying, bufferSize, onOverflow)\n}",
    "repo": "monix/monix",
    "path": "./datasets/diagrams-repos/monix/monix/monix-reactive/jvm/src/main/scala/monix/reactive/observers/buffers/DropNewBufferedSubscriber.scala",
    "query": "How does the provided code handle errors, from the onError method to the signalError method?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'DropNewBufferedSubscriber', 'node_id': 'DropNewBufferedSubscriber', 'description': 'Implements buffered subscriber with drop new strategy', 'visibility': 'private', 'return_type': None, 'params': 'out: Subscriber[A], bufferSize: Int, onOverflow: Long => Coeval[Option[A]]', 'source_class_id': None}, {'type': 'method', 'name': 'onError', 'node_id': 'onError', 'description': 'Initial error handling method that marks upstream as complete and triggers consumer push', 'visibility': 'public', 'return_type': 'Unit', 'params': 'ex: Throwable', 'source_class_id': 'DropNewBufferedSubscriber'}, {'type': 'method', 'name': 'signalError', 'node_id': 'signalError', 'description': 'Propagates error to downstream subscriber with failure reporting', 'visibility': 'private', 'return_type': 'Unit', 'params': 'ex: Throwable', 'source_class_id': 'DropNewBufferedSubscriber'}, {'type': 'field', 'name': 'errorThrown', 'node_id': 'errorThrown', 'description': 'Stores the error that occurred during processing', 'visibility': 'private', 'return_type': 'Throwable', 'params': None, 'source_class_id': 'DropNewBufferedSubscriber'}], 'edges': [{'node_id_from': 'onError', 'node_id_to': 'errorThrown', 'description': 'stores error'}, {'node_id_from': 'onError', 'node_id_to': 'signalError', 'description': 'triggers error propagation'}, {'node_id_from': 'DropNewBufferedSubscriber', 'node_id_to': 'onError', 'description': ''}, {'node_id_from': 'DropNewBufferedSubscriber', 'node_id_to': 'signalError', 'description': ''}, {'node_id_from': 'DropNewBufferedSubscriber', 'node_id_to': 'errorThrown', 'description': ''}], 'packages': [{'package_id': 'errorHandling', 'children': ['onError', 'signalError', 'errorThrown'], 'description': 'Core error handling components'}]}",
    "version": "minimal",
    "text_answer": "The error handling flow starts from onError method, which stores the error in errorThrown field and marks upstream as complete. It then triggers pushToConsumer, which eventually leads to signalError being called. signalError propagates the error to downstream subscriber and handles any subsequent errors through scheduler's failure reporting mechanism.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Scala",
    "code": "\npackage monix.reactive.observers.buffers\n\nimport monix.eval.Coeval\nimport monix.execution.Ack\nimport monix.execution.Ack.{ Continue, Stop }\nimport monix.execution.Scheduler\nimport monix.execution.atomic.PaddingStrategy.{ LeftRight128, LeftRight256 }\nimport monix.execution.atomic.{ Atomic, AtomicInt }\n\nimport scala.util.control.NonFatal\nimport monix.reactive.observers.{ BufferedSubscriber, Subscriber }\n\nimport scala.concurrent.Future\nimport scala.util.{ Failure, Success }\nimport scala.annotation.nowarn\n\n/** A high-performance and non-blocking [[BufferedSubscriber]]\n  * implementation for the [[monix.reactive.OverflowStrategy.DropNew DropNew]]\n  * and the [[monix.reactive.OverflowStrategy.DropNewAndSignal DropNewAndSignal]]\n  * overflow strategies.\n  */\nprivate[observers] final class DropNewBufferedSubscriber[A] private (\n  out: Subscriber[A],\n  bufferSize: Int,\n  @nowarn onOverflow: Long => Coeval[Option[A]] = null,\n) extends CommonBufferMembers with BufferedSubscriber[A] with Subscriber.Sync[A] {\n\n  require(bufferSize > 0, \"bufferSize must be a strictly positive number\")\n\n  implicit val scheduler: Scheduler = out.scheduler\n  private[this] val em = out.scheduler.executionModel\n\n  private[this] val itemsToPush =\n    Atomic.withPadding(0, LeftRight256)\n\n  private[this] val droppedCount: AtomicInt =\n    if (onOverflow != null) AtomicInt.withPadding(0, LeftRight128)\n    else null\n\n  private[this] val queue =\n    ConcurrentQueue.limited[A](bufferSize)\n\n  def onNext(elem: A): Ack = {\n    if (upstreamIsComplete || downstreamIsComplete) Stop\n    else {\n      if (elem == null) {\n        onError(new NullPointerException(\"Null not supported in onNext\"))\n        Stop\n      } else {\n        if (queue.offer(elem)) pushToConsumer()\n        else if (onOverflow != null) droppedCount.increment()\n        Continue\n      }\n    }\n  }\n\n  def onError(ex: Throwable): Unit = {\n    if (!upstreamIsComplete && !downstreamIsComplete) {\n      errorThrown = ex\n      upstreamIsComplete = true\n      pushToConsumer()\n    }\n  }\n\n  def onComplete(): Unit = {\n    if (!upstreamIsComplete && !downstreamIsComplete) {\n      upstreamIsComplete = true\n      pushToConsumer()\n    }\n  }\n\n  private[this] def pushToConsumer(): Unit = {\n    val currentNr = itemsToPush.getAndIncrement()\n\n    // If a run-loop isn't started, then go, go, go!\n    if (currentNr == 0) {\n      // Starting the run-loop, as at this point we can be sure\n      // that no other loop is active\n      scheduler.execute(consumerRunLoop)\n    }\n  }\n\n  private[this] val consumerRunLoop = new Runnable {\n    def run(): Unit = {\n      // This lastIterationAck is also being set by the consumer-loop,\n      // but it's important for the write to happen before `itemsToPush`,\n      // to ensure its visibility\n      fastLoop(lastIterationAck, 0, 0)\n    }\n\n    private final def signalNext(next: A): Future[Ack] =\n      try {\n        val ack = out.onNext(next)\n        // Tries flattening the Future[Ack] to a\n        // synchronous value\n        if (ack == Continue || ack == Stop)\n          ack\n        else\n          ack.value match {\n            case Some(Success(success)) =>\n              success\n            case Some(Failure(ex)) =>\n              signalError(ex)\n              Stop\n            case None =>\n              ack\n          }\n      } catch {\n        case ex if NonFatal(ex) =>\n          signalError(ex)\n          Stop\n      }\n\n    private final def signalComplete(): Unit =\n      try out.onComplete()\n      catch {\n        case ex if NonFatal(ex) =>\n          scheduler.reportFailure(ex)\n      }\n\n    private final def signalError(ex: Throwable): Unit =\n      try out.onError(ex)\n      catch {\n        case err if NonFatal(err) =>\n          scheduler.reportFailure(err)\n      }\n\n    private def goAsync(next: A, ack: Future[Ack], processed: Int, toProcess: Int): Unit =\n      ack.onComplete {\n        case Success(Continue) =>\n          val nextAck = signalNext(next)\n          val isSync = ack == Continue || ack == Stop\n          val nextFrame = if (isSync) em.nextFrameIndex(0) else 0\n          fastLoop(nextAck, processed + toProcess, nextFrame)\n\n        case Success(Stop) =>\n          // ending loop\n          downstreamIsComplete = true\n\n        case Failure(ex) =>\n          // ending loop\n          downstreamIsComplete = true\n          signalError(ex)\n      }\n\n    private def fastLoop(prevAck: Future[Ack], lastProcessed: Int, startIndex: Int): Unit = {\n      var ack = if (prevAck == null) Continue else prevAck\n      var isFirstIteration = ack == Continue\n      var processed = lastProcessed\n      var nextIndex = startIndex\n\n      while (!downstreamIsComplete) {\n        var streamErrors = true\n        try {\n          // The `processed` count is only for counting things processed\n          // from the queue, but not overflow messages, as these are\n          // not pushed to the queue - so we keep track of what to add\n          var toProcess = 0\n          val next = {\n            // Do we have an overflow message to send?\n            val overflowMessage =\n              if (onOverflow == null || droppedCount.get() == 0)\n                null.asInstanceOf[A]\n              else\n                onOverflow(droppedCount.getAndSet(0).toLong).value() match {\n                  case Some(value) => value\n                  case None => null.asInstanceOf[A]\n                }\n\n            if (overflowMessage != null) overflowMessage\n            else {\n              toProcess = 1\n              queue.poll()\n            }\n          }\n\n          // Threshold after which we are no longer allowed to\n          // stream errors downstream if they happen\n          streamErrors = false\n\n          if (next != null) {\n            if (nextIndex > 0 || isFirstIteration) {\n              isFirstIteration = false\n\n              ack match {\n                case Continue =>\n                  ack = signalNext(next)\n                  if (ack == Stop) {\n                    // ending loop\n                    downstreamIsComplete = true\n                    return\n                  } else {\n                    val isSync = ack == Continue\n                    nextIndex = if (isSync) em.nextFrameIndex(nextIndex) else 0\n                    processed += toProcess\n                  }\n\n                case Stop =>\n                  // ending loop\n                  downstreamIsComplete = true\n                  return\n\n                case _ =>\n                  goAsync(next, ack, processed, toProcess)\n                  return\n              }\n            } else {\n              goAsync(next, ack, processed, toProcess)\n              return\n            }\n          } else if (upstreamIsComplete) {\n            // Race-condition check, but if upstreamIsComplete=true is\n            // visible, then the queue should be fully published because\n            // there's a clear happens-before relationship between\n            // queue.offer() and upstreamIsComplete=true\n            if (queue.isEmpty && (onOverflow == null || droppedCount.get() == 0)) {\n              // ending loop\n              downstreamIsComplete = true\n\n              if (errorThrown ne null) signalError(errorThrown)\n              else signalComplete()\n              return\n            }\n          } else {\n            // Given we are writing in `itemsToPush` before this\n            // assignment, it means that writes will not get reordered,\n            // so when we observe that itemsToPush is zero on the\n            // producer side, we will also have the latest lastIterationAck\n            lastIterationAck = ack\n            val remaining = itemsToPush.decrementAndGet(processed)\n\n            processed = 0\n            // if the queue is non-empty (i.e. concurrent modifications\n            // just happened) then continue loop, otherwise stop\n            if (remaining <= 0) return\n          }\n        } catch {\n          case ex if NonFatal(ex) =>\n            if (streamErrors) {\n              // ending loop\n              downstreamIsComplete = true\n              signalError(ex)\n            } else {\n              scheduler.reportFailure(ex)\n            }\n        }\n      }\n    }\n  }\n}\n\nprivate[observers] object DropNewBufferedSubscriber {\n  /** Returns an instance of a [[DropNewBufferedSubscriber]]\n    * for the [[monix.reactive.OverflowStrategy.DropNew DropNew]]\n    * overflowStrategy.\n    */\n  def simple[A](underlying: Subscriber[A], bufferSize: Int): DropNewBufferedSubscriber[A] =\n    new DropNewBufferedSubscriber[A](underlying, bufferSize, null)\n\n  /** Returns an instance of a [[DropNewBufferedSubscriber]] for the\n    * [[monix.reactive.OverflowStrategy.DropNewAndSignal DropNewAndSignal]]\n    * overflowStrategy.\n    */\n  def withSignal[A](\n    underlying: Subscriber[A],\n    bufferSize: Int,\n    onOverflow: Long => Coeval[Option[A]]\n  ): DropNewBufferedSubscriber[A] =\n    new DropNewBufferedSubscriber[A](underlying, bufferSize, onOverflow)\n}",
    "repo": "monix/monix",
    "path": "./datasets/diagrams-repos/monix/monix/monix-reactive/jvm/src/main/scala/monix/reactive/observers/buffers/DropNewBufferedSubscriber.scala",
    "query": "How does the provided code handle errors, from the onError method to the signalError method?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'DropNewBufferedSubscriber', 'node_id': 'DropNewBufferedSubscriber', 'description': 'Implements buffered subscriber with drop new strategy', 'visibility': 'private', 'return_type': None, 'params': 'out: Subscriber[A], bufferSize: Int, onOverflow: Long => Coeval[Option[A]]', 'source_class_id': None}, {'type': 'method', 'name': 'onError', 'node_id': 'onError', 'description': 'Initial error handling method that marks upstream as complete and triggers consumer push', 'visibility': 'public', 'return_type': 'Unit', 'params': 'ex: Throwable', 'source_class_id': 'DropNewBufferedSubscriber'}, {'type': 'method', 'name': 'signalError', 'node_id': 'signalError', 'description': 'Propagates error to downstream subscriber with failure reporting', 'visibility': 'private', 'return_type': 'Unit', 'params': 'ex: Throwable', 'source_class_id': 'DropNewBufferedSubscriber'}, {'type': 'field', 'name': 'errorThrown', 'node_id': 'errorThrown', 'description': 'Stores the error that occurred during processing', 'visibility': 'private', 'return_type': 'Throwable', 'params': None, 'source_class_id': 'DropNewBufferedSubscriber'}, {'type': 'method', 'name': 'pushToConsumer', 'node_id': 'pushToConsumer', 'description': 'Initiates consumer run loop for processing', 'visibility': 'private', 'return_type': 'Unit', 'params': None, 'source_class_id': 'DropNewBufferedSubscriber'}, {'type': 'field', 'name': 'upstreamIsComplete', 'node_id': 'upstreamIsComplete', 'description': 'Flag indicating if upstream processing is complete', 'visibility': 'private', 'return_type': 'boolean', 'params': None, 'source_class_id': 'DropNewBufferedSubscriber'}, {'type': 'field', 'name': 'downstreamIsComplete', 'node_id': 'downstreamIsComplete', 'description': 'Flag indicating if downstream processing is complete', 'visibility': 'private', 'return_type': 'boolean', 'params': None, 'source_class_id': 'DropNewBufferedSubscriber'}], 'edges': [{'node_id_from': 'onError', 'node_id_to': 'errorThrown', 'description': 'stores error'}, {'node_id_from': 'onError', 'node_id_to': 'pushToConsumer', 'description': 'triggers processing'}, {'node_id_from': 'onError', 'node_id_to': 'upstreamIsComplete', 'description': 'marks as complete'}, {'node_id_from': 'signalError', 'node_id_to': 'downstreamIsComplete', 'description': 'marks as complete'}, {'node_id_from': 'DropNewBufferedSubscriber', 'node_id_to': 'onError', 'description': ''}, {'node_id_from': 'DropNewBufferedSubscriber', 'node_id_to': 'signalError', 'description': ''}, {'node_id_from': 'DropNewBufferedSubscriber', 'node_id_to': 'errorThrown', 'description': ''}, {'node_id_from': 'DropNewBufferedSubscriber', 'node_id_to': 'pushToConsumer', 'description': ''}, {'node_id_from': 'DropNewBufferedSubscriber', 'node_id_to': 'upstreamIsComplete', 'description': ''}, {'node_id_from': 'DropNewBufferedSubscriber', 'node_id_to': 'downstreamIsComplete', 'description': ''}], 'packages': [{'package_id': 'errorHandling', 'children': ['onError', 'signalError', 'errorThrown'], 'description': 'Core error handling components'}, {'package_id': 'stateManagement', 'children': ['upstreamIsComplete', 'downstreamIsComplete'], 'description': 'Stream state management'}]}",
    "version": "medium",
    "text_answer": "The error handling flow starts from onError method, which stores the error in errorThrown field and marks upstream as complete. It then triggers pushToConsumer, which eventually leads to signalError being called. signalError propagates the error to downstream subscriber and handles any subsequent errors through scheduler's failure reporting mechanism.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Scala",
    "code": "\npackage monix.reactive.observers.buffers\n\nimport monix.eval.Coeval\nimport monix.execution.Ack\nimport monix.execution.Ack.{ Continue, Stop }\nimport monix.execution.Scheduler\nimport monix.execution.atomic.PaddingStrategy.{ LeftRight128, LeftRight256 }\nimport monix.execution.atomic.{ Atomic, AtomicInt }\n\nimport scala.util.control.NonFatal\nimport monix.reactive.observers.{ BufferedSubscriber, Subscriber }\n\nimport scala.concurrent.Future\nimport scala.util.{ Failure, Success }\nimport scala.annotation.nowarn\n\n/** A high-performance and non-blocking [[BufferedSubscriber]]\n  * implementation for the [[monix.reactive.OverflowStrategy.DropNew DropNew]]\n  * and the [[monix.reactive.OverflowStrategy.DropNewAndSignal DropNewAndSignal]]\n  * overflow strategies.\n  */\nprivate[observers] final class DropNewBufferedSubscriber[A] private (\n  out: Subscriber[A],\n  bufferSize: Int,\n  @nowarn onOverflow: Long => Coeval[Option[A]] = null,\n) extends CommonBufferMembers with BufferedSubscriber[A] with Subscriber.Sync[A] {\n\n  require(bufferSize > 0, \"bufferSize must be a strictly positive number\")\n\n  implicit val scheduler: Scheduler = out.scheduler\n  private[this] val em = out.scheduler.executionModel\n\n  private[this] val itemsToPush =\n    Atomic.withPadding(0, LeftRight256)\n\n  private[this] val droppedCount: AtomicInt =\n    if (onOverflow != null) AtomicInt.withPadding(0, LeftRight128)\n    else null\n\n  private[this] val queue =\n    ConcurrentQueue.limited[A](bufferSize)\n\n  def onNext(elem: A): Ack = {\n    if (upstreamIsComplete || downstreamIsComplete) Stop\n    else {\n      if (elem == null) {\n        onError(new NullPointerException(\"Null not supported in onNext\"))\n        Stop\n      } else {\n        if (queue.offer(elem)) pushToConsumer()\n        else if (onOverflow != null) droppedCount.increment()\n        Continue\n      }\n    }\n  }\n\n  def onError(ex: Throwable): Unit = {\n    if (!upstreamIsComplete && !downstreamIsComplete) {\n      errorThrown = ex\n      upstreamIsComplete = true\n      pushToConsumer()\n    }\n  }\n\n  def onComplete(): Unit = {\n    if (!upstreamIsComplete && !downstreamIsComplete) {\n      upstreamIsComplete = true\n      pushToConsumer()\n    }\n  }\n\n  private[this] def pushToConsumer(): Unit = {\n    val currentNr = itemsToPush.getAndIncrement()\n\n    // If a run-loop isn't started, then go, go, go!\n    if (currentNr == 0) {\n      // Starting the run-loop, as at this point we can be sure\n      // that no other loop is active\n      scheduler.execute(consumerRunLoop)\n    }\n  }\n\n  private[this] val consumerRunLoop = new Runnable {\n    def run(): Unit = {\n      // This lastIterationAck is also being set by the consumer-loop,\n      // but it's important for the write to happen before `itemsToPush`,\n      // to ensure its visibility\n      fastLoop(lastIterationAck, 0, 0)\n    }\n\n    private final def signalNext(next: A): Future[Ack] =\n      try {\n        val ack = out.onNext(next)\n        // Tries flattening the Future[Ack] to a\n        // synchronous value\n        if (ack == Continue || ack == Stop)\n          ack\n        else\n          ack.value match {\n            case Some(Success(success)) =>\n              success\n            case Some(Failure(ex)) =>\n              signalError(ex)\n              Stop\n            case None =>\n              ack\n          }\n      } catch {\n        case ex if NonFatal(ex) =>\n          signalError(ex)\n          Stop\n      }\n\n    private final def signalComplete(): Unit =\n      try out.onComplete()\n      catch {\n        case ex if NonFatal(ex) =>\n          scheduler.reportFailure(ex)\n      }\n\n    private final def signalError(ex: Throwable): Unit =\n      try out.onError(ex)\n      catch {\n        case err if NonFatal(err) =>\n          scheduler.reportFailure(err)\n      }\n\n    private def goAsync(next: A, ack: Future[Ack], processed: Int, toProcess: Int): Unit =\n      ack.onComplete {\n        case Success(Continue) =>\n          val nextAck = signalNext(next)\n          val isSync = ack == Continue || ack == Stop\n          val nextFrame = if (isSync) em.nextFrameIndex(0) else 0\n          fastLoop(nextAck, processed + toProcess, nextFrame)\n\n        case Success(Stop) =>\n          // ending loop\n          downstreamIsComplete = true\n\n        case Failure(ex) =>\n          // ending loop\n          downstreamIsComplete = true\n          signalError(ex)\n      }\n\n    private def fastLoop(prevAck: Future[Ack], lastProcessed: Int, startIndex: Int): Unit = {\n      var ack = if (prevAck == null) Continue else prevAck\n      var isFirstIteration = ack == Continue\n      var processed = lastProcessed\n      var nextIndex = startIndex\n\n      while (!downstreamIsComplete) {\n        var streamErrors = true\n        try {\n          // The `processed` count is only for counting things processed\n          // from the queue, but not overflow messages, as these are\n          // not pushed to the queue - so we keep track of what to add\n          var toProcess = 0\n          val next = {\n            // Do we have an overflow message to send?\n            val overflowMessage =\n              if (onOverflow == null || droppedCount.get() == 0)\n                null.asInstanceOf[A]\n              else\n                onOverflow(droppedCount.getAndSet(0).toLong).value() match {\n                  case Some(value) => value\n                  case None => null.asInstanceOf[A]\n                }\n\n            if (overflowMessage != null) overflowMessage\n            else {\n              toProcess = 1\n              queue.poll()\n            }\n          }\n\n          // Threshold after which we are no longer allowed to\n          // stream errors downstream if they happen\n          streamErrors = false\n\n          if (next != null) {\n            if (nextIndex > 0 || isFirstIteration) {\n              isFirstIteration = false\n\n              ack match {\n                case Continue =>\n                  ack = signalNext(next)\n                  if (ack == Stop) {\n                    // ending loop\n                    downstreamIsComplete = true\n                    return\n                  } else {\n                    val isSync = ack == Continue\n                    nextIndex = if (isSync) em.nextFrameIndex(nextIndex) else 0\n                    processed += toProcess\n                  }\n\n                case Stop =>\n                  // ending loop\n                  downstreamIsComplete = true\n                  return\n\n                case _ =>\n                  goAsync(next, ack, processed, toProcess)\n                  return\n              }\n            } else {\n              goAsync(next, ack, processed, toProcess)\n              return\n            }\n          } else if (upstreamIsComplete) {\n            // Race-condition check, but if upstreamIsComplete=true is\n            // visible, then the queue should be fully published because\n            // there's a clear happens-before relationship between\n            // queue.offer() and upstreamIsComplete=true\n            if (queue.isEmpty && (onOverflow == null || droppedCount.get() == 0)) {\n              // ending loop\n              downstreamIsComplete = true\n\n              if (errorThrown ne null) signalError(errorThrown)\n              else signalComplete()\n              return\n            }\n          } else {\n            // Given we are writing in `itemsToPush` before this\n            // assignment, it means that writes will not get reordered,\n            // so when we observe that itemsToPush is zero on the\n            // producer side, we will also have the latest lastIterationAck\n            lastIterationAck = ack\n            val remaining = itemsToPush.decrementAndGet(processed)\n\n            processed = 0\n            // if the queue is non-empty (i.e. concurrent modifications\n            // just happened) then continue loop, otherwise stop\n            if (remaining <= 0) return\n          }\n        } catch {\n          case ex if NonFatal(ex) =>\n            if (streamErrors) {\n              // ending loop\n              downstreamIsComplete = true\n              signalError(ex)\n            } else {\n              scheduler.reportFailure(ex)\n            }\n        }\n      }\n    }\n  }\n}\n\nprivate[observers] object DropNewBufferedSubscriber {\n  /** Returns an instance of a [[DropNewBufferedSubscriber]]\n    * for the [[monix.reactive.OverflowStrategy.DropNew DropNew]]\n    * overflowStrategy.\n    */\n  def simple[A](underlying: Subscriber[A], bufferSize: Int): DropNewBufferedSubscriber[A] =\n    new DropNewBufferedSubscriber[A](underlying, bufferSize, null)\n\n  /** Returns an instance of a [[DropNewBufferedSubscriber]] for the\n    * [[monix.reactive.OverflowStrategy.DropNewAndSignal DropNewAndSignal]]\n    * overflowStrategy.\n    */\n  def withSignal[A](\n    underlying: Subscriber[A],\n    bufferSize: Int,\n    onOverflow: Long => Coeval[Option[A]]\n  ): DropNewBufferedSubscriber[A] =\n    new DropNewBufferedSubscriber[A](underlying, bufferSize, onOverflow)\n}",
    "repo": "monix/monix",
    "path": "./datasets/diagrams-repos/monix/monix/monix-reactive/jvm/src/main/scala/monix/reactive/observers/buffers/DropNewBufferedSubscriber.scala",
    "query": "How does the provided code handle errors, from the onError method to the signalError method?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'DropNewBufferedSubscriber', 'node_id': 'DropNewBufferedSubscriber', 'description': 'Implements buffered subscriber with drop new strategy', 'visibility': 'private', 'return_type': None, 'params': 'out: Subscriber[A], bufferSize: Int, onOverflow: Long => Coeval[Option[A]]', 'source_class_id': None}, {'type': 'method', 'name': 'onError', 'node_id': 'onError', 'description': 'Initial error handling method that marks upstream as complete and triggers consumer push', 'visibility': 'public', 'return_type': 'Unit', 'params': 'ex: Throwable', 'source_class_id': 'DropNewBufferedSubscriber'}, {'type': 'method', 'name': 'signalError', 'node_id': 'signalError', 'description': 'Propagates error to downstream subscriber with failure reporting', 'visibility': 'private', 'return_type': 'Unit', 'params': 'ex: Throwable', 'source_class_id': 'DropNewBufferedSubscriber'}, {'type': 'method', 'name': 'fastLoop', 'node_id': 'fastLoop', 'description': 'Main processing loop handling stream elements', 'visibility': 'private', 'return_type': 'Unit', 'params': 'prevAck: Future[Ack], lastProcessed: Int, startIndex: Int', 'source_class_id': 'DropNewBufferedSubscriber'}, {'type': 'method', 'name': 'pushToConsumer', 'node_id': 'pushToConsumer', 'description': 'Initiates consumer run loop for processing', 'visibility': 'private', 'return_type': 'Unit', 'params': None, 'source_class_id': 'DropNewBufferedSubscriber'}, {'type': 'field', 'name': 'errorThrown', 'node_id': 'errorThrown', 'description': 'Stores the error that occurred during processing', 'visibility': 'private', 'return_type': 'Throwable', 'params': None, 'source_class_id': 'DropNewBufferedSubscriber'}, {'type': 'field', 'name': 'upstreamIsComplete', 'node_id': 'upstreamIsComplete', 'description': 'Flag indicating if upstream processing is complete', 'visibility': 'private', 'return_type': 'boolean', 'params': None, 'source_class_id': 'DropNewBufferedSubscriber'}, {'type': 'field', 'name': 'downstreamIsComplete', 'node_id': 'downstreamIsComplete', 'description': 'Flag indicating if downstream processing is complete', 'visibility': 'private', 'return_type': 'boolean', 'params': None, 'source_class_id': 'DropNewBufferedSubscriber'}, {'type': 'field', 'name': 'scheduler', 'node_id': 'scheduler', 'description': 'Scheduler for executing async operations', 'visibility': 'private', 'return_type': 'Scheduler', 'params': None, 'source_class_id': 'DropNewBufferedSubscriber'}], 'edges': [{'node_id_from': 'onError', 'node_id_to': 'errorThrown', 'description': 'stores error'}, {'node_id_from': 'onError', 'node_id_to': 'pushToConsumer', 'description': 'triggers processing'}, {'node_id_from': 'pushToConsumer', 'node_id_to': 'fastLoop', 'description': 'initiates processing'}, {'node_id_from': 'fastLoop', 'node_id_to': 'signalError', 'description': 'propagates errors'}, {'node_id_from': 'signalError', 'node_id_to': 'scheduler', 'description': 'reports failures'}, {'node_id_from': 'onError', 'node_id_to': 'upstreamIsComplete', 'description': 'marks as complete'}, {'node_id_from': 'signalError', 'node_id_to': 'downstreamIsComplete', 'description': 'marks as complete'}, {'node_id_from': 'DropNewBufferedSubscriber', 'node_id_to': 'onError', 'description': ''}, {'node_id_from': 'DropNewBufferedSubscriber', 'node_id_to': 'signalError', 'description': ''}, {'node_id_from': 'DropNewBufferedSubscriber', 'node_id_to': 'errorThrown', 'description': ''}, {'node_id_from': 'DropNewBufferedSubscriber', 'node_id_to': 'pushToConsumer', 'description': ''}, {'node_id_from': 'DropNewBufferedSubscriber', 'node_id_to': 'upstreamIsComplete', 'description': ''}, {'node_id_from': 'DropNewBufferedSubscriber', 'node_id_to': 'downstreamIsComplete', 'description': ''}, {'node_id_from': 'DropNewBufferedSubscriber', 'node_id_to': 'fastLoop', 'description': ''}, {'node_id_from': 'DropNewBufferedSubscriber', 'node_id_to': 'scheduler', 'description': ''}], 'packages': [{'package_id': 'errorHandling', 'children': ['onError', 'signalError', 'errorThrown'], 'description': 'Core error handling components'}, {'package_id': 'processing', 'children': ['pushToConsumer', 'fastLoop'], 'description': 'Stream processing components'}, {'package_id': 'state', 'children': ['upstreamIsComplete', 'downstreamIsComplete', 'scheduler'], 'description': 'State and execution management'}]}",
    "version": "full",
    "text_answer": "The error handling flow starts from onError method, which stores the error in errorThrown field and marks upstream as complete. It then triggers pushToConsumer, which eventually leads to signalError being called. signalError propagates the error to downstream subscriber and handles any subsequent errors through scheduler's failure reporting mechanism.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C++",
    "code": "\n#pragma once\n\n#include \"CFGMutation.h\"\n#include \"ConstantEnvironment.h\"\n#include \"ConstantPropagationAnalysis.h\"\n#include \"ConstantPropagationState.h\"\n#include \"ConstantPropagationWholeProgramState.h\"\n#include \"IRCode.h\"\n#include \"Liveness.h\"\n#include \"NullPointerExceptionUtil.h\"\n\nclass ScopedMetrics;\n\nnamespace constant_propagation {\n\n/**\n * Optimize the given code by:\n *   - removing dead branches\n *   - converting instructions to `const` when the values are known\n *   - removing field writes if they all write the same constant value\n */\nclass Transform final {\n public:\n  struct Config {\n    bool replace_moves_with_consts{true};\n    bool replace_move_result_with_consts{false};\n    bool remove_dead_switch{true};\n    bool add_param_const{true};\n    bool to_int_lit8{true};\n    bool to_int_lit16{false}; // Does not seem beneficial by default.\n    const DexType* class_under_init{nullptr};\n    // These methods are known pure, we can replace their results with constant\n    // value.\n    const ConcurrentSet<DexMethod*>* getter_methods_for_immutable_fields{\n        nullptr};\n    const std::unordered_set<DexMethodRef*>* pure_methods{nullptr};\n    Config() {}\n  };\n\n  struct Stats {\n    size_t branches_removed{0};\n    size_t branches_forwarded{0};\n    size_t materialized_consts{0};\n    size_t added_param_const{0};\n    size_t throws{0};\n    size_t null_checks{0};\n    size_t null_checks_method_calls{0};\n    size_t unreachable_instructions_removed{0};\n    size_t redundant_puts_removed{0};\n\n    Stats& operator+=(const Stats& that) {\n      branches_removed += that.branches_removed;\n      branches_forwarded += that.branches_forwarded;\n      materialized_consts += that.materialized_consts;\n      added_param_const += that.added_param_const;\n      throws += that.throws;\n      null_checks += that.null_checks;\n      null_checks_method_calls += that.null_checks_method_calls;\n      unreachable_instructions_removed += that.unreachable_instructions_removed;\n      redundant_puts_removed += that.redundant_puts_removed;\n      return *this;\n    }\n\n    void log_metrics(ScopedMetrics& sm, bool with_scope = true) const;\n  };\n\n  explicit Transform(Config config, const State& state)\n      : m_config(config), m_state(state) {}\n\n  // Apply all available transformations on editable cfg\n  // May run cfg.calculate_exit_block as a side-effect.\n  void apply(const intraprocedural::FixpointIterator& fp_iter,\n             const WholeProgramState& wps,\n             cfg::ControlFlowGraph& cfg,\n             const XStoreRefs* xstores,\n             bool is_static,\n             DexType* declaring_type,\n             DexProto*);\n\n  // Apply transformations on editable cfg; don't call directly, prefer calling\n  // `apply` instead.\n  void legacy_apply_constants_and_prune_unreachable(\n      const intraprocedural::FixpointIterator&,\n      const WholeProgramState&,\n      cfg::ControlFlowGraph&,\n      const XStoreRefs*,\n      const DexType*);\n\n  // Apply targets-forwarding transformations on editable cfg; don't call\n  // directly, prefer calling `apply` instead.\n  // Runs cfg.calculate_exit_block as a side-effect.\n  void legacy_apply_forward_targets(const intraprocedural::FixpointIterator&,\n                                    cfg::ControlFlowGraph&,\n                                    bool is_static,\n                                    DexType* declaring_type,\n                                    DexProto*,\n                                    const XStoreRefs*);\n\n  const Stats& get_stats() const { return m_stats; }\n\n private:\n  /*\n   * The methods in this class queue up their transformations. After they are\n   * all done, the apply_changes() method does the actual modifications.\n   */\n  void apply_changes(cfg::ControlFlowGraph&);\n\n  void simplify_instruction(const ConstantEnvironment&,\n                            const WholeProgramState& wps,\n                            const cfg::InstructionIterator& cfg_it,\n                            const XStoreRefs*,\n                            const DexType*);\n\n  bool replace_with_const(const ConstantEnvironment&,\n                          const cfg::InstructionIterator& cfg_it,\n                          const XStoreRefs*,\n                          const DexType*);\n  void generate_const_param(const ConstantEnvironment&,\n                            const cfg::InstructionIterator& cfg_it,\n                            const XStoreRefs*,\n                            const DexType*);\n\n  bool eliminate_redundant_put(const ConstantEnvironment&,\n                               const WholeProgramState& wps,\n                               const cfg::InstructionIterator& cfg_it);\n  bool eliminate_redundant_null_check(const ConstantEnvironment&,\n                                      const WholeProgramState& wps,\n                                      const cfg::InstructionIterator& cfg_it);\n  bool replace_with_throw(const ConstantEnvironment&,\n                          const cfg::InstructionIterator& cfg_it,\n                          npe::NullPointerExceptionCreator* npe_creator);\n\n  void remove_dead_switch(const intraprocedural::FixpointIterator& intra_cp,\n                          const ConstantEnvironment&,\n                          cfg::ControlFlowGraph&,\n                          cfg::Block*);\n\n  void eliminate_dead_branch(const intraprocedural::FixpointIterator&,\n                             const ConstantEnvironment&,\n                             cfg::ControlFlowGraph&,\n                             cfg::Block*);\n\n  void forward_targets(\n      const intraprocedural::FixpointIterator&,\n      const ConstantEnvironment&,\n      cfg::ControlFlowGraph&,\n      cfg::Block*,\n      std::unique_ptr<LivenessFixpointIterator>& liveness_fixpoint_iter);\n\n  // Check whether the code can return a value of a unavailable/external type,\n  // or a type defined in a store different from the one where the method is\n  // defined in.\n  bool has_problematic_return(cfg::ControlFlowGraph&,\n                              bool is_static,\n                              DexType* declaring_type,\n                              DexProto* proto,\n                              const XStoreRefs*);\n\n  bool assumenosideeffects(DexMethodRef* ref, DexMethod* meth) const;\n\n  const Config m_config;\n  std::unique_ptr<cfg::CFGMutation> m_mutation;\n  std::vector<IRInstruction*> m_added_param_values;\n  std::unordered_set<IRInstruction*> m_redundant_move_results;\n  std::vector<cfg::Edge*> m_edge_deletes;\n  std::vector<std::tuple<cfg::Block*, cfg::Block*, cfg::EdgeType>> m_edge_adds;\n  Stats m_stats;\n\n  const State& m_state;\n};\n\n/*\n * Generates an appropriate const-* instruction for a given ConstantValue.\n */\nclass value_to_instruction_visitor final\n    : public boost::static_visitor<std::vector<IRInstruction*>> {\n public:\n  explicit value_to_instruction_visitor(const IRInstruction* original,\n                                        const XStoreRefs* xstores,\n                                        const DexType* declaring_type)\n      : m_original(original),\n        m_xstores(xstores),\n        m_declaring_type(declaring_type) {}\n\n  std::vector<IRInstruction*> operator()(\n      const SignedConstantDomain& dom) const {\n    auto cst = dom.get_constant();\n    if (!cst) {\n      return {};\n    }\n    IRInstruction* insn = new IRInstruction(\n        m_original->dest_is_wide() ? OPCODE_CONST_WIDE : OPCODE_CONST);\n    insn->set_literal(*cst);\n    insn->set_dest(m_original->dest());\n    return {insn};\n  }\n\n  std::vector<IRInstruction*> operator()(const StringDomain& dom) const {\n    auto cst = dom.get_constant();\n    if (!cst) {\n      return {};\n    }\n    IRInstruction* insn = new IRInstruction(OPCODE_CONST_STRING);\n    insn->set_string(*cst);\n    return {insn, (new IRInstruction(IOPCODE_MOVE_RESULT_PSEUDO_OBJECT))\n                      ->set_dest(m_original->dest())};\n  }\n\n  std::vector<IRInstruction*> operator()(\n      const ConstantClassObjectDomain& dom) const {\n    auto cst = dom.get_constant();\n    if (!cst) {\n      return {};\n    }\n    auto type = const_cast<DexType*>(*cst);\n    if (!m_xstores || m_xstores->illegal_ref(m_declaring_type, type)) {\n      return {};\n    }\n    IRInstruction* insn = new IRInstruction(OPCODE_CONST_CLASS);\n    insn->set_type(type);\n    return {insn, (new IRInstruction(IOPCODE_MOVE_RESULT_PSEUDO_OBJECT))\n                      ->set_dest(m_original->dest())};\n  }\n\n  template <typename Domain>\n  std::vector<IRInstruction*> operator()(const Domain& dom) const {\n    return {};\n  }\n\n private:\n  const IRInstruction* m_original;\n  const XStoreRefs* m_xstores;\n  const DexType* m_declaring_type;\n};\n\n} // namespace constant_propagation",
    "repo": "facebook/redex",
    "path": "./datasets/diagrams-repos/facebook/redex/service/constant-propagation/ConstantPropagationTransform.h",
    "query": "How does the Transform class modify the control flow graph (CFG)?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'Transform', 'node_id': 'Transform', 'description': 'Main class responsible for optimizing code through CFG modifications', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'apply', 'node_id': 'apply', 'description': 'Main method that applies all available transformations on CFG', 'visibility': 'public', 'return_type': 'void', 'params': '(FixpointIterator&, WholeProgramState&, ControlFlowGraph&, XStoreRefs*, bool, DexType*, DexProto*)', 'source_class_id': 'Transform'}, {'type': 'method', 'name': 'remove_dead_switch', 'node_id': 'remove_dead_switch', 'description': 'Removes unnecessary switch statements', 'visibility': 'private', 'return_type': 'void', 'params': '(FixpointIterator&, ConstantEnvironment&, ControlFlowGraph&, Block*)', 'source_class_id': 'Transform'}, {'type': 'method', 'name': 'eliminate_dead_branch', 'node_id': 'eliminate_dead_branch', 'description': 'Removes unreachable code branches', 'visibility': 'private', 'return_type': 'void', 'params': '(FixpointIterator&, ConstantEnvironment&, ControlFlowGraph&, Block*)', 'source_class_id': 'Transform'}], 'edges': [{'node_id_from': 'apply', 'node_id_to': 'remove_dead_switch', 'description': 'calls'}, {'node_id_from': 'apply', 'node_id_to': 'eliminate_dead_branch', 'description': 'calls'}, {'node_id_from': 'Transform', 'node_id_to': 'apply', 'description': ''}, {'node_id_from': 'Transform', 'node_id_to': 'remove_dead_switch', 'description': ''}, {'node_id_from': 'Transform', 'node_id_to': 'eliminate_dead_branch', 'description': ''}], 'packages': [{'package_id': 'cfgTransformation', 'children': ['Transform', 'apply', 'remove_dead_switch', 'eliminate_dead_branch'], 'description': 'Core CFG transformation functionality'}]}",
    "version": "minimal",
    "text_answer": "The Transform class modifies the CFG through three main operations: removing dead code (branches and switches), converting instructions to constants when values are known, and forwarding branch targets. It uses constant propagation analysis to identify opportunities for these optimizations and applies them through a series of transformations coordinated by the apply method.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C++",
    "code": "\n#pragma once\n\n#include \"CFGMutation.h\"\n#include \"ConstantEnvironment.h\"\n#include \"ConstantPropagationAnalysis.h\"\n#include \"ConstantPropagationState.h\"\n#include \"ConstantPropagationWholeProgramState.h\"\n#include \"IRCode.h\"\n#include \"Liveness.h\"\n#include \"NullPointerExceptionUtil.h\"\n\nclass ScopedMetrics;\n\nnamespace constant_propagation {\n\n/**\n * Optimize the given code by:\n *   - removing dead branches\n *   - converting instructions to `const` when the values are known\n *   - removing field writes if they all write the same constant value\n */\nclass Transform final {\n public:\n  struct Config {\n    bool replace_moves_with_consts{true};\n    bool replace_move_result_with_consts{false};\n    bool remove_dead_switch{true};\n    bool add_param_const{true};\n    bool to_int_lit8{true};\n    bool to_int_lit16{false}; // Does not seem beneficial by default.\n    const DexType* class_under_init{nullptr};\n    // These methods are known pure, we can replace their results with constant\n    // value.\n    const ConcurrentSet<DexMethod*>* getter_methods_for_immutable_fields{\n        nullptr};\n    const std::unordered_set<DexMethodRef*>* pure_methods{nullptr};\n    Config() {}\n  };\n\n  struct Stats {\n    size_t branches_removed{0};\n    size_t branches_forwarded{0};\n    size_t materialized_consts{0};\n    size_t added_param_const{0};\n    size_t throws{0};\n    size_t null_checks{0};\n    size_t null_checks_method_calls{0};\n    size_t unreachable_instructions_removed{0};\n    size_t redundant_puts_removed{0};\n\n    Stats& operator+=(const Stats& that) {\n      branches_removed += that.branches_removed;\n      branches_forwarded += that.branches_forwarded;\n      materialized_consts += that.materialized_consts;\n      added_param_const += that.added_param_const;\n      throws += that.throws;\n      null_checks += that.null_checks;\n      null_checks_method_calls += that.null_checks_method_calls;\n      unreachable_instructions_removed += that.unreachable_instructions_removed;\n      redundant_puts_removed += that.redundant_puts_removed;\n      return *this;\n    }\n\n    void log_metrics(ScopedMetrics& sm, bool with_scope = true) const;\n  };\n\n  explicit Transform(Config config, const State& state)\n      : m_config(config), m_state(state) {}\n\n  // Apply all available transformations on editable cfg\n  // May run cfg.calculate_exit_block as a side-effect.\n  void apply(const intraprocedural::FixpointIterator& fp_iter,\n             const WholeProgramState& wps,\n             cfg::ControlFlowGraph& cfg,\n             const XStoreRefs* xstores,\n             bool is_static,\n             DexType* declaring_type,\n             DexProto*);\n\n  // Apply transformations on editable cfg; don't call directly, prefer calling\n  // `apply` instead.\n  void legacy_apply_constants_and_prune_unreachable(\n      const intraprocedural::FixpointIterator&,\n      const WholeProgramState&,\n      cfg::ControlFlowGraph&,\n      const XStoreRefs*,\n      const DexType*);\n\n  // Apply targets-forwarding transformations on editable cfg; don't call\n  // directly, prefer calling `apply` instead.\n  // Runs cfg.calculate_exit_block as a side-effect.\n  void legacy_apply_forward_targets(const intraprocedural::FixpointIterator&,\n                                    cfg::ControlFlowGraph&,\n                                    bool is_static,\n                                    DexType* declaring_type,\n                                    DexProto*,\n                                    const XStoreRefs*);\n\n  const Stats& get_stats() const { return m_stats; }\n\n private:\n  /*\n   * The methods in this class queue up their transformations. After they are\n   * all done, the apply_changes() method does the actual modifications.\n   */\n  void apply_changes(cfg::ControlFlowGraph&);\n\n  void simplify_instruction(const ConstantEnvironment&,\n                            const WholeProgramState& wps,\n                            const cfg::InstructionIterator& cfg_it,\n                            const XStoreRefs*,\n                            const DexType*);\n\n  bool replace_with_const(const ConstantEnvironment&,\n                          const cfg::InstructionIterator& cfg_it,\n                          const XStoreRefs*,\n                          const DexType*);\n  void generate_const_param(const ConstantEnvironment&,\n                            const cfg::InstructionIterator& cfg_it,\n                            const XStoreRefs*,\n                            const DexType*);\n\n  bool eliminate_redundant_put(const ConstantEnvironment&,\n                               const WholeProgramState& wps,\n                               const cfg::InstructionIterator& cfg_it);\n  bool eliminate_redundant_null_check(const ConstantEnvironment&,\n                                      const WholeProgramState& wps,\n                                      const cfg::InstructionIterator& cfg_it);\n  bool replace_with_throw(const ConstantEnvironment&,\n                          const cfg::InstructionIterator& cfg_it,\n                          npe::NullPointerExceptionCreator* npe_creator);\n\n  void remove_dead_switch(const intraprocedural::FixpointIterator& intra_cp,\n                          const ConstantEnvironment&,\n                          cfg::ControlFlowGraph&,\n                          cfg::Block*);\n\n  void eliminate_dead_branch(const intraprocedural::FixpointIterator&,\n                             const ConstantEnvironment&,\n                             cfg::ControlFlowGraph&,\n                             cfg::Block*);\n\n  void forward_targets(\n      const intraprocedural::FixpointIterator&,\n      const ConstantEnvironment&,\n      cfg::ControlFlowGraph&,\n      cfg::Block*,\n      std::unique_ptr<LivenessFixpointIterator>& liveness_fixpoint_iter);\n\n  // Check whether the code can return a value of a unavailable/external type,\n  // or a type defined in a store different from the one where the method is\n  // defined in.\n  bool has_problematic_return(cfg::ControlFlowGraph&,\n                              bool is_static,\n                              DexType* declaring_type,\n                              DexProto* proto,\n                              const XStoreRefs*);\n\n  bool assumenosideeffects(DexMethodRef* ref, DexMethod* meth) const;\n\n  const Config m_config;\n  std::unique_ptr<cfg::CFGMutation> m_mutation;\n  std::vector<IRInstruction*> m_added_param_values;\n  std::unordered_set<IRInstruction*> m_redundant_move_results;\n  std::vector<cfg::Edge*> m_edge_deletes;\n  std::vector<std::tuple<cfg::Block*, cfg::Block*, cfg::EdgeType>> m_edge_adds;\n  Stats m_stats;\n\n  const State& m_state;\n};\n\n/*\n * Generates an appropriate const-* instruction for a given ConstantValue.\n */\nclass value_to_instruction_visitor final\n    : public boost::static_visitor<std::vector<IRInstruction*>> {\n public:\n  explicit value_to_instruction_visitor(const IRInstruction* original,\n                                        const XStoreRefs* xstores,\n                                        const DexType* declaring_type)\n      : m_original(original),\n        m_xstores(xstores),\n        m_declaring_type(declaring_type) {}\n\n  std::vector<IRInstruction*> operator()(\n      const SignedConstantDomain& dom) const {\n    auto cst = dom.get_constant();\n    if (!cst) {\n      return {};\n    }\n    IRInstruction* insn = new IRInstruction(\n        m_original->dest_is_wide() ? OPCODE_CONST_WIDE : OPCODE_CONST);\n    insn->set_literal(*cst);\n    insn->set_dest(m_original->dest());\n    return {insn};\n  }\n\n  std::vector<IRInstruction*> operator()(const StringDomain& dom) const {\n    auto cst = dom.get_constant();\n    if (!cst) {\n      return {};\n    }\n    IRInstruction* insn = new IRInstruction(OPCODE_CONST_STRING);\n    insn->set_string(*cst);\n    return {insn, (new IRInstruction(IOPCODE_MOVE_RESULT_PSEUDO_OBJECT))\n                      ->set_dest(m_original->dest())};\n  }\n\n  std::vector<IRInstruction*> operator()(\n      const ConstantClassObjectDomain& dom) const {\n    auto cst = dom.get_constant();\n    if (!cst) {\n      return {};\n    }\n    auto type = const_cast<DexType*>(*cst);\n    if (!m_xstores || m_xstores->illegal_ref(m_declaring_type, type)) {\n      return {};\n    }\n    IRInstruction* insn = new IRInstruction(OPCODE_CONST_CLASS);\n    insn->set_type(type);\n    return {insn, (new IRInstruction(IOPCODE_MOVE_RESULT_PSEUDO_OBJECT))\n                      ->set_dest(m_original->dest())};\n  }\n\n  template <typename Domain>\n  std::vector<IRInstruction*> operator()(const Domain& dom) const {\n    return {};\n  }\n\n private:\n  const IRInstruction* m_original;\n  const XStoreRefs* m_xstores;\n  const DexType* m_declaring_type;\n};\n\n} // namespace constant_propagation",
    "repo": "facebook/redex",
    "path": "./datasets/diagrams-repos/facebook/redex/service/constant-propagation/ConstantPropagationTransform.h",
    "query": "How does the Transform class modify the control flow graph (CFG)?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'Transform', 'node_id': 'Transform', 'description': 'Main class responsible for optimizing code through CFG modifications', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'apply', 'node_id': 'apply', 'description': 'Main method that applies all available transformations on CFG', 'visibility': 'public', 'return_type': 'void', 'params': '(FixpointIterator&, WholeProgramState&, ControlFlowGraph&, XStoreRefs*, bool, DexType*, DexProto*)', 'source_class_id': 'Transform'}, {'type': 'method', 'name': 'legacy_apply_constants_and_prune_unreachable', 'node_id': 'legacy_apply_constants_and_prune_unreachable', 'description': 'Applies constant propagation and removes unreachable code', 'visibility': 'public', 'return_type': 'void', 'params': '(FixpointIterator&, WholeProgramState&, ControlFlowGraph&, XStoreRefs*, DexType*)', 'source_class_id': 'Transform'}, {'type': 'method', 'name': 'legacy_apply_forward_targets', 'node_id': 'legacy_apply_forward_targets', 'description': 'Applies target forwarding transformations', 'visibility': 'public', 'return_type': 'void', 'params': '(FixpointIterator&, ControlFlowGraph&, bool, DexType*, DexProto*, XStoreRefs*)', 'source_class_id': 'Transform'}, {'type': 'method', 'name': 'remove_dead_switch', 'node_id': 'remove_dead_switch', 'description': 'Removes unnecessary switch statements', 'visibility': 'private', 'return_type': 'void', 'params': '(FixpointIterator&, ConstantEnvironment&, ControlFlowGraph&, Block*)', 'source_class_id': 'Transform'}, {'type': 'method', 'name': 'eliminate_dead_branch', 'node_id': 'eliminate_dead_branch', 'description': 'Removes unreachable code branches', 'visibility': 'private', 'return_type': 'void', 'params': '(FixpointIterator&, ConstantEnvironment&, ControlFlowGraph&, Block*)', 'source_class_id': 'Transform'}, {'type': 'method', 'name': 'forward_targets', 'node_id': 'forward_targets', 'description': 'Updates branch targets based on constant propagation', 'visibility': 'private', 'return_type': 'void', 'params': '(FixpointIterator&, ConstantEnvironment&, ControlFlowGraph&, Block*, LivenessFixpointIterator&)', 'source_class_id': 'Transform'}], 'edges': [{'node_id_from': 'apply', 'node_id_to': 'legacy_apply_constants_and_prune_unreachable', 'description': 'calls'}, {'node_id_from': 'apply', 'node_id_to': 'legacy_apply_forward_targets', 'description': 'calls'}, {'node_id_from': 'legacy_apply_constants_and_prune_unreachable', 'node_id_to': 'remove_dead_switch', 'description': 'calls'}, {'node_id_from': 'legacy_apply_constants_and_prune_unreachable', 'node_id_to': 'eliminate_dead_branch', 'description': 'calls'}, {'node_id_from': 'legacy_apply_forward_targets', 'node_id_to': 'forward_targets', 'description': 'calls'}, {'node_id_from': 'Transform', 'node_id_to': 'apply', 'description': ''}, {'node_id_from': 'Transform', 'node_id_to': 'remove_dead_switch', 'description': ''}, {'node_id_from': 'Transform', 'node_id_to': 'eliminate_dead_branch', 'description': ''}, {'node_id_from': 'Transform', 'node_id_to': 'legacy_apply_constants_and_prune_unreachable', 'description': ''}, {'node_id_from': 'Transform', 'node_id_to': 'legacy_apply_forward_targets', 'description': ''}, {'node_id_from': 'Transform', 'node_id_to': 'forward_targets', 'description': ''}], 'packages': [{'package_id': 'cfgTransformation', 'children': ['Transform', 'apply', 'legacy_apply_constants_and_prune_unreachable', 'legacy_apply_forward_targets', 'optimizations'], 'description': 'Core CFG transformation functionality'}, {'package_id': 'optimizations', 'children': ['remove_dead_switch', 'eliminate_dead_branch', 'forward_targets'], 'description': 'Specific optimization techniques'}]}",
    "version": "medium",
    "text_answer": "The Transform class modifies the CFG through three main operations: removing dead code (branches and switches), converting instructions to constants when values are known, and forwarding branch targets. It uses constant propagation analysis to identify opportunities for these optimizations and applies them through a series of transformations coordinated by the apply method.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C++",
    "code": "\n#pragma once\n\n#include \"CFGMutation.h\"\n#include \"ConstantEnvironment.h\"\n#include \"ConstantPropagationAnalysis.h\"\n#include \"ConstantPropagationState.h\"\n#include \"ConstantPropagationWholeProgramState.h\"\n#include \"IRCode.h\"\n#include \"Liveness.h\"\n#include \"NullPointerExceptionUtil.h\"\n\nclass ScopedMetrics;\n\nnamespace constant_propagation {\n\n/**\n * Optimize the given code by:\n *   - removing dead branches\n *   - converting instructions to `const` when the values are known\n *   - removing field writes if they all write the same constant value\n */\nclass Transform final {\n public:\n  struct Config {\n    bool replace_moves_with_consts{true};\n    bool replace_move_result_with_consts{false};\n    bool remove_dead_switch{true};\n    bool add_param_const{true};\n    bool to_int_lit8{true};\n    bool to_int_lit16{false}; // Does not seem beneficial by default.\n    const DexType* class_under_init{nullptr};\n    // These methods are known pure, we can replace their results with constant\n    // value.\n    const ConcurrentSet<DexMethod*>* getter_methods_for_immutable_fields{\n        nullptr};\n    const std::unordered_set<DexMethodRef*>* pure_methods{nullptr};\n    Config() {}\n  };\n\n  struct Stats {\n    size_t branches_removed{0};\n    size_t branches_forwarded{0};\n    size_t materialized_consts{0};\n    size_t added_param_const{0};\n    size_t throws{0};\n    size_t null_checks{0};\n    size_t null_checks_method_calls{0};\n    size_t unreachable_instructions_removed{0};\n    size_t redundant_puts_removed{0};\n\n    Stats& operator+=(const Stats& that) {\n      branches_removed += that.branches_removed;\n      branches_forwarded += that.branches_forwarded;\n      materialized_consts += that.materialized_consts;\n      added_param_const += that.added_param_const;\n      throws += that.throws;\n      null_checks += that.null_checks;\n      null_checks_method_calls += that.null_checks_method_calls;\n      unreachable_instructions_removed += that.unreachable_instructions_removed;\n      redundant_puts_removed += that.redundant_puts_removed;\n      return *this;\n    }\n\n    void log_metrics(ScopedMetrics& sm, bool with_scope = true) const;\n  };\n\n  explicit Transform(Config config, const State& state)\n      : m_config(config), m_state(state) {}\n\n  // Apply all available transformations on editable cfg\n  // May run cfg.calculate_exit_block as a side-effect.\n  void apply(const intraprocedural::FixpointIterator& fp_iter,\n             const WholeProgramState& wps,\n             cfg::ControlFlowGraph& cfg,\n             const XStoreRefs* xstores,\n             bool is_static,\n             DexType* declaring_type,\n             DexProto*);\n\n  // Apply transformations on editable cfg; don't call directly, prefer calling\n  // `apply` instead.\n  void legacy_apply_constants_and_prune_unreachable(\n      const intraprocedural::FixpointIterator&,\n      const WholeProgramState&,\n      cfg::ControlFlowGraph&,\n      const XStoreRefs*,\n      const DexType*);\n\n  // Apply targets-forwarding transformations on editable cfg; don't call\n  // directly, prefer calling `apply` instead.\n  // Runs cfg.calculate_exit_block as a side-effect.\n  void legacy_apply_forward_targets(const intraprocedural::FixpointIterator&,\n                                    cfg::ControlFlowGraph&,\n                                    bool is_static,\n                                    DexType* declaring_type,\n                                    DexProto*,\n                                    const XStoreRefs*);\n\n  const Stats& get_stats() const { return m_stats; }\n\n private:\n  /*\n   * The methods in this class queue up their transformations. After they are\n   * all done, the apply_changes() method does the actual modifications.\n   */\n  void apply_changes(cfg::ControlFlowGraph&);\n\n  void simplify_instruction(const ConstantEnvironment&,\n                            const WholeProgramState& wps,\n                            const cfg::InstructionIterator& cfg_it,\n                            const XStoreRefs*,\n                            const DexType*);\n\n  bool replace_with_const(const ConstantEnvironment&,\n                          const cfg::InstructionIterator& cfg_it,\n                          const XStoreRefs*,\n                          const DexType*);\n  void generate_const_param(const ConstantEnvironment&,\n                            const cfg::InstructionIterator& cfg_it,\n                            const XStoreRefs*,\n                            const DexType*);\n\n  bool eliminate_redundant_put(const ConstantEnvironment&,\n                               const WholeProgramState& wps,\n                               const cfg::InstructionIterator& cfg_it);\n  bool eliminate_redundant_null_check(const ConstantEnvironment&,\n                                      const WholeProgramState& wps,\n                                      const cfg::InstructionIterator& cfg_it);\n  bool replace_with_throw(const ConstantEnvironment&,\n                          const cfg::InstructionIterator& cfg_it,\n                          npe::NullPointerExceptionCreator* npe_creator);\n\n  void remove_dead_switch(const intraprocedural::FixpointIterator& intra_cp,\n                          const ConstantEnvironment&,\n                          cfg::ControlFlowGraph&,\n                          cfg::Block*);\n\n  void eliminate_dead_branch(const intraprocedural::FixpointIterator&,\n                             const ConstantEnvironment&,\n                             cfg::ControlFlowGraph&,\n                             cfg::Block*);\n\n  void forward_targets(\n      const intraprocedural::FixpointIterator&,\n      const ConstantEnvironment&,\n      cfg::ControlFlowGraph&,\n      cfg::Block*,\n      std::unique_ptr<LivenessFixpointIterator>& liveness_fixpoint_iter);\n\n  // Check whether the code can return a value of a unavailable/external type,\n  // or a type defined in a store different from the one where the method is\n  // defined in.\n  bool has_problematic_return(cfg::ControlFlowGraph&,\n                              bool is_static,\n                              DexType* declaring_type,\n                              DexProto* proto,\n                              const XStoreRefs*);\n\n  bool assumenosideeffects(DexMethodRef* ref, DexMethod* meth) const;\n\n  const Config m_config;\n  std::unique_ptr<cfg::CFGMutation> m_mutation;\n  std::vector<IRInstruction*> m_added_param_values;\n  std::unordered_set<IRInstruction*> m_redundant_move_results;\n  std::vector<cfg::Edge*> m_edge_deletes;\n  std::vector<std::tuple<cfg::Block*, cfg::Block*, cfg::EdgeType>> m_edge_adds;\n  Stats m_stats;\n\n  const State& m_state;\n};\n\n/*\n * Generates an appropriate const-* instruction for a given ConstantValue.\n */\nclass value_to_instruction_visitor final\n    : public boost::static_visitor<std::vector<IRInstruction*>> {\n public:\n  explicit value_to_instruction_visitor(const IRInstruction* original,\n                                        const XStoreRefs* xstores,\n                                        const DexType* declaring_type)\n      : m_original(original),\n        m_xstores(xstores),\n        m_declaring_type(declaring_type) {}\n\n  std::vector<IRInstruction*> operator()(\n      const SignedConstantDomain& dom) const {\n    auto cst = dom.get_constant();\n    if (!cst) {\n      return {};\n    }\n    IRInstruction* insn = new IRInstruction(\n        m_original->dest_is_wide() ? OPCODE_CONST_WIDE : OPCODE_CONST);\n    insn->set_literal(*cst);\n    insn->set_dest(m_original->dest());\n    return {insn};\n  }\n\n  std::vector<IRInstruction*> operator()(const StringDomain& dom) const {\n    auto cst = dom.get_constant();\n    if (!cst) {\n      return {};\n    }\n    IRInstruction* insn = new IRInstruction(OPCODE_CONST_STRING);\n    insn->set_string(*cst);\n    return {insn, (new IRInstruction(IOPCODE_MOVE_RESULT_PSEUDO_OBJECT))\n                      ->set_dest(m_original->dest())};\n  }\n\n  std::vector<IRInstruction*> operator()(\n      const ConstantClassObjectDomain& dom) const {\n    auto cst = dom.get_constant();\n    if (!cst) {\n      return {};\n    }\n    auto type = const_cast<DexType*>(*cst);\n    if (!m_xstores || m_xstores->illegal_ref(m_declaring_type, type)) {\n      return {};\n    }\n    IRInstruction* insn = new IRInstruction(OPCODE_CONST_CLASS);\n    insn->set_type(type);\n    return {insn, (new IRInstruction(IOPCODE_MOVE_RESULT_PSEUDO_OBJECT))\n                      ->set_dest(m_original->dest())};\n  }\n\n  template <typename Domain>\n  std::vector<IRInstruction*> operator()(const Domain& dom) const {\n    return {};\n  }\n\n private:\n  const IRInstruction* m_original;\n  const XStoreRefs* m_xstores;\n  const DexType* m_declaring_type;\n};\n\n} // namespace constant_propagation",
    "repo": "facebook/redex",
    "path": "./datasets/diagrams-repos/facebook/redex/service/constant-propagation/ConstantPropagationTransform.h",
    "query": "How does the Transform class modify the control flow graph (CFG)?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'Transform', 'node_id': 'Transform', 'description': 'Main class responsible for optimizing code through CFG modifications', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'apply', 'node_id': 'apply', 'description': 'Main method that applies all available transformations on CFG', 'visibility': 'public', 'return_type': 'void', 'params': '(FixpointIterator&, WholeProgramState&, ControlFlowGraph&, XStoreRefs*, bool, DexType*, DexProto*)', 'source_class_id': 'Transform'}, {'type': 'method', 'name': 'legacy_apply_constants_and_prune_unreachable', 'node_id': 'legacy_apply_constants_and_prune_unreachable', 'description': 'Applies constant propagation and removes unreachable code', 'visibility': 'public', 'return_type': 'void', 'params': '(FixpointIterator&, WholeProgramState&, ControlFlowGraph&, XStoreRefs*, DexType*)', 'source_class_id': 'Transform'}, {'type': 'method', 'name': 'legacy_apply_forward_targets', 'node_id': 'legacy_apply_forward_targets', 'description': 'Applies target forwarding transformations', 'visibility': 'public', 'return_type': 'void', 'params': '(FixpointIterator&, ControlFlowGraph&, bool, DexType*, DexProto*, XStoreRefs*)', 'source_class_id': 'Transform'}, {'type': 'method', 'name': 'remove_dead_switch', 'node_id': 'remove_dead_switch', 'description': 'Removes unnecessary switch statements', 'visibility': 'private', 'return_type': 'void', 'params': '(FixpointIterator&, ConstantEnvironment&, ControlFlowGraph&, Block*)', 'source_class_id': 'Transform'}, {'type': 'method', 'name': 'eliminate_dead_branch', 'node_id': 'eliminate_dead_branch', 'description': 'Removes unreachable code branches', 'visibility': 'private', 'return_type': 'void', 'params': '(FixpointIterator&, ConstantEnvironment&, ControlFlowGraph&, Block*)', 'source_class_id': 'Transform'}, {'type': 'method', 'name': 'forward_targets', 'node_id': 'forward_targets', 'description': 'Updates branch targets based on constant propagation', 'visibility': 'private', 'return_type': 'void', 'params': '(FixpointIterator&, ConstantEnvironment&, ControlFlowGraph&, Block*, LivenessFixpointIterator&)', 'source_class_id': 'Transform'}, {'type': 'method', 'name': 'simplify_instruction', 'node_id': 'simplify_instruction', 'description': 'Simplifies instructions based on constant values', 'visibility': 'private', 'return_type': 'void', 'params': '(ConstantEnvironment&, WholeProgramState&, InstructionIterator&, XStoreRefs*, DexType*)', 'source_class_id': 'Transform'}, {'type': 'method', 'name': 'replace_with_const', 'node_id': 'replace_with_const', 'description': 'Replaces instructions with constant values', 'visibility': 'private', 'return_type': 'bool', 'params': '(ConstantEnvironment&, InstructionIterator&, XStoreRefs*, DexType*)', 'source_class_id': 'Transform'}, {'type': 'method', 'name': 'eliminate_redundant_put', 'node_id': 'eliminate_redundant_put', 'description': 'Removes redundant field writes', 'visibility': 'private', 'return_type': 'bool', 'params': '(ConstantEnvironment&, WholeProgramState&, InstructionIterator&)', 'source_class_id': 'Transform'}, {'type': 'class', 'name': 'value_to_instruction_visitor', 'node_id': 'value_to_instruction_visitor', 'description': 'Helper class for converting constant values to instructions', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'apply', 'node_id_to': 'legacy_apply_constants_and_prune_unreachable', 'description': 'calls'}, {'node_id_from': 'apply', 'node_id_to': 'legacy_apply_forward_targets', 'description': 'calls'}, {'node_id_from': 'legacy_apply_constants_and_prune_unreachable', 'node_id_to': 'simplify_instruction', 'description': 'calls'}, {'node_id_from': 'legacy_apply_constants_and_prune_unreachable', 'node_id_to': 'remove_dead_switch', 'description': 'calls'}, {'node_id_from': 'legacy_apply_constants_and_prune_unreachable', 'node_id_to': 'eliminate_dead_branch', 'description': 'calls'}, {'node_id_from': 'simplify_instruction', 'node_id_to': 'replace_with_const', 'description': 'calls'}, {'node_id_from': 'simplify_instruction', 'node_id_to': 'eliminate_redundant_put', 'description': 'calls'}, {'node_id_from': 'legacy_apply_forward_targets', 'node_id_to': 'forward_targets', 'description': 'calls'}, {'node_id_from': 'replace_with_const', 'node_id_to': 'value_to_instruction_visitor', 'description': 'uses'}, {'node_id_from': 'Transform', 'node_id_to': 'apply', 'description': ''}, {'node_id_from': 'Transform', 'node_id_to': 'remove_dead_switch', 'description': ''}, {'node_id_from': 'Transform', 'node_id_to': 'eliminate_dead_branch', 'description': ''}, {'node_id_from': 'Transform', 'node_id_to': 'legacy_apply_constants_and_prune_unreachable', 'description': ''}, {'node_id_from': 'Transform', 'node_id_to': 'legacy_apply_forward_targets', 'description': ''}, {'node_id_from': 'Transform', 'node_id_to': 'forward_targets', 'description': ''}, {'node_id_from': 'Transform', 'node_id_to': 'simplify_instruction', 'description': ''}, {'node_id_from': 'Transform', 'node_id_to': 'replace_with_const', 'description': ''}, {'node_id_from': 'Transform', 'node_id_to': 'eliminate_redundant_put', 'description': ''}], 'packages': [{'package_id': 'cfgTransformation', 'children': ['Transform', 'apply', 'legacy_apply_constants_and_prune_unreachable', 'legacy_apply_forward_targets', 'optimizations'], 'description': 'Core CFG transformation functionality'}, {'package_id': 'optimizations', 'children': ['remove_dead_switch', 'eliminate_dead_branch', 'forward_targets', 'simplify_instruction', 'replace_with_const', 'eliminate_redundant_put'], 'description': 'Specific optimization techniques'}]}",
    "version": "full",
    "text_answer": "The Transform class modifies the CFG through three main operations: removing dead code (branches and switches), converting instructions to constants when values are known, and forwarding branch targets. It uses constant propagation analysis to identify opportunities for these optimizations and applies them through a series of transformations coordinated by the apply method.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nJX.install('TextAreaUtils', {\n  statics : {\n    getSelectionRange : function(area) {\n      var v = area.value;\n\n      // NOTE: This works well in Safari, Firefox and Chrome. We'll probably get\n      // less-good behavior on IE.\n\n      var s = v.length;\n      var e = v.length;\n\n      if ('selectionStart' in area) {\n        s = area.selectionStart;\n        e = area.selectionEnd;\n      }\n\n      return {start: s, end: e};\n    },\n\n    getSelectionText : function(area) {\n      var v = area.value;\n      var r = JX.TextAreaUtils.getSelectionRange(area);\n      return v.substring(r.start, r.end);\n    },\n\n    setSelectionRange : function(area, start, end) {\n      if ('setSelectionRange' in area) {\n\n        // Chrome scrolls the textarea to the bottom as a side effect of\n        // calling focus(), so save the scroll position, focus, then restore\n        // the scroll position.\n        var scroll_top = area.scrollTop;\n        area.focus();\n        area.scrollTop = scroll_top;\n\n        area.setSelectionRange(start, end);\n      }\n    },\n\n    setSelectionText : function(area, text, select) {\n      var v = area.value;\n      var r = JX.TextAreaUtils.getSelectionRange(area);\n\n      v = v.substring(0, r.start) + text + v.substring(r.end, v.length);\n      area.value = v;\n\n      var start = r.start;\n      var end = r.start + text.length;\n\n      if (!select) {\n        start = end;\n      }\n\n      JX.TextAreaUtils.setSelectionRange(area, start, end);\n    },\n\n\n    /**\n     * Insert a reference to a given uploaded file into a textarea.\n     */\n    insertFileReference: function(area, file) {\n      var ref = '{F' + file.getID() + '}';\n\n      // If we're inserting immediately after a \"}\" (usually, another file\n      // reference), put some newlines before our token so that multiple file\n      // uploads get laid out more nicely.\n      var range = JX.TextAreaUtils.getSelectionRange(area);\n      var before = area.value.substring(0, range.start);\n      if (before.match(/\\}$/)) {\n        ref = '\\n\\n' + ref;\n      }\n\n      JX.TextAreaUtils.setSelectionText(area, ref, false);\n    },\n\n\n    /**\n     * Get the document pixel positions of the beginning and end of a character\n     * range in a textarea.\n     */\n    getPixelDimensions: function(area, start, end) {\n      var v = area.value;\n\n      // We're using zero-width spaces to make sure the spans get some\n      // height even if there's no text in the metrics tag.\n\n      var head = v.substring(0, start);\n      var before = JX.$N('span', {}, '\\u200b');\n      var body = v.substring(start, end);\n      var after = JX.$N('span', {}, '\\u200b');\n\n      // Create a similar shadow element which we can measure.\n      var metrics = JX.$N(\n        'var',\n        {\n          className: area.className,\n        },\n        [head, before, body, after]);\n\n      // If the textarea has a scrollbar, force a scrollbar on the shadow\n      // element too.\n      if (area.scrollHeight > area.clientHeight) {\n        metrics.style.overflowY = 'scroll';\n      }\n\n      area.parentNode.appendChild(metrics);\n\n      // Adjust the positions we read out of the document to account for the\n      // current scroll position of the textarea.\n      var metrics_pos = JX.Vector.getPos(metrics);\n      metrics_pos.x += area.scrollLeft;\n      metrics_pos.y += area.scrollTop;\n\n      var area_pos = JX.Vector.getPos(area);\n      var before_pos = JX.Vector.getPos(before);\n      var after_pos = JX.Vector.getPos(after);\n\n      JX.DOM.remove(metrics);\n\n      return {\n        start: {\n          x: area_pos.x + (before_pos.x - metrics_pos.x),\n          y: area_pos.y + (before_pos.y - metrics_pos.y)\n        },\n        end: {\n          x: area_pos.x + (after_pos.x - metrics_pos.x),\n          y: area_pos.y + (after_pos.y - metrics_pos.y)\n        }\n      };\n    }\n\n  }\n});",
    "repo": "phacility/phabricator",
    "path": "./datasets/diagrams-repos/phacility/phabricator/webroot/rsrc/js/core/TextAreaUtils.js",
    "query": "Show the process of setting the selection range and text in a textarea?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'setSelectionRange', 'node_id': 'setSelectionRange', 'description': 'Sets selection range in textarea', 'visibility': 'public', 'return_type': 'void', 'params': '(area, start, end)', 'source_class_id': None}, {'type': 'function', 'name': 'setSelectionText', 'node_id': 'setSelectionText', 'description': 'Sets selected text in textarea', 'visibility': 'public', 'return_type': 'void', 'params': '(area, text, select)', 'source_class_id': None}], 'edges': [{'node_id_from': 'setSelectionText', 'node_id_to': 'setSelectionRange', 'description': 'calls'}], 'packages': [{'package_id': 'textAreaOperations', 'children': ['setSelectionRange', 'setSelectionText'], 'description': 'Core text area manipulation functions'}]}",
    "version": "minimal",
    "text_answer": "To set selection range and text in a textarea, first getSelectionRange() obtains current selection coordinates, then setSelectionText() updates the content using these coordinates and finally calls setSelectionRange() to update the visual selection.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nJX.install('TextAreaUtils', {\n  statics : {\n    getSelectionRange : function(area) {\n      var v = area.value;\n\n      // NOTE: This works well in Safari, Firefox and Chrome. We'll probably get\n      // less-good behavior on IE.\n\n      var s = v.length;\n      var e = v.length;\n\n      if ('selectionStart' in area) {\n        s = area.selectionStart;\n        e = area.selectionEnd;\n      }\n\n      return {start: s, end: e};\n    },\n\n    getSelectionText : function(area) {\n      var v = area.value;\n      var r = JX.TextAreaUtils.getSelectionRange(area);\n      return v.substring(r.start, r.end);\n    },\n\n    setSelectionRange : function(area, start, end) {\n      if ('setSelectionRange' in area) {\n\n        // Chrome scrolls the textarea to the bottom as a side effect of\n        // calling focus(), so save the scroll position, focus, then restore\n        // the scroll position.\n        var scroll_top = area.scrollTop;\n        area.focus();\n        area.scrollTop = scroll_top;\n\n        area.setSelectionRange(start, end);\n      }\n    },\n\n    setSelectionText : function(area, text, select) {\n      var v = area.value;\n      var r = JX.TextAreaUtils.getSelectionRange(area);\n\n      v = v.substring(0, r.start) + text + v.substring(r.end, v.length);\n      area.value = v;\n\n      var start = r.start;\n      var end = r.start + text.length;\n\n      if (!select) {\n        start = end;\n      }\n\n      JX.TextAreaUtils.setSelectionRange(area, start, end);\n    },\n\n\n    /**\n     * Insert a reference to a given uploaded file into a textarea.\n     */\n    insertFileReference: function(area, file) {\n      var ref = '{F' + file.getID() + '}';\n\n      // If we're inserting immediately after a \"}\" (usually, another file\n      // reference), put some newlines before our token so that multiple file\n      // uploads get laid out more nicely.\n      var range = JX.TextAreaUtils.getSelectionRange(area);\n      var before = area.value.substring(0, range.start);\n      if (before.match(/\\}$/)) {\n        ref = '\\n\\n' + ref;\n      }\n\n      JX.TextAreaUtils.setSelectionText(area, ref, false);\n    },\n\n\n    /**\n     * Get the document pixel positions of the beginning and end of a character\n     * range in a textarea.\n     */\n    getPixelDimensions: function(area, start, end) {\n      var v = area.value;\n\n      // We're using zero-width spaces to make sure the spans get some\n      // height even if there's no text in the metrics tag.\n\n      var head = v.substring(0, start);\n      var before = JX.$N('span', {}, '\\u200b');\n      var body = v.substring(start, end);\n      var after = JX.$N('span', {}, '\\u200b');\n\n      // Create a similar shadow element which we can measure.\n      var metrics = JX.$N(\n        'var',\n        {\n          className: area.className,\n        },\n        [head, before, body, after]);\n\n      // If the textarea has a scrollbar, force a scrollbar on the shadow\n      // element too.\n      if (area.scrollHeight > area.clientHeight) {\n        metrics.style.overflowY = 'scroll';\n      }\n\n      area.parentNode.appendChild(metrics);\n\n      // Adjust the positions we read out of the document to account for the\n      // current scroll position of the textarea.\n      var metrics_pos = JX.Vector.getPos(metrics);\n      metrics_pos.x += area.scrollLeft;\n      metrics_pos.y += area.scrollTop;\n\n      var area_pos = JX.Vector.getPos(area);\n      var before_pos = JX.Vector.getPos(before);\n      var after_pos = JX.Vector.getPos(after);\n\n      JX.DOM.remove(metrics);\n\n      return {\n        start: {\n          x: area_pos.x + (before_pos.x - metrics_pos.x),\n          y: area_pos.y + (before_pos.y - metrics_pos.y)\n        },\n        end: {\n          x: area_pos.x + (after_pos.x - metrics_pos.x),\n          y: area_pos.y + (after_pos.y - metrics_pos.y)\n        }\n      };\n    }\n\n  }\n});",
    "repo": "phacility/phabricator",
    "path": "./datasets/diagrams-repos/phacility/phabricator/webroot/rsrc/js/core/TextAreaUtils.js",
    "query": "Show the process of setting the selection range and text in a textarea?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'getSelectionRange', 'node_id': 'getSelectionRange', 'description': 'Gets current selection range in textarea', 'visibility': 'public', 'return_type': 'object', 'params': '(area)', 'source_class_id': None}, {'type': 'function', 'name': 'setSelectionRange', 'node_id': 'setSelectionRange', 'description': 'Sets selection range in textarea', 'visibility': 'public', 'return_type': 'void', 'params': '(area, start, end)', 'source_class_id': None}, {'type': 'function', 'name': 'setSelectionText', 'node_id': 'setSelectionText', 'description': 'Sets selected text in textarea', 'visibility': 'public', 'return_type': 'void', 'params': '(area, text, select)', 'source_class_id': None}, {'type': 'entity', 'name': 'selectionRange', 'node_id': 'selectionRange', 'description': 'Selection range object with start and end positions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'setSelectionText', 'node_id_to': 'getSelectionRange', 'description': 'gets current selection'}, {'node_id_from': 'setSelectionText', 'node_id_to': 'setSelectionRange', 'description': 'updates selection'}, {'node_id_from': 'getSelectionRange', 'node_id_to': 'selectionRange', 'description': 'returns'}], 'packages': [{'package_id': 'textAreaOperations', 'children': ['getSelectionRange', 'setSelectionRange', 'setSelectionText', 'selectionRange'], 'description': 'Text area selection manipulation functions'}]}",
    "version": "medium",
    "text_answer": "To set selection range and text in a textarea, first getSelectionRange() obtains current selection coordinates, then setSelectionText() updates the content using these coordinates and finally calls setSelectionRange() to update the visual selection.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nJX.install('TextAreaUtils', {\n  statics : {\n    getSelectionRange : function(area) {\n      var v = area.value;\n\n      // NOTE: This works well in Safari, Firefox and Chrome. We'll probably get\n      // less-good behavior on IE.\n\n      var s = v.length;\n      var e = v.length;\n\n      if ('selectionStart' in area) {\n        s = area.selectionStart;\n        e = area.selectionEnd;\n      }\n\n      return {start: s, end: e};\n    },\n\n    getSelectionText : function(area) {\n      var v = area.value;\n      var r = JX.TextAreaUtils.getSelectionRange(area);\n      return v.substring(r.start, r.end);\n    },\n\n    setSelectionRange : function(area, start, end) {\n      if ('setSelectionRange' in area) {\n\n        // Chrome scrolls the textarea to the bottom as a side effect of\n        // calling focus(), so save the scroll position, focus, then restore\n        // the scroll position.\n        var scroll_top = area.scrollTop;\n        area.focus();\n        area.scrollTop = scroll_top;\n\n        area.setSelectionRange(start, end);\n      }\n    },\n\n    setSelectionText : function(area, text, select) {\n      var v = area.value;\n      var r = JX.TextAreaUtils.getSelectionRange(area);\n\n      v = v.substring(0, r.start) + text + v.substring(r.end, v.length);\n      area.value = v;\n\n      var start = r.start;\n      var end = r.start + text.length;\n\n      if (!select) {\n        start = end;\n      }\n\n      JX.TextAreaUtils.setSelectionRange(area, start, end);\n    },\n\n\n    /**\n     * Insert a reference to a given uploaded file into a textarea.\n     */\n    insertFileReference: function(area, file) {\n      var ref = '{F' + file.getID() + '}';\n\n      // If we're inserting immediately after a \"}\" (usually, another file\n      // reference), put some newlines before our token so that multiple file\n      // uploads get laid out more nicely.\n      var range = JX.TextAreaUtils.getSelectionRange(area);\n      var before = area.value.substring(0, range.start);\n      if (before.match(/\\}$/)) {\n        ref = '\\n\\n' + ref;\n      }\n\n      JX.TextAreaUtils.setSelectionText(area, ref, false);\n    },\n\n\n    /**\n     * Get the document pixel positions of the beginning and end of a character\n     * range in a textarea.\n     */\n    getPixelDimensions: function(area, start, end) {\n      var v = area.value;\n\n      // We're using zero-width spaces to make sure the spans get some\n      // height even if there's no text in the metrics tag.\n\n      var head = v.substring(0, start);\n      var before = JX.$N('span', {}, '\\u200b');\n      var body = v.substring(start, end);\n      var after = JX.$N('span', {}, '\\u200b');\n\n      // Create a similar shadow element which we can measure.\n      var metrics = JX.$N(\n        'var',\n        {\n          className: area.className,\n        },\n        [head, before, body, after]);\n\n      // If the textarea has a scrollbar, force a scrollbar on the shadow\n      // element too.\n      if (area.scrollHeight > area.clientHeight) {\n        metrics.style.overflowY = 'scroll';\n      }\n\n      area.parentNode.appendChild(metrics);\n\n      // Adjust the positions we read out of the document to account for the\n      // current scroll position of the textarea.\n      var metrics_pos = JX.Vector.getPos(metrics);\n      metrics_pos.x += area.scrollLeft;\n      metrics_pos.y += area.scrollTop;\n\n      var area_pos = JX.Vector.getPos(area);\n      var before_pos = JX.Vector.getPos(before);\n      var after_pos = JX.Vector.getPos(after);\n\n      JX.DOM.remove(metrics);\n\n      return {\n        start: {\n          x: area_pos.x + (before_pos.x - metrics_pos.x),\n          y: area_pos.y + (before_pos.y - metrics_pos.y)\n        },\n        end: {\n          x: area_pos.x + (after_pos.x - metrics_pos.x),\n          y: area_pos.y + (after_pos.y - metrics_pos.y)\n        }\n      };\n    }\n\n  }\n});",
    "repo": "phacility/phabricator",
    "path": "./datasets/diagrams-repos/phacility/phabricator/webroot/rsrc/js/core/TextAreaUtils.js",
    "query": "Show the process of setting the selection range and text in a textarea?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'TextAreaUtils', 'node_id': 'TextAreaUtils', 'description': 'Utility class for textarea operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'getSelectionRange', 'node_id': 'getSelectionRange', 'description': 'Gets current selection range in textarea', 'visibility': 'public', 'return_type': 'object', 'params': '(area)', 'source_class_id': 'TextAreaUtils'}, {'type': 'method', 'name': 'setSelectionRange', 'node_id': 'setSelectionRange', 'description': 'Sets selection range in textarea', 'visibility': 'public', 'return_type': 'void', 'params': '(area, start, end)', 'source_class_id': 'TextAreaUtils'}, {'type': 'method', 'name': 'setSelectionText', 'node_id': 'setSelectionText', 'description': 'Sets selected text in textarea', 'visibility': 'public', 'return_type': 'void', 'params': '(area, text, select)', 'source_class_id': 'TextAreaUtils'}, {'type': 'method', 'name': 'getSelectionText', 'node_id': 'getSelectionText', 'description': 'Gets currently selected text', 'visibility': 'public', 'return_type': 'string', 'params': '(area)', 'source_class_id': 'TextAreaUtils'}, {'type': 'method', 'name': 'insertFileReference', 'node_id': 'insertFileReference', 'description': 'Inserts file reference at current position', 'visibility': 'public', 'return_type': 'void', 'params': '(area, file)', 'source_class_id': 'TextAreaUtils'}, {'type': 'method', 'name': 'getPixelDimensions', 'node_id': 'getPixelDimensions', 'description': 'Gets pixel positions of selection range', 'visibility': 'public', 'return_type': 'object', 'params': '(area, start, end)', 'source_class_id': 'TextAreaUtils'}, {'type': 'entity', 'name': 'selectionRange', 'node_id': 'selectionRange', 'description': 'Selection range object with start and end positions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'TextAreaUtils', 'node_id_to': 'getSelectionRange', 'description': 'contains'}, {'node_id_from': 'TextAreaUtils', 'node_id_to': 'setSelectionRange', 'description': 'contains'}, {'node_id_from': 'TextAreaUtils', 'node_id_to': 'setSelectionText', 'description': 'contains'}, {'node_id_from': 'TextAreaUtils', 'node_id_to': 'getSelectionText', 'description': 'contains'}, {'node_id_from': 'TextAreaUtils', 'node_id_to': 'insertFileReference', 'description': 'contains'}, {'node_id_from': 'TextAreaUtils', 'node_id_to': 'getPixelDimensions', 'description': 'contains'}, {'node_id_from': 'setSelectionText', 'node_id_to': 'getSelectionRange', 'description': 'uses'}, {'node_id_from': 'setSelectionText', 'node_id_to': 'setSelectionRange', 'description': 'calls'}, {'node_id_from': 'getSelectionText', 'node_id_to': 'getSelectionRange', 'description': 'uses'}, {'node_id_from': 'insertFileReference', 'node_id_to': 'getSelectionRange', 'description': 'uses'}, {'node_id_from': 'insertFileReference', 'node_id_to': 'setSelectionText', 'description': 'uses'}, {'node_id_from': 'getSelectionRange', 'node_id_to': 'selectionRange', 'description': 'returns'}], 'packages': [{'package_id': 'selectionOperations', 'children': ['getSelectionRange', 'setSelectionRange', 'getSelectionText', 'setSelectionText', 'selectionRange'], 'description': 'Selection-related operations'}, {'package_id': 'additionalFeatures', 'children': ['insertFileReference', 'getPixelDimensions'], 'description': 'Additional textarea utilities'}]}",
    "version": "full",
    "text_answer": "To set selection range and text in a textarea, first getSelectionRange() obtains current selection coordinates, then setSelectionText() updates the content using these coordinates and finally calls setSelectionRange() to update the visual selection.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nconst assert = require(\"assert\");\nconst cas = require(\"../../cas.js\");\n\n(async () => {\n    let params = \"client_id=client&\";\n    params += \"client_secret=secret&\";\n    params += \"scope=uma_protection&\";\n    params += \"username=casuser&\";\n    params += \"password=Mellon&\";\n    params += \"grant_type=password\";\n\n    let at = null;\n    const url = `https://localhost:8443/cas/oauth2.0/token?${params}`;\n    await cas.doPost(url, params, {\n        \"Content-Type\": \"application/json\"\n    }, (res) => {\n        at = res.data.access_token;\n    }, (error) => {\n        throw `Operation failed: ${error}`;\n    });\n\n    const resourceUrl = \"https://localhost:8443/cas/oauth2.0/resourceSet\";\n    const resourceObject = {\n        uri: \"http://api.example.org/photos/**\",\n        type: \"website\",\n        name: \"Photos API\",\n        resource_scopes: [\"create\", \"read\"]\n    };\n    const resourceRequest = JSON.stringify(resourceObject);\n    await cas.log(`Creating resource ${resourceRequest}`);\n    const resource = JSON.parse(await cas.doRequest(resourceUrl, \"POST\",\n        {\n            \"Authorization\": `Bearer ${at}`,\n            \"Content-Length\": resourceRequest.length,\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\"\n        }, 200, resourceRequest));\n    await cas.log(resource);\n\n    const policyUrl = `https://localhost:8443/cas/oauth2.0/${resource.resourceId}/policy`;\n    const policyObject = {\n        id: 1234,\n        permissions: [\n            {\n                id: 1,\n                subject: \"casuser\",\n                scopes: [\"read\"],\n                claims: {\n                    first_name: \"CAS\",\n                    last_name: \"User\"\n                }\n            },\n            {\n                id: 2,\n                subject: \"casuser\",\n                scopes: [\"create\"],\n                claims: {\n                    first_name: \"CAS\",\n                    last_name: \"User\"\n                }\n            }\n        ]\n    };\n    const policyRequest = JSON.stringify(policyObject);\n    await cas.log(`Creating policy ${policyRequest}`);\n    let result = JSON.parse(await cas.doRequest(policyUrl, \"POST\",\n        {\n            \"Authorization\": `Bearer ${at}`,\n            \"Content-Length\": policyRequest.length,\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\"\n        }, 200, policyRequest));\n    await cas.log(result);\n\n    const permissionObject = {\n        resource_id: resource.resourceId,\n        resource_scopes: [\"read\"],\n        claims: {\n            first_name: \"CAS\"\n        }\n    };\n\n    const permissionRequest = JSON.stringify(permissionObject);\n    await cas.log(`Creating permission ${permissionRequest}`);\n    result = JSON.parse(await cas.doRequest(\"https://localhost:8443/cas/oauth2.0/permission\", \"POST\",\n        {\n            \"Authorization\": `Bearer ${at}`,\n            \"Content-Length\": permissionRequest.length,\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\"\n        }, 200, permissionRequest));\n    await cas.log(result);\n    assert(result.ticket !== undefined);\n    assert(result.code !== undefined);\n\n    await cas.log(\"Checking for claims\");\n\n    const redirectUrl = \"https://localhost:9859/anything/cas\";\n    params = `client_id=client&ticket=${result.ticket}&state=12345&redirect_uri=${redirectUrl}`;\n    await cas.doRequest(`https://localhost:8443/cas/oauth2.0/rqpClaims?${params}`, \"GET\",\n        {\n            \"Authorization\": `Bearer ${at}`,\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\"\n        }, 302, undefined,\n        (res) => {\n            cas.log(res.headers);\n            assert(res.headers.location.includes(\n                `${redirectUrl}?authorization_state=claims_submitted&state=12345`));\n        });\n})();",
    "repo": "apereo/cas",
    "path": "./datasets/diagrams-repos/apereo/cas/ci/tests/puppeteer/scenarios/uma-permission-management/script.js",
    "query": "What is the structure of the resource object in the code?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'resourceObject', 'node_id': 'resourceObject', 'description': 'Object containing resource details', 'visibility': 'public', 'return_type': 'object', 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'uri', 'node_id': 'uri', 'description': 'API endpoint pattern', 'visibility': 'public', 'return_type': 'string', 'params': None, 'source_class_id': 'resourceObject'}, {'type': 'field', 'name': 'type', 'node_id': 'type', 'description': 'Resource type', 'visibility': 'public', 'return_type': 'string', 'params': None, 'source_class_id': 'resourceObject'}, {'type': 'field', 'name': 'name', 'node_id': 'name', 'description': 'Resource name', 'visibility': 'public', 'return_type': 'string', 'params': None, 'source_class_id': 'resourceObject'}, {'type': 'field', 'name': 'resource_scopes', 'node_id': 'resource_scopes', 'description': 'Available resource permissions', 'visibility': 'public', 'return_type': 'array', 'params': None, 'source_class_id': 'resourceObject'}], 'edges': [{'node_id_from': 'resourceObject', 'node_id_to': 'uri', 'description': None}, {'node_id_from': 'resourceObject', 'node_id_to': 'type', 'description': None}, {'node_id_from': 'resourceObject', 'node_id_to': 'name', 'description': None}, {'node_id_from': 'resourceObject', 'node_id_to': 'resource_scopes', 'description': None}], 'packages': [{'package_id': 'resourceStructure', 'children': ['resourceObject', 'uri', 'type', 'name', 'resource_scopes'], 'description': 'Resource object structure'}]}",
    "version": "minimal",
    "text_answer": "The resource object is structured with four fields: 'uri' (API endpoint pattern), 'type' (website), 'name' (Photos API), and 'resource_scopes' (array containing 'create' and 'read' permissions).",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nconst assert = require(\"assert\");\nconst cas = require(\"../../cas.js\");\n\n(async () => {\n    let params = \"client_id=client&\";\n    params += \"client_secret=secret&\";\n    params += \"scope=uma_protection&\";\n    params += \"username=casuser&\";\n    params += \"password=Mellon&\";\n    params += \"grant_type=password\";\n\n    let at = null;\n    const url = `https://localhost:8443/cas/oauth2.0/token?${params}`;\n    await cas.doPost(url, params, {\n        \"Content-Type\": \"application/json\"\n    }, (res) => {\n        at = res.data.access_token;\n    }, (error) => {\n        throw `Operation failed: ${error}`;\n    });\n\n    const resourceUrl = \"https://localhost:8443/cas/oauth2.0/resourceSet\";\n    const resourceObject = {\n        uri: \"http://api.example.org/photos/**\",\n        type: \"website\",\n        name: \"Photos API\",\n        resource_scopes: [\"create\", \"read\"]\n    };\n    const resourceRequest = JSON.stringify(resourceObject);\n    await cas.log(`Creating resource ${resourceRequest}`);\n    const resource = JSON.parse(await cas.doRequest(resourceUrl, \"POST\",\n        {\n            \"Authorization\": `Bearer ${at}`,\n            \"Content-Length\": resourceRequest.length,\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\"\n        }, 200, resourceRequest));\n    await cas.log(resource);\n\n    const policyUrl = `https://localhost:8443/cas/oauth2.0/${resource.resourceId}/policy`;\n    const policyObject = {\n        id: 1234,\n        permissions: [\n            {\n                id: 1,\n                subject: \"casuser\",\n                scopes: [\"read\"],\n                claims: {\n                    first_name: \"CAS\",\n                    last_name: \"User\"\n                }\n            },\n            {\n                id: 2,\n                subject: \"casuser\",\n                scopes: [\"create\"],\n                claims: {\n                    first_name: \"CAS\",\n                    last_name: \"User\"\n                }\n            }\n        ]\n    };\n    const policyRequest = JSON.stringify(policyObject);\n    await cas.log(`Creating policy ${policyRequest}`);\n    let result = JSON.parse(await cas.doRequest(policyUrl, \"POST\",\n        {\n            \"Authorization\": `Bearer ${at}`,\n            \"Content-Length\": policyRequest.length,\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\"\n        }, 200, policyRequest));\n    await cas.log(result);\n\n    const permissionObject = {\n        resource_id: resource.resourceId,\n        resource_scopes: [\"read\"],\n        claims: {\n            first_name: \"CAS\"\n        }\n    };\n\n    const permissionRequest = JSON.stringify(permissionObject);\n    await cas.log(`Creating permission ${permissionRequest}`);\n    result = JSON.parse(await cas.doRequest(\"https://localhost:8443/cas/oauth2.0/permission\", \"POST\",\n        {\n            \"Authorization\": `Bearer ${at}`,\n            \"Content-Length\": permissionRequest.length,\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\"\n        }, 200, permissionRequest));\n    await cas.log(result);\n    assert(result.ticket !== undefined);\n    assert(result.code !== undefined);\n\n    await cas.log(\"Checking for claims\");\n\n    const redirectUrl = \"https://localhost:9859/anything/cas\";\n    params = `client_id=client&ticket=${result.ticket}&state=12345&redirect_uri=${redirectUrl}`;\n    await cas.doRequest(`https://localhost:8443/cas/oauth2.0/rqpClaims?${params}`, \"GET\",\n        {\n            \"Authorization\": `Bearer ${at}`,\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\"\n        }, 302, undefined,\n        (res) => {\n            cas.log(res.headers);\n            assert(res.headers.location.includes(\n                `${redirectUrl}?authorization_state=claims_submitted&state=12345`));\n        });\n})();",
    "repo": "apereo/cas",
    "path": "./datasets/diagrams-repos/apereo/cas/ci/tests/puppeteer/scenarios/uma-permission-management/script.js",
    "query": "What is the structure of the resource object in the code?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'resourceObject', 'node_id': 'resourceObject', 'description': 'Object containing resource details', 'visibility': 'public', 'return_type': 'object', 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'uri', 'node_id': 'uri', 'description': 'API endpoint pattern', 'visibility': 'public', 'return_type': 'string', 'params': None, 'source_class_id': 'resourceObject'}, {'type': 'field', 'name': 'type', 'node_id': 'type', 'description': 'Resource type', 'visibility': 'public', 'return_type': 'string', 'params': None, 'source_class_id': 'resourceObject'}, {'type': 'field', 'name': 'name', 'node_id': 'name', 'description': 'Resource name', 'visibility': 'public', 'return_type': 'string', 'params': None, 'source_class_id': 'resourceObject'}, {'type': 'field', 'name': 'resource_scopes', 'node_id': 'resource_scopes', 'description': 'Available resource permissions', 'visibility': 'public', 'return_type': 'array', 'params': None, 'source_class_id': 'resourceObject'}, {'type': 'variable', 'name': 'resourceRequest', 'node_id': 'resourceRequest', 'description': 'Stringified resource object', 'visibility': 'public', 'return_type': 'string', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'resourceObject', 'node_id_to': 'uri', 'description': None}, {'node_id_from': 'resourceObject', 'node_id_to': 'type', 'description': None}, {'node_id_from': 'resourceObject', 'node_id_to': 'name', 'description': None}, {'node_id_from': 'resourceObject', 'node_id_to': 'resource_scopes', 'description': None}, {'node_id_from': 'resourceObject', 'node_id_to': 'resourceRequest', 'description': 'JSON.stringify'}], 'packages': [{'package_id': 'resourceManagement', 'children': ['resourceStructure', 'resourceRequest'], 'description': 'Resource management components'}, {'package_id': 'resourceStructure', 'children': ['resourceObject', 'uri', 'type', 'name', 'resource_scopes'], 'description': 'Resource object structure'}]}",
    "version": "medium",
    "text_answer": "The resource object is structured with four fields: 'uri' (API endpoint pattern), 'type' (website), 'name' (Photos API), and 'resource_scopes' (array containing 'create' and 'read' permissions).",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nconst assert = require(\"assert\");\nconst cas = require(\"../../cas.js\");\n\n(async () => {\n    let params = \"client_id=client&\";\n    params += \"client_secret=secret&\";\n    params += \"scope=uma_protection&\";\n    params += \"username=casuser&\";\n    params += \"password=Mellon&\";\n    params += \"grant_type=password\";\n\n    let at = null;\n    const url = `https://localhost:8443/cas/oauth2.0/token?${params}`;\n    await cas.doPost(url, params, {\n        \"Content-Type\": \"application/json\"\n    }, (res) => {\n        at = res.data.access_token;\n    }, (error) => {\n        throw `Operation failed: ${error}`;\n    });\n\n    const resourceUrl = \"https://localhost:8443/cas/oauth2.0/resourceSet\";\n    const resourceObject = {\n        uri: \"http://api.example.org/photos/**\",\n        type: \"website\",\n        name: \"Photos API\",\n        resource_scopes: [\"create\", \"read\"]\n    };\n    const resourceRequest = JSON.stringify(resourceObject);\n    await cas.log(`Creating resource ${resourceRequest}`);\n    const resource = JSON.parse(await cas.doRequest(resourceUrl, \"POST\",\n        {\n            \"Authorization\": `Bearer ${at}`,\n            \"Content-Length\": resourceRequest.length,\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\"\n        }, 200, resourceRequest));\n    await cas.log(resource);\n\n    const policyUrl = `https://localhost:8443/cas/oauth2.0/${resource.resourceId}/policy`;\n    const policyObject = {\n        id: 1234,\n        permissions: [\n            {\n                id: 1,\n                subject: \"casuser\",\n                scopes: [\"read\"],\n                claims: {\n                    first_name: \"CAS\",\n                    last_name: \"User\"\n                }\n            },\n            {\n                id: 2,\n                subject: \"casuser\",\n                scopes: [\"create\"],\n                claims: {\n                    first_name: \"CAS\",\n                    last_name: \"User\"\n                }\n            }\n        ]\n    };\n    const policyRequest = JSON.stringify(policyObject);\n    await cas.log(`Creating policy ${policyRequest}`);\n    let result = JSON.parse(await cas.doRequest(policyUrl, \"POST\",\n        {\n            \"Authorization\": `Bearer ${at}`,\n            \"Content-Length\": policyRequest.length,\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\"\n        }, 200, policyRequest));\n    await cas.log(result);\n\n    const permissionObject = {\n        resource_id: resource.resourceId,\n        resource_scopes: [\"read\"],\n        claims: {\n            first_name: \"CAS\"\n        }\n    };\n\n    const permissionRequest = JSON.stringify(permissionObject);\n    await cas.log(`Creating permission ${permissionRequest}`);\n    result = JSON.parse(await cas.doRequest(\"https://localhost:8443/cas/oauth2.0/permission\", \"POST\",\n        {\n            \"Authorization\": `Bearer ${at}`,\n            \"Content-Length\": permissionRequest.length,\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\"\n        }, 200, permissionRequest));\n    await cas.log(result);\n    assert(result.ticket !== undefined);\n    assert(result.code !== undefined);\n\n    await cas.log(\"Checking for claims\");\n\n    const redirectUrl = \"https://localhost:9859/anything/cas\";\n    params = `client_id=client&ticket=${result.ticket}&state=12345&redirect_uri=${redirectUrl}`;\n    await cas.doRequest(`https://localhost:8443/cas/oauth2.0/rqpClaims?${params}`, \"GET\",\n        {\n            \"Authorization\": `Bearer ${at}`,\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\"\n        }, 302, undefined,\n        (res) => {\n            cas.log(res.headers);\n            assert(res.headers.location.includes(\n                `${redirectUrl}?authorization_state=claims_submitted&state=12345`));\n        });\n})();",
    "repo": "apereo/cas",
    "path": "./datasets/diagrams-repos/apereo/cas/ci/tests/puppeteer/scenarios/uma-permission-management/script.js",
    "query": "What is the structure of the resource object in the code?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'resourceObject', 'node_id': 'resourceObject', 'description': 'Object containing resource details', 'visibility': 'public', 'return_type': 'object', 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'uri', 'node_id': 'uri', 'description': 'API endpoint pattern', 'visibility': 'public', 'return_type': 'string', 'params': None, 'source_class_id': 'resourceObject'}, {'type': 'field', 'name': 'type', 'node_id': 'type', 'description': 'Resource type', 'visibility': 'public', 'return_type': 'string', 'params': None, 'source_class_id': 'resourceObject'}, {'type': 'field', 'name': 'name', 'node_id': 'name', 'description': 'Resource name', 'visibility': 'public', 'return_type': 'string', 'params': None, 'source_class_id': 'resourceObject'}, {'type': 'field', 'name': 'resource_scopes', 'node_id': 'resource_scopes', 'description': 'Available resource permissions', 'visibility': 'public', 'return_type': 'array', 'params': None, 'source_class_id': 'resourceObject'}, {'type': 'variable', 'name': 'resourceRequest', 'node_id': 'resourceRequest', 'description': 'Stringified resource object', 'visibility': 'public', 'return_type': 'string', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'resourceUrl', 'node_id': 'resourceUrl', 'description': 'Endpoint for resource creation', 'visibility': 'public', 'return_type': 'string', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'resource', 'node_id': 'resource', 'description': 'Created resource response', 'visibility': 'public', 'return_type': 'object', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'doRequest', 'node_id': 'doRequest', 'description': 'Performs HTTP request', 'visibility': 'public', 'return_type': 'Promise', 'params': '(url, method, headers, status, body)', 'source_class_id': None}], 'edges': [{'node_id_from': 'resourceObject', 'node_id_to': 'uri', 'description': None}, {'node_id_from': 'resourceObject', 'node_id_to': 'type', 'description': None}, {'node_id_from': 'resourceObject', 'node_id_to': 'name', 'description': None}, {'node_id_from': 'resourceObject', 'node_id_to': 'resource_scopes', 'description': None}, {'node_id_from': 'resourceObject', 'node_id_to': 'resourceRequest', 'description': 'JSON.stringify'}, {'node_id_from': 'resourceRequest', 'node_id_to': 'doRequest', 'description': 'Used as request body'}, {'node_id_from': 'doRequest', 'node_id_to': 'resource', 'description': 'Response parsed'}, {'node_id_from': 'resourceUrl', 'node_id_to': 'resource', 'description': 'used by'}], 'packages': [{'package_id': 'resourceManagement', 'children': ['resourceStructure', 'apiCommunication'], 'description': 'Resource management components'}, {'package_id': 'resourceStructure', 'children': ['resourceObject', 'uri', 'type', 'name', 'resource_scopes'], 'description': 'Resource object structure'}, {'package_id': 'apiCommunication', 'children': ['resourceRequest', 'resourceUrl', 'resource', 'doRequest'], 'description': 'API communication components'}]}",
    "version": "full",
    "text_answer": "The resource object is structured with four fields: 'uri' (API endpoint pattern), 'type' (website), 'name' (Photos API), and 'resource_scopes' (array containing 'create' and 'read' permissions).",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Python",
    "code": "\nimport os\n\nimport toml\nfrom prefect_kubernetes.settings import KubernetesSettings\n\n\ndef test_set_values_via_environment_variables(monkeypatch):\n    monkeypatch.setenv(\n        \"PREFECT_INTEGRATIONS_KUBERNETES_WORKER_API_KEY_SECRET_NAME\", \"test-secret\"\n    )\n    monkeypatch.setenv(\n        \"PREFECT_INTEGRATIONS_KUBERNETES_WORKER_CREATE_SECRET_FOR_API_KEY\", \"true\"\n    )\n    monkeypatch.setenv(\n        \"PREFECT_INTEGRATIONS_KUBERNETES_WORKER_ADD_TCP_KEEPALIVE\", \"false\"\n    )\n    monkeypatch.setenv(\n        \"PREFECT_INTEGRATIONS_KUBERNETES_CLUSTER_UID\", \"test-cluster-uid\"\n    )\n\n    settings = KubernetesSettings()\n\n    assert settings.worker.api_key_secret_name == \"test-secret\"\n    assert settings.worker.create_secret_for_api_key is True\n    assert settings.worker.add_tcp_keepalive is False\n    assert settings.cluster_uid == \"test-cluster-uid\"\n\n\ndef test_set_values_via_dot_env_file(tmp_path):\n    dot_env_path = tmp_path / \".env\"\n    with open(dot_env_path, \"w\") as f:\n        f.write(\n            \"PREFECT_INTEGRATIONS_KUBERNETES_WORKER_API_KEY_SECRET_NAME=test-secret\\n\"\n            \"PREFECT_INTEGRATIONS_KUBERNETES_WORKER_CREATE_SECRET_FOR_API_KEY=true\\n\"\n            \"PREFECT_INTEGRATIONS_KUBERNETES_WORKER_ADD_TCP_KEEPALIVE=false\\n\"\n            \"PREFECT_INTEGRATIONS_KUBERNETES_CLUSTER_UID=test-cluster-uid\\n\"\n        )\n\n    original_dir = os.getcwd()\n    try:\n        os.chdir(tmp_path)\n        settings = KubernetesSettings()\n    finally:\n        os.chdir(original_dir)\n\n    assert settings.worker.api_key_secret_name == \"test-secret\"\n    assert settings.worker.create_secret_for_api_key is True\n    assert settings.worker.add_tcp_keepalive is False\n    assert settings.cluster_uid == \"test-cluster-uid\"\n\n\ndef test_set_values_via_prefect_toml_file(tmp_path):\n    toml_path = tmp_path / \"prefect.toml\"\n    toml_data = {\n        \"integrations\": {\n            \"kubernetes\": {\n                \"worker\": {\n                    \"api_key_secret_name\": \"test-secret\",\n                    \"create_secret_for_api_key\": True,\n                    \"add_tcp_keepalive\": False,\n                },\n                \"cluster_uid\": \"test-cluster-uid\",\n            },\n        },\n    }\n    toml_path.write_text(toml.dumps(toml_data))\n\n    original_dir = os.getcwd()\n    try:\n        os.chdir(tmp_path)\n        settings = KubernetesSettings()\n    finally:\n        os.chdir(original_dir)\n\n    assert settings.worker.api_key_secret_name == \"test-secret\"\n    assert settings.worker.create_secret_for_api_key is True\n    assert settings.worker.add_tcp_keepalive is False\n    assert settings.cluster_uid == \"test-cluster-uid\"\n\n\ndef test_set_values_via_pyproject_toml_file(tmp_path):\n    pyproject_toml_path = tmp_path / \"pyproject.toml\"\n    pyproject_toml_data = {\n        \"tool\": {\n            \"prefect\": {\n                \"integrations\": {\n                    \"kubernetes\": {\n                        \"cluster_uid\": \"test-cluster-uid\",\n                        \"worker\": {\n                            \"api_key_secret_name\": \"test-secret\",\n                            \"create_secret_for_api_key\": True,\n                            \"add_tcp_keepalive\": False,\n                        },\n                    },\n                },\n            },\n        },\n    }\n    pyproject_toml_path.write_text(toml.dumps(pyproject_toml_data))\n\n    original_dir = os.getcwd()\n    try:\n        os.chdir(tmp_path)\n        settings = KubernetesSettings()\n    finally:\n        os.chdir(original_dir)\n\n    assert settings.worker.api_key_secret_name == \"test-secret\"\n    assert settings.worker.create_secret_for_api_key is True\n    assert settings.worker.add_tcp_keepalive is False\n    assert settings.cluster_uid == \"test-cluster-uid\"",
    "repo": "PrefectHQ/prefect",
    "path": "./datasets/diagrams-repos/PrefectHQ/prefect/src/integrations/prefect-kubernetes/tests/test_settings.py",
    "query": "What is the structure of the pyproject.toml file used by KubernetesSettings?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'KubernetesSettings', 'node_id': 'KubernetesSettings', 'description': 'Class for managing Kubernetes configuration settings', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'pyprojectToml', 'node_id': 'pyprojectToml', 'description': 'Configuration file structure for Kubernetes settings', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'KubernetesSettings', 'node_id_to': 'pyprojectToml', 'description': 'reads configuration from'}], 'packages': []}",
    "version": "minimal",
    "text_answer": "The pyproject.toml file for KubernetesSettings uses a nested structure starting with [tool.prefect.integrations.kubernetes] section, containing cluster_uid and worker subsection with api_key_secret_name, create_secret_for_api_key, and add_tcp_keepalive settings.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Python",
    "code": "\nimport os\n\nimport toml\nfrom prefect_kubernetes.settings import KubernetesSettings\n\n\ndef test_set_values_via_environment_variables(monkeypatch):\n    monkeypatch.setenv(\n        \"PREFECT_INTEGRATIONS_KUBERNETES_WORKER_API_KEY_SECRET_NAME\", \"test-secret\"\n    )\n    monkeypatch.setenv(\n        \"PREFECT_INTEGRATIONS_KUBERNETES_WORKER_CREATE_SECRET_FOR_API_KEY\", \"true\"\n    )\n    monkeypatch.setenv(\n        \"PREFECT_INTEGRATIONS_KUBERNETES_WORKER_ADD_TCP_KEEPALIVE\", \"false\"\n    )\n    monkeypatch.setenv(\n        \"PREFECT_INTEGRATIONS_KUBERNETES_CLUSTER_UID\", \"test-cluster-uid\"\n    )\n\n    settings = KubernetesSettings()\n\n    assert settings.worker.api_key_secret_name == \"test-secret\"\n    assert settings.worker.create_secret_for_api_key is True\n    assert settings.worker.add_tcp_keepalive is False\n    assert settings.cluster_uid == \"test-cluster-uid\"\n\n\ndef test_set_values_via_dot_env_file(tmp_path):\n    dot_env_path = tmp_path / \".env\"\n    with open(dot_env_path, \"w\") as f:\n        f.write(\n            \"PREFECT_INTEGRATIONS_KUBERNETES_WORKER_API_KEY_SECRET_NAME=test-secret\\n\"\n            \"PREFECT_INTEGRATIONS_KUBERNETES_WORKER_CREATE_SECRET_FOR_API_KEY=true\\n\"\n            \"PREFECT_INTEGRATIONS_KUBERNETES_WORKER_ADD_TCP_KEEPALIVE=false\\n\"\n            \"PREFECT_INTEGRATIONS_KUBERNETES_CLUSTER_UID=test-cluster-uid\\n\"\n        )\n\n    original_dir = os.getcwd()\n    try:\n        os.chdir(tmp_path)\n        settings = KubernetesSettings()\n    finally:\n        os.chdir(original_dir)\n\n    assert settings.worker.api_key_secret_name == \"test-secret\"\n    assert settings.worker.create_secret_for_api_key is True\n    assert settings.worker.add_tcp_keepalive is False\n    assert settings.cluster_uid == \"test-cluster-uid\"\n\n\ndef test_set_values_via_prefect_toml_file(tmp_path):\n    toml_path = tmp_path / \"prefect.toml\"\n    toml_data = {\n        \"integrations\": {\n            \"kubernetes\": {\n                \"worker\": {\n                    \"api_key_secret_name\": \"test-secret\",\n                    \"create_secret_for_api_key\": True,\n                    \"add_tcp_keepalive\": False,\n                },\n                \"cluster_uid\": \"test-cluster-uid\",\n            },\n        },\n    }\n    toml_path.write_text(toml.dumps(toml_data))\n\n    original_dir = os.getcwd()\n    try:\n        os.chdir(tmp_path)\n        settings = KubernetesSettings()\n    finally:\n        os.chdir(original_dir)\n\n    assert settings.worker.api_key_secret_name == \"test-secret\"\n    assert settings.worker.create_secret_for_api_key is True\n    assert settings.worker.add_tcp_keepalive is False\n    assert settings.cluster_uid == \"test-cluster-uid\"\n\n\ndef test_set_values_via_pyproject_toml_file(tmp_path):\n    pyproject_toml_path = tmp_path / \"pyproject.toml\"\n    pyproject_toml_data = {\n        \"tool\": {\n            \"prefect\": {\n                \"integrations\": {\n                    \"kubernetes\": {\n                        \"cluster_uid\": \"test-cluster-uid\",\n                        \"worker\": {\n                            \"api_key_secret_name\": \"test-secret\",\n                            \"create_secret_for_api_key\": True,\n                            \"add_tcp_keepalive\": False,\n                        },\n                    },\n                },\n            },\n        },\n    }\n    pyproject_toml_path.write_text(toml.dumps(pyproject_toml_data))\n\n    original_dir = os.getcwd()\n    try:\n        os.chdir(tmp_path)\n        settings = KubernetesSettings()\n    finally:\n        os.chdir(original_dir)\n\n    assert settings.worker.api_key_secret_name == \"test-secret\"\n    assert settings.worker.create_secret_for_api_key is True\n    assert settings.worker.add_tcp_keepalive is False\n    assert settings.cluster_uid == \"test-cluster-uid\"",
    "repo": "PrefectHQ/prefect",
    "path": "./datasets/diagrams-repos/PrefectHQ/prefect/src/integrations/prefect-kubernetes/tests/test_settings.py",
    "query": "What is the structure of the pyproject.toml file used by KubernetesSettings?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'KubernetesSettings', 'node_id': 'KubernetesSettings', 'description': 'Class for managing Kubernetes configuration settings', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'pyprojectToml', 'node_id': 'pyprojectToml', 'description': 'Configuration file structure for Kubernetes settings', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'toolSection', 'node_id': 'toolSection', 'description': 'Top-level tool section in pyproject.toml', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'prefectSection', 'node_id': 'prefectSection', 'description': 'Prefect-specific configuration section', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'integrationsSection', 'node_id': 'integrationsSection', 'description': 'Integration settings section', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'KubernetesSettings', 'node_id_to': 'pyprojectToml', 'description': 'reads configuration from'}, {'node_id_from': 'pyprojectToml', 'node_id_to': 'toolSection', 'description': 'contains'}, {'node_id_from': 'toolSection', 'node_id_to': 'prefectSection', 'description': 'contains'}, {'node_id_from': 'prefectSection', 'node_id_to': 'integrationsSection', 'description': 'contains'}], 'packages': [{'package_id': 'tomlStructure', 'children': ['pyprojectToml', 'toolSection', 'prefectSection', 'integrationsSection'], 'description': 'TOML configuration hierarchy'}]}",
    "version": "medium",
    "text_answer": "The pyproject.toml file for KubernetesSettings uses a nested structure starting with [tool.prefect.integrations.kubernetes] section, containing cluster_uid and worker subsection with api_key_secret_name, create_secret_for_api_key, and add_tcp_keepalive settings.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Python",
    "code": "\nimport os\n\nimport toml\nfrom prefect_kubernetes.settings import KubernetesSettings\n\n\ndef test_set_values_via_environment_variables(monkeypatch):\n    monkeypatch.setenv(\n        \"PREFECT_INTEGRATIONS_KUBERNETES_WORKER_API_KEY_SECRET_NAME\", \"test-secret\"\n    )\n    monkeypatch.setenv(\n        \"PREFECT_INTEGRATIONS_KUBERNETES_WORKER_CREATE_SECRET_FOR_API_KEY\", \"true\"\n    )\n    monkeypatch.setenv(\n        \"PREFECT_INTEGRATIONS_KUBERNETES_WORKER_ADD_TCP_KEEPALIVE\", \"false\"\n    )\n    monkeypatch.setenv(\n        \"PREFECT_INTEGRATIONS_KUBERNETES_CLUSTER_UID\", \"test-cluster-uid\"\n    )\n\n    settings = KubernetesSettings()\n\n    assert settings.worker.api_key_secret_name == \"test-secret\"\n    assert settings.worker.create_secret_for_api_key is True\n    assert settings.worker.add_tcp_keepalive is False\n    assert settings.cluster_uid == \"test-cluster-uid\"\n\n\ndef test_set_values_via_dot_env_file(tmp_path):\n    dot_env_path = tmp_path / \".env\"\n    with open(dot_env_path, \"w\") as f:\n        f.write(\n            \"PREFECT_INTEGRATIONS_KUBERNETES_WORKER_API_KEY_SECRET_NAME=test-secret\\n\"\n            \"PREFECT_INTEGRATIONS_KUBERNETES_WORKER_CREATE_SECRET_FOR_API_KEY=true\\n\"\n            \"PREFECT_INTEGRATIONS_KUBERNETES_WORKER_ADD_TCP_KEEPALIVE=false\\n\"\n            \"PREFECT_INTEGRATIONS_KUBERNETES_CLUSTER_UID=test-cluster-uid\\n\"\n        )\n\n    original_dir = os.getcwd()\n    try:\n        os.chdir(tmp_path)\n        settings = KubernetesSettings()\n    finally:\n        os.chdir(original_dir)\n\n    assert settings.worker.api_key_secret_name == \"test-secret\"\n    assert settings.worker.create_secret_for_api_key is True\n    assert settings.worker.add_tcp_keepalive is False\n    assert settings.cluster_uid == \"test-cluster-uid\"\n\n\ndef test_set_values_via_prefect_toml_file(tmp_path):\n    toml_path = tmp_path / \"prefect.toml\"\n    toml_data = {\n        \"integrations\": {\n            \"kubernetes\": {\n                \"worker\": {\n                    \"api_key_secret_name\": \"test-secret\",\n                    \"create_secret_for_api_key\": True,\n                    \"add_tcp_keepalive\": False,\n                },\n                \"cluster_uid\": \"test-cluster-uid\",\n            },\n        },\n    }\n    toml_path.write_text(toml.dumps(toml_data))\n\n    original_dir = os.getcwd()\n    try:\n        os.chdir(tmp_path)\n        settings = KubernetesSettings()\n    finally:\n        os.chdir(original_dir)\n\n    assert settings.worker.api_key_secret_name == \"test-secret\"\n    assert settings.worker.create_secret_for_api_key is True\n    assert settings.worker.add_tcp_keepalive is False\n    assert settings.cluster_uid == \"test-cluster-uid\"\n\n\ndef test_set_values_via_pyproject_toml_file(tmp_path):\n    pyproject_toml_path = tmp_path / \"pyproject.toml\"\n    pyproject_toml_data = {\n        \"tool\": {\n            \"prefect\": {\n                \"integrations\": {\n                    \"kubernetes\": {\n                        \"cluster_uid\": \"test-cluster-uid\",\n                        \"worker\": {\n                            \"api_key_secret_name\": \"test-secret\",\n                            \"create_secret_for_api_key\": True,\n                            \"add_tcp_keepalive\": False,\n                        },\n                    },\n                },\n            },\n        },\n    }\n    pyproject_toml_path.write_text(toml.dumps(pyproject_toml_data))\n\n    original_dir = os.getcwd()\n    try:\n        os.chdir(tmp_path)\n        settings = KubernetesSettings()\n    finally:\n        os.chdir(original_dir)\n\n    assert settings.worker.api_key_secret_name == \"test-secret\"\n    assert settings.worker.create_secret_for_api_key is True\n    assert settings.worker.add_tcp_keepalive is False\n    assert settings.cluster_uid == \"test-cluster-uid\"",
    "repo": "PrefectHQ/prefect",
    "path": "./datasets/diagrams-repos/PrefectHQ/prefect/src/integrations/prefect-kubernetes/tests/test_settings.py",
    "query": "What is the structure of the pyproject.toml file used by KubernetesSettings?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'KubernetesSettings', 'node_id': 'KubernetesSettings', 'description': 'Class for managing Kubernetes configuration settings', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'pyprojectToml', 'node_id': 'pyprojectToml', 'description': 'Configuration file structure for Kubernetes settings', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'toolSection', 'node_id': 'toolSection', 'description': 'Top-level tool section in pyproject.toml', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'prefectSection', 'node_id': 'prefectSection', 'description': 'Prefect-specific configuration section', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'integrationsSection', 'node_id': 'integrationsSection', 'description': 'Integration settings section', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'kubernetesSection', 'node_id': 'kubernetesSection', 'description': 'Kubernetes-specific settings', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'workerSection', 'node_id': 'workerSection', 'description': 'Worker-specific configuration', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'api_key_secret_name', 'node_id': 'api_key_secret_name', 'description': 'Name of the secret for API key', 'visibility': 'public', 'return_type': 'str', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'create_secret_for_api_key', 'node_id': 'create_secret_for_api_key', 'description': 'Flag to create secret for API key', 'visibility': 'public', 'return_type': 'bool', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'add_tcp_keepalive', 'node_id': 'add_tcp_keepalive', 'description': 'TCP keepalive setting', 'visibility': 'public', 'return_type': 'bool', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'cluster_uid', 'node_id': 'cluster_uid', 'description': 'Kubernetes cluster unique identifier', 'visibility': 'public', 'return_type': 'str', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'KubernetesSettings', 'node_id_to': 'pyprojectToml', 'description': 'reads configuration from'}, {'node_id_from': 'pyprojectToml', 'node_id_to': 'toolSection', 'description': 'contains'}, {'node_id_from': 'toolSection', 'node_id_to': 'prefectSection', 'description': 'contains'}, {'node_id_from': 'prefectSection', 'node_id_to': 'integrationsSection', 'description': 'contains'}, {'node_id_from': 'integrationsSection', 'node_id_to': 'kubernetesSection', 'description': 'contains'}, {'node_id_from': 'kubernetesSection', 'node_id_to': 'workerSection', 'description': 'contains'}, {'node_id_from': 'workerSection', 'node_id_to': 'api_key_secret_name', 'description': 'configures'}, {'node_id_from': 'workerSection', 'node_id_to': 'create_secret_for_api_key', 'description': 'configures'}, {'node_id_from': 'workerSection', 'node_id_to': 'add_tcp_keepalive', 'description': 'configures'}, {'node_id_from': 'kubernetesSection', 'node_id_to': 'cluster_uid', 'description': 'configures'}], 'packages': [{'package_id': 'tomlStructure', 'children': ['pyprojectToml', 'toolSection', 'prefectSection', 'integrationsSection', 'kubernetesSection', 'workerSection'], 'description': 'TOML configuration hierarchy'}, {'package_id': 'workerSettings', 'children': ['api_key_secret_name', 'create_secret_for_api_key', 'add_tcp_keepalive'], 'description': 'Worker configuration settings'}]}",
    "version": "full",
    "text_answer": "The pyproject.toml file for KubernetesSettings uses a nested structure starting with [tool.prefect.integrations.kubernetes] section, containing cluster_uid and worker subsection with api_key_secret_name, create_secret_for_api_key, and add_tcp_keepalive settings.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Rust",
    "code": "\nuse std::{\n    collections::{HashMap, HashSet},\n    sync::Arc,\n};\n\nuse spin_factor_sqlite::{RuntimeConfig, SqliteFactor};\nuse spin_factors::{\n    anyhow::{self, bail, Context as _},\n    RuntimeFactors,\n};\nuse spin_factors_test::{toml, TestEnvironment};\nuse spin_world::{async_trait, v2::sqlite as v2};\nuse v2::HostConnection as _;\n\n#[derive(RuntimeFactors)]\nstruct TestFactors {\n    sqlite: SqliteFactor,\n}\n\n#[tokio::test]\nasync fn errors_when_non_configured_database_used() -> anyhow::Result<()> {\n    let factors = TestFactors {\n        sqlite: SqliteFactor::new(),\n    };\n    let env = TestEnvironment::new(factors).extend_manifest(toml! {\n        [component.test-component]\n        source = \"does-not-exist.wasm\"\n        sqlite_databases = [\"foo\"]\n    });\n    let Err(err) = env.build_instance_state().await else {\n        bail!(\"Expected build_instance_state to error but it did not\");\n    };\n\n    assert!(err\n        .to_string()\n        .contains(\"One or more components use SQLite databases which are not defined.\"));\n\n    Ok(())\n}\n\n#[tokio::test]\nasync fn errors_when_database_not_allowed() -> anyhow::Result<()> {\n    let factors = TestFactors {\n        sqlite: SqliteFactor::new(),\n    };\n    let env = TestEnvironment::new(factors).extend_manifest(toml! {\n        [component.test-component]\n        source = \"does-not-exist.wasm\"\n        sqlite_databases = []\n    });\n    let mut state = env\n        .build_instance_state()\n        .await\n        .context(\"build_instance_state failed\")?;\n\n    assert!(matches!(\n        state.sqlite.open(\"foo\".into()).await,\n        Err(spin_world::v2::sqlite::Error::AccessDenied)\n    ));\n\n    Ok(())\n}\n\n#[tokio::test]\nasync fn it_works_when_database_is_configured() -> anyhow::Result<()> {\n    let factors = TestFactors {\n        sqlite: SqliteFactor::new(),\n    };\n    let mut connection_creators = HashMap::new();\n    connection_creators.insert(\"foo\".to_owned(), Arc::new(MockConnectionCreator) as _);\n    let runtime_config = TestFactorsRuntimeConfig {\n        sqlite: Some(RuntimeConfig {\n            connection_creators,\n        }),\n    };\n    let env = TestEnvironment::new(factors)\n        .extend_manifest(toml! {\n            [component.test-component]\n            source = \"does-not-exist.wasm\"\n            sqlite_databases = [\"foo\"]\n        })\n        .runtime_config(runtime_config)?;\n\n    let mut state = env\n        .build_instance_state()\n        .await\n        .context(\"build_instance_state failed\")?;\n\n    assert_eq!(\n        state.sqlite.allowed_databases(),\n        &[\"foo\".into()].into_iter().collect::<HashSet<_>>()\n    );\n\n    assert!(state.sqlite.open(\"foo\".into()).await.is_ok());\n    Ok(())\n}\n\n/// A connection creator that returns a mock connection.\nstruct MockConnectionCreator;\n\n#[async_trait]\nimpl spin_factor_sqlite::ConnectionCreator for MockConnectionCreator {\n    async fn create_connection(\n        &self,\n        label: &str,\n    ) -> Result<Box<dyn spin_factor_sqlite::Connection + 'static>, v2::Error> {\n        let _ = label;\n        Ok(Box::new(MockConnection))\n    }\n}\n\n/// A mock connection that always errors.\nstruct MockConnection;\n\n#[async_trait]\nimpl spin_factor_sqlite::Connection for MockConnection {\n    async fn query(\n        &self,\n        query: &str,\n        parameters: Vec<v2::Value>,\n    ) -> Result<v2::QueryResult, v2::Error> {\n        let _ = (query, parameters);\n        Err(v2::Error::Io(\"Mock connection\".into()))\n    }\n\n    async fn execute_batch(&self, statements: &str) -> anyhow::Result<()> {\n        let _ = statements;\n        bail!(\"Mock connection\")\n    }\n}",
    "repo": "fermyon/spin",
    "path": "./datasets/diagrams-repos/fermyon/spin/crates/factor-sqlite/tests/factor_test.rs",
    "query": "How are the different modules and components organized in this code?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'TestFactors', 'node_id': 'TestFactors', 'description': 'Main struct for managing SQLite factors in tests', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MockConnectionCreator', 'node_id': 'MockConnectionCreator', 'description': 'Creates mock connections for testing', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MockConnection', 'node_id': 'MockConnection', 'description': 'Mock implementation of SQLite connection', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'TestFactors', 'node_id_to': 'MockConnectionCreator', 'description': 'uses'}, {'node_id_from': 'MockConnectionCreator', 'node_id_to': 'MockConnection', 'description': 'creates'}], 'packages': [{'package_id': 'testComponents', 'children': ['TestFactors', 'MockConnectionCreator', 'MockConnection'], 'description': 'Test implementation components'}]}",
    "version": "minimal",
    "text_answer": "The codebase is organized around SQLite testing functionality with TestFactors as the main component. It uses mock implementations (MockConnectionCreator and MockConnection) for testing, and includes three main test cases verifying database configuration and access. The code is structured using runtime configurations and SQLite factors for database interaction testing.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Rust",
    "code": "\nuse std::{\n    collections::{HashMap, HashSet},\n    sync::Arc,\n};\n\nuse spin_factor_sqlite::{RuntimeConfig, SqliteFactor};\nuse spin_factors::{\n    anyhow::{self, bail, Context as _},\n    RuntimeFactors,\n};\nuse spin_factors_test::{toml, TestEnvironment};\nuse spin_world::{async_trait, v2::sqlite as v2};\nuse v2::HostConnection as _;\n\n#[derive(RuntimeFactors)]\nstruct TestFactors {\n    sqlite: SqliteFactor,\n}\n\n#[tokio::test]\nasync fn errors_when_non_configured_database_used() -> anyhow::Result<()> {\n    let factors = TestFactors {\n        sqlite: SqliteFactor::new(),\n    };\n    let env = TestEnvironment::new(factors).extend_manifest(toml! {\n        [component.test-component]\n        source = \"does-not-exist.wasm\"\n        sqlite_databases = [\"foo\"]\n    });\n    let Err(err) = env.build_instance_state().await else {\n        bail!(\"Expected build_instance_state to error but it did not\");\n    };\n\n    assert!(err\n        .to_string()\n        .contains(\"One or more components use SQLite databases which are not defined.\"));\n\n    Ok(())\n}\n\n#[tokio::test]\nasync fn errors_when_database_not_allowed() -> anyhow::Result<()> {\n    let factors = TestFactors {\n        sqlite: SqliteFactor::new(),\n    };\n    let env = TestEnvironment::new(factors).extend_manifest(toml! {\n        [component.test-component]\n        source = \"does-not-exist.wasm\"\n        sqlite_databases = []\n    });\n    let mut state = env\n        .build_instance_state()\n        .await\n        .context(\"build_instance_state failed\")?;\n\n    assert!(matches!(\n        state.sqlite.open(\"foo\".into()).await,\n        Err(spin_world::v2::sqlite::Error::AccessDenied)\n    ));\n\n    Ok(())\n}\n\n#[tokio::test]\nasync fn it_works_when_database_is_configured() -> anyhow::Result<()> {\n    let factors = TestFactors {\n        sqlite: SqliteFactor::new(),\n    };\n    let mut connection_creators = HashMap::new();\n    connection_creators.insert(\"foo\".to_owned(), Arc::new(MockConnectionCreator) as _);\n    let runtime_config = TestFactorsRuntimeConfig {\n        sqlite: Some(RuntimeConfig {\n            connection_creators,\n        }),\n    };\n    let env = TestEnvironment::new(factors)\n        .extend_manifest(toml! {\n            [component.test-component]\n            source = \"does-not-exist.wasm\"\n            sqlite_databases = [\"foo\"]\n        })\n        .runtime_config(runtime_config)?;\n\n    let mut state = env\n        .build_instance_state()\n        .await\n        .context(\"build_instance_state failed\")?;\n\n    assert_eq!(\n        state.sqlite.allowed_databases(),\n        &[\"foo\".into()].into_iter().collect::<HashSet<_>>()\n    );\n\n    assert!(state.sqlite.open(\"foo\".into()).await.is_ok());\n    Ok(())\n}\n\n/// A connection creator that returns a mock connection.\nstruct MockConnectionCreator;\n\n#[async_trait]\nimpl spin_factor_sqlite::ConnectionCreator for MockConnectionCreator {\n    async fn create_connection(\n        &self,\n        label: &str,\n    ) -> Result<Box<dyn spin_factor_sqlite::Connection + 'static>, v2::Error> {\n        let _ = label;\n        Ok(Box::new(MockConnection))\n    }\n}\n\n/// A mock connection that always errors.\nstruct MockConnection;\n\n#[async_trait]\nimpl spin_factor_sqlite::Connection for MockConnection {\n    async fn query(\n        &self,\n        query: &str,\n        parameters: Vec<v2::Value>,\n    ) -> Result<v2::QueryResult, v2::Error> {\n        let _ = (query, parameters);\n        Err(v2::Error::Io(\"Mock connection\".into()))\n    }\n\n    async fn execute_batch(&self, statements: &str) -> anyhow::Result<()> {\n        let _ = statements;\n        bail!(\"Mock connection\")\n    }\n}",
    "repo": "fermyon/spin",
    "path": "./datasets/diagrams-repos/fermyon/spin/crates/factor-sqlite/tests/factor_test.rs",
    "query": "How are the different modules and components organized in this code?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'TestFactors', 'node_id': 'TestFactors', 'description': 'Main struct for managing SQLite factors in tests', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MockConnectionCreator', 'node_id': 'MockConnectionCreator', 'description': 'Creates mock connections for testing', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MockConnection', 'node_id': 'MockConnection', 'description': 'Mock implementation of SQLite connection', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'errors_when_non_configured_database_used', 'node_id': 'errors_when_non_configured_database_used', 'description': 'Test for database configuration errors', 'visibility': 'public', 'return_type': 'anyhow::Result<()>', 'params': '()', 'source_class_id': None}, {'type': 'function', 'name': 'errors_when_database_not_allowed', 'node_id': 'errors_when_database_not_allowed', 'description': 'Test for database access permission errors', 'visibility': 'public', 'return_type': 'anyhow::Result<()>', 'params': '()', 'source_class_id': None}, {'type': 'function', 'name': 'it_works_when_database_is_configured', 'node_id': 'it_works_when_database_is_configured', 'description': 'Test for successful database configuration', 'visibility': 'public', 'return_type': 'anyhow::Result<()>', 'params': '()', 'source_class_id': None}], 'edges': [{'node_id_from': 'TestFactors', 'node_id_to': 'MockConnectionCreator', 'description': 'uses'}, {'node_id_from': 'MockConnectionCreator', 'node_id_to': 'MockConnection', 'description': 'creates'}, {'node_id_from': 'errors_when_non_configured_database_used', 'node_id_to': 'TestFactors', 'description': 'tests'}, {'node_id_from': 'errors_when_database_not_allowed', 'node_id_to': 'TestFactors', 'description': 'tests'}, {'node_id_from': 'it_works_when_database_is_configured', 'node_id_to': 'TestFactors', 'description': 'tests'}], 'packages': [{'package_id': 'testComponents', 'children': ['TestFactors', 'MockConnectionCreator', 'MockConnection'], 'description': 'Test implementation components'}, {'package_id': 'testCases', 'children': ['errors_when_non_configured_database_used', 'errors_when_database_not_allowed', 'it_works_when_database_is_configured'], 'description': 'Test cases for SQLite functionality'}]}",
    "version": "medium",
    "text_answer": "The codebase is organized around SQLite testing functionality with TestFactors as the main component. It uses mock implementations (MockConnectionCreator and MockConnection) for testing, and includes three main test cases verifying database configuration and access. The code is structured using runtime configurations and SQLite factors for database interaction testing.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Rust",
    "code": "\nuse std::{\n    collections::{HashMap, HashSet},\n    sync::Arc,\n};\n\nuse spin_factor_sqlite::{RuntimeConfig, SqliteFactor};\nuse spin_factors::{\n    anyhow::{self, bail, Context as _},\n    RuntimeFactors,\n};\nuse spin_factors_test::{toml, TestEnvironment};\nuse spin_world::{async_trait, v2::sqlite as v2};\nuse v2::HostConnection as _;\n\n#[derive(RuntimeFactors)]\nstruct TestFactors {\n    sqlite: SqliteFactor,\n}\n\n#[tokio::test]\nasync fn errors_when_non_configured_database_used() -> anyhow::Result<()> {\n    let factors = TestFactors {\n        sqlite: SqliteFactor::new(),\n    };\n    let env = TestEnvironment::new(factors).extend_manifest(toml! {\n        [component.test-component]\n        source = \"does-not-exist.wasm\"\n        sqlite_databases = [\"foo\"]\n    });\n    let Err(err) = env.build_instance_state().await else {\n        bail!(\"Expected build_instance_state to error but it did not\");\n    };\n\n    assert!(err\n        .to_string()\n        .contains(\"One or more components use SQLite databases which are not defined.\"));\n\n    Ok(())\n}\n\n#[tokio::test]\nasync fn errors_when_database_not_allowed() -> anyhow::Result<()> {\n    let factors = TestFactors {\n        sqlite: SqliteFactor::new(),\n    };\n    let env = TestEnvironment::new(factors).extend_manifest(toml! {\n        [component.test-component]\n        source = \"does-not-exist.wasm\"\n        sqlite_databases = []\n    });\n    let mut state = env\n        .build_instance_state()\n        .await\n        .context(\"build_instance_state failed\")?;\n\n    assert!(matches!(\n        state.sqlite.open(\"foo\".into()).await,\n        Err(spin_world::v2::sqlite::Error::AccessDenied)\n    ));\n\n    Ok(())\n}\n\n#[tokio::test]\nasync fn it_works_when_database_is_configured() -> anyhow::Result<()> {\n    let factors = TestFactors {\n        sqlite: SqliteFactor::new(),\n    };\n    let mut connection_creators = HashMap::new();\n    connection_creators.insert(\"foo\".to_owned(), Arc::new(MockConnectionCreator) as _);\n    let runtime_config = TestFactorsRuntimeConfig {\n        sqlite: Some(RuntimeConfig {\n            connection_creators,\n        }),\n    };\n    let env = TestEnvironment::new(factors)\n        .extend_manifest(toml! {\n            [component.test-component]\n            source = \"does-not-exist.wasm\"\n            sqlite_databases = [\"foo\"]\n        })\n        .runtime_config(runtime_config)?;\n\n    let mut state = env\n        .build_instance_state()\n        .await\n        .context(\"build_instance_state failed\")?;\n\n    assert_eq!(\n        state.sqlite.allowed_databases(),\n        &[\"foo\".into()].into_iter().collect::<HashSet<_>>()\n    );\n\n    assert!(state.sqlite.open(\"foo\".into()).await.is_ok());\n    Ok(())\n}\n\n/// A connection creator that returns a mock connection.\nstruct MockConnectionCreator;\n\n#[async_trait]\nimpl spin_factor_sqlite::ConnectionCreator for MockConnectionCreator {\n    async fn create_connection(\n        &self,\n        label: &str,\n    ) -> Result<Box<dyn spin_factor_sqlite::Connection + 'static>, v2::Error> {\n        let _ = label;\n        Ok(Box::new(MockConnection))\n    }\n}\n\n/// A mock connection that always errors.\nstruct MockConnection;\n\n#[async_trait]\nimpl spin_factor_sqlite::Connection for MockConnection {\n    async fn query(\n        &self,\n        query: &str,\n        parameters: Vec<v2::Value>,\n    ) -> Result<v2::QueryResult, v2::Error> {\n        let _ = (query, parameters);\n        Err(v2::Error::Io(\"Mock connection\".into()))\n    }\n\n    async fn execute_batch(&self, statements: &str) -> anyhow::Result<()> {\n        let _ = statements;\n        bail!(\"Mock connection\")\n    }\n}",
    "repo": "fermyon/spin",
    "path": "./datasets/diagrams-repos/fermyon/spin/crates/factor-sqlite/tests/factor_test.rs",
    "query": "How are the different modules and components organized in this code?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'TestFactors', 'node_id': 'TestFactors', 'description': 'Main struct for managing SQLite factors in tests', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MockConnectionCreator', 'node_id': 'MockConnectionCreator', 'description': 'Creates mock connections for testing', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MockConnection', 'node_id': 'MockConnection', 'description': 'Mock implementation of SQLite connection', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'create_connection', 'node_id': 'create_connection', 'description': 'Creates a new mock connection', 'visibility': 'public', 'return_type': 'Result<Box<dyn Connection>, Error>', 'params': '(&self, label: &str)', 'source_class_id': 'MockConnectionCreator'}, {'type': 'method', 'name': 'query', 'node_id': 'query', 'description': 'Mock query implementation', 'visibility': 'public', 'return_type': 'Result<QueryResult, Error>', 'params': '(&self, query: &str, parameters: Vec<Value>)', 'source_class_id': 'MockConnection'}, {'type': 'method', 'name': 'execute_batch', 'node_id': 'execute_batch', 'description': 'Mock batch execution implementation', 'visibility': 'public', 'return_type': 'anyhow::Result<()>', 'params': '(&self, statements: &str)', 'source_class_id': 'MockConnection'}, {'type': 'function', 'name': 'errors_when_non_configured_database_used', 'node_id': 'errors_when_non_configured_database_used', 'description': 'Test for database configuration errors', 'visibility': 'public', 'return_type': 'anyhow::Result<()>', 'params': '()', 'source_class_id': None}, {'type': 'function', 'name': 'errors_when_database_not_allowed', 'node_id': 'errors_when_database_not_allowed', 'description': 'Test for database access permission errors', 'visibility': 'public', 'return_type': 'anyhow::Result<()>', 'params': '()', 'source_class_id': None}, {'type': 'function', 'name': 'it_works_when_database_is_configured', 'node_id': 'it_works_when_database_is_configured', 'description': 'Test for successful database configuration', 'visibility': 'public', 'return_type': 'anyhow::Result<()>', 'params': '()', 'source_class_id': None}, {'type': 'entity', 'name': 'RuntimeConfig', 'node_id': 'RuntimeConfig', 'description': 'Configuration for runtime components', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SqliteFactor', 'node_id': 'SqliteFactor', 'description': 'SQLite implementation factor', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'TestFactors', 'node_id_to': 'MockConnectionCreator', 'description': 'uses'}, {'node_id_from': 'MockConnectionCreator', 'node_id_to': 'MockConnection', 'description': 'creates'}, {'node_id_from': 'MockConnectionCreator', 'node_id_to': 'create_connection', 'description': 'implements'}, {'node_id_from': 'MockConnection', 'node_id_to': 'query', 'description': 'implements'}, {'node_id_from': 'MockConnection', 'node_id_to': 'execute_batch', 'description': 'implements'}, {'node_id_from': 'TestFactors', 'node_id_to': 'SqliteFactor', 'description': 'contains'}, {'node_id_from': 'TestFactors', 'node_id_to': 'RuntimeConfig', 'description': 'uses'}, {'node_id_from': 'errors_when_non_configured_database_used', 'node_id_to': 'TestFactors', 'description': 'tests'}, {'node_id_from': 'errors_when_database_not_allowed', 'node_id_to': 'TestFactors', 'description': 'tests'}, {'node_id_from': 'it_works_when_database_is_configured', 'node_id_to': 'TestFactors', 'description': 'tests'}], 'packages': [{'package_id': 'testComponents', 'children': ['TestFactors', 'MockConnectionCreator', 'MockConnection', 'mockImplementation'], 'description': 'Test implementation components'}, {'package_id': 'mockImplementation', 'children': ['create_connection', 'query', 'execute_batch'], 'description': 'Mock implementations of database operations'}, {'package_id': 'testCases', 'children': ['errors_when_non_configured_database_used', 'errors_when_database_not_allowed', 'it_works_when_database_is_configured'], 'description': 'Test cases for SQLite functionality'}, {'package_id': 'core', 'children': ['RuntimeConfig', 'SqliteFactor'], 'description': 'Core components and configurations'}]}",
    "version": "full",
    "text_answer": "The codebase is organized around SQLite testing functionality with TestFactors as the main component. It uses mock implementations (MockConnectionCreator and MockConnection) for testing, and includes three main test cases verifying database configuration and access. The code is structured using runtime configurations and SQLite factors for database interaction testing.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\n\"use strict\";\n\nconst DependenciesBlock = require(\"./DependenciesBlock\");\nconst makeSerializable = require(\"./util/makeSerializable\");\n\n/** @typedef {import(\"./ChunkGraph\")} ChunkGraph */\n/** @typedef {import(\"./ChunkGroup\")} ChunkGroup */\n/** @typedef {import(\"./ChunkGroup\").ChunkGroupOptions} ChunkGroupOptions */\n/** @typedef {import(\"./Dependency\").DependencyLocation} DependencyLocation */\n/** @typedef {import(\"./Dependency\").UpdateHashContext} UpdateHashContext */\n/** @typedef {import(\"./Entrypoint\").EntryOptions} EntryOptions */\n/** @typedef {import(\"./Module\")} Module */\n/** @typedef {import(\"./serialization/ObjectMiddleware\").ObjectDeserializerContext} ObjectDeserializerContext */\n/** @typedef {import(\"./serialization/ObjectMiddleware\").ObjectSerializerContext} ObjectSerializerContext */\n/** @typedef {import(\"./util/Hash\")} Hash */\n\nclass AsyncDependenciesBlock extends DependenciesBlock {\n\t/**\n\t * @param {(ChunkGroupOptions & { entryOptions?: EntryOptions }) | null} groupOptions options for the group\n\t * @param {(DependencyLocation | null)=} loc the line of code\n\t * @param {(string | null)=} request the request\n\t */\n\tconstructor(groupOptions, loc, request) {\n\t\tsuper();\n\t\tif (typeof groupOptions === \"string\") {\n\t\t\tgroupOptions = { name: groupOptions };\n\t\t} else if (!groupOptions) {\n\t\t\tgroupOptions = { name: undefined };\n\t\t}\n\t\tthis.groupOptions = groupOptions;\n\t\tthis.loc = loc;\n\t\tthis.request = request;\n\t\tthis._stringifiedGroupOptions = undefined;\n\t}\n\n\t/**\n\t * @returns {string | null | undefined} The name of the chunk\n\t */\n\tget chunkName() {\n\t\treturn this.groupOptions.name;\n\t}\n\n\t/**\n\t * @param {string | undefined} value The new chunk name\n\t * @returns {void}\n\t */\n\tset chunkName(value) {\n\t\tif (this.groupOptions.name !== value) {\n\t\t\tthis.groupOptions.name = value;\n\t\t\tthis._stringifiedGroupOptions = undefined;\n\t\t}\n\t}\n\n\t/**\n\t * @param {Hash} hash the hash used to track dependencies\n\t * @param {UpdateHashContext} context context\n\t * @returns {void}\n\t */\n\tupdateHash(hash, context) {\n\t\tconst { chunkGraph } = context;\n\t\tif (this._stringifiedGroupOptions === undefined) {\n\t\t\tthis._stringifiedGroupOptions = JSON.stringify(this.groupOptions);\n\t\t}\n\t\tconst chunkGroup = chunkGraph.getBlockChunkGroup(this);\n\t\thash.update(\n\t\t\t`${this._stringifiedGroupOptions}${chunkGroup ? chunkGroup.id : \"\"}`\n\t\t);\n\t\tsuper.updateHash(hash, context);\n\t}\n\n\t/**\n\t * @param {ObjectSerializerContext} context context\n\t */\n\tserialize(context) {\n\t\tconst { write } = context;\n\t\twrite(this.groupOptions);\n\t\twrite(this.loc);\n\t\twrite(this.request);\n\t\tsuper.serialize(context);\n\t}\n\n\t/**\n\t * @param {ObjectDeserializerContext} context context\n\t */\n\tdeserialize(context) {\n\t\tconst { read } = context;\n\t\tthis.groupOptions = read();\n\t\tthis.loc = read();\n\t\tthis.request = read();\n\t\tsuper.deserialize(context);\n\t}\n}\n\nmakeSerializable(AsyncDependenciesBlock, \"webpack/lib/AsyncDependenciesBlock\");\n\nObject.defineProperty(AsyncDependenciesBlock.prototype, \"module\", {\n\tget() {\n\t\tthrow new Error(\n\t\t\t\"module property was removed from AsyncDependenciesBlock (it's not needed)\"\n\t\t);\n\t},\n\tset() {\n\t\tthrow new Error(\n\t\t\t\"module property was removed from AsyncDependenciesBlock (it's not needed)\"\n\t\t);\n\t}\n});\n\nmodule.exports = AsyncDependenciesBlock;",
    "repo": "webpack/webpack",
    "path": "./datasets/diagrams-repos/webpack/webpack/lib/AsyncDependenciesBlock.js",
    "query": "What are the key dependencies and their relationships in the provided code?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'AsyncDependenciesBlock', 'node_id': 'AsyncDependenciesBlock', 'description': 'Main class for handling async dependencies, extends DependenciesBlock', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'DependenciesBlock', 'node_id': 'DependenciesBlock', 'description': 'Parent class for dependency blocks', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'AsyncDependenciesBlock', 'node_id_to': 'DependenciesBlock', 'description': 'extends'}], 'packages': [{'package_id': 'dependencyManagement', 'children': ['AsyncDependenciesBlock', 'DependenciesBlock'], 'description': 'Core dependency management components'}]}",
    "version": "minimal",
    "text_answer": "The code primarily revolves around AsyncDependenciesBlock which extends DependenciesBlock for managing async dependencies. It integrates with webpack's chunk system through ChunkGraph and ChunkGroup, and includes serialization capabilities via makeSerializable function.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\n\"use strict\";\n\nconst DependenciesBlock = require(\"./DependenciesBlock\");\nconst makeSerializable = require(\"./util/makeSerializable\");\n\n/** @typedef {import(\"./ChunkGraph\")} ChunkGraph */\n/** @typedef {import(\"./ChunkGroup\")} ChunkGroup */\n/** @typedef {import(\"./ChunkGroup\").ChunkGroupOptions} ChunkGroupOptions */\n/** @typedef {import(\"./Dependency\").DependencyLocation} DependencyLocation */\n/** @typedef {import(\"./Dependency\").UpdateHashContext} UpdateHashContext */\n/** @typedef {import(\"./Entrypoint\").EntryOptions} EntryOptions */\n/** @typedef {import(\"./Module\")} Module */\n/** @typedef {import(\"./serialization/ObjectMiddleware\").ObjectDeserializerContext} ObjectDeserializerContext */\n/** @typedef {import(\"./serialization/ObjectMiddleware\").ObjectSerializerContext} ObjectSerializerContext */\n/** @typedef {import(\"./util/Hash\")} Hash */\n\nclass AsyncDependenciesBlock extends DependenciesBlock {\n\t/**\n\t * @param {(ChunkGroupOptions & { entryOptions?: EntryOptions }) | null} groupOptions options for the group\n\t * @param {(DependencyLocation | null)=} loc the line of code\n\t * @param {(string | null)=} request the request\n\t */\n\tconstructor(groupOptions, loc, request) {\n\t\tsuper();\n\t\tif (typeof groupOptions === \"string\") {\n\t\t\tgroupOptions = { name: groupOptions };\n\t\t} else if (!groupOptions) {\n\t\t\tgroupOptions = { name: undefined };\n\t\t}\n\t\tthis.groupOptions = groupOptions;\n\t\tthis.loc = loc;\n\t\tthis.request = request;\n\t\tthis._stringifiedGroupOptions = undefined;\n\t}\n\n\t/**\n\t * @returns {string | null | undefined} The name of the chunk\n\t */\n\tget chunkName() {\n\t\treturn this.groupOptions.name;\n\t}\n\n\t/**\n\t * @param {string | undefined} value The new chunk name\n\t * @returns {void}\n\t */\n\tset chunkName(value) {\n\t\tif (this.groupOptions.name !== value) {\n\t\t\tthis.groupOptions.name = value;\n\t\t\tthis._stringifiedGroupOptions = undefined;\n\t\t}\n\t}\n\n\t/**\n\t * @param {Hash} hash the hash used to track dependencies\n\t * @param {UpdateHashContext} context context\n\t * @returns {void}\n\t */\n\tupdateHash(hash, context) {\n\t\tconst { chunkGraph } = context;\n\t\tif (this._stringifiedGroupOptions === undefined) {\n\t\t\tthis._stringifiedGroupOptions = JSON.stringify(this.groupOptions);\n\t\t}\n\t\tconst chunkGroup = chunkGraph.getBlockChunkGroup(this);\n\t\thash.update(\n\t\t\t`${this._stringifiedGroupOptions}${chunkGroup ? chunkGroup.id : \"\"}`\n\t\t);\n\t\tsuper.updateHash(hash, context);\n\t}\n\n\t/**\n\t * @param {ObjectSerializerContext} context context\n\t */\n\tserialize(context) {\n\t\tconst { write } = context;\n\t\twrite(this.groupOptions);\n\t\twrite(this.loc);\n\t\twrite(this.request);\n\t\tsuper.serialize(context);\n\t}\n\n\t/**\n\t * @param {ObjectDeserializerContext} context context\n\t */\n\tdeserialize(context) {\n\t\tconst { read } = context;\n\t\tthis.groupOptions = read();\n\t\tthis.loc = read();\n\t\tthis.request = read();\n\t\tsuper.deserialize(context);\n\t}\n}\n\nmakeSerializable(AsyncDependenciesBlock, \"webpack/lib/AsyncDependenciesBlock\");\n\nObject.defineProperty(AsyncDependenciesBlock.prototype, \"module\", {\n\tget() {\n\t\tthrow new Error(\n\t\t\t\"module property was removed from AsyncDependenciesBlock (it's not needed)\"\n\t\t);\n\t},\n\tset() {\n\t\tthrow new Error(\n\t\t\t\"module property was removed from AsyncDependenciesBlock (it's not needed)\"\n\t\t);\n\t}\n});\n\nmodule.exports = AsyncDependenciesBlock;",
    "repo": "webpack/webpack",
    "path": "./datasets/diagrams-repos/webpack/webpack/lib/AsyncDependenciesBlock.js",
    "query": "What are the key dependencies and their relationships in the provided code?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'AsyncDependenciesBlock', 'node_id': 'AsyncDependenciesBlock', 'description': 'Main class for handling async dependencies', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'DependenciesBlock', 'node_id': 'DependenciesBlock', 'description': 'Parent class for dependency blocks', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'updateHash', 'node_id': 'updateHash', 'description': 'Updates hash tracking dependencies', 'visibility': 'public', 'return_type': 'void', 'params': '(hash, context)', 'source_class_id': 'AsyncDependenciesBlock'}, {'type': 'method', 'name': 'serialize', 'node_id': 'serialize', 'description': 'Serializes block data', 'visibility': 'public', 'return_type': 'void', 'params': '(context)', 'source_class_id': 'AsyncDependenciesBlock'}, {'type': 'function', 'name': 'makeSerializable', 'node_id': 'makeSerializable', 'description': 'Makes class serializable', 'visibility': 'public', 'return_type': 'void', 'params': '(AsyncDependenciesBlock, path)', 'source_class_id': None}], 'edges': [{'node_id_from': 'AsyncDependenciesBlock', 'node_id_to': 'DependenciesBlock', 'description': 'extends'}, {'node_id_from': 'AsyncDependenciesBlock', 'node_id_to': 'updateHash', 'description': 'implements'}, {'node_id_from': 'AsyncDependenciesBlock', 'node_id_to': 'serialize', 'description': 'implements'}, {'node_id_from': 'makeSerializable', 'node_id_to': 'AsyncDependenciesBlock', 'description': 'enhances'}], 'packages': [{'package_id': 'dependencyManagement', 'children': ['AsyncDependenciesBlock', 'DependenciesBlock', 'updateHash', 'serialization'], 'description': 'Core dependency management components'}, {'package_id': 'serialization', 'children': ['makeSerializable', 'serialize'], 'description': 'Serialization-related functionality'}]}",
    "version": "medium",
    "text_answer": "The code primarily revolves around AsyncDependenciesBlock which extends DependenciesBlock for managing async dependencies. It integrates with webpack's chunk system through ChunkGraph and ChunkGroup, and includes serialization capabilities via makeSerializable function.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\n\"use strict\";\n\nconst DependenciesBlock = require(\"./DependenciesBlock\");\nconst makeSerializable = require(\"./util/makeSerializable\");\n\n/** @typedef {import(\"./ChunkGraph\")} ChunkGraph */\n/** @typedef {import(\"./ChunkGroup\")} ChunkGroup */\n/** @typedef {import(\"./ChunkGroup\").ChunkGroupOptions} ChunkGroupOptions */\n/** @typedef {import(\"./Dependency\").DependencyLocation} DependencyLocation */\n/** @typedef {import(\"./Dependency\").UpdateHashContext} UpdateHashContext */\n/** @typedef {import(\"./Entrypoint\").EntryOptions} EntryOptions */\n/** @typedef {import(\"./Module\")} Module */\n/** @typedef {import(\"./serialization/ObjectMiddleware\").ObjectDeserializerContext} ObjectDeserializerContext */\n/** @typedef {import(\"./serialization/ObjectMiddleware\").ObjectSerializerContext} ObjectSerializerContext */\n/** @typedef {import(\"./util/Hash\")} Hash */\n\nclass AsyncDependenciesBlock extends DependenciesBlock {\n\t/**\n\t * @param {(ChunkGroupOptions & { entryOptions?: EntryOptions }) | null} groupOptions options for the group\n\t * @param {(DependencyLocation | null)=} loc the line of code\n\t * @param {(string | null)=} request the request\n\t */\n\tconstructor(groupOptions, loc, request) {\n\t\tsuper();\n\t\tif (typeof groupOptions === \"string\") {\n\t\t\tgroupOptions = { name: groupOptions };\n\t\t} else if (!groupOptions) {\n\t\t\tgroupOptions = { name: undefined };\n\t\t}\n\t\tthis.groupOptions = groupOptions;\n\t\tthis.loc = loc;\n\t\tthis.request = request;\n\t\tthis._stringifiedGroupOptions = undefined;\n\t}\n\n\t/**\n\t * @returns {string | null | undefined} The name of the chunk\n\t */\n\tget chunkName() {\n\t\treturn this.groupOptions.name;\n\t}\n\n\t/**\n\t * @param {string | undefined} value The new chunk name\n\t * @returns {void}\n\t */\n\tset chunkName(value) {\n\t\tif (this.groupOptions.name !== value) {\n\t\t\tthis.groupOptions.name = value;\n\t\t\tthis._stringifiedGroupOptions = undefined;\n\t\t}\n\t}\n\n\t/**\n\t * @param {Hash} hash the hash used to track dependencies\n\t * @param {UpdateHashContext} context context\n\t * @returns {void}\n\t */\n\tupdateHash(hash, context) {\n\t\tconst { chunkGraph } = context;\n\t\tif (this._stringifiedGroupOptions === undefined) {\n\t\t\tthis._stringifiedGroupOptions = JSON.stringify(this.groupOptions);\n\t\t}\n\t\tconst chunkGroup = chunkGraph.getBlockChunkGroup(this);\n\t\thash.update(\n\t\t\t`${this._stringifiedGroupOptions}${chunkGroup ? chunkGroup.id : \"\"}`\n\t\t);\n\t\tsuper.updateHash(hash, context);\n\t}\n\n\t/**\n\t * @param {ObjectSerializerContext} context context\n\t */\n\tserialize(context) {\n\t\tconst { write } = context;\n\t\twrite(this.groupOptions);\n\t\twrite(this.loc);\n\t\twrite(this.request);\n\t\tsuper.serialize(context);\n\t}\n\n\t/**\n\t * @param {ObjectDeserializerContext} context context\n\t */\n\tdeserialize(context) {\n\t\tconst { read } = context;\n\t\tthis.groupOptions = read();\n\t\tthis.loc = read();\n\t\tthis.request = read();\n\t\tsuper.deserialize(context);\n\t}\n}\n\nmakeSerializable(AsyncDependenciesBlock, \"webpack/lib/AsyncDependenciesBlock\");\n\nObject.defineProperty(AsyncDependenciesBlock.prototype, \"module\", {\n\tget() {\n\t\tthrow new Error(\n\t\t\t\"module property was removed from AsyncDependenciesBlock (it's not needed)\"\n\t\t);\n\t},\n\tset() {\n\t\tthrow new Error(\n\t\t\t\"module property was removed from AsyncDependenciesBlock (it's not needed)\"\n\t\t);\n\t}\n});\n\nmodule.exports = AsyncDependenciesBlock;",
    "repo": "webpack/webpack",
    "path": "./datasets/diagrams-repos/webpack/webpack/lib/AsyncDependenciesBlock.js",
    "query": "What are the key dependencies and their relationships in the provided code?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'AsyncDependenciesBlock', 'node_id': 'AsyncDependenciesBlock', 'description': 'Main class for handling async dependencies', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'DependenciesBlock', 'node_id': 'DependenciesBlock', 'description': 'Parent class for dependency blocks', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'updateHash', 'node_id': 'updateHash', 'description': 'Updates hash tracking dependencies', 'visibility': 'public', 'return_type': 'void', 'params': '(hash, context)', 'source_class_id': 'AsyncDependenciesBlock'}, {'type': 'method', 'name': 'serialize', 'node_id': 'serialize', 'description': 'Serializes block data', 'visibility': 'public', 'return_type': 'void', 'params': '(context)', 'source_class_id': 'AsyncDependenciesBlock'}, {'type': 'method', 'name': 'deserialize', 'node_id': 'deserialize', 'description': 'Deserializes block data', 'visibility': 'public', 'return_type': 'void', 'params': '(context)', 'source_class_id': 'AsyncDependenciesBlock'}, {'type': 'field', 'name': 'groupOptions', 'node_id': 'groupOptions', 'description': 'Options for chunk group', 'visibility': 'private', 'return_type': 'object', 'params': None, 'source_class_id': 'AsyncDependenciesBlock'}, {'type': 'field', 'name': 'chunkName', 'node_id': 'chunkName', 'description': 'Name of the chunk', 'visibility': 'public', 'return_type': 'string', 'params': None, 'source_class_id': 'AsyncDependenciesBlock'}, {'type': 'function', 'name': 'makeSerializable', 'node_id': 'makeSerializable', 'description': 'Makes class serializable', 'visibility': 'public', 'return_type': 'void', 'params': '(AsyncDependenciesBlock, path)', 'source_class_id': None}, {'type': 'entity', 'name': 'ChunkGraph', 'node_id': 'ChunkGraph', 'description': 'Graph structure for chunks', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'ChunkGroup', 'node_id': 'ChunkGroup', 'description': 'Group of chunks', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'AsyncDependenciesBlock', 'node_id_to': 'DependenciesBlock', 'description': 'extends'}, {'node_id_from': 'AsyncDependenciesBlock', 'node_id_to': 'updateHash', 'description': 'implements'}, {'node_id_from': 'AsyncDependenciesBlock', 'node_id_to': 'serialize', 'description': 'implements'}, {'node_id_from': 'AsyncDependenciesBlock', 'node_id_to': 'deserialize', 'description': 'implements'}, {'node_id_from': 'AsyncDependenciesBlock', 'node_id_to': 'groupOptions', 'description': 'contains'}, {'node_id_from': 'AsyncDependenciesBlock', 'node_id_to': 'chunkName', 'description': 'contains'}, {'node_id_from': 'makeSerializable', 'node_id_to': 'AsyncDependenciesBlock', 'description': 'enhances'}, {'node_id_from': 'AsyncDependenciesBlock', 'node_id_to': 'ChunkGraph', 'description': 'uses'}, {'node_id_from': 'AsyncDependenciesBlock', 'node_id_to': 'ChunkGroup', 'description': 'uses'}], 'packages': [{'package_id': 'dependencyManagement', 'children': ['AsyncDependenciesBlock', 'DependenciesBlock', 'updateHash', 'groupOptions', 'chunkName', 'serialization'], 'description': 'Core dependency management components'}, {'package_id': 'serialization', 'children': ['makeSerializable', 'serialize', 'deserialize'], 'description': 'Serialization-related functionality'}, {'package_id': 'chunkManagement', 'children': ['ChunkGraph', 'ChunkGroup'], 'description': 'Chunk-related components'}]}",
    "version": "full",
    "text_answer": "The code primarily revolves around AsyncDependenciesBlock which extends DependenciesBlock for managing async dependencies. It integrates with webpack's chunk system through ChunkGraph and ChunkGroup, and includes serialization capabilities via makeSerializable function.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Python",
    "code": "\nfrom enum import Enum\n\nimport pytest\n\nfrom homeassistant.components import cover\nfrom homeassistant.components.cover import CoverState\nfrom homeassistant.const import ATTR_ENTITY_ID, CONF_PLATFORM, SERVICE_TOGGLE\nfrom homeassistant.core import HomeAssistant, ServiceResponse\nfrom homeassistant.helpers.entity import Entity\nfrom homeassistant.setup import async_setup_component\n\nfrom .common import MockCover\n\nfrom tests.common import (\n    MockEntityPlatform,\n    help_test_all,\n    setup_test_component_platform,\n)\n\n\nasync def test_services(\n    hass: HomeAssistant,\n    mock_cover_entities: list[MockCover],\n) -> None:\n    \"\"\"Test the provided services.\"\"\"\n    setup_test_component_platform(hass, cover.DOMAIN, mock_cover_entities)\n\n    assert await async_setup_component(\n        hass, cover.DOMAIN, {cover.DOMAIN: {CONF_PLATFORM: \"test\"}}\n    )\n    await hass.async_block_till_done()\n\n    # ent1 = cover without tilt and position\n    # ent2 = cover with position but no tilt\n    # ent3 = cover with simple tilt functions and no position\n    # ent4 = cover with all tilt functions but no position\n    # ent5 = cover with all functions\n    # ent6 = cover with only open/close, but also reports opening/closing\n    ent1, ent2, ent3, ent4, ent5, ent6 = mock_cover_entities\n\n    # Test init all covers should be open\n    assert is_open(hass, ent1)\n    assert is_open(hass, ent2)\n    assert is_open(hass, ent3)\n    assert is_open(hass, ent4)\n    assert is_open(hass, ent5)\n    assert is_open(hass, ent6)\n\n    # call basic toggle services\n    await call_service(hass, SERVICE_TOGGLE, ent1)\n    await call_service(hass, SERVICE_TOGGLE, ent2)\n    await call_service(hass, SERVICE_TOGGLE, ent3)\n    await call_service(hass, SERVICE_TOGGLE, ent4)\n    await call_service(hass, SERVICE_TOGGLE, ent5)\n    await call_service(hass, SERVICE_TOGGLE, ent6)\n\n    # entities should be either closed or closing, depending on if they report transitional states\n    assert is_closed(hass, ent1)\n    assert is_closing(hass, ent2)\n    assert is_closed(hass, ent3)\n    assert is_closed(hass, ent4)\n    assert is_closing(hass, ent5)\n    assert is_closing(hass, ent6)\n\n    # call basic toggle services and set different cover position states\n    await call_service(hass, SERVICE_TOGGLE, ent1)\n    set_cover_position(ent2, 0)\n    await call_service(hass, SERVICE_TOGGLE, ent2)\n    await call_service(hass, SERVICE_TOGGLE, ent3)\n    await call_service(hass, SERVICE_TOGGLE, ent4)\n    set_cover_position(ent5, 15)\n    await call_service(hass, SERVICE_TOGGLE, ent5)\n    await call_service(hass, SERVICE_TOGGLE, ent6)\n\n    # entities should be in correct state depending on the SUPPORT_STOP feature and cover position\n    assert is_open(hass, ent1)\n    assert is_closed(hass, ent2)\n    assert is_open(hass, ent3)\n    assert is_open(hass, ent4)\n    assert is_open(hass, ent5)\n    assert is_opening(hass, ent6)\n\n    # call basic toggle services\n    await call_service(hass, SERVICE_TOGGLE, ent1)\n    await call_service(hass, SERVICE_TOGGLE, ent2)\n    await call_service(hass, SERVICE_TOGGLE, ent3)\n    await call_service(hass, SERVICE_TOGGLE, ent4)\n    await call_service(hass, SERVICE_TOGGLE, ent5)\n    await call_service(hass, SERVICE_TOGGLE, ent6)\n\n    # entities should be in correct state depending on the SUPPORT_STOP feature and cover position\n    assert is_closed(hass, ent1)\n    assert is_opening(hass, ent2)\n    assert is_closed(hass, ent3)\n    assert is_closed(hass, ent4)\n    assert is_opening(hass, ent5)\n    assert is_closing(hass, ent6)\n\n    # Without STOP but still reports opening/closing has a 4th possible toggle state\n    set_state(ent6, CoverState.CLOSED)\n    await call_service(hass, SERVICE_TOGGLE, ent6)\n    assert is_opening(hass, ent6)\n\n    # After the unusual state transition: closing -> fully open, toggle should close\n    set_state(ent5, CoverState.OPEN)\n    await call_service(hass, SERVICE_TOGGLE, ent5)  # Start closing\n    assert is_closing(hass, ent5)\n    set_state(\n        ent5, CoverState.OPEN\n    )  # Unusual state transition from closing -> fully open\n    set_cover_position(ent5, 100)\n    await call_service(hass, SERVICE_TOGGLE, ent5)  # Should close, not open\n    assert is_closing(hass, ent5)\n\n\ndef call_service(hass: HomeAssistant, service: str, ent: Entity) -> ServiceResponse:\n    \"\"\"Call any service on entity.\"\"\"\n    return hass.services.async_call(\n        cover.DOMAIN, service, {ATTR_ENTITY_ID: ent.entity_id}, blocking=True\n    )\n\n\ndef set_cover_position(ent, position) -> None:\n    \"\"\"Set a position value to a cover.\"\"\"\n    ent._values[\"current_cover_position\"] = position\n\n\ndef set_state(ent, state) -> None:\n    \"\"\"Set the state of a cover.\"\"\"\n    ent._values[\"state\"] = state\n\n\ndef is_open(hass: HomeAssistant, ent: Entity) -> bool:\n    \"\"\"Return if the cover is closed based on the statemachine.\"\"\"\n    return hass.states.is_state(ent.entity_id, CoverState.OPEN)\n\n\ndef is_opening(hass: HomeAssistant, ent: Entity) -> bool:\n    \"\"\"Return if the cover is closed based on the statemachine.\"\"\"\n    return hass.states.is_state(ent.entity_id, CoverState.OPENING)\n\n\ndef is_closed(hass: HomeAssistant, ent: Entity) -> bool:\n    \"\"\"Return if the cover is closed based on the statemachine.\"\"\"\n    return hass.states.is_state(ent.entity_id, CoverState.CLOSED)\n\n\ndef is_closing(hass: HomeAssistant, ent: Entity) -> bool:\n    \"\"\"Return if the cover is closed based on the statemachine.\"\"\"\n    return hass.states.is_state(ent.entity_id, CoverState.CLOSING)\n\n\ndef _create_tuples(enum: type[Enum], constant_prefix: str) -> list[tuple[Enum, str]]:\n    return [(enum_field, constant_prefix) for enum_field in enum]\n\n\ndef test_all() -> None:\n    \"\"\"Test module.__all__ is correctly set.\"\"\"\n    help_test_all(cover)\n\n\ndef test_deprecated_supported_features_ints(\n    hass: HomeAssistant, caplog: pytest.LogCaptureFixture\n) -> None:\n    \"\"\"Test deprecated supported features ints.\"\"\"\n\n    class MockCoverEntity(cover.CoverEntity):\n        _attr_supported_features = 1\n\n    entity = MockCoverEntity()\n    entity.hass = hass\n    entity.platform = MockEntityPlatform(hass)\n    assert entity.supported_features is cover.CoverEntityFeature(1)\n    assert \"MockCoverEntity\" in caplog.text\n    assert \"is using deprecated supported features values\" in caplog.text\n    assert \"Instead it should use\" in caplog.text\n    assert \"CoverEntityFeature.OPEN\" in caplog.text\n    caplog.clear()\n    assert entity.supported_features is cover.CoverEntityFeature(1)\n    assert \"is using deprecated supported features values\" not in caplog.text",
    "repo": "home-assistant/core",
    "path": "./datasets/diagrams-repos/home-assistant/core/tests/components/cover/test_init.py",
    "query": "What is the hierarchy of the cover entities and their features as demonstrated in the test cases?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'MockCover', 'node_id': 'MockCover', 'description': 'Base mock cover entity for testing', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'CoverState', 'node_id': 'CoverState', 'description': 'Enum representing cover states (OPEN, CLOSED, OPENING, CLOSING)', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'CoverEntity', 'node_id': 'CoverEntity', 'description': 'Base class for cover entities', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'MockCover', 'node_id_to': 'CoverEntity', 'description': 'inherits'}, {'node_id_from': 'CoverEntity', 'node_id_to': 'CoverState', 'description': 'uses'}], 'packages': [{'package_id': 'coverEntities', 'children': ['MockCover', 'CoverEntity', 'CoverState'], 'description': 'Core cover components'}]}",
    "version": "minimal",
    "text_answer": "The test cases demonstrate a hierarchy where CoverEntity is the base class, extended by MockCover for testing. Six different cover types are tested, ranging from basic covers with just open/close functionality to fully featured covers with position and tilt capabilities. The covers can be in states of OPEN, CLOSED, OPENING, or CLOSING, with some covers supporting transitional states reporting.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Python",
    "code": "\nfrom enum import Enum\n\nimport pytest\n\nfrom homeassistant.components import cover\nfrom homeassistant.components.cover import CoverState\nfrom homeassistant.const import ATTR_ENTITY_ID, CONF_PLATFORM, SERVICE_TOGGLE\nfrom homeassistant.core import HomeAssistant, ServiceResponse\nfrom homeassistant.helpers.entity import Entity\nfrom homeassistant.setup import async_setup_component\n\nfrom .common import MockCover\n\nfrom tests.common import (\n    MockEntityPlatform,\n    help_test_all,\n    setup_test_component_platform,\n)\n\n\nasync def test_services(\n    hass: HomeAssistant,\n    mock_cover_entities: list[MockCover],\n) -> None:\n    \"\"\"Test the provided services.\"\"\"\n    setup_test_component_platform(hass, cover.DOMAIN, mock_cover_entities)\n\n    assert await async_setup_component(\n        hass, cover.DOMAIN, {cover.DOMAIN: {CONF_PLATFORM: \"test\"}}\n    )\n    await hass.async_block_till_done()\n\n    # ent1 = cover without tilt and position\n    # ent2 = cover with position but no tilt\n    # ent3 = cover with simple tilt functions and no position\n    # ent4 = cover with all tilt functions but no position\n    # ent5 = cover with all functions\n    # ent6 = cover with only open/close, but also reports opening/closing\n    ent1, ent2, ent3, ent4, ent5, ent6 = mock_cover_entities\n\n    # Test init all covers should be open\n    assert is_open(hass, ent1)\n    assert is_open(hass, ent2)\n    assert is_open(hass, ent3)\n    assert is_open(hass, ent4)\n    assert is_open(hass, ent5)\n    assert is_open(hass, ent6)\n\n    # call basic toggle services\n    await call_service(hass, SERVICE_TOGGLE, ent1)\n    await call_service(hass, SERVICE_TOGGLE, ent2)\n    await call_service(hass, SERVICE_TOGGLE, ent3)\n    await call_service(hass, SERVICE_TOGGLE, ent4)\n    await call_service(hass, SERVICE_TOGGLE, ent5)\n    await call_service(hass, SERVICE_TOGGLE, ent6)\n\n    # entities should be either closed or closing, depending on if they report transitional states\n    assert is_closed(hass, ent1)\n    assert is_closing(hass, ent2)\n    assert is_closed(hass, ent3)\n    assert is_closed(hass, ent4)\n    assert is_closing(hass, ent5)\n    assert is_closing(hass, ent6)\n\n    # call basic toggle services and set different cover position states\n    await call_service(hass, SERVICE_TOGGLE, ent1)\n    set_cover_position(ent2, 0)\n    await call_service(hass, SERVICE_TOGGLE, ent2)\n    await call_service(hass, SERVICE_TOGGLE, ent3)\n    await call_service(hass, SERVICE_TOGGLE, ent4)\n    set_cover_position(ent5, 15)\n    await call_service(hass, SERVICE_TOGGLE, ent5)\n    await call_service(hass, SERVICE_TOGGLE, ent6)\n\n    # entities should be in correct state depending on the SUPPORT_STOP feature and cover position\n    assert is_open(hass, ent1)\n    assert is_closed(hass, ent2)\n    assert is_open(hass, ent3)\n    assert is_open(hass, ent4)\n    assert is_open(hass, ent5)\n    assert is_opening(hass, ent6)\n\n    # call basic toggle services\n    await call_service(hass, SERVICE_TOGGLE, ent1)\n    await call_service(hass, SERVICE_TOGGLE, ent2)\n    await call_service(hass, SERVICE_TOGGLE, ent3)\n    await call_service(hass, SERVICE_TOGGLE, ent4)\n    await call_service(hass, SERVICE_TOGGLE, ent5)\n    await call_service(hass, SERVICE_TOGGLE, ent6)\n\n    # entities should be in correct state depending on the SUPPORT_STOP feature and cover position\n    assert is_closed(hass, ent1)\n    assert is_opening(hass, ent2)\n    assert is_closed(hass, ent3)\n    assert is_closed(hass, ent4)\n    assert is_opening(hass, ent5)\n    assert is_closing(hass, ent6)\n\n    # Without STOP but still reports opening/closing has a 4th possible toggle state\n    set_state(ent6, CoverState.CLOSED)\n    await call_service(hass, SERVICE_TOGGLE, ent6)\n    assert is_opening(hass, ent6)\n\n    # After the unusual state transition: closing -> fully open, toggle should close\n    set_state(ent5, CoverState.OPEN)\n    await call_service(hass, SERVICE_TOGGLE, ent5)  # Start closing\n    assert is_closing(hass, ent5)\n    set_state(\n        ent5, CoverState.OPEN\n    )  # Unusual state transition from closing -> fully open\n    set_cover_position(ent5, 100)\n    await call_service(hass, SERVICE_TOGGLE, ent5)  # Should close, not open\n    assert is_closing(hass, ent5)\n\n\ndef call_service(hass: HomeAssistant, service: str, ent: Entity) -> ServiceResponse:\n    \"\"\"Call any service on entity.\"\"\"\n    return hass.services.async_call(\n        cover.DOMAIN, service, {ATTR_ENTITY_ID: ent.entity_id}, blocking=True\n    )\n\n\ndef set_cover_position(ent, position) -> None:\n    \"\"\"Set a position value to a cover.\"\"\"\n    ent._values[\"current_cover_position\"] = position\n\n\ndef set_state(ent, state) -> None:\n    \"\"\"Set the state of a cover.\"\"\"\n    ent._values[\"state\"] = state\n\n\ndef is_open(hass: HomeAssistant, ent: Entity) -> bool:\n    \"\"\"Return if the cover is closed based on the statemachine.\"\"\"\n    return hass.states.is_state(ent.entity_id, CoverState.OPEN)\n\n\ndef is_opening(hass: HomeAssistant, ent: Entity) -> bool:\n    \"\"\"Return if the cover is closed based on the statemachine.\"\"\"\n    return hass.states.is_state(ent.entity_id, CoverState.OPENING)\n\n\ndef is_closed(hass: HomeAssistant, ent: Entity) -> bool:\n    \"\"\"Return if the cover is closed based on the statemachine.\"\"\"\n    return hass.states.is_state(ent.entity_id, CoverState.CLOSED)\n\n\ndef is_closing(hass: HomeAssistant, ent: Entity) -> bool:\n    \"\"\"Return if the cover is closed based on the statemachine.\"\"\"\n    return hass.states.is_state(ent.entity_id, CoverState.CLOSING)\n\n\ndef _create_tuples(enum: type[Enum], constant_prefix: str) -> list[tuple[Enum, str]]:\n    return [(enum_field, constant_prefix) for enum_field in enum]\n\n\ndef test_all() -> None:\n    \"\"\"Test module.__all__ is correctly set.\"\"\"\n    help_test_all(cover)\n\n\ndef test_deprecated_supported_features_ints(\n    hass: HomeAssistant, caplog: pytest.LogCaptureFixture\n) -> None:\n    \"\"\"Test deprecated supported features ints.\"\"\"\n\n    class MockCoverEntity(cover.CoverEntity):\n        _attr_supported_features = 1\n\n    entity = MockCoverEntity()\n    entity.hass = hass\n    entity.platform = MockEntityPlatform(hass)\n    assert entity.supported_features is cover.CoverEntityFeature(1)\n    assert \"MockCoverEntity\" in caplog.text\n    assert \"is using deprecated supported features values\" in caplog.text\n    assert \"Instead it should use\" in caplog.text\n    assert \"CoverEntityFeature.OPEN\" in caplog.text\n    caplog.clear()\n    assert entity.supported_features is cover.CoverEntityFeature(1)\n    assert \"is using deprecated supported features values\" not in caplog.text",
    "repo": "home-assistant/core",
    "path": "./datasets/diagrams-repos/home-assistant/core/tests/components/cover/test_init.py",
    "query": "What is the hierarchy of the cover entities and their features as demonstrated in the test cases?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'MockCover', 'node_id': 'MockCover', 'description': 'Base mock cover entity for testing with different feature combinations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'CoverState', 'node_id': 'CoverState', 'description': 'Enum representing cover states (OPEN, CLOSED, OPENING, CLOSING)', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'CoverEntity', 'node_id': 'CoverEntity', 'description': 'Base class for cover entities', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'BasicCover', 'node_id': 'BasicCover', 'description': 'Cover without tilt and position features', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'PositionCover', 'node_id': 'PositionCover', 'description': 'Cover with position but no tilt', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'TiltCover', 'node_id': 'TiltCover', 'description': 'Cover with tilt functions but no position', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'MockCover', 'node_id_to': 'CoverEntity', 'description': 'inherits'}, {'node_id_from': 'BasicCover', 'node_id_to': 'MockCover', 'description': 'implements'}, {'node_id_from': 'PositionCover', 'node_id_to': 'MockCover', 'description': 'implements'}, {'node_id_from': 'TiltCover', 'node_id_to': 'MockCover', 'description': 'implements'}, {'node_id_from': 'CoverEntity', 'node_id_to': 'CoverState', 'description': 'uses'}], 'packages': [{'package_id': 'coverTypes', 'children': ['BasicCover', 'PositionCover', 'TiltCover'], 'description': 'Different types of covers tested'}, {'package_id': 'coverCore', 'children': ['MockCover', 'CoverEntity', 'CoverState'], 'description': 'Core cover components'}]}",
    "version": "medium",
    "text_answer": "The test cases demonstrate a hierarchy where CoverEntity is the base class, extended by MockCover for testing. Six different cover types are tested, ranging from basic covers with just open/close functionality to fully featured covers with position and tilt capabilities. The covers can be in states of OPEN, CLOSED, OPENING, or CLOSING, with some covers supporting transitional states reporting.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Python",
    "code": "\nfrom enum import Enum\n\nimport pytest\n\nfrom homeassistant.components import cover\nfrom homeassistant.components.cover import CoverState\nfrom homeassistant.const import ATTR_ENTITY_ID, CONF_PLATFORM, SERVICE_TOGGLE\nfrom homeassistant.core import HomeAssistant, ServiceResponse\nfrom homeassistant.helpers.entity import Entity\nfrom homeassistant.setup import async_setup_component\n\nfrom .common import MockCover\n\nfrom tests.common import (\n    MockEntityPlatform,\n    help_test_all,\n    setup_test_component_platform,\n)\n\n\nasync def test_services(\n    hass: HomeAssistant,\n    mock_cover_entities: list[MockCover],\n) -> None:\n    \"\"\"Test the provided services.\"\"\"\n    setup_test_component_platform(hass, cover.DOMAIN, mock_cover_entities)\n\n    assert await async_setup_component(\n        hass, cover.DOMAIN, {cover.DOMAIN: {CONF_PLATFORM: \"test\"}}\n    )\n    await hass.async_block_till_done()\n\n    # ent1 = cover without tilt and position\n    # ent2 = cover with position but no tilt\n    # ent3 = cover with simple tilt functions and no position\n    # ent4 = cover with all tilt functions but no position\n    # ent5 = cover with all functions\n    # ent6 = cover with only open/close, but also reports opening/closing\n    ent1, ent2, ent3, ent4, ent5, ent6 = mock_cover_entities\n\n    # Test init all covers should be open\n    assert is_open(hass, ent1)\n    assert is_open(hass, ent2)\n    assert is_open(hass, ent3)\n    assert is_open(hass, ent4)\n    assert is_open(hass, ent5)\n    assert is_open(hass, ent6)\n\n    # call basic toggle services\n    await call_service(hass, SERVICE_TOGGLE, ent1)\n    await call_service(hass, SERVICE_TOGGLE, ent2)\n    await call_service(hass, SERVICE_TOGGLE, ent3)\n    await call_service(hass, SERVICE_TOGGLE, ent4)\n    await call_service(hass, SERVICE_TOGGLE, ent5)\n    await call_service(hass, SERVICE_TOGGLE, ent6)\n\n    # entities should be either closed or closing, depending on if they report transitional states\n    assert is_closed(hass, ent1)\n    assert is_closing(hass, ent2)\n    assert is_closed(hass, ent3)\n    assert is_closed(hass, ent4)\n    assert is_closing(hass, ent5)\n    assert is_closing(hass, ent6)\n\n    # call basic toggle services and set different cover position states\n    await call_service(hass, SERVICE_TOGGLE, ent1)\n    set_cover_position(ent2, 0)\n    await call_service(hass, SERVICE_TOGGLE, ent2)\n    await call_service(hass, SERVICE_TOGGLE, ent3)\n    await call_service(hass, SERVICE_TOGGLE, ent4)\n    set_cover_position(ent5, 15)\n    await call_service(hass, SERVICE_TOGGLE, ent5)\n    await call_service(hass, SERVICE_TOGGLE, ent6)\n\n    # entities should be in correct state depending on the SUPPORT_STOP feature and cover position\n    assert is_open(hass, ent1)\n    assert is_closed(hass, ent2)\n    assert is_open(hass, ent3)\n    assert is_open(hass, ent4)\n    assert is_open(hass, ent5)\n    assert is_opening(hass, ent6)\n\n    # call basic toggle services\n    await call_service(hass, SERVICE_TOGGLE, ent1)\n    await call_service(hass, SERVICE_TOGGLE, ent2)\n    await call_service(hass, SERVICE_TOGGLE, ent3)\n    await call_service(hass, SERVICE_TOGGLE, ent4)\n    await call_service(hass, SERVICE_TOGGLE, ent5)\n    await call_service(hass, SERVICE_TOGGLE, ent6)\n\n    # entities should be in correct state depending on the SUPPORT_STOP feature and cover position\n    assert is_closed(hass, ent1)\n    assert is_opening(hass, ent2)\n    assert is_closed(hass, ent3)\n    assert is_closed(hass, ent4)\n    assert is_opening(hass, ent5)\n    assert is_closing(hass, ent6)\n\n    # Without STOP but still reports opening/closing has a 4th possible toggle state\n    set_state(ent6, CoverState.CLOSED)\n    await call_service(hass, SERVICE_TOGGLE, ent6)\n    assert is_opening(hass, ent6)\n\n    # After the unusual state transition: closing -> fully open, toggle should close\n    set_state(ent5, CoverState.OPEN)\n    await call_service(hass, SERVICE_TOGGLE, ent5)  # Start closing\n    assert is_closing(hass, ent5)\n    set_state(\n        ent5, CoverState.OPEN\n    )  # Unusual state transition from closing -> fully open\n    set_cover_position(ent5, 100)\n    await call_service(hass, SERVICE_TOGGLE, ent5)  # Should close, not open\n    assert is_closing(hass, ent5)\n\n\ndef call_service(hass: HomeAssistant, service: str, ent: Entity) -> ServiceResponse:\n    \"\"\"Call any service on entity.\"\"\"\n    return hass.services.async_call(\n        cover.DOMAIN, service, {ATTR_ENTITY_ID: ent.entity_id}, blocking=True\n    )\n\n\ndef set_cover_position(ent, position) -> None:\n    \"\"\"Set a position value to a cover.\"\"\"\n    ent._values[\"current_cover_position\"] = position\n\n\ndef set_state(ent, state) -> None:\n    \"\"\"Set the state of a cover.\"\"\"\n    ent._values[\"state\"] = state\n\n\ndef is_open(hass: HomeAssistant, ent: Entity) -> bool:\n    \"\"\"Return if the cover is closed based on the statemachine.\"\"\"\n    return hass.states.is_state(ent.entity_id, CoverState.OPEN)\n\n\ndef is_opening(hass: HomeAssistant, ent: Entity) -> bool:\n    \"\"\"Return if the cover is closed based on the statemachine.\"\"\"\n    return hass.states.is_state(ent.entity_id, CoverState.OPENING)\n\n\ndef is_closed(hass: HomeAssistant, ent: Entity) -> bool:\n    \"\"\"Return if the cover is closed based on the statemachine.\"\"\"\n    return hass.states.is_state(ent.entity_id, CoverState.CLOSED)\n\n\ndef is_closing(hass: HomeAssistant, ent: Entity) -> bool:\n    \"\"\"Return if the cover is closed based on the statemachine.\"\"\"\n    return hass.states.is_state(ent.entity_id, CoverState.CLOSING)\n\n\ndef _create_tuples(enum: type[Enum], constant_prefix: str) -> list[tuple[Enum, str]]:\n    return [(enum_field, constant_prefix) for enum_field in enum]\n\n\ndef test_all() -> None:\n    \"\"\"Test module.__all__ is correctly set.\"\"\"\n    help_test_all(cover)\n\n\ndef test_deprecated_supported_features_ints(\n    hass: HomeAssistant, caplog: pytest.LogCaptureFixture\n) -> None:\n    \"\"\"Test deprecated supported features ints.\"\"\"\n\n    class MockCoverEntity(cover.CoverEntity):\n        _attr_supported_features = 1\n\n    entity = MockCoverEntity()\n    entity.hass = hass\n    entity.platform = MockEntityPlatform(hass)\n    assert entity.supported_features is cover.CoverEntityFeature(1)\n    assert \"MockCoverEntity\" in caplog.text\n    assert \"is using deprecated supported features values\" in caplog.text\n    assert \"Instead it should use\" in caplog.text\n    assert \"CoverEntityFeature.OPEN\" in caplog.text\n    caplog.clear()\n    assert entity.supported_features is cover.CoverEntityFeature(1)\n    assert \"is using deprecated supported features values\" not in caplog.text",
    "repo": "home-assistant/core",
    "path": "./datasets/diagrams-repos/home-assistant/core/tests/components/cover/test_init.py",
    "query": "What is the hierarchy of the cover entities and their features as demonstrated in the test cases?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'MockCover', 'node_id': 'MockCover', 'description': 'Base mock cover entity for testing', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'CoverState', 'node_id': 'CoverState', 'description': 'Enum representing cover states', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'CoverEntity', 'node_id': 'CoverEntity', 'description': 'Base class for cover entities', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'BasicCover', 'node_id': 'BasicCover', 'description': 'Cover without tilt and position', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'PositionCover', 'node_id': 'PositionCover', 'description': 'Cover with position but no tilt', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SimpleTiltCover', 'node_id': 'SimpleTiltCover', 'description': 'Cover with simple tilt functions and no position', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'FullTiltCover', 'node_id': 'FullTiltCover', 'description': 'Cover with all tilt functions but no position', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'FullFeatureCover', 'node_id': 'FullFeatureCover', 'description': 'Cover with all functions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'TransitionalCover', 'node_id': 'TransitionalCover', 'description': 'Cover with only open/close but reports opening/closing states', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'MockCover', 'node_id_to': 'CoverEntity', 'description': 'inherits'}, {'node_id_from': 'BasicCover', 'node_id_to': 'MockCover', 'description': 'implements'}, {'node_id_from': 'PositionCover', 'node_id_to': 'MockCover', 'description': 'implements'}, {'node_id_from': 'SimpleTiltCover', 'node_id_to': 'MockCover', 'description': 'implements'}, {'node_id_from': 'FullTiltCover', 'node_id_to': 'MockCover', 'description': 'implements'}, {'node_id_from': 'FullFeatureCover', 'node_id_to': 'MockCover', 'description': 'implements'}, {'node_id_from': 'TransitionalCover', 'node_id_to': 'MockCover', 'description': 'implements'}, {'node_id_from': 'CoverEntity', 'node_id_to': 'CoverState', 'description': 'uses'}], 'packages': [{'package_id': 'coverFeatures', 'children': ['BasicCover', 'PositionCover', 'SimpleTiltCover', 'FullTiltCover', 'FullFeatureCover', 'TransitionalCover'], 'description': 'Different feature combinations of covers'}, {'package_id': 'coverCore', 'children': ['MockCover', 'CoverEntity', 'CoverState'], 'description': 'Core cover components and enums'}]}",
    "version": "full",
    "text_answer": "The test cases demonstrate a hierarchy where CoverEntity is the base class, extended by MockCover for testing. Six different cover types are tested, ranging from basic covers with just open/close functionality to fully featured covers with position and tilt capabilities. The covers can be in states of OPEN, CLOSED, OPENING, or CLOSING, with some covers supporting transitional states reporting.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C",
    "code": "\n#include \"lzfP.h\"\n\n#if AVOID_ERRNO\n# define SET_ERRNO(n)\n#else\n# include <errno.h>\n# define SET_ERRNO(n) errno = (n)\n#endif\n\n#if USE_REP_MOVSB /* small win on amd, big loss on intel */\n#if (__i386 || __amd64) && __GNUC__ >= 3\n# define lzf_movsb(dst, src, len)                \\\n   asm (\"rep movsb\"                              \\\n        : \"=D\" (dst), \"=S\" (src), \"=c\" (len)     \\\n        :  \"0\" (dst),  \"1\" (src),  \"2\" (len));\n#endif\n#endif\n\nunsigned int\nlzf_decompress (const void *const in_data,  unsigned int in_len,\n                void             *out_data, unsigned int out_len)\n{\n  u8 const *ip = (const u8 *)in_data;\n  u8       *op = (u8 *)out_data;\n  u8 const *const in_end  = ip + in_len;\n  u8       *const out_end = op + out_len;\n\n  do\n    {\n      unsigned int ctrl = *ip++;\n\n      if (ctrl < (1 << 5)) /* literal run */\n        {\n          ctrl++;\n\n          if (op + ctrl > out_end)\n            {\n              SET_ERRNO (E2BIG);\n              return 0;\n            }\n\n#if CHECK_INPUT\n          if (ip + ctrl > in_end)\n            {\n              SET_ERRNO (EINVAL);\n              return 0;\n            }\n#endif\n\n#ifdef lzf_movsb\n          lzf_movsb (op, ip, ctrl);\n#else\n          switch (ctrl)\n            {\n              case 32: *op++ = *ip++; case 31: *op++ = *ip++; case 30: *op++ = *ip++; case 29: *op++ = *ip++;\n              case 28: *op++ = *ip++; case 27: *op++ = *ip++; case 26: *op++ = *ip++; case 25: *op++ = *ip++;\n              case 24: *op++ = *ip++; case 23: *op++ = *ip++; case 22: *op++ = *ip++; case 21: *op++ = *ip++;\n              case 20: *op++ = *ip++; case 19: *op++ = *ip++; case 18: *op++ = *ip++; case 17: *op++ = *ip++;\n              case 16: *op++ = *ip++; case 15: *op++ = *ip++; case 14: *op++ = *ip++; case 13: *op++ = *ip++;\n              case 12: *op++ = *ip++; case 11: *op++ = *ip++; case 10: *op++ = *ip++; case  9: *op++ = *ip++;\n              case  8: *op++ = *ip++; case  7: *op++ = *ip++; case  6: *op++ = *ip++; case  5: *op++ = *ip++;\n              case  4: *op++ = *ip++; case  3: *op++ = *ip++; case  2: *op++ = *ip++; case  1: *op++ = *ip++;\n            }\n#endif\n        }\n      else /* back reference */\n        {\n          unsigned int len = ctrl >> 5;\n\n          u8 *ref = op - ((ctrl & 0x1f) << 8) - 1;\n\n#if CHECK_INPUT\n          if (ip >= in_end)\n            {\n              SET_ERRNO (EINVAL);\n              return 0;\n            }\n#endif\n          if (len == 7)\n            {\n              len += *ip++;\n#if CHECK_INPUT\n              if (ip >= in_end)\n                {\n                  SET_ERRNO (EINVAL);\n                  return 0;\n                }\n#endif\n            }\n\n          ref -= *ip++;\n\n          if (op + len + 2 > out_end)\n            {\n              SET_ERRNO (E2BIG);\n              return 0;\n            }\n\n          if (ref < (u8 *)out_data)\n            {\n              SET_ERRNO (EINVAL);\n              return 0;\n            }\n\n#ifdef lzf_movsb\n          len += 2;\n          lzf_movsb (op, ref, len);\n#else\n          switch (len)\n            {\n              default:\n                len += 2;\n\n                if (op >= ref + len)\n                  {\n                    /* disjunct areas */\n                    memcpy (op, ref, len);\n                    op += len;\n                  }\n                else\n                  {\n                    /* overlapping, use octte by octte copying */\n                    do\n                      *op++ = *ref++;\n                    while (--len);\n                  }\n\n                break;\n\n              case 9: *op++ = *ref++;\n              case 8: *op++ = *ref++;\n              case 7: *op++ = *ref++;\n              case 6: *op++ = *ref++;\n              case 5: *op++ = *ref++;\n              case 4: *op++ = *ref++;\n              case 3: *op++ = *ref++;\n              case 2: *op++ = *ref++;\n              case 1: *op++ = *ref++;\n              case 0: *op++ = *ref++; /* two octets more */\n                      *op++ = *ref++;\n            }\n#endif\n        }\n    }\n  while (ip < in_end);\n\n  return op - (u8 *)out_data;\n}",
    "repo": "CodisLabs/codis",
    "path": "./datasets/diagrams-repos/CodisLabs/codis/extern/deprecated/redis-3.2.8/src/lzf_d.c",
    "query": "What is the data flow between input and output buffers in the lzf_decompress function?",
    "diagram": "{'nodes': [{'type': 'variable', 'name': 'ip', 'node_id': 'ip', 'description': 'Input buffer pointer', 'visibility': 'private', 'return_type': 'u8 const *', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'op', 'node_id': 'op', 'description': 'Output buffer pointer', 'visibility': 'private', 'return_type': 'u8 *', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'ip', 'node_id_to': 'op', 'description': 'Copy data from input to output'}], 'packages': [{'package_id': 'lzf_decompress', 'children': ['ip', 'op'], 'description': 'Decompresses data from input buffer to output buffer'}]}",
    "version": "minimal",
    "text_answer": "The lzf_decompress function processes data from input to output buffer in two ways: direct literal copying for uncompressed data and back-reference copying for compressed sequences. Input pointer (ip) reads control bytes to determine the processing method, then either copies literal data directly to output pointer (op) or uses a reference pointer (ref) to copy previously decompressed data.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C",
    "code": "\n#include \"lzfP.h\"\n\n#if AVOID_ERRNO\n# define SET_ERRNO(n)\n#else\n# include <errno.h>\n# define SET_ERRNO(n) errno = (n)\n#endif\n\n#if USE_REP_MOVSB /* small win on amd, big loss on intel */\n#if (__i386 || __amd64) && __GNUC__ >= 3\n# define lzf_movsb(dst, src, len)                \\\n   asm (\"rep movsb\"                              \\\n        : \"=D\" (dst), \"=S\" (src), \"=c\" (len)     \\\n        :  \"0\" (dst),  \"1\" (src),  \"2\" (len));\n#endif\n#endif\n\nunsigned int\nlzf_decompress (const void *const in_data,  unsigned int in_len,\n                void             *out_data, unsigned int out_len)\n{\n  u8 const *ip = (const u8 *)in_data;\n  u8       *op = (u8 *)out_data;\n  u8 const *const in_end  = ip + in_len;\n  u8       *const out_end = op + out_len;\n\n  do\n    {\n      unsigned int ctrl = *ip++;\n\n      if (ctrl < (1 << 5)) /* literal run */\n        {\n          ctrl++;\n\n          if (op + ctrl > out_end)\n            {\n              SET_ERRNO (E2BIG);\n              return 0;\n            }\n\n#if CHECK_INPUT\n          if (ip + ctrl > in_end)\n            {\n              SET_ERRNO (EINVAL);\n              return 0;\n            }\n#endif\n\n#ifdef lzf_movsb\n          lzf_movsb (op, ip, ctrl);\n#else\n          switch (ctrl)\n            {\n              case 32: *op++ = *ip++; case 31: *op++ = *ip++; case 30: *op++ = *ip++; case 29: *op++ = *ip++;\n              case 28: *op++ = *ip++; case 27: *op++ = *ip++; case 26: *op++ = *ip++; case 25: *op++ = *ip++;\n              case 24: *op++ = *ip++; case 23: *op++ = *ip++; case 22: *op++ = *ip++; case 21: *op++ = *ip++;\n              case 20: *op++ = *ip++; case 19: *op++ = *ip++; case 18: *op++ = *ip++; case 17: *op++ = *ip++;\n              case 16: *op++ = *ip++; case 15: *op++ = *ip++; case 14: *op++ = *ip++; case 13: *op++ = *ip++;\n              case 12: *op++ = *ip++; case 11: *op++ = *ip++; case 10: *op++ = *ip++; case  9: *op++ = *ip++;\n              case  8: *op++ = *ip++; case  7: *op++ = *ip++; case  6: *op++ = *ip++; case  5: *op++ = *ip++;\n              case  4: *op++ = *ip++; case  3: *op++ = *ip++; case  2: *op++ = *ip++; case  1: *op++ = *ip++;\n            }\n#endif\n        }\n      else /* back reference */\n        {\n          unsigned int len = ctrl >> 5;\n\n          u8 *ref = op - ((ctrl & 0x1f) << 8) - 1;\n\n#if CHECK_INPUT\n          if (ip >= in_end)\n            {\n              SET_ERRNO (EINVAL);\n              return 0;\n            }\n#endif\n          if (len == 7)\n            {\n              len += *ip++;\n#if CHECK_INPUT\n              if (ip >= in_end)\n                {\n                  SET_ERRNO (EINVAL);\n                  return 0;\n                }\n#endif\n            }\n\n          ref -= *ip++;\n\n          if (op + len + 2 > out_end)\n            {\n              SET_ERRNO (E2BIG);\n              return 0;\n            }\n\n          if (ref < (u8 *)out_data)\n            {\n              SET_ERRNO (EINVAL);\n              return 0;\n            }\n\n#ifdef lzf_movsb\n          len += 2;\n          lzf_movsb (op, ref, len);\n#else\n          switch (len)\n            {\n              default:\n                len += 2;\n\n                if (op >= ref + len)\n                  {\n                    /* disjunct areas */\n                    memcpy (op, ref, len);\n                    op += len;\n                  }\n                else\n                  {\n                    /* overlapping, use octte by octte copying */\n                    do\n                      *op++ = *ref++;\n                    while (--len);\n                  }\n\n                break;\n\n              case 9: *op++ = *ref++;\n              case 8: *op++ = *ref++;\n              case 7: *op++ = *ref++;\n              case 6: *op++ = *ref++;\n              case 5: *op++ = *ref++;\n              case 4: *op++ = *ref++;\n              case 3: *op++ = *ref++;\n              case 2: *op++ = *ref++;\n              case 1: *op++ = *ref++;\n              case 0: *op++ = *ref++; /* two octets more */\n                      *op++ = *ref++;\n            }\n#endif\n        }\n    }\n  while (ip < in_end);\n\n  return op - (u8 *)out_data;\n}",
    "repo": "CodisLabs/codis",
    "path": "./datasets/diagrams-repos/CodisLabs/codis/extern/deprecated/redis-3.2.8/src/lzf_d.c",
    "query": "What is the data flow between input and output buffers in the lzf_decompress function?",
    "diagram": "{'nodes': [{'type': 'variable', 'name': 'ip', 'node_id': 'ip', 'description': 'Input buffer pointer', 'visibility': 'private', 'return_type': 'u8 const *', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'op', 'node_id': 'op', 'description': 'Output buffer pointer', 'visibility': 'private', 'return_type': 'u8 *', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'ref', 'node_id': 'ref', 'description': 'Reference pointer for back-references', 'visibility': 'private', 'return_type': 'u8 *', 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'literalRun', 'node_id': 'literalRun', 'description': 'Direct copy of literal bytes', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'backReference', 'node_id': 'backReference', 'description': 'Copy of previously decompressed data', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'ip', 'node_id_to': 'literalRun', 'description': 'Read literal data'}, {'node_id_from': 'literalRun', 'node_id_to': 'op', 'description': 'Write literal data'}, {'node_id_from': 'ref', 'node_id_to': 'backReference', 'description': 'Read previous data'}, {'node_id_from': 'backReference', 'node_id_to': 'op', 'description': 'Write referenced data'}], 'packages': [{'package_id': 'lzf_decompress', 'children': ['decompression', 'bufferManagement'], 'description': 'Decompresses data from input buffer to output buffer'}, {'package_id': 'decompression', 'children': ['literalRun', 'backReference'], 'description': 'Main decompression logic'}, {'package_id': 'bufferManagement', 'children': ['ip', 'op', 'ref'], 'description': 'Buffer pointer management'}]}",
    "version": "medium",
    "text_answer": "The lzf_decompress function processes data from input to output buffer in two ways: direct literal copying for uncompressed data and back-reference copying for compressed sequences. Input pointer (ip) reads control bytes to determine the processing method, then either copies literal data directly to output pointer (op) or uses a reference pointer (ref) to copy previously decompressed data.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C",
    "code": "\n#include \"lzfP.h\"\n\n#if AVOID_ERRNO\n# define SET_ERRNO(n)\n#else\n# include <errno.h>\n# define SET_ERRNO(n) errno = (n)\n#endif\n\n#if USE_REP_MOVSB /* small win on amd, big loss on intel */\n#if (__i386 || __amd64) && __GNUC__ >= 3\n# define lzf_movsb(dst, src, len)                \\\n   asm (\"rep movsb\"                              \\\n        : \"=D\" (dst), \"=S\" (src), \"=c\" (len)     \\\n        :  \"0\" (dst),  \"1\" (src),  \"2\" (len));\n#endif\n#endif\n\nunsigned int\nlzf_decompress (const void *const in_data,  unsigned int in_len,\n                void             *out_data, unsigned int out_len)\n{\n  u8 const *ip = (const u8 *)in_data;\n  u8       *op = (u8 *)out_data;\n  u8 const *const in_end  = ip + in_len;\n  u8       *const out_end = op + out_len;\n\n  do\n    {\n      unsigned int ctrl = *ip++;\n\n      if (ctrl < (1 << 5)) /* literal run */\n        {\n          ctrl++;\n\n          if (op + ctrl > out_end)\n            {\n              SET_ERRNO (E2BIG);\n              return 0;\n            }\n\n#if CHECK_INPUT\n          if (ip + ctrl > in_end)\n            {\n              SET_ERRNO (EINVAL);\n              return 0;\n            }\n#endif\n\n#ifdef lzf_movsb\n          lzf_movsb (op, ip, ctrl);\n#else\n          switch (ctrl)\n            {\n              case 32: *op++ = *ip++; case 31: *op++ = *ip++; case 30: *op++ = *ip++; case 29: *op++ = *ip++;\n              case 28: *op++ = *ip++; case 27: *op++ = *ip++; case 26: *op++ = *ip++; case 25: *op++ = *ip++;\n              case 24: *op++ = *ip++; case 23: *op++ = *ip++; case 22: *op++ = *ip++; case 21: *op++ = *ip++;\n              case 20: *op++ = *ip++; case 19: *op++ = *ip++; case 18: *op++ = *ip++; case 17: *op++ = *ip++;\n              case 16: *op++ = *ip++; case 15: *op++ = *ip++; case 14: *op++ = *ip++; case 13: *op++ = *ip++;\n              case 12: *op++ = *ip++; case 11: *op++ = *ip++; case 10: *op++ = *ip++; case  9: *op++ = *ip++;\n              case  8: *op++ = *ip++; case  7: *op++ = *ip++; case  6: *op++ = *ip++; case  5: *op++ = *ip++;\n              case  4: *op++ = *ip++; case  3: *op++ = *ip++; case  2: *op++ = *ip++; case  1: *op++ = *ip++;\n            }\n#endif\n        }\n      else /* back reference */\n        {\n          unsigned int len = ctrl >> 5;\n\n          u8 *ref = op - ((ctrl & 0x1f) << 8) - 1;\n\n#if CHECK_INPUT\n          if (ip >= in_end)\n            {\n              SET_ERRNO (EINVAL);\n              return 0;\n            }\n#endif\n          if (len == 7)\n            {\n              len += *ip++;\n#if CHECK_INPUT\n              if (ip >= in_end)\n                {\n                  SET_ERRNO (EINVAL);\n                  return 0;\n                }\n#endif\n            }\n\n          ref -= *ip++;\n\n          if (op + len + 2 > out_end)\n            {\n              SET_ERRNO (E2BIG);\n              return 0;\n            }\n\n          if (ref < (u8 *)out_data)\n            {\n              SET_ERRNO (EINVAL);\n              return 0;\n            }\n\n#ifdef lzf_movsb\n          len += 2;\n          lzf_movsb (op, ref, len);\n#else\n          switch (len)\n            {\n              default:\n                len += 2;\n\n                if (op >= ref + len)\n                  {\n                    /* disjunct areas */\n                    memcpy (op, ref, len);\n                    op += len;\n                  }\n                else\n                  {\n                    /* overlapping, use octte by octte copying */\n                    do\n                      *op++ = *ref++;\n                    while (--len);\n                  }\n\n                break;\n\n              case 9: *op++ = *ref++;\n              case 8: *op++ = *ref++;\n              case 7: *op++ = *ref++;\n              case 6: *op++ = *ref++;\n              case 5: *op++ = *ref++;\n              case 4: *op++ = *ref++;\n              case 3: *op++ = *ref++;\n              case 2: *op++ = *ref++;\n              case 1: *op++ = *ref++;\n              case 0: *op++ = *ref++; /* two octets more */\n                      *op++ = *ref++;\n            }\n#endif\n        }\n    }\n  while (ip < in_end);\n\n  return op - (u8 *)out_data;\n}",
    "repo": "CodisLabs/codis",
    "path": "./datasets/diagrams-repos/CodisLabs/codis/extern/deprecated/redis-3.2.8/src/lzf_d.c",
    "query": "What is the data flow between input and output buffers in the lzf_decompress function?",
    "diagram": "{'nodes': [{'type': 'variable', 'name': 'ip', 'node_id': 'ip', 'description': 'Input buffer pointer', 'visibility': 'private', 'return_type': 'u8 const *', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'op', 'node_id': 'op', 'description': 'Output buffer pointer', 'visibility': 'private', 'return_type': 'u8 *', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'in_end', 'node_id': 'in_end', 'description': 'Input buffer end pointer', 'visibility': 'private', 'return_type': 'u8 const *', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'out_end', 'node_id': 'out_end', 'description': 'Output buffer end pointer', 'visibility': 'private', 'return_type': 'u8 *', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'ref', 'node_id': 'ref', 'description': 'Reference pointer for back-references', 'visibility': 'private', 'return_type': 'u8 *', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'ctrl', 'node_id': 'ctrl', 'description': 'Control byte for compression type', 'visibility': 'private', 'return_type': 'unsigned int', 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'literalRun', 'node_id': 'literalRun', 'description': 'Direct copy of literal bytes', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'backReference', 'node_id': 'backReference', 'description': 'Copy of previously decompressed data', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'boundaryCheck', 'node_id': 'boundaryCheck', 'description': 'Buffer boundary validation', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'ip', 'node_id_to': 'ctrl', 'description': 'Read control byte'}, {'node_id_from': 'ctrl', 'node_id_to': 'literalRun', 'description': 'Process as literal if ctrl < 32'}, {'node_id_from': 'ctrl', 'node_id_to': 'backReference', 'description': 'Process as back-reference if ctrl >= 32'}, {'node_id_from': 'ip', 'node_id_to': 'literalRun', 'description': 'Read literal data'}, {'node_id_from': 'ip', 'node_id_to': 'in_end', 'description': 'uses'}, {'node_id_from': 'op', 'node_id_to': 'out_end', 'description': 'uses'}, {'node_id_from': 'literalRun', 'node_id_to': 'op', 'description': 'Write literal data'}, {'node_id_from': 'ref', 'node_id_to': 'backReference', 'description': 'Read previous data'}, {'node_id_from': 'backReference', 'node_id_to': 'op', 'description': 'Write referenced data'}, {'node_id_from': 'boundaryCheck', 'node_id_to': 'op', 'description': 'Validate output bounds'}, {'node_id_from': 'boundaryCheck', 'node_id_to': 'ip', 'description': 'Validate input bounds'}], 'packages': [{'package_id': 'lzf_decompress', 'children': ['decompression', 'bufferManagement'], 'description': 'Decompresses data from input buffer to output buffer'}, {'package_id': 'decompression', 'children': ['literalRun', 'backReference', 'ctrl'], 'description': 'Main decompression logic'}, {'package_id': 'bufferManagement', 'children': ['ip', 'op', 'ref', 'in_end', 'out_end', 'boundaryCheck'], 'description': 'Buffer pointer management'}]}",
    "version": "full",
    "text_answer": "The lzf_decompress function processes data from input to output buffer in two ways: direct literal copying for uncompressed data and back-reference copying for compressed sequences. Input pointer (ip) reads control bytes to determine the processing method, then either copies literal data directly to output pointer (op) or uses a reference pointer (ref) to copy previously decompressed data.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C",
    "code": "\n#include \"jemalloc/internal/jemalloc_preamble.h\"\n#include \"jemalloc/internal/jemalloc_internal_includes.h\"\n\n#include \"jemalloc/internal/ehooks.h\"\n#include \"jemalloc/internal/extent_mmap.h\"\n\nvoid\nehooks_init(ehooks_t *ehooks, extent_hooks_t *extent_hooks, unsigned ind) {\n\t/* All other hooks are optional; this one is not. */\n\tassert(extent_hooks->alloc != NULL);\n\tehooks->ind = ind;\n\tehooks_set_extent_hooks_ptr(ehooks, extent_hooks);\n}\n\n/*\n * If the caller specifies (!*zero), it is still possible to receive zeroed\n * memory, in which case *zero is toggled to true.  arena_extent_alloc() takes\n * advantage of this to avoid demanding zeroed extents, but taking advantage of\n * them if they are returned.\n */\nstatic void *\nextent_alloc_core(tsdn_t *tsdn, arena_t *arena, void *new_addr, size_t size,\n    size_t alignment, bool *zero, bool *commit, dss_prec_t dss_prec) {\n\tvoid *ret;\n\n\tassert(size != 0);\n\tassert(alignment != 0);\n\n\t/* \"primary\" dss. */\n\tif (have_dss && dss_prec == dss_prec_primary && (ret =\n\t    extent_alloc_dss(tsdn, arena, new_addr, size, alignment, zero,\n\t    commit)) != NULL) {\n\t\treturn ret;\n\t}\n\t/* mmap. */\n\tif ((ret = extent_alloc_mmap(new_addr, size, alignment, zero, commit))\n\t    != NULL) {\n\t\treturn ret;\n\t}\n\t/* \"secondary\" dss. */\n\tif (have_dss && dss_prec == dss_prec_secondary && (ret =\n\t    extent_alloc_dss(tsdn, arena, new_addr, size, alignment, zero,\n\t    commit)) != NULL) {\n\t\treturn ret;\n\t}\n\n\t/* All strategies for allocation failed. */\n\treturn NULL;\n}\n\nvoid *\nehooks_default_alloc_impl(tsdn_t *tsdn, void *new_addr, size_t size,\n    size_t alignment, bool *zero, bool *commit, unsigned arena_ind) {\n\tarena_t *arena = arena_get(tsdn, arena_ind, false);\n\t/* NULL arena indicates arena_create. */\n\tassert(arena != NULL || alignment == HUGEPAGE);\n\tdss_prec_t dss = (arena == NULL) ? dss_prec_disabled :\n\t    (dss_prec_t)atomic_load_u(&arena->dss_prec, ATOMIC_RELAXED);\n\tvoid *ret = extent_alloc_core(tsdn, arena, new_addr, size, alignment,\n\t    zero, commit, dss);\n\tif (have_madvise_huge && ret) {\n\t\tpages_set_thp_state(ret, size);\n\t}\n\treturn ret;\n}\n\nstatic void *\nehooks_default_alloc(extent_hooks_t *extent_hooks, void *new_addr, size_t size,\n    size_t alignment, bool *zero, bool *commit, unsigned arena_ind) {\n\treturn ehooks_default_alloc_impl(tsdn_fetch(), new_addr, size,\n\t    ALIGNMENT_CEILING(alignment, PAGE), zero, commit, arena_ind);\n}\n\nbool\nehooks_default_dalloc_impl(void *addr, size_t size) {\n\tif (!have_dss || !extent_in_dss(addr)) {\n\t\treturn extent_dalloc_mmap(addr, size);\n\t}\n\treturn true;\n}\n\nstatic bool\nehooks_default_dalloc(extent_hooks_t *extent_hooks, void *addr, size_t size,\n    bool committed, unsigned arena_ind) {\n\treturn ehooks_default_dalloc_impl(addr, size);\n}\n\nvoid\nehooks_default_destroy_impl(void *addr, size_t size) {\n\tif (!have_dss || !extent_in_dss(addr)) {\n\t\tpages_unmap(addr, size);\n\t}\n}\n\nstatic void\nehooks_default_destroy(extent_hooks_t *extent_hooks, void *addr, size_t size,\n    bool committed, unsigned arena_ind) {\n\tehooks_default_destroy_impl(addr, size);\n}\n\nbool\nehooks_default_commit_impl(void *addr, size_t offset, size_t length) {\n\treturn pages_commit((void *)((byte_t *)addr + (uintptr_t)offset),\n\t    length);\n}\n\nstatic bool\nehooks_default_commit(extent_hooks_t *extent_hooks, void *addr, size_t size,\n    size_t offset, size_t length, unsigned arena_ind) {\n\treturn ehooks_default_commit_impl(addr, offset, length);\n}\n\nbool\nehooks_default_decommit_impl(void *addr, size_t offset, size_t length) {\n\treturn pages_decommit((void *)((byte_t *)addr + (uintptr_t)offset),\n\t    length);\n}\n\nstatic bool\nehooks_default_decommit(extent_hooks_t *extent_hooks, void *addr, size_t size,\n    size_t offset, size_t length, unsigned arena_ind) {\n\treturn ehooks_default_decommit_impl(addr, offset, length);\n}\n\n#ifdef PAGES_CAN_PURGE_LAZY\nbool\nehooks_default_purge_lazy_impl(void *addr, size_t offset, size_t length) {\n\treturn pages_purge_lazy((void *)((byte_t *)addr + (uintptr_t)offset),\n\t    length);\n}\n\nstatic bool\nehooks_default_purge_lazy(extent_hooks_t *extent_hooks, void *addr, size_t size,\n    size_t offset, size_t length, unsigned arena_ind) {\n\tassert(addr != NULL);\n\tassert((offset & PAGE_MASK) == 0);\n\tassert(length != 0);\n\tassert((length & PAGE_MASK) == 0);\n\treturn ehooks_default_purge_lazy_impl(addr, offset, length);\n}\n#endif\n\n#ifdef PAGES_CAN_PURGE_FORCED\nbool\nehooks_default_purge_forced_impl(void *addr, size_t offset, size_t length) {\n\treturn pages_purge_forced((void *)((byte_t *)addr +\n\t    (uintptr_t)offset), length);\n}\n\nstatic bool\nehooks_default_purge_forced(extent_hooks_t *extent_hooks, void *addr,\n    size_t size, size_t offset, size_t length, unsigned arena_ind) {\n\tassert(addr != NULL);\n\tassert((offset & PAGE_MASK) == 0);\n\tassert(length != 0);\n\tassert((length & PAGE_MASK) == 0);\n\treturn ehooks_default_purge_forced_impl(addr, offset, length);\n}\n#endif\n\nbool\nehooks_default_split_impl(void) {\n\tif (!maps_coalesce) {\n\t\t/*\n\t\t * Without retain, only whole regions can be purged (required by\n\t\t * MEM_RELEASE on Windows) -- therefore disallow splitting.  See\n\t\t * comments in extent_head_no_merge().\n\t\t */\n\t\treturn !opt_retain;\n\t}\n\n\treturn false;\n}\n\nstatic bool\nehooks_default_split(extent_hooks_t *extent_hooks, void *addr, size_t size,\n    size_t size_a, size_t size_b, bool committed, unsigned arena_ind) {\n\treturn ehooks_default_split_impl();\n}\n\nbool\nehooks_default_merge_impl(tsdn_t *tsdn, void *addr_a, void *addr_b) {\n\tassert(addr_a < addr_b);\n\t/*\n\t * For non-DSS cases --\n\t * a) W/o maps_coalesce, merge is not always allowed (Windows):\n\t *   1) w/o retain, never merge (first branch below).\n\t *   2) with retain, only merge extents from the same VirtualAlloc\n\t *      region (in which case MEM_DECOMMIT is utilized for purging).\n\t *\n\t * b) With maps_coalesce, it's always possible to merge.\n\t *   1) w/o retain, always allow merge (only about dirty / muzzy).\n\t *   2) with retain, to preserve the SN / first-fit, merge is still\n\t *      disallowed if b is a head extent, i.e. no merging across\n\t *      different mmap regions.\n\t *\n\t * a2) and b2) are implemented in emap_try_acquire_edata_neighbor, and\n\t * sanity checked in the second branch below.\n\t */\n\tif (!maps_coalesce && !opt_retain) {\n\t\treturn true;\n\t}\n\tif (config_debug) {\n\t\tedata_t *a = emap_edata_lookup(tsdn, &arena_emap_global,\n\t\t    addr_a);\n\t\tbool head_a = edata_is_head_get(a);\n\t\tedata_t *b = emap_edata_lookup(tsdn, &arena_emap_global,\n\t\t    addr_b);\n\t\tbool head_b = edata_is_head_get(b);\n\t\temap_assert_mapped(tsdn, &arena_emap_global, a);\n\t\temap_assert_mapped(tsdn, &arena_emap_global, b);\n\t\tassert(extent_neighbor_head_state_mergeable(head_a, head_b,\n\t\t    /* forward */ true));\n\t}\n\tif (have_dss && !extent_dss_mergeable(addr_a, addr_b)) {\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nbool\nehooks_default_merge(extent_hooks_t *extent_hooks, void *addr_a, size_t size_a,\n    void *addr_b, size_t size_b, bool committed, unsigned arena_ind) {\n\ttsdn_t *tsdn = tsdn_fetch();\n\n\treturn ehooks_default_merge_impl(tsdn, addr_a, addr_b);\n}\n\nvoid\nehooks_default_zero_impl(void *addr, size_t size) {\n\t/*\n\t * By default, we try to zero out memory using OS-provided demand-zeroed\n\t * pages.  If the user has specifically requested hugepages, though, we\n\t * don't want to purge in the middle of a hugepage (which would break it\n\t * up), so we act conservatively and use memset.\n\t */\n\tbool needs_memset = true;\n\tif (opt_thp != thp_mode_always) {\n\t\tneeds_memset = pages_purge_forced(addr, size);\n\t}\n\tif (needs_memset) {\n\t\tmemset(addr, 0, size);\n\t}\n}\n\nvoid\nehooks_default_guard_impl(void *guard1, void *guard2) {\n\tpages_mark_guards(guard1, guard2);\n}\n\nvoid\nehooks_default_unguard_impl(void *guard1, void *guard2) {\n\tpages_unmark_guards(guard1, guard2);\n}\n\nconst extent_hooks_t ehooks_default_extent_hooks = {\n\tehooks_default_alloc,\n\tehooks_default_dalloc,\n\tehooks_default_destroy,\n\tehooks_default_commit,\n\tehooks_default_decommit,\n#ifdef PAGES_CAN_PURGE_LAZY\n\tehooks_default_purge_lazy,\n#else\n\tNULL,\n#endif\n#ifdef PAGES_CAN_PURGE_FORCED\n\tehooks_default_purge_forced,\n#else\n\tNULL,\n#endif\n\tehooks_default_split,\n\tehooks_default_merge\n};",
    "repo": "arangodb/arangodb",
    "path": "./datasets/diagrams-repos/arangodb/arangodb/3rdParty/jemalloc/jemalloc/src/ehooks.c",
    "query": "Can you illustrate the logic behind the merge and split operations?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'ehooks_default_split_impl', 'node_id': 'ehooks_default_split_impl', 'description': 'Core implementation of split operation, checks if splitting is allowed based on maps coalescing and retention settings', 'visibility': 'public', 'return_type': 'bool', 'params': 'void', 'source_class_id': None}, {'type': 'function', 'name': 'ehooks_default_merge_impl', 'node_id': 'ehooks_default_merge_impl', 'description': 'Core implementation of merge operation, determines if two memory regions can be merged based on various conditions', 'visibility': 'public', 'return_type': 'bool', 'params': 'tsdn_t *tsdn, void *addr_a, void *addr_b', 'source_class_id': None}, {'type': 'entity', 'name': 'Configuration', 'node_id': 'Configuration', 'description': 'Configuration of maps coalescing and retention settings', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'ehooks_default_split_impl', 'node_id_to': 'Configuration', 'description': 'uses'}, {'node_id_from': 'ehooks_default_merge_impl', 'node_id_to': 'Configuration', 'description': 'uses'}], 'packages': [{'package_id': 'memoryOperations', 'children': ['ehooks_default_split_impl', 'ehooks_default_merge_impl'], 'description': 'Core memory management operations for splitting and merging'}]}",
    "version": "minimal",
    "text_answer": "The merge and split operations are controlled by two main factors: maps coalescing and retention settings. Split operations are generally disallowed when maps don't coalesce and retention is disabled. Merge operations are more complex, considering memory region adjacency, DSS compatibility, and various system-specific constraints.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C",
    "code": "\n#include \"jemalloc/internal/jemalloc_preamble.h\"\n#include \"jemalloc/internal/jemalloc_internal_includes.h\"\n\n#include \"jemalloc/internal/ehooks.h\"\n#include \"jemalloc/internal/extent_mmap.h\"\n\nvoid\nehooks_init(ehooks_t *ehooks, extent_hooks_t *extent_hooks, unsigned ind) {\n\t/* All other hooks are optional; this one is not. */\n\tassert(extent_hooks->alloc != NULL);\n\tehooks->ind = ind;\n\tehooks_set_extent_hooks_ptr(ehooks, extent_hooks);\n}\n\n/*\n * If the caller specifies (!*zero), it is still possible to receive zeroed\n * memory, in which case *zero is toggled to true.  arena_extent_alloc() takes\n * advantage of this to avoid demanding zeroed extents, but taking advantage of\n * them if they are returned.\n */\nstatic void *\nextent_alloc_core(tsdn_t *tsdn, arena_t *arena, void *new_addr, size_t size,\n    size_t alignment, bool *zero, bool *commit, dss_prec_t dss_prec) {\n\tvoid *ret;\n\n\tassert(size != 0);\n\tassert(alignment != 0);\n\n\t/* \"primary\" dss. */\n\tif (have_dss && dss_prec == dss_prec_primary && (ret =\n\t    extent_alloc_dss(tsdn, arena, new_addr, size, alignment, zero,\n\t    commit)) != NULL) {\n\t\treturn ret;\n\t}\n\t/* mmap. */\n\tif ((ret = extent_alloc_mmap(new_addr, size, alignment, zero, commit))\n\t    != NULL) {\n\t\treturn ret;\n\t}\n\t/* \"secondary\" dss. */\n\tif (have_dss && dss_prec == dss_prec_secondary && (ret =\n\t    extent_alloc_dss(tsdn, arena, new_addr, size, alignment, zero,\n\t    commit)) != NULL) {\n\t\treturn ret;\n\t}\n\n\t/* All strategies for allocation failed. */\n\treturn NULL;\n}\n\nvoid *\nehooks_default_alloc_impl(tsdn_t *tsdn, void *new_addr, size_t size,\n    size_t alignment, bool *zero, bool *commit, unsigned arena_ind) {\n\tarena_t *arena = arena_get(tsdn, arena_ind, false);\n\t/* NULL arena indicates arena_create. */\n\tassert(arena != NULL || alignment == HUGEPAGE);\n\tdss_prec_t dss = (arena == NULL) ? dss_prec_disabled :\n\t    (dss_prec_t)atomic_load_u(&arena->dss_prec, ATOMIC_RELAXED);\n\tvoid *ret = extent_alloc_core(tsdn, arena, new_addr, size, alignment,\n\t    zero, commit, dss);\n\tif (have_madvise_huge && ret) {\n\t\tpages_set_thp_state(ret, size);\n\t}\n\treturn ret;\n}\n\nstatic void *\nehooks_default_alloc(extent_hooks_t *extent_hooks, void *new_addr, size_t size,\n    size_t alignment, bool *zero, bool *commit, unsigned arena_ind) {\n\treturn ehooks_default_alloc_impl(tsdn_fetch(), new_addr, size,\n\t    ALIGNMENT_CEILING(alignment, PAGE), zero, commit, arena_ind);\n}\n\nbool\nehooks_default_dalloc_impl(void *addr, size_t size) {\n\tif (!have_dss || !extent_in_dss(addr)) {\n\t\treturn extent_dalloc_mmap(addr, size);\n\t}\n\treturn true;\n}\n\nstatic bool\nehooks_default_dalloc(extent_hooks_t *extent_hooks, void *addr, size_t size,\n    bool committed, unsigned arena_ind) {\n\treturn ehooks_default_dalloc_impl(addr, size);\n}\n\nvoid\nehooks_default_destroy_impl(void *addr, size_t size) {\n\tif (!have_dss || !extent_in_dss(addr)) {\n\t\tpages_unmap(addr, size);\n\t}\n}\n\nstatic void\nehooks_default_destroy(extent_hooks_t *extent_hooks, void *addr, size_t size,\n    bool committed, unsigned arena_ind) {\n\tehooks_default_destroy_impl(addr, size);\n}\n\nbool\nehooks_default_commit_impl(void *addr, size_t offset, size_t length) {\n\treturn pages_commit((void *)((byte_t *)addr + (uintptr_t)offset),\n\t    length);\n}\n\nstatic bool\nehooks_default_commit(extent_hooks_t *extent_hooks, void *addr, size_t size,\n    size_t offset, size_t length, unsigned arena_ind) {\n\treturn ehooks_default_commit_impl(addr, offset, length);\n}\n\nbool\nehooks_default_decommit_impl(void *addr, size_t offset, size_t length) {\n\treturn pages_decommit((void *)((byte_t *)addr + (uintptr_t)offset),\n\t    length);\n}\n\nstatic bool\nehooks_default_decommit(extent_hooks_t *extent_hooks, void *addr, size_t size,\n    size_t offset, size_t length, unsigned arena_ind) {\n\treturn ehooks_default_decommit_impl(addr, offset, length);\n}\n\n#ifdef PAGES_CAN_PURGE_LAZY\nbool\nehooks_default_purge_lazy_impl(void *addr, size_t offset, size_t length) {\n\treturn pages_purge_lazy((void *)((byte_t *)addr + (uintptr_t)offset),\n\t    length);\n}\n\nstatic bool\nehooks_default_purge_lazy(extent_hooks_t *extent_hooks, void *addr, size_t size,\n    size_t offset, size_t length, unsigned arena_ind) {\n\tassert(addr != NULL);\n\tassert((offset & PAGE_MASK) == 0);\n\tassert(length != 0);\n\tassert((length & PAGE_MASK) == 0);\n\treturn ehooks_default_purge_lazy_impl(addr, offset, length);\n}\n#endif\n\n#ifdef PAGES_CAN_PURGE_FORCED\nbool\nehooks_default_purge_forced_impl(void *addr, size_t offset, size_t length) {\n\treturn pages_purge_forced((void *)((byte_t *)addr +\n\t    (uintptr_t)offset), length);\n}\n\nstatic bool\nehooks_default_purge_forced(extent_hooks_t *extent_hooks, void *addr,\n    size_t size, size_t offset, size_t length, unsigned arena_ind) {\n\tassert(addr != NULL);\n\tassert((offset & PAGE_MASK) == 0);\n\tassert(length != 0);\n\tassert((length & PAGE_MASK) == 0);\n\treturn ehooks_default_purge_forced_impl(addr, offset, length);\n}\n#endif\n\nbool\nehooks_default_split_impl(void) {\n\tif (!maps_coalesce) {\n\t\t/*\n\t\t * Without retain, only whole regions can be purged (required by\n\t\t * MEM_RELEASE on Windows) -- therefore disallow splitting.  See\n\t\t * comments in extent_head_no_merge().\n\t\t */\n\t\treturn !opt_retain;\n\t}\n\n\treturn false;\n}\n\nstatic bool\nehooks_default_split(extent_hooks_t *extent_hooks, void *addr, size_t size,\n    size_t size_a, size_t size_b, bool committed, unsigned arena_ind) {\n\treturn ehooks_default_split_impl();\n}\n\nbool\nehooks_default_merge_impl(tsdn_t *tsdn, void *addr_a, void *addr_b) {\n\tassert(addr_a < addr_b);\n\t/*\n\t * For non-DSS cases --\n\t * a) W/o maps_coalesce, merge is not always allowed (Windows):\n\t *   1) w/o retain, never merge (first branch below).\n\t *   2) with retain, only merge extents from the same VirtualAlloc\n\t *      region (in which case MEM_DECOMMIT is utilized for purging).\n\t *\n\t * b) With maps_coalesce, it's always possible to merge.\n\t *   1) w/o retain, always allow merge (only about dirty / muzzy).\n\t *   2) with retain, to preserve the SN / first-fit, merge is still\n\t *      disallowed if b is a head extent, i.e. no merging across\n\t *      different mmap regions.\n\t *\n\t * a2) and b2) are implemented in emap_try_acquire_edata_neighbor, and\n\t * sanity checked in the second branch below.\n\t */\n\tif (!maps_coalesce && !opt_retain) {\n\t\treturn true;\n\t}\n\tif (config_debug) {\n\t\tedata_t *a = emap_edata_lookup(tsdn, &arena_emap_global,\n\t\t    addr_a);\n\t\tbool head_a = edata_is_head_get(a);\n\t\tedata_t *b = emap_edata_lookup(tsdn, &arena_emap_global,\n\t\t    addr_b);\n\t\tbool head_b = edata_is_head_get(b);\n\t\temap_assert_mapped(tsdn, &arena_emap_global, a);\n\t\temap_assert_mapped(tsdn, &arena_emap_global, b);\n\t\tassert(extent_neighbor_head_state_mergeable(head_a, head_b,\n\t\t    /* forward */ true));\n\t}\n\tif (have_dss && !extent_dss_mergeable(addr_a, addr_b)) {\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nbool\nehooks_default_merge(extent_hooks_t *extent_hooks, void *addr_a, size_t size_a,\n    void *addr_b, size_t size_b, bool committed, unsigned arena_ind) {\n\ttsdn_t *tsdn = tsdn_fetch();\n\n\treturn ehooks_default_merge_impl(tsdn, addr_a, addr_b);\n}\n\nvoid\nehooks_default_zero_impl(void *addr, size_t size) {\n\t/*\n\t * By default, we try to zero out memory using OS-provided demand-zeroed\n\t * pages.  If the user has specifically requested hugepages, though, we\n\t * don't want to purge in the middle of a hugepage (which would break it\n\t * up), so we act conservatively and use memset.\n\t */\n\tbool needs_memset = true;\n\tif (opt_thp != thp_mode_always) {\n\t\tneeds_memset = pages_purge_forced(addr, size);\n\t}\n\tif (needs_memset) {\n\t\tmemset(addr, 0, size);\n\t}\n}\n\nvoid\nehooks_default_guard_impl(void *guard1, void *guard2) {\n\tpages_mark_guards(guard1, guard2);\n}\n\nvoid\nehooks_default_unguard_impl(void *guard1, void *guard2) {\n\tpages_unmark_guards(guard1, guard2);\n}\n\nconst extent_hooks_t ehooks_default_extent_hooks = {\n\tehooks_default_alloc,\n\tehooks_default_dalloc,\n\tehooks_default_destroy,\n\tehooks_default_commit,\n\tehooks_default_decommit,\n#ifdef PAGES_CAN_PURGE_LAZY\n\tehooks_default_purge_lazy,\n#else\n\tNULL,\n#endif\n#ifdef PAGES_CAN_PURGE_FORCED\n\tehooks_default_purge_forced,\n#else\n\tNULL,\n#endif\n\tehooks_default_split,\n\tehooks_default_merge\n};",
    "repo": "arangodb/arangodb",
    "path": "./datasets/diagrams-repos/arangodb/arangodb/3rdParty/jemalloc/jemalloc/src/ehooks.c",
    "query": "Can you illustrate the logic behind the merge and split operations?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'ehooks_default_split_impl', 'node_id': 'ehooks_default_split_impl', 'description': 'Core implementation of split operation, checks if splitting is allowed based on maps coalescing and retention settings', 'visibility': 'public', 'return_type': 'bool', 'params': 'void', 'source_class_id': None}, {'type': 'function', 'name': 'ehooks_default_merge_impl', 'node_id': 'ehooks_default_merge_impl', 'description': 'Core implementation of merge operation, determines if two memory regions can be merged based on various conditions', 'visibility': 'public', 'return_type': 'bool', 'params': 'tsdn_t *tsdn, void *addr_a, void *addr_b', 'source_class_id': None}, {'type': 'function', 'name': 'ehooks_default_split', 'node_id': 'ehooks_default_split', 'description': 'External interface for split operation', 'visibility': 'private', 'return_type': 'bool', 'params': 'extent_hooks_t *extent_hooks, void *addr, size_t size, size_t size_a, size_t size_b, bool committed, unsigned arena_ind', 'source_class_id': None}, {'type': 'function', 'name': 'ehooks_default_merge', 'node_id': 'ehooks_default_merge', 'description': 'External interface for merge operation', 'visibility': 'public', 'return_type': 'bool', 'params': 'extent_hooks_t *extent_hooks, void *addr_a, size_t size_a, void *addr_b, size_t size_b, bool committed, unsigned arena_ind', 'source_class_id': None}, {'type': 'entity', 'name': 'Configuration', 'node_id': 'Configuration', 'description': 'Configuration of maps coalescing and retention settings', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'ehooks_default_split', 'node_id_to': 'ehooks_default_split_impl', 'description': 'calls'}, {'node_id_from': 'ehooks_default_merge', 'node_id_to': 'ehooks_default_merge_impl', 'description': 'calls'}, {'node_id_from': 'ehooks_default_split_impl', 'node_id_to': 'Configuration', 'description': 'uses'}, {'node_id_from': 'ehooks_default_merge_impl', 'node_id_to': 'Configuration', 'description': 'uses'}], 'packages': [{'package_id': 'memoryOperations', 'children': ['ehooks_default_split_impl', 'ehooks_default_merge_impl', 'ehooks_default_split', 'ehooks_default_merge'], 'description': 'Memory management operations for splitting and merging'}]}",
    "version": "medium",
    "text_answer": "The merge and split operations are controlled by two main factors: maps coalescing and retention settings. Split operations are generally disallowed when maps don't coalesce and retention is disabled. Merge operations are more complex, considering memory region adjacency, DSS compatibility, and various system-specific constraints.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C",
    "code": "\n#include \"jemalloc/internal/jemalloc_preamble.h\"\n#include \"jemalloc/internal/jemalloc_internal_includes.h\"\n\n#include \"jemalloc/internal/ehooks.h\"\n#include \"jemalloc/internal/extent_mmap.h\"\n\nvoid\nehooks_init(ehooks_t *ehooks, extent_hooks_t *extent_hooks, unsigned ind) {\n\t/* All other hooks are optional; this one is not. */\n\tassert(extent_hooks->alloc != NULL);\n\tehooks->ind = ind;\n\tehooks_set_extent_hooks_ptr(ehooks, extent_hooks);\n}\n\n/*\n * If the caller specifies (!*zero), it is still possible to receive zeroed\n * memory, in which case *zero is toggled to true.  arena_extent_alloc() takes\n * advantage of this to avoid demanding zeroed extents, but taking advantage of\n * them if they are returned.\n */\nstatic void *\nextent_alloc_core(tsdn_t *tsdn, arena_t *arena, void *new_addr, size_t size,\n    size_t alignment, bool *zero, bool *commit, dss_prec_t dss_prec) {\n\tvoid *ret;\n\n\tassert(size != 0);\n\tassert(alignment != 0);\n\n\t/* \"primary\" dss. */\n\tif (have_dss && dss_prec == dss_prec_primary && (ret =\n\t    extent_alloc_dss(tsdn, arena, new_addr, size, alignment, zero,\n\t    commit)) != NULL) {\n\t\treturn ret;\n\t}\n\t/* mmap. */\n\tif ((ret = extent_alloc_mmap(new_addr, size, alignment, zero, commit))\n\t    != NULL) {\n\t\treturn ret;\n\t}\n\t/* \"secondary\" dss. */\n\tif (have_dss && dss_prec == dss_prec_secondary && (ret =\n\t    extent_alloc_dss(tsdn, arena, new_addr, size, alignment, zero,\n\t    commit)) != NULL) {\n\t\treturn ret;\n\t}\n\n\t/* All strategies for allocation failed. */\n\treturn NULL;\n}\n\nvoid *\nehooks_default_alloc_impl(tsdn_t *tsdn, void *new_addr, size_t size,\n    size_t alignment, bool *zero, bool *commit, unsigned arena_ind) {\n\tarena_t *arena = arena_get(tsdn, arena_ind, false);\n\t/* NULL arena indicates arena_create. */\n\tassert(arena != NULL || alignment == HUGEPAGE);\n\tdss_prec_t dss = (arena == NULL) ? dss_prec_disabled :\n\t    (dss_prec_t)atomic_load_u(&arena->dss_prec, ATOMIC_RELAXED);\n\tvoid *ret = extent_alloc_core(tsdn, arena, new_addr, size, alignment,\n\t    zero, commit, dss);\n\tif (have_madvise_huge && ret) {\n\t\tpages_set_thp_state(ret, size);\n\t}\n\treturn ret;\n}\n\nstatic void *\nehooks_default_alloc(extent_hooks_t *extent_hooks, void *new_addr, size_t size,\n    size_t alignment, bool *zero, bool *commit, unsigned arena_ind) {\n\treturn ehooks_default_alloc_impl(tsdn_fetch(), new_addr, size,\n\t    ALIGNMENT_CEILING(alignment, PAGE), zero, commit, arena_ind);\n}\n\nbool\nehooks_default_dalloc_impl(void *addr, size_t size) {\n\tif (!have_dss || !extent_in_dss(addr)) {\n\t\treturn extent_dalloc_mmap(addr, size);\n\t}\n\treturn true;\n}\n\nstatic bool\nehooks_default_dalloc(extent_hooks_t *extent_hooks, void *addr, size_t size,\n    bool committed, unsigned arena_ind) {\n\treturn ehooks_default_dalloc_impl(addr, size);\n}\n\nvoid\nehooks_default_destroy_impl(void *addr, size_t size) {\n\tif (!have_dss || !extent_in_dss(addr)) {\n\t\tpages_unmap(addr, size);\n\t}\n}\n\nstatic void\nehooks_default_destroy(extent_hooks_t *extent_hooks, void *addr, size_t size,\n    bool committed, unsigned arena_ind) {\n\tehooks_default_destroy_impl(addr, size);\n}\n\nbool\nehooks_default_commit_impl(void *addr, size_t offset, size_t length) {\n\treturn pages_commit((void *)((byte_t *)addr + (uintptr_t)offset),\n\t    length);\n}\n\nstatic bool\nehooks_default_commit(extent_hooks_t *extent_hooks, void *addr, size_t size,\n    size_t offset, size_t length, unsigned arena_ind) {\n\treturn ehooks_default_commit_impl(addr, offset, length);\n}\n\nbool\nehooks_default_decommit_impl(void *addr, size_t offset, size_t length) {\n\treturn pages_decommit((void *)((byte_t *)addr + (uintptr_t)offset),\n\t    length);\n}\n\nstatic bool\nehooks_default_decommit(extent_hooks_t *extent_hooks, void *addr, size_t size,\n    size_t offset, size_t length, unsigned arena_ind) {\n\treturn ehooks_default_decommit_impl(addr, offset, length);\n}\n\n#ifdef PAGES_CAN_PURGE_LAZY\nbool\nehooks_default_purge_lazy_impl(void *addr, size_t offset, size_t length) {\n\treturn pages_purge_lazy((void *)((byte_t *)addr + (uintptr_t)offset),\n\t    length);\n}\n\nstatic bool\nehooks_default_purge_lazy(extent_hooks_t *extent_hooks, void *addr, size_t size,\n    size_t offset, size_t length, unsigned arena_ind) {\n\tassert(addr != NULL);\n\tassert((offset & PAGE_MASK) == 0);\n\tassert(length != 0);\n\tassert((length & PAGE_MASK) == 0);\n\treturn ehooks_default_purge_lazy_impl(addr, offset, length);\n}\n#endif\n\n#ifdef PAGES_CAN_PURGE_FORCED\nbool\nehooks_default_purge_forced_impl(void *addr, size_t offset, size_t length) {\n\treturn pages_purge_forced((void *)((byte_t *)addr +\n\t    (uintptr_t)offset), length);\n}\n\nstatic bool\nehooks_default_purge_forced(extent_hooks_t *extent_hooks, void *addr,\n    size_t size, size_t offset, size_t length, unsigned arena_ind) {\n\tassert(addr != NULL);\n\tassert((offset & PAGE_MASK) == 0);\n\tassert(length != 0);\n\tassert((length & PAGE_MASK) == 0);\n\treturn ehooks_default_purge_forced_impl(addr, offset, length);\n}\n#endif\n\nbool\nehooks_default_split_impl(void) {\n\tif (!maps_coalesce) {\n\t\t/*\n\t\t * Without retain, only whole regions can be purged (required by\n\t\t * MEM_RELEASE on Windows) -- therefore disallow splitting.  See\n\t\t * comments in extent_head_no_merge().\n\t\t */\n\t\treturn !opt_retain;\n\t}\n\n\treturn false;\n}\n\nstatic bool\nehooks_default_split(extent_hooks_t *extent_hooks, void *addr, size_t size,\n    size_t size_a, size_t size_b, bool committed, unsigned arena_ind) {\n\treturn ehooks_default_split_impl();\n}\n\nbool\nehooks_default_merge_impl(tsdn_t *tsdn, void *addr_a, void *addr_b) {\n\tassert(addr_a < addr_b);\n\t/*\n\t * For non-DSS cases --\n\t * a) W/o maps_coalesce, merge is not always allowed (Windows):\n\t *   1) w/o retain, never merge (first branch below).\n\t *   2) with retain, only merge extents from the same VirtualAlloc\n\t *      region (in which case MEM_DECOMMIT is utilized for purging).\n\t *\n\t * b) With maps_coalesce, it's always possible to merge.\n\t *   1) w/o retain, always allow merge (only about dirty / muzzy).\n\t *   2) with retain, to preserve the SN / first-fit, merge is still\n\t *      disallowed if b is a head extent, i.e. no merging across\n\t *      different mmap regions.\n\t *\n\t * a2) and b2) are implemented in emap_try_acquire_edata_neighbor, and\n\t * sanity checked in the second branch below.\n\t */\n\tif (!maps_coalesce && !opt_retain) {\n\t\treturn true;\n\t}\n\tif (config_debug) {\n\t\tedata_t *a = emap_edata_lookup(tsdn, &arena_emap_global,\n\t\t    addr_a);\n\t\tbool head_a = edata_is_head_get(a);\n\t\tedata_t *b = emap_edata_lookup(tsdn, &arena_emap_global,\n\t\t    addr_b);\n\t\tbool head_b = edata_is_head_get(b);\n\t\temap_assert_mapped(tsdn, &arena_emap_global, a);\n\t\temap_assert_mapped(tsdn, &arena_emap_global, b);\n\t\tassert(extent_neighbor_head_state_mergeable(head_a, head_b,\n\t\t    /* forward */ true));\n\t}\n\tif (have_dss && !extent_dss_mergeable(addr_a, addr_b)) {\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nbool\nehooks_default_merge(extent_hooks_t *extent_hooks, void *addr_a, size_t size_a,\n    void *addr_b, size_t size_b, bool committed, unsigned arena_ind) {\n\ttsdn_t *tsdn = tsdn_fetch();\n\n\treturn ehooks_default_merge_impl(tsdn, addr_a, addr_b);\n}\n\nvoid\nehooks_default_zero_impl(void *addr, size_t size) {\n\t/*\n\t * By default, we try to zero out memory using OS-provided demand-zeroed\n\t * pages.  If the user has specifically requested hugepages, though, we\n\t * don't want to purge in the middle of a hugepage (which would break it\n\t * up), so we act conservatively and use memset.\n\t */\n\tbool needs_memset = true;\n\tif (opt_thp != thp_mode_always) {\n\t\tneeds_memset = pages_purge_forced(addr, size);\n\t}\n\tif (needs_memset) {\n\t\tmemset(addr, 0, size);\n\t}\n}\n\nvoid\nehooks_default_guard_impl(void *guard1, void *guard2) {\n\tpages_mark_guards(guard1, guard2);\n}\n\nvoid\nehooks_default_unguard_impl(void *guard1, void *guard2) {\n\tpages_unmark_guards(guard1, guard2);\n}\n\nconst extent_hooks_t ehooks_default_extent_hooks = {\n\tehooks_default_alloc,\n\tehooks_default_dalloc,\n\tehooks_default_destroy,\n\tehooks_default_commit,\n\tehooks_default_decommit,\n#ifdef PAGES_CAN_PURGE_LAZY\n\tehooks_default_purge_lazy,\n#else\n\tNULL,\n#endif\n#ifdef PAGES_CAN_PURGE_FORCED\n\tehooks_default_purge_forced,\n#else\n\tNULL,\n#endif\n\tehooks_default_split,\n\tehooks_default_merge\n};",
    "repo": "arangodb/arangodb",
    "path": "./datasets/diagrams-repos/arangodb/arangodb/3rdParty/jemalloc/jemalloc/src/ehooks.c",
    "query": "Can you illustrate the logic behind the merge and split operations?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'ehooks_default_split_impl', 'node_id': 'ehooks_default_split_impl', 'description': 'Core implementation of split operation', 'visibility': 'public', 'return_type': 'bool', 'params': 'void', 'source_class_id': None}, {'type': 'function', 'name': 'ehooks_default_merge_impl', 'node_id': 'ehooks_default_merge_impl', 'description': 'Core implementation of merge operation', 'visibility': 'public', 'return_type': 'bool', 'params': 'tsdn_t *tsdn, void *addr_a, void *addr_b', 'source_class_id': None}, {'type': 'function', 'name': 'ehooks_default_split', 'node_id': 'ehooks_default_split', 'description': 'External interface for split operation', 'visibility': 'private', 'return_type': 'bool', 'params': 'extent_hooks_t *extent_hooks, void *addr, size_t size, size_t size_a, size_t size_b, bool committed, unsigned arena_ind', 'source_class_id': None}, {'type': 'function', 'name': 'ehooks_default_merge', 'node_id': 'ehooks_default_merge', 'description': 'External interface for merge operation', 'visibility': 'public', 'return_type': 'bool', 'params': 'extent_hooks_t *extent_hooks, void *addr_a, size_t size_a, void *addr_b, size_t size_b, bool committed, unsigned arena_ind', 'source_class_id': None}, {'type': 'variable', 'name': 'maps_coalesce', 'node_id': 'maps_coalesce', 'description': 'Flag indicating if memory maps can be coalesced', 'visibility': 'private', 'return_type': 'bool', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'opt_retain', 'node_id': 'opt_retain', 'description': 'Option for memory retention', 'visibility': 'private', 'return_type': 'bool', 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'extent_hooks_t', 'node_id': 'extent_hooks_t', 'description': 'Structure containing memory management hooks', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'extent_hooks_t', 'node_id_to': 'ehooks_default_split', 'description': 'contains'}, {'node_id_from': 'extent_hooks_t', 'node_id_to': 'ehooks_default_merge', 'description': 'contains'}, {'node_id_from': 'ehooks_default_split', 'node_id_to': 'ehooks_default_split_impl', 'description': 'calls'}, {'node_id_from': 'ehooks_default_merge', 'node_id_to': 'ehooks_default_merge_impl', 'description': 'calls'}, {'node_id_from': 'ehooks_default_split_impl', 'node_id_to': 'maps_coalesce', 'description': 'reads'}, {'node_id_from': 'ehooks_default_split_impl', 'node_id_to': 'opt_retain', 'description': 'reads'}, {'node_id_from': 'ehooks_default_merge_impl', 'node_id_to': 'maps_coalesce', 'description': 'reads'}, {'node_id_from': 'ehooks_default_merge_impl', 'node_id_to': 'opt_retain', 'description': 'reads'}], 'packages': [{'package_id': 'memoryOperations', 'children': ['ehooks_default_split_impl', 'ehooks_default_merge_impl', 'ehooks_default_split', 'ehooks_default_merge'], 'description': 'Memory management operations for splitting and merging'}, {'package_id': 'configuration', 'children': ['maps_coalesce', 'opt_retain'], 'description': 'Configuration flags affecting memory operations'}]}",
    "version": "full",
    "text_answer": "The merge and split operations are controlled by two main factors: maps coalescing and retention settings. Split operations are generally disallowed when maps don't coalesce and retention is disabled. Merge operations are more complex, considering memory region adjacency, DSS compatibility, and various system-specific constraints.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Python",
    "code": "\nfrom __future__ import annotations as _annotations\n\nfrom typing import TYPE_CHECKING, Any, Union\n\nfrom pydantic_core import core_schema\n\nif TYPE_CHECKING:\n    from ._internal._namespace_utils import NamespacesTuple\n    from .json_schema import JsonSchemaMode, JsonSchemaValue\n\n    CoreSchemaOrField = Union[\n        core_schema.CoreSchema,\n        core_schema.ModelField,\n        core_schema.DataclassField,\n        core_schema.TypedDictField,\n        core_schema.ComputedField,\n    ]\n\n__all__ = 'GetJsonSchemaHandler', 'GetCoreSchemaHandler'\n\n\nclass GetJsonSchemaHandler:\n    \"\"\"Handler to call into the next JSON schema generation function.\n\n    Attributes:\n        mode: Json schema mode, can be `validation` or `serialization`.\n    \"\"\"\n\n    mode: JsonSchemaMode\n\n    def __call__(self, core_schema: CoreSchemaOrField, /) -> JsonSchemaValue:\n        \"\"\"Call the inner handler and get the JsonSchemaValue it returns.\n        This will call the next JSON schema modifying function up until it calls\n        into `pydantic.json_schema.GenerateJsonSchema`, which will raise a\n        `pydantic.errors.PydanticInvalidForJsonSchema` error if it cannot generate\n        a JSON schema.\n\n        Args:\n            core_schema: A `pydantic_core.core_schema.CoreSchema`.\n\n        Returns:\n            JsonSchemaValue: The JSON schema generated by the inner JSON schema modify\n            functions.\n        \"\"\"\n        raise NotImplementedError\n\n    def resolve_ref_schema(self, maybe_ref_json_schema: JsonSchemaValue, /) -> JsonSchemaValue:\n        \"\"\"Get the real schema for a `{\"$ref\": ...}` schema.\n        If the schema given is not a `$ref` schema, it will be returned as is.\n        This means you don't have to check before calling this function.\n\n        Args:\n            maybe_ref_json_schema: A JsonSchemaValue which may be a `$ref` schema.\n\n        Raises:\n            LookupError: If the ref is not found.\n\n        Returns:\n            JsonSchemaValue: A JsonSchemaValue that has no `$ref`.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass GetCoreSchemaHandler:\n    \"\"\"Handler to call into the next CoreSchema schema generation function.\"\"\"\n\n    def __call__(self, source_type: Any, /) -> core_schema.CoreSchema:\n        \"\"\"Call the inner handler and get the CoreSchema it returns.\n        This will call the next CoreSchema modifying function up until it calls\n        into Pydantic's internal schema generation machinery, which will raise a\n        `pydantic.errors.PydanticSchemaGenerationError` error if it cannot generate\n        a CoreSchema for the given source type.\n\n        Args:\n            source_type: The input type.\n\n        Returns:\n            CoreSchema: The `pydantic-core` CoreSchema generated.\n        \"\"\"\n        raise NotImplementedError\n\n    def generate_schema(self, source_type: Any, /) -> core_schema.CoreSchema:\n        \"\"\"Generate a schema unrelated to the current context.\n        Use this function if e.g. you are handling schema generation for a sequence\n        and want to generate a schema for its items.\n        Otherwise, you may end up doing something like applying a `min_length` constraint\n        that was intended for the sequence itself to its items!\n\n        Args:\n            source_type: The input type.\n\n        Returns:\n            CoreSchema: The `pydantic-core` CoreSchema generated.\n        \"\"\"\n        raise NotImplementedError\n\n    def resolve_ref_schema(self, maybe_ref_schema: core_schema.CoreSchema, /) -> core_schema.CoreSchema:\n        \"\"\"Get the real schema for a `definition-ref` schema.\n        If the schema given is not a `definition-ref` schema, it will be returned as is.\n        This means you don't have to check before calling this function.\n\n        Args:\n            maybe_ref_schema: A `CoreSchema`, `ref`-based or not.\n\n        Raises:\n            LookupError: If the `ref` is not found.\n\n        Returns:\n            A concrete `CoreSchema`.\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    def field_name(self) -> str | None:\n        \"\"\"Get the name of the closest field to this validator.\"\"\"\n        raise NotImplementedError\n\n    def _get_types_namespace(self) -> NamespacesTuple:\n        \"\"\"Internal method used during type resolution for serializer annotations.\"\"\"\n        raise NotImplementedError",
    "repo": "pydantic/pydantic",
    "path": "./datasets/diagrams-repos/pydantic/pydantic/pydantic/annotated_handlers.py",
    "query": "How do the GetJsonSchemaHandler and GetCoreSchemaHandler classes interact?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'GetJsonSchemaHandler', 'node_id': 'GetJsonSchemaHandler', 'description': 'Handles JSON schema generation and resolution', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'GetCoreSchemaHandler', 'node_id': 'GetCoreSchemaHandler', 'description': 'Handles core schema generation and resolution', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'GetCoreSchemaHandler', 'node_id_to': 'GetJsonSchemaHandler', 'description': 'converted by'}], 'packages': [{'package_id': 'schemaHandlers', 'children': ['GetJsonSchemaHandler', 'GetCoreSchemaHandler'], 'description': 'Schema handling components'}]}",
    "version": "minimal",
    "text_answer": "GetJsonSchemaHandler and GetCoreSchemaHandler operate independently but complementarily. GetJsonSchemaHandler converts core schemas to JSON schemas, while GetCoreSchemaHandler handles core schema generation and resolution. The JSON schema generation process may utilize core schema functionality, but there's no direct dependency between these classes.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Python",
    "code": "\nfrom __future__ import annotations as _annotations\n\nfrom typing import TYPE_CHECKING, Any, Union\n\nfrom pydantic_core import core_schema\n\nif TYPE_CHECKING:\n    from ._internal._namespace_utils import NamespacesTuple\n    from .json_schema import JsonSchemaMode, JsonSchemaValue\n\n    CoreSchemaOrField = Union[\n        core_schema.CoreSchema,\n        core_schema.ModelField,\n        core_schema.DataclassField,\n        core_schema.TypedDictField,\n        core_schema.ComputedField,\n    ]\n\n__all__ = 'GetJsonSchemaHandler', 'GetCoreSchemaHandler'\n\n\nclass GetJsonSchemaHandler:\n    \"\"\"Handler to call into the next JSON schema generation function.\n\n    Attributes:\n        mode: Json schema mode, can be `validation` or `serialization`.\n    \"\"\"\n\n    mode: JsonSchemaMode\n\n    def __call__(self, core_schema: CoreSchemaOrField, /) -> JsonSchemaValue:\n        \"\"\"Call the inner handler and get the JsonSchemaValue it returns.\n        This will call the next JSON schema modifying function up until it calls\n        into `pydantic.json_schema.GenerateJsonSchema`, which will raise a\n        `pydantic.errors.PydanticInvalidForJsonSchema` error if it cannot generate\n        a JSON schema.\n\n        Args:\n            core_schema: A `pydantic_core.core_schema.CoreSchema`.\n\n        Returns:\n            JsonSchemaValue: The JSON schema generated by the inner JSON schema modify\n            functions.\n        \"\"\"\n        raise NotImplementedError\n\n    def resolve_ref_schema(self, maybe_ref_json_schema: JsonSchemaValue, /) -> JsonSchemaValue:\n        \"\"\"Get the real schema for a `{\"$ref\": ...}` schema.\n        If the schema given is not a `$ref` schema, it will be returned as is.\n        This means you don't have to check before calling this function.\n\n        Args:\n            maybe_ref_json_schema: A JsonSchemaValue which may be a `$ref` schema.\n\n        Raises:\n            LookupError: If the ref is not found.\n\n        Returns:\n            JsonSchemaValue: A JsonSchemaValue that has no `$ref`.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass GetCoreSchemaHandler:\n    \"\"\"Handler to call into the next CoreSchema schema generation function.\"\"\"\n\n    def __call__(self, source_type: Any, /) -> core_schema.CoreSchema:\n        \"\"\"Call the inner handler and get the CoreSchema it returns.\n        This will call the next CoreSchema modifying function up until it calls\n        into Pydantic's internal schema generation machinery, which will raise a\n        `pydantic.errors.PydanticSchemaGenerationError` error if it cannot generate\n        a CoreSchema for the given source type.\n\n        Args:\n            source_type: The input type.\n\n        Returns:\n            CoreSchema: The `pydantic-core` CoreSchema generated.\n        \"\"\"\n        raise NotImplementedError\n\n    def generate_schema(self, source_type: Any, /) -> core_schema.CoreSchema:\n        \"\"\"Generate a schema unrelated to the current context.\n        Use this function if e.g. you are handling schema generation for a sequence\n        and want to generate a schema for its items.\n        Otherwise, you may end up doing something like applying a `min_length` constraint\n        that was intended for the sequence itself to its items!\n\n        Args:\n            source_type: The input type.\n\n        Returns:\n            CoreSchema: The `pydantic-core` CoreSchema generated.\n        \"\"\"\n        raise NotImplementedError\n\n    def resolve_ref_schema(self, maybe_ref_schema: core_schema.CoreSchema, /) -> core_schema.CoreSchema:\n        \"\"\"Get the real schema for a `definition-ref` schema.\n        If the schema given is not a `definition-ref` schema, it will be returned as is.\n        This means you don't have to check before calling this function.\n\n        Args:\n            maybe_ref_schema: A `CoreSchema`, `ref`-based or not.\n\n        Raises:\n            LookupError: If the `ref` is not found.\n\n        Returns:\n            A concrete `CoreSchema`.\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    def field_name(self) -> str | None:\n        \"\"\"Get the name of the closest field to this validator.\"\"\"\n        raise NotImplementedError\n\n    def _get_types_namespace(self) -> NamespacesTuple:\n        \"\"\"Internal method used during type resolution for serializer annotations.\"\"\"\n        raise NotImplementedError",
    "repo": "pydantic/pydantic",
    "path": "./datasets/diagrams-repos/pydantic/pydantic/pydantic/annotated_handlers.py",
    "query": "How do the GetJsonSchemaHandler and GetCoreSchemaHandler classes interact?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'GetJsonSchemaHandler', 'node_id': 'GetJsonSchemaHandler', 'description': 'Handles JSON schema generation and resolution', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': '__call__', 'node_id': 'GetJsonSchemaHandler.__call__', 'description': 'Generates JSON schema from core schema', 'visibility': 'public', 'return_type': 'JsonSchemaValue', 'params': 'core_schema: CoreSchemaOrField', 'source_class_id': 'GetJsonSchemaHandler'}, {'type': 'method', 'name': 'resolve_ref_schema', 'node_id': 'GetJsonSchemaHandler.resolve_ref_schema', 'description': 'Resolves JSON schema references', 'visibility': 'public', 'return_type': 'JsonSchemaValue', 'params': 'maybe_ref_json_schema: JsonSchemaValue', 'source_class_id': 'GetJsonSchemaHandler'}, {'type': 'class', 'name': 'GetCoreSchemaHandler', 'node_id': 'GetCoreSchemaHandler', 'description': 'Handles core schema generation and resolution', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': '__call__', 'node_id': 'GetCoreSchemaHandler.__call__', 'description': 'Generates core schema from source type', 'visibility': 'public', 'return_type': 'CoreSchema', 'params': 'source_type: Any', 'source_class_id': 'GetCoreSchemaHandler'}, {'type': 'method', 'name': 'resolve_ref_schema', 'node_id': 'GetCoreSchemaHandler.resolve_ref_schema', 'description': 'Resolves core schema references', 'visibility': 'public', 'return_type': 'CoreSchema', 'params': 'maybe_ref_schema: CoreSchema', 'source_class_id': 'GetCoreSchemaHandler'}], 'edges': [{'node_id_from': 'GetJsonSchemaHandler.__call__', 'node_id_to': 'GetCoreSchemaHandler.resolve_ref_schema', 'description': 'May use for schema resolution'}, {'node_id_from': 'GetJsonSchemaHandler', 'node_id_to': 'GetJsonSchemaHandler.__call__', 'description': ''}, {'node_id_from': 'GetJsonSchemaHandler', 'node_id_to': 'GetJsonSchemaHandler.resolve_ref_schema', 'description': ''}, {'node_id_from': 'GetCoreSchemaHandler', 'node_id_to': 'GetCoreSchemaHandler.__call__', 'description': ''}, {'node_id_from': 'GetCoreSchemaHandler', 'node_id_to': 'GetCoreSchemaHandler.resolve_ref_schema', 'description': ''}], 'packages': [{'package_id': 'schemaHandlers', 'children': ['GetJsonSchemaHandler', 'GetCoreSchemaHandler', 'GetCoreSchemaHandler.resolve_ref_schema', 'GetCoreSchemaHandler.__call__', 'GetJsonSchemaHandler.resolve_ref_schema', 'GetJsonSchemaHandler.__call__'], 'description': 'Schema handling components'}]}",
    "version": "medium",
    "text_answer": "GetJsonSchemaHandler and GetCoreSchemaHandler operate independently but complementarily. GetJsonSchemaHandler converts core schemas to JSON schemas, while GetCoreSchemaHandler handles core schema generation and resolution. The JSON schema generation process may utilize core schema functionality, but there's no direct dependency between these classes.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Python",
    "code": "\nfrom __future__ import annotations as _annotations\n\nfrom typing import TYPE_CHECKING, Any, Union\n\nfrom pydantic_core import core_schema\n\nif TYPE_CHECKING:\n    from ._internal._namespace_utils import NamespacesTuple\n    from .json_schema import JsonSchemaMode, JsonSchemaValue\n\n    CoreSchemaOrField = Union[\n        core_schema.CoreSchema,\n        core_schema.ModelField,\n        core_schema.DataclassField,\n        core_schema.TypedDictField,\n        core_schema.ComputedField,\n    ]\n\n__all__ = 'GetJsonSchemaHandler', 'GetCoreSchemaHandler'\n\n\nclass GetJsonSchemaHandler:\n    \"\"\"Handler to call into the next JSON schema generation function.\n\n    Attributes:\n        mode: Json schema mode, can be `validation` or `serialization`.\n    \"\"\"\n\n    mode: JsonSchemaMode\n\n    def __call__(self, core_schema: CoreSchemaOrField, /) -> JsonSchemaValue:\n        \"\"\"Call the inner handler and get the JsonSchemaValue it returns.\n        This will call the next JSON schema modifying function up until it calls\n        into `pydantic.json_schema.GenerateJsonSchema`, which will raise a\n        `pydantic.errors.PydanticInvalidForJsonSchema` error if it cannot generate\n        a JSON schema.\n\n        Args:\n            core_schema: A `pydantic_core.core_schema.CoreSchema`.\n\n        Returns:\n            JsonSchemaValue: The JSON schema generated by the inner JSON schema modify\n            functions.\n        \"\"\"\n        raise NotImplementedError\n\n    def resolve_ref_schema(self, maybe_ref_json_schema: JsonSchemaValue, /) -> JsonSchemaValue:\n        \"\"\"Get the real schema for a `{\"$ref\": ...}` schema.\n        If the schema given is not a `$ref` schema, it will be returned as is.\n        This means you don't have to check before calling this function.\n\n        Args:\n            maybe_ref_json_schema: A JsonSchemaValue which may be a `$ref` schema.\n\n        Raises:\n            LookupError: If the ref is not found.\n\n        Returns:\n            JsonSchemaValue: A JsonSchemaValue that has no `$ref`.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass GetCoreSchemaHandler:\n    \"\"\"Handler to call into the next CoreSchema schema generation function.\"\"\"\n\n    def __call__(self, source_type: Any, /) -> core_schema.CoreSchema:\n        \"\"\"Call the inner handler and get the CoreSchema it returns.\n        This will call the next CoreSchema modifying function up until it calls\n        into Pydantic's internal schema generation machinery, which will raise a\n        `pydantic.errors.PydanticSchemaGenerationError` error if it cannot generate\n        a CoreSchema for the given source type.\n\n        Args:\n            source_type: The input type.\n\n        Returns:\n            CoreSchema: The `pydantic-core` CoreSchema generated.\n        \"\"\"\n        raise NotImplementedError\n\n    def generate_schema(self, source_type: Any, /) -> core_schema.CoreSchema:\n        \"\"\"Generate a schema unrelated to the current context.\n        Use this function if e.g. you are handling schema generation for a sequence\n        and want to generate a schema for its items.\n        Otherwise, you may end up doing something like applying a `min_length` constraint\n        that was intended for the sequence itself to its items!\n\n        Args:\n            source_type: The input type.\n\n        Returns:\n            CoreSchema: The `pydantic-core` CoreSchema generated.\n        \"\"\"\n        raise NotImplementedError\n\n    def resolve_ref_schema(self, maybe_ref_schema: core_schema.CoreSchema, /) -> core_schema.CoreSchema:\n        \"\"\"Get the real schema for a `definition-ref` schema.\n        If the schema given is not a `definition-ref` schema, it will be returned as is.\n        This means you don't have to check before calling this function.\n\n        Args:\n            maybe_ref_schema: A `CoreSchema`, `ref`-based or not.\n\n        Raises:\n            LookupError: If the `ref` is not found.\n\n        Returns:\n            A concrete `CoreSchema`.\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    def field_name(self) -> str | None:\n        \"\"\"Get the name of the closest field to this validator.\"\"\"\n        raise NotImplementedError\n\n    def _get_types_namespace(self) -> NamespacesTuple:\n        \"\"\"Internal method used during type resolution for serializer annotations.\"\"\"\n        raise NotImplementedError",
    "repo": "pydantic/pydantic",
    "path": "./datasets/diagrams-repos/pydantic/pydantic/pydantic/annotated_handlers.py",
    "query": "How do the GetJsonSchemaHandler and GetCoreSchemaHandler classes interact?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'GetJsonSchemaHandler', 'node_id': 'GetJsonSchemaHandler', 'description': 'Handles JSON schema generation and resolution', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'mode', 'node_id': 'GetJsonSchemaHandler.mode', 'description': 'JSON schema mode (validation/serialization)', 'visibility': 'public', 'return_type': 'JsonSchemaMode', 'params': None, 'source_class_id': 'GetJsonSchemaHandler'}, {'type': 'method', 'name': '__call__', 'node_id': 'GetJsonSchemaHandler.__call__', 'description': 'Generates JSON schema from core schema', 'visibility': 'public', 'return_type': 'JsonSchemaValue', 'params': 'core_schema: CoreSchemaOrField', 'source_class_id': 'GetJsonSchemaHandler'}, {'type': 'method', 'name': 'resolve_ref_schema', 'node_id': 'GetJsonSchemaHandler.resolve_ref_schema', 'description': 'Resolves JSON schema references', 'visibility': 'public', 'return_type': 'JsonSchemaValue', 'params': 'maybe_ref_json_schema: JsonSchemaValue', 'source_class_id': 'GetJsonSchemaHandler'}, {'type': 'class', 'name': 'GetCoreSchemaHandler', 'node_id': 'GetCoreSchemaHandler', 'description': 'Handles core schema generation and resolution', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': 'GetCoreSchemaHandler'}, {'type': 'method', 'name': '__call__', 'node_id': 'GetCoreSchemaHandler.__call__', 'description': 'Generates core schema from source type', 'visibility': 'public', 'return_type': 'CoreSchema', 'params': 'source_type: Any', 'source_class_id': 'GetCoreSchemaHandler'}, {'type': 'method', 'name': 'generate_schema', 'node_id': 'GetCoreSchemaHandler.generate_schema', 'description': 'Generates independent core schema', 'visibility': 'public', 'return_type': 'CoreSchema', 'params': 'source_type: Any', 'source_class_id': 'GetCoreSchemaHandler'}, {'type': 'method', 'name': 'resolve_ref_schema', 'node_id': 'GetCoreSchemaHandler.resolve_ref_schema', 'description': 'Resolves core schema references', 'visibility': 'public', 'return_type': 'CoreSchema', 'params': 'maybe_ref_schema: CoreSchema', 'source_class_id': 'GetCoreSchemaHandler'}, {'type': 'method', 'name': 'field_name', 'node_id': 'GetCoreSchemaHandler.field_name', 'description': 'Gets closest field name', 'visibility': 'public', 'return_type': 'str | None', 'params': '', 'source_class_id': 'GetCoreSchemaHandler'}, {'type': 'method', 'name': '_get_types_namespace', 'node_id': 'GetCoreSchemaHandler._get_types_namespace', 'description': 'Gets types namespace for serialization', 'visibility': 'private', 'return_type': 'NamespacesTuple', 'params': '', 'source_class_id': 'GetCoreSchemaHandler'}], 'edges': [{'node_id_from': 'GetJsonSchemaHandler.__call__', 'node_id_to': 'GetCoreSchemaHandler.resolve_ref_schema', 'description': 'May use for schema resolution'}, {'node_id_from': 'GetJsonSchemaHandler.__call__', 'node_id_to': 'GetCoreSchemaHandler.__call__', 'description': 'Uses core schema'}, {'node_id_from': 'GetCoreSchemaHandler.__call__', 'node_id_to': 'GetCoreSchemaHandler.generate_schema', 'description': 'May delegate schema generation'}, {'node_id_from': 'GetCoreSchemaHandler.generate_schema', 'node_id_to': 'GetCoreSchemaHandler._get_types_namespace', 'description': 'Uses for type resolution'}, {'node_id_from': 'GetJsonSchemaHandler', 'node_id_to': 'GetJsonSchemaHandler.__call__', 'description': ''}, {'node_id_from': 'GetJsonSchemaHandler', 'node_id_to': 'GetJsonSchemaHandler.resolve_ref_schema', 'description': ''}, {'node_id_from': 'GetJsonSchemaHandler', 'node_id_to': 'GetJsonSchemaHandler.mode', 'description': ''}, {'node_id_from': 'GetCoreSchemaHandler', 'node_id_to': 'GetCoreSchemaHandler.field_name', 'description': ''}, {'node_id_from': 'GetCoreSchemaHandler', 'node_id_to': 'GetCoreSchemaHandler.__call__', 'description': ''}, {'node_id_from': 'GetCoreSchemaHandler', 'node_id_to': 'GetCoreSchemaHandler.generate_schema', 'description': ''}, {'node_id_from': 'GetCoreSchemaHandler', 'node_id_to': 'GetCoreSchemaHandler._get_types_namespace', 'description': ''}, {'node_id_from': 'GetCoreSchemaHandler', 'node_id_to': 'GetCoreSchemaHandler.resolve_ref_schema', 'description': ''}], 'packages': [{'package_id': 'schemaHandlers', 'children': ['GetJsonSchemaHandler', 'GetCoreSchemaHandler', 'GetJsonSchemaHandler.mode', 'GetJsonSchemaHandler.__call__', 'GetJsonSchemaHandler.resolve_ref_schema', 'GetCoreSchemaHandler.__call__', 'GetCoreSchemaHandler.generate_schema', 'GetCoreSchemaHandler.resolve_ref_schema', 'GetCoreSchemaHandler.field_name', 'GetCoreSchemaHandler._get_types_namespace'], 'description': 'Schema handling components'}]}",
    "version": "full",
    "text_answer": "GetJsonSchemaHandler and GetCoreSchemaHandler operate independently but complementarily. GetJsonSchemaHandler converts core schemas to JSON schemas, while GetCoreSchemaHandler handles core schema generation and resolution. The JSON schema generation process may utilize core schema functionality, but there's no direct dependency between these classes.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "PHP",
    "code": "\n<?php\ndeclare(strict_types=1);\n\n/**\n * CakePHP(tm) : Rapid Development Framework (https://cakephp.org)\n * Copyright (c) Cake Software Foundation, Inc. (https://cakefoundation.org)\n *\n * Licensed under The MIT License\n * For full copyright and license information, please see the LICENSE.txt\n * Redistributions of files must retain the above copyright notice\n *\n * @copyright     Copyright (c) Cake Software Foundation, Inc. (https://cakefoundation.org)\n * @since         4.3.0\n * @license       https://opensource.org/licenses/mit-license.php MIT License\n */\nnamespace Cake\\TestSuite\\Fixture;\n\nuse Cake\\Core\\Exception\\CakeException;\nuse Cake\\Database\\Connection;\nuse Cake\\Database\\Schema\\TableSchema;\nuse Cake\\Datasource\\ConnectionManager;\nuse Cake\\TestSuite\\ConnectionHelper;\nuse InvalidArgumentException;\n\n/**\n * Create test database schema from one or more SQL dump files.\n *\n * This class can be useful to create test database schema when\n * your schema is managed by tools external to your CakePHP\n * application.\n *\n * It is not well suited for applications/plugins that need to\n * support multiple database platforms. You should use migrations\n * for that instead.\n */\nclass SchemaLoader\n{\n    /**\n     * Load and apply schema sql file, or an array of files.\n     *\n     * @param array<string>|string $paths Schema files to load\n     * @param string $connectionName Connection name\n     * @param bool $dropTables Drop all tables prior to loading schema files\n     * @param bool $truncateTables Truncate all tables after loading schema files\n     * @return void\n     */\n    public function loadSqlFiles(\n        array|string $paths,\n        string $connectionName = 'test',\n        bool $dropTables = true,\n        bool $truncateTables = false,\n    ): void {\n        $files = (array)$paths;\n\n        // Don't create schema if we are in a phpunit separate process test method.\n        if (isset($GLOBALS['__PHPUNIT_BOOTSTRAP'])) {\n            return;\n        }\n\n        if ($dropTables) {\n            ConnectionHelper::dropTables($connectionName);\n        }\n\n        /** @var \\Cake\\Database\\Connection $connection */\n        $connection = ConnectionManager::get($connectionName);\n        foreach ($files as $file) {\n            if (!file_exists($file)) {\n                throw new InvalidArgumentException(sprintf('Unable to load SQL file `%s`.', $file));\n            }\n            $sql = file_get_contents($file);\n            if ($sql === false) {\n                throw new CakeException(sprintf('Cannot read file content of `%s`', $file));\n            }\n\n            // Use the underlying PDO connection so we can avoid prepared statements\n            // which don't support multiple queries in postgres.\n            $driver = $connection->getDriver();\n            $driver->exec($sql);\n        }\n\n        if ($truncateTables) {\n            ConnectionHelper::truncateTables($connectionName);\n        }\n    }\n\n    /**\n     * Load and apply CakePHP schema file.\n     *\n     * This method will process the array returned by `$file` and treat\n     * the contents as a list of table schema.\n     *\n     * An example table is:\n     *\n     * ```\n     * return [\n     *   'articles' => [\n     *      'columns' => [\n     *          'id' => [\n     *              'type' => 'integer',\n     *          ],\n     *          'author_id' => [\n     *              'type' => 'integer',\n     *              'null' => true,\n     *          ],\n     *          'title' => [\n     *              'type' => 'string',\n     *              'null' => true,\n     *          ],\n     *          'body' => 'text',\n     *          'published' => [\n     *              'type' => 'string',\n     *              'length' => 1,\n     *              'default' => 'N',\n     *          ],\n     *      ],\n     *      'constraints' => [\n     *          'primary' => [\n     *              'type' => 'primary',\n     *              'columns' => [\n     *                  'id',\n     *              ],\n     *          ],\n     *      ],\n     *   ],\n     * ];\n     * ```\n     *\n     * This schema format can be useful for plugins that want to include\n     * tables to test against but don't need to include production\n     * ready schema via migrations. Applications should favour using migrations\n     * or SQL dump files over this format for ease of maintenance.\n     *\n     * A more complete example can be found in `tests/schema.php`.\n     *\n     * @param string $file Schema file\n     * @param string $connectionName Connection name\n     * @throws \\InvalidArgumentException For missing table name(s).\n     * @return void\n     */\n    public function loadInternalFile(string $file, string $connectionName = 'test'): void\n    {\n        // Don't reload schema when we are in a separate process state.\n        if (isset($GLOBALS['__PHPUNIT_BOOTSTRAP'])) {\n            return;\n        }\n\n        ConnectionHelper::dropTables($connectionName);\n\n        $tables = include $file;\n\n        /**\n         * @var \\Cake\\Database\\Connection $connection\n         */\n        $connection = ConnectionManager::get($connectionName);\n        $connection->disableConstraints(function (Connection $connection) use ($tables): void {\n            foreach ($tables as $tableName => $table) {\n                $name = $table['table'] ?? $tableName;\n                if (!is_string($name)) {\n                    throw new InvalidArgumentException(\n                        sprintf('`%s` is not a valid table name. Either use a string key for the table definition'\n                            . \"(`'articles' => [...]`) or define the `table` key in the table definition.\", $name),\n                    );\n                }\n                $schema = new TableSchema($name, $table['columns']);\n                if (isset($table['indexes'])) {\n                    foreach ($table['indexes'] as $key => $index) {\n                        $schema->addIndex($key, $index);\n                    }\n                }\n                if (isset($table['constraints'])) {\n                    foreach ($table['constraints'] as $key => $index) {\n                        $schema->addConstraint($key, $index);\n                    }\n                }\n\n                // Generate SQL for each table.\n                foreach ($schema->createSql($connection) as $sql) {\n                    $connection->execute($sql);\n                }\n            }\n        });\n    }\n}",
    "repo": "cakephp/cakephp",
    "path": "./datasets/diagrams-repos/cakephp/cakephp/src/TestSuite/Fixture/SchemaLoader.php",
    "query": "What is the structure of the SchemaLoader class and its main methods?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'SchemaLoader', 'node_id': 'SchemaLoader', 'description': 'Creates test database schema from SQL dump files or schema definitions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'loadSqlFiles', 'node_id': 'loadSqlFiles', 'description': 'Loads and applies schema from SQL files', 'visibility': 'public', 'return_type': 'void', 'params': 'array|string $paths, string $connectionName, bool $dropTables, bool $truncateTables', 'source_class_id': 'SchemaLoader'}, {'type': 'method', 'name': 'loadInternalFile', 'node_id': 'loadInternalFile', 'description': 'Loads and applies schema from CakePHP schema file', 'visibility': 'public', 'return_type': 'void', 'params': 'string $file, string $connectionName', 'source_class_id': 'SchemaLoader'}], 'edges': [{'node_id_from': 'SchemaLoader', 'node_id_to': 'loadSqlFiles', 'description': 'contains'}, {'node_id_from': 'SchemaLoader', 'node_id_to': 'loadInternalFile', 'description': 'contains'}], 'packages': [{'package_id': 'schemaManagement', 'children': ['SchemaLoader', 'loadSqlFiles', 'loadInternalFile'], 'description': 'Core schema loading functionality'}]}",
    "version": "minimal",
    "text_answer": "SchemaLoader is a class that manages test database schema creation with two main methods: loadSqlFiles for loading schema from SQL files and loadInternalFile for loading schema from CakePHP schema definitions. It works with database connections and can handle table operations like dropping and truncating.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "PHP",
    "code": "\n<?php\ndeclare(strict_types=1);\n\n/**\n * CakePHP(tm) : Rapid Development Framework (https://cakephp.org)\n * Copyright (c) Cake Software Foundation, Inc. (https://cakefoundation.org)\n *\n * Licensed under The MIT License\n * For full copyright and license information, please see the LICENSE.txt\n * Redistributions of files must retain the above copyright notice\n *\n * @copyright     Copyright (c) Cake Software Foundation, Inc. (https://cakefoundation.org)\n * @since         4.3.0\n * @license       https://opensource.org/licenses/mit-license.php MIT License\n */\nnamespace Cake\\TestSuite\\Fixture;\n\nuse Cake\\Core\\Exception\\CakeException;\nuse Cake\\Database\\Connection;\nuse Cake\\Database\\Schema\\TableSchema;\nuse Cake\\Datasource\\ConnectionManager;\nuse Cake\\TestSuite\\ConnectionHelper;\nuse InvalidArgumentException;\n\n/**\n * Create test database schema from one or more SQL dump files.\n *\n * This class can be useful to create test database schema when\n * your schema is managed by tools external to your CakePHP\n * application.\n *\n * It is not well suited for applications/plugins that need to\n * support multiple database platforms. You should use migrations\n * for that instead.\n */\nclass SchemaLoader\n{\n    /**\n     * Load and apply schema sql file, or an array of files.\n     *\n     * @param array<string>|string $paths Schema files to load\n     * @param string $connectionName Connection name\n     * @param bool $dropTables Drop all tables prior to loading schema files\n     * @param bool $truncateTables Truncate all tables after loading schema files\n     * @return void\n     */\n    public function loadSqlFiles(\n        array|string $paths,\n        string $connectionName = 'test',\n        bool $dropTables = true,\n        bool $truncateTables = false,\n    ): void {\n        $files = (array)$paths;\n\n        // Don't create schema if we are in a phpunit separate process test method.\n        if (isset($GLOBALS['__PHPUNIT_BOOTSTRAP'])) {\n            return;\n        }\n\n        if ($dropTables) {\n            ConnectionHelper::dropTables($connectionName);\n        }\n\n        /** @var \\Cake\\Database\\Connection $connection */\n        $connection = ConnectionManager::get($connectionName);\n        foreach ($files as $file) {\n            if (!file_exists($file)) {\n                throw new InvalidArgumentException(sprintf('Unable to load SQL file `%s`.', $file));\n            }\n            $sql = file_get_contents($file);\n            if ($sql === false) {\n                throw new CakeException(sprintf('Cannot read file content of `%s`', $file));\n            }\n\n            // Use the underlying PDO connection so we can avoid prepared statements\n            // which don't support multiple queries in postgres.\n            $driver = $connection->getDriver();\n            $driver->exec($sql);\n        }\n\n        if ($truncateTables) {\n            ConnectionHelper::truncateTables($connectionName);\n        }\n    }\n\n    /**\n     * Load and apply CakePHP schema file.\n     *\n     * This method will process the array returned by `$file` and treat\n     * the contents as a list of table schema.\n     *\n     * An example table is:\n     *\n     * ```\n     * return [\n     *   'articles' => [\n     *      'columns' => [\n     *          'id' => [\n     *              'type' => 'integer',\n     *          ],\n     *          'author_id' => [\n     *              'type' => 'integer',\n     *              'null' => true,\n     *          ],\n     *          'title' => [\n     *              'type' => 'string',\n     *              'null' => true,\n     *          ],\n     *          'body' => 'text',\n     *          'published' => [\n     *              'type' => 'string',\n     *              'length' => 1,\n     *              'default' => 'N',\n     *          ],\n     *      ],\n     *      'constraints' => [\n     *          'primary' => [\n     *              'type' => 'primary',\n     *              'columns' => [\n     *                  'id',\n     *              ],\n     *          ],\n     *      ],\n     *   ],\n     * ];\n     * ```\n     *\n     * This schema format can be useful for plugins that want to include\n     * tables to test against but don't need to include production\n     * ready schema via migrations. Applications should favour using migrations\n     * or SQL dump files over this format for ease of maintenance.\n     *\n     * A more complete example can be found in `tests/schema.php`.\n     *\n     * @param string $file Schema file\n     * @param string $connectionName Connection name\n     * @throws \\InvalidArgumentException For missing table name(s).\n     * @return void\n     */\n    public function loadInternalFile(string $file, string $connectionName = 'test'): void\n    {\n        // Don't reload schema when we are in a separate process state.\n        if (isset($GLOBALS['__PHPUNIT_BOOTSTRAP'])) {\n            return;\n        }\n\n        ConnectionHelper::dropTables($connectionName);\n\n        $tables = include $file;\n\n        /**\n         * @var \\Cake\\Database\\Connection $connection\n         */\n        $connection = ConnectionManager::get($connectionName);\n        $connection->disableConstraints(function (Connection $connection) use ($tables): void {\n            foreach ($tables as $tableName => $table) {\n                $name = $table['table'] ?? $tableName;\n                if (!is_string($name)) {\n                    throw new InvalidArgumentException(\n                        sprintf('`%s` is not a valid table name. Either use a string key for the table definition'\n                            . \"(`'articles' => [...]`) or define the `table` key in the table definition.\", $name),\n                    );\n                }\n                $schema = new TableSchema($name, $table['columns']);\n                if (isset($table['indexes'])) {\n                    foreach ($table['indexes'] as $key => $index) {\n                        $schema->addIndex($key, $index);\n                    }\n                }\n                if (isset($table['constraints'])) {\n                    foreach ($table['constraints'] as $key => $index) {\n                        $schema->addConstraint($key, $index);\n                    }\n                }\n\n                // Generate SQL for each table.\n                foreach ($schema->createSql($connection) as $sql) {\n                    $connection->execute($sql);\n                }\n            }\n        });\n    }\n}",
    "repo": "cakephp/cakephp",
    "path": "./datasets/diagrams-repos/cakephp/cakephp/src/TestSuite/Fixture/SchemaLoader.php",
    "query": "What is the structure of the SchemaLoader class and its main methods?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'SchemaLoader', 'node_id': 'SchemaLoader', 'description': 'Creates test database schema from SQL dump files or schema definitions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'loadSqlFiles', 'node_id': 'loadSqlFiles', 'description': 'Loads and applies schema from SQL files', 'visibility': 'public', 'return_type': 'void', 'params': 'array|string $paths, string $connectionName, bool $dropTables, bool $truncateTables', 'source_class_id': 'SchemaLoader'}, {'type': 'method', 'name': 'loadInternalFile', 'node_id': 'loadInternalFile', 'description': 'Loads and applies schema from CakePHP schema file', 'visibility': 'public', 'return_type': 'void', 'params': 'string $file, string $connectionName', 'source_class_id': 'SchemaLoader'}, {'type': 'class', 'name': 'ConnectionManager', 'node_id': 'ConnectionManager', 'description': 'Manages database connections', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'ConnectionHelper', 'node_id': 'ConnectionHelper', 'description': 'Helps with database connection operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'SchemaLoader', 'node_id_to': 'loadSqlFiles', 'description': 'contains'}, {'node_id_from': 'SchemaLoader', 'node_id_to': 'loadInternalFile', 'description': 'contains'}, {'node_id_from': 'loadSqlFiles', 'node_id_to': 'ConnectionManager', 'description': 'uses'}, {'node_id_from': 'loadInternalFile', 'node_id_to': 'ConnectionManager', 'description': 'uses'}, {'node_id_from': 'loadSqlFiles', 'node_id_to': 'ConnectionHelper', 'description': 'uses'}, {'node_id_from': 'loadInternalFile', 'node_id_to': 'ConnectionHelper', 'description': 'uses'}], 'packages': [{'package_id': 'schemaManagement', 'children': ['SchemaLoader', 'loadSqlFiles', 'loadInternalFile'], 'description': 'Core schema loading functionality'}, {'package_id': 'databaseConnection', 'children': ['ConnectionManager', 'ConnectionHelper'], 'description': 'Database connection management'}]}",
    "version": "medium",
    "text_answer": "SchemaLoader is a class that manages test database schema creation with two main methods: loadSqlFiles for loading schema from SQL files and loadInternalFile for loading schema from CakePHP schema definitions. It works with database connections and can handle table operations like dropping and truncating.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "PHP",
    "code": "\n<?php\ndeclare(strict_types=1);\n\n/**\n * CakePHP(tm) : Rapid Development Framework (https://cakephp.org)\n * Copyright (c) Cake Software Foundation, Inc. (https://cakefoundation.org)\n *\n * Licensed under The MIT License\n * For full copyright and license information, please see the LICENSE.txt\n * Redistributions of files must retain the above copyright notice\n *\n * @copyright     Copyright (c) Cake Software Foundation, Inc. (https://cakefoundation.org)\n * @since         4.3.0\n * @license       https://opensource.org/licenses/mit-license.php MIT License\n */\nnamespace Cake\\TestSuite\\Fixture;\n\nuse Cake\\Core\\Exception\\CakeException;\nuse Cake\\Database\\Connection;\nuse Cake\\Database\\Schema\\TableSchema;\nuse Cake\\Datasource\\ConnectionManager;\nuse Cake\\TestSuite\\ConnectionHelper;\nuse InvalidArgumentException;\n\n/**\n * Create test database schema from one or more SQL dump files.\n *\n * This class can be useful to create test database schema when\n * your schema is managed by tools external to your CakePHP\n * application.\n *\n * It is not well suited for applications/plugins that need to\n * support multiple database platforms. You should use migrations\n * for that instead.\n */\nclass SchemaLoader\n{\n    /**\n     * Load and apply schema sql file, or an array of files.\n     *\n     * @param array<string>|string $paths Schema files to load\n     * @param string $connectionName Connection name\n     * @param bool $dropTables Drop all tables prior to loading schema files\n     * @param bool $truncateTables Truncate all tables after loading schema files\n     * @return void\n     */\n    public function loadSqlFiles(\n        array|string $paths,\n        string $connectionName = 'test',\n        bool $dropTables = true,\n        bool $truncateTables = false,\n    ): void {\n        $files = (array)$paths;\n\n        // Don't create schema if we are in a phpunit separate process test method.\n        if (isset($GLOBALS['__PHPUNIT_BOOTSTRAP'])) {\n            return;\n        }\n\n        if ($dropTables) {\n            ConnectionHelper::dropTables($connectionName);\n        }\n\n        /** @var \\Cake\\Database\\Connection $connection */\n        $connection = ConnectionManager::get($connectionName);\n        foreach ($files as $file) {\n            if (!file_exists($file)) {\n                throw new InvalidArgumentException(sprintf('Unable to load SQL file `%s`.', $file));\n            }\n            $sql = file_get_contents($file);\n            if ($sql === false) {\n                throw new CakeException(sprintf('Cannot read file content of `%s`', $file));\n            }\n\n            // Use the underlying PDO connection so we can avoid prepared statements\n            // which don't support multiple queries in postgres.\n            $driver = $connection->getDriver();\n            $driver->exec($sql);\n        }\n\n        if ($truncateTables) {\n            ConnectionHelper::truncateTables($connectionName);\n        }\n    }\n\n    /**\n     * Load and apply CakePHP schema file.\n     *\n     * This method will process the array returned by `$file` and treat\n     * the contents as a list of table schema.\n     *\n     * An example table is:\n     *\n     * ```\n     * return [\n     *   'articles' => [\n     *      'columns' => [\n     *          'id' => [\n     *              'type' => 'integer',\n     *          ],\n     *          'author_id' => [\n     *              'type' => 'integer',\n     *              'null' => true,\n     *          ],\n     *          'title' => [\n     *              'type' => 'string',\n     *              'null' => true,\n     *          ],\n     *          'body' => 'text',\n     *          'published' => [\n     *              'type' => 'string',\n     *              'length' => 1,\n     *              'default' => 'N',\n     *          ],\n     *      ],\n     *      'constraints' => [\n     *          'primary' => [\n     *              'type' => 'primary',\n     *              'columns' => [\n     *                  'id',\n     *              ],\n     *          ],\n     *      ],\n     *   ],\n     * ];\n     * ```\n     *\n     * This schema format can be useful for plugins that want to include\n     * tables to test against but don't need to include production\n     * ready schema via migrations. Applications should favour using migrations\n     * or SQL dump files over this format for ease of maintenance.\n     *\n     * A more complete example can be found in `tests/schema.php`.\n     *\n     * @param string $file Schema file\n     * @param string $connectionName Connection name\n     * @throws \\InvalidArgumentException For missing table name(s).\n     * @return void\n     */\n    public function loadInternalFile(string $file, string $connectionName = 'test'): void\n    {\n        // Don't reload schema when we are in a separate process state.\n        if (isset($GLOBALS['__PHPUNIT_BOOTSTRAP'])) {\n            return;\n        }\n\n        ConnectionHelper::dropTables($connectionName);\n\n        $tables = include $file;\n\n        /**\n         * @var \\Cake\\Database\\Connection $connection\n         */\n        $connection = ConnectionManager::get($connectionName);\n        $connection->disableConstraints(function (Connection $connection) use ($tables): void {\n            foreach ($tables as $tableName => $table) {\n                $name = $table['table'] ?? $tableName;\n                if (!is_string($name)) {\n                    throw new InvalidArgumentException(\n                        sprintf('`%s` is not a valid table name. Either use a string key for the table definition'\n                            . \"(`'articles' => [...]`) or define the `table` key in the table definition.\", $name),\n                    );\n                }\n                $schema = new TableSchema($name, $table['columns']);\n                if (isset($table['indexes'])) {\n                    foreach ($table['indexes'] as $key => $index) {\n                        $schema->addIndex($key, $index);\n                    }\n                }\n                if (isset($table['constraints'])) {\n                    foreach ($table['constraints'] as $key => $index) {\n                        $schema->addConstraint($key, $index);\n                    }\n                }\n\n                // Generate SQL for each table.\n                foreach ($schema->createSql($connection) as $sql) {\n                    $connection->execute($sql);\n                }\n            }\n        });\n    }\n}",
    "repo": "cakephp/cakephp",
    "path": "./datasets/diagrams-repos/cakephp/cakephp/src/TestSuite/Fixture/SchemaLoader.php",
    "query": "What is the structure of the SchemaLoader class and its main methods?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'SchemaLoader', 'node_id': 'SchemaLoader', 'description': 'Creates test database schema from SQL dump files or schema definitions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'loadSqlFiles', 'node_id': 'loadSqlFiles', 'description': 'Loads and applies schema from SQL files', 'visibility': 'public', 'return_type': 'void', 'params': 'array|string $paths, string $connectionName, bool $dropTables, bool $truncateTables', 'source_class_id': 'SchemaLoader'}, {'type': 'method', 'name': 'loadInternalFile', 'node_id': 'loadInternalFile', 'description': 'Loads and applies schema from CakePHP schema file', 'visibility': 'public', 'return_type': 'void', 'params': 'string $file, string $connectionName', 'source_class_id': 'SchemaLoader'}, {'type': 'class', 'name': 'ConnectionManager', 'node_id': 'ConnectionManager', 'description': 'Manages database connections', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'ConnectionHelper', 'node_id': 'ConnectionHelper', 'description': 'Helps with database connection operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'TableSchema', 'node_id': 'TableSchema', 'description': 'Represents database table schema', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'Connection', 'node_id': 'Connection', 'description': 'Represents database connection', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'CakeException', 'node_id': 'CakeException', 'description': 'CakePHP specific exception', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'InvalidArgumentException', 'node_id': 'InvalidArgumentException', 'description': 'Exception for invalid arguments', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'SchemaLoader', 'node_id_to': 'loadSqlFiles', 'description': 'contains'}, {'node_id_from': 'SchemaLoader', 'node_id_to': 'loadInternalFile', 'description': 'contains'}, {'node_id_from': 'loadSqlFiles', 'node_id_to': 'ConnectionManager', 'description': 'uses'}, {'node_id_from': 'loadInternalFile', 'node_id_to': 'ConnectionManager', 'description': 'uses'}, {'node_id_from': 'loadSqlFiles', 'node_id_to': 'ConnectionHelper', 'description': 'uses'}, {'node_id_from': 'loadInternalFile', 'node_id_to': 'ConnectionHelper', 'description': 'uses'}, {'node_id_from': 'loadInternalFile', 'node_id_to': 'TableSchema', 'description': 'creates'}, {'node_id_from': 'loadSqlFiles', 'node_id_to': 'Connection', 'description': 'uses'}, {'node_id_from': 'loadInternalFile', 'node_id_to': 'Connection', 'description': 'uses'}, {'node_id_from': 'loadSqlFiles', 'node_id_to': 'CakeException', 'description': 'throws'}, {'node_id_from': 'loadSqlFiles', 'node_id_to': 'InvalidArgumentException', 'description': 'throws'}, {'node_id_from': 'loadInternalFile', 'node_id_to': 'InvalidArgumentException', 'description': 'throws'}], 'packages': [{'package_id': 'schemaManagement', 'children': ['SchemaLoader', 'loadSqlFiles', 'loadInternalFile'], 'description': 'Core schema loading functionality'}, {'package_id': 'databaseConnection', 'children': ['ConnectionManager', 'ConnectionHelper', 'Connection'], 'description': 'Database connection management'}, {'package_id': 'exceptions', 'children': ['CakeException', 'InvalidArgumentException'], 'description': 'Exception handling'}]}",
    "version": "full",
    "text_answer": "SchemaLoader is a class that manages test database schema creation with two main methods: loadSqlFiles for loading schema from SQL files and loadInternalFile for loading schema from CakePHP schema definitions. It works with database connections and can handle table operations like dropping and truncating.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include <platform/internal/CHIPDeviceLayerInternal.h>\n\n#include <lib/core/ErrorStr.h>\n#include <lib/support/CodeUtils.h>\n#include <lib/support/logging/CHIPLogging.h>\n#include <platform/ESP32/ESP32Utils.h>\n\n#include \"esp_event.h\"\n#include \"esp_netif.h\"\n#include \"esp_netif_net_stack.h\"\n#include \"esp_wifi.h\"\n#include \"nvs.h\"\n\nusing namespace ::chip::DeviceLayer::Internal;\nusing chip::DeviceLayer::Internal::DeviceNetworkInfo;\n#if CHIP_DEVICE_CONFIG_ENABLE_WIFI\nCHIP_ERROR ESP32Utils::IsAPEnabled(bool & apEnabled)\n{\n#if CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n    wifi_mode_t curWiFiMode;\n\n    esp_err_t err = esp_wifi_get_mode(&curWiFiMode);\n    if (err != ESP_OK)\n    {\n        ChipLogError(DeviceLayer, \"esp_wifi_get_mode() failed: %s\", esp_err_to_name(err));\n        return ESP32Utils::MapError(err);\n    }\n\n    apEnabled = (curWiFiMode == WIFI_MODE_AP || curWiFiMode == WIFI_MODE_APSTA);\n\n    return CHIP_NO_ERROR;\n#else\n    return CHIP_ERROR_NOT_IMPLEMENTED;\n#endif // CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n}\n\nCHIP_ERROR ESP32Utils::IsStationEnabled(bool & staEnabled)\n{\n    wifi_mode_t curWiFiMode;\n    esp_err_t err = esp_wifi_get_mode(&curWiFiMode);\n    if (err != ESP_OK)\n    {\n        ChipLogError(DeviceLayer, \"esp_wifi_get_mode() failed: %s\", esp_err_to_name(err));\n        return ESP32Utils::MapError(err);\n    }\n\n    staEnabled = (curWiFiMode == WIFI_MODE_STA || curWiFiMode == WIFI_MODE_APSTA);\n\n    return CHIP_NO_ERROR;\n}\n\nbool ESP32Utils::IsStationProvisioned(void)\n{\n    wifi_config_t stationConfig;\n    return (esp_wifi_get_config(WIFI_IF_STA, &stationConfig) == ERR_OK && stationConfig.sta.ssid[0] != 0);\n}\n\nCHIP_ERROR ESP32Utils::IsStationConnected(bool & connected)\n{\n    wifi_ap_record_t apInfo;\n    connected = (esp_wifi_sta_get_ap_info(&apInfo) == ESP_OK && apInfo.ssid[0] != 0);\n    return CHIP_NO_ERROR;\n}\n\nCHIP_ERROR ESP32Utils::StartWiFiLayer(void)\n{\n    int8_t ignored;\n    bool wifiStarted;\n\n    // There appears to be no direct way to ask the ESP WiFi layer if esp_wifi_start()\n    // has been called.  So use the ESP_ERR_WIFI_NOT_STARTED error returned by\n    // esp_wifi_get_max_tx_power() to detect this.\n    esp_err_t err = esp_wifi_get_max_tx_power(&ignored);\n    switch (err)\n    {\n    case ESP_OK:\n        wifiStarted = true;\n        break;\n    case ESP_ERR_WIFI_NOT_STARTED:\n        wifiStarted = false;\n        break;\n    default:\n        return ESP32Utils::MapError(err);\n    }\n\n    if (!wifiStarted)\n    {\n        ChipLogProgress(DeviceLayer, \"Starting ESP WiFi layer\");\n\n        err = esp_wifi_start();\n        if (err != ESP_OK)\n        {\n            ChipLogError(DeviceLayer, \"esp_wifi_start() failed: %s\", esp_err_to_name(err));\n            return ESP32Utils::MapError(err);\n        }\n    }\n\n    return CHIP_NO_ERROR;\n}\n\nCHIP_ERROR ESP32Utils::EnableStationMode(void)\n{\n    wifi_mode_t curWiFiMode;\n\n    // Get the current ESP WiFI mode.\n    esp_err_t err = esp_wifi_get_mode(&curWiFiMode);\n    if (err != ESP_OK)\n    {\n        ChipLogError(DeviceLayer, \"esp_wifi_get_mode() failed: %s\", esp_err_to_name(err));\n        return ESP32Utils::MapError(err);\n    }\n\n#if CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n    // If station mode is not already enabled (implying the current mode is WIFI_MODE_AP), change\n    // the mode to WIFI_MODE_APSTA.\n    if (curWiFiMode == WIFI_MODE_AP)\n    {\n        ChipLogProgress(DeviceLayer, \"Changing ESP WiFi mode: %s -> %s\", WiFiModeToStr(WIFI_MODE_AP),\n                        WiFiModeToStr(WIFI_MODE_APSTA));\n\n        err = esp_wifi_set_mode(WIFI_MODE_APSTA);\n        if (err != ESP_OK)\n        {\n            ChipLogError(DeviceLayer, \"esp_wifi_set_mode() failed: %s\", esp_err_to_name(err));\n            return ESP32Utils::MapError(err);\n        }\n    }\n#endif // CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n\n    return CHIP_NO_ERROR;\n}\n\nCHIP_ERROR ESP32Utils::SetAPMode(bool enabled)\n{\n    wifi_mode_t curWiFiMode;\n    wifi_mode_t targetWiFiMode = WIFI_MODE_STA;\n\n#if CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n    targetWiFiMode = (enabled) ? WIFI_MODE_APSTA : WIFI_MODE_STA;\n#endif // CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n\n    // Get the current ESP WiFI mode.\n    esp_err_t err = esp_wifi_get_mode(&curWiFiMode);\n    if (err != ESP_OK)\n    {\n        ChipLogError(DeviceLayer, \"esp_wifi_get_mode() failed: %s\", esp_err_to_name(err));\n        return ESP32Utils::MapError(err);\n    }\n\n    // If station mode is not already enabled (implying the current mode is WIFI_MODE_AP), change\n    // the mode to WIFI_MODE_APSTA.\n    if (curWiFiMode != targetWiFiMode)\n    {\n        ChipLogProgress(DeviceLayer, \"Changing ESP WiFi mode: %s -> %s\", WiFiModeToStr(curWiFiMode), WiFiModeToStr(targetWiFiMode));\n\n        err = esp_wifi_set_mode(targetWiFiMode);\n        if (err != ESP_OK)\n        {\n            ChipLogError(DeviceLayer, \"esp_wifi_set_mode() failed: %s\", esp_err_to_name(err));\n            return ESP32Utils::MapError(err);\n        }\n    }\n\n    return CHIP_NO_ERROR;\n}\n\nint ESP32Utils::OrderScanResultsByRSSI(const void * _res1, const void * _res2)\n{\n    const wifi_ap_record_t * res1 = (const wifi_ap_record_t *) _res1;\n    const wifi_ap_record_t * res2 = (const wifi_ap_record_t *) _res2;\n\n    if (res1->rssi > res2->rssi)\n    {\n        return -1;\n    }\n    if (res1->rssi < res2->rssi)\n    {\n        return 1;\n    }\n    return 0;\n}\n\nconst char * ESP32Utils::WiFiModeToStr(wifi_mode_t wifiMode)\n{\n    switch (wifiMode)\n    {\n    case WIFI_MODE_NULL:\n        return \"NULL\";\n    case WIFI_MODE_STA:\n        return \"STA\";\n    case WIFI_MODE_AP:\n        return \"AP\";\n    case WIFI_MODE_APSTA:\n        return \"STA+AP\";\n    default:\n        return \"(unknown)\";\n    }\n}\n\nstruct netif * ESP32Utils::GetStationNetif(void)\n{\n    return GetNetif(kDefaultWiFiStationNetifKey);\n}\n\nCHIP_ERROR ESP32Utils::GetWiFiStationProvision(Internal::DeviceNetworkInfo & netInfo, bool includeCredentials)\n{\n    wifi_config_t stationConfig;\n\n    esp_err_t err = esp_wifi_get_config(WIFI_IF_STA, &stationConfig);\n    if (err != ESP_OK)\n    {\n        return ESP32Utils::MapError(err);\n    }\n\n    VerifyOrReturnError(stationConfig.sta.ssid[0] != 0, CHIP_ERROR_INCORRECT_STATE);\n\n    netInfo.NetworkId              = kWiFiStationNetworkId;\n    netInfo.FieldPresent.NetworkId = true;\n    memcpy(netInfo.WiFiSSID, stationConfig.sta.ssid,\n           std::min(strlen(reinterpret_cast<char *>(stationConfig.sta.ssid)) + 1, sizeof(netInfo.WiFiSSID)));\n\n    // Enforce that netInfo wifiSSID is null terminated\n    netInfo.WiFiSSID[kMaxWiFiSSIDLength] = '\\0';\n\n    if (includeCredentials)\n    {\n        static_assert(sizeof(netInfo.WiFiKey) < 255, \"Our min might not fit in netInfo.WiFiKeyLen\");\n        netInfo.WiFiKeyLen = static_cast<uint8_t>(std::min(strlen((char *) stationConfig.sta.password), sizeof(netInfo.WiFiKey)));\n        memcpy(netInfo.WiFiKey, stationConfig.sta.password, netInfo.WiFiKeyLen);\n    }\n\n    return CHIP_NO_ERROR;\n}\n\nCHIP_ERROR ESP32Utils::SetWiFiStationProvision(const Internal::DeviceNetworkInfo & netInfo)\n{\n    wifi_config_t wifiConfig;\n\n    char wifiSSID[kMaxWiFiSSIDLength + 1];\n    size_t netInfoSSIDLen = strlen(netInfo.WiFiSSID);\n\n    // Ensure that ESP station mode is enabled.  This is required before esp_wifi_set_config(ESP_IF_WIFI_STA,...)\n    // can be called.\n    ReturnErrorOnFailure(ESP32Utils::EnableStationMode());\n\n    // Enforce that wifiSSID is null terminated before copying it\n    memcpy(wifiSSID, netInfo.WiFiSSID, std::min(netInfoSSIDLen + 1, sizeof(wifiSSID)));\n    if (netInfoSSIDLen + 1 < sizeof(wifiSSID))\n    {\n        wifiSSID[netInfoSSIDLen] = '\\0';\n    }\n    else\n    {\n        wifiSSID[kMaxWiFiSSIDLength] = '\\0';\n    }\n\n    // Initialize an ESP wifi_config_t structure based on the new provision information.\n    memset(&wifiConfig, 0, sizeof(wifiConfig));\n    memcpy(wifiConfig.sta.ssid, wifiSSID, std::min(strlen(wifiSSID) + 1, sizeof(wifiConfig.sta.ssid)));\n    memcpy(wifiConfig.sta.password, netInfo.WiFiKey, std::min((size_t) netInfo.WiFiKeyLen, sizeof(wifiConfig.sta.password)));\n    wifiConfig.sta.scan_method = WIFI_ALL_CHANNEL_SCAN;\n    wifiConfig.sta.sort_method = WIFI_CONNECT_AP_BY_SIGNAL;\n\n    // Configure the ESP WiFi interface.\n    esp_err_t err = esp_wifi_set_config(WIFI_IF_STA, &wifiConfig);\n    if (err != ESP_OK)\n    {\n        ChipLogError(DeviceLayer, \"esp_wifi_set_config() failed: %s\", esp_err_to_name(err));\n        return ESP32Utils::MapError(err);\n    }\n\n    ChipLogProgress(DeviceLayer, \"WiFi station provision set (SSID: %s)\", netInfo.WiFiSSID);\n\n    return CHIP_NO_ERROR;\n}\n\nCHIP_ERROR ESP32Utils::ClearWiFiStationProvision(void)\n{\n    wifi_config_t stationConfig;\n\n    // Clear the ESP WiFi station configuration.\n    memset(&stationConfig, 0, sizeof(stationConfig));\n    esp_wifi_set_config(WIFI_IF_STA, &stationConfig);\n\n    return CHIP_NO_ERROR;\n}\n\nCHIP_ERROR ESP32Utils::InitWiFiStack(void)\n{\n    wifi_init_config_t cfg;\n    uint8_t ap_mac[6];\n    wifi_mode_t mode;\n    esp_err_t err = esp_netif_init();\n    if (err != ESP_OK)\n    {\n        return ESP32Utils::MapError(err);\n    }\n\n#if CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n    // Lets not create a default AP interface if already present\n    if (!esp_netif_get_handle_from_ifkey(kDefaultWiFiAPNetifKey))\n    {\n        if (!esp_netif_create_default_wifi_ap())\n        {\n            ChipLogError(DeviceLayer, \"Failed to create the WiFi AP netif\");\n            return CHIP_ERROR_INTERNAL;\n        }\n    }\n#endif // CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n\n    // Lets not create a default station interface if already present\n    if (!esp_netif_get_handle_from_ifkey(kDefaultWiFiStationNetifKey))\n    {\n        if (!esp_netif_create_default_wifi_sta())\n        {\n            ChipLogError(DeviceLayer, \"Failed to create the WiFi STA netif\");\n            return CHIP_ERROR_INTERNAL;\n        }\n    }\n\n    // Initialize the ESP WiFi layer.\n    cfg = WIFI_INIT_CONFIG_DEFAULT();\n    err = esp_wifi_init(&cfg);\n    if (err != ESP_OK)\n    {\n        return ESP32Utils::MapError(err);\n    }\n\n    esp_wifi_get_mode(&mode);\n    if ((mode == WIFI_MODE_AP) || (mode == WIFI_MODE_APSTA))\n    {\n        esp_fill_random(ap_mac, sizeof(ap_mac));\n        /* Bit 0 of the first octet of MAC Address should always be 0 */\n        ap_mac[0] &= (uint8_t) ~0x01;\n        err = esp_wifi_set_mac(WIFI_IF_AP, ap_mac);\n        if (err != ESP_OK)\n        {\n            return ESP32Utils::MapError(err);\n        }\n    }\n    err = esp_event_handler_register(WIFI_EVENT, ESP_EVENT_ANY_ID, PlatformManagerImpl::HandleESPSystemEvent, NULL);\n    if (err != ESP_OK)\n    {\n        return ESP32Utils::MapError(err);\n    }\n    return CHIP_NO_ERROR;\n}\n#endif // CHIP_DEVICE_CONFIG_ENABLE_WIFI\n\nstruct netif * ESP32Utils::GetNetif(const char * ifKey)\n{\n    struct netif * netif       = NULL;\n    esp_netif_t * netif_handle = NULL;\n    netif_handle               = esp_netif_get_handle_from_ifkey(ifKey);\n    netif                      = (struct netif *) esp_netif_get_netif_impl(netif_handle);\n    return netif;\n}\n\nbool ESP32Utils::IsInterfaceUp(const char * ifKey)\n{\n    struct netif * netif = GetNetif(ifKey);\n    return netif != NULL && netif_is_up(netif);\n}\n\nbool ESP32Utils::HasIPv6LinkLocalAddress(const char * ifKey)\n{\n    struct esp_ip6_addr if_ip6_unused;\n    return esp_netif_get_ip6_linklocal(esp_netif_get_handle_from_ifkey(ifKey), &if_ip6_unused) == ESP_OK;\n}\n\nCHIP_ERROR ESP32Utils::MapError(esp_err_t error)\n{\n    if (error == ESP_OK)\n    {\n        return CHIP_NO_ERROR;\n    }\n    if (error == ESP_ERR_NVS_NOT_FOUND)\n    {\n        return CHIP_ERROR_PERSISTED_STORAGE_VALUE_NOT_FOUND;\n    }\n    if (error == ESP_ERR_NVS_INVALID_LENGTH)\n    {\n        return CHIP_ERROR_BUFFER_TOO_SMALL;\n    }\n    return CHIP_ERROR(ChipError::Range::kPlatform, error);\n}\n\n/**\n * Given a CHIP error value that represents an ESP32 error, returns a\n * human-readable NULL-terminated C string describing the error.\n *\n * @param[in] buf                   Buffer into which the error string will be placed.\n * @param[in] bufSize               Size of the supplied buffer in bytes.\n * @param[in] err                   The error to be described.\n *\n * @return true                     If a description string was written into the supplied buffer.\n * @return false                    If the supplied error was not an ESP32 error.\n *\n */\nbool ESP32Utils::FormatError(char * buf, uint16_t bufSize, CHIP_ERROR err)\n{\n    if (!err.IsRange(ChipError::Range::kPlatform))\n    {\n        return false;\n    }\n\n#if CHIP_CONFIG_SHORT_ERROR_STR\n    const char * desc = NULL;\n#else  // CHIP_CONFIG_SHORT_ERROR_STR\n    const char * desc = esp_err_to_name((esp_err_t) err.GetValue());\n#endif // CHIP_CONFIG_SHORT_ERROR_STR\n\n    chip::FormatError(buf, bufSize, \"ESP32\", err, desc);\n\n    return true;\n}\n\n/**\n * Register a text error formatter for ESP32 errors.\n */\nvoid ESP32Utils::RegisterESP32ErrorFormatter()\n{\n    static ErrorFormatter sErrorFormatter = { ESP32Utils::FormatError, NULL };\n\n    RegisterErrorFormatter(&sErrorFormatter);\n}",
    "repo": "project-chip/connectedhomeip",
    "path": "./datasets/diagrams-repos/project-chip/connectedhomeip/examples/platform/esp32/external_platform/ESP32_custom/ESP32Utils.cpp",
    "query": "What is the interaction between the CHIP framework and ESP32's Wi-Fi stack?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'ESP32Utils', 'node_id': 'ESP32Utils', 'description': 'Utility class managing interactions between CHIP and ESP32 WiFi', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'InitWiFiStack', 'node_id': 'InitWiFiStack', 'description': 'Initializes ESP32 WiFi stack and creates network interfaces', 'visibility': 'public', 'return_type': 'CHIP_ERROR', 'params': 'void', 'source_class_id': 'ESP32Utils'}, {'type': 'method', 'name': 'StartWiFiLayer', 'node_id': 'StartWiFiLayer', 'description': 'Starts ESP32 WiFi layer if not already started', 'visibility': 'public', 'return_type': 'CHIP_ERROR', 'params': 'void', 'source_class_id': 'ESP32Utils'}, {'type': 'function', 'name': 'esp_wifi_init', 'node_id': 'esp_wifi_init', 'description': 'ESP32 SDK function to initialize WiFi', 'visibility': 'public', 'return_type': 'esp_err_t', 'params': 'wifi_init_config_t*', 'source_class_id': None}], 'edges': [{'node_id_from': 'InitWiFiStack', 'node_id_to': 'esp_wifi_init', 'description': 'initializes WiFi stack'}, {'node_id_from': 'ESP32Utils', 'node_id_to': 'InitWiFiStack', 'description': ''}, {'node_id_from': 'ESP32Utils', 'node_id_to': 'StartWiFiLayer', 'description': ''}], 'packages': [{'package_id': 'WiFiManagement', 'children': ['ESP32Utils', 'InitWiFiStack', 'StartWiFiLayer', 'esp_wifi_init'], 'description': 'Core WiFi management functionality'}]}",
    "version": "minimal",
    "text_answer": "The CHIP framework interacts with ESP32's Wi-Fi stack through the ESP32Utils class, which provides a wrapper layer for WiFi operations. The main interaction flow starts with InitWiFiStack initializing the ESP32 WiFi stack, followed by StartWiFiLayer enabling the WiFi functionality. The framework manages both station and AP modes, handles WiFi configurations, and provides error mapping between ESP32 and CHIP error codes.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include <platform/internal/CHIPDeviceLayerInternal.h>\n\n#include <lib/core/ErrorStr.h>\n#include <lib/support/CodeUtils.h>\n#include <lib/support/logging/CHIPLogging.h>\n#include <platform/ESP32/ESP32Utils.h>\n\n#include \"esp_event.h\"\n#include \"esp_netif.h\"\n#include \"esp_netif_net_stack.h\"\n#include \"esp_wifi.h\"\n#include \"nvs.h\"\n\nusing namespace ::chip::DeviceLayer::Internal;\nusing chip::DeviceLayer::Internal::DeviceNetworkInfo;\n#if CHIP_DEVICE_CONFIG_ENABLE_WIFI\nCHIP_ERROR ESP32Utils::IsAPEnabled(bool & apEnabled)\n{\n#if CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n    wifi_mode_t curWiFiMode;\n\n    esp_err_t err = esp_wifi_get_mode(&curWiFiMode);\n    if (err != ESP_OK)\n    {\n        ChipLogError(DeviceLayer, \"esp_wifi_get_mode() failed: %s\", esp_err_to_name(err));\n        return ESP32Utils::MapError(err);\n    }\n\n    apEnabled = (curWiFiMode == WIFI_MODE_AP || curWiFiMode == WIFI_MODE_APSTA);\n\n    return CHIP_NO_ERROR;\n#else\n    return CHIP_ERROR_NOT_IMPLEMENTED;\n#endif // CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n}\n\nCHIP_ERROR ESP32Utils::IsStationEnabled(bool & staEnabled)\n{\n    wifi_mode_t curWiFiMode;\n    esp_err_t err = esp_wifi_get_mode(&curWiFiMode);\n    if (err != ESP_OK)\n    {\n        ChipLogError(DeviceLayer, \"esp_wifi_get_mode() failed: %s\", esp_err_to_name(err));\n        return ESP32Utils::MapError(err);\n    }\n\n    staEnabled = (curWiFiMode == WIFI_MODE_STA || curWiFiMode == WIFI_MODE_APSTA);\n\n    return CHIP_NO_ERROR;\n}\n\nbool ESP32Utils::IsStationProvisioned(void)\n{\n    wifi_config_t stationConfig;\n    return (esp_wifi_get_config(WIFI_IF_STA, &stationConfig) == ERR_OK && stationConfig.sta.ssid[0] != 0);\n}\n\nCHIP_ERROR ESP32Utils::IsStationConnected(bool & connected)\n{\n    wifi_ap_record_t apInfo;\n    connected = (esp_wifi_sta_get_ap_info(&apInfo) == ESP_OK && apInfo.ssid[0] != 0);\n    return CHIP_NO_ERROR;\n}\n\nCHIP_ERROR ESP32Utils::StartWiFiLayer(void)\n{\n    int8_t ignored;\n    bool wifiStarted;\n\n    // There appears to be no direct way to ask the ESP WiFi layer if esp_wifi_start()\n    // has been called.  So use the ESP_ERR_WIFI_NOT_STARTED error returned by\n    // esp_wifi_get_max_tx_power() to detect this.\n    esp_err_t err = esp_wifi_get_max_tx_power(&ignored);\n    switch (err)\n    {\n    case ESP_OK:\n        wifiStarted = true;\n        break;\n    case ESP_ERR_WIFI_NOT_STARTED:\n        wifiStarted = false;\n        break;\n    default:\n        return ESP32Utils::MapError(err);\n    }\n\n    if (!wifiStarted)\n    {\n        ChipLogProgress(DeviceLayer, \"Starting ESP WiFi layer\");\n\n        err = esp_wifi_start();\n        if (err != ESP_OK)\n        {\n            ChipLogError(DeviceLayer, \"esp_wifi_start() failed: %s\", esp_err_to_name(err));\n            return ESP32Utils::MapError(err);\n        }\n    }\n\n    return CHIP_NO_ERROR;\n}\n\nCHIP_ERROR ESP32Utils::EnableStationMode(void)\n{\n    wifi_mode_t curWiFiMode;\n\n    // Get the current ESP WiFI mode.\n    esp_err_t err = esp_wifi_get_mode(&curWiFiMode);\n    if (err != ESP_OK)\n    {\n        ChipLogError(DeviceLayer, \"esp_wifi_get_mode() failed: %s\", esp_err_to_name(err));\n        return ESP32Utils::MapError(err);\n    }\n\n#if CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n    // If station mode is not already enabled (implying the current mode is WIFI_MODE_AP), change\n    // the mode to WIFI_MODE_APSTA.\n    if (curWiFiMode == WIFI_MODE_AP)\n    {\n        ChipLogProgress(DeviceLayer, \"Changing ESP WiFi mode: %s -> %s\", WiFiModeToStr(WIFI_MODE_AP),\n                        WiFiModeToStr(WIFI_MODE_APSTA));\n\n        err = esp_wifi_set_mode(WIFI_MODE_APSTA);\n        if (err != ESP_OK)\n        {\n            ChipLogError(DeviceLayer, \"esp_wifi_set_mode() failed: %s\", esp_err_to_name(err));\n            return ESP32Utils::MapError(err);\n        }\n    }\n#endif // CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n\n    return CHIP_NO_ERROR;\n}\n\nCHIP_ERROR ESP32Utils::SetAPMode(bool enabled)\n{\n    wifi_mode_t curWiFiMode;\n    wifi_mode_t targetWiFiMode = WIFI_MODE_STA;\n\n#if CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n    targetWiFiMode = (enabled) ? WIFI_MODE_APSTA : WIFI_MODE_STA;\n#endif // CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n\n    // Get the current ESP WiFI mode.\n    esp_err_t err = esp_wifi_get_mode(&curWiFiMode);\n    if (err != ESP_OK)\n    {\n        ChipLogError(DeviceLayer, \"esp_wifi_get_mode() failed: %s\", esp_err_to_name(err));\n        return ESP32Utils::MapError(err);\n    }\n\n    // If station mode is not already enabled (implying the current mode is WIFI_MODE_AP), change\n    // the mode to WIFI_MODE_APSTA.\n    if (curWiFiMode != targetWiFiMode)\n    {\n        ChipLogProgress(DeviceLayer, \"Changing ESP WiFi mode: %s -> %s\", WiFiModeToStr(curWiFiMode), WiFiModeToStr(targetWiFiMode));\n\n        err = esp_wifi_set_mode(targetWiFiMode);\n        if (err != ESP_OK)\n        {\n            ChipLogError(DeviceLayer, \"esp_wifi_set_mode() failed: %s\", esp_err_to_name(err));\n            return ESP32Utils::MapError(err);\n        }\n    }\n\n    return CHIP_NO_ERROR;\n}\n\nint ESP32Utils::OrderScanResultsByRSSI(const void * _res1, const void * _res2)\n{\n    const wifi_ap_record_t * res1 = (const wifi_ap_record_t *) _res1;\n    const wifi_ap_record_t * res2 = (const wifi_ap_record_t *) _res2;\n\n    if (res1->rssi > res2->rssi)\n    {\n        return -1;\n    }\n    if (res1->rssi < res2->rssi)\n    {\n        return 1;\n    }\n    return 0;\n}\n\nconst char * ESP32Utils::WiFiModeToStr(wifi_mode_t wifiMode)\n{\n    switch (wifiMode)\n    {\n    case WIFI_MODE_NULL:\n        return \"NULL\";\n    case WIFI_MODE_STA:\n        return \"STA\";\n    case WIFI_MODE_AP:\n        return \"AP\";\n    case WIFI_MODE_APSTA:\n        return \"STA+AP\";\n    default:\n        return \"(unknown)\";\n    }\n}\n\nstruct netif * ESP32Utils::GetStationNetif(void)\n{\n    return GetNetif(kDefaultWiFiStationNetifKey);\n}\n\nCHIP_ERROR ESP32Utils::GetWiFiStationProvision(Internal::DeviceNetworkInfo & netInfo, bool includeCredentials)\n{\n    wifi_config_t stationConfig;\n\n    esp_err_t err = esp_wifi_get_config(WIFI_IF_STA, &stationConfig);\n    if (err != ESP_OK)\n    {\n        return ESP32Utils::MapError(err);\n    }\n\n    VerifyOrReturnError(stationConfig.sta.ssid[0] != 0, CHIP_ERROR_INCORRECT_STATE);\n\n    netInfo.NetworkId              = kWiFiStationNetworkId;\n    netInfo.FieldPresent.NetworkId = true;\n    memcpy(netInfo.WiFiSSID, stationConfig.sta.ssid,\n           std::min(strlen(reinterpret_cast<char *>(stationConfig.sta.ssid)) + 1, sizeof(netInfo.WiFiSSID)));\n\n    // Enforce that netInfo wifiSSID is null terminated\n    netInfo.WiFiSSID[kMaxWiFiSSIDLength] = '\\0';\n\n    if (includeCredentials)\n    {\n        static_assert(sizeof(netInfo.WiFiKey) < 255, \"Our min might not fit in netInfo.WiFiKeyLen\");\n        netInfo.WiFiKeyLen = static_cast<uint8_t>(std::min(strlen((char *) stationConfig.sta.password), sizeof(netInfo.WiFiKey)));\n        memcpy(netInfo.WiFiKey, stationConfig.sta.password, netInfo.WiFiKeyLen);\n    }\n\n    return CHIP_NO_ERROR;\n}\n\nCHIP_ERROR ESP32Utils::SetWiFiStationProvision(const Internal::DeviceNetworkInfo & netInfo)\n{\n    wifi_config_t wifiConfig;\n\n    char wifiSSID[kMaxWiFiSSIDLength + 1];\n    size_t netInfoSSIDLen = strlen(netInfo.WiFiSSID);\n\n    // Ensure that ESP station mode is enabled.  This is required before esp_wifi_set_config(ESP_IF_WIFI_STA,...)\n    // can be called.\n    ReturnErrorOnFailure(ESP32Utils::EnableStationMode());\n\n    // Enforce that wifiSSID is null terminated before copying it\n    memcpy(wifiSSID, netInfo.WiFiSSID, std::min(netInfoSSIDLen + 1, sizeof(wifiSSID)));\n    if (netInfoSSIDLen + 1 < sizeof(wifiSSID))\n    {\n        wifiSSID[netInfoSSIDLen] = '\\0';\n    }\n    else\n    {\n        wifiSSID[kMaxWiFiSSIDLength] = '\\0';\n    }\n\n    // Initialize an ESP wifi_config_t structure based on the new provision information.\n    memset(&wifiConfig, 0, sizeof(wifiConfig));\n    memcpy(wifiConfig.sta.ssid, wifiSSID, std::min(strlen(wifiSSID) + 1, sizeof(wifiConfig.sta.ssid)));\n    memcpy(wifiConfig.sta.password, netInfo.WiFiKey, std::min((size_t) netInfo.WiFiKeyLen, sizeof(wifiConfig.sta.password)));\n    wifiConfig.sta.scan_method = WIFI_ALL_CHANNEL_SCAN;\n    wifiConfig.sta.sort_method = WIFI_CONNECT_AP_BY_SIGNAL;\n\n    // Configure the ESP WiFi interface.\n    esp_err_t err = esp_wifi_set_config(WIFI_IF_STA, &wifiConfig);\n    if (err != ESP_OK)\n    {\n        ChipLogError(DeviceLayer, \"esp_wifi_set_config() failed: %s\", esp_err_to_name(err));\n        return ESP32Utils::MapError(err);\n    }\n\n    ChipLogProgress(DeviceLayer, \"WiFi station provision set (SSID: %s)\", netInfo.WiFiSSID);\n\n    return CHIP_NO_ERROR;\n}\n\nCHIP_ERROR ESP32Utils::ClearWiFiStationProvision(void)\n{\n    wifi_config_t stationConfig;\n\n    // Clear the ESP WiFi station configuration.\n    memset(&stationConfig, 0, sizeof(stationConfig));\n    esp_wifi_set_config(WIFI_IF_STA, &stationConfig);\n\n    return CHIP_NO_ERROR;\n}\n\nCHIP_ERROR ESP32Utils::InitWiFiStack(void)\n{\n    wifi_init_config_t cfg;\n    uint8_t ap_mac[6];\n    wifi_mode_t mode;\n    esp_err_t err = esp_netif_init();\n    if (err != ESP_OK)\n    {\n        return ESP32Utils::MapError(err);\n    }\n\n#if CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n    // Lets not create a default AP interface if already present\n    if (!esp_netif_get_handle_from_ifkey(kDefaultWiFiAPNetifKey))\n    {\n        if (!esp_netif_create_default_wifi_ap())\n        {\n            ChipLogError(DeviceLayer, \"Failed to create the WiFi AP netif\");\n            return CHIP_ERROR_INTERNAL;\n        }\n    }\n#endif // CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n\n    // Lets not create a default station interface if already present\n    if (!esp_netif_get_handle_from_ifkey(kDefaultWiFiStationNetifKey))\n    {\n        if (!esp_netif_create_default_wifi_sta())\n        {\n            ChipLogError(DeviceLayer, \"Failed to create the WiFi STA netif\");\n            return CHIP_ERROR_INTERNAL;\n        }\n    }\n\n    // Initialize the ESP WiFi layer.\n    cfg = WIFI_INIT_CONFIG_DEFAULT();\n    err = esp_wifi_init(&cfg);\n    if (err != ESP_OK)\n    {\n        return ESP32Utils::MapError(err);\n    }\n\n    esp_wifi_get_mode(&mode);\n    if ((mode == WIFI_MODE_AP) || (mode == WIFI_MODE_APSTA))\n    {\n        esp_fill_random(ap_mac, sizeof(ap_mac));\n        /* Bit 0 of the first octet of MAC Address should always be 0 */\n        ap_mac[0] &= (uint8_t) ~0x01;\n        err = esp_wifi_set_mac(WIFI_IF_AP, ap_mac);\n        if (err != ESP_OK)\n        {\n            return ESP32Utils::MapError(err);\n        }\n    }\n    err = esp_event_handler_register(WIFI_EVENT, ESP_EVENT_ANY_ID, PlatformManagerImpl::HandleESPSystemEvent, NULL);\n    if (err != ESP_OK)\n    {\n        return ESP32Utils::MapError(err);\n    }\n    return CHIP_NO_ERROR;\n}\n#endif // CHIP_DEVICE_CONFIG_ENABLE_WIFI\n\nstruct netif * ESP32Utils::GetNetif(const char * ifKey)\n{\n    struct netif * netif       = NULL;\n    esp_netif_t * netif_handle = NULL;\n    netif_handle               = esp_netif_get_handle_from_ifkey(ifKey);\n    netif                      = (struct netif *) esp_netif_get_netif_impl(netif_handle);\n    return netif;\n}\n\nbool ESP32Utils::IsInterfaceUp(const char * ifKey)\n{\n    struct netif * netif = GetNetif(ifKey);\n    return netif != NULL && netif_is_up(netif);\n}\n\nbool ESP32Utils::HasIPv6LinkLocalAddress(const char * ifKey)\n{\n    struct esp_ip6_addr if_ip6_unused;\n    return esp_netif_get_ip6_linklocal(esp_netif_get_handle_from_ifkey(ifKey), &if_ip6_unused) == ESP_OK;\n}\n\nCHIP_ERROR ESP32Utils::MapError(esp_err_t error)\n{\n    if (error == ESP_OK)\n    {\n        return CHIP_NO_ERROR;\n    }\n    if (error == ESP_ERR_NVS_NOT_FOUND)\n    {\n        return CHIP_ERROR_PERSISTED_STORAGE_VALUE_NOT_FOUND;\n    }\n    if (error == ESP_ERR_NVS_INVALID_LENGTH)\n    {\n        return CHIP_ERROR_BUFFER_TOO_SMALL;\n    }\n    return CHIP_ERROR(ChipError::Range::kPlatform, error);\n}\n\n/**\n * Given a CHIP error value that represents an ESP32 error, returns a\n * human-readable NULL-terminated C string describing the error.\n *\n * @param[in] buf                   Buffer into which the error string will be placed.\n * @param[in] bufSize               Size of the supplied buffer in bytes.\n * @param[in] err                   The error to be described.\n *\n * @return true                     If a description string was written into the supplied buffer.\n * @return false                    If the supplied error was not an ESP32 error.\n *\n */\nbool ESP32Utils::FormatError(char * buf, uint16_t bufSize, CHIP_ERROR err)\n{\n    if (!err.IsRange(ChipError::Range::kPlatform))\n    {\n        return false;\n    }\n\n#if CHIP_CONFIG_SHORT_ERROR_STR\n    const char * desc = NULL;\n#else  // CHIP_CONFIG_SHORT_ERROR_STR\n    const char * desc = esp_err_to_name((esp_err_t) err.GetValue());\n#endif // CHIP_CONFIG_SHORT_ERROR_STR\n\n    chip::FormatError(buf, bufSize, \"ESP32\", err, desc);\n\n    return true;\n}\n\n/**\n * Register a text error formatter for ESP32 errors.\n */\nvoid ESP32Utils::RegisterESP32ErrorFormatter()\n{\n    static ErrorFormatter sErrorFormatter = { ESP32Utils::FormatError, NULL };\n\n    RegisterErrorFormatter(&sErrorFormatter);\n}",
    "repo": "project-chip/connectedhomeip",
    "path": "./datasets/diagrams-repos/project-chip/connectedhomeip/examples/platform/esp32/external_platform/ESP32_custom/ESP32Utils.cpp",
    "query": "What is the interaction between the CHIP framework and ESP32's Wi-Fi stack?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'ESP32Utils', 'node_id': 'ESP32Utils', 'description': 'Utility class managing interactions between CHIP and ESP32 WiFi', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'InitWiFiStack', 'node_id': 'InitWiFiStack', 'description': 'Initializes ESP32 WiFi stack and creates network interfaces', 'visibility': 'public', 'return_type': 'CHIP_ERROR', 'params': 'void', 'source_class_id': 'ESP32Utils'}, {'type': 'method', 'name': 'StartWiFiLayer', 'node_id': 'StartWiFiLayer', 'description': 'Starts ESP32 WiFi layer if not already started', 'visibility': 'public', 'return_type': 'CHIP_ERROR', 'params': 'void', 'source_class_id': 'ESP32Utils'}, {'type': 'method', 'name': 'SetWiFiStationProvision', 'node_id': 'SetWiFiStationProvision', 'description': 'Configures WiFi station with network credentials', 'visibility': 'public', 'return_type': 'CHIP_ERROR', 'params': 'const DeviceNetworkInfo&', 'source_class_id': 'ESP32Utils'}, {'type': 'method', 'name': 'IsStationEnabled', 'node_id': 'IsStationEnabled', 'description': 'Checks if WiFi station mode is enabled', 'visibility': 'public', 'return_type': 'CHIP_ERROR', 'params': 'bool&', 'source_class_id': 'ESP32Utils'}, {'type': 'function', 'name': 'esp_wifi_init', 'node_id': 'esp_wifi_init', 'description': 'ESP32 SDK function to initialize WiFi', 'visibility': 'public', 'return_type': 'esp_err_t', 'params': 'wifi_init_config_t*', 'source_class_id': None}, {'type': 'function', 'name': 'esp_wifi_set_mode', 'node_id': 'esp_wifi_set_mode', 'description': 'ESP32 SDK function to set WiFi operation mode', 'visibility': 'public', 'return_type': 'esp_err_t', 'params': 'wifi_mode_t', 'source_class_id': None}], 'edges': [{'node_id_from': 'InitWiFiStack', 'node_id_to': 'esp_wifi_init', 'description': 'initializes WiFi stack'}, {'node_id_from': 'SetWiFiStationProvision', 'node_id_to': 'esp_wifi_set_mode', 'description': 'configures WiFi mode'}, {'node_id_from': 'IsStationEnabled', 'node_id_to': 'esp_wifi_set_mode', 'description': 'checks WiFi mode'}, {'node_id_from': 'ESP32Utils', 'node_id_to': 'InitWiFiStack', 'description': ''}, {'node_id_from': 'ESP32Utils', 'node_id_to': 'StartWiFiLayer', 'description': ''}, {'node_id_from': 'ESP32Utils', 'node_id_to': 'SetWiFiStationProvision', 'description': ''}, {'node_id_from': 'ESP32Utils', 'node_id_to': 'IsStationEnabled', 'description': ''}], 'packages': [{'package_id': 'WiFiManagement', 'children': ['ESP32Utils', 'InitWiFiStack', 'StartWiFiLayer', 'SetWiFiStationProvision', 'IsStationEnabled'], 'description': 'Core WiFi management functionality'}, {'package_id': 'ESP32_SDK', 'children': ['esp_wifi_init', 'esp_wifi_set_mode'], 'description': 'ESP32 SDK WiFi functions'}]}",
    "version": "medium",
    "text_answer": "The CHIP framework interacts with ESP32's Wi-Fi stack through the ESP32Utils class, which provides a wrapper layer for WiFi operations. The main interaction flow starts with InitWiFiStack initializing the ESP32 WiFi stack, followed by StartWiFiLayer enabling the WiFi functionality. The framework manages both station and AP modes, handles WiFi configurations, and provides error mapping between ESP32 and CHIP error codes.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include <platform/internal/CHIPDeviceLayerInternal.h>\n\n#include <lib/core/ErrorStr.h>\n#include <lib/support/CodeUtils.h>\n#include <lib/support/logging/CHIPLogging.h>\n#include <platform/ESP32/ESP32Utils.h>\n\n#include \"esp_event.h\"\n#include \"esp_netif.h\"\n#include \"esp_netif_net_stack.h\"\n#include \"esp_wifi.h\"\n#include \"nvs.h\"\n\nusing namespace ::chip::DeviceLayer::Internal;\nusing chip::DeviceLayer::Internal::DeviceNetworkInfo;\n#if CHIP_DEVICE_CONFIG_ENABLE_WIFI\nCHIP_ERROR ESP32Utils::IsAPEnabled(bool & apEnabled)\n{\n#if CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n    wifi_mode_t curWiFiMode;\n\n    esp_err_t err = esp_wifi_get_mode(&curWiFiMode);\n    if (err != ESP_OK)\n    {\n        ChipLogError(DeviceLayer, \"esp_wifi_get_mode() failed: %s\", esp_err_to_name(err));\n        return ESP32Utils::MapError(err);\n    }\n\n    apEnabled = (curWiFiMode == WIFI_MODE_AP || curWiFiMode == WIFI_MODE_APSTA);\n\n    return CHIP_NO_ERROR;\n#else\n    return CHIP_ERROR_NOT_IMPLEMENTED;\n#endif // CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n}\n\nCHIP_ERROR ESP32Utils::IsStationEnabled(bool & staEnabled)\n{\n    wifi_mode_t curWiFiMode;\n    esp_err_t err = esp_wifi_get_mode(&curWiFiMode);\n    if (err != ESP_OK)\n    {\n        ChipLogError(DeviceLayer, \"esp_wifi_get_mode() failed: %s\", esp_err_to_name(err));\n        return ESP32Utils::MapError(err);\n    }\n\n    staEnabled = (curWiFiMode == WIFI_MODE_STA || curWiFiMode == WIFI_MODE_APSTA);\n\n    return CHIP_NO_ERROR;\n}\n\nbool ESP32Utils::IsStationProvisioned(void)\n{\n    wifi_config_t stationConfig;\n    return (esp_wifi_get_config(WIFI_IF_STA, &stationConfig) == ERR_OK && stationConfig.sta.ssid[0] != 0);\n}\n\nCHIP_ERROR ESP32Utils::IsStationConnected(bool & connected)\n{\n    wifi_ap_record_t apInfo;\n    connected = (esp_wifi_sta_get_ap_info(&apInfo) == ESP_OK && apInfo.ssid[0] != 0);\n    return CHIP_NO_ERROR;\n}\n\nCHIP_ERROR ESP32Utils::StartWiFiLayer(void)\n{\n    int8_t ignored;\n    bool wifiStarted;\n\n    // There appears to be no direct way to ask the ESP WiFi layer if esp_wifi_start()\n    // has been called.  So use the ESP_ERR_WIFI_NOT_STARTED error returned by\n    // esp_wifi_get_max_tx_power() to detect this.\n    esp_err_t err = esp_wifi_get_max_tx_power(&ignored);\n    switch (err)\n    {\n    case ESP_OK:\n        wifiStarted = true;\n        break;\n    case ESP_ERR_WIFI_NOT_STARTED:\n        wifiStarted = false;\n        break;\n    default:\n        return ESP32Utils::MapError(err);\n    }\n\n    if (!wifiStarted)\n    {\n        ChipLogProgress(DeviceLayer, \"Starting ESP WiFi layer\");\n\n        err = esp_wifi_start();\n        if (err != ESP_OK)\n        {\n            ChipLogError(DeviceLayer, \"esp_wifi_start() failed: %s\", esp_err_to_name(err));\n            return ESP32Utils::MapError(err);\n        }\n    }\n\n    return CHIP_NO_ERROR;\n}\n\nCHIP_ERROR ESP32Utils::EnableStationMode(void)\n{\n    wifi_mode_t curWiFiMode;\n\n    // Get the current ESP WiFI mode.\n    esp_err_t err = esp_wifi_get_mode(&curWiFiMode);\n    if (err != ESP_OK)\n    {\n        ChipLogError(DeviceLayer, \"esp_wifi_get_mode() failed: %s\", esp_err_to_name(err));\n        return ESP32Utils::MapError(err);\n    }\n\n#if CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n    // If station mode is not already enabled (implying the current mode is WIFI_MODE_AP), change\n    // the mode to WIFI_MODE_APSTA.\n    if (curWiFiMode == WIFI_MODE_AP)\n    {\n        ChipLogProgress(DeviceLayer, \"Changing ESP WiFi mode: %s -> %s\", WiFiModeToStr(WIFI_MODE_AP),\n                        WiFiModeToStr(WIFI_MODE_APSTA));\n\n        err = esp_wifi_set_mode(WIFI_MODE_APSTA);\n        if (err != ESP_OK)\n        {\n            ChipLogError(DeviceLayer, \"esp_wifi_set_mode() failed: %s\", esp_err_to_name(err));\n            return ESP32Utils::MapError(err);\n        }\n    }\n#endif // CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n\n    return CHIP_NO_ERROR;\n}\n\nCHIP_ERROR ESP32Utils::SetAPMode(bool enabled)\n{\n    wifi_mode_t curWiFiMode;\n    wifi_mode_t targetWiFiMode = WIFI_MODE_STA;\n\n#if CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n    targetWiFiMode = (enabled) ? WIFI_MODE_APSTA : WIFI_MODE_STA;\n#endif // CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n\n    // Get the current ESP WiFI mode.\n    esp_err_t err = esp_wifi_get_mode(&curWiFiMode);\n    if (err != ESP_OK)\n    {\n        ChipLogError(DeviceLayer, \"esp_wifi_get_mode() failed: %s\", esp_err_to_name(err));\n        return ESP32Utils::MapError(err);\n    }\n\n    // If station mode is not already enabled (implying the current mode is WIFI_MODE_AP), change\n    // the mode to WIFI_MODE_APSTA.\n    if (curWiFiMode != targetWiFiMode)\n    {\n        ChipLogProgress(DeviceLayer, \"Changing ESP WiFi mode: %s -> %s\", WiFiModeToStr(curWiFiMode), WiFiModeToStr(targetWiFiMode));\n\n        err = esp_wifi_set_mode(targetWiFiMode);\n        if (err != ESP_OK)\n        {\n            ChipLogError(DeviceLayer, \"esp_wifi_set_mode() failed: %s\", esp_err_to_name(err));\n            return ESP32Utils::MapError(err);\n        }\n    }\n\n    return CHIP_NO_ERROR;\n}\n\nint ESP32Utils::OrderScanResultsByRSSI(const void * _res1, const void * _res2)\n{\n    const wifi_ap_record_t * res1 = (const wifi_ap_record_t *) _res1;\n    const wifi_ap_record_t * res2 = (const wifi_ap_record_t *) _res2;\n\n    if (res1->rssi > res2->rssi)\n    {\n        return -1;\n    }\n    if (res1->rssi < res2->rssi)\n    {\n        return 1;\n    }\n    return 0;\n}\n\nconst char * ESP32Utils::WiFiModeToStr(wifi_mode_t wifiMode)\n{\n    switch (wifiMode)\n    {\n    case WIFI_MODE_NULL:\n        return \"NULL\";\n    case WIFI_MODE_STA:\n        return \"STA\";\n    case WIFI_MODE_AP:\n        return \"AP\";\n    case WIFI_MODE_APSTA:\n        return \"STA+AP\";\n    default:\n        return \"(unknown)\";\n    }\n}\n\nstruct netif * ESP32Utils::GetStationNetif(void)\n{\n    return GetNetif(kDefaultWiFiStationNetifKey);\n}\n\nCHIP_ERROR ESP32Utils::GetWiFiStationProvision(Internal::DeviceNetworkInfo & netInfo, bool includeCredentials)\n{\n    wifi_config_t stationConfig;\n\n    esp_err_t err = esp_wifi_get_config(WIFI_IF_STA, &stationConfig);\n    if (err != ESP_OK)\n    {\n        return ESP32Utils::MapError(err);\n    }\n\n    VerifyOrReturnError(stationConfig.sta.ssid[0] != 0, CHIP_ERROR_INCORRECT_STATE);\n\n    netInfo.NetworkId              = kWiFiStationNetworkId;\n    netInfo.FieldPresent.NetworkId = true;\n    memcpy(netInfo.WiFiSSID, stationConfig.sta.ssid,\n           std::min(strlen(reinterpret_cast<char *>(stationConfig.sta.ssid)) + 1, sizeof(netInfo.WiFiSSID)));\n\n    // Enforce that netInfo wifiSSID is null terminated\n    netInfo.WiFiSSID[kMaxWiFiSSIDLength] = '\\0';\n\n    if (includeCredentials)\n    {\n        static_assert(sizeof(netInfo.WiFiKey) < 255, \"Our min might not fit in netInfo.WiFiKeyLen\");\n        netInfo.WiFiKeyLen = static_cast<uint8_t>(std::min(strlen((char *) stationConfig.sta.password), sizeof(netInfo.WiFiKey)));\n        memcpy(netInfo.WiFiKey, stationConfig.sta.password, netInfo.WiFiKeyLen);\n    }\n\n    return CHIP_NO_ERROR;\n}\n\nCHIP_ERROR ESP32Utils::SetWiFiStationProvision(const Internal::DeviceNetworkInfo & netInfo)\n{\n    wifi_config_t wifiConfig;\n\n    char wifiSSID[kMaxWiFiSSIDLength + 1];\n    size_t netInfoSSIDLen = strlen(netInfo.WiFiSSID);\n\n    // Ensure that ESP station mode is enabled.  This is required before esp_wifi_set_config(ESP_IF_WIFI_STA,...)\n    // can be called.\n    ReturnErrorOnFailure(ESP32Utils::EnableStationMode());\n\n    // Enforce that wifiSSID is null terminated before copying it\n    memcpy(wifiSSID, netInfo.WiFiSSID, std::min(netInfoSSIDLen + 1, sizeof(wifiSSID)));\n    if (netInfoSSIDLen + 1 < sizeof(wifiSSID))\n    {\n        wifiSSID[netInfoSSIDLen] = '\\0';\n    }\n    else\n    {\n        wifiSSID[kMaxWiFiSSIDLength] = '\\0';\n    }\n\n    // Initialize an ESP wifi_config_t structure based on the new provision information.\n    memset(&wifiConfig, 0, sizeof(wifiConfig));\n    memcpy(wifiConfig.sta.ssid, wifiSSID, std::min(strlen(wifiSSID) + 1, sizeof(wifiConfig.sta.ssid)));\n    memcpy(wifiConfig.sta.password, netInfo.WiFiKey, std::min((size_t) netInfo.WiFiKeyLen, sizeof(wifiConfig.sta.password)));\n    wifiConfig.sta.scan_method = WIFI_ALL_CHANNEL_SCAN;\n    wifiConfig.sta.sort_method = WIFI_CONNECT_AP_BY_SIGNAL;\n\n    // Configure the ESP WiFi interface.\n    esp_err_t err = esp_wifi_set_config(WIFI_IF_STA, &wifiConfig);\n    if (err != ESP_OK)\n    {\n        ChipLogError(DeviceLayer, \"esp_wifi_set_config() failed: %s\", esp_err_to_name(err));\n        return ESP32Utils::MapError(err);\n    }\n\n    ChipLogProgress(DeviceLayer, \"WiFi station provision set (SSID: %s)\", netInfo.WiFiSSID);\n\n    return CHIP_NO_ERROR;\n}\n\nCHIP_ERROR ESP32Utils::ClearWiFiStationProvision(void)\n{\n    wifi_config_t stationConfig;\n\n    // Clear the ESP WiFi station configuration.\n    memset(&stationConfig, 0, sizeof(stationConfig));\n    esp_wifi_set_config(WIFI_IF_STA, &stationConfig);\n\n    return CHIP_NO_ERROR;\n}\n\nCHIP_ERROR ESP32Utils::InitWiFiStack(void)\n{\n    wifi_init_config_t cfg;\n    uint8_t ap_mac[6];\n    wifi_mode_t mode;\n    esp_err_t err = esp_netif_init();\n    if (err != ESP_OK)\n    {\n        return ESP32Utils::MapError(err);\n    }\n\n#if CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n    // Lets not create a default AP interface if already present\n    if (!esp_netif_get_handle_from_ifkey(kDefaultWiFiAPNetifKey))\n    {\n        if (!esp_netif_create_default_wifi_ap())\n        {\n            ChipLogError(DeviceLayer, \"Failed to create the WiFi AP netif\");\n            return CHIP_ERROR_INTERNAL;\n        }\n    }\n#endif // CHIP_DEVICE_CONFIG_ENABLE_WIFI_AP\n\n    // Lets not create a default station interface if already present\n    if (!esp_netif_get_handle_from_ifkey(kDefaultWiFiStationNetifKey))\n    {\n        if (!esp_netif_create_default_wifi_sta())\n        {\n            ChipLogError(DeviceLayer, \"Failed to create the WiFi STA netif\");\n            return CHIP_ERROR_INTERNAL;\n        }\n    }\n\n    // Initialize the ESP WiFi layer.\n    cfg = WIFI_INIT_CONFIG_DEFAULT();\n    err = esp_wifi_init(&cfg);\n    if (err != ESP_OK)\n    {\n        return ESP32Utils::MapError(err);\n    }\n\n    esp_wifi_get_mode(&mode);\n    if ((mode == WIFI_MODE_AP) || (mode == WIFI_MODE_APSTA))\n    {\n        esp_fill_random(ap_mac, sizeof(ap_mac));\n        /* Bit 0 of the first octet of MAC Address should always be 0 */\n        ap_mac[0] &= (uint8_t) ~0x01;\n        err = esp_wifi_set_mac(WIFI_IF_AP, ap_mac);\n        if (err != ESP_OK)\n        {\n            return ESP32Utils::MapError(err);\n        }\n    }\n    err = esp_event_handler_register(WIFI_EVENT, ESP_EVENT_ANY_ID, PlatformManagerImpl::HandleESPSystemEvent, NULL);\n    if (err != ESP_OK)\n    {\n        return ESP32Utils::MapError(err);\n    }\n    return CHIP_NO_ERROR;\n}\n#endif // CHIP_DEVICE_CONFIG_ENABLE_WIFI\n\nstruct netif * ESP32Utils::GetNetif(const char * ifKey)\n{\n    struct netif * netif       = NULL;\n    esp_netif_t * netif_handle = NULL;\n    netif_handle               = esp_netif_get_handle_from_ifkey(ifKey);\n    netif                      = (struct netif *) esp_netif_get_netif_impl(netif_handle);\n    return netif;\n}\n\nbool ESP32Utils::IsInterfaceUp(const char * ifKey)\n{\n    struct netif * netif = GetNetif(ifKey);\n    return netif != NULL && netif_is_up(netif);\n}\n\nbool ESP32Utils::HasIPv6LinkLocalAddress(const char * ifKey)\n{\n    struct esp_ip6_addr if_ip6_unused;\n    return esp_netif_get_ip6_linklocal(esp_netif_get_handle_from_ifkey(ifKey), &if_ip6_unused) == ESP_OK;\n}\n\nCHIP_ERROR ESP32Utils::MapError(esp_err_t error)\n{\n    if (error == ESP_OK)\n    {\n        return CHIP_NO_ERROR;\n    }\n    if (error == ESP_ERR_NVS_NOT_FOUND)\n    {\n        return CHIP_ERROR_PERSISTED_STORAGE_VALUE_NOT_FOUND;\n    }\n    if (error == ESP_ERR_NVS_INVALID_LENGTH)\n    {\n        return CHIP_ERROR_BUFFER_TOO_SMALL;\n    }\n    return CHIP_ERROR(ChipError::Range::kPlatform, error);\n}\n\n/**\n * Given a CHIP error value that represents an ESP32 error, returns a\n * human-readable NULL-terminated C string describing the error.\n *\n * @param[in] buf                   Buffer into which the error string will be placed.\n * @param[in] bufSize               Size of the supplied buffer in bytes.\n * @param[in] err                   The error to be described.\n *\n * @return true                     If a description string was written into the supplied buffer.\n * @return false                    If the supplied error was not an ESP32 error.\n *\n */\nbool ESP32Utils::FormatError(char * buf, uint16_t bufSize, CHIP_ERROR err)\n{\n    if (!err.IsRange(ChipError::Range::kPlatform))\n    {\n        return false;\n    }\n\n#if CHIP_CONFIG_SHORT_ERROR_STR\n    const char * desc = NULL;\n#else  // CHIP_CONFIG_SHORT_ERROR_STR\n    const char * desc = esp_err_to_name((esp_err_t) err.GetValue());\n#endif // CHIP_CONFIG_SHORT_ERROR_STR\n\n    chip::FormatError(buf, bufSize, \"ESP32\", err, desc);\n\n    return true;\n}\n\n/**\n * Register a text error formatter for ESP32 errors.\n */\nvoid ESP32Utils::RegisterESP32ErrorFormatter()\n{\n    static ErrorFormatter sErrorFormatter = { ESP32Utils::FormatError, NULL };\n\n    RegisterErrorFormatter(&sErrorFormatter);\n}",
    "repo": "project-chip/connectedhomeip",
    "path": "./datasets/diagrams-repos/project-chip/connectedhomeip/examples/platform/esp32/external_platform/ESP32_custom/ESP32Utils.cpp",
    "query": "What is the interaction between the CHIP framework and ESP32's Wi-Fi stack?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'ESP32Utils', 'node_id': 'ESP32Utils', 'description': 'Utility class managing interactions between CHIP and ESP32 WiFi', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'InitWiFiStack', 'node_id': 'InitWiFiStack', 'description': 'Initializes ESP32 WiFi stack and creates network interfaces', 'visibility': 'public', 'return_type': 'CHIP_ERROR', 'params': 'void', 'source_class_id': 'ESP32Utils'}, {'type': 'method', 'name': 'StartWiFiLayer', 'node_id': 'StartWiFiLayer', 'description': 'Starts ESP32 WiFi layer if not already started', 'visibility': 'public', 'return_type': 'CHIP_ERROR', 'params': 'void', 'source_class_id': 'ESP32Utils'}, {'type': 'method', 'name': 'SetWiFiStationProvision', 'node_id': 'SetWiFiStationProvision', 'description': 'Configures WiFi station with network credentials', 'visibility': 'public', 'return_type': 'CHIP_ERROR', 'params': 'const DeviceNetworkInfo&', 'source_class_id': 'ESP32Utils'}, {'type': 'method', 'name': 'IsStationEnabled', 'node_id': 'IsStationEnabled', 'description': 'Checks if WiFi station mode is enabled', 'visibility': 'public', 'return_type': 'CHIP_ERROR', 'params': 'bool&', 'source_class_id': 'ESP32Utils'}, {'type': 'method', 'name': 'IsAPEnabled', 'node_id': 'IsAPEnabled', 'description': 'Checks if WiFi AP mode is enabled', 'visibility': 'public', 'return_type': 'CHIP_ERROR', 'params': 'bool&', 'source_class_id': 'ESP32Utils'}, {'type': 'method', 'name': 'SetAPMode', 'node_id': 'SetAPMode', 'description': 'Enables or disables AP mode', 'visibility': 'public', 'return_type': 'CHIP_ERROR', 'params': 'bool', 'source_class_id': 'ESP32Utils'}, {'type': 'method', 'name': 'MapError', 'node_id': 'MapError', 'description': 'Maps ESP32 errors to CHIP errors', 'visibility': 'public', 'return_type': 'CHIP_ERROR', 'params': 'esp_err_t', 'source_class_id': 'ESP32Utils'}, {'type': 'function', 'name': 'esp_wifi_init', 'node_id': 'esp_wifi_init', 'description': 'ESP32 SDK function to initialize WiFi', 'visibility': 'public', 'return_type': 'esp_err_t', 'params': 'wifi_init_config_t*', 'source_class_id': None}, {'type': 'function', 'name': 'esp_wifi_set_mode', 'node_id': 'esp_wifi_set_mode', 'description': 'ESP32 SDK function to set WiFi operation mode', 'visibility': 'public', 'return_type': 'esp_err_t', 'params': 'wifi_mode_t', 'source_class_id': None}, {'type': 'function', 'name': 'esp_wifi_start', 'node_id': 'esp_wifi_start', 'description': 'ESP32 SDK function to start WiFi', 'visibility': 'public', 'return_type': 'esp_err_t', 'params': 'void', 'source_class_id': None}, {'type': 'function', 'name': 'esp_wifi_set_config', 'node_id': 'esp_wifi_set_config', 'description': 'ESP32 SDK function to configure WiFi settings', 'visibility': 'public', 'return_type': 'esp_err_t', 'params': 'wifi_interface_t, wifi_config_t*', 'source_class_id': None}], 'edges': [{'node_id_from': 'InitWiFiStack', 'node_id_to': 'esp_wifi_init', 'description': 'initializes WiFi stack'}, {'node_id_from': 'StartWiFiLayer', 'node_id_to': 'esp_wifi_start', 'description': 'starts WiFi'}, {'node_id_from': 'SetWiFiStationProvision', 'node_id_to': 'esp_wifi_set_config', 'description': 'configures WiFi settings'}, {'node_id_from': 'SetAPMode', 'node_id_to': 'esp_wifi_set_mode', 'description': 'sets WiFi mode'}, {'node_id_from': 'IsStationEnabled', 'node_id_to': 'esp_wifi_set_mode', 'description': 'checks WiFi mode'}, {'node_id_from': 'IsAPEnabled', 'node_id_to': 'esp_wifi_set_mode', 'description': 'checks AP mode'}, {'node_id_from': 'ESP32Utils', 'node_id_to': 'InitWiFiStack', 'description': ''}, {'node_id_from': 'ESP32Utils', 'node_id_to': 'StartWiFiLayer', 'description': ''}, {'node_id_from': 'ESP32Utils', 'node_id_to': 'SetWiFiStationProvision', 'description': ''}, {'node_id_from': 'ESP32Utils', 'node_id_to': 'IsStationEnabled', 'description': ''}, {'node_id_from': 'ESP32Utils', 'node_id_to': 'IsAPEnabled', 'description': ''}, {'node_id_from': 'ESP32Utils', 'node_id_to': 'SetAPMode', 'description': ''}, {'node_id_from': 'ESP32Utils', 'node_id_to': 'MapError', 'description': ''}], 'packages': [{'package_id': 'WiFiManagement', 'children': ['ESP32Utils', 'InitWiFiStack', 'StartWiFiLayer', 'SetWiFiStationProvision', 'IsStationEnabled', 'IsAPEnabled', 'SetAPMode', 'MapError'], 'description': 'Core WiFi management functionality'}, {'package_id': 'ESP32_SDK', 'children': ['esp_wifi_init', 'esp_wifi_set_mode', 'esp_wifi_start', 'esp_wifi_set_config'], 'description': 'ESP32 SDK WiFi functions'}]}",
    "version": "full",
    "text_answer": "The CHIP framework interacts with ESP32's Wi-Fi stack through the ESP32Utils class, which provides a wrapper layer for WiFi operations. The main interaction flow starts with InitWiFiStack initializing the ESP32 WiFi stack, followed by StartWiFiLayer enabling the WiFi functionality. The framework manages both station and AP modes, handles WiFi configurations, and provides error mapping between ESP32 and CHIP error codes.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.thingsboard.server.transport.coap.claim;\n\nimport lombok.extern.slf4j.Slf4j;\nimport org.eclipse.californium.core.CoapResponse;\nimport org.eclipse.californium.core.coap.CoAP;\nimport org.eclipse.californium.elements.exception.ConnectorException;\nimport org.junit.After;\nimport org.junit.Before;\nimport org.junit.Test;\nimport org.thingsboard.server.common.data.ClaimRequest;\nimport org.thingsboard.server.common.data.Device;\nimport org.thingsboard.server.common.msg.session.FeatureType;\nimport org.thingsboard.server.dao.device.claim.ClaimResponse;\nimport org.thingsboard.server.dao.device.claim.ClaimResult;\nimport org.thingsboard.server.dao.service.DaoSqlTest;\nimport org.thingsboard.server.transport.coap.AbstractCoapIntegrationTest;\nimport org.thingsboard.server.transport.coap.CoapTestClient;\nimport org.thingsboard.server.transport.coap.CoapTestConfigProperties;\n\nimport java.io.IOException;\n\nimport static org.junit.Assert.assertEquals;\nimport static org.junit.Assert.assertNotNull;\nimport static org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;\n\n@Slf4j\n@DaoSqlTest\npublic class CoapClaimDeviceTest extends AbstractCoapIntegrationTest {\n\n    @Before\n    public void beforeTest() throws Exception {\n        CoapTestConfigProperties configProperties = CoapTestConfigProperties.builder()\n                .deviceName(\"Test Claim device\")\n                .build();\n        processBeforeTest(configProperties);\n    }\n\n    @After\n    public void afterTest() throws Exception {\n        processAfterTest();\n    }\n\n    @Test\n    public void testClaimingDevice() throws Exception {\n        processTestClaimingDevice(false);\n    }\n\n    @Test\n    public void testClaimingDeviceWithoutSecretAndDuration() throws Exception {\n        processTestClaimingDevice(true);\n    }\n\n    protected void processTestClaimingDevice(boolean emptyPayload) throws Exception {\n        log.warn(\"[testClaimingDevice] Device: {}, Transport type: {}\", savedDevice.getName(), savedDevice.getType());\n        client = new CoapTestClient(accessToken, FeatureType.CLAIM);\n        byte[] payloadBytes;\n        byte[] failurePayloadBytes;\n        if (emptyPayload) {\n            payloadBytes = \"{}\".getBytes();\n            failurePayloadBytes = \"{\\\"durationMs\\\":1}\".getBytes();\n        } else {\n            payloadBytes = \"{\\\"secretKey\\\":\\\"value\\\", \\\"durationMs\\\":60000}\".getBytes();\n            failurePayloadBytes = \"{\\\"secretKey\\\":\\\"value\\\", \\\"durationMs\\\":1}\".getBytes();\n        }\n        validateClaimResponse(emptyPayload, client, payloadBytes, failurePayloadBytes);\n    }\n\n    protected void validateClaimResponse(boolean emptyPayload, CoapTestClient client, byte[] payloadBytes, byte[] failurePayloadBytes) throws Exception {\n        postClaimRequest(client, failurePayloadBytes);\n        awaitForClaimingInfoToBeRegistered(savedDevice.getId());\n\n        loginCustomerUser();\n        ClaimRequest claimRequest;\n        if (!emptyPayload) {\n            claimRequest = new ClaimRequest(\"value\");\n        } else {\n            claimRequest = new ClaimRequest(null);\n        }\n\n        ClaimResponse claimResponse = doExecuteWithRetriesAndInterval(\n                () -> doPostClaimAsync(\"/api/customer/device/\" + savedDevice.getName() + \"/claim\", claimRequest, ClaimResponse.class, status().isBadRequest()),\n                100,\n                200\n        );\n\n        assertEquals(claimResponse, ClaimResponse.FAILURE);\n\n        postClaimRequest(client, payloadBytes);\n        awaitForClaimingInfoToBeRegistered(savedDevice.getId());\n\n        ClaimResult claimResult = doExecuteWithRetriesAndInterval(\n                () -> doPostClaimAsync(\"/api/customer/device/\" + savedDevice.getName() + \"/claim\", claimRequest, ClaimResult.class, status().isOk()),\n                100,\n                200\n        );\n        assertEquals(claimResult.getResponse(), ClaimResponse.SUCCESS);\n        Device claimedDevice = claimResult.getDevice();\n        assertNotNull(claimedDevice);\n        assertNotNull(claimedDevice.getCustomerId());\n        assertEquals(customerId, claimedDevice.getCustomerId());\n\n        claimResponse = doPostClaimAsync(\"/api/customer/device/\" + savedDevice.getName() + \"/claim\", claimRequest, ClaimResponse.class, status().isBadRequest());\n        assertEquals(claimResponse, ClaimResponse.CLAIMED);\n    }\n\n    private void postClaimRequest(CoapTestClient client, byte[] payload) throws IOException, ConnectorException {\n        CoapResponse coapResponse = client.postMethod(payload);\n        assertEquals(CoAP.ResponseCode.CREATED, coapResponse.getCode());\n    }\n\n}",
    "repo": "thingsboard/thingsboard",
    "path": "./datasets/diagrams-repos/thingsboard/thingsboard/application/src/test/java/org/thingsboard/server/transport/coap/claim/CoapClaimDeviceTest.java",
    "query": "What is the structure of the CoapClaimDeviceTest class?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'AbstractCoapIntegrationTest', 'node_id': 'AbstractCoapIntegrationTest', 'description': 'Base class for CoAP integration tests', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'CoapClaimDeviceTest', 'node_id': 'CoapClaimDeviceTest', 'description': 'Test class for device claiming functionality via CoAP protocol', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'testClaimingDevice', 'node_id': 'testClaimingDevice', 'description': 'Tests device claiming process with payload', 'visibility': 'public', 'return_type': 'void', 'params': '()', 'source_class_id': 'CoapClaimDeviceTest'}, {'type': 'method', 'name': 'processTestClaimingDevice', 'node_id': 'processTestClaimingDevice', 'description': 'Core method for testing device claiming', 'visibility': 'protected', 'return_type': 'void', 'params': '(boolean emptyPayload)', 'source_class_id': 'CoapClaimDeviceTest'}], 'edges': [{'node_id_from': 'CoapClaimDeviceTest', 'node_id_to': 'AbstractCoapIntegrationTest', 'description': 'extends'}, {'node_id_from': 'testClaimingDevice', 'node_id_to': 'processTestClaimingDevice', 'description': 'calls'}, {'node_id_from': 'CoapClaimDeviceTest', 'node_id_to': 'testClaimingDevice', 'description': ''}, {'node_id_from': 'CoapClaimDeviceTest', 'node_id_to': 'processTestClaimingDevice', 'description': ''}], 'packages': [{'package_id': 'coapClaim', 'children': ['CoapClaimDeviceTest', 'AbstractCoapIntegrationTest', 'testClaimingDevice', 'processTestClaimingDevice'], 'description': 'CoAP claiming functionality'}]}",
    "version": "minimal",
    "text_answer": "CoapClaimDeviceTest extends AbstractCoapIntegrationTest and is annotated with @DaoSqlTest and @Slf4j. It contains lifecycle methods (beforeTest, afterTest), two test methods for device claiming, and several supporting methods for processing and validating claim requests.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.thingsboard.server.transport.coap.claim;\n\nimport lombok.extern.slf4j.Slf4j;\nimport org.eclipse.californium.core.CoapResponse;\nimport org.eclipse.californium.core.coap.CoAP;\nimport org.eclipse.californium.elements.exception.ConnectorException;\nimport org.junit.After;\nimport org.junit.Before;\nimport org.junit.Test;\nimport org.thingsboard.server.common.data.ClaimRequest;\nimport org.thingsboard.server.common.data.Device;\nimport org.thingsboard.server.common.msg.session.FeatureType;\nimport org.thingsboard.server.dao.device.claim.ClaimResponse;\nimport org.thingsboard.server.dao.device.claim.ClaimResult;\nimport org.thingsboard.server.dao.service.DaoSqlTest;\nimport org.thingsboard.server.transport.coap.AbstractCoapIntegrationTest;\nimport org.thingsboard.server.transport.coap.CoapTestClient;\nimport org.thingsboard.server.transport.coap.CoapTestConfigProperties;\n\nimport java.io.IOException;\n\nimport static org.junit.Assert.assertEquals;\nimport static org.junit.Assert.assertNotNull;\nimport static org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;\n\n@Slf4j\n@DaoSqlTest\npublic class CoapClaimDeviceTest extends AbstractCoapIntegrationTest {\n\n    @Before\n    public void beforeTest() throws Exception {\n        CoapTestConfigProperties configProperties = CoapTestConfigProperties.builder()\n                .deviceName(\"Test Claim device\")\n                .build();\n        processBeforeTest(configProperties);\n    }\n\n    @After\n    public void afterTest() throws Exception {\n        processAfterTest();\n    }\n\n    @Test\n    public void testClaimingDevice() throws Exception {\n        processTestClaimingDevice(false);\n    }\n\n    @Test\n    public void testClaimingDeviceWithoutSecretAndDuration() throws Exception {\n        processTestClaimingDevice(true);\n    }\n\n    protected void processTestClaimingDevice(boolean emptyPayload) throws Exception {\n        log.warn(\"[testClaimingDevice] Device: {}, Transport type: {}\", savedDevice.getName(), savedDevice.getType());\n        client = new CoapTestClient(accessToken, FeatureType.CLAIM);\n        byte[] payloadBytes;\n        byte[] failurePayloadBytes;\n        if (emptyPayload) {\n            payloadBytes = \"{}\".getBytes();\n            failurePayloadBytes = \"{\\\"durationMs\\\":1}\".getBytes();\n        } else {\n            payloadBytes = \"{\\\"secretKey\\\":\\\"value\\\", \\\"durationMs\\\":60000}\".getBytes();\n            failurePayloadBytes = \"{\\\"secretKey\\\":\\\"value\\\", \\\"durationMs\\\":1}\".getBytes();\n        }\n        validateClaimResponse(emptyPayload, client, payloadBytes, failurePayloadBytes);\n    }\n\n    protected void validateClaimResponse(boolean emptyPayload, CoapTestClient client, byte[] payloadBytes, byte[] failurePayloadBytes) throws Exception {\n        postClaimRequest(client, failurePayloadBytes);\n        awaitForClaimingInfoToBeRegistered(savedDevice.getId());\n\n        loginCustomerUser();\n        ClaimRequest claimRequest;\n        if (!emptyPayload) {\n            claimRequest = new ClaimRequest(\"value\");\n        } else {\n            claimRequest = new ClaimRequest(null);\n        }\n\n        ClaimResponse claimResponse = doExecuteWithRetriesAndInterval(\n                () -> doPostClaimAsync(\"/api/customer/device/\" + savedDevice.getName() + \"/claim\", claimRequest, ClaimResponse.class, status().isBadRequest()),\n                100,\n                200\n        );\n\n        assertEquals(claimResponse, ClaimResponse.FAILURE);\n\n        postClaimRequest(client, payloadBytes);\n        awaitForClaimingInfoToBeRegistered(savedDevice.getId());\n\n        ClaimResult claimResult = doExecuteWithRetriesAndInterval(\n                () -> doPostClaimAsync(\"/api/customer/device/\" + savedDevice.getName() + \"/claim\", claimRequest, ClaimResult.class, status().isOk()),\n                100,\n                200\n        );\n        assertEquals(claimResult.getResponse(), ClaimResponse.SUCCESS);\n        Device claimedDevice = claimResult.getDevice();\n        assertNotNull(claimedDevice);\n        assertNotNull(claimedDevice.getCustomerId());\n        assertEquals(customerId, claimedDevice.getCustomerId());\n\n        claimResponse = doPostClaimAsync(\"/api/customer/device/\" + savedDevice.getName() + \"/claim\", claimRequest, ClaimResponse.class, status().isBadRequest());\n        assertEquals(claimResponse, ClaimResponse.CLAIMED);\n    }\n\n    private void postClaimRequest(CoapTestClient client, byte[] payload) throws IOException, ConnectorException {\n        CoapResponse coapResponse = client.postMethod(payload);\n        assertEquals(CoAP.ResponseCode.CREATED, coapResponse.getCode());\n    }\n\n}",
    "repo": "thingsboard/thingsboard",
    "path": "./datasets/diagrams-repos/thingsboard/thingsboard/application/src/test/java/org/thingsboard/server/transport/coap/claim/CoapClaimDeviceTest.java",
    "query": "What is the structure of the CoapClaimDeviceTest class?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'AbstractCoapIntegrationTest', 'node_id': 'AbstractCoapIntegrationTest', 'description': 'Base class for CoAP integration tests', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'CoapClaimDeviceTest', 'node_id': 'CoapClaimDeviceTest', 'description': 'Test class for device claiming functionality via CoAP protocol', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'beforeTest', 'node_id': 'beforeTest', 'description': 'Setup method executed before each test', 'visibility': 'public', 'return_type': 'void', 'params': '()', 'source_class_id': 'CoapClaimDeviceTest'}, {'type': 'method', 'name': 'afterTest', 'node_id': 'afterTest', 'description': 'Cleanup method executed after each test', 'visibility': 'public', 'return_type': 'void', 'params': '()', 'source_class_id': 'CoapClaimDeviceTest'}, {'type': 'method', 'name': 'testClaimingDevice', 'node_id': 'testClaimingDevice', 'description': 'Tests device claiming process with payload', 'visibility': 'public', 'return_type': 'void', 'params': '()', 'source_class_id': 'CoapClaimDeviceTest'}, {'type': 'method', 'name': 'testClaimingDeviceWithoutSecretAndDuration', 'node_id': 'testClaimingDeviceWithoutSecretAndDuration', 'description': 'Tests device claiming process without secret and duration', 'visibility': 'public', 'return_type': 'void', 'params': '()', 'source_class_id': 'CoapClaimDeviceTest'}, {'type': 'method', 'name': 'processTestClaimingDevice', 'node_id': 'processTestClaimingDevice', 'description': 'Core method for testing device claiming', 'visibility': 'protected', 'return_type': 'void', 'params': '(boolean emptyPayload)', 'source_class_id': 'CoapClaimDeviceTest'}, {'type': 'method', 'name': 'validateClaimResponse', 'node_id': 'validateClaimResponse', 'description': 'Validates claim response', 'visibility': 'protected', 'return_type': 'void', 'params': '(boolean emptyPayload, CoapTestClient client, byte[] payloadBytes, byte[] failurePayloadBytes)', 'source_class_id': 'CoapClaimDeviceTest'}], 'edges': [{'node_id_from': 'CoapClaimDeviceTest', 'node_id_to': 'AbstractCoapIntegrationTest', 'description': 'extends'}, {'node_id_from': 'testClaimingDevice', 'node_id_to': 'processTestClaimingDevice', 'description': 'calls'}, {'node_id_from': 'testClaimingDeviceWithoutSecretAndDuration', 'node_id_to': 'processTestClaimingDevice', 'description': 'calls'}, {'node_id_from': 'processTestClaimingDevice', 'node_id_to': 'validateClaimResponse', 'description': 'calls'}, {'node_id_from': 'CoapClaimDeviceTest', 'node_id_to': 'beforeTest', 'description': ''}, {'node_id_from': 'CoapClaimDeviceTest', 'node_id_to': 'afterTest', 'description': ''}, {'node_id_from': 'CoapClaimDeviceTest', 'node_id_to': 'testClaimingDevice', 'description': ''}, {'node_id_from': 'CoapClaimDeviceTest', 'node_id_to': 'processTestClaimingDevice', 'description': ''}, {'node_id_from': 'CoapClaimDeviceTest', 'node_id_to': 'validateClaimResponse', 'description': ''}, {'node_id_from': 'CoapClaimDeviceTest', 'node_id_to': 'testClaimingDeviceWithoutSecretAndDuration', 'description': ''}], 'packages': [{'package_id': 'coapClaim', 'children': ['CoapClaimDeviceTest', 'AbstractCoapIntegrationTest', 'testMethods', 'coreMethods'], 'description': 'CoAP claiming functionality'}, {'package_id': 'testMethods', 'children': ['beforeTest', 'afterTest', 'testClaimingDevice', 'testClaimingDeviceWithoutSecretAndDuration'], 'description': 'Test methods'}, {'package_id': 'coreMethods', 'children': ['processTestClaimingDevice', 'validateClaimResponse'], 'description': 'Core implementation methods'}]}",
    "version": "medium",
    "text_answer": "CoapClaimDeviceTest extends AbstractCoapIntegrationTest and is annotated with @DaoSqlTest and @Slf4j. It contains lifecycle methods (beforeTest, afterTest), two test methods for device claiming, and several supporting methods for processing and validating claim requests.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.thingsboard.server.transport.coap.claim;\n\nimport lombok.extern.slf4j.Slf4j;\nimport org.eclipse.californium.core.CoapResponse;\nimport org.eclipse.californium.core.coap.CoAP;\nimport org.eclipse.californium.elements.exception.ConnectorException;\nimport org.junit.After;\nimport org.junit.Before;\nimport org.junit.Test;\nimport org.thingsboard.server.common.data.ClaimRequest;\nimport org.thingsboard.server.common.data.Device;\nimport org.thingsboard.server.common.msg.session.FeatureType;\nimport org.thingsboard.server.dao.device.claim.ClaimResponse;\nimport org.thingsboard.server.dao.device.claim.ClaimResult;\nimport org.thingsboard.server.dao.service.DaoSqlTest;\nimport org.thingsboard.server.transport.coap.AbstractCoapIntegrationTest;\nimport org.thingsboard.server.transport.coap.CoapTestClient;\nimport org.thingsboard.server.transport.coap.CoapTestConfigProperties;\n\nimport java.io.IOException;\n\nimport static org.junit.Assert.assertEquals;\nimport static org.junit.Assert.assertNotNull;\nimport static org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;\n\n@Slf4j\n@DaoSqlTest\npublic class CoapClaimDeviceTest extends AbstractCoapIntegrationTest {\n\n    @Before\n    public void beforeTest() throws Exception {\n        CoapTestConfigProperties configProperties = CoapTestConfigProperties.builder()\n                .deviceName(\"Test Claim device\")\n                .build();\n        processBeforeTest(configProperties);\n    }\n\n    @After\n    public void afterTest() throws Exception {\n        processAfterTest();\n    }\n\n    @Test\n    public void testClaimingDevice() throws Exception {\n        processTestClaimingDevice(false);\n    }\n\n    @Test\n    public void testClaimingDeviceWithoutSecretAndDuration() throws Exception {\n        processTestClaimingDevice(true);\n    }\n\n    protected void processTestClaimingDevice(boolean emptyPayload) throws Exception {\n        log.warn(\"[testClaimingDevice] Device: {}, Transport type: {}\", savedDevice.getName(), savedDevice.getType());\n        client = new CoapTestClient(accessToken, FeatureType.CLAIM);\n        byte[] payloadBytes;\n        byte[] failurePayloadBytes;\n        if (emptyPayload) {\n            payloadBytes = \"{}\".getBytes();\n            failurePayloadBytes = \"{\\\"durationMs\\\":1}\".getBytes();\n        } else {\n            payloadBytes = \"{\\\"secretKey\\\":\\\"value\\\", \\\"durationMs\\\":60000}\".getBytes();\n            failurePayloadBytes = \"{\\\"secretKey\\\":\\\"value\\\", \\\"durationMs\\\":1}\".getBytes();\n        }\n        validateClaimResponse(emptyPayload, client, payloadBytes, failurePayloadBytes);\n    }\n\n    protected void validateClaimResponse(boolean emptyPayload, CoapTestClient client, byte[] payloadBytes, byte[] failurePayloadBytes) throws Exception {\n        postClaimRequest(client, failurePayloadBytes);\n        awaitForClaimingInfoToBeRegistered(savedDevice.getId());\n\n        loginCustomerUser();\n        ClaimRequest claimRequest;\n        if (!emptyPayload) {\n            claimRequest = new ClaimRequest(\"value\");\n        } else {\n            claimRequest = new ClaimRequest(null);\n        }\n\n        ClaimResponse claimResponse = doExecuteWithRetriesAndInterval(\n                () -> doPostClaimAsync(\"/api/customer/device/\" + savedDevice.getName() + \"/claim\", claimRequest, ClaimResponse.class, status().isBadRequest()),\n                100,\n                200\n        );\n\n        assertEquals(claimResponse, ClaimResponse.FAILURE);\n\n        postClaimRequest(client, payloadBytes);\n        awaitForClaimingInfoToBeRegistered(savedDevice.getId());\n\n        ClaimResult claimResult = doExecuteWithRetriesAndInterval(\n                () -> doPostClaimAsync(\"/api/customer/device/\" + savedDevice.getName() + \"/claim\", claimRequest, ClaimResult.class, status().isOk()),\n                100,\n                200\n        );\n        assertEquals(claimResult.getResponse(), ClaimResponse.SUCCESS);\n        Device claimedDevice = claimResult.getDevice();\n        assertNotNull(claimedDevice);\n        assertNotNull(claimedDevice.getCustomerId());\n        assertEquals(customerId, claimedDevice.getCustomerId());\n\n        claimResponse = doPostClaimAsync(\"/api/customer/device/\" + savedDevice.getName() + \"/claim\", claimRequest, ClaimResponse.class, status().isBadRequest());\n        assertEquals(claimResponse, ClaimResponse.CLAIMED);\n    }\n\n    private void postClaimRequest(CoapTestClient client, byte[] payload) throws IOException, ConnectorException {\n        CoapResponse coapResponse = client.postMethod(payload);\n        assertEquals(CoAP.ResponseCode.CREATED, coapResponse.getCode());\n    }\n\n}",
    "repo": "thingsboard/thingsboard",
    "path": "./datasets/diagrams-repos/thingsboard/thingsboard/application/src/test/java/org/thingsboard/server/transport/coap/claim/CoapClaimDeviceTest.java",
    "query": "What is the structure of the CoapClaimDeviceTest class?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'AbstractCoapIntegrationTest', 'node_id': 'AbstractCoapIntegrationTest', 'description': 'Base class for CoAP integration tests', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'CoapClaimDeviceTest', 'node_id': 'CoapClaimDeviceTest', 'description': 'Test class for device claiming functionality via CoAP protocol', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'beforeTest', 'node_id': 'beforeTest', 'description': 'Setup method executed before each test', 'visibility': 'public', 'return_type': 'void', 'params': '()', 'source_class_id': 'CoapClaimDeviceTest'}, {'type': 'method', 'name': 'afterTest', 'node_id': 'afterTest', 'description': 'Cleanup method executed after each test', 'visibility': 'public', 'return_type': 'void', 'params': '()', 'source_class_id': 'CoapClaimDeviceTest'}, {'type': 'method', 'name': 'testClaimingDevice', 'node_id': 'testClaimingDevice', 'description': 'Tests device claiming process with payload', 'visibility': 'public', 'return_type': 'void', 'params': '()', 'source_class_id': 'CoapClaimDeviceTest'}, {'type': 'method', 'name': 'testClaimingDeviceWithoutSecretAndDuration', 'node_id': 'testClaimingDeviceWithoutSecretAndDuration', 'description': 'Tests device claiming process without secret and duration', 'visibility': 'public', 'return_type': 'void', 'params': '()', 'source_class_id': 'CoapClaimDeviceTest'}, {'type': 'method', 'name': 'processTestClaimingDevice', 'node_id': 'processTestClaimingDevice', 'description': 'Core method for testing device claiming', 'visibility': 'protected', 'return_type': 'void', 'params': '(boolean emptyPayload)', 'source_class_id': 'CoapClaimDeviceTest'}, {'type': 'method', 'name': 'validateClaimResponse', 'node_id': 'validateClaimResponse', 'description': 'Validates claim response', 'visibility': 'protected', 'return_type': 'void', 'params': '(boolean emptyPayload, CoapTestClient client, byte[] payloadBytes, byte[] failurePayloadBytes)', 'source_class_id': 'CoapClaimDeviceTest'}, {'type': 'method', 'name': 'postClaimRequest', 'node_id': 'postClaimRequest', 'description': 'Posts claim request via CoAP', 'visibility': 'private', 'return_type': 'void', 'params': '(CoapTestClient client, byte[] payload)', 'source_class_id': 'CoapClaimDeviceTest'}, {'type': 'entity', 'name': 'DaoSqlTest', 'node_id': 'DaoSqlTest', 'description': 'Annotation for SQL DAO tests', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'Slf4j', 'node_id': 'Slf4j', 'description': 'Logging annotation', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'CoapClaimDeviceTest', 'node_id_to': 'AbstractCoapIntegrationTest', 'description': 'extends'}, {'node_id_from': 'CoapClaimDeviceTest', 'node_id_to': 'DaoSqlTest', 'description': 'annotated with'}, {'node_id_from': 'CoapClaimDeviceTest', 'node_id_to': 'Slf4j', 'description': 'annotated with'}, {'node_id_from': 'testClaimingDevice', 'node_id_to': 'processTestClaimingDevice', 'description': 'calls'}, {'node_id_from': 'testClaimingDeviceWithoutSecretAndDuration', 'node_id_to': 'processTestClaimingDevice', 'description': 'calls'}, {'node_id_from': 'processTestClaimingDevice', 'node_id_to': 'validateClaimResponse', 'description': 'calls'}, {'node_id_from': 'validateClaimResponse', 'node_id_to': 'postClaimRequest', 'description': 'calls'}, {'node_id_from': 'CoapClaimDeviceTest', 'node_id_to': 'beforeTest', 'description': ''}, {'node_id_from': 'CoapClaimDeviceTest', 'node_id_to': 'afterTest', 'description': ''}, {'node_id_from': 'CoapClaimDeviceTest', 'node_id_to': 'testClaimingDevice', 'description': ''}, {'node_id_from': 'CoapClaimDeviceTest', 'node_id_to': 'processTestClaimingDevice', 'description': ''}, {'node_id_from': 'CoapClaimDeviceTest', 'node_id_to': 'validateClaimResponse', 'description': ''}, {'node_id_from': 'CoapClaimDeviceTest', 'node_id_to': 'postClaimRequest', 'description': ''}, {'node_id_from': 'CoapClaimDeviceTest', 'node_id_to': 'testClaimingDeviceWithoutSecretAndDuration', 'description': ''}], 'packages': [{'package_id': 'coapClaim', 'children': ['CoapClaimDeviceTest', 'AbstractCoapIntegrationTest', 'testMethods', 'coreMethods', 'annotations'], 'description': 'CoAP claiming functionality'}, {'package_id': 'testMethods', 'children': ['beforeTest', 'afterTest', 'testClaimingDevice', 'testClaimingDeviceWithoutSecretAndDuration'], 'description': 'Test methods'}, {'package_id': 'coreMethods', 'children': ['processTestClaimingDevice', 'validateClaimResponse', 'postClaimRequest'], 'description': 'Core implementation methods'}, {'package_id': 'annotations', 'children': ['DaoSqlTest', 'Slf4j'], 'description': 'Class annotations'}]}",
    "version": "full",
    "text_answer": "CoapClaimDeviceTest extends AbstractCoapIntegrationTest and is annotated with @DaoSqlTest and @Slf4j. It contains lifecycle methods (beforeTest, afterTest), two test methods for device claiming, and several supporting methods for processing and validating claim requests.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { beforeEach, describe, expect, it, vi } from 'vitest'\nimport { nextTick } from 'vue'\nimport { useUrlSearchParams } from '.'\n\ndescribe('useUrlSearchParams', () => {\n  const baseURL = 'https://vueuse.org'\n\n  Object.defineProperty(window, 'location', {\n    value: new URL(baseURL),\n    writable: true,\n  })\n\n  const mockReplaceState = vi.fn()\n  const mockPushState = vi.fn()\n\n  beforeEach(() => {\n    vi.clearAllMocks()\n    window.location.search = ''\n    window.location.hash = ''\n    window.history.replaceState = mockReplaceState\n    window.history.pushState = mockPushState\n  })\n\n  const mockPopstate = (search: string, hash: string) => {\n    window.location.search = search\n    window.location.hash = hash\n    window.dispatchEvent(new PopStateEvent('popstate', {\n      state: {\n        ...window.location,\n        search,\n        hash,\n      },\n    }))\n  }\n\n  ([\n    'history',\n    'hash',\n    'hash-params',\n  ] as const).forEach((mode) => {\n    describe(`${mode} mode`, () => {\n      it('return initial params', async () => {\n        if (mode === 'hash')\n          window.location.hash = '#/test/?foo=bar'\n        else if (mode === 'hash-params')\n          window.location.hash = '#foo=bar'\n        else\n          window.location.search = '?foo=bar'\n\n        const params = useUrlSearchParams(mode)\n\n        await nextTick()\n        expect(params.foo).toBe('bar')\n      })\n\n      it('return initialValue', async () => {\n        const initialValue = { foo: 'bar' }\n        const params1 = useUrlSearchParams(mode, { initialValue })\n        // @ts-expect-error test window=null\n        const params2 = useUrlSearchParams(mode, { initialValue, window: null })\n\n        expect(params1.foo).toBe('bar')\n        expect(params2.foo).toBe('bar')\n      })\n\n      it('update params on poststate event', async () => {\n        const params = useUrlSearchParams(mode)\n        expect(params.foo).toBeUndefined()\n\n        switch (mode) {\n          case 'hash':\n            mockPopstate('', '#/test/?foo=bar')\n            break\n          case 'hash-params':\n            mockPopstate('', '#foo=bar')\n            break\n          case 'history':\n            mockPopstate('?foo=bar', '')\n        }\n        await nextTick()\n        expect(params.foo).toBe('bar')\n\n        switch (mode) {\n          case 'hash':\n            mockPopstate('', '#/test/?foo=bar1&foo=bar2')\n            break\n          case 'hash-params':\n            mockPopstate('', '#foo=bar1&foo=bar2')\n            break\n          case 'history':\n            mockPopstate('?foo=bar1&foo=bar2', '')\n        }\n        await nextTick()\n        expect(params.foo).toEqual(['bar1', 'bar2'])\n\n        switch (mode) {\n          case 'hash':\n            mockPopstate('', '#/test/?foo=')\n            break\n          case 'hash-params':\n            mockPopstate('', '#foo=')\n            break\n          case 'history':\n            mockPopstate('?foo=', '')\n        }\n        await nextTick()\n        expect(params.foo).toBe('')\n      })\n\n      it('stop poststate event', async () => {\n        const params = useUrlSearchParams(mode, { write: false })\n        expect(params.foo).toBeUndefined()\n\n        switch (mode) {\n          case 'hash':\n            mockPopstate('', '#/test/?foo=bar')\n            break\n          case 'hash-params':\n            mockPopstate('', '#foo=bar')\n            break\n          case 'history':\n            mockPopstate('?foo=bar', '')\n        }\n        await nextTick()\n        expect(params.foo).toBeUndefined()\n      })\n\n      it('update browser location on params change', async () => {\n        const params = useUrlSearchParams(mode)\n\n        params.foo = 'bar'\n        await nextTick()\n        switch (mode) {\n          case 'history':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/?foo=bar')\n            break\n          case 'hash':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/#?foo=bar')\n            break\n          case 'hash-params':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/#foo=bar')\n            break\n        }\n\n        if (mode === 'hash')\n          window.location.hash = '#?foo=bar'\n\n        delete params.foo\n        await nextTick()\n        switch (mode) {\n          case 'history':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/')\n            break\n          case 'hash':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/#')\n            break\n          case 'hash-params':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/')\n            break\n        }\n      })\n\n      it('array url search param', async () => {\n        const params = useUrlSearchParams(mode)\n        expect(params.foo).toBeUndefined()\n        params.foo = ['bar1', 'bar2']\n\n        await nextTick()\n        switch (mode) {\n          case 'history':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/?foo=bar1&foo=bar2')\n            break\n          case 'hash':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/#?foo=bar1&foo=bar2')\n            break\n          case 'hash-params':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/#foo=bar1&foo=bar2')\n            break\n        }\n      })\n\n      it('changes write mode', async () => {\n        const params = useUrlSearchParams(mode, { writeMode: 'push' })\n\n        params.foo = 'bar'\n        await nextTick()\n        switch (mode) {\n          case 'history':\n            expect(window.history.pushState).toBeCalledWith(null, '', '/?foo=bar')\n            expect(window.history.replaceState).not.toBeCalled()\n            break\n          case 'hash':\n            expect(window.history.pushState).toBeCalledWith(null, '', '/#?foo=bar')\n            expect(window.history.replaceState).not.toBeCalled()\n            break\n          case 'hash-params':\n            expect(window.history.pushState).toBeCalledWith(null, '', '/#foo=bar')\n            expect(window.history.replaceState).not.toBeCalled()\n            break\n        }\n      })\n\n      it('generic url search params', () => {\n        interface CustomUrlParams extends Record<string, any> {\n          customFoo: number | undefined\n        }\n\n        const params = useUrlSearchParams<CustomUrlParams>(mode)\n        expect(params.customFoo).toBeUndefined()\n\n        params.customFoo = 42\n\n        expect(params.customFoo).toEqual(42)\n      })\n\n      it('should remove null & falsy', async () => {\n        const params = useUrlSearchParams(mode, {\n          removeNullishValues: true,\n          removeFalsyValues: true,\n          initialValue: {\n            foo: 'bar',\n            bar: 'foo',\n          } as { foo: string | null, bar: string | boolean },\n        })\n        params.foo = null\n        params.bar = false\n        await nextTick()\n        expect(params).toEqual({ foo: null, bar: false })\n      })\n    })\n  })\n\n  it('hash url without params', () => {\n    window.location.hash = '#/test/'\n    const params = useUrlSearchParams('hash')\n    expect(params).toEqual({})\n\n    const newHash = '#/change/?foo=bar'\n    window.location.hash = newHash\n    expect(window.location.hash).toBe(newHash)\n  })\n})",
    "repo": "vueuse/vueuse",
    "path": "./datasets/diagrams-repos/vueuse/vueuse/packages/core/useUrlSearchParams/index.test.ts",
    "query": "What is the structure of the different modes supported by useUrlSearchParams?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'useUrlSearchParams', 'node_id': 'useUrlSearchParams', 'description': 'Main function to handle URL search parameters', 'visibility': 'public', 'return_type': None, 'params': \"mode: 'history' | 'hash' | 'hash-params'\", 'source_class_id': None}, {'type': 'entity', 'name': 'historyMode', 'node_id': 'historyMode', 'description': 'Uses browser history API with search parameters in URL path', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'hashMode', 'node_id': 'hashMode', 'description': 'Uses URL hash with search parameters after #/?', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'hashParamsMode', 'node_id': 'hashParamsMode', 'description': 'Uses URL hash with direct parameters after #', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'useUrlSearchParams', 'node_id_to': 'historyMode', 'description': 'implements'}, {'node_id_from': 'useUrlSearchParams', 'node_id_to': 'hashMode', 'description': 'implements'}, {'node_id_from': 'useUrlSearchParams', 'node_id_to': 'hashParamsMode', 'description': 'implements'}], 'packages': [{'package_id': 'urlModes', 'children': ['historyMode', 'hashMode', 'hashParamsMode'], 'description': 'Different URL parameter handling modes'}]}",
    "version": "minimal",
    "text_answer": "useUrlSearchParams supports three modes: 'history' (using URL search parameters), 'hash' (using parameters after #/?), and 'hash-params' (using parameters directly after #). Each mode handles URL parameters differently but provides consistent API for parameter manipulation.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { beforeEach, describe, expect, it, vi } from 'vitest'\nimport { nextTick } from 'vue'\nimport { useUrlSearchParams } from '.'\n\ndescribe('useUrlSearchParams', () => {\n  const baseURL = 'https://vueuse.org'\n\n  Object.defineProperty(window, 'location', {\n    value: new URL(baseURL),\n    writable: true,\n  })\n\n  const mockReplaceState = vi.fn()\n  const mockPushState = vi.fn()\n\n  beforeEach(() => {\n    vi.clearAllMocks()\n    window.location.search = ''\n    window.location.hash = ''\n    window.history.replaceState = mockReplaceState\n    window.history.pushState = mockPushState\n  })\n\n  const mockPopstate = (search: string, hash: string) => {\n    window.location.search = search\n    window.location.hash = hash\n    window.dispatchEvent(new PopStateEvent('popstate', {\n      state: {\n        ...window.location,\n        search,\n        hash,\n      },\n    }))\n  }\n\n  ([\n    'history',\n    'hash',\n    'hash-params',\n  ] as const).forEach((mode) => {\n    describe(`${mode} mode`, () => {\n      it('return initial params', async () => {\n        if (mode === 'hash')\n          window.location.hash = '#/test/?foo=bar'\n        else if (mode === 'hash-params')\n          window.location.hash = '#foo=bar'\n        else\n          window.location.search = '?foo=bar'\n\n        const params = useUrlSearchParams(mode)\n\n        await nextTick()\n        expect(params.foo).toBe('bar')\n      })\n\n      it('return initialValue', async () => {\n        const initialValue = { foo: 'bar' }\n        const params1 = useUrlSearchParams(mode, { initialValue })\n        // @ts-expect-error test window=null\n        const params2 = useUrlSearchParams(mode, { initialValue, window: null })\n\n        expect(params1.foo).toBe('bar')\n        expect(params2.foo).toBe('bar')\n      })\n\n      it('update params on poststate event', async () => {\n        const params = useUrlSearchParams(mode)\n        expect(params.foo).toBeUndefined()\n\n        switch (mode) {\n          case 'hash':\n            mockPopstate('', '#/test/?foo=bar')\n            break\n          case 'hash-params':\n            mockPopstate('', '#foo=bar')\n            break\n          case 'history':\n            mockPopstate('?foo=bar', '')\n        }\n        await nextTick()\n        expect(params.foo).toBe('bar')\n\n        switch (mode) {\n          case 'hash':\n            mockPopstate('', '#/test/?foo=bar1&foo=bar2')\n            break\n          case 'hash-params':\n            mockPopstate('', '#foo=bar1&foo=bar2')\n            break\n          case 'history':\n            mockPopstate('?foo=bar1&foo=bar2', '')\n        }\n        await nextTick()\n        expect(params.foo).toEqual(['bar1', 'bar2'])\n\n        switch (mode) {\n          case 'hash':\n            mockPopstate('', '#/test/?foo=')\n            break\n          case 'hash-params':\n            mockPopstate('', '#foo=')\n            break\n          case 'history':\n            mockPopstate('?foo=', '')\n        }\n        await nextTick()\n        expect(params.foo).toBe('')\n      })\n\n      it('stop poststate event', async () => {\n        const params = useUrlSearchParams(mode, { write: false })\n        expect(params.foo).toBeUndefined()\n\n        switch (mode) {\n          case 'hash':\n            mockPopstate('', '#/test/?foo=bar')\n            break\n          case 'hash-params':\n            mockPopstate('', '#foo=bar')\n            break\n          case 'history':\n            mockPopstate('?foo=bar', '')\n        }\n        await nextTick()\n        expect(params.foo).toBeUndefined()\n      })\n\n      it('update browser location on params change', async () => {\n        const params = useUrlSearchParams(mode)\n\n        params.foo = 'bar'\n        await nextTick()\n        switch (mode) {\n          case 'history':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/?foo=bar')\n            break\n          case 'hash':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/#?foo=bar')\n            break\n          case 'hash-params':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/#foo=bar')\n            break\n        }\n\n        if (mode === 'hash')\n          window.location.hash = '#?foo=bar'\n\n        delete params.foo\n        await nextTick()\n        switch (mode) {\n          case 'history':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/')\n            break\n          case 'hash':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/#')\n            break\n          case 'hash-params':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/')\n            break\n        }\n      })\n\n      it('array url search param', async () => {\n        const params = useUrlSearchParams(mode)\n        expect(params.foo).toBeUndefined()\n        params.foo = ['bar1', 'bar2']\n\n        await nextTick()\n        switch (mode) {\n          case 'history':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/?foo=bar1&foo=bar2')\n            break\n          case 'hash':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/#?foo=bar1&foo=bar2')\n            break\n          case 'hash-params':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/#foo=bar1&foo=bar2')\n            break\n        }\n      })\n\n      it('changes write mode', async () => {\n        const params = useUrlSearchParams(mode, { writeMode: 'push' })\n\n        params.foo = 'bar'\n        await nextTick()\n        switch (mode) {\n          case 'history':\n            expect(window.history.pushState).toBeCalledWith(null, '', '/?foo=bar')\n            expect(window.history.replaceState).not.toBeCalled()\n            break\n          case 'hash':\n            expect(window.history.pushState).toBeCalledWith(null, '', '/#?foo=bar')\n            expect(window.history.replaceState).not.toBeCalled()\n            break\n          case 'hash-params':\n            expect(window.history.pushState).toBeCalledWith(null, '', '/#foo=bar')\n            expect(window.history.replaceState).not.toBeCalled()\n            break\n        }\n      })\n\n      it('generic url search params', () => {\n        interface CustomUrlParams extends Record<string, any> {\n          customFoo: number | undefined\n        }\n\n        const params = useUrlSearchParams<CustomUrlParams>(mode)\n        expect(params.customFoo).toBeUndefined()\n\n        params.customFoo = 42\n\n        expect(params.customFoo).toEqual(42)\n      })\n\n      it('should remove null & falsy', async () => {\n        const params = useUrlSearchParams(mode, {\n          removeNullishValues: true,\n          removeFalsyValues: true,\n          initialValue: {\n            foo: 'bar',\n            bar: 'foo',\n          } as { foo: string | null, bar: string | boolean },\n        })\n        params.foo = null\n        params.bar = false\n        await nextTick()\n        expect(params).toEqual({ foo: null, bar: false })\n      })\n    })\n  })\n\n  it('hash url without params', () => {\n    window.location.hash = '#/test/'\n    const params = useUrlSearchParams('hash')\n    expect(params).toEqual({})\n\n    const newHash = '#/change/?foo=bar'\n    window.location.hash = newHash\n    expect(window.location.hash).toBe(newHash)\n  })\n})",
    "repo": "vueuse/vueuse",
    "path": "./datasets/diagrams-repos/vueuse/vueuse/packages/core/useUrlSearchParams/index.test.ts",
    "query": "What is the structure of the different modes supported by useUrlSearchParams?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'useUrlSearchParams', 'node_id': 'useUrlSearchParams', 'description': 'Main function to handle URL search parameters', 'visibility': 'public', 'return_type': None, 'params': 'mode, options', 'source_class_id': None}, {'type': 'entity', 'name': 'historyMode', 'node_id': 'historyMode', 'description': 'Uses browser history API with search parameters in URL path', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'hashMode', 'node_id': 'hashMode', 'description': 'Uses URL hash with search parameters after #/?', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'hashParamsMode', 'node_id': 'hashParamsMode', 'description': 'Uses URL hash with direct parameters after #', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'replaceState', 'node_id': 'replaceState', 'description': 'Updates URL without creating history entry', 'visibility': 'public', 'return_type': None, 'params': 'state, title, url', 'source_class_id': None}, {'type': 'function', 'name': 'pushState', 'node_id': 'pushState', 'description': 'Updates URL and creates history entry', 'visibility': 'public', 'return_type': None, 'params': 'state, title, url', 'source_class_id': None}], 'edges': [{'node_id_from': 'useUrlSearchParams', 'node_id_to': 'historyMode', 'description': 'implements'}, {'node_id_from': 'useUrlSearchParams', 'node_id_to': 'hashMode', 'description': 'implements'}, {'node_id_from': 'useUrlSearchParams', 'node_id_to': 'hashParamsMode', 'description': 'implements'}, {'node_id_from': 'historyMode', 'node_id_to': 'replaceState', 'description': 'uses'}, {'node_id_from': 'hashMode', 'node_id_to': 'replaceState', 'description': 'uses'}, {'node_id_from': 'hashParamsMode', 'node_id_to': 'replaceState', 'description': 'uses'}, {'node_id_from': 'historyMode', 'node_id_to': 'pushState', 'description': 'uses'}, {'node_id_from': 'hashMode', 'node_id_to': 'pushState', 'description': 'uses'}, {'node_id_from': 'hashParamsMode', 'node_id_to': 'pushState', 'description': 'uses'}], 'packages': [{'package_id': 'urlModes', 'children': ['historyMode', 'hashMode', 'hashParamsMode'], 'description': 'Different URL parameter handling modes'}, {'package_id': 'historyAPI', 'children': ['replaceState', 'pushState'], 'description': 'Browser history API methods'}]}",
    "version": "medium",
    "text_answer": "useUrlSearchParams supports three modes: 'history' (using URL search parameters), 'hash' (using parameters after #/?), and 'hash-params' (using parameters directly after #). Each mode handles URL parameters differently but provides consistent API for parameter manipulation.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { beforeEach, describe, expect, it, vi } from 'vitest'\nimport { nextTick } from 'vue'\nimport { useUrlSearchParams } from '.'\n\ndescribe('useUrlSearchParams', () => {\n  const baseURL = 'https://vueuse.org'\n\n  Object.defineProperty(window, 'location', {\n    value: new URL(baseURL),\n    writable: true,\n  })\n\n  const mockReplaceState = vi.fn()\n  const mockPushState = vi.fn()\n\n  beforeEach(() => {\n    vi.clearAllMocks()\n    window.location.search = ''\n    window.location.hash = ''\n    window.history.replaceState = mockReplaceState\n    window.history.pushState = mockPushState\n  })\n\n  const mockPopstate = (search: string, hash: string) => {\n    window.location.search = search\n    window.location.hash = hash\n    window.dispatchEvent(new PopStateEvent('popstate', {\n      state: {\n        ...window.location,\n        search,\n        hash,\n      },\n    }))\n  }\n\n  ([\n    'history',\n    'hash',\n    'hash-params',\n  ] as const).forEach((mode) => {\n    describe(`${mode} mode`, () => {\n      it('return initial params', async () => {\n        if (mode === 'hash')\n          window.location.hash = '#/test/?foo=bar'\n        else if (mode === 'hash-params')\n          window.location.hash = '#foo=bar'\n        else\n          window.location.search = '?foo=bar'\n\n        const params = useUrlSearchParams(mode)\n\n        await nextTick()\n        expect(params.foo).toBe('bar')\n      })\n\n      it('return initialValue', async () => {\n        const initialValue = { foo: 'bar' }\n        const params1 = useUrlSearchParams(mode, { initialValue })\n        // @ts-expect-error test window=null\n        const params2 = useUrlSearchParams(mode, { initialValue, window: null })\n\n        expect(params1.foo).toBe('bar')\n        expect(params2.foo).toBe('bar')\n      })\n\n      it('update params on poststate event', async () => {\n        const params = useUrlSearchParams(mode)\n        expect(params.foo).toBeUndefined()\n\n        switch (mode) {\n          case 'hash':\n            mockPopstate('', '#/test/?foo=bar')\n            break\n          case 'hash-params':\n            mockPopstate('', '#foo=bar')\n            break\n          case 'history':\n            mockPopstate('?foo=bar', '')\n        }\n        await nextTick()\n        expect(params.foo).toBe('bar')\n\n        switch (mode) {\n          case 'hash':\n            mockPopstate('', '#/test/?foo=bar1&foo=bar2')\n            break\n          case 'hash-params':\n            mockPopstate('', '#foo=bar1&foo=bar2')\n            break\n          case 'history':\n            mockPopstate('?foo=bar1&foo=bar2', '')\n        }\n        await nextTick()\n        expect(params.foo).toEqual(['bar1', 'bar2'])\n\n        switch (mode) {\n          case 'hash':\n            mockPopstate('', '#/test/?foo=')\n            break\n          case 'hash-params':\n            mockPopstate('', '#foo=')\n            break\n          case 'history':\n            mockPopstate('?foo=', '')\n        }\n        await nextTick()\n        expect(params.foo).toBe('')\n      })\n\n      it('stop poststate event', async () => {\n        const params = useUrlSearchParams(mode, { write: false })\n        expect(params.foo).toBeUndefined()\n\n        switch (mode) {\n          case 'hash':\n            mockPopstate('', '#/test/?foo=bar')\n            break\n          case 'hash-params':\n            mockPopstate('', '#foo=bar')\n            break\n          case 'history':\n            mockPopstate('?foo=bar', '')\n        }\n        await nextTick()\n        expect(params.foo).toBeUndefined()\n      })\n\n      it('update browser location on params change', async () => {\n        const params = useUrlSearchParams(mode)\n\n        params.foo = 'bar'\n        await nextTick()\n        switch (mode) {\n          case 'history':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/?foo=bar')\n            break\n          case 'hash':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/#?foo=bar')\n            break\n          case 'hash-params':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/#foo=bar')\n            break\n        }\n\n        if (mode === 'hash')\n          window.location.hash = '#?foo=bar'\n\n        delete params.foo\n        await nextTick()\n        switch (mode) {\n          case 'history':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/')\n            break\n          case 'hash':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/#')\n            break\n          case 'hash-params':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/')\n            break\n        }\n      })\n\n      it('array url search param', async () => {\n        const params = useUrlSearchParams(mode)\n        expect(params.foo).toBeUndefined()\n        params.foo = ['bar1', 'bar2']\n\n        await nextTick()\n        switch (mode) {\n          case 'history':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/?foo=bar1&foo=bar2')\n            break\n          case 'hash':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/#?foo=bar1&foo=bar2')\n            break\n          case 'hash-params':\n            expect(window.history.replaceState).toBeCalledWith(null, '', '/#foo=bar1&foo=bar2')\n            break\n        }\n      })\n\n      it('changes write mode', async () => {\n        const params = useUrlSearchParams(mode, { writeMode: 'push' })\n\n        params.foo = 'bar'\n        await nextTick()\n        switch (mode) {\n          case 'history':\n            expect(window.history.pushState).toBeCalledWith(null, '', '/?foo=bar')\n            expect(window.history.replaceState).not.toBeCalled()\n            break\n          case 'hash':\n            expect(window.history.pushState).toBeCalledWith(null, '', '/#?foo=bar')\n            expect(window.history.replaceState).not.toBeCalled()\n            break\n          case 'hash-params':\n            expect(window.history.pushState).toBeCalledWith(null, '', '/#foo=bar')\n            expect(window.history.replaceState).not.toBeCalled()\n            break\n        }\n      })\n\n      it('generic url search params', () => {\n        interface CustomUrlParams extends Record<string, any> {\n          customFoo: number | undefined\n        }\n\n        const params = useUrlSearchParams<CustomUrlParams>(mode)\n        expect(params.customFoo).toBeUndefined()\n\n        params.customFoo = 42\n\n        expect(params.customFoo).toEqual(42)\n      })\n\n      it('should remove null & falsy', async () => {\n        const params = useUrlSearchParams(mode, {\n          removeNullishValues: true,\n          removeFalsyValues: true,\n          initialValue: {\n            foo: 'bar',\n            bar: 'foo',\n          } as { foo: string | null, bar: string | boolean },\n        })\n        params.foo = null\n        params.bar = false\n        await nextTick()\n        expect(params).toEqual({ foo: null, bar: false })\n      })\n    })\n  })\n\n  it('hash url without params', () => {\n    window.location.hash = '#/test/'\n    const params = useUrlSearchParams('hash')\n    expect(params).toEqual({})\n\n    const newHash = '#/change/?foo=bar'\n    window.location.hash = newHash\n    expect(window.location.hash).toBe(newHash)\n  })\n})",
    "repo": "vueuse/vueuse",
    "path": "./datasets/diagrams-repos/vueuse/vueuse/packages/core/useUrlSearchParams/index.test.ts",
    "query": "What is the structure of the different modes supported by useUrlSearchParams?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'useUrlSearchParams', 'node_id': 'useUrlSearchParams', 'description': 'Main function to handle URL search parameters', 'visibility': 'public', 'return_type': None, 'params': 'mode, options', 'source_class_id': None}, {'type': 'entity', 'name': 'historyMode', 'node_id': 'historyMode', 'description': 'Uses browser history API with search parameters in URL path', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'hashMode', 'node_id': 'hashMode', 'description': 'Uses URL hash with search parameters after #/?', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'hashParamsMode', 'node_id': 'hashParamsMode', 'description': 'Uses URL hash with direct parameters after #', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'replaceState', 'node_id': 'replaceState', 'description': 'Updates URL without creating history entry', 'visibility': 'public', 'return_type': None, 'params': 'state, title, url', 'source_class_id': None}, {'type': 'function', 'name': 'pushState', 'node_id': 'pushState', 'description': 'Updates URL and creates history entry', 'visibility': 'public', 'return_type': None, 'params': 'state, title, url', 'source_class_id': None}, {'type': 'variable', 'name': 'initialValue', 'node_id': 'initialValue', 'description': 'Initial parameters value', 'visibility': 'public', 'return_type': 'object', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'writeMode', 'node_id': 'writeMode', 'description': 'Mode of writing URL changes', 'visibility': 'public', 'return_type': 'string', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'removeNullishValues', 'node_id': 'removeNullishValues', 'description': 'Flag to remove None values', 'visibility': 'public', 'return_type': 'boolean', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'removeFalsyValues', 'node_id': 'removeFalsyValues', 'description': 'Flag to remove falsy values', 'visibility': 'public', 'return_type': 'boolean', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'useUrlSearchParams', 'node_id_to': 'historyMode', 'description': 'implements'}, {'node_id_from': 'useUrlSearchParams', 'node_id_to': 'hashMode', 'description': 'implements'}, {'node_id_from': 'useUrlSearchParams', 'node_id_to': 'hashParamsMode', 'description': 'implements'}, {'node_id_from': 'historyMode', 'node_id_to': 'replaceState', 'description': 'uses'}, {'node_id_from': 'hashMode', 'node_id_to': 'replaceState', 'description': 'uses'}, {'node_id_from': 'hashParamsMode', 'node_id_to': 'replaceState', 'description': 'uses'}, {'node_id_from': 'useUrlSearchParams', 'node_id_to': 'initialValue', 'description': 'configures'}, {'node_id_from': 'useUrlSearchParams', 'node_id_to': 'writeMode', 'description': 'configures'}, {'node_id_from': 'useUrlSearchParams', 'node_id_to': 'removeNullishValues', 'description': 'configures'}, {'node_id_from': 'useUrlSearchParams', 'node_id_to': 'removeFalsyValues', 'description': 'configures'}, {'node_id_from': 'historyMode', 'node_id_to': 'pushState', 'description': 'uses'}, {'node_id_from': 'hashMode', 'node_id_to': 'pushState', 'description': 'uses'}, {'node_id_from': 'hashParamsMode', 'node_id_to': 'pushState', 'description': 'uses'}], 'packages': [{'package_id': 'urlModes', 'children': ['historyMode', 'hashMode', 'hashParamsMode'], 'description': 'Different URL parameter handling modes'}, {'package_id': 'historyAPI', 'children': ['replaceState', 'pushState'], 'description': 'Browser history API methods'}, {'package_id': 'configuration', 'children': ['initialValue', 'writeMode', 'removeNullishValues', 'removeFalsyValues'], 'description': 'Configuration options'}]}",
    "version": "full",
    "text_answer": "useUrlSearchParams supports three modes: 'history' (using URL search parameters), 'hash' (using parameters after #/?), and 'hash-params' (using parameters directly after #). Each mode handles URL parameters differently but provides consistent API for parameter manipulation.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport * as recast from 'recast';\nimport { parse as docgenParse, PropTypeDescriptor } from 'react-docgen';\nimport { escapeCell, escapeEntities, joinUnionTypes } from '../buildApi';\n\nfunction getDeprecatedInfo(type: PropTypeDescriptor) {\n  const marker = /deprecatedPropType\\((\\r*\\n)*\\s*PropTypes\\./g;\n  const match = type.raw.match(marker);\n  const startIndex = type.raw.search(marker);\n  if (match) {\n    const offset = match[0].length;\n\n    return {\n      propTypes: type.raw.substring(startIndex + offset, type.raw.indexOf(',')),\n      explanation: recast.parse(type.raw).program.body[0].expression.arguments[1].value,\n    };\n  }\n\n  return false;\n}\n\nexport function getChained(type: PropTypeDescriptor) {\n  if (type.raw) {\n    const marker = 'chainPropTypes';\n    const indexStart = type.raw.indexOf(marker);\n\n    if (indexStart !== -1) {\n      const parsed = docgenParse(\n        `\n        import PropTypes from 'prop-types';\n        const Foo = () => <div />\n        Foo.propTypes = {\n          bar: ${recast.print(recast.parse(type.raw).program.body[0].expression.arguments[0]).code}\n        }\n        export default Foo\n      `,\n        null,\n        null,\n        // helps react-docgen pickup babel.config.js\n        { filename: './' },\n      );\n      return {\n        type: parsed.props.bar.type,\n        required: parsed.props.bar.required,\n      };\n    }\n  }\n\n  return false;\n}\n\nexport function isElementTypeAcceptingRefProp(type: PropTypeDescriptor): boolean {\n  return type.raw === 'elementTypeAcceptingRef';\n}\n\nfunction isRefType(type: PropTypeDescriptor): boolean {\n  return type.raw === 'refType';\n}\n\nfunction isIntegerType(type: PropTypeDescriptor): boolean {\n  return type.raw.startsWith('integerPropType');\n}\n\nexport function isElementAcceptingRefProp(type: PropTypeDescriptor): boolean {\n  return /^elementAcceptingRef/.test(type.raw);\n}\n\nexport default function generatePropTypeDescription(type: PropTypeDescriptor): string | undefined {\n  switch (type.name) {\n    case 'custom': {\n      if (isElementTypeAcceptingRefProp(type)) {\n        return 'element type';\n      }\n      if (isElementAcceptingRefProp(type)) {\n        return 'element';\n      }\n      if (isIntegerType(type)) {\n        return 'integer';\n      }\n      if (isRefType(type)) {\n        return 'ref';\n      }\n      if (type.raw === 'HTMLElementType') {\n        return 'HTML element';\n      }\n      if (type.raw === '() => null') {\n        return 'any';\n      }\n\n      const deprecatedInfo = getDeprecatedInfo(type);\n      if (deprecatedInfo !== false) {\n        return generatePropTypeDescription({\n          // eslint-disable-next-line react/forbid-foreign-prop-types\n          name: deprecatedInfo.propTypes,\n        } as any);\n      }\n\n      const chained = getChained(type);\n      if (chained !== false) {\n        return generatePropTypeDescription(chained.type);\n      }\n\n      return type.raw;\n    }\n\n    case 'shape':\n      return `{ ${Object.keys(type.value)\n        .map((subValue) => {\n          const subType = type.value[subValue];\n          return `${subValue}${subType.required ? '' : '?'}: ${generatePropTypeDescription(\n            subType,\n          )}`;\n        })\n        .join(', ')} }`;\n\n    case 'union':\n      return joinUnionTypes(\n        type.value.map((type2) => {\n          return generatePropTypeDescription(type2) ?? '';\n        }),\n      );\n    case 'enum':\n      return joinUnionTypes(\n        type.value.map((type2) => {\n          return escapeCell(type2.value);\n        }),\n      );\n\n    case 'arrayOf': {\n      return `Array${escapeEntities('<')}${generatePropTypeDescription(type.value)}${escapeEntities('>')}`;\n    }\n\n    case 'instanceOf': {\n      if (type.value.startsWith('typeof')) {\n        return /typeof (.*) ===/.exec(type.value)![1];\n      }\n      return type.value;\n    }\n\n    default:\n      return type.name;\n  }\n}",
    "repo": "mui/material-ui",
    "path": "./datasets/diagrams-repos/mui/material-ui/packages/api-docs-builder/utils/generatePropTypeDescription.ts",
    "query": "How do the functions interact with each other in terms of prop type handling?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'generatePropTypeDescription', 'node_id': 'generatePropTypeDescription', 'description': 'Main function that generates description for different prop types', 'visibility': 'public', 'return_type': 'string | undefined', 'params': 'type: PropTypeDescriptor', 'source_class_id': None}, {'type': 'function', 'name': 'getDeprecatedInfo', 'node_id': 'getDeprecatedInfo', 'description': 'Extracts deprecated information from prop type', 'visibility': 'private', 'return_type': 'object | false', 'params': 'type: PropTypeDescriptor', 'source_class_id': None}, {'type': 'function', 'name': 'getChained', 'node_id': 'getChained', 'description': 'Processes chained prop types', 'visibility': 'public', 'return_type': 'object | false', 'params': 'type: PropTypeDescriptor', 'source_class_id': None}], 'edges': [{'node_id_from': 'generatePropTypeDescription', 'node_id_to': 'getDeprecatedInfo', 'description': 'calls to handle deprecated props'}, {'node_id_from': 'generatePropTypeDescription', 'node_id_to': 'getChained', 'description': 'calls to handle chained props'}], 'packages': [{'package_id': 'propTypeHandling', 'children': ['generatePropTypeDescription', 'getDeprecatedInfo', 'getChained'], 'description': 'Core prop type processing functionality'}]}",
    "version": "minimal",
    "text_answer": "The generatePropTypeDescription function serves as the main entry point, processing various prop types by delegating to specialized helper functions. It handles deprecated props through getDeprecatedInfo, chained props via getChained, and uses multiple type-checking functions to determine specific prop types. The function also formats the output using utility functions for unions and escaping.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport * as recast from 'recast';\nimport { parse as docgenParse, PropTypeDescriptor } from 'react-docgen';\nimport { escapeCell, escapeEntities, joinUnionTypes } from '../buildApi';\n\nfunction getDeprecatedInfo(type: PropTypeDescriptor) {\n  const marker = /deprecatedPropType\\((\\r*\\n)*\\s*PropTypes\\./g;\n  const match = type.raw.match(marker);\n  const startIndex = type.raw.search(marker);\n  if (match) {\n    const offset = match[0].length;\n\n    return {\n      propTypes: type.raw.substring(startIndex + offset, type.raw.indexOf(',')),\n      explanation: recast.parse(type.raw).program.body[0].expression.arguments[1].value,\n    };\n  }\n\n  return false;\n}\n\nexport function getChained(type: PropTypeDescriptor) {\n  if (type.raw) {\n    const marker = 'chainPropTypes';\n    const indexStart = type.raw.indexOf(marker);\n\n    if (indexStart !== -1) {\n      const parsed = docgenParse(\n        `\n        import PropTypes from 'prop-types';\n        const Foo = () => <div />\n        Foo.propTypes = {\n          bar: ${recast.print(recast.parse(type.raw).program.body[0].expression.arguments[0]).code}\n        }\n        export default Foo\n      `,\n        null,\n        null,\n        // helps react-docgen pickup babel.config.js\n        { filename: './' },\n      );\n      return {\n        type: parsed.props.bar.type,\n        required: parsed.props.bar.required,\n      };\n    }\n  }\n\n  return false;\n}\n\nexport function isElementTypeAcceptingRefProp(type: PropTypeDescriptor): boolean {\n  return type.raw === 'elementTypeAcceptingRef';\n}\n\nfunction isRefType(type: PropTypeDescriptor): boolean {\n  return type.raw === 'refType';\n}\n\nfunction isIntegerType(type: PropTypeDescriptor): boolean {\n  return type.raw.startsWith('integerPropType');\n}\n\nexport function isElementAcceptingRefProp(type: PropTypeDescriptor): boolean {\n  return /^elementAcceptingRef/.test(type.raw);\n}\n\nexport default function generatePropTypeDescription(type: PropTypeDescriptor): string | undefined {\n  switch (type.name) {\n    case 'custom': {\n      if (isElementTypeAcceptingRefProp(type)) {\n        return 'element type';\n      }\n      if (isElementAcceptingRefProp(type)) {\n        return 'element';\n      }\n      if (isIntegerType(type)) {\n        return 'integer';\n      }\n      if (isRefType(type)) {\n        return 'ref';\n      }\n      if (type.raw === 'HTMLElementType') {\n        return 'HTML element';\n      }\n      if (type.raw === '() => null') {\n        return 'any';\n      }\n\n      const deprecatedInfo = getDeprecatedInfo(type);\n      if (deprecatedInfo !== false) {\n        return generatePropTypeDescription({\n          // eslint-disable-next-line react/forbid-foreign-prop-types\n          name: deprecatedInfo.propTypes,\n        } as any);\n      }\n\n      const chained = getChained(type);\n      if (chained !== false) {\n        return generatePropTypeDescription(chained.type);\n      }\n\n      return type.raw;\n    }\n\n    case 'shape':\n      return `{ ${Object.keys(type.value)\n        .map((subValue) => {\n          const subType = type.value[subValue];\n          return `${subValue}${subType.required ? '' : '?'}: ${generatePropTypeDescription(\n            subType,\n          )}`;\n        })\n        .join(', ')} }`;\n\n    case 'union':\n      return joinUnionTypes(\n        type.value.map((type2) => {\n          return generatePropTypeDescription(type2) ?? '';\n        }),\n      );\n    case 'enum':\n      return joinUnionTypes(\n        type.value.map((type2) => {\n          return escapeCell(type2.value);\n        }),\n      );\n\n    case 'arrayOf': {\n      return `Array${escapeEntities('<')}${generatePropTypeDescription(type.value)}${escapeEntities('>')}`;\n    }\n\n    case 'instanceOf': {\n      if (type.value.startsWith('typeof')) {\n        return /typeof (.*) ===/.exec(type.value)![1];\n      }\n      return type.value;\n    }\n\n    default:\n      return type.name;\n  }\n}",
    "repo": "mui/material-ui",
    "path": "./datasets/diagrams-repos/mui/material-ui/packages/api-docs-builder/utils/generatePropTypeDescription.ts",
    "query": "How do the functions interact with each other in terms of prop type handling?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'generatePropTypeDescription', 'node_id': 'generatePropTypeDescription', 'description': 'Main function that generates description for different prop types', 'visibility': 'public', 'return_type': 'string | undefined', 'params': 'type: PropTypeDescriptor', 'source_class_id': None}, {'type': 'function', 'name': 'getDeprecatedInfo', 'node_id': 'getDeprecatedInfo', 'description': 'Extracts deprecated information from prop type', 'visibility': 'private', 'return_type': 'object | false', 'params': 'type: PropTypeDescriptor', 'source_class_id': None}, {'type': 'function', 'name': 'getChained', 'node_id': 'getChained', 'description': 'Processes chained prop types', 'visibility': 'public', 'return_type': 'object | false', 'params': 'type: PropTypeDescriptor', 'source_class_id': None}, {'type': 'function', 'name': 'isElementTypeAcceptingRefProp', 'node_id': 'isElementTypeAcceptingRefProp', 'description': 'Checks if type accepts ref prop', 'visibility': 'public', 'return_type': 'boolean', 'params': 'type: PropTypeDescriptor', 'source_class_id': None}, {'type': 'function', 'name': 'isElementAcceptingRefProp', 'node_id': 'isElementAcceptingRefProp', 'description': 'Checks if element accepts ref prop', 'visibility': 'public', 'return_type': 'boolean', 'params': 'type: PropTypeDescriptor', 'source_class_id': None}], 'edges': [{'node_id_from': 'generatePropTypeDescription', 'node_id_to': 'getDeprecatedInfo', 'description': 'calls to handle deprecated props'}, {'node_id_from': 'generatePropTypeDescription', 'node_id_to': 'getChained', 'description': 'calls to handle chained props'}, {'node_id_from': 'generatePropTypeDescription', 'node_id_to': 'isElementTypeAcceptingRefProp', 'description': 'checks element type ref acceptance'}, {'node_id_from': 'generatePropTypeDescription', 'node_id_to': 'isElementAcceptingRefProp', 'description': 'checks element ref acceptance'}], 'packages': [{'package_id': 'propTypeHandling', 'children': ['generatePropTypeDescription', 'getDeprecatedInfo', 'getChained'], 'description': 'Core prop type processing functionality'}, {'package_id': 'refTypeChecks', 'children': ['isElementTypeAcceptingRefProp', 'isElementAcceptingRefProp'], 'description': 'Reference prop type validation'}]}",
    "version": "medium",
    "text_answer": "The generatePropTypeDescription function serves as the main entry point, processing various prop types by delegating to specialized helper functions. It handles deprecated props through getDeprecatedInfo, chained props via getChained, and uses multiple type-checking functions to determine specific prop types. The function also formats the output using utility functions for unions and escaping.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport * as recast from 'recast';\nimport { parse as docgenParse, PropTypeDescriptor } from 'react-docgen';\nimport { escapeCell, escapeEntities, joinUnionTypes } from '../buildApi';\n\nfunction getDeprecatedInfo(type: PropTypeDescriptor) {\n  const marker = /deprecatedPropType\\((\\r*\\n)*\\s*PropTypes\\./g;\n  const match = type.raw.match(marker);\n  const startIndex = type.raw.search(marker);\n  if (match) {\n    const offset = match[0].length;\n\n    return {\n      propTypes: type.raw.substring(startIndex + offset, type.raw.indexOf(',')),\n      explanation: recast.parse(type.raw).program.body[0].expression.arguments[1].value,\n    };\n  }\n\n  return false;\n}\n\nexport function getChained(type: PropTypeDescriptor) {\n  if (type.raw) {\n    const marker = 'chainPropTypes';\n    const indexStart = type.raw.indexOf(marker);\n\n    if (indexStart !== -1) {\n      const parsed = docgenParse(\n        `\n        import PropTypes from 'prop-types';\n        const Foo = () => <div />\n        Foo.propTypes = {\n          bar: ${recast.print(recast.parse(type.raw).program.body[0].expression.arguments[0]).code}\n        }\n        export default Foo\n      `,\n        null,\n        null,\n        // helps react-docgen pickup babel.config.js\n        { filename: './' },\n      );\n      return {\n        type: parsed.props.bar.type,\n        required: parsed.props.bar.required,\n      };\n    }\n  }\n\n  return false;\n}\n\nexport function isElementTypeAcceptingRefProp(type: PropTypeDescriptor): boolean {\n  return type.raw === 'elementTypeAcceptingRef';\n}\n\nfunction isRefType(type: PropTypeDescriptor): boolean {\n  return type.raw === 'refType';\n}\n\nfunction isIntegerType(type: PropTypeDescriptor): boolean {\n  return type.raw.startsWith('integerPropType');\n}\n\nexport function isElementAcceptingRefProp(type: PropTypeDescriptor): boolean {\n  return /^elementAcceptingRef/.test(type.raw);\n}\n\nexport default function generatePropTypeDescription(type: PropTypeDescriptor): string | undefined {\n  switch (type.name) {\n    case 'custom': {\n      if (isElementTypeAcceptingRefProp(type)) {\n        return 'element type';\n      }\n      if (isElementAcceptingRefProp(type)) {\n        return 'element';\n      }\n      if (isIntegerType(type)) {\n        return 'integer';\n      }\n      if (isRefType(type)) {\n        return 'ref';\n      }\n      if (type.raw === 'HTMLElementType') {\n        return 'HTML element';\n      }\n      if (type.raw === '() => null') {\n        return 'any';\n      }\n\n      const deprecatedInfo = getDeprecatedInfo(type);\n      if (deprecatedInfo !== false) {\n        return generatePropTypeDescription({\n          // eslint-disable-next-line react/forbid-foreign-prop-types\n          name: deprecatedInfo.propTypes,\n        } as any);\n      }\n\n      const chained = getChained(type);\n      if (chained !== false) {\n        return generatePropTypeDescription(chained.type);\n      }\n\n      return type.raw;\n    }\n\n    case 'shape':\n      return `{ ${Object.keys(type.value)\n        .map((subValue) => {\n          const subType = type.value[subValue];\n          return `${subValue}${subType.required ? '' : '?'}: ${generatePropTypeDescription(\n            subType,\n          )}`;\n        })\n        .join(', ')} }`;\n\n    case 'union':\n      return joinUnionTypes(\n        type.value.map((type2) => {\n          return generatePropTypeDescription(type2) ?? '';\n        }),\n      );\n    case 'enum':\n      return joinUnionTypes(\n        type.value.map((type2) => {\n          return escapeCell(type2.value);\n        }),\n      );\n\n    case 'arrayOf': {\n      return `Array${escapeEntities('<')}${generatePropTypeDescription(type.value)}${escapeEntities('>')}`;\n    }\n\n    case 'instanceOf': {\n      if (type.value.startsWith('typeof')) {\n        return /typeof (.*) ===/.exec(type.value)![1];\n      }\n      return type.value;\n    }\n\n    default:\n      return type.name;\n  }\n}",
    "repo": "mui/material-ui",
    "path": "./datasets/diagrams-repos/mui/material-ui/packages/api-docs-builder/utils/generatePropTypeDescription.ts",
    "query": "How do the functions interact with each other in terms of prop type handling?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'generatePropTypeDescription', 'node_id': 'generatePropTypeDescription', 'description': 'Main function that generates description for different prop types', 'visibility': 'public', 'return_type': 'string | undefined', 'params': 'type: PropTypeDescriptor', 'source_class_id': None}, {'type': 'function', 'name': 'getDeprecatedInfo', 'node_id': 'getDeprecatedInfo', 'description': 'Extracts deprecated information from prop type', 'visibility': 'private', 'return_type': 'object | false', 'params': 'type: PropTypeDescriptor', 'source_class_id': None}, {'type': 'function', 'name': 'getChained', 'node_id': 'getChained', 'description': 'Processes chained prop types', 'visibility': 'public', 'return_type': 'object | false', 'params': 'type: PropTypeDescriptor', 'source_class_id': None}, {'type': 'function', 'name': 'isElementTypeAcceptingRefProp', 'node_id': 'isElementTypeAcceptingRefProp', 'description': 'Checks if type accepts ref prop', 'visibility': 'public', 'return_type': 'boolean', 'params': 'type: PropTypeDescriptor', 'source_class_id': None}, {'type': 'function', 'name': 'isElementAcceptingRefProp', 'node_id': 'isElementAcceptingRefProp', 'description': 'Checks if element accepts ref prop', 'visibility': 'public', 'return_type': 'boolean', 'params': 'type: PropTypeDescriptor', 'source_class_id': None}, {'type': 'function', 'name': 'isRefType', 'node_id': 'isRefType', 'description': 'Checks if type is ref type', 'visibility': 'private', 'return_type': 'boolean', 'params': 'type: PropTypeDescriptor', 'source_class_id': None}, {'type': 'function', 'name': 'isIntegerType', 'node_id': 'isIntegerType', 'description': 'Checks if type is integer', 'visibility': 'private', 'return_type': 'boolean', 'params': 'type: PropTypeDescriptor', 'source_class_id': None}, {'type': 'function', 'name': 'joinUnionTypes', 'node_id': 'joinUnionTypes', 'description': 'Joins union type descriptions', 'visibility': 'public', 'return_type': 'string', 'params': 'types: string[]', 'source_class_id': None}, {'type': 'function', 'name': 'escapeCell', 'node_id': 'escapeCell', 'description': 'Escapes cell content', 'visibility': 'public', 'return_type': 'string', 'params': 'content: string', 'source_class_id': None}, {'type': 'function', 'name': 'escapeEntities', 'node_id': 'escapeEntities', 'description': 'Escapes HTML entities', 'visibility': 'public', 'return_type': 'string', 'params': 'content: string', 'source_class_id': None}], 'edges': [{'node_id_from': 'generatePropTypeDescription', 'node_id_to': 'getDeprecatedInfo', 'description': 'calls to handle deprecated props'}, {'node_id_from': 'generatePropTypeDescription', 'node_id_to': 'getChained', 'description': 'calls to handle chained props'}, {'node_id_from': 'generatePropTypeDescription', 'node_id_to': 'isElementTypeAcceptingRefProp', 'description': 'checks element type ref acceptance'}, {'node_id_from': 'generatePropTypeDescription', 'node_id_to': 'isElementAcceptingRefProp', 'description': 'checks element ref acceptance'}, {'node_id_from': 'generatePropTypeDescription', 'node_id_to': 'isRefType', 'description': 'checks ref type'}, {'node_id_from': 'generatePropTypeDescription', 'node_id_to': 'isIntegerType', 'description': 'checks integer type'}, {'node_id_from': 'generatePropTypeDescription', 'node_id_to': 'joinUnionTypes', 'description': 'formats union types'}, {'node_id_from': 'generatePropTypeDescription', 'node_id_to': 'escapeCell', 'description': 'escapes cell content'}, {'node_id_from': 'generatePropTypeDescription', 'node_id_to': 'escapeEntities', 'description': 'escapes HTML entities'}], 'packages': [{'package_id': 'propTypeHandling', 'children': ['generatePropTypeDescription', 'getDeprecatedInfo', 'getChained'], 'description': 'Core prop type processing functionality'}, {'package_id': 'typeChecks', 'children': ['isElementTypeAcceptingRefProp', 'isElementAcceptingRefProp', 'isRefType', 'isIntegerType'], 'description': 'Type validation functions'}, {'package_id': 'formatting', 'children': ['joinUnionTypes', 'escapeCell', 'escapeEntities'], 'description': 'String formatting utilities'}]}",
    "version": "full",
    "text_answer": "The generatePropTypeDescription function serves as the main entry point, processing various prop types by delegating to specialized helper functions. It handles deprecated props through getDeprecatedInfo, chained props via getChained, and uses multiple type-checking functions to determine specific prop types. The function also formats the output using utility functions for unions and escaping.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Python",
    "code": "\nimport warnings\n\nfrom langchain_core.globals import get_debug as core_get_debug\nfrom langchain_core.globals import get_verbose as core_get_verbose\nfrom langchain_core.globals import set_debug as core_set_debug\nfrom langchain_core.globals import set_verbose as core_set_verbose\n\nfrom langchain.globals import get_debug, get_verbose, set_debug, set_verbose\n\n\ndef test_no_warning() -> None:\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"error\")\n\n        get_debug()\n        set_debug(False)\n        get_verbose()\n        set_verbose(False)\n        core_get_debug()\n        core_set_debug(False)\n        core_get_verbose()\n        core_set_verbose(False)\n\n\ndef test_debug_is_settable_directly() -> None:\n    from langchain_core.callbacks.manager import _get_debug\n\n    import langchain\n\n    previous_value = langchain.debug\n    previous_fn_reading = _get_debug()\n    assert previous_value == previous_fn_reading\n\n    # Flip the value of the flag.\n    langchain.debug = not previous_value\n\n    new_value = langchain.debug\n    new_fn_reading = _get_debug()\n\n    try:\n        # We successfully changed the value of `debug`.\n        assert new_value != previous_value\n\n        # If we access `debug` via a function used elsewhere in langchain,\n        # it also sees the same new value.\n        assert new_value == new_fn_reading\n\n        # If we access `debug` via `get_debug()` we also get the same value.\n        assert new_value == get_debug()\n    finally:\n        # Make sure we don't alter global state, even if the test fails.\n        # Always reset `debug` to the value it had before.\n        set_debug(previous_value)\n\n\ndef test_debug_is_settable_via_setter() -> None:\n    from langchain_core.callbacks.manager import _get_debug\n\n    from langchain import globals\n\n    previous_value = globals._debug\n    previous_fn_reading = _get_debug()\n    assert previous_value == previous_fn_reading\n\n    # Flip the value of the flag.\n    set_debug(not previous_value)\n\n    new_value = globals._debug\n    new_fn_reading = _get_debug()\n\n    try:\n        # We successfully changed the value of `debug`.\n        assert new_value != previous_value\n\n        # If we access `debug` via a function used elsewhere in langchain,\n        # it also sees the same new value.\n        assert new_value == new_fn_reading\n\n        # If we access `debug` via `get_debug()` we also get the same value.\n        assert new_value == get_debug()\n    finally:\n        # Make sure we don't alter global state, even if the test fails.\n        # Always reset `debug` to the value it had before.\n        set_debug(previous_value)\n\n\ndef test_verbose_is_settable_directly() -> None:\n    import langchain\n    from langchain.chains.base import _get_verbosity\n\n    previous_value = langchain.verbose\n    previous_fn_reading = _get_verbosity()\n    assert previous_value == previous_fn_reading\n\n    # Flip the value of the flag.\n    langchain.verbose = not previous_value\n\n    new_value = langchain.verbose\n    new_fn_reading = _get_verbosity()\n\n    try:\n        # We successfully changed the value of `verbose`.\n        assert new_value != previous_value\n\n        # If we access `verbose` via a function used elsewhere in langchain,\n        # it also sees the same new value.\n        assert new_value == new_fn_reading\n\n        # If we access `verbose` via `get_verbose()` we also get the same value.\n        assert new_value == get_verbose()\n    finally:\n        # Make sure we don't alter global state, even if the test fails.\n        # Always reset `verbose` to the value it had before.\n        set_verbose(previous_value)\n\n\ndef test_verbose_is_settable_via_setter() -> None:\n    from langchain import globals\n    from langchain.chains.base import _get_verbosity\n\n    previous_value = globals._verbose\n    previous_fn_reading = _get_verbosity()\n    assert previous_value == previous_fn_reading\n\n    # Flip the value of the flag.\n    set_verbose(not previous_value)\n\n    new_value = globals._verbose\n    new_fn_reading = _get_verbosity()\n\n    try:\n        # We successfully changed the value of `verbose`.\n        assert new_value != previous_value\n\n        # If we access `verbose` via a function used elsewhere in langchain,\n        # it also sees the same new value.\n        assert new_value == new_fn_reading\n\n        # If we access `verbose` via `get_verbose()` we also get the same value.\n        assert new_value == get_verbose()\n    finally:\n        # Make sure we don't alter global state, even if the test fails.\n        # Always reset `verbose` to the value it had before.\n        set_verbose(previous_value)",
    "repo": "langchain-ai/langchain",
    "path": "./datasets/diagrams-repos/langchain-ai/langchain/libs/langchain/tests/unit_tests/test_globals.py",
    "query": "How do the test functions interact with the global settings?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'test_no_warning', 'node_id': 'test_no_warning', 'description': 'Tests basic get/set operations for debug and verbose flags without warnings', 'visibility': 'public', 'return_type': 'None', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': '_debug', 'node_id': '_debug', 'description': 'Global debug flag', 'visibility': 'public', 'return_type': 'bool', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': '_verbose', 'node_id': '_verbose', 'description': 'Global verbose flag', 'visibility': 'public', 'return_type': 'bool', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'test_no_warning', 'node_id_to': '_debug', 'description': 'gets/sets debug flag'}, {'node_id_from': 'test_no_warning', 'node_id_to': '_verbose', 'description': 'gets/sets verbose flag'}], 'packages': [{'package_id': 'globalSettings', 'children': ['_debug', '_verbose'], 'description': 'Global configuration flags'}]}",
    "version": "minimal",
    "text_answer": "The test functions verify global settings (debug and verbose) can be modified both directly and through setter functions, ensuring consistency across different access methods and proper state restoration after tests.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Python",
    "code": "\nimport warnings\n\nfrom langchain_core.globals import get_debug as core_get_debug\nfrom langchain_core.globals import get_verbose as core_get_verbose\nfrom langchain_core.globals import set_debug as core_set_debug\nfrom langchain_core.globals import set_verbose as core_set_verbose\n\nfrom langchain.globals import get_debug, get_verbose, set_debug, set_verbose\n\n\ndef test_no_warning() -> None:\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"error\")\n\n        get_debug()\n        set_debug(False)\n        get_verbose()\n        set_verbose(False)\n        core_get_debug()\n        core_set_debug(False)\n        core_get_verbose()\n        core_set_verbose(False)\n\n\ndef test_debug_is_settable_directly() -> None:\n    from langchain_core.callbacks.manager import _get_debug\n\n    import langchain\n\n    previous_value = langchain.debug\n    previous_fn_reading = _get_debug()\n    assert previous_value == previous_fn_reading\n\n    # Flip the value of the flag.\n    langchain.debug = not previous_value\n\n    new_value = langchain.debug\n    new_fn_reading = _get_debug()\n\n    try:\n        # We successfully changed the value of `debug`.\n        assert new_value != previous_value\n\n        # If we access `debug` via a function used elsewhere in langchain,\n        # it also sees the same new value.\n        assert new_value == new_fn_reading\n\n        # If we access `debug` via `get_debug()` we also get the same value.\n        assert new_value == get_debug()\n    finally:\n        # Make sure we don't alter global state, even if the test fails.\n        # Always reset `debug` to the value it had before.\n        set_debug(previous_value)\n\n\ndef test_debug_is_settable_via_setter() -> None:\n    from langchain_core.callbacks.manager import _get_debug\n\n    from langchain import globals\n\n    previous_value = globals._debug\n    previous_fn_reading = _get_debug()\n    assert previous_value == previous_fn_reading\n\n    # Flip the value of the flag.\n    set_debug(not previous_value)\n\n    new_value = globals._debug\n    new_fn_reading = _get_debug()\n\n    try:\n        # We successfully changed the value of `debug`.\n        assert new_value != previous_value\n\n        # If we access `debug` via a function used elsewhere in langchain,\n        # it also sees the same new value.\n        assert new_value == new_fn_reading\n\n        # If we access `debug` via `get_debug()` we also get the same value.\n        assert new_value == get_debug()\n    finally:\n        # Make sure we don't alter global state, even if the test fails.\n        # Always reset `debug` to the value it had before.\n        set_debug(previous_value)\n\n\ndef test_verbose_is_settable_directly() -> None:\n    import langchain\n    from langchain.chains.base import _get_verbosity\n\n    previous_value = langchain.verbose\n    previous_fn_reading = _get_verbosity()\n    assert previous_value == previous_fn_reading\n\n    # Flip the value of the flag.\n    langchain.verbose = not previous_value\n\n    new_value = langchain.verbose\n    new_fn_reading = _get_verbosity()\n\n    try:\n        # We successfully changed the value of `verbose`.\n        assert new_value != previous_value\n\n        # If we access `verbose` via a function used elsewhere in langchain,\n        # it also sees the same new value.\n        assert new_value == new_fn_reading\n\n        # If we access `verbose` via `get_verbose()` we also get the same value.\n        assert new_value == get_verbose()\n    finally:\n        # Make sure we don't alter global state, even if the test fails.\n        # Always reset `verbose` to the value it had before.\n        set_verbose(previous_value)\n\n\ndef test_verbose_is_settable_via_setter() -> None:\n    from langchain import globals\n    from langchain.chains.base import _get_verbosity\n\n    previous_value = globals._verbose\n    previous_fn_reading = _get_verbosity()\n    assert previous_value == previous_fn_reading\n\n    # Flip the value of the flag.\n    set_verbose(not previous_value)\n\n    new_value = globals._verbose\n    new_fn_reading = _get_verbosity()\n\n    try:\n        # We successfully changed the value of `verbose`.\n        assert new_value != previous_value\n\n        # If we access `verbose` via a function used elsewhere in langchain,\n        # it also sees the same new value.\n        assert new_value == new_fn_reading\n\n        # If we access `verbose` via `get_verbose()` we also get the same value.\n        assert new_value == get_verbose()\n    finally:\n        # Make sure we don't alter global state, even if the test fails.\n        # Always reset `verbose` to the value it had before.\n        set_verbose(previous_value)",
    "repo": "langchain-ai/langchain",
    "path": "./datasets/diagrams-repos/langchain-ai/langchain/libs/langchain/tests/unit_tests/test_globals.py",
    "query": "How do the test functions interact with the global settings?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'test_no_warning', 'node_id': 'test_no_warning', 'description': 'Tests basic get/set operations for debug and verbose flags without warnings', 'visibility': 'public', 'return_type': 'None', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'test_debug_is_settable_directly', 'node_id': 'test_debug_is_settable_directly', 'description': 'Tests direct modification of debug flag', 'visibility': 'public', 'return_type': 'None', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'test_verbose_is_settable_directly', 'node_id': 'test_verbose_is_settable_directly', 'description': 'Tests direct modification of verbose flag', 'visibility': 'public', 'return_type': 'None', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': '_debug', 'node_id': '_debug', 'description': 'Global debug flag', 'visibility': 'public', 'return_type': 'bool', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': '_verbose', 'node_id': '_verbose', 'description': 'Global verbose flag', 'visibility': 'public', 'return_type': 'bool', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': '_get_debug', 'node_id': '_get_debug', 'description': 'Internal function to get debug state', 'visibility': 'private', 'return_type': 'bool', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': '_get_verbosity', 'node_id': '_get_verbosity', 'description': 'Internal function to get verbose state', 'visibility': 'private', 'return_type': 'bool', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'test_no_warning', 'node_id_to': '_debug', 'description': 'gets/sets debug flag'}, {'node_id_from': 'test_no_warning', 'node_id_to': '_verbose', 'description': 'gets/sets verbose flag'}, {'node_id_from': 'test_debug_is_settable_directly', 'node_id_to': '_debug', 'description': 'modifies directly'}, {'node_id_from': 'test_verbose_is_settable_directly', 'node_id_to': '_verbose', 'description': 'modifies directly'}, {'node_id_from': 'test_debug_is_settable_directly', 'node_id_to': '_get_debug', 'description': 'verifies state'}, {'node_id_from': 'test_verbose_is_settable_directly', 'node_id_to': '_get_verbosity', 'description': 'verifies state'}], 'packages': [{'package_id': 'globalSettings', 'children': ['_debug', '_verbose'], 'description': 'Global configuration flags'}, {'package_id': 'testFunctions', 'children': ['test_no_warning', 'test_debug_is_settable_directly', 'test_verbose_is_settable_directly'], 'description': 'Test functions for global settings'}]}",
    "version": "medium",
    "text_answer": "The test functions verify global settings (debug and verbose) can be modified both directly and through setter functions, ensuring consistency across different access methods and proper state restoration after tests.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Python",
    "code": "\nimport warnings\n\nfrom langchain_core.globals import get_debug as core_get_debug\nfrom langchain_core.globals import get_verbose as core_get_verbose\nfrom langchain_core.globals import set_debug as core_set_debug\nfrom langchain_core.globals import set_verbose as core_set_verbose\n\nfrom langchain.globals import get_debug, get_verbose, set_debug, set_verbose\n\n\ndef test_no_warning() -> None:\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"error\")\n\n        get_debug()\n        set_debug(False)\n        get_verbose()\n        set_verbose(False)\n        core_get_debug()\n        core_set_debug(False)\n        core_get_verbose()\n        core_set_verbose(False)\n\n\ndef test_debug_is_settable_directly() -> None:\n    from langchain_core.callbacks.manager import _get_debug\n\n    import langchain\n\n    previous_value = langchain.debug\n    previous_fn_reading = _get_debug()\n    assert previous_value == previous_fn_reading\n\n    # Flip the value of the flag.\n    langchain.debug = not previous_value\n\n    new_value = langchain.debug\n    new_fn_reading = _get_debug()\n\n    try:\n        # We successfully changed the value of `debug`.\n        assert new_value != previous_value\n\n        # If we access `debug` via a function used elsewhere in langchain,\n        # it also sees the same new value.\n        assert new_value == new_fn_reading\n\n        # If we access `debug` via `get_debug()` we also get the same value.\n        assert new_value == get_debug()\n    finally:\n        # Make sure we don't alter global state, even if the test fails.\n        # Always reset `debug` to the value it had before.\n        set_debug(previous_value)\n\n\ndef test_debug_is_settable_via_setter() -> None:\n    from langchain_core.callbacks.manager import _get_debug\n\n    from langchain import globals\n\n    previous_value = globals._debug\n    previous_fn_reading = _get_debug()\n    assert previous_value == previous_fn_reading\n\n    # Flip the value of the flag.\n    set_debug(not previous_value)\n\n    new_value = globals._debug\n    new_fn_reading = _get_debug()\n\n    try:\n        # We successfully changed the value of `debug`.\n        assert new_value != previous_value\n\n        # If we access `debug` via a function used elsewhere in langchain,\n        # it also sees the same new value.\n        assert new_value == new_fn_reading\n\n        # If we access `debug` via `get_debug()` we also get the same value.\n        assert new_value == get_debug()\n    finally:\n        # Make sure we don't alter global state, even if the test fails.\n        # Always reset `debug` to the value it had before.\n        set_debug(previous_value)\n\n\ndef test_verbose_is_settable_directly() -> None:\n    import langchain\n    from langchain.chains.base import _get_verbosity\n\n    previous_value = langchain.verbose\n    previous_fn_reading = _get_verbosity()\n    assert previous_value == previous_fn_reading\n\n    # Flip the value of the flag.\n    langchain.verbose = not previous_value\n\n    new_value = langchain.verbose\n    new_fn_reading = _get_verbosity()\n\n    try:\n        # We successfully changed the value of `verbose`.\n        assert new_value != previous_value\n\n        # If we access `verbose` via a function used elsewhere in langchain,\n        # it also sees the same new value.\n        assert new_value == new_fn_reading\n\n        # If we access `verbose` via `get_verbose()` we also get the same value.\n        assert new_value == get_verbose()\n    finally:\n        # Make sure we don't alter global state, even if the test fails.\n        # Always reset `verbose` to the value it had before.\n        set_verbose(previous_value)\n\n\ndef test_verbose_is_settable_via_setter() -> None:\n    from langchain import globals\n    from langchain.chains.base import _get_verbosity\n\n    previous_value = globals._verbose\n    previous_fn_reading = _get_verbosity()\n    assert previous_value == previous_fn_reading\n\n    # Flip the value of the flag.\n    set_verbose(not previous_value)\n\n    new_value = globals._verbose\n    new_fn_reading = _get_verbosity()\n\n    try:\n        # We successfully changed the value of `verbose`.\n        assert new_value != previous_value\n\n        # If we access `verbose` via a function used elsewhere in langchain,\n        # it also sees the same new value.\n        assert new_value == new_fn_reading\n\n        # If we access `verbose` via `get_verbose()` we also get the same value.\n        assert new_value == get_verbose()\n    finally:\n        # Make sure we don't alter global state, even if the test fails.\n        # Always reset `verbose` to the value it had before.\n        set_verbose(previous_value)",
    "repo": "langchain-ai/langchain",
    "path": "./datasets/diagrams-repos/langchain-ai/langchain/libs/langchain/tests/unit_tests/test_globals.py",
    "query": "How do the test functions interact with the global settings?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'test_no_warning', 'node_id': 'test_no_warning', 'description': 'Tests basic get/set operations for debug and verbose flags without warnings', 'visibility': 'public', 'return_type': 'None', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'test_debug_is_settable_directly', 'node_id': 'test_debug_is_settable_directly', 'description': 'Tests direct modification of debug flag', 'visibility': 'public', 'return_type': 'None', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'test_debug_is_settable_via_setter', 'node_id': 'test_debug_is_settable_via_setter', 'description': 'Tests modification of debug flag via setter function', 'visibility': 'public', 'return_type': 'None', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'test_verbose_is_settable_directly', 'node_id': 'test_verbose_is_settable_directly', 'description': 'Tests direct modification of verbose flag', 'visibility': 'public', 'return_type': 'None', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'test_verbose_is_settable_via_setter', 'node_id': 'test_verbose_is_settable_via_setter', 'description': 'Tests modification of verbose flag via setter function', 'visibility': 'public', 'return_type': 'None', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': '_debug', 'node_id': '_debug', 'description': 'Global debug flag', 'visibility': 'public', 'return_type': 'bool', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': '_verbose', 'node_id': '_verbose', 'description': 'Global verbose flag', 'visibility': 'public', 'return_type': 'bool', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': '_get_debug', 'node_id': '_get_debug', 'description': 'Internal function to get debug state', 'visibility': 'private', 'return_type': 'bool', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': '_get_verbosity', 'node_id': '_get_verbosity', 'description': 'Internal function to get verbose state', 'visibility': 'private', 'return_type': 'bool', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'get_debug', 'node_id': 'get_debug', 'description': 'Public function to get debug state', 'visibility': 'public', 'return_type': 'bool', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'set_debug', 'node_id': 'set_debug', 'description': 'Public function to set debug state', 'visibility': 'public', 'return_type': 'None', 'params': 'value: bool', 'source_class_id': None}, {'type': 'function', 'name': 'get_verbose', 'node_id': 'get_verbose', 'description': 'Public function to get verbose state', 'visibility': 'public', 'return_type': 'bool', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'set_verbose', 'node_id': 'set_verbose', 'description': 'Public function to set verbose state', 'visibility': 'public', 'return_type': 'None', 'params': 'value: bool', 'source_class_id': None}], 'edges': [{'node_id_from': 'test_no_warning', 'node_id_to': 'get_debug', 'description': 'calls'}, {'node_id_from': 'test_no_warning', 'node_id_to': 'set_debug', 'description': 'calls'}, {'node_id_from': 'test_no_warning', 'node_id_to': 'get_verbose', 'description': 'calls'}, {'node_id_from': 'test_no_warning', 'node_id_to': 'set_verbose', 'description': 'calls'}, {'node_id_from': 'test_debug_is_settable_directly', 'node_id_to': '_debug', 'description': 'modifies directly'}, {'node_id_from': 'test_debug_is_settable_directly', 'node_id_to': '_get_debug', 'description': 'verifies state'}, {'node_id_from': 'test_debug_is_settable_via_setter', 'node_id_to': 'set_debug', 'description': 'calls'}, {'node_id_from': 'test_debug_is_settable_via_setter', 'node_id_to': '_get_debug', 'description': 'verifies state'}, {'node_id_from': 'test_verbose_is_settable_directly', 'node_id_to': '_verbose', 'description': 'modifies directly'}, {'node_id_from': 'test_verbose_is_settable_directly', 'node_id_to': '_get_verbosity', 'description': 'verifies state'}, {'node_id_from': 'test_verbose_is_settable_via_setter', 'node_id_to': 'set_verbose', 'description': 'calls'}, {'node_id_from': 'test_verbose_is_settable_via_setter', 'node_id_to': '_get_verbosity', 'description': 'verifies state'}, {'node_id_from': 'get_debug', 'node_id_to': '_debug', 'description': 'reads'}, {'node_id_from': 'set_debug', 'node_id_to': '_debug', 'description': 'modifies'}, {'node_id_from': 'get_verbose', 'node_id_to': '_verbose', 'description': 'reads'}, {'node_id_from': 'set_verbose', 'node_id_to': '_verbose', 'description': 'modifies'}], 'packages': [{'package_id': 'globalSettings', 'children': ['_debug', '_verbose', 'get_debug', 'set_debug', 'get_verbose', 'set_verbose'], 'description': 'Global configuration flags and their accessors'}, {'package_id': 'testFunctions', 'children': ['test_no_warning', 'test_debug_is_settable_directly', 'test_debug_is_settable_via_setter', 'test_verbose_is_settable_directly', 'test_verbose_is_settable_via_setter'], 'description': 'Test functions for global settings'}, {'package_id': 'internalFunctions', 'children': ['_get_debug', '_get_verbosity'], 'description': 'Internal helper functions'}]}",
    "version": "full",
    "text_answer": "The test functions verify global settings (debug and verbose) can be modified both directly and through setter functions, ensuring consistency across different access methods and proper state restoration after tests.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nimport BasicObject from \"trix/core/basic_object\"\n\nimport { nodeIsAttachmentElement, removeNode, tagName, walkTree } from \"trix/core/helpers\"\nimport DOMPurify from \"dompurify\"\nimport * as config from \"trix/config\"\n\nDOMPurify.addHook(\"uponSanitizeAttribute\", function (node, data) {\n  const allowedAttributePattern = /^data-trix-/\n  if (allowedAttributePattern.test(data.attrName)) {\n    data.forceKeepAttr = true\n  }\n})\n\nconst DEFAULT_ALLOWED_ATTRIBUTES = \"style href src width height language class\".split(\" \")\nconst DEFAULT_FORBIDDEN_PROTOCOLS = \"javascript:\".split(\" \")\nconst DEFAULT_FORBIDDEN_ELEMENTS = \"script iframe form noscript\".split(\" \")\n\nexport default class HTMLSanitizer extends BasicObject {\n  static setHTML(element, html) {\n    const sanitizedElement = new this(html).sanitize()\n    const sanitizedHtml = sanitizedElement.getHTML ? sanitizedElement.getHTML() : sanitizedElement.outerHTML\n    element.innerHTML = sanitizedHtml\n  }\n\n  static sanitize(html, options) {\n    const sanitizer = new this(html, options)\n    sanitizer.sanitize()\n    return sanitizer\n  }\n\n  constructor(html, { allowedAttributes, forbiddenProtocols, forbiddenElements } = {}) {\n    super(...arguments)\n    this.allowedAttributes = allowedAttributes || DEFAULT_ALLOWED_ATTRIBUTES\n    this.forbiddenProtocols = forbiddenProtocols || DEFAULT_FORBIDDEN_PROTOCOLS\n    this.forbiddenElements = forbiddenElements || DEFAULT_FORBIDDEN_ELEMENTS\n    this.body = createBodyElementForHTML(html)\n  }\n\n  sanitize() {\n    this.sanitizeElements()\n    this.normalizeListElementNesting()\n    DOMPurify.setConfig(config.dompurify)\n    this.body = DOMPurify.sanitize(this.body)\n\n    return this.body\n  }\n\n  getHTML() {\n    return this.body.innerHTML\n  }\n\n  getBody() {\n    return this.body\n  }\n\n  // Private\n\n  sanitizeElements() {\n    const walker = walkTree(this.body)\n    const nodesToRemove = []\n\n    while (walker.nextNode()) {\n      const node = walker.currentNode\n      switch (node.nodeType) {\n        case Node.ELEMENT_NODE:\n          if (this.elementIsRemovable(node)) {\n            nodesToRemove.push(node)\n          } else {\n            this.sanitizeElement(node)\n          }\n          break\n        case Node.COMMENT_NODE:\n          nodesToRemove.push(node)\n          break\n      }\n    }\n\n    nodesToRemove.forEach((node) => removeNode(node))\n\n    return this.body\n  }\n\n  sanitizeElement(element) {\n    if (element.hasAttribute(\"href\")) {\n      if (this.forbiddenProtocols.includes(element.protocol)) {\n        element.removeAttribute(\"href\")\n      }\n    }\n\n    Array.from(element.attributes).forEach(({ name }) => {\n      if (!this.allowedAttributes.includes(name) && name.indexOf(\"data-trix\") !== 0) {\n        element.removeAttribute(name)\n      }\n    })\n\n    return element\n  }\n\n  normalizeListElementNesting() {\n    Array.from(this.body.querySelectorAll(\"ul,ol\")).forEach((listElement) => {\n      const previousElement = listElement.previousElementSibling\n      if (previousElement) {\n        if (tagName(previousElement) === \"li\") {\n          previousElement.appendChild(listElement)\n        }\n      }\n    })\n\n    return this.body\n  }\n\n  elementIsRemovable(element) {\n    if (element?.nodeType !== Node.ELEMENT_NODE) return\n    return this.elementIsForbidden(element) || this.elementIsntSerializable(element)\n  }\n\n  elementIsForbidden(element) {\n    return this.forbiddenElements.includes(tagName(element))\n  }\n\n  elementIsntSerializable(element) {\n    return element.getAttribute(\"data-trix-serialize\") === \"false\" && !nodeIsAttachmentElement(element)\n  }\n}\n\nconst createBodyElementForHTML = function(html = \"\") {\n  // Remove everything after </html>\n  html = html.replace(/<\\/html[^>]*>[^]*$/i, \"</html>\")\n  const doc = document.implementation.createHTMLDocument(\"\")\n  doc.documentElement.innerHTML = html\n\n  Array.from(doc.head.querySelectorAll(\"style\")).forEach((element) => {\n    doc.body.appendChild(element)\n  })\n\n  return doc.body\n}",
    "repo": "basecamp/trix",
    "path": "./datasets/diagrams-repos/basecamp/trix/src/trix/models/html_sanitizer.js",
    "query": "What is the structure of the HTMLSanitizer class?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'BasicObject', 'node_id': 'BasicObject', 'description': 'Base class for inheritance', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'HTMLSanitizer', 'node_id': 'HTMLSanitizer', 'description': 'Class for sanitizing HTML content', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'sanitize', 'node_id': 'sanitize', 'description': 'Main method to sanitize HTML content', 'visibility': 'public', 'return_type': 'HTMLElement', 'params': '()', 'source_class_id': 'HTMLSanitizer'}], 'edges': [{'node_id_from': 'HTMLSanitizer', 'node_id_to': 'BasicObject', 'description': 'extends'}, {'node_id_from': 'HTMLSanitizer', 'node_id_to': 'sanitize', 'description': ''}], 'packages': [{'package_id': 'core', 'children': ['BasicObject', 'HTMLSanitizer', 'sanitize'], 'description': 'Core functionality'}]}",
    "version": "minimal",
    "text_answer": "HTMLSanitizer extends BasicObject and provides HTML content sanitization functionality. It includes public methods for HTML manipulation (setHTML, sanitize, getHTML, getBody) and private methods for element processing and validation. The class uses DOMPurify for secure HTML sanitization and implements custom rules for allowed attributes and forbidden elements.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nimport BasicObject from \"trix/core/basic_object\"\n\nimport { nodeIsAttachmentElement, removeNode, tagName, walkTree } from \"trix/core/helpers\"\nimport DOMPurify from \"dompurify\"\nimport * as config from \"trix/config\"\n\nDOMPurify.addHook(\"uponSanitizeAttribute\", function (node, data) {\n  const allowedAttributePattern = /^data-trix-/\n  if (allowedAttributePattern.test(data.attrName)) {\n    data.forceKeepAttr = true\n  }\n})\n\nconst DEFAULT_ALLOWED_ATTRIBUTES = \"style href src width height language class\".split(\" \")\nconst DEFAULT_FORBIDDEN_PROTOCOLS = \"javascript:\".split(\" \")\nconst DEFAULT_FORBIDDEN_ELEMENTS = \"script iframe form noscript\".split(\" \")\n\nexport default class HTMLSanitizer extends BasicObject {\n  static setHTML(element, html) {\n    const sanitizedElement = new this(html).sanitize()\n    const sanitizedHtml = sanitizedElement.getHTML ? sanitizedElement.getHTML() : sanitizedElement.outerHTML\n    element.innerHTML = sanitizedHtml\n  }\n\n  static sanitize(html, options) {\n    const sanitizer = new this(html, options)\n    sanitizer.sanitize()\n    return sanitizer\n  }\n\n  constructor(html, { allowedAttributes, forbiddenProtocols, forbiddenElements } = {}) {\n    super(...arguments)\n    this.allowedAttributes = allowedAttributes || DEFAULT_ALLOWED_ATTRIBUTES\n    this.forbiddenProtocols = forbiddenProtocols || DEFAULT_FORBIDDEN_PROTOCOLS\n    this.forbiddenElements = forbiddenElements || DEFAULT_FORBIDDEN_ELEMENTS\n    this.body = createBodyElementForHTML(html)\n  }\n\n  sanitize() {\n    this.sanitizeElements()\n    this.normalizeListElementNesting()\n    DOMPurify.setConfig(config.dompurify)\n    this.body = DOMPurify.sanitize(this.body)\n\n    return this.body\n  }\n\n  getHTML() {\n    return this.body.innerHTML\n  }\n\n  getBody() {\n    return this.body\n  }\n\n  // Private\n\n  sanitizeElements() {\n    const walker = walkTree(this.body)\n    const nodesToRemove = []\n\n    while (walker.nextNode()) {\n      const node = walker.currentNode\n      switch (node.nodeType) {\n        case Node.ELEMENT_NODE:\n          if (this.elementIsRemovable(node)) {\n            nodesToRemove.push(node)\n          } else {\n            this.sanitizeElement(node)\n          }\n          break\n        case Node.COMMENT_NODE:\n          nodesToRemove.push(node)\n          break\n      }\n    }\n\n    nodesToRemove.forEach((node) => removeNode(node))\n\n    return this.body\n  }\n\n  sanitizeElement(element) {\n    if (element.hasAttribute(\"href\")) {\n      if (this.forbiddenProtocols.includes(element.protocol)) {\n        element.removeAttribute(\"href\")\n      }\n    }\n\n    Array.from(element.attributes).forEach(({ name }) => {\n      if (!this.allowedAttributes.includes(name) && name.indexOf(\"data-trix\") !== 0) {\n        element.removeAttribute(name)\n      }\n    })\n\n    return element\n  }\n\n  normalizeListElementNesting() {\n    Array.from(this.body.querySelectorAll(\"ul,ol\")).forEach((listElement) => {\n      const previousElement = listElement.previousElementSibling\n      if (previousElement) {\n        if (tagName(previousElement) === \"li\") {\n          previousElement.appendChild(listElement)\n        }\n      }\n    })\n\n    return this.body\n  }\n\n  elementIsRemovable(element) {\n    if (element?.nodeType !== Node.ELEMENT_NODE) return\n    return this.elementIsForbidden(element) || this.elementIsntSerializable(element)\n  }\n\n  elementIsForbidden(element) {\n    return this.forbiddenElements.includes(tagName(element))\n  }\n\n  elementIsntSerializable(element) {\n    return element.getAttribute(\"data-trix-serialize\") === \"false\" && !nodeIsAttachmentElement(element)\n  }\n}\n\nconst createBodyElementForHTML = function(html = \"\") {\n  // Remove everything after </html>\n  html = html.replace(/<\\/html[^>]*>[^]*$/i, \"</html>\")\n  const doc = document.implementation.createHTMLDocument(\"\")\n  doc.documentElement.innerHTML = html\n\n  Array.from(doc.head.querySelectorAll(\"style\")).forEach((element) => {\n    doc.body.appendChild(element)\n  })\n\n  return doc.body\n}",
    "repo": "basecamp/trix",
    "path": "./datasets/diagrams-repos/basecamp/trix/src/trix/models/html_sanitizer.js",
    "query": "What is the structure of the HTMLSanitizer class?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'BasicObject', 'node_id': 'BasicObject', 'description': 'Base class for inheritance', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'HTMLSanitizer', 'node_id': 'HTMLSanitizer', 'description': 'Class for sanitizing HTML content', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'setHTML', 'node_id': 'setHTML', 'description': 'Static method to set sanitized HTML', 'visibility': 'public', 'return_type': 'void', 'params': '(element, html)', 'source_class_id': 'HTMLSanitizer'}, {'type': 'method', 'name': 'sanitize', 'node_id': 'sanitize', 'description': 'Main method to sanitize HTML content', 'visibility': 'public', 'return_type': 'HTMLElement', 'params': '()', 'source_class_id': 'HTMLSanitizer'}, {'type': 'method', 'name': 'getHTML', 'node_id': 'getHTML', 'description': 'Get sanitized HTML content', 'visibility': 'public', 'return_type': 'string', 'params': '()', 'source_class_id': 'HTMLSanitizer'}, {'type': 'method', 'name': 'getBody', 'node_id': 'getBody', 'description': 'Get sanitized body element', 'visibility': 'public', 'return_type': 'HTMLElement', 'params': '()', 'source_class_id': 'HTMLSanitizer'}], 'edges': [{'node_id_from': 'HTMLSanitizer', 'node_id_to': 'BasicObject', 'description': 'extends'}, {'node_id_from': 'HTMLSanitizer', 'node_id_to': 'sanitize', 'description': ''}, {'node_id_from': 'HTMLSanitizer', 'node_id_to': 'setHTML', 'description': ''}, {'node_id_from': 'HTMLSanitizer', 'node_id_to': 'getHTML', 'description': ''}, {'node_id_from': 'HTMLSanitizer', 'node_id_to': 'getBody', 'description': ''}], 'packages': [{'package_id': 'core', 'children': ['BasicObject', 'HTMLSanitizer', 'setHTML', 'sanitize', 'getHTML', 'getBody'], 'description': 'Core functionality'}]}",
    "version": "medium",
    "text_answer": "HTMLSanitizer extends BasicObject and provides HTML content sanitization functionality. It includes public methods for HTML manipulation (setHTML, sanitize, getHTML, getBody) and private methods for element processing and validation. The class uses DOMPurify for secure HTML sanitization and implements custom rules for allowed attributes and forbidden elements.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nimport BasicObject from \"trix/core/basic_object\"\n\nimport { nodeIsAttachmentElement, removeNode, tagName, walkTree } from \"trix/core/helpers\"\nimport DOMPurify from \"dompurify\"\nimport * as config from \"trix/config\"\n\nDOMPurify.addHook(\"uponSanitizeAttribute\", function (node, data) {\n  const allowedAttributePattern = /^data-trix-/\n  if (allowedAttributePattern.test(data.attrName)) {\n    data.forceKeepAttr = true\n  }\n})\n\nconst DEFAULT_ALLOWED_ATTRIBUTES = \"style href src width height language class\".split(\" \")\nconst DEFAULT_FORBIDDEN_PROTOCOLS = \"javascript:\".split(\" \")\nconst DEFAULT_FORBIDDEN_ELEMENTS = \"script iframe form noscript\".split(\" \")\n\nexport default class HTMLSanitizer extends BasicObject {\n  static setHTML(element, html) {\n    const sanitizedElement = new this(html).sanitize()\n    const sanitizedHtml = sanitizedElement.getHTML ? sanitizedElement.getHTML() : sanitizedElement.outerHTML\n    element.innerHTML = sanitizedHtml\n  }\n\n  static sanitize(html, options) {\n    const sanitizer = new this(html, options)\n    sanitizer.sanitize()\n    return sanitizer\n  }\n\n  constructor(html, { allowedAttributes, forbiddenProtocols, forbiddenElements } = {}) {\n    super(...arguments)\n    this.allowedAttributes = allowedAttributes || DEFAULT_ALLOWED_ATTRIBUTES\n    this.forbiddenProtocols = forbiddenProtocols || DEFAULT_FORBIDDEN_PROTOCOLS\n    this.forbiddenElements = forbiddenElements || DEFAULT_FORBIDDEN_ELEMENTS\n    this.body = createBodyElementForHTML(html)\n  }\n\n  sanitize() {\n    this.sanitizeElements()\n    this.normalizeListElementNesting()\n    DOMPurify.setConfig(config.dompurify)\n    this.body = DOMPurify.sanitize(this.body)\n\n    return this.body\n  }\n\n  getHTML() {\n    return this.body.innerHTML\n  }\n\n  getBody() {\n    return this.body\n  }\n\n  // Private\n\n  sanitizeElements() {\n    const walker = walkTree(this.body)\n    const nodesToRemove = []\n\n    while (walker.nextNode()) {\n      const node = walker.currentNode\n      switch (node.nodeType) {\n        case Node.ELEMENT_NODE:\n          if (this.elementIsRemovable(node)) {\n            nodesToRemove.push(node)\n          } else {\n            this.sanitizeElement(node)\n          }\n          break\n        case Node.COMMENT_NODE:\n          nodesToRemove.push(node)\n          break\n      }\n    }\n\n    nodesToRemove.forEach((node) => removeNode(node))\n\n    return this.body\n  }\n\n  sanitizeElement(element) {\n    if (element.hasAttribute(\"href\")) {\n      if (this.forbiddenProtocols.includes(element.protocol)) {\n        element.removeAttribute(\"href\")\n      }\n    }\n\n    Array.from(element.attributes).forEach(({ name }) => {\n      if (!this.allowedAttributes.includes(name) && name.indexOf(\"data-trix\") !== 0) {\n        element.removeAttribute(name)\n      }\n    })\n\n    return element\n  }\n\n  normalizeListElementNesting() {\n    Array.from(this.body.querySelectorAll(\"ul,ol\")).forEach((listElement) => {\n      const previousElement = listElement.previousElementSibling\n      if (previousElement) {\n        if (tagName(previousElement) === \"li\") {\n          previousElement.appendChild(listElement)\n        }\n      }\n    })\n\n    return this.body\n  }\n\n  elementIsRemovable(element) {\n    if (element?.nodeType !== Node.ELEMENT_NODE) return\n    return this.elementIsForbidden(element) || this.elementIsntSerializable(element)\n  }\n\n  elementIsForbidden(element) {\n    return this.forbiddenElements.includes(tagName(element))\n  }\n\n  elementIsntSerializable(element) {\n    return element.getAttribute(\"data-trix-serialize\") === \"false\" && !nodeIsAttachmentElement(element)\n  }\n}\n\nconst createBodyElementForHTML = function(html = \"\") {\n  // Remove everything after </html>\n  html = html.replace(/<\\/html[^>]*>[^]*$/i, \"</html>\")\n  const doc = document.implementation.createHTMLDocument(\"\")\n  doc.documentElement.innerHTML = html\n\n  Array.from(doc.head.querySelectorAll(\"style\")).forEach((element) => {\n    doc.body.appendChild(element)\n  })\n\n  return doc.body\n}",
    "repo": "basecamp/trix",
    "path": "./datasets/diagrams-repos/basecamp/trix/src/trix/models/html_sanitizer.js",
    "query": "What is the structure of the HTMLSanitizer class?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'BasicObject', 'node_id': 'BasicObject', 'description': 'Base class for inheritance', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'HTMLSanitizer', 'node_id': 'HTMLSanitizer', 'description': 'Class for sanitizing HTML content', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'setHTML', 'node_id': 'setHTML', 'description': 'Static method to set sanitized HTML', 'visibility': 'public', 'return_type': 'void', 'params': '(element, html)', 'source_class_id': 'HTMLSanitizer'}, {'type': 'method', 'name': 'sanitize', 'node_id': 'sanitize', 'description': 'Main method to sanitize HTML content', 'visibility': 'public', 'return_type': 'HTMLElement', 'params': '()', 'source_class_id': 'HTMLSanitizer'}, {'type': 'method', 'name': 'getHTML', 'node_id': 'getHTML', 'description': 'Get sanitized HTML content', 'visibility': 'public', 'return_type': 'string', 'params': '()', 'source_class_id': 'HTMLSanitizer'}, {'type': 'method', 'name': 'getBody', 'node_id': 'getBody', 'description': 'Get sanitized body element', 'visibility': 'public', 'return_type': 'HTMLElement', 'params': '()', 'source_class_id': 'HTMLSanitizer'}, {'type': 'method', 'name': 'sanitizeElements', 'node_id': 'sanitizeElements', 'description': 'Clean up HTML elements', 'visibility': 'private', 'return_type': 'HTMLElement', 'params': '()', 'source_class_id': 'HTMLSanitizer'}, {'type': 'method', 'name': 'sanitizeElement', 'node_id': 'sanitizeElement', 'description': 'Clean up single element', 'visibility': 'private', 'return_type': 'HTMLElement', 'params': '(element)', 'source_class_id': 'HTMLSanitizer'}, {'type': 'method', 'name': 'normalizeListElementNesting', 'node_id': 'normalizeListElementNesting', 'description': 'Fix list element structure', 'visibility': 'private', 'return_type': 'HTMLElement', 'params': '()', 'source_class_id': 'HTMLSanitizer'}, {'type': 'method', 'name': 'elementIsRemovable', 'node_id': 'elementIsRemovable', 'description': 'Check if element should be removed', 'visibility': 'private', 'return_type': 'boolean', 'params': '(element)', 'source_class_id': 'HTMLSanitizer'}, {'type': 'method', 'name': 'elementIsForbidden', 'node_id': 'elementIsForbidden', 'description': 'Check if element is in forbidden list', 'visibility': 'private', 'return_type': 'boolean', 'params': '(element)', 'source_class_id': 'HTMLSanitizer'}, {'type': 'method', 'name': 'elementIsntSerializable', 'node_id': 'elementIsntSerializable', 'description': \"Check if element can't be serialized\", 'visibility': 'private', 'return_type': 'boolean', 'params': '(element)', 'source_class_id': 'HTMLSanitizer'}, {'type': 'function', 'name': 'createBodyElementForHTML', 'node_id': 'createBodyElementForHTML', 'description': 'Helper function to create body element', 'visibility': 'private', 'return_type': 'HTMLElement', 'params': '(html)', 'source_class_id': None}], 'edges': [{'node_id_from': 'HTMLSanitizer', 'node_id_to': 'BasicObject', 'description': 'extends'}, {'node_id_from': 'sanitize', 'node_id_to': 'sanitizeElements', 'description': 'calls'}, {'node_id_from': 'sanitize', 'node_id_to': 'normalizeListElementNesting', 'description': 'calls'}, {'node_id_from': 'sanitizeElements', 'node_id_to': 'sanitizeElement', 'description': 'calls'}, {'node_id_from': 'sanitizeElements', 'node_id_to': 'elementIsRemovable', 'description': 'calls'}, {'node_id_from': 'HTMLSanitizer', 'node_id_to': 'createBodyElementForHTML', 'description': 'initialize body using'}, {'node_id_from': 'HTMLSanitizer', 'node_id_to': 'sanitize', 'description': ''}, {'node_id_from': 'HTMLSanitizer', 'node_id_to': 'setHTML', 'description': ''}, {'node_id_from': 'HTMLSanitizer', 'node_id_to': 'getHTML', 'description': ''}, {'node_id_from': 'HTMLSanitizer', 'node_id_to': 'getBody', 'description': ''}, {'node_id_from': 'HTMLSanitizer', 'node_id_to': 'elementIsForbidden', 'description': ''}, {'node_id_from': 'HTMLSanitizer', 'node_id_to': 'elementIsntSerializable', 'description': ''}, {'node_id_from': 'HTMLSanitizer', 'node_id_to': 'sanitizeElements', 'description': ''}, {'node_id_from': 'HTMLSanitizer', 'node_id_to': 'sanitizeElement', 'description': ''}, {'node_id_from': 'HTMLSanitizer', 'node_id_to': 'normalizeListElementNesting', 'description': ''}, {'node_id_from': 'HTMLSanitizer', 'node_id_to': 'elementIsRemovable', 'description': ''}], 'packages': [{'package_id': 'core', 'children': ['BasicObject', 'HTMLSanitizer', 'setHTML', 'sanitize', 'getHTML', 'getBody', 'elementIsForbidden', 'elementIsntSerializable', 'sanitizeElements', 'sanitizeElement', 'normalizeListElementNesting', 'elementIsRemovable'], 'description': 'Core functionality'}]}",
    "version": "full",
    "text_answer": "HTMLSanitizer extends BasicObject and provides HTML content sanitization functionality. It includes public methods for HTML manipulation (setHTML, sanitize, getHTML, getBody) and private methods for element processing and validation. The class uses DOMPurify for secure HTML sanitization and implements custom rules for allowed attributes and forbidden elements.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Rust",
    "code": "#![allow(unused_imports)]\n#![allow(clippy::all)]\nuse super::*;\nuse wasm_bindgen::prelude::*;\n#[cfg(web_sys_unstable_apis)]\n#[wasm_bindgen]\nextern \"C\" {\n    # [wasm_bindgen (extends = :: js_sys :: Object , js_name = WebTransportSendStreamStats)]\n    #[derive(Debug, Clone, PartialEq, Eq)]\n    #[doc = \"The `WebTransportSendStreamStats` dictionary.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    pub type WebTransportSendStreamStats;\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Get the `bytesAcknowledged` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, getter = \"bytesAcknowledged\")]\n    pub fn get_bytes_acknowledged(this: &WebTransportSendStreamStats) -> Option<f64>;\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Change the `bytesAcknowledged` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, setter = \"bytesAcknowledged\")]\n    pub fn set_bytes_acknowledged(this: &WebTransportSendStreamStats, val: f64);\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Get the `bytesSent` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, getter = \"bytesSent\")]\n    pub fn get_bytes_sent(this: &WebTransportSendStreamStats) -> Option<f64>;\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Change the `bytesSent` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, setter = \"bytesSent\")]\n    pub fn set_bytes_sent(this: &WebTransportSendStreamStats, val: f64);\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Get the `bytesWritten` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, getter = \"bytesWritten\")]\n    pub fn get_bytes_written(this: &WebTransportSendStreamStats) -> Option<f64>;\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Change the `bytesWritten` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, setter = \"bytesWritten\")]\n    pub fn set_bytes_written(this: &WebTransportSendStreamStats, val: f64);\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Get the `timestamp` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, getter = \"timestamp\")]\n    pub fn get_timestamp(this: &WebTransportSendStreamStats) -> Option<f64>;\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Change the `timestamp` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, setter = \"timestamp\")]\n    pub fn set_timestamp(this: &WebTransportSendStreamStats, val: f64);\n}\n#[cfg(web_sys_unstable_apis)]\nimpl WebTransportSendStreamStats {\n    #[doc = \"Construct a new `WebTransportSendStreamStats`.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    pub fn new() -> Self {\n        #[allow(unused_mut)]\n        let mut ret: Self = ::wasm_bindgen::JsCast::unchecked_into(::js_sys::Object::new());\n        ret\n    }\n    #[cfg(web_sys_unstable_apis)]\n    #[deprecated = \"Use `set_bytes_acknowledged()` instead.\"]\n    pub fn bytes_acknowledged(&mut self, val: f64) -> &mut Self {\n        self.set_bytes_acknowledged(val);\n        self\n    }\n    #[cfg(web_sys_unstable_apis)]\n    #[deprecated = \"Use `set_bytes_sent()` instead.\"]\n    pub fn bytes_sent(&mut self, val: f64) -> &mut Self {\n        self.set_bytes_sent(val);\n        self\n    }\n    #[cfg(web_sys_unstable_apis)]\n    #[deprecated = \"Use `set_bytes_written()` instead.\"]\n    pub fn bytes_written(&mut self, val: f64) -> &mut Self {\n        self.set_bytes_written(val);\n        self\n    }\n    #[cfg(web_sys_unstable_apis)]\n    #[deprecated = \"Use `set_timestamp()` instead.\"]\n    pub fn timestamp(&mut self, val: f64) -> &mut Self {\n        self.set_timestamp(val);\n        self\n    }\n}\n#[cfg(web_sys_unstable_apis)]\nimpl Default for WebTransportSendStreamStats {\n    fn default() -> Self {\n        Self::new()\n    }\n}",
    "repo": "rustwasm/wasm-bindgen",
    "path": "./datasets/diagrams-repos/rustwasm/wasm-bindgen/crates/web-sys/src/features/gen_WebTransportSendStreamStats.rs",
    "query": "What is the structure of the `WebTransportSendStreamStats` type and its associated methods?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'WebTransportSendStreamStats', 'node_id': 'WebTransportSendStreamStats', 'description': 'A dictionary type representing statistics for a WebTransport send stream', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'new', 'node_id': 'new', 'description': 'Constructs a new WebTransportSendStreamStats instance', 'visibility': 'public', 'return_type': 'Self', 'params': '', 'source_class_id': 'WebTransportSendStreamStats'}, {'type': 'method', 'name': 'get_bytes_sent', 'node_id': 'get_bytes_sent', 'description': 'Gets the number of bytes sent', 'visibility': 'public', 'return_type': 'Option<f64>', 'params': '&self', 'source_class_id': 'WebTransportSendStreamStats'}, {'type': 'method', 'name': 'set_bytes_sent', 'node_id': 'set_bytes_sent', 'description': 'Sets the number of bytes sent', 'visibility': 'public', 'return_type': 'void', 'params': '&self, val: f64', 'source_class_id': 'WebTransportSendStreamStats'}], 'edges': [{'node_id_from': 'WebTransportSendStreamStats', 'node_id_to': 'new', 'description': 'constructs'}, {'node_id_from': 'WebTransportSendStreamStats', 'node_id_to': 'get_bytes_sent', 'description': 'has method'}, {'node_id_from': 'WebTransportSendStreamStats', 'node_id_to': 'set_bytes_sent', 'description': 'has method'}], 'packages': [{'package_id': 'webTransportStats', 'children': ['WebTransportSendStreamStats', 'new', 'get_bytes_sent', 'set_bytes_sent'], 'description': 'Core WebTransport statistics functionality'}]}",
    "version": "minimal",
    "text_answer": "WebTransportSendStreamStats is a public type that tracks statistics for WebTransport send streams. It provides getters and setters for bytes sent, acknowledged, written, and timestamp data. The type can be constructed using new() or default() methods and all numeric values are represented as Optional<f64>.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Rust",
    "code": "#![allow(unused_imports)]\n#![allow(clippy::all)]\nuse super::*;\nuse wasm_bindgen::prelude::*;\n#[cfg(web_sys_unstable_apis)]\n#[wasm_bindgen]\nextern \"C\" {\n    # [wasm_bindgen (extends = :: js_sys :: Object , js_name = WebTransportSendStreamStats)]\n    #[derive(Debug, Clone, PartialEq, Eq)]\n    #[doc = \"The `WebTransportSendStreamStats` dictionary.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    pub type WebTransportSendStreamStats;\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Get the `bytesAcknowledged` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, getter = \"bytesAcknowledged\")]\n    pub fn get_bytes_acknowledged(this: &WebTransportSendStreamStats) -> Option<f64>;\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Change the `bytesAcknowledged` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, setter = \"bytesAcknowledged\")]\n    pub fn set_bytes_acknowledged(this: &WebTransportSendStreamStats, val: f64);\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Get the `bytesSent` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, getter = \"bytesSent\")]\n    pub fn get_bytes_sent(this: &WebTransportSendStreamStats) -> Option<f64>;\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Change the `bytesSent` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, setter = \"bytesSent\")]\n    pub fn set_bytes_sent(this: &WebTransportSendStreamStats, val: f64);\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Get the `bytesWritten` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, getter = \"bytesWritten\")]\n    pub fn get_bytes_written(this: &WebTransportSendStreamStats) -> Option<f64>;\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Change the `bytesWritten` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, setter = \"bytesWritten\")]\n    pub fn set_bytes_written(this: &WebTransportSendStreamStats, val: f64);\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Get the `timestamp` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, getter = \"timestamp\")]\n    pub fn get_timestamp(this: &WebTransportSendStreamStats) -> Option<f64>;\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Change the `timestamp` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, setter = \"timestamp\")]\n    pub fn set_timestamp(this: &WebTransportSendStreamStats, val: f64);\n}\n#[cfg(web_sys_unstable_apis)]\nimpl WebTransportSendStreamStats {\n    #[doc = \"Construct a new `WebTransportSendStreamStats`.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    pub fn new() -> Self {\n        #[allow(unused_mut)]\n        let mut ret: Self = ::wasm_bindgen::JsCast::unchecked_into(::js_sys::Object::new());\n        ret\n    }\n    #[cfg(web_sys_unstable_apis)]\n    #[deprecated = \"Use `set_bytes_acknowledged()` instead.\"]\n    pub fn bytes_acknowledged(&mut self, val: f64) -> &mut Self {\n        self.set_bytes_acknowledged(val);\n        self\n    }\n    #[cfg(web_sys_unstable_apis)]\n    #[deprecated = \"Use `set_bytes_sent()` instead.\"]\n    pub fn bytes_sent(&mut self, val: f64) -> &mut Self {\n        self.set_bytes_sent(val);\n        self\n    }\n    #[cfg(web_sys_unstable_apis)]\n    #[deprecated = \"Use `set_bytes_written()` instead.\"]\n    pub fn bytes_written(&mut self, val: f64) -> &mut Self {\n        self.set_bytes_written(val);\n        self\n    }\n    #[cfg(web_sys_unstable_apis)]\n    #[deprecated = \"Use `set_timestamp()` instead.\"]\n    pub fn timestamp(&mut self, val: f64) -> &mut Self {\n        self.set_timestamp(val);\n        self\n    }\n}\n#[cfg(web_sys_unstable_apis)]\nimpl Default for WebTransportSendStreamStats {\n    fn default() -> Self {\n        Self::new()\n    }\n}",
    "repo": "rustwasm/wasm-bindgen",
    "path": "./datasets/diagrams-repos/rustwasm/wasm-bindgen/crates/web-sys/src/features/gen_WebTransportSendStreamStats.rs",
    "query": "What is the structure of the `WebTransportSendStreamStats` type and its associated methods?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'WebTransportSendStreamStats', 'node_id': 'WebTransportSendStreamStats', 'description': 'A dictionary type representing statistics for a WebTransport send stream', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'new', 'node_id': 'new', 'description': 'Constructs a new WebTransportSendStreamStats instance', 'visibility': 'public', 'return_type': 'Self', 'params': '', 'source_class_id': 'WebTransportSendStreamStats'}, {'type': 'method', 'name': 'get_bytes_sent', 'node_id': 'get_bytes_sent', 'description': 'Gets the number of bytes sent', 'visibility': 'public', 'return_type': 'Option<f64>', 'params': '&self', 'source_class_id': 'WebTransportSendStreamStats'}, {'type': 'method', 'name': 'set_bytes_sent', 'node_id': 'set_bytes_sent', 'description': 'Sets the number of bytes sent', 'visibility': 'public', 'return_type': 'void', 'params': '&self, val: f64', 'source_class_id': 'WebTransportSendStreamStats'}, {'type': 'method', 'name': 'get_bytes_acknowledged', 'node_id': 'get_bytes_acknowledged', 'description': 'Gets the number of bytes acknowledged', 'visibility': 'public', 'return_type': 'Option<f64>', 'params': '&self', 'source_class_id': 'WebTransportSendStreamStats'}, {'type': 'method', 'name': 'set_bytes_acknowledged', 'node_id': 'set_bytes_acknowledged', 'description': 'Sets the number of bytes acknowledged', 'visibility': 'public', 'return_type': 'void', 'params': '&self, val: f64', 'source_class_id': 'WebTransportSendStreamStats'}], 'edges': [{'node_id_from': 'WebTransportSendStreamStats', 'node_id_to': 'new', 'description': 'constructs'}, {'node_id_from': 'WebTransportSendStreamStats', 'node_id_to': 'get_bytes_sent', 'description': 'has method'}, {'node_id_from': 'WebTransportSendStreamStats', 'node_id_to': 'set_bytes_sent', 'description': 'has method'}, {'node_id_from': 'WebTransportSendStreamStats', 'node_id_to': 'get_bytes_acknowledged', 'description': 'has method'}, {'node_id_from': 'WebTransportSendStreamStats', 'node_id_to': 'set_bytes_acknowledged', 'description': 'has method'}], 'packages': [{'package_id': 'webTransportStats', 'children': ['WebTransportSendStreamStats', 'new', 'get_bytes_sent', 'set_bytes_sent', 'get_bytes_acknowledged', 'set_bytes_acknowledged'], 'description': 'Core WebTransport statistics functionality'}]}",
    "version": "medium",
    "text_answer": "WebTransportSendStreamStats is a public type that tracks statistics for WebTransport send streams. It provides getters and setters for bytes sent, acknowledged, written, and timestamp data. The type can be constructed using new() or default() methods and all numeric values are represented as Optional<f64>.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Rust",
    "code": "#![allow(unused_imports)]\n#![allow(clippy::all)]\nuse super::*;\nuse wasm_bindgen::prelude::*;\n#[cfg(web_sys_unstable_apis)]\n#[wasm_bindgen]\nextern \"C\" {\n    # [wasm_bindgen (extends = :: js_sys :: Object , js_name = WebTransportSendStreamStats)]\n    #[derive(Debug, Clone, PartialEq, Eq)]\n    #[doc = \"The `WebTransportSendStreamStats` dictionary.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    pub type WebTransportSendStreamStats;\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Get the `bytesAcknowledged` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, getter = \"bytesAcknowledged\")]\n    pub fn get_bytes_acknowledged(this: &WebTransportSendStreamStats) -> Option<f64>;\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Change the `bytesAcknowledged` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, setter = \"bytesAcknowledged\")]\n    pub fn set_bytes_acknowledged(this: &WebTransportSendStreamStats, val: f64);\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Get the `bytesSent` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, getter = \"bytesSent\")]\n    pub fn get_bytes_sent(this: &WebTransportSendStreamStats) -> Option<f64>;\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Change the `bytesSent` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, setter = \"bytesSent\")]\n    pub fn set_bytes_sent(this: &WebTransportSendStreamStats, val: f64);\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Get the `bytesWritten` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, getter = \"bytesWritten\")]\n    pub fn get_bytes_written(this: &WebTransportSendStreamStats) -> Option<f64>;\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Change the `bytesWritten` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, setter = \"bytesWritten\")]\n    pub fn set_bytes_written(this: &WebTransportSendStreamStats, val: f64);\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Get the `timestamp` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, getter = \"timestamp\")]\n    pub fn get_timestamp(this: &WebTransportSendStreamStats) -> Option<f64>;\n    #[cfg(web_sys_unstable_apis)]\n    #[doc = \"Change the `timestamp` field of this object.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    #[wasm_bindgen(method, setter = \"timestamp\")]\n    pub fn set_timestamp(this: &WebTransportSendStreamStats, val: f64);\n}\n#[cfg(web_sys_unstable_apis)]\nimpl WebTransportSendStreamStats {\n    #[doc = \"Construct a new `WebTransportSendStreamStats`.\"]\n    #[doc = \"\"]\n    #[doc = \"*This API requires the following crate features to be activated: `WebTransportSendStreamStats`*\"]\n    #[doc = \"\"]\n    #[doc = \"*This API is unstable and requires `--cfg=web_sys_unstable_apis` to be activated, as\"]\n    #[doc = \"[described in the `wasm-bindgen` guide](https://rustwasm.github.io/docs/wasm-bindgen/web-sys/unstable-apis.html)*\"]\n    pub fn new() -> Self {\n        #[allow(unused_mut)]\n        let mut ret: Self = ::wasm_bindgen::JsCast::unchecked_into(::js_sys::Object::new());\n        ret\n    }\n    #[cfg(web_sys_unstable_apis)]\n    #[deprecated = \"Use `set_bytes_acknowledged()` instead.\"]\n    pub fn bytes_acknowledged(&mut self, val: f64) -> &mut Self {\n        self.set_bytes_acknowledged(val);\n        self\n    }\n    #[cfg(web_sys_unstable_apis)]\n    #[deprecated = \"Use `set_bytes_sent()` instead.\"]\n    pub fn bytes_sent(&mut self, val: f64) -> &mut Self {\n        self.set_bytes_sent(val);\n        self\n    }\n    #[cfg(web_sys_unstable_apis)]\n    #[deprecated = \"Use `set_bytes_written()` instead.\"]\n    pub fn bytes_written(&mut self, val: f64) -> &mut Self {\n        self.set_bytes_written(val);\n        self\n    }\n    #[cfg(web_sys_unstable_apis)]\n    #[deprecated = \"Use `set_timestamp()` instead.\"]\n    pub fn timestamp(&mut self, val: f64) -> &mut Self {\n        self.set_timestamp(val);\n        self\n    }\n}\n#[cfg(web_sys_unstable_apis)]\nimpl Default for WebTransportSendStreamStats {\n    fn default() -> Self {\n        Self::new()\n    }\n}",
    "repo": "rustwasm/wasm-bindgen",
    "path": "./datasets/diagrams-repos/rustwasm/wasm-bindgen/crates/web-sys/src/features/gen_WebTransportSendStreamStats.rs",
    "query": "What is the structure of the `WebTransportSendStreamStats` type and its associated methods?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'WebTransportSendStreamStats', 'node_id': 'WebTransportSendStreamStats', 'description': 'A dictionary type representing statistics for a WebTransport send stream', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'new', 'node_id': 'new', 'description': 'Constructs a new WebTransportSendStreamStats instance', 'visibility': 'public', 'return_type': 'Self', 'params': '', 'source_class_id': 'WebTransportSendStreamStats'}, {'type': 'method', 'name': 'get_bytes_sent', 'node_id': 'get_bytes_sent', 'description': 'Gets the number of bytes sent', 'visibility': 'public', 'return_type': 'Option<f64>', 'params': '&self', 'source_class_id': 'WebTransportSendStreamStats'}, {'type': 'method', 'name': 'set_bytes_sent', 'node_id': 'set_bytes_sent', 'description': 'Sets the number of bytes sent', 'visibility': 'public', 'return_type': 'void', 'params': '&self, val: f64', 'source_class_id': 'WebTransportSendStreamStats'}, {'type': 'method', 'name': 'get_bytes_acknowledged', 'node_id': 'get_bytes_acknowledged', 'description': 'Gets the number of bytes acknowledged', 'visibility': 'public', 'return_type': 'Option<f64>', 'params': '&self', 'source_class_id': 'WebTransportSendStreamStats'}, {'type': 'method', 'name': 'set_bytes_acknowledged', 'node_id': 'set_bytes_acknowledged', 'description': 'Sets the number of bytes acknowledged', 'visibility': 'public', 'return_type': 'void', 'params': '&self, val: f64', 'source_class_id': 'WebTransportSendStreamStats'}, {'type': 'method', 'name': 'get_bytes_written', 'node_id': 'get_bytes_written', 'description': 'Gets the number of bytes written', 'visibility': 'public', 'return_type': 'Option<f64>', 'params': '&self', 'source_class_id': 'WebTransportSendStreamStats'}, {'type': 'method', 'name': 'set_bytes_written', 'node_id': 'set_bytes_written', 'description': 'Sets the number of bytes written', 'visibility': 'public', 'return_type': 'void', 'params': '&self, val: f64', 'source_class_id': 'WebTransportSendStreamStats'}, {'type': 'method', 'name': 'get_timestamp', 'node_id': 'get_timestamp', 'description': 'Gets the timestamp', 'visibility': 'public', 'return_type': 'Option<f64>', 'params': '&self', 'source_class_id': 'WebTransportSendStreamStats'}, {'type': 'method', 'name': 'set_timestamp', 'node_id': 'set_timestamp', 'description': 'Sets the timestamp', 'visibility': 'public', 'return_type': 'void', 'params': '&self, val: f64', 'source_class_id': 'WebTransportSendStreamStats'}, {'type': 'method', 'name': 'default', 'node_id': 'default', 'description': 'Creates a default instance', 'visibility': 'public', 'return_type': 'Self', 'params': '', 'source_class_id': 'WebTransportSendStreamStats'}], 'edges': [{'node_id_from': 'WebTransportSendStreamStats', 'node_id_to': 'new', 'description': 'constructs'}, {'node_id_from': 'WebTransportSendStreamStats', 'node_id_to': 'get_bytes_sent', 'description': 'has method'}, {'node_id_from': 'WebTransportSendStreamStats', 'node_id_to': 'set_bytes_sent', 'description': 'has method'}, {'node_id_from': 'WebTransportSendStreamStats', 'node_id_to': 'get_bytes_acknowledged', 'description': 'has method'}, {'node_id_from': 'WebTransportSendStreamStats', 'node_id_to': 'set_bytes_acknowledged', 'description': 'has method'}, {'node_id_from': 'WebTransportSendStreamStats', 'node_id_to': 'get_bytes_written', 'description': 'has method'}, {'node_id_from': 'WebTransportSendStreamStats', 'node_id_to': 'set_bytes_written', 'description': 'has method'}, {'node_id_from': 'WebTransportSendStreamStats', 'node_id_to': 'get_timestamp', 'description': 'has method'}, {'node_id_from': 'WebTransportSendStreamStats', 'node_id_to': 'set_timestamp', 'description': 'has method'}, {'node_id_from': 'WebTransportSendStreamStats', 'node_id_to': 'default', 'description': 'implements'}], 'packages': [{'package_id': 'webTransportStats', 'children': ['WebTransportSendStreamStats', 'new', 'get_bytes_sent', 'set_bytes_sent', 'get_bytes_acknowledged', 'set_bytes_acknowledged', 'get_bytes_written', 'set_bytes_written', 'get_timestamp', 'set_timestamp', 'default'], 'description': 'Core WebTransport statistics functionality'}]}",
    "version": "full",
    "text_answer": "WebTransportSendStreamStats is a public type that tracks statistics for WebTransport send streams. It provides getters and setters for bytes sent, acknowledged, written, and timestamp data. The type can be constructed using new() or default() methods and all numeric values are represented as Optional<f64>.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C#",
    "code": "\nnamespace NPOI.HWPF.Model\n{\n    using NPOI.Util;\n    using System;\n\n    /**\n     *\n     */\n    public class ListLevel\n    {\n        private static int RGBXCH_NUMS_SIZE = 9;\n\n        private int _iStartAt;\n        private byte _nfc;\n        private byte _info;\n        private static BitField _jc;\n        private static BitField _fLegal;\n        private static BitField _fNoRestart;\n        private static BitField _fPrev;\n        private static BitField _fPrevSpace;\n        private static BitField _fWord6;\n        private byte[] _rgbxchNums;\n        private byte _ixchFollow;\n        private int _dxaSpace;\n        private int _dxaIndent;\n        private int _cbGrpprlChpx;\n        private int _cbGrpprlPapx;\n        private short _reserved;\n        private byte[] _grpprlPapx;\n        private byte[] _grpprlChpx;\n        private char[] _numberText = null;\n\n        public ListLevel(int startAt, int numberFormatCode, int alignment,\n                         byte[] numberProperties, byte[] entryProperties,\n                         String numberText)\n        {\n            _iStartAt = startAt;\n            _nfc = (byte)numberFormatCode;\n            _jc.SetValue(_info, alignment);\n            _grpprlChpx = numberProperties;\n            _grpprlPapx = entryProperties;\n            _numberText = numberText.ToCharArray();\n        }\n\n        public ListLevel(int level, bool numbered)\n        {\n            _iStartAt = 1;\n            _grpprlPapx = new byte[0];\n            _grpprlChpx = new byte[0];\n            _numberText = new char[0];\n            _rgbxchNums = new byte[RGBXCH_NUMS_SIZE];\n\n            if (numbered)\n            {\n                _rgbxchNums[0] = 1;\n                _numberText = new char[] { (char)level, '.' };\n            }\n            else\n            {\n                _numberText = new char[] { '\\u2022' };\n            }\n        }\n\n        public ListLevel(byte[] buf, int offset)\n        {\n            _iStartAt = LittleEndian.GetInt(buf, offset);\n            offset += LittleEndianConsts.INT_SIZE;\n            _nfc = buf[offset++];\n            _info = buf[offset++];\n\n            _rgbxchNums = new byte[RGBXCH_NUMS_SIZE];\n            Array.Copy(buf, offset, _rgbxchNums, 0, RGBXCH_NUMS_SIZE);\n            offset += RGBXCH_NUMS_SIZE;\n\n            _ixchFollow = buf[offset++];\n            _dxaSpace = LittleEndian.GetInt(buf, offset);\n            offset += LittleEndianConsts.INT_SIZE;\n            _dxaIndent = LittleEndian.GetInt(buf, offset);\n            offset += LittleEndianConsts.INT_SIZE;\n            _cbGrpprlChpx = LittleEndian.GetUByte(buf, offset++);\n            _cbGrpprlPapx = LittleEndian.GetUByte(buf, offset++);\n            _reserved = LittleEndian.GetShort(buf, offset);\n            offset += LittleEndianConsts.SHORT_SIZE;\n\n            _grpprlPapx = new byte[_cbGrpprlPapx];\n            _grpprlChpx = new byte[_cbGrpprlChpx];\n            Array.Copy(buf, offset, _grpprlPapx, 0, _cbGrpprlPapx);\n            offset += _cbGrpprlPapx;\n            Array.Copy(buf, offset, _grpprlChpx, 0, _cbGrpprlChpx);\n            offset += _cbGrpprlChpx;\n\n            int numberTextLength = LittleEndian.GetShort(buf, offset);\n            /* sometimes numberTextLength<0 */\n            /* by derjohng */\n            if (numberTextLength > 0)\n            {\n                _numberText = new char[numberTextLength];\n                offset += LittleEndianConsts.SHORT_SIZE;\n                for (int x = 0; x < numberTextLength; x++)\n                {\n                    _numberText[x] = (char)LittleEndian.GetShort(buf, offset);\n                    offset += LittleEndianConsts.SHORT_SIZE;\n                }\n            }\n\n        }\n\n        public int GetStartAt()\n        {\n            return _iStartAt;\n        }\n\n        public int GetNumberFormat()\n        {\n            return _nfc;\n        }\n\n        public int GetAlignment()\n        {\n            return _jc.GetValue(_info);\n        }\n\n        public String GetNumberText()\n        {\n            if (_numberText != null)\n                return new String(_numberText);\n            else\n                return null;\n        }\n        /**\n     * \"The type of character following the number text for the paragraph: 0 == tab, 1 == space, 2 == nothing.\"\n     */\n        public byte GetTypeOfCharFollowingTheNumber()\n        {\n            return this._ixchFollow;\n        }\n        public void SetStartAt(int startAt)\n        {\n            _iStartAt = startAt;\n        }\n\n        public void SetNumberFormat(int numberFormatCode)\n        {\n            _nfc = (byte)numberFormatCode;\n        }\n\n        public void SetAlignment(int alignment)\n        {\n            _jc.SetValue(_info, alignment);\n        }\n\n        public void SetNumberProperties(byte[] grpprl)\n        {\n            _grpprlChpx = grpprl;\n\n        }\n\n        public void SetLevelProperties(byte[] grpprl)\n        {\n            _grpprlPapx = grpprl;\n        }\n\n        public byte[] GetLevelProperties()\n        {\n            return _grpprlPapx;\n        }\n\n        public override bool Equals(Object obj)\n        {\n            if (obj == null)\n            {\n                return false;\n            }\n\n            ListLevel lvl = (ListLevel)obj;\n            return _cbGrpprlChpx == lvl._cbGrpprlChpx && lvl._cbGrpprlPapx == _cbGrpprlPapx &&\n              lvl._dxaIndent == _dxaIndent && lvl._dxaSpace == _dxaSpace &&\n              Arrays.Equals(lvl._grpprlChpx, _grpprlChpx) &&\n              Arrays.Equals(lvl._grpprlPapx, _grpprlPapx) &&\n              lvl._info == _info && lvl._iStartAt == _iStartAt &&\n              lvl._ixchFollow == _ixchFollow && lvl._nfc == _nfc &&\n              Arrays.Equals(lvl._numberText, _numberText) &&\n              Arrays.Equals(lvl._rgbxchNums, _rgbxchNums) &&\n              lvl._reserved == _reserved;\n\n\n        }\n        public byte[] ToArray()\n        {\n            byte[] buf = new byte[GetSizeInBytes()];\n            int offset = 0;\n            LittleEndian.PutInt(buf, offset, _iStartAt);\n            offset += LittleEndianConsts.INT_SIZE;\n            buf[offset++] = _nfc;\n            buf[offset++] = _info;\n            Array.Copy(_rgbxchNums, 0, buf, offset, RGBXCH_NUMS_SIZE);\n            offset += RGBXCH_NUMS_SIZE;\n            buf[offset++] = _ixchFollow;\n            LittleEndian.PutInt(buf, offset, _dxaSpace);\n            offset += LittleEndianConsts.INT_SIZE;\n            LittleEndian.PutInt(buf, offset, _dxaIndent);\n            offset += LittleEndianConsts.INT_SIZE;\n\n            buf[offset++] = (byte)_cbGrpprlChpx;\n            buf[offset++] = (byte)_cbGrpprlPapx;\n            LittleEndian.PutShort(buf, offset, _reserved);\n            offset += LittleEndianConsts.SHORT_SIZE;\n\n            Array.Copy(_grpprlPapx, 0, buf, offset, _cbGrpprlPapx);\n            offset += _cbGrpprlPapx;\n            Array.Copy(_grpprlChpx, 0, buf, offset, _cbGrpprlChpx);\n            offset += _cbGrpprlChpx;\n\n            if (_numberText == null)\n            {\n                // TODO - write junit to test this flow\n                LittleEndian.PutUShort(buf, offset, 0);\n            }\n            else\n            {\n                LittleEndian.PutUShort(buf, offset, _numberText.Length);\n                offset += LittleEndianConsts.SHORT_SIZE;\n                for (int x = 0; x < _numberText.Length; x++)\n                {\n                    LittleEndian.PutUShort(buf, offset, _numberText[x]);\n                    offset += LittleEndianConsts.SHORT_SIZE;\n                }\n            }\n            return buf;\n        }\n        public int GetSizeInBytes()\n        {\n            int result =\n                6 // int byte byte\n                + RGBXCH_NUMS_SIZE\n                + 13 // byte int int byte byte short\n                + _cbGrpprlChpx\n                + _cbGrpprlPapx\n                + 2; // numberText length\n            if (_numberText != null)\n            {\n                result += _numberText.Length * LittleEndianConsts.SHORT_SIZE;\n            }\n            return result;\n        }\n\n    }\n}",
    "repo": "nissl-lab/npoi",
    "path": "./datasets/diagrams-repos/nissl-lab/npoi/scratchpad/HWPF/Model/ListLevel.cs",
    "query": "How do the methods in the ListLevel class interact with each other and the class's fields?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'ListLevel', 'node_id': 'ListLevel', 'description': 'Represents a level in a list format in HWPF document', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'GetStartAt', 'node_id': 'GetStartAt', 'description': 'Returns the starting number of the list level', 'visibility': 'public', 'return_type': 'int', 'params': '', 'source_class_id': 'ListLevel'}, {'type': 'method', 'name': 'SetStartAt', 'node_id': 'SetStartAt', 'description': 'Sets the starting number of the list level', 'visibility': 'public', 'return_type': 'void', 'params': 'int startAt', 'source_class_id': 'ListLevel'}, {'type': 'field', 'name': '_iStartAt', 'node_id': '_iStartAt', 'description': 'Starting number for this list level', 'visibility': 'private', 'return_type': 'int', 'params': None, 'source_class_id': 'ListLevel'}], 'edges': [{'node_id_from': 'GetStartAt', 'node_id_to': '_iStartAt', 'description': 'reads'}, {'node_id_from': 'SetStartAt', 'node_id_to': '_iStartAt', 'description': 'modifies'}, {'node_id_from': 'ListLevel', 'node_id_to': 'GetStartAt', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': 'SetStartAt', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': '_iStartAt', 'description': ''}], 'packages': [{'package_id': 'listLevelCore', 'children': ['ListLevel', 'GetStartAt', 'SetStartAt', '_iStartAt'], 'description': 'Core list level functionality'}]}",
    "version": "minimal",
    "text_answer": "The ListLevel class methods primarily interact through getter and setter patterns, accessing private fields. Core methods manage the start number (_iStartAt), number format (_nfc), and alignment (_info). The ToArray method depends on GetSizeInBytes for serialization, while Equals compares all fields. Most interactions are direct field access, with minimal method-to-method communication.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C#",
    "code": "\nnamespace NPOI.HWPF.Model\n{\n    using NPOI.Util;\n    using System;\n\n    /**\n     *\n     */\n    public class ListLevel\n    {\n        private static int RGBXCH_NUMS_SIZE = 9;\n\n        private int _iStartAt;\n        private byte _nfc;\n        private byte _info;\n        private static BitField _jc;\n        private static BitField _fLegal;\n        private static BitField _fNoRestart;\n        private static BitField _fPrev;\n        private static BitField _fPrevSpace;\n        private static BitField _fWord6;\n        private byte[] _rgbxchNums;\n        private byte _ixchFollow;\n        private int _dxaSpace;\n        private int _dxaIndent;\n        private int _cbGrpprlChpx;\n        private int _cbGrpprlPapx;\n        private short _reserved;\n        private byte[] _grpprlPapx;\n        private byte[] _grpprlChpx;\n        private char[] _numberText = null;\n\n        public ListLevel(int startAt, int numberFormatCode, int alignment,\n                         byte[] numberProperties, byte[] entryProperties,\n                         String numberText)\n        {\n            _iStartAt = startAt;\n            _nfc = (byte)numberFormatCode;\n            _jc.SetValue(_info, alignment);\n            _grpprlChpx = numberProperties;\n            _grpprlPapx = entryProperties;\n            _numberText = numberText.ToCharArray();\n        }\n\n        public ListLevel(int level, bool numbered)\n        {\n            _iStartAt = 1;\n            _grpprlPapx = new byte[0];\n            _grpprlChpx = new byte[0];\n            _numberText = new char[0];\n            _rgbxchNums = new byte[RGBXCH_NUMS_SIZE];\n\n            if (numbered)\n            {\n                _rgbxchNums[0] = 1;\n                _numberText = new char[] { (char)level, '.' };\n            }\n            else\n            {\n                _numberText = new char[] { '\\u2022' };\n            }\n        }\n\n        public ListLevel(byte[] buf, int offset)\n        {\n            _iStartAt = LittleEndian.GetInt(buf, offset);\n            offset += LittleEndianConsts.INT_SIZE;\n            _nfc = buf[offset++];\n            _info = buf[offset++];\n\n            _rgbxchNums = new byte[RGBXCH_NUMS_SIZE];\n            Array.Copy(buf, offset, _rgbxchNums, 0, RGBXCH_NUMS_SIZE);\n            offset += RGBXCH_NUMS_SIZE;\n\n            _ixchFollow = buf[offset++];\n            _dxaSpace = LittleEndian.GetInt(buf, offset);\n            offset += LittleEndianConsts.INT_SIZE;\n            _dxaIndent = LittleEndian.GetInt(buf, offset);\n            offset += LittleEndianConsts.INT_SIZE;\n            _cbGrpprlChpx = LittleEndian.GetUByte(buf, offset++);\n            _cbGrpprlPapx = LittleEndian.GetUByte(buf, offset++);\n            _reserved = LittleEndian.GetShort(buf, offset);\n            offset += LittleEndianConsts.SHORT_SIZE;\n\n            _grpprlPapx = new byte[_cbGrpprlPapx];\n            _grpprlChpx = new byte[_cbGrpprlChpx];\n            Array.Copy(buf, offset, _grpprlPapx, 0, _cbGrpprlPapx);\n            offset += _cbGrpprlPapx;\n            Array.Copy(buf, offset, _grpprlChpx, 0, _cbGrpprlChpx);\n            offset += _cbGrpprlChpx;\n\n            int numberTextLength = LittleEndian.GetShort(buf, offset);\n            /* sometimes numberTextLength<0 */\n            /* by derjohng */\n            if (numberTextLength > 0)\n            {\n                _numberText = new char[numberTextLength];\n                offset += LittleEndianConsts.SHORT_SIZE;\n                for (int x = 0; x < numberTextLength; x++)\n                {\n                    _numberText[x] = (char)LittleEndian.GetShort(buf, offset);\n                    offset += LittleEndianConsts.SHORT_SIZE;\n                }\n            }\n\n        }\n\n        public int GetStartAt()\n        {\n            return _iStartAt;\n        }\n\n        public int GetNumberFormat()\n        {\n            return _nfc;\n        }\n\n        public int GetAlignment()\n        {\n            return _jc.GetValue(_info);\n        }\n\n        public String GetNumberText()\n        {\n            if (_numberText != null)\n                return new String(_numberText);\n            else\n                return null;\n        }\n        /**\n     * \"The type of character following the number text for the paragraph: 0 == tab, 1 == space, 2 == nothing.\"\n     */\n        public byte GetTypeOfCharFollowingTheNumber()\n        {\n            return this._ixchFollow;\n        }\n        public void SetStartAt(int startAt)\n        {\n            _iStartAt = startAt;\n        }\n\n        public void SetNumberFormat(int numberFormatCode)\n        {\n            _nfc = (byte)numberFormatCode;\n        }\n\n        public void SetAlignment(int alignment)\n        {\n            _jc.SetValue(_info, alignment);\n        }\n\n        public void SetNumberProperties(byte[] grpprl)\n        {\n            _grpprlChpx = grpprl;\n\n        }\n\n        public void SetLevelProperties(byte[] grpprl)\n        {\n            _grpprlPapx = grpprl;\n        }\n\n        public byte[] GetLevelProperties()\n        {\n            return _grpprlPapx;\n        }\n\n        public override bool Equals(Object obj)\n        {\n            if (obj == null)\n            {\n                return false;\n            }\n\n            ListLevel lvl = (ListLevel)obj;\n            return _cbGrpprlChpx == lvl._cbGrpprlChpx && lvl._cbGrpprlPapx == _cbGrpprlPapx &&\n              lvl._dxaIndent == _dxaIndent && lvl._dxaSpace == _dxaSpace &&\n              Arrays.Equals(lvl._grpprlChpx, _grpprlChpx) &&\n              Arrays.Equals(lvl._grpprlPapx, _grpprlPapx) &&\n              lvl._info == _info && lvl._iStartAt == _iStartAt &&\n              lvl._ixchFollow == _ixchFollow && lvl._nfc == _nfc &&\n              Arrays.Equals(lvl._numberText, _numberText) &&\n              Arrays.Equals(lvl._rgbxchNums, _rgbxchNums) &&\n              lvl._reserved == _reserved;\n\n\n        }\n        public byte[] ToArray()\n        {\n            byte[] buf = new byte[GetSizeInBytes()];\n            int offset = 0;\n            LittleEndian.PutInt(buf, offset, _iStartAt);\n            offset += LittleEndianConsts.INT_SIZE;\n            buf[offset++] = _nfc;\n            buf[offset++] = _info;\n            Array.Copy(_rgbxchNums, 0, buf, offset, RGBXCH_NUMS_SIZE);\n            offset += RGBXCH_NUMS_SIZE;\n            buf[offset++] = _ixchFollow;\n            LittleEndian.PutInt(buf, offset, _dxaSpace);\n            offset += LittleEndianConsts.INT_SIZE;\n            LittleEndian.PutInt(buf, offset, _dxaIndent);\n            offset += LittleEndianConsts.INT_SIZE;\n\n            buf[offset++] = (byte)_cbGrpprlChpx;\n            buf[offset++] = (byte)_cbGrpprlPapx;\n            LittleEndian.PutShort(buf, offset, _reserved);\n            offset += LittleEndianConsts.SHORT_SIZE;\n\n            Array.Copy(_grpprlPapx, 0, buf, offset, _cbGrpprlPapx);\n            offset += _cbGrpprlPapx;\n            Array.Copy(_grpprlChpx, 0, buf, offset, _cbGrpprlChpx);\n            offset += _cbGrpprlChpx;\n\n            if (_numberText == null)\n            {\n                // TODO - write junit to test this flow\n                LittleEndian.PutUShort(buf, offset, 0);\n            }\n            else\n            {\n                LittleEndian.PutUShort(buf, offset, _numberText.Length);\n                offset += LittleEndianConsts.SHORT_SIZE;\n                for (int x = 0; x < _numberText.Length; x++)\n                {\n                    LittleEndian.PutUShort(buf, offset, _numberText[x]);\n                    offset += LittleEndianConsts.SHORT_SIZE;\n                }\n            }\n            return buf;\n        }\n        public int GetSizeInBytes()\n        {\n            int result =\n                6 // int byte byte\n                + RGBXCH_NUMS_SIZE\n                + 13 // byte int int byte byte short\n                + _cbGrpprlChpx\n                + _cbGrpprlPapx\n                + 2; // numberText length\n            if (_numberText != null)\n            {\n                result += _numberText.Length * LittleEndianConsts.SHORT_SIZE;\n            }\n            return result;\n        }\n\n    }\n}",
    "repo": "nissl-lab/npoi",
    "path": "./datasets/diagrams-repos/nissl-lab/npoi/scratchpad/HWPF/Model/ListLevel.cs",
    "query": "How do the methods in the ListLevel class interact with each other and the class's fields?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'ListLevel', 'node_id': 'ListLevel', 'description': 'Represents a level in a list format in HWPF document', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'GetStartAt', 'node_id': 'GetStartAt', 'description': 'Returns the starting number of the list level', 'visibility': 'public', 'return_type': 'int', 'params': '', 'source_class_id': 'ListLevel'}, {'type': 'method', 'name': 'SetStartAt', 'node_id': 'SetStartAt', 'description': 'Sets the starting number of the list level', 'visibility': 'public', 'return_type': 'void', 'params': 'int startAt', 'source_class_id': 'ListLevel'}, {'type': 'method', 'name': 'GetNumberFormat', 'node_id': 'GetNumberFormat', 'description': 'Returns the number format code', 'visibility': 'public', 'return_type': 'int', 'params': '', 'source_class_id': 'ListLevel'}, {'type': 'method', 'name': 'SetNumberFormat', 'node_id': 'SetNumberFormat', 'description': 'Sets the number format code', 'visibility': 'public', 'return_type': 'void', 'params': 'int numberFormatCode', 'source_class_id': 'ListLevel'}, {'type': 'method', 'name': 'ToArray', 'node_id': 'ToArray', 'description': 'Converts list level to byte array', 'visibility': 'public', 'return_type': 'byte[]', 'params': '', 'source_class_id': 'ListLevel'}, {'type': 'field', 'name': '_iStartAt', 'node_id': '_iStartAt', 'description': 'Starting number for this list level', 'visibility': 'private', 'return_type': 'int', 'params': None, 'source_class_id': 'ListLevel'}, {'type': 'field', 'name': '_nfc', 'node_id': '_nfc', 'description': 'Number format code', 'visibility': 'private', 'return_type': 'byte', 'params': None, 'source_class_id': 'ListLevel'}], 'edges': [{'node_id_from': 'GetStartAt', 'node_id_to': '_iStartAt', 'description': 'reads'}, {'node_id_from': 'SetStartAt', 'node_id_to': '_iStartAt', 'description': 'modifies'}, {'node_id_from': 'GetNumberFormat', 'node_id_to': '_nfc', 'description': 'reads'}, {'node_id_from': 'SetNumberFormat', 'node_id_to': '_nfc', 'description': 'modifies'}, {'node_id_from': 'ToArray', 'node_id_to': '_iStartAt', 'description': 'reads'}, {'node_id_from': 'ToArray', 'node_id_to': '_nfc', 'description': 'reads'}, {'node_id_from': 'ListLevel', 'node_id_to': 'GetStartAt', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': 'SetStartAt', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': 'GetNumberFormat', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': 'SetNumberFormat', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': 'ToArray', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': '_iStartAt', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': '_nfc', 'description': ''}], 'packages': [{'package_id': 'listLevelCore', 'children': ['ListLevel', 'GetStartAt', 'SetStartAt', 'ToArray', '_iStartAt', 'formatting'], 'description': 'Core list level functionality'}, {'package_id': 'formatting', 'children': ['GetNumberFormat', 'SetNumberFormat', '_nfc'], 'description': 'Number formatting related functionality'}]}",
    "version": "medium",
    "text_answer": "The ListLevel class methods primarily interact through getter and setter patterns, accessing private fields. Core methods manage the start number (_iStartAt), number format (_nfc), and alignment (_info). The ToArray method depends on GetSizeInBytes for serialization, while Equals compares all fields. Most interactions are direct field access, with minimal method-to-method communication.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C#",
    "code": "\nnamespace NPOI.HWPF.Model\n{\n    using NPOI.Util;\n    using System;\n\n    /**\n     *\n     */\n    public class ListLevel\n    {\n        private static int RGBXCH_NUMS_SIZE = 9;\n\n        private int _iStartAt;\n        private byte _nfc;\n        private byte _info;\n        private static BitField _jc;\n        private static BitField _fLegal;\n        private static BitField _fNoRestart;\n        private static BitField _fPrev;\n        private static BitField _fPrevSpace;\n        private static BitField _fWord6;\n        private byte[] _rgbxchNums;\n        private byte _ixchFollow;\n        private int _dxaSpace;\n        private int _dxaIndent;\n        private int _cbGrpprlChpx;\n        private int _cbGrpprlPapx;\n        private short _reserved;\n        private byte[] _grpprlPapx;\n        private byte[] _grpprlChpx;\n        private char[] _numberText = null;\n\n        public ListLevel(int startAt, int numberFormatCode, int alignment,\n                         byte[] numberProperties, byte[] entryProperties,\n                         String numberText)\n        {\n            _iStartAt = startAt;\n            _nfc = (byte)numberFormatCode;\n            _jc.SetValue(_info, alignment);\n            _grpprlChpx = numberProperties;\n            _grpprlPapx = entryProperties;\n            _numberText = numberText.ToCharArray();\n        }\n\n        public ListLevel(int level, bool numbered)\n        {\n            _iStartAt = 1;\n            _grpprlPapx = new byte[0];\n            _grpprlChpx = new byte[0];\n            _numberText = new char[0];\n            _rgbxchNums = new byte[RGBXCH_NUMS_SIZE];\n\n            if (numbered)\n            {\n                _rgbxchNums[0] = 1;\n                _numberText = new char[] { (char)level, '.' };\n            }\n            else\n            {\n                _numberText = new char[] { '\\u2022' };\n            }\n        }\n\n        public ListLevel(byte[] buf, int offset)\n        {\n            _iStartAt = LittleEndian.GetInt(buf, offset);\n            offset += LittleEndianConsts.INT_SIZE;\n            _nfc = buf[offset++];\n            _info = buf[offset++];\n\n            _rgbxchNums = new byte[RGBXCH_NUMS_SIZE];\n            Array.Copy(buf, offset, _rgbxchNums, 0, RGBXCH_NUMS_SIZE);\n            offset += RGBXCH_NUMS_SIZE;\n\n            _ixchFollow = buf[offset++];\n            _dxaSpace = LittleEndian.GetInt(buf, offset);\n            offset += LittleEndianConsts.INT_SIZE;\n            _dxaIndent = LittleEndian.GetInt(buf, offset);\n            offset += LittleEndianConsts.INT_SIZE;\n            _cbGrpprlChpx = LittleEndian.GetUByte(buf, offset++);\n            _cbGrpprlPapx = LittleEndian.GetUByte(buf, offset++);\n            _reserved = LittleEndian.GetShort(buf, offset);\n            offset += LittleEndianConsts.SHORT_SIZE;\n\n            _grpprlPapx = new byte[_cbGrpprlPapx];\n            _grpprlChpx = new byte[_cbGrpprlChpx];\n            Array.Copy(buf, offset, _grpprlPapx, 0, _cbGrpprlPapx);\n            offset += _cbGrpprlPapx;\n            Array.Copy(buf, offset, _grpprlChpx, 0, _cbGrpprlChpx);\n            offset += _cbGrpprlChpx;\n\n            int numberTextLength = LittleEndian.GetShort(buf, offset);\n            /* sometimes numberTextLength<0 */\n            /* by derjohng */\n            if (numberTextLength > 0)\n            {\n                _numberText = new char[numberTextLength];\n                offset += LittleEndianConsts.SHORT_SIZE;\n                for (int x = 0; x < numberTextLength; x++)\n                {\n                    _numberText[x] = (char)LittleEndian.GetShort(buf, offset);\n                    offset += LittleEndianConsts.SHORT_SIZE;\n                }\n            }\n\n        }\n\n        public int GetStartAt()\n        {\n            return _iStartAt;\n        }\n\n        public int GetNumberFormat()\n        {\n            return _nfc;\n        }\n\n        public int GetAlignment()\n        {\n            return _jc.GetValue(_info);\n        }\n\n        public String GetNumberText()\n        {\n            if (_numberText != null)\n                return new String(_numberText);\n            else\n                return null;\n        }\n        /**\n     * \"The type of character following the number text for the paragraph: 0 == tab, 1 == space, 2 == nothing.\"\n     */\n        public byte GetTypeOfCharFollowingTheNumber()\n        {\n            return this._ixchFollow;\n        }\n        public void SetStartAt(int startAt)\n        {\n            _iStartAt = startAt;\n        }\n\n        public void SetNumberFormat(int numberFormatCode)\n        {\n            _nfc = (byte)numberFormatCode;\n        }\n\n        public void SetAlignment(int alignment)\n        {\n            _jc.SetValue(_info, alignment);\n        }\n\n        public void SetNumberProperties(byte[] grpprl)\n        {\n            _grpprlChpx = grpprl;\n\n        }\n\n        public void SetLevelProperties(byte[] grpprl)\n        {\n            _grpprlPapx = grpprl;\n        }\n\n        public byte[] GetLevelProperties()\n        {\n            return _grpprlPapx;\n        }\n\n        public override bool Equals(Object obj)\n        {\n            if (obj == null)\n            {\n                return false;\n            }\n\n            ListLevel lvl = (ListLevel)obj;\n            return _cbGrpprlChpx == lvl._cbGrpprlChpx && lvl._cbGrpprlPapx == _cbGrpprlPapx &&\n              lvl._dxaIndent == _dxaIndent && lvl._dxaSpace == _dxaSpace &&\n              Arrays.Equals(lvl._grpprlChpx, _grpprlChpx) &&\n              Arrays.Equals(lvl._grpprlPapx, _grpprlPapx) &&\n              lvl._info == _info && lvl._iStartAt == _iStartAt &&\n              lvl._ixchFollow == _ixchFollow && lvl._nfc == _nfc &&\n              Arrays.Equals(lvl._numberText, _numberText) &&\n              Arrays.Equals(lvl._rgbxchNums, _rgbxchNums) &&\n              lvl._reserved == _reserved;\n\n\n        }\n        public byte[] ToArray()\n        {\n            byte[] buf = new byte[GetSizeInBytes()];\n            int offset = 0;\n            LittleEndian.PutInt(buf, offset, _iStartAt);\n            offset += LittleEndianConsts.INT_SIZE;\n            buf[offset++] = _nfc;\n            buf[offset++] = _info;\n            Array.Copy(_rgbxchNums, 0, buf, offset, RGBXCH_NUMS_SIZE);\n            offset += RGBXCH_NUMS_SIZE;\n            buf[offset++] = _ixchFollow;\n            LittleEndian.PutInt(buf, offset, _dxaSpace);\n            offset += LittleEndianConsts.INT_SIZE;\n            LittleEndian.PutInt(buf, offset, _dxaIndent);\n            offset += LittleEndianConsts.INT_SIZE;\n\n            buf[offset++] = (byte)_cbGrpprlChpx;\n            buf[offset++] = (byte)_cbGrpprlPapx;\n            LittleEndian.PutShort(buf, offset, _reserved);\n            offset += LittleEndianConsts.SHORT_SIZE;\n\n            Array.Copy(_grpprlPapx, 0, buf, offset, _cbGrpprlPapx);\n            offset += _cbGrpprlPapx;\n            Array.Copy(_grpprlChpx, 0, buf, offset, _cbGrpprlChpx);\n            offset += _cbGrpprlChpx;\n\n            if (_numberText == null)\n            {\n                // TODO - write junit to test this flow\n                LittleEndian.PutUShort(buf, offset, 0);\n            }\n            else\n            {\n                LittleEndian.PutUShort(buf, offset, _numberText.Length);\n                offset += LittleEndianConsts.SHORT_SIZE;\n                for (int x = 0; x < _numberText.Length; x++)\n                {\n                    LittleEndian.PutUShort(buf, offset, _numberText[x]);\n                    offset += LittleEndianConsts.SHORT_SIZE;\n                }\n            }\n            return buf;\n        }\n        public int GetSizeInBytes()\n        {\n            int result =\n                6 // int byte byte\n                + RGBXCH_NUMS_SIZE\n                + 13 // byte int int byte byte short\n                + _cbGrpprlChpx\n                + _cbGrpprlPapx\n                + 2; // numberText length\n            if (_numberText != null)\n            {\n                result += _numberText.Length * LittleEndianConsts.SHORT_SIZE;\n            }\n            return result;\n        }\n\n    }\n}",
    "repo": "nissl-lab/npoi",
    "path": "./datasets/diagrams-repos/nissl-lab/npoi/scratchpad/HWPF/Model/ListLevel.cs",
    "query": "How do the methods in the ListLevel class interact with each other and the class's fields?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'ListLevel', 'node_id': 'ListLevel', 'description': 'Represents a level in a list format in HWPF document', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'GetStartAt', 'node_id': 'GetStartAt', 'description': 'Returns the starting number of the list level', 'visibility': 'public', 'return_type': 'int', 'params': '', 'source_class_id': 'ListLevel'}, {'type': 'method', 'name': 'SetStartAt', 'node_id': 'SetStartAt', 'description': 'Sets the starting number of the list level', 'visibility': 'public', 'return_type': 'void', 'params': 'int startAt', 'source_class_id': 'ListLevel'}, {'type': 'method', 'name': 'GetNumberFormat', 'node_id': 'GetNumberFormat', 'description': 'Returns the number format code', 'visibility': 'public', 'return_type': 'int', 'params': '', 'source_class_id': 'ListLevel'}, {'type': 'method', 'name': 'SetNumberFormat', 'node_id': 'SetNumberFormat', 'description': 'Sets the number format code', 'visibility': 'public', 'return_type': 'void', 'params': 'int numberFormatCode', 'source_class_id': 'ListLevel'}, {'type': 'method', 'name': 'GetAlignment', 'node_id': 'GetAlignment', 'description': 'Returns the alignment value', 'visibility': 'public', 'return_type': 'int', 'params': '', 'source_class_id': 'ListLevel'}, {'type': 'method', 'name': 'SetAlignment', 'node_id': 'SetAlignment', 'description': 'Sets the alignment value', 'visibility': 'public', 'return_type': 'void', 'params': 'int alignment', 'source_class_id': 'ListLevel'}, {'type': 'method', 'name': 'GetNumberText', 'node_id': 'GetNumberText', 'description': 'Returns the number text', 'visibility': 'public', 'return_type': 'String', 'params': '', 'source_class_id': 'ListLevel'}, {'type': 'method', 'name': 'ToArray', 'node_id': 'ToArray', 'description': 'Converts list level to byte array', 'visibility': 'public', 'return_type': 'byte[]', 'params': '', 'source_class_id': 'ListLevel'}, {'type': 'method', 'name': 'GetSizeInBytes', 'node_id': 'GetSizeInBytes', 'description': 'Calculates size in bytes', 'visibility': 'public', 'return_type': 'int', 'params': '', 'source_class_id': 'ListLevel'}, {'type': 'method', 'name': 'Equals', 'node_id': 'Equals', 'description': 'Compares two ListLevel objects', 'visibility': 'public', 'return_type': 'bool', 'params': 'Object obj', 'source_class_id': 'ListLevel'}, {'type': 'field', 'name': '_iStartAt', 'node_id': '_iStartAt', 'description': 'Starting number for this list level', 'visibility': 'private', 'return_type': 'int', 'params': None, 'source_class_id': 'ListLevel'}, {'type': 'field', 'name': '_nfc', 'node_id': '_nfc', 'description': 'Number format code', 'visibility': 'private', 'return_type': 'byte', 'params': None, 'source_class_id': 'ListLevel'}, {'type': 'field', 'name': '_info', 'node_id': '_info', 'description': 'Information bits', 'visibility': 'private', 'return_type': 'byte', 'params': None, 'source_class_id': 'ListLevel'}, {'type': 'field', 'name': '_numberText', 'node_id': '_numberText', 'description': 'Number text characters', 'visibility': 'private', 'return_type': 'char[]', 'params': None, 'source_class_id': 'ListLevel'}], 'edges': [{'node_id_from': 'GetStartAt', 'node_id_to': '_iStartAt', 'description': 'reads'}, {'node_id_from': 'SetStartAt', 'node_id_to': '_iStartAt', 'description': 'modifies'}, {'node_id_from': 'GetNumberFormat', 'node_id_to': '_nfc', 'description': 'reads'}, {'node_id_from': 'SetNumberFormat', 'node_id_to': '_nfc', 'description': 'modifies'}, {'node_id_from': 'GetAlignment', 'node_id_to': '_info', 'description': 'reads'}, {'node_id_from': 'SetAlignment', 'node_id_to': '_info', 'description': 'modifies'}, {'node_id_from': 'GetNumberText', 'node_id_to': '_numberText', 'description': 'reads'}, {'node_id_from': 'ToArray', 'node_id_to': 'GetSizeInBytes', 'description': 'calls'}, {'node_id_from': 'Equals', 'node_id_to': '_iStartAt', 'description': 'reads'}, {'node_id_from': 'Equals', 'node_id_to': '_nfc', 'description': 'reads'}, {'node_id_from': 'ListLevel', 'node_id_to': 'GetStartAt', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': 'SetStartAt', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': 'GetNumberFormat', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': 'SetNumberFormat', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': 'GetAlignment', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': 'SetAlignment', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': 'GetNumberText', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': 'ToArray', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': 'Equals', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': 'GetSizeInBytes', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': '_iStartAt', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': '_nfc', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': '_info', 'description': ''}, {'node_id_from': 'ListLevel', 'node_id_to': '_numberText', 'description': ''}], 'packages': [{'package_id': 'listLevelCore', 'children': ['ListLevel', 'GetStartAt', 'SetStartAt', '_iStartAt', 'utilities', 'serialization', 'formatting'], 'description': 'Core list level functionality'}, {'package_id': 'formatting', 'children': ['GetNumberFormat', 'SetNumberFormat', 'GetAlignment', 'SetAlignment', '_nfc', '_info'], 'description': 'Number formatting related functionality'}, {'package_id': 'serialization', 'children': ['ToArray', 'GetSizeInBytes'], 'description': 'Data serialization functionality'}, {'package_id': 'utilities', 'children': ['Equals', 'GetNumberText', '_numberText'], 'description': 'Utility methods and text handling'}]}",
    "version": "full",
    "text_answer": "The ListLevel class methods primarily interact through getter and setter patterns, accessing private fields. Core methods manage the start number (_iStartAt), number format (_nfc), and alignment (_info). The ToArray method depends on GetSizeInBytes for serialization, while Equals compares all fields. Most interactions are direct field access, with minimal method-to-method communication.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Python",
    "code": "\nfrom __future__ import annotations\n\nimport json\nimport logging\nfrom typing import TYPE_CHECKING, Any, cast\n\nfrom google.cloud import texttospeech\nimport voluptuous as vol\n\nfrom homeassistant.components.file_upload import process_uploaded_file\nfrom homeassistant.components.tts import CONF_LANG\nfrom homeassistant.config_entries import (\n    ConfigEntry,\n    ConfigFlow,\n    ConfigFlowResult,\n    OptionsFlow,\n)\nfrom homeassistant.core import callback\nfrom homeassistant.helpers.selector import (\n    FileSelector,\n    FileSelectorConfig,\n    SelectSelector,\n    SelectSelectorConfig,\n    SelectSelectorMode,\n)\n\nfrom .const import (\n    CONF_KEY_FILE,\n    CONF_SERVICE_ACCOUNT_INFO,\n    CONF_STT_MODEL,\n    DEFAULT_LANG,\n    DEFAULT_STT_MODEL,\n    DOMAIN,\n    SUPPORTED_STT_MODELS,\n    TITLE,\n)\nfrom .helpers import (\n    async_tts_voices,\n    tts_options_schema,\n    tts_platform_schema,\n    validate_service_account_info,\n)\n\n_LOGGER = logging.getLogger(__name__)\n\nUPLOADED_KEY_FILE = \"uploaded_key_file\"\n\nSTEP_USER_DATA_SCHEMA = vol.Schema(\n    {\n        vol.Required(UPLOADED_KEY_FILE): FileSelector(\n            FileSelectorConfig(accept=\".json,application/json\")\n        )\n    }\n)\n\n\nclass GoogleCloudConfigFlow(ConfigFlow, domain=DOMAIN):\n    \"\"\"Handle a config flow for Google Cloud integration.\"\"\"\n\n    VERSION = 1\n\n    _name: str | None = None\n    entry: ConfigEntry | None = None\n    abort_reason: str | None = None\n\n    def _parse_uploaded_file(self, uploaded_file_id: str) -> dict[str, Any]:\n        \"\"\"Read and parse an uploaded JSON file.\"\"\"\n        with process_uploaded_file(self.hass, uploaded_file_id) as file_path:\n            contents = file_path.read_text()\n        return cast(dict[str, Any], json.loads(contents))\n\n    async def async_step_user(\n        self, user_input: dict[str, Any] | None = None\n    ) -> ConfigFlowResult:\n        \"\"\"Handle the initial step.\"\"\"\n        errors: dict[str, Any] = {}\n        if user_input is not None:\n            try:\n                service_account_info = await self.hass.async_add_executor_job(\n                    self._parse_uploaded_file, user_input[UPLOADED_KEY_FILE]\n                )\n                validate_service_account_info(service_account_info)\n            except ValueError:\n                _LOGGER.exception(\"Reading uploaded JSON file failed\")\n                errors[\"base\"] = \"invalid_file\"\n            else:\n                data = {CONF_SERVICE_ACCOUNT_INFO: service_account_info}\n                if self.entry:\n                    if TYPE_CHECKING:\n                        assert self.abort_reason\n                    return self.async_update_reload_and_abort(\n                        self.entry, data=data, reason=self.abort_reason\n                    )\n                return self.async_create_entry(title=TITLE, data=data)\n        return self.async_show_form(\n            step_id=\"user\",\n            data_schema=STEP_USER_DATA_SCHEMA,\n            errors=errors,\n            description_placeholders={\n                \"url\": \"https://console.cloud.google.com/apis/credentials/serviceaccountkey\"\n            },\n        )\n\n    async def async_step_import(self, import_data: dict[str, Any]) -> ConfigFlowResult:\n        \"\"\"Import Google Cloud configuration from YAML.\"\"\"\n\n        def _read_key_file() -> dict[str, Any]:\n            with open(\n                self.hass.config.path(import_data[CONF_KEY_FILE]), encoding=\"utf8\"\n            ) as f:\n                return cast(dict[str, Any], json.load(f))\n\n        service_account_info = await self.hass.async_add_executor_job(_read_key_file)\n        try:\n            validate_service_account_info(service_account_info)\n        except ValueError:\n            _LOGGER.exception(\"Reading credentials JSON file failed\")\n            return self.async_abort(reason=\"invalid_file\")\n        options = {\n            k: v for k, v in import_data.items() if k in tts_platform_schema().schema\n        }\n        options.pop(CONF_KEY_FILE)\n        _LOGGER.debug(\"Creating imported config entry with options: %s\", options)\n        return self.async_create_entry(\n            title=TITLE,\n            data={CONF_SERVICE_ACCOUNT_INFO: service_account_info},\n            options=options,\n        )\n\n    @staticmethod\n    @callback\n    def async_get_options_flow(\n        config_entry: ConfigEntry,\n    ) -> GoogleCloudOptionsFlowHandler:\n        \"\"\"Create the options flow.\"\"\"\n        return GoogleCloudOptionsFlowHandler()\n\n\nclass GoogleCloudOptionsFlowHandler(OptionsFlow):\n    \"\"\"Google Cloud options flow.\"\"\"\n\n    async def async_step_init(\n        self, user_input: dict[str, Any] | None = None\n    ) -> ConfigFlowResult:\n        \"\"\"Manage the options.\"\"\"\n        if user_input is not None:\n            return self.async_create_entry(data=user_input)\n\n        service_account_info = self.config_entry.data[CONF_SERVICE_ACCOUNT_INFO]\n        client: texttospeech.TextToSpeechAsyncClient = (\n            texttospeech.TextToSpeechAsyncClient.from_service_account_info(\n                service_account_info\n            )\n        )\n        voices = await async_tts_voices(client)\n        return self.async_show_form(\n            step_id=\"init\",\n            data_schema=self.add_suggested_values_to_schema(\n                vol.Schema(\n                    {\n                        vol.Optional(\n                            CONF_LANG,\n                            default=DEFAULT_LANG,\n                        ): SelectSelector(\n                            SelectSelectorConfig(\n                                mode=SelectSelectorMode.DROPDOWN, options=list(voices)\n                            )\n                        ),\n                        **tts_options_schema(\n                            self.config_entry.options, voices, from_config_flow=True\n                        ).schema,\n                        vol.Optional(\n                            CONF_STT_MODEL,\n                            default=DEFAULT_STT_MODEL,\n                        ): SelectSelector(\n                            SelectSelectorConfig(\n                                mode=SelectSelectorMode.DROPDOWN,\n                                options=SUPPORTED_STT_MODELS,\n                            )\n                        ),\n                    }\n                ),\n                self.config_entry.options,\n            ),\n        )",
    "repo": "home-assistant/core",
    "path": "./datasets/diagrams-repos/home-assistant/core/homeassistant/components/google_cloud/config_flow.py",
    "query": "How does the Google Cloud integration use the Text-to-Speech client?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'GoogleCloudOptionsFlowHandler', 'node_id': 'GoogleCloudOptionsFlowHandler', 'description': 'Handles options configuration for Google Cloud integration', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'async_step_init', 'node_id': 'async_step_init', 'description': 'Initializes TTS client and configures voice options', 'visibility': 'public', 'return_type': 'ConfigFlowResult', 'params': 'self, user_input: dict[str, Any] | None = None', 'source_class_id': 'GoogleCloudOptionsFlowHandler'}, {'type': 'function', 'name': 'async_tts_voices', 'node_id': 'async_tts_voices', 'description': 'Retrieves available TTS voices from Google Cloud', 'visibility': 'public', 'return_type': 'List[str]', 'params': 'client: TextToSpeechAsyncClient', 'source_class_id': None}], 'edges': [{'node_id_from': 'GoogleCloudOptionsFlowHandler', 'node_id_to': 'async_step_init', 'description': 'contains'}, {'node_id_from': 'async_step_init', 'node_id_to': 'async_tts_voices', 'description': 'calls'}], 'packages': [{'package_id': 'ttsFlow', 'children': ['GoogleCloudOptionsFlowHandler', 'async_step_init', 'async_tts_voices'], 'description': 'Core TTS configuration flow'}]}",
    "version": "minimal",
    "text_answer": "The Google Cloud integration uses Text-to-Speech client by creating a TextToSpeechAsyncClient instance from service account information in the options flow. This client is then used to fetch available TTS voices and configure language and voice options for the integration.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Python",
    "code": "\nfrom __future__ import annotations\n\nimport json\nimport logging\nfrom typing import TYPE_CHECKING, Any, cast\n\nfrom google.cloud import texttospeech\nimport voluptuous as vol\n\nfrom homeassistant.components.file_upload import process_uploaded_file\nfrom homeassistant.components.tts import CONF_LANG\nfrom homeassistant.config_entries import (\n    ConfigEntry,\n    ConfigFlow,\n    ConfigFlowResult,\n    OptionsFlow,\n)\nfrom homeassistant.core import callback\nfrom homeassistant.helpers.selector import (\n    FileSelector,\n    FileSelectorConfig,\n    SelectSelector,\n    SelectSelectorConfig,\n    SelectSelectorMode,\n)\n\nfrom .const import (\n    CONF_KEY_FILE,\n    CONF_SERVICE_ACCOUNT_INFO,\n    CONF_STT_MODEL,\n    DEFAULT_LANG,\n    DEFAULT_STT_MODEL,\n    DOMAIN,\n    SUPPORTED_STT_MODELS,\n    TITLE,\n)\nfrom .helpers import (\n    async_tts_voices,\n    tts_options_schema,\n    tts_platform_schema,\n    validate_service_account_info,\n)\n\n_LOGGER = logging.getLogger(__name__)\n\nUPLOADED_KEY_FILE = \"uploaded_key_file\"\n\nSTEP_USER_DATA_SCHEMA = vol.Schema(\n    {\n        vol.Required(UPLOADED_KEY_FILE): FileSelector(\n            FileSelectorConfig(accept=\".json,application/json\")\n        )\n    }\n)\n\n\nclass GoogleCloudConfigFlow(ConfigFlow, domain=DOMAIN):\n    \"\"\"Handle a config flow for Google Cloud integration.\"\"\"\n\n    VERSION = 1\n\n    _name: str | None = None\n    entry: ConfigEntry | None = None\n    abort_reason: str | None = None\n\n    def _parse_uploaded_file(self, uploaded_file_id: str) -> dict[str, Any]:\n        \"\"\"Read and parse an uploaded JSON file.\"\"\"\n        with process_uploaded_file(self.hass, uploaded_file_id) as file_path:\n            contents = file_path.read_text()\n        return cast(dict[str, Any], json.loads(contents))\n\n    async def async_step_user(\n        self, user_input: dict[str, Any] | None = None\n    ) -> ConfigFlowResult:\n        \"\"\"Handle the initial step.\"\"\"\n        errors: dict[str, Any] = {}\n        if user_input is not None:\n            try:\n                service_account_info = await self.hass.async_add_executor_job(\n                    self._parse_uploaded_file, user_input[UPLOADED_KEY_FILE]\n                )\n                validate_service_account_info(service_account_info)\n            except ValueError:\n                _LOGGER.exception(\"Reading uploaded JSON file failed\")\n                errors[\"base\"] = \"invalid_file\"\n            else:\n                data = {CONF_SERVICE_ACCOUNT_INFO: service_account_info}\n                if self.entry:\n                    if TYPE_CHECKING:\n                        assert self.abort_reason\n                    return self.async_update_reload_and_abort(\n                        self.entry, data=data, reason=self.abort_reason\n                    )\n                return self.async_create_entry(title=TITLE, data=data)\n        return self.async_show_form(\n            step_id=\"user\",\n            data_schema=STEP_USER_DATA_SCHEMA,\n            errors=errors,\n            description_placeholders={\n                \"url\": \"https://console.cloud.google.com/apis/credentials/serviceaccountkey\"\n            },\n        )\n\n    async def async_step_import(self, import_data: dict[str, Any]) -> ConfigFlowResult:\n        \"\"\"Import Google Cloud configuration from YAML.\"\"\"\n\n        def _read_key_file() -> dict[str, Any]:\n            with open(\n                self.hass.config.path(import_data[CONF_KEY_FILE]), encoding=\"utf8\"\n            ) as f:\n                return cast(dict[str, Any], json.load(f))\n\n        service_account_info = await self.hass.async_add_executor_job(_read_key_file)\n        try:\n            validate_service_account_info(service_account_info)\n        except ValueError:\n            _LOGGER.exception(\"Reading credentials JSON file failed\")\n            return self.async_abort(reason=\"invalid_file\")\n        options = {\n            k: v for k, v in import_data.items() if k in tts_platform_schema().schema\n        }\n        options.pop(CONF_KEY_FILE)\n        _LOGGER.debug(\"Creating imported config entry with options: %s\", options)\n        return self.async_create_entry(\n            title=TITLE,\n            data={CONF_SERVICE_ACCOUNT_INFO: service_account_info},\n            options=options,\n        )\n\n    @staticmethod\n    @callback\n    def async_get_options_flow(\n        config_entry: ConfigEntry,\n    ) -> GoogleCloudOptionsFlowHandler:\n        \"\"\"Create the options flow.\"\"\"\n        return GoogleCloudOptionsFlowHandler()\n\n\nclass GoogleCloudOptionsFlowHandler(OptionsFlow):\n    \"\"\"Google Cloud options flow.\"\"\"\n\n    async def async_step_init(\n        self, user_input: dict[str, Any] | None = None\n    ) -> ConfigFlowResult:\n        \"\"\"Manage the options.\"\"\"\n        if user_input is not None:\n            return self.async_create_entry(data=user_input)\n\n        service_account_info = self.config_entry.data[CONF_SERVICE_ACCOUNT_INFO]\n        client: texttospeech.TextToSpeechAsyncClient = (\n            texttospeech.TextToSpeechAsyncClient.from_service_account_info(\n                service_account_info\n            )\n        )\n        voices = await async_tts_voices(client)\n        return self.async_show_form(\n            step_id=\"init\",\n            data_schema=self.add_suggested_values_to_schema(\n                vol.Schema(\n                    {\n                        vol.Optional(\n                            CONF_LANG,\n                            default=DEFAULT_LANG,\n                        ): SelectSelector(\n                            SelectSelectorConfig(\n                                mode=SelectSelectorMode.DROPDOWN, options=list(voices)\n                            )\n                        ),\n                        **tts_options_schema(\n                            self.config_entry.options, voices, from_config_flow=True\n                        ).schema,\n                        vol.Optional(\n                            CONF_STT_MODEL,\n                            default=DEFAULT_STT_MODEL,\n                        ): SelectSelector(\n                            SelectSelectorConfig(\n                                mode=SelectSelectorMode.DROPDOWN,\n                                options=SUPPORTED_STT_MODELS,\n                            )\n                        ),\n                    }\n                ),\n                self.config_entry.options,\n            ),\n        )",
    "repo": "home-assistant/core",
    "path": "./datasets/diagrams-repos/home-assistant/core/homeassistant/components/google_cloud/config_flow.py",
    "query": "How does the Google Cloud integration use the Text-to-Speech client?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'GoogleCloudOptionsFlowHandler', 'node_id': 'GoogleCloudOptionsFlowHandler', 'description': 'Handles options configuration for Google Cloud integration', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'async_step_init', 'node_id': 'async_step_init', 'description': 'Initializes TTS client and configures voice options', 'visibility': 'public', 'return_type': 'ConfigFlowResult', 'params': 'self, user_input: dict[str, Any] | None = None', 'source_class_id': 'GoogleCloudOptionsFlowHandler'}, {'type': 'function', 'name': 'async_tts_voices', 'node_id': 'async_tts_voices', 'description': 'Retrieves available TTS voices from Google Cloud', 'visibility': 'public', 'return_type': 'List[str]', 'params': 'client: TextToSpeechAsyncClient', 'source_class_id': None}, {'type': 'entity', 'name': 'TextToSpeechAsyncClient', 'node_id': 'TextToSpeechAsyncClient', 'description': 'Google Cloud TTS client', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'CONF_LANG', 'node_id': 'CONF_LANG', 'description': 'Language configuration constant', 'visibility': 'public', 'return_type': 'str', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'DEFAULT_LANG', 'node_id': 'DEFAULT_LANG', 'description': 'Default language setting', 'visibility': 'public', 'return_type': 'str', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'GoogleCloudOptionsFlowHandler', 'node_id_to': 'async_step_init', 'description': 'contains'}, {'node_id_from': 'async_step_init', 'node_id_to': 'async_tts_voices', 'description': 'calls'}, {'node_id_from': 'async_step_init', 'node_id_to': 'TextToSpeechAsyncClient', 'description': 'creates'}, {'node_id_from': 'async_step_init', 'node_id_to': 'DEFAULT_LANG', 'description': 'uses'}, {'node_id_from': 'async_step_init', 'node_id_to': 'CONF_LANG', 'description': 'uses'}], 'packages': [{'package_id': 'ttsFlow', 'children': ['GoogleCloudOptionsFlowHandler', 'async_step_init', 'async_tts_voices'], 'description': 'Core TTS configuration flow'}, {'package_id': 'configuration', 'children': ['CONF_LANG', 'DEFAULT_LANG'], 'description': 'Configuration constants'}]}",
    "version": "medium",
    "text_answer": "The Google Cloud integration uses Text-to-Speech client by creating a TextToSpeechAsyncClient instance from service account information in the options flow. This client is then used to fetch available TTS voices and configure language and voice options for the integration.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Python",
    "code": "\nfrom __future__ import annotations\n\nimport json\nimport logging\nfrom typing import TYPE_CHECKING, Any, cast\n\nfrom google.cloud import texttospeech\nimport voluptuous as vol\n\nfrom homeassistant.components.file_upload import process_uploaded_file\nfrom homeassistant.components.tts import CONF_LANG\nfrom homeassistant.config_entries import (\n    ConfigEntry,\n    ConfigFlow,\n    ConfigFlowResult,\n    OptionsFlow,\n)\nfrom homeassistant.core import callback\nfrom homeassistant.helpers.selector import (\n    FileSelector,\n    FileSelectorConfig,\n    SelectSelector,\n    SelectSelectorConfig,\n    SelectSelectorMode,\n)\n\nfrom .const import (\n    CONF_KEY_FILE,\n    CONF_SERVICE_ACCOUNT_INFO,\n    CONF_STT_MODEL,\n    DEFAULT_LANG,\n    DEFAULT_STT_MODEL,\n    DOMAIN,\n    SUPPORTED_STT_MODELS,\n    TITLE,\n)\nfrom .helpers import (\n    async_tts_voices,\n    tts_options_schema,\n    tts_platform_schema,\n    validate_service_account_info,\n)\n\n_LOGGER = logging.getLogger(__name__)\n\nUPLOADED_KEY_FILE = \"uploaded_key_file\"\n\nSTEP_USER_DATA_SCHEMA = vol.Schema(\n    {\n        vol.Required(UPLOADED_KEY_FILE): FileSelector(\n            FileSelectorConfig(accept=\".json,application/json\")\n        )\n    }\n)\n\n\nclass GoogleCloudConfigFlow(ConfigFlow, domain=DOMAIN):\n    \"\"\"Handle a config flow for Google Cloud integration.\"\"\"\n\n    VERSION = 1\n\n    _name: str | None = None\n    entry: ConfigEntry | None = None\n    abort_reason: str | None = None\n\n    def _parse_uploaded_file(self, uploaded_file_id: str) -> dict[str, Any]:\n        \"\"\"Read and parse an uploaded JSON file.\"\"\"\n        with process_uploaded_file(self.hass, uploaded_file_id) as file_path:\n            contents = file_path.read_text()\n        return cast(dict[str, Any], json.loads(contents))\n\n    async def async_step_user(\n        self, user_input: dict[str, Any] | None = None\n    ) -> ConfigFlowResult:\n        \"\"\"Handle the initial step.\"\"\"\n        errors: dict[str, Any] = {}\n        if user_input is not None:\n            try:\n                service_account_info = await self.hass.async_add_executor_job(\n                    self._parse_uploaded_file, user_input[UPLOADED_KEY_FILE]\n                )\n                validate_service_account_info(service_account_info)\n            except ValueError:\n                _LOGGER.exception(\"Reading uploaded JSON file failed\")\n                errors[\"base\"] = \"invalid_file\"\n            else:\n                data = {CONF_SERVICE_ACCOUNT_INFO: service_account_info}\n                if self.entry:\n                    if TYPE_CHECKING:\n                        assert self.abort_reason\n                    return self.async_update_reload_and_abort(\n                        self.entry, data=data, reason=self.abort_reason\n                    )\n                return self.async_create_entry(title=TITLE, data=data)\n        return self.async_show_form(\n            step_id=\"user\",\n            data_schema=STEP_USER_DATA_SCHEMA,\n            errors=errors,\n            description_placeholders={\n                \"url\": \"https://console.cloud.google.com/apis/credentials/serviceaccountkey\"\n            },\n        )\n\n    async def async_step_import(self, import_data: dict[str, Any]) -> ConfigFlowResult:\n        \"\"\"Import Google Cloud configuration from YAML.\"\"\"\n\n        def _read_key_file() -> dict[str, Any]:\n            with open(\n                self.hass.config.path(import_data[CONF_KEY_FILE]), encoding=\"utf8\"\n            ) as f:\n                return cast(dict[str, Any], json.load(f))\n\n        service_account_info = await self.hass.async_add_executor_job(_read_key_file)\n        try:\n            validate_service_account_info(service_account_info)\n        except ValueError:\n            _LOGGER.exception(\"Reading credentials JSON file failed\")\n            return self.async_abort(reason=\"invalid_file\")\n        options = {\n            k: v for k, v in import_data.items() if k in tts_platform_schema().schema\n        }\n        options.pop(CONF_KEY_FILE)\n        _LOGGER.debug(\"Creating imported config entry with options: %s\", options)\n        return self.async_create_entry(\n            title=TITLE,\n            data={CONF_SERVICE_ACCOUNT_INFO: service_account_info},\n            options=options,\n        )\n\n    @staticmethod\n    @callback\n    def async_get_options_flow(\n        config_entry: ConfigEntry,\n    ) -> GoogleCloudOptionsFlowHandler:\n        \"\"\"Create the options flow.\"\"\"\n        return GoogleCloudOptionsFlowHandler()\n\n\nclass GoogleCloudOptionsFlowHandler(OptionsFlow):\n    \"\"\"Google Cloud options flow.\"\"\"\n\n    async def async_step_init(\n        self, user_input: dict[str, Any] | None = None\n    ) -> ConfigFlowResult:\n        \"\"\"Manage the options.\"\"\"\n        if user_input is not None:\n            return self.async_create_entry(data=user_input)\n\n        service_account_info = self.config_entry.data[CONF_SERVICE_ACCOUNT_INFO]\n        client: texttospeech.TextToSpeechAsyncClient = (\n            texttospeech.TextToSpeechAsyncClient.from_service_account_info(\n                service_account_info\n            )\n        )\n        voices = await async_tts_voices(client)\n        return self.async_show_form(\n            step_id=\"init\",\n            data_schema=self.add_suggested_values_to_schema(\n                vol.Schema(\n                    {\n                        vol.Optional(\n                            CONF_LANG,\n                            default=DEFAULT_LANG,\n                        ): SelectSelector(\n                            SelectSelectorConfig(\n                                mode=SelectSelectorMode.DROPDOWN, options=list(voices)\n                            )\n                        ),\n                        **tts_options_schema(\n                            self.config_entry.options, voices, from_config_flow=True\n                        ).schema,\n                        vol.Optional(\n                            CONF_STT_MODEL,\n                            default=DEFAULT_STT_MODEL,\n                        ): SelectSelector(\n                            SelectSelectorConfig(\n                                mode=SelectSelectorMode.DROPDOWN,\n                                options=SUPPORTED_STT_MODELS,\n                            )\n                        ),\n                    }\n                ),\n                self.config_entry.options,\n            ),\n        )",
    "repo": "home-assistant/core",
    "path": "./datasets/diagrams-repos/home-assistant/core/homeassistant/components/google_cloud/config_flow.py",
    "query": "How does the Google Cloud integration use the Text-to-Speech client?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'GoogleCloudConfigFlow', 'node_id': 'GoogleCloudConfigFlow', 'description': 'Main configuration flow for Google Cloud integration', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'GoogleCloudOptionsFlowHandler', 'node_id': 'GoogleCloudOptionsFlowHandler', 'description': 'Handles options configuration for Google Cloud integration', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'async_step_init', 'node_id': 'async_step_init', 'description': 'Initializes TTS client and configures voice options', 'visibility': 'public', 'return_type': 'ConfigFlowResult', 'params': 'self, user_input: dict[str, Any] | None = None', 'source_class_id': 'GoogleCloudOptionsFlowHandler'}, {'type': 'function', 'name': 'async_tts_voices', 'node_id': 'async_tts_voices', 'description': 'Retrieves available TTS voices from Google Cloud', 'visibility': 'public', 'return_type': 'List[str]', 'params': 'client: TextToSpeechAsyncClient', 'source_class_id': None}, {'type': 'entity', 'name': 'TextToSpeechAsyncClient', 'node_id': 'TextToSpeechAsyncClient', 'description': 'Google Cloud TTS client', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'CONF_LANG', 'node_id': 'CONF_LANG', 'description': 'Language configuration constant', 'visibility': 'public', 'return_type': 'str', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'DEFAULT_LANG', 'node_id': 'DEFAULT_LANG', 'description': 'Default language setting', 'visibility': 'public', 'return_type': 'str', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'CONF_SERVICE_ACCOUNT_INFO', 'node_id': 'CONF_SERVICE_ACCOUNT_INFO', 'description': 'Service account configuration constant', 'visibility': 'public', 'return_type': 'str', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'tts_options_schema', 'node_id': 'tts_options_schema', 'description': 'Creates schema for TTS options', 'visibility': 'public', 'return_type': 'vol.Schema', 'params': 'options, voices, from_config_flow', 'source_class_id': None}, {'type': 'variable', 'name': 'CONF_STT_MODEL', 'node_id': 'CONF_STT_MODEL', 'description': 'Speech-to-text model configuration', 'visibility': 'public', 'return_type': 'str', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'GoogleCloudConfigFlow', 'node_id_to': 'GoogleCloudOptionsFlowHandler', 'description': 'creates'}, {'node_id_from': 'GoogleCloudOptionsFlowHandler', 'node_id_to': 'async_step_init', 'description': 'contains'}, {'node_id_from': 'async_step_init', 'node_id_to': 'async_tts_voices', 'description': 'calls'}, {'node_id_from': 'async_step_init', 'node_id_to': 'TextToSpeechAsyncClient', 'description': 'creates'}, {'node_id_from': 'async_step_init', 'node_id_to': 'tts_options_schema', 'description': 'uses'}, {'node_id_from': 'async_step_init', 'node_id_to': 'DEFAULT_LANG', 'description': 'uses'}, {'node_id_from': 'async_step_init', 'node_id_to': 'CONF_LANG', 'description': 'uses'}, {'node_id_from': 'async_step_init', 'node_id_to': 'CONF_SERVICE_ACCOUNT_INFO', 'description': 'uses'}, {'node_id_from': 'async_step_init', 'node_id_to': 'CONF_STT_MODEL', 'description': 'uses'}], 'packages': [{'package_id': 'ttsFlow', 'children': ['GoogleCloudConfigFlow', 'GoogleCloudOptionsFlowHandler', 'async_step_init', 'async_tts_voices'], 'description': 'Core TTS configuration flow'}, {'package_id': 'configuration', 'children': ['CONF_LANG', 'DEFAULT_LANG', 'CONF_SERVICE_ACCOUNT_INFO', 'CONF_STT_MODEL'], 'description': 'Configuration constants'}]}",
    "version": "full",
    "text_answer": "The Google Cloud integration uses Text-to-Speech client by creating a TextToSpeechAsyncClient instance from service account information in the options flow. This client is then used to fetch available TTS voices and configure language and voice options for the integration.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include <inttypes.h>\n#include <stdarg.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\n#include <pw_unit_test/framework.h>\n\n#include <lib/core/StringBuilderAdapters.h>\n#include <lib/support/CodeUtils.h>\n#include <lib/support/UnitTestUtils.h>\n#include <system/SystemClock.h>\n\n#include <platform/internal/CHIPDeviceLayerInternal.h>\n\nusing namespace chip;\nusing namespace chip::Logging;\nusing namespace chip::System;\nusing namespace chip::System::Clock::Literals;\n\nconstexpr Clock::Milliseconds64 kTestTimeMarginMs = 2_ms64;\nconstexpr Clock::Microseconds64 kTestTimeMarginUs = 500_us64;\n\n// =================================\n//      Unit tests\n// =================================\n\nTEST(TestDevice, GetMonotonicMicroseconds)\n{\n    static const Clock::Microseconds64 kTestVectorSystemTimeUs[] = {\n        600_us64,\n        900_us64,\n        1500_us64,\n    };\n    int numOfTestsRan                      = 0;\n    constexpr Clock::Microseconds64 margin = kTestTimeMarginUs;\n\n    for (const Clock::Microseconds64 & Tdelay : kTestVectorSystemTimeUs)\n    {\n        const Clock::Microseconds64 Tstart = System::SystemClock().GetMonotonicMicroseconds64();\n\n        chip::test_utils::SleepMicros(Tdelay.count());\n\n        const Clock::Microseconds64 Tend   = System::SystemClock().GetMonotonicMicroseconds64();\n        const Clock::Microseconds64 Tdelta = Tend - Tstart;\n\n        ChipLogProgress(DeviceLayer,\n                        \"Start=0x\" ChipLogFormatX64 \" End=0x\" ChipLogFormatX64 \" Delta=0x\" ChipLogFormatX64\n                        \" Expected=0x\" ChipLogFormatX64,\n                        ChipLogValueX64(Tstart.count()), ChipLogValueX64(Tend.count()), ChipLogValueX64(Tdelta.count()),\n                        ChipLogValueX64(Tdelay.count()));\n\n        // verify that timers don't fire early\n        EXPECT_GT(Tdelta, (Tdelay - margin));\n        // verify they're not too late\n        //        EXPECT_LT(Tdelta, (Tdelay + margin));\n        numOfTestsRan++;\n    }\n    EXPECT_GT(numOfTestsRan, 0);\n}\n\nTEST(TestDevice, GetMonotonicMilliseconds)\n{\n    static const System::Clock::Milliseconds64 kTestVectorSystemTimeMs[] = {\n        10_ms64,\n        100_ms64,\n        250_ms64,\n    };\n    int numOfTestsRan                      = 0;\n    constexpr Clock::Milliseconds64 margin = kTestTimeMarginMs;\n\n    for (const Clock::Milliseconds64 & Tdelay : kTestVectorSystemTimeMs)\n    {\n        const Clock::Milliseconds64 Tstart = System::SystemClock().GetMonotonicMilliseconds64();\n\n        chip::test_utils::SleepMillis(Tdelay.count());\n\n        const Clock::Milliseconds64 Tend   = System::SystemClock().GetMonotonicMilliseconds64();\n        const Clock::Milliseconds64 Tdelta = Tend - Tstart;\n\n        ChipLogProgress(DeviceLayer,\n                        \"Start=0x\" ChipLogFormatX64 \" End=0x\" ChipLogFormatX64 \" Delta=0x\" ChipLogFormatX64\n                        \" Expected=0x\" ChipLogFormatX64,\n                        ChipLogValueX64(Tstart.count()), ChipLogValueX64(Tend.count()), ChipLogValueX64(Tdelta.count()),\n                        ChipLogValueX64(Tdelay.count()));\n\n        // verify that timers don't fire early\n        EXPECT_GT(Tdelta, (Tdelay - margin));\n        // verify they're not too late\n        //        EXPECT_LT(Tdelta, (Tdelay + margin));\n        numOfTestsRan++;\n    }\n    EXPECT_GT(numOfTestsRan, 0);\n}",
    "repo": "project-chip/connectedhomeip",
    "path": "./datasets/diagrams-repos/project-chip/connectedhomeip/src/platform/tests/TestPlatformTime.cpp",
    "query": "What are the interactions between the test functions and the system clock?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'GetMonotonicMicroseconds', 'node_id': 'GetMonotonicMicroseconds', 'description': 'Test function that verifies microsecond-level system clock measurements', 'visibility': 'public', 'return_type': 'void', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'GetMonotonicMilliseconds', 'node_id': 'GetMonotonicMilliseconds', 'description': 'Test function that verifies millisecond-level system clock measurements', 'visibility': 'public', 'return_type': 'void', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'SystemClock', 'node_id': 'SystemClock', 'description': 'System clock interface providing time measurements', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'GetMonotonicMicroseconds', 'node_id_to': 'SystemClock', 'description': 'Gets microsecond timestamps'}, {'node_id_from': 'GetMonotonicMilliseconds', 'node_id_to': 'SystemClock', 'description': 'Gets millisecond timestamps'}], 'packages': [{'package_id': 'TestingFramework', 'children': ['GetMonotonicMicroseconds', 'GetMonotonicMilliseconds'], 'description': 'Unit tests for system clock functionality'}]}",
    "version": "minimal",
    "text_answer": "The test functions interact with SystemClock by getting timestamps before and after sleep operations to verify timing accuracy at both microsecond and millisecond levels, ensuring measurements are within defined margins.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include <inttypes.h>\n#include <stdarg.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\n#include <pw_unit_test/framework.h>\n\n#include <lib/core/StringBuilderAdapters.h>\n#include <lib/support/CodeUtils.h>\n#include <lib/support/UnitTestUtils.h>\n#include <system/SystemClock.h>\n\n#include <platform/internal/CHIPDeviceLayerInternal.h>\n\nusing namespace chip;\nusing namespace chip::Logging;\nusing namespace chip::System;\nusing namespace chip::System::Clock::Literals;\n\nconstexpr Clock::Milliseconds64 kTestTimeMarginMs = 2_ms64;\nconstexpr Clock::Microseconds64 kTestTimeMarginUs = 500_us64;\n\n// =================================\n//      Unit tests\n// =================================\n\nTEST(TestDevice, GetMonotonicMicroseconds)\n{\n    static const Clock::Microseconds64 kTestVectorSystemTimeUs[] = {\n        600_us64,\n        900_us64,\n        1500_us64,\n    };\n    int numOfTestsRan                      = 0;\n    constexpr Clock::Microseconds64 margin = kTestTimeMarginUs;\n\n    for (const Clock::Microseconds64 & Tdelay : kTestVectorSystemTimeUs)\n    {\n        const Clock::Microseconds64 Tstart = System::SystemClock().GetMonotonicMicroseconds64();\n\n        chip::test_utils::SleepMicros(Tdelay.count());\n\n        const Clock::Microseconds64 Tend   = System::SystemClock().GetMonotonicMicroseconds64();\n        const Clock::Microseconds64 Tdelta = Tend - Tstart;\n\n        ChipLogProgress(DeviceLayer,\n                        \"Start=0x\" ChipLogFormatX64 \" End=0x\" ChipLogFormatX64 \" Delta=0x\" ChipLogFormatX64\n                        \" Expected=0x\" ChipLogFormatX64,\n                        ChipLogValueX64(Tstart.count()), ChipLogValueX64(Tend.count()), ChipLogValueX64(Tdelta.count()),\n                        ChipLogValueX64(Tdelay.count()));\n\n        // verify that timers don't fire early\n        EXPECT_GT(Tdelta, (Tdelay - margin));\n        // verify they're not too late\n        //        EXPECT_LT(Tdelta, (Tdelay + margin));\n        numOfTestsRan++;\n    }\n    EXPECT_GT(numOfTestsRan, 0);\n}\n\nTEST(TestDevice, GetMonotonicMilliseconds)\n{\n    static const System::Clock::Milliseconds64 kTestVectorSystemTimeMs[] = {\n        10_ms64,\n        100_ms64,\n        250_ms64,\n    };\n    int numOfTestsRan                      = 0;\n    constexpr Clock::Milliseconds64 margin = kTestTimeMarginMs;\n\n    for (const Clock::Milliseconds64 & Tdelay : kTestVectorSystemTimeMs)\n    {\n        const Clock::Milliseconds64 Tstart = System::SystemClock().GetMonotonicMilliseconds64();\n\n        chip::test_utils::SleepMillis(Tdelay.count());\n\n        const Clock::Milliseconds64 Tend   = System::SystemClock().GetMonotonicMilliseconds64();\n        const Clock::Milliseconds64 Tdelta = Tend - Tstart;\n\n        ChipLogProgress(DeviceLayer,\n                        \"Start=0x\" ChipLogFormatX64 \" End=0x\" ChipLogFormatX64 \" Delta=0x\" ChipLogFormatX64\n                        \" Expected=0x\" ChipLogFormatX64,\n                        ChipLogValueX64(Tstart.count()), ChipLogValueX64(Tend.count()), ChipLogValueX64(Tdelta.count()),\n                        ChipLogValueX64(Tdelay.count()));\n\n        // verify that timers don't fire early\n        EXPECT_GT(Tdelta, (Tdelay - margin));\n        // verify they're not too late\n        //        EXPECT_LT(Tdelta, (Tdelay + margin));\n        numOfTestsRan++;\n    }\n    EXPECT_GT(numOfTestsRan, 0);\n}",
    "repo": "project-chip/connectedhomeip",
    "path": "./datasets/diagrams-repos/project-chip/connectedhomeip/src/platform/tests/TestPlatformTime.cpp",
    "query": "What are the interactions between the test functions and the system clock?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'GetMonotonicMicroseconds', 'node_id': 'GetMonotonicMicroseconds', 'description': 'Test function that verifies microsecond-level system clock measurements', 'visibility': 'public', 'return_type': 'void', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'GetMonotonicMilliseconds', 'node_id': 'GetMonotonicMilliseconds', 'description': 'Test function that verifies millisecond-level system clock measurements', 'visibility': 'public', 'return_type': 'void', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'SystemClock', 'node_id': 'SystemClock', 'description': 'System clock interface providing time measurements', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SleepMicros', 'node_id': 'SleepMicros', 'description': 'Utility function to sleep for microseconds', 'visibility': 'public', 'return_type': 'void', 'params': 'uint64_t micros', 'source_class_id': None}, {'type': 'function', 'name': 'SleepMillis', 'node_id': 'SleepMillis', 'description': 'Utility function to sleep for milliseconds', 'visibility': 'public', 'return_type': 'void', 'params': 'uint64_t millis', 'source_class_id': None}], 'edges': [{'node_id_from': 'GetMonotonicMicroseconds', 'node_id_to': 'SystemClock', 'description': 'Gets microsecond timestamps'}, {'node_id_from': 'GetMonotonicMilliseconds', 'node_id_to': 'SystemClock', 'description': 'Gets millisecond timestamps'}, {'node_id_from': 'GetMonotonicMicroseconds', 'node_id_to': 'SleepMicros', 'description': 'Delays execution'}, {'node_id_from': 'GetMonotonicMilliseconds', 'node_id_to': 'SleepMillis', 'description': 'Delays execution'}], 'packages': [{'package_id': 'TestingFramework', 'children': ['GetMonotonicMicroseconds', 'GetMonotonicMilliseconds'], 'description': 'Unit tests for system clock functionality'}, {'package_id': 'TestUtils', 'children': ['SleepMicros', 'SleepMillis'], 'description': 'Testing utility functions'}]}",
    "version": "medium",
    "text_answer": "The test functions interact with SystemClock by getting timestamps before and after sleep operations to verify timing accuracy at both microsecond and millisecond levels, ensuring measurements are within defined margins.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include <inttypes.h>\n#include <stdarg.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\n#include <pw_unit_test/framework.h>\n\n#include <lib/core/StringBuilderAdapters.h>\n#include <lib/support/CodeUtils.h>\n#include <lib/support/UnitTestUtils.h>\n#include <system/SystemClock.h>\n\n#include <platform/internal/CHIPDeviceLayerInternal.h>\n\nusing namespace chip;\nusing namespace chip::Logging;\nusing namespace chip::System;\nusing namespace chip::System::Clock::Literals;\n\nconstexpr Clock::Milliseconds64 kTestTimeMarginMs = 2_ms64;\nconstexpr Clock::Microseconds64 kTestTimeMarginUs = 500_us64;\n\n// =================================\n//      Unit tests\n// =================================\n\nTEST(TestDevice, GetMonotonicMicroseconds)\n{\n    static const Clock::Microseconds64 kTestVectorSystemTimeUs[] = {\n        600_us64,\n        900_us64,\n        1500_us64,\n    };\n    int numOfTestsRan                      = 0;\n    constexpr Clock::Microseconds64 margin = kTestTimeMarginUs;\n\n    for (const Clock::Microseconds64 & Tdelay : kTestVectorSystemTimeUs)\n    {\n        const Clock::Microseconds64 Tstart = System::SystemClock().GetMonotonicMicroseconds64();\n\n        chip::test_utils::SleepMicros(Tdelay.count());\n\n        const Clock::Microseconds64 Tend   = System::SystemClock().GetMonotonicMicroseconds64();\n        const Clock::Microseconds64 Tdelta = Tend - Tstart;\n\n        ChipLogProgress(DeviceLayer,\n                        \"Start=0x\" ChipLogFormatX64 \" End=0x\" ChipLogFormatX64 \" Delta=0x\" ChipLogFormatX64\n                        \" Expected=0x\" ChipLogFormatX64,\n                        ChipLogValueX64(Tstart.count()), ChipLogValueX64(Tend.count()), ChipLogValueX64(Tdelta.count()),\n                        ChipLogValueX64(Tdelay.count()));\n\n        // verify that timers don't fire early\n        EXPECT_GT(Tdelta, (Tdelay - margin));\n        // verify they're not too late\n        //        EXPECT_LT(Tdelta, (Tdelay + margin));\n        numOfTestsRan++;\n    }\n    EXPECT_GT(numOfTestsRan, 0);\n}\n\nTEST(TestDevice, GetMonotonicMilliseconds)\n{\n    static const System::Clock::Milliseconds64 kTestVectorSystemTimeMs[] = {\n        10_ms64,\n        100_ms64,\n        250_ms64,\n    };\n    int numOfTestsRan                      = 0;\n    constexpr Clock::Milliseconds64 margin = kTestTimeMarginMs;\n\n    for (const Clock::Milliseconds64 & Tdelay : kTestVectorSystemTimeMs)\n    {\n        const Clock::Milliseconds64 Tstart = System::SystemClock().GetMonotonicMilliseconds64();\n\n        chip::test_utils::SleepMillis(Tdelay.count());\n\n        const Clock::Milliseconds64 Tend   = System::SystemClock().GetMonotonicMilliseconds64();\n        const Clock::Milliseconds64 Tdelta = Tend - Tstart;\n\n        ChipLogProgress(DeviceLayer,\n                        \"Start=0x\" ChipLogFormatX64 \" End=0x\" ChipLogFormatX64 \" Delta=0x\" ChipLogFormatX64\n                        \" Expected=0x\" ChipLogFormatX64,\n                        ChipLogValueX64(Tstart.count()), ChipLogValueX64(Tend.count()), ChipLogValueX64(Tdelta.count()),\n                        ChipLogValueX64(Tdelay.count()));\n\n        // verify that timers don't fire early\n        EXPECT_GT(Tdelta, (Tdelay - margin));\n        // verify they're not too late\n        //        EXPECT_LT(Tdelta, (Tdelay + margin));\n        numOfTestsRan++;\n    }\n    EXPECT_GT(numOfTestsRan, 0);\n}",
    "repo": "project-chip/connectedhomeip",
    "path": "./datasets/diagrams-repos/project-chip/connectedhomeip/src/platform/tests/TestPlatformTime.cpp",
    "query": "What are the interactions between the test functions and the system clock?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'GetMonotonicMicroseconds', 'node_id': 'GetMonotonicMicroseconds', 'description': 'Test function that verifies microsecond-level system clock measurements', 'visibility': 'public', 'return_type': 'void', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'GetMonotonicMilliseconds', 'node_id': 'GetMonotonicMilliseconds', 'description': 'Test function that verifies millisecond-level system clock measurements', 'visibility': 'public', 'return_type': 'void', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'SystemClock', 'node_id': 'SystemClock', 'description': 'System clock interface providing time measurements', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SleepMicros', 'node_id': 'SleepMicros', 'description': 'Utility function to sleep for microseconds', 'visibility': 'public', 'return_type': 'void', 'params': 'uint64_t micros', 'source_class_id': None}, {'type': 'function', 'name': 'SleepMillis', 'node_id': 'SleepMillis', 'description': 'Utility function to sleep for milliseconds', 'visibility': 'public', 'return_type': 'void', 'params': 'uint64_t millis', 'source_class_id': None}, {'type': 'variable', 'name': 'kTestTimeMarginMs', 'node_id': 'kTestTimeMarginMs', 'description': 'Margin of error for millisecond tests', 'visibility': 'private', 'return_type': 'Clock::Milliseconds64', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'kTestTimeMarginUs', 'node_id': 'kTestTimeMarginUs', 'description': 'Margin of error for microsecond tests', 'visibility': 'private', 'return_type': 'Clock::Microseconds64', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'ChipLogProgress', 'node_id': 'ChipLogProgress', 'description': 'Logging function for test progress', 'visibility': 'public', 'return_type': 'void', 'params': 'const char* format, ...', 'source_class_id': None}], 'edges': [{'node_id_from': 'GetMonotonicMicroseconds', 'node_id_to': 'SystemClock', 'description': 'Gets microsecond timestamps'}, {'node_id_from': 'GetMonotonicMilliseconds', 'node_id_to': 'SystemClock', 'description': 'Gets millisecond timestamps'}, {'node_id_from': 'GetMonotonicMicroseconds', 'node_id_to': 'SleepMicros', 'description': 'Delays execution'}, {'node_id_from': 'GetMonotonicMilliseconds', 'node_id_to': 'SleepMillis', 'description': 'Delays execution'}, {'node_id_from': 'GetMonotonicMicroseconds', 'node_id_to': 'kTestTimeMarginUs', 'description': 'Uses for verification'}, {'node_id_from': 'GetMonotonicMilliseconds', 'node_id_to': 'kTestTimeMarginMs', 'description': 'Uses for verification'}, {'node_id_from': 'GetMonotonicMicroseconds', 'node_id_to': 'ChipLogProgress', 'description': 'Logs test results'}, {'node_id_from': 'GetMonotonicMilliseconds', 'node_id_to': 'ChipLogProgress', 'description': 'Logs test results'}], 'packages': [{'package_id': 'TestingFramework', 'children': ['GetMonotonicMicroseconds', 'GetMonotonicMilliseconds'], 'description': 'Unit tests for system clock functionality'}, {'package_id': 'TestUtils', 'children': ['SleepMicros', 'SleepMillis'], 'description': 'Testing utility functions'}, {'package_id': 'Constants', 'children': ['kTestTimeMarginMs', 'kTestTimeMarginUs'], 'description': 'Test configuration constants'}]}",
    "version": "full",
    "text_answer": "The test functions interact with SystemClock by getting timestamps before and after sleep operations to verify timing accuracy at both microsecond and millisecond levels, ensuring measurements are within defined margins.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage com.baeldung.boot.daos.user;\n\nimport org.springframework.data.domain.Page;\nimport org.springframework.data.domain.Pageable;\nimport org.springframework.data.domain.Sort;\nimport org.springframework.data.jpa.repository.JpaRepository;\nimport org.springframework.data.jpa.repository.Modifying;\nimport org.springframework.data.jpa.repository.Query;\nimport org.springframework.data.repository.query.Param;\n\nimport com.baeldung.boot.domain.User;\n\nimport java.time.LocalDate;\nimport java.util.Collection;\nimport java.util.List;\nimport java.util.stream.Stream;\n\npublic interface UserRepository extends JpaRepository<User, Integer> , UserRepositoryCustom{\n\n    @Query(\"SELECT u FROM User u WHERE u.status = 1\")\n    Collection<User> findAllActiveUsers();\n\n    @Query(\"select u from User u where u.email like '%@gmail.com'\")\n    List<User> findUsersWithGmailAddress();\n\n    @Query(value = \"SELECT * FROM Users u WHERE u.status = 1\", nativeQuery = true)\n    Collection<User> findAllActiveUsersNative();\n\n    @Query(\"SELECT u FROM User u WHERE u.status = ?1\")\n    User findUserByStatus(Integer status);\n\n    @Query(value = \"SELECT * FROM Users u WHERE u.status = ?1\", nativeQuery = true)\n    User findUserByStatusNative(Integer status);\n\n    @Query(\"SELECT u FROM User u WHERE u.status = ?1 and u.name = ?2\")\n    User findUserByStatusAndName(Integer status, String name);\n\n    @Query(\"SELECT u FROM User u WHERE u.status = :status and u.name = :name\")\n    User findUserByStatusAndNameNamedParams(@Param(\"status\") Integer status, @Param(\"name\") String name);\n\n    @Query(value = \"SELECT * FROM Users u WHERE u.status = :status AND u.name = :name\", nativeQuery = true)\n    User findUserByStatusAndNameNamedParamsNative(@Param(\"status\") Integer status, @Param(\"name\") String name);\n\n    @Query(\"SELECT u FROM User u WHERE u.status = :status and u.name = :name\")\n    User findUserByUserStatusAndUserName(@Param(\"status\") Integer userStatus, @Param(\"name\") String userName);\n\n    @Query(\"SELECT u FROM User u WHERE u.name like ?1%\")\n    User findUserByNameLike(String name);\n\n    @Query(\"SELECT u FROM User u WHERE u.name like :name%\")\n    User findUserByNameLikeNamedParam(@Param(\"name\") String name);\n\n    @Query(value = \"SELECT * FROM users u WHERE u.name LIKE ?1%\", nativeQuery = true)\n    User findUserByNameLikeNative(String name);\n\n    @Query(value = \"SELECT u FROM User u\")\n    List<User> findAllUsers(Sort sort);\n\n    @Query(value = \"SELECT u FROM User u ORDER BY id\")\n    Page<User> findAllUsersWithPagination(Pageable pageable);\n\n    @Query(value = \"SELECT * FROM Users ORDER BY id\", countQuery = \"SELECT count(*) FROM Users\", nativeQuery = true)\n    Page<User> findAllUsersWithPaginationNative(Pageable pageable);\n\n    @Modifying\n    @Query(\"update User u set u.status = :status where u.name = :name\")\n    int updateUserSetStatusForName(@Param(\"status\") Integer status, @Param(\"name\") String name);\n\n    @Modifying\n    @Query(value = \"UPDATE Users u SET u.status = ? WHERE u.name = ?\", nativeQuery = true)\n    int updateUserSetStatusForNameNative(Integer status, String name);\n\n    @Query(value = \"INSERT INTO Users (name, age, email, status, active) VALUES (:name, :age, :email, :status, :active)\", nativeQuery = true)\n    @Modifying\n    void insertUser(@Param(\"name\") String name, @Param(\"age\") Integer age, @Param(\"email\") String email, @Param(\"status\") Integer status, @Param(\"active\") boolean active);\n\n    @Modifying\n    @Query(value = \"UPDATE Users u SET status = ? WHERE u.name = ?\", nativeQuery = true)\n    int updateUserSetStatusForNameNativePostgres(Integer status, String name);\n\n    @Query(value = \"SELECT u FROM User u WHERE u.name IN :names\")\n\t  List<User> findUserByNameList(@Param(\"names\") Collection<String> names);\n\n    void deleteAllByCreationDateAfter(LocalDate date);\n\n    @Modifying(clearAutomatically = true, flushAutomatically = true)\n    @Query(\"update User u set u.active = false where u.lastLoginDate < :date\")\n    void deactivateUsersNotLoggedInSince(@Param(\"date\") LocalDate date);\n\n    @Modifying(clearAutomatically = true, flushAutomatically = true)\n    @Query(\"delete User u where u.active = false\")\n    int deleteDeactivatedUsers();\n\n    @Query(\"delete User u where u.active = false\")\n    int deleteDeactivatedUsersWithNoModifyingAnnotation();\n\n    @Modifying(clearAutomatically = true, flushAutomatically = true)\n    @Query(value = \"alter table USERS add column deleted int not null default 0\", nativeQuery = true)\n    void addDeletedColumn();\n}",
    "repo": "eugenp/tutorials",
    "path": "./datasets/diagrams-repos/eugenp/tutorials/persistence-modules/spring-data-jpa-enterprise/src/main/java/com/baeldung/boot/daos/user/UserRepository.java",
    "query": "What is the structure of the UserRepository interface and its relationships with other components?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'UserRepository', 'node_id': 'UserRepository', 'description': 'Interface for User entity database operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'JpaRepository', 'node_id': 'JpaRepository', 'description': 'Spring Data JPA base repository interface', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'UserRepositoryCustom', 'node_id': 'UserRepositoryCustom', 'description': 'Custom interface for additional User operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'User', 'node_id': 'User', 'description': 'Domain entity representing user data', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'UserRepository', 'node_id_to': 'JpaRepository', 'description': 'extends'}, {'node_id_from': 'UserRepository', 'node_id_to': 'UserRepositoryCustom', 'description': 'extends'}, {'node_id_from': 'UserRepository', 'node_id_to': 'User', 'description': 'manages'}], 'packages': [{'package_id': 'repositories', 'children': ['UserRepository', 'UserRepositoryCustom'], 'description': 'Repository interfaces'}]}",
    "version": "minimal",
    "text_answer": "UserRepository is a Spring Data JPA interface that extends JpaRepository and UserRepositoryCustom to manage User entities. It provides various methods for querying, updating, and deleting user data, supporting both JPQL and native SQL queries, with pagination and sorting capabilities.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage com.baeldung.boot.daos.user;\n\nimport org.springframework.data.domain.Page;\nimport org.springframework.data.domain.Pageable;\nimport org.springframework.data.domain.Sort;\nimport org.springframework.data.jpa.repository.JpaRepository;\nimport org.springframework.data.jpa.repository.Modifying;\nimport org.springframework.data.jpa.repository.Query;\nimport org.springframework.data.repository.query.Param;\n\nimport com.baeldung.boot.domain.User;\n\nimport java.time.LocalDate;\nimport java.util.Collection;\nimport java.util.List;\nimport java.util.stream.Stream;\n\npublic interface UserRepository extends JpaRepository<User, Integer> , UserRepositoryCustom{\n\n    @Query(\"SELECT u FROM User u WHERE u.status = 1\")\n    Collection<User> findAllActiveUsers();\n\n    @Query(\"select u from User u where u.email like '%@gmail.com'\")\n    List<User> findUsersWithGmailAddress();\n\n    @Query(value = \"SELECT * FROM Users u WHERE u.status = 1\", nativeQuery = true)\n    Collection<User> findAllActiveUsersNative();\n\n    @Query(\"SELECT u FROM User u WHERE u.status = ?1\")\n    User findUserByStatus(Integer status);\n\n    @Query(value = \"SELECT * FROM Users u WHERE u.status = ?1\", nativeQuery = true)\n    User findUserByStatusNative(Integer status);\n\n    @Query(\"SELECT u FROM User u WHERE u.status = ?1 and u.name = ?2\")\n    User findUserByStatusAndName(Integer status, String name);\n\n    @Query(\"SELECT u FROM User u WHERE u.status = :status and u.name = :name\")\n    User findUserByStatusAndNameNamedParams(@Param(\"status\") Integer status, @Param(\"name\") String name);\n\n    @Query(value = \"SELECT * FROM Users u WHERE u.status = :status AND u.name = :name\", nativeQuery = true)\n    User findUserByStatusAndNameNamedParamsNative(@Param(\"status\") Integer status, @Param(\"name\") String name);\n\n    @Query(\"SELECT u FROM User u WHERE u.status = :status and u.name = :name\")\n    User findUserByUserStatusAndUserName(@Param(\"status\") Integer userStatus, @Param(\"name\") String userName);\n\n    @Query(\"SELECT u FROM User u WHERE u.name like ?1%\")\n    User findUserByNameLike(String name);\n\n    @Query(\"SELECT u FROM User u WHERE u.name like :name%\")\n    User findUserByNameLikeNamedParam(@Param(\"name\") String name);\n\n    @Query(value = \"SELECT * FROM users u WHERE u.name LIKE ?1%\", nativeQuery = true)\n    User findUserByNameLikeNative(String name);\n\n    @Query(value = \"SELECT u FROM User u\")\n    List<User> findAllUsers(Sort sort);\n\n    @Query(value = \"SELECT u FROM User u ORDER BY id\")\n    Page<User> findAllUsersWithPagination(Pageable pageable);\n\n    @Query(value = \"SELECT * FROM Users ORDER BY id\", countQuery = \"SELECT count(*) FROM Users\", nativeQuery = true)\n    Page<User> findAllUsersWithPaginationNative(Pageable pageable);\n\n    @Modifying\n    @Query(\"update User u set u.status = :status where u.name = :name\")\n    int updateUserSetStatusForName(@Param(\"status\") Integer status, @Param(\"name\") String name);\n\n    @Modifying\n    @Query(value = \"UPDATE Users u SET u.status = ? WHERE u.name = ?\", nativeQuery = true)\n    int updateUserSetStatusForNameNative(Integer status, String name);\n\n    @Query(value = \"INSERT INTO Users (name, age, email, status, active) VALUES (:name, :age, :email, :status, :active)\", nativeQuery = true)\n    @Modifying\n    void insertUser(@Param(\"name\") String name, @Param(\"age\") Integer age, @Param(\"email\") String email, @Param(\"status\") Integer status, @Param(\"active\") boolean active);\n\n    @Modifying\n    @Query(value = \"UPDATE Users u SET status = ? WHERE u.name = ?\", nativeQuery = true)\n    int updateUserSetStatusForNameNativePostgres(Integer status, String name);\n\n    @Query(value = \"SELECT u FROM User u WHERE u.name IN :names\")\n\t  List<User> findUserByNameList(@Param(\"names\") Collection<String> names);\n\n    void deleteAllByCreationDateAfter(LocalDate date);\n\n    @Modifying(clearAutomatically = true, flushAutomatically = true)\n    @Query(\"update User u set u.active = false where u.lastLoginDate < :date\")\n    void deactivateUsersNotLoggedInSince(@Param(\"date\") LocalDate date);\n\n    @Modifying(clearAutomatically = true, flushAutomatically = true)\n    @Query(\"delete User u where u.active = false\")\n    int deleteDeactivatedUsers();\n\n    @Query(\"delete User u where u.active = false\")\n    int deleteDeactivatedUsersWithNoModifyingAnnotation();\n\n    @Modifying(clearAutomatically = true, flushAutomatically = true)\n    @Query(value = \"alter table USERS add column deleted int not null default 0\", nativeQuery = true)\n    void addDeletedColumn();\n}",
    "repo": "eugenp/tutorials",
    "path": "./datasets/diagrams-repos/eugenp/tutorials/persistence-modules/spring-data-jpa-enterprise/src/main/java/com/baeldung/boot/daos/user/UserRepository.java",
    "query": "What is the structure of the UserRepository interface and its relationships with other components?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'UserRepository', 'node_id': 'UserRepository', 'description': 'Interface for User entity database operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'findAllActiveUsers', 'node_id': 'findAllActiveUsers', 'description': 'Retrieves all active users', 'visibility': 'public', 'return_type': 'Collection<User>', 'params': '', 'source_class_id': 'UserRepository'}, {'type': 'method', 'name': 'updateUserSetStatusForName', 'node_id': 'updateUserSetStatusForName', 'description': 'Updates user status by name', 'visibility': 'public', 'return_type': 'int', 'params': 'Integer status, String name', 'source_class_id': 'UserRepository'}, {'type': 'class', 'name': 'JpaRepository', 'node_id': 'JpaRepository', 'description': 'Spring Data JPA base repository interface', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'UserRepositoryCustom', 'node_id': 'UserRepositoryCustom', 'description': 'Custom interface for additional User operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'User', 'node_id': 'User', 'description': 'Domain entity representing user data', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'UserRepository', 'node_id_to': 'JpaRepository', 'description': 'extends'}, {'node_id_from': 'UserRepository', 'node_id_to': 'UserRepositoryCustom', 'description': 'extends'}, {'node_id_from': 'UserRepository', 'node_id_to': 'User', 'description': 'manages'}, {'node_id_from': 'findAllActiveUsers', 'node_id_to': 'User', 'description': 'returns'}, {'node_id_from': 'updateUserSetStatusForName', 'node_id_to': 'User', 'description': 'modifies'}, {'node_id_from': 'UserRepository', 'node_id_to': 'findAllActiveUsers', 'description': ''}, {'node_id_from': 'UserRepository', 'node_id_to': 'updateUserSetStatusForName', 'description': ''}], 'packages': [{'package_id': 'repositories', 'children': ['UserRepository', 'UserRepositoryCustom', 'queries'], 'description': 'Repository interfaces'}, {'package_id': 'queries', 'children': ['findAllActiveUsers', 'updateUserSetStatusForName'], 'description': 'Repository query methods'}]}",
    "version": "medium",
    "text_answer": "UserRepository is a Spring Data JPA interface that extends JpaRepository and UserRepositoryCustom to manage User entities. It provides various methods for querying, updating, and deleting user data, supporting both JPQL and native SQL queries, with pagination and sorting capabilities.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage com.baeldung.boot.daos.user;\n\nimport org.springframework.data.domain.Page;\nimport org.springframework.data.domain.Pageable;\nimport org.springframework.data.domain.Sort;\nimport org.springframework.data.jpa.repository.JpaRepository;\nimport org.springframework.data.jpa.repository.Modifying;\nimport org.springframework.data.jpa.repository.Query;\nimport org.springframework.data.repository.query.Param;\n\nimport com.baeldung.boot.domain.User;\n\nimport java.time.LocalDate;\nimport java.util.Collection;\nimport java.util.List;\nimport java.util.stream.Stream;\n\npublic interface UserRepository extends JpaRepository<User, Integer> , UserRepositoryCustom{\n\n    @Query(\"SELECT u FROM User u WHERE u.status = 1\")\n    Collection<User> findAllActiveUsers();\n\n    @Query(\"select u from User u where u.email like '%@gmail.com'\")\n    List<User> findUsersWithGmailAddress();\n\n    @Query(value = \"SELECT * FROM Users u WHERE u.status = 1\", nativeQuery = true)\n    Collection<User> findAllActiveUsersNative();\n\n    @Query(\"SELECT u FROM User u WHERE u.status = ?1\")\n    User findUserByStatus(Integer status);\n\n    @Query(value = \"SELECT * FROM Users u WHERE u.status = ?1\", nativeQuery = true)\n    User findUserByStatusNative(Integer status);\n\n    @Query(\"SELECT u FROM User u WHERE u.status = ?1 and u.name = ?2\")\n    User findUserByStatusAndName(Integer status, String name);\n\n    @Query(\"SELECT u FROM User u WHERE u.status = :status and u.name = :name\")\n    User findUserByStatusAndNameNamedParams(@Param(\"status\") Integer status, @Param(\"name\") String name);\n\n    @Query(value = \"SELECT * FROM Users u WHERE u.status = :status AND u.name = :name\", nativeQuery = true)\n    User findUserByStatusAndNameNamedParamsNative(@Param(\"status\") Integer status, @Param(\"name\") String name);\n\n    @Query(\"SELECT u FROM User u WHERE u.status = :status and u.name = :name\")\n    User findUserByUserStatusAndUserName(@Param(\"status\") Integer userStatus, @Param(\"name\") String userName);\n\n    @Query(\"SELECT u FROM User u WHERE u.name like ?1%\")\n    User findUserByNameLike(String name);\n\n    @Query(\"SELECT u FROM User u WHERE u.name like :name%\")\n    User findUserByNameLikeNamedParam(@Param(\"name\") String name);\n\n    @Query(value = \"SELECT * FROM users u WHERE u.name LIKE ?1%\", nativeQuery = true)\n    User findUserByNameLikeNative(String name);\n\n    @Query(value = \"SELECT u FROM User u\")\n    List<User> findAllUsers(Sort sort);\n\n    @Query(value = \"SELECT u FROM User u ORDER BY id\")\n    Page<User> findAllUsersWithPagination(Pageable pageable);\n\n    @Query(value = \"SELECT * FROM Users ORDER BY id\", countQuery = \"SELECT count(*) FROM Users\", nativeQuery = true)\n    Page<User> findAllUsersWithPaginationNative(Pageable pageable);\n\n    @Modifying\n    @Query(\"update User u set u.status = :status where u.name = :name\")\n    int updateUserSetStatusForName(@Param(\"status\") Integer status, @Param(\"name\") String name);\n\n    @Modifying\n    @Query(value = \"UPDATE Users u SET u.status = ? WHERE u.name = ?\", nativeQuery = true)\n    int updateUserSetStatusForNameNative(Integer status, String name);\n\n    @Query(value = \"INSERT INTO Users (name, age, email, status, active) VALUES (:name, :age, :email, :status, :active)\", nativeQuery = true)\n    @Modifying\n    void insertUser(@Param(\"name\") String name, @Param(\"age\") Integer age, @Param(\"email\") String email, @Param(\"status\") Integer status, @Param(\"active\") boolean active);\n\n    @Modifying\n    @Query(value = \"UPDATE Users u SET status = ? WHERE u.name = ?\", nativeQuery = true)\n    int updateUserSetStatusForNameNativePostgres(Integer status, String name);\n\n    @Query(value = \"SELECT u FROM User u WHERE u.name IN :names\")\n\t  List<User> findUserByNameList(@Param(\"names\") Collection<String> names);\n\n    void deleteAllByCreationDateAfter(LocalDate date);\n\n    @Modifying(clearAutomatically = true, flushAutomatically = true)\n    @Query(\"update User u set u.active = false where u.lastLoginDate < :date\")\n    void deactivateUsersNotLoggedInSince(@Param(\"date\") LocalDate date);\n\n    @Modifying(clearAutomatically = true, flushAutomatically = true)\n    @Query(\"delete User u where u.active = false\")\n    int deleteDeactivatedUsers();\n\n    @Query(\"delete User u where u.active = false\")\n    int deleteDeactivatedUsersWithNoModifyingAnnotation();\n\n    @Modifying(clearAutomatically = true, flushAutomatically = true)\n    @Query(value = \"alter table USERS add column deleted int not null default 0\", nativeQuery = true)\n    void addDeletedColumn();\n}",
    "repo": "eugenp/tutorials",
    "path": "./datasets/diagrams-repos/eugenp/tutorials/persistence-modules/spring-data-jpa-enterprise/src/main/java/com/baeldung/boot/daos/user/UserRepository.java",
    "query": "What is the structure of the UserRepository interface and its relationships with other components?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'UserRepository', 'node_id': 'UserRepository', 'description': 'Interface for User entity database operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'findAllActiveUsers', 'node_id': 'findAllActiveUsers', 'description': 'Retrieves all active users', 'visibility': 'public', 'return_type': 'Collection<User>', 'params': '', 'source_class_id': 'UserRepository'}, {'type': 'method', 'name': 'findUsersWithGmailAddress', 'node_id': 'findUsersWithGmailAddress', 'description': 'Finds users with Gmail addresses', 'visibility': 'public', 'return_type': 'List<User>', 'params': '', 'source_class_id': 'UserRepository'}, {'type': 'method', 'name': 'findAllActiveUsersNative', 'node_id': 'findAllActiveUsersNative', 'description': 'Retrieves active users using native query', 'visibility': 'public', 'return_type': 'Collection<User>', 'params': '', 'source_class_id': 'UserRepository'}, {'type': 'method', 'name': 'updateUserSetStatusForName', 'node_id': 'updateUserSetStatusForName', 'description': 'Updates user status by name', 'visibility': 'public', 'return_type': 'int', 'params': 'Integer status, String name', 'source_class_id': 'UserRepository'}, {'type': 'method', 'name': 'insertUser', 'node_id': 'insertUser', 'description': 'Inserts new user', 'visibility': 'public', 'return_type': 'void', 'params': 'String name, Integer age, String email, Integer status, boolean active', 'source_class_id': 'UserRepository'}, {'type': 'method', 'name': 'deleteDeactivatedUsers', 'node_id': 'deleteDeactivatedUsers', 'description': 'Removes deactivated users', 'visibility': 'public', 'return_type': 'int', 'params': '', 'source_class_id': 'UserRepository'}, {'type': 'class', 'name': 'JpaRepository', 'node_id': 'JpaRepository', 'description': 'Spring Data JPA base repository interface', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'UserRepositoryCustom', 'node_id': 'UserRepositoryCustom', 'description': 'Custom interface for additional User operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'User', 'node_id': 'User', 'description': 'Domain entity representing user data', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'UserRepository', 'node_id_to': 'JpaRepository', 'description': 'extends'}, {'node_id_from': 'UserRepository', 'node_id_to': 'UserRepositoryCustom', 'description': 'extends'}, {'node_id_from': 'UserRepository', 'node_id_to': 'User', 'description': 'manages'}, {'node_id_from': 'findAllActiveUsers', 'node_id_to': 'User', 'description': 'returns'}, {'node_id_from': 'findUsersWithGmailAddress', 'node_id_to': 'User', 'description': 'returns'}, {'node_id_from': 'findAllActiveUsersNative', 'node_id_to': 'User', 'description': 'returns'}, {'node_id_from': 'updateUserSetStatusForName', 'node_id_to': 'User', 'description': 'modifies'}, {'node_id_from': 'insertUser', 'node_id_to': 'User', 'description': 'creates'}, {'node_id_from': 'deleteDeactivatedUsers', 'node_id_to': 'User', 'description': 'removes'}, {'node_id_from': 'UserRepository', 'node_id_to': 'findAllActiveUsers', 'description': ''}, {'node_id_from': 'UserRepository', 'node_id_to': 'findUsersWithGmailAddress', 'description': ''}, {'node_id_from': 'UserRepository', 'node_id_to': 'findAllActiveUsersNative', 'description': ''}, {'node_id_from': 'UserRepository', 'node_id_to': 'updateUserSetStatusForName', 'description': ''}, {'node_id_from': 'UserRepository', 'node_id_to': 'insertUser', 'description': ''}, {'node_id_from': 'UserRepository', 'node_id_to': 'deleteDeactivatedUsers', 'description': ''}], 'packages': [{'package_id': 'repositories', 'children': ['UserRepository', 'UserRepositoryCustom', 'queries'], 'description': 'Repository interfaces'}, {'package_id': 'queries', 'children': ['findAllActiveUsers', 'findUsersWithGmailAddress', 'findAllActiveUsersNative', 'updateUserSetStatusForName', 'insertUser', 'deleteDeactivatedUsers'], 'description': 'Repository query methods'}]}",
    "version": "full",
    "text_answer": "UserRepository is a Spring Data JPA interface that extends JpaRepository and UserRepositoryCustom to manage User entities. It provides various methods for querying, updating, and deleting user data, supporting both JPQL and native SQL queries, with pagination and sorting capabilities.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Go",
    "code": "\npackage provider\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"os\"\n\t\"os/exec\"\n\t\"runtime\"\n\t\"strings\"\n\n\t\"github.com/blang/semver/v4\"\n\t\"github.com/containers/common/pkg/config\"\n\t\"github.com/containers/podman/v5/pkg/machine/applehv\"\n\t\"github.com/containers/podman/v5/pkg/machine/define\"\n\t\"github.com/containers/podman/v5/pkg/machine/libkrun\"\n\t\"github.com/containers/podman/v5/pkg/machine/vmconfigs\"\n\t\"github.com/sirupsen/logrus\"\n)\n\nfunc Get() (vmconfigs.VMProvider, error) {\n\tcfg, err := config.Default()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tprovider := cfg.Machine.Provider\n\tif providerOverride, found := os.LookupEnv(\"CONTAINERS_MACHINE_PROVIDER\"); found {\n\t\tprovider = providerOverride\n\t}\n\tresolvedVMType, err := define.ParseVMType(provider, define.AppleHvVirt)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tlogrus.Debugf(\"Using Podman machine with `%s` virtualization provider\", resolvedVMType.String())\n\tswitch resolvedVMType {\n\tcase define.AppleHvVirt:\n\t\treturn new(applehv.AppleHVStubber), nil\n\tcase define.LibKrun:\n\t\tif runtime.GOARCH == \"amd64\" {\n\t\t\treturn nil, errors.New(\"libkrun is not supported on Intel based machines. Please revert to the applehv provider\")\n\t\t}\n\t\treturn new(libkrun.LibKrunStubber), nil\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"unsupported virtualization provider: `%s`\", resolvedVMType.String())\n\t}\n}\n\nfunc GetAll() []vmconfigs.VMProvider {\n\tconfigs := []vmconfigs.VMProvider{new(applehv.AppleHVStubber)}\n\tif runtime.GOARCH == \"arm64\" {\n\t\tconfigs = append(configs, new(libkrun.LibKrunStubber))\n\t}\n\treturn configs\n}\n\n// SupportedProviders returns the providers that are supported on the host operating system\nfunc SupportedProviders() []define.VMType {\n\tsupported := []define.VMType{define.AppleHvVirt}\n\tif runtime.GOARCH == \"arm64\" {\n\t\treturn append(supported, define.LibKrun)\n\t}\n\treturn supported\n}\n\nfunc IsInstalled(provider define.VMType) (bool, error) {\n\tswitch provider {\n\tcase define.AppleHvVirt:\n\t\tahv, err := appleHvInstalled()\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\treturn ahv, nil\n\tcase define.LibKrun:\n\t\tlkr, err := libKrunInstalled()\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\treturn lkr, nil\n\tdefault:\n\t\treturn false, nil\n\t}\n}\n\nfunc appleHvInstalled() (bool, error) {\n\tvar outBuf bytes.Buffer\n\t// Apple's Virtualization.Framework is only supported on MacOS 11.0+,\n\t// but to use EFI MacOS 13.0+ is required\n\texpectedVer, err := semver.Make(\"13.0.0\")\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tcmd := exec.Command(\"sw_vers\", \"--productVersion\")\n\tcmd.Stdout = &outBuf\n\tif err := cmd.Run(); err != nil {\n\t\treturn false, fmt.Errorf(\"unable to check current macOS version using `sw_vers --productVersion`: %s\", err)\n\t}\n\n\t// the output will be in the format of MAJOR.MINOR.PATCH\n\toutput := strings.TrimSuffix(outBuf.String(), \"\\n\")\n\tcurrentVer, err := semver.Make(output)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\treturn currentVer.GTE(expectedVer), nil\n}\n\nfunc libKrunInstalled() (bool, error) {\n\tif runtime.GOARCH != \"arm64\" {\n\t\treturn false, nil\n\t}\n\n\t// need to verify that krunkit, virglrenderer, and libkrun-efi are installed\n\tcfg, err := config.Default()\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\t_, err = cfg.FindHelperBinary(\"krunkit\", false)\n\treturn err == nil, nil\n}\n\n// HasPermsForProvider returns whether the host operating system has the proper permissions to use the given provider\nfunc HasPermsForProvider(provider define.VMType) bool {\n\t// there are no permissions required for AppleHV or LibKrun\n\treturn provider == define.AppleHvVirt || provider == define.LibKrun\n}",
    "repo": "containers/podman",
    "path": "./datasets/diagrams-repos/containers/podman/pkg/machine/provider/platform_darwin.go",
    "query": "How do the imported modules relate to each other?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'config', 'node_id': 'config', 'description': 'Provides configuration functionality for containers', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'define', 'node_id': 'define', 'description': 'Contains core definitions and types for VM management', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'vmconfigs', 'node_id': 'vmconfigs', 'description': 'Handles VM provider configurations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'config', 'node_id_to': 'vmconfigs', 'description': 'Provides configuration for VM providers'}, {'node_id_from': 'define', 'node_id_to': 'vmconfigs', 'description': 'Defines VM types used in configurations'}], 'packages': [{'package_id': 'coreDependencies', 'children': ['config', 'define', 'vmconfigs'], 'description': 'Core packages for VM management'}]}",
    "version": "minimal",
    "text_answer": "The core relationship revolves around vmconfigs package, which defines the VM provider interface. Config and define packages provide essential configuration and type definitions. AppleHV and LibKrun implement the VM provider interface, while utility packages (semver and logrus) support version checking and logging functionality.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Go",
    "code": "\npackage provider\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"os\"\n\t\"os/exec\"\n\t\"runtime\"\n\t\"strings\"\n\n\t\"github.com/blang/semver/v4\"\n\t\"github.com/containers/common/pkg/config\"\n\t\"github.com/containers/podman/v5/pkg/machine/applehv\"\n\t\"github.com/containers/podman/v5/pkg/machine/define\"\n\t\"github.com/containers/podman/v5/pkg/machine/libkrun\"\n\t\"github.com/containers/podman/v5/pkg/machine/vmconfigs\"\n\t\"github.com/sirupsen/logrus\"\n)\n\nfunc Get() (vmconfigs.VMProvider, error) {\n\tcfg, err := config.Default()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tprovider := cfg.Machine.Provider\n\tif providerOverride, found := os.LookupEnv(\"CONTAINERS_MACHINE_PROVIDER\"); found {\n\t\tprovider = providerOverride\n\t}\n\tresolvedVMType, err := define.ParseVMType(provider, define.AppleHvVirt)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tlogrus.Debugf(\"Using Podman machine with `%s` virtualization provider\", resolvedVMType.String())\n\tswitch resolvedVMType {\n\tcase define.AppleHvVirt:\n\t\treturn new(applehv.AppleHVStubber), nil\n\tcase define.LibKrun:\n\t\tif runtime.GOARCH == \"amd64\" {\n\t\t\treturn nil, errors.New(\"libkrun is not supported on Intel based machines. Please revert to the applehv provider\")\n\t\t}\n\t\treturn new(libkrun.LibKrunStubber), nil\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"unsupported virtualization provider: `%s`\", resolvedVMType.String())\n\t}\n}\n\nfunc GetAll() []vmconfigs.VMProvider {\n\tconfigs := []vmconfigs.VMProvider{new(applehv.AppleHVStubber)}\n\tif runtime.GOARCH == \"arm64\" {\n\t\tconfigs = append(configs, new(libkrun.LibKrunStubber))\n\t}\n\treturn configs\n}\n\n// SupportedProviders returns the providers that are supported on the host operating system\nfunc SupportedProviders() []define.VMType {\n\tsupported := []define.VMType{define.AppleHvVirt}\n\tif runtime.GOARCH == \"arm64\" {\n\t\treturn append(supported, define.LibKrun)\n\t}\n\treturn supported\n}\n\nfunc IsInstalled(provider define.VMType) (bool, error) {\n\tswitch provider {\n\tcase define.AppleHvVirt:\n\t\tahv, err := appleHvInstalled()\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\treturn ahv, nil\n\tcase define.LibKrun:\n\t\tlkr, err := libKrunInstalled()\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\treturn lkr, nil\n\tdefault:\n\t\treturn false, nil\n\t}\n}\n\nfunc appleHvInstalled() (bool, error) {\n\tvar outBuf bytes.Buffer\n\t// Apple's Virtualization.Framework is only supported on MacOS 11.0+,\n\t// but to use EFI MacOS 13.0+ is required\n\texpectedVer, err := semver.Make(\"13.0.0\")\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tcmd := exec.Command(\"sw_vers\", \"--productVersion\")\n\tcmd.Stdout = &outBuf\n\tif err := cmd.Run(); err != nil {\n\t\treturn false, fmt.Errorf(\"unable to check current macOS version using `sw_vers --productVersion`: %s\", err)\n\t}\n\n\t// the output will be in the format of MAJOR.MINOR.PATCH\n\toutput := strings.TrimSuffix(outBuf.String(), \"\\n\")\n\tcurrentVer, err := semver.Make(output)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\treturn currentVer.GTE(expectedVer), nil\n}\n\nfunc libKrunInstalled() (bool, error) {\n\tif runtime.GOARCH != \"arm64\" {\n\t\treturn false, nil\n\t}\n\n\t// need to verify that krunkit, virglrenderer, and libkrun-efi are installed\n\tcfg, err := config.Default()\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\t_, err = cfg.FindHelperBinary(\"krunkit\", false)\n\treturn err == nil, nil\n}\n\n// HasPermsForProvider returns whether the host operating system has the proper permissions to use the given provider\nfunc HasPermsForProvider(provider define.VMType) bool {\n\t// there are no permissions required for AppleHV or LibKrun\n\treturn provider == define.AppleHvVirt || provider == define.LibKrun\n}",
    "repo": "containers/podman",
    "path": "./datasets/diagrams-repos/containers/podman/pkg/machine/provider/platform_darwin.go",
    "query": "How do the imported modules relate to each other?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'config', 'node_id': 'config', 'description': 'Provides configuration functionality for containers', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'define', 'node_id': 'define', 'description': 'Contains core definitions and types for VM management', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'vmconfigs', 'node_id': 'vmconfigs', 'description': 'Handles VM provider configurations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'applehv', 'node_id': 'applehv', 'description': 'Implementation for Apple Hypervisor', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'libkrun', 'node_id': 'libkrun', 'description': 'Implementation for LibKrun virtualization', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'config', 'node_id_to': 'vmconfigs', 'description': 'Provides configuration for VM providers'}, {'node_id_from': 'define', 'node_id_to': 'vmconfigs', 'description': 'Defines VM types used in configurations'}, {'node_id_from': 'applehv', 'node_id_to': 'vmconfigs', 'description': 'Implements VM provider interface'}, {'node_id_from': 'libkrun', 'node_id_to': 'vmconfigs', 'description': 'Implements VM provider interface'}], 'packages': [{'package_id': 'coreDependencies', 'children': ['config', 'define', 'vmconfigs'], 'description': 'Core packages for VM management'}, {'package_id': 'providers', 'children': ['applehv', 'libkrun'], 'description': 'VM provider implementations'}]}",
    "version": "medium",
    "text_answer": "The core relationship revolves around vmconfigs package, which defines the VM provider interface. Config and define packages provide essential configuration and type definitions. AppleHV and LibKrun implement the VM provider interface, while utility packages (semver and logrus) support version checking and logging functionality.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Go",
    "code": "\npackage provider\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"os\"\n\t\"os/exec\"\n\t\"runtime\"\n\t\"strings\"\n\n\t\"github.com/blang/semver/v4\"\n\t\"github.com/containers/common/pkg/config\"\n\t\"github.com/containers/podman/v5/pkg/machine/applehv\"\n\t\"github.com/containers/podman/v5/pkg/machine/define\"\n\t\"github.com/containers/podman/v5/pkg/machine/libkrun\"\n\t\"github.com/containers/podman/v5/pkg/machine/vmconfigs\"\n\t\"github.com/sirupsen/logrus\"\n)\n\nfunc Get() (vmconfigs.VMProvider, error) {\n\tcfg, err := config.Default()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tprovider := cfg.Machine.Provider\n\tif providerOverride, found := os.LookupEnv(\"CONTAINERS_MACHINE_PROVIDER\"); found {\n\t\tprovider = providerOverride\n\t}\n\tresolvedVMType, err := define.ParseVMType(provider, define.AppleHvVirt)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tlogrus.Debugf(\"Using Podman machine with `%s` virtualization provider\", resolvedVMType.String())\n\tswitch resolvedVMType {\n\tcase define.AppleHvVirt:\n\t\treturn new(applehv.AppleHVStubber), nil\n\tcase define.LibKrun:\n\t\tif runtime.GOARCH == \"amd64\" {\n\t\t\treturn nil, errors.New(\"libkrun is not supported on Intel based machines. Please revert to the applehv provider\")\n\t\t}\n\t\treturn new(libkrun.LibKrunStubber), nil\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"unsupported virtualization provider: `%s`\", resolvedVMType.String())\n\t}\n}\n\nfunc GetAll() []vmconfigs.VMProvider {\n\tconfigs := []vmconfigs.VMProvider{new(applehv.AppleHVStubber)}\n\tif runtime.GOARCH == \"arm64\" {\n\t\tconfigs = append(configs, new(libkrun.LibKrunStubber))\n\t}\n\treturn configs\n}\n\n// SupportedProviders returns the providers that are supported on the host operating system\nfunc SupportedProviders() []define.VMType {\n\tsupported := []define.VMType{define.AppleHvVirt}\n\tif runtime.GOARCH == \"arm64\" {\n\t\treturn append(supported, define.LibKrun)\n\t}\n\treturn supported\n}\n\nfunc IsInstalled(provider define.VMType) (bool, error) {\n\tswitch provider {\n\tcase define.AppleHvVirt:\n\t\tahv, err := appleHvInstalled()\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\treturn ahv, nil\n\tcase define.LibKrun:\n\t\tlkr, err := libKrunInstalled()\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\treturn lkr, nil\n\tdefault:\n\t\treturn false, nil\n\t}\n}\n\nfunc appleHvInstalled() (bool, error) {\n\tvar outBuf bytes.Buffer\n\t// Apple's Virtualization.Framework is only supported on MacOS 11.0+,\n\t// but to use EFI MacOS 13.0+ is required\n\texpectedVer, err := semver.Make(\"13.0.0\")\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tcmd := exec.Command(\"sw_vers\", \"--productVersion\")\n\tcmd.Stdout = &outBuf\n\tif err := cmd.Run(); err != nil {\n\t\treturn false, fmt.Errorf(\"unable to check current macOS version using `sw_vers --productVersion`: %s\", err)\n\t}\n\n\t// the output will be in the format of MAJOR.MINOR.PATCH\n\toutput := strings.TrimSuffix(outBuf.String(), \"\\n\")\n\tcurrentVer, err := semver.Make(output)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\treturn currentVer.GTE(expectedVer), nil\n}\n\nfunc libKrunInstalled() (bool, error) {\n\tif runtime.GOARCH != \"arm64\" {\n\t\treturn false, nil\n\t}\n\n\t// need to verify that krunkit, virglrenderer, and libkrun-efi are installed\n\tcfg, err := config.Default()\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\t_, err = cfg.FindHelperBinary(\"krunkit\", false)\n\treturn err == nil, nil\n}\n\n// HasPermsForProvider returns whether the host operating system has the proper permissions to use the given provider\nfunc HasPermsForProvider(provider define.VMType) bool {\n\t// there are no permissions required for AppleHV or LibKrun\n\treturn provider == define.AppleHvVirt || provider == define.LibKrun\n}",
    "repo": "containers/podman",
    "path": "./datasets/diagrams-repos/containers/podman/pkg/machine/provider/platform_darwin.go",
    "query": "How do the imported modules relate to each other?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'config', 'node_id': 'config', 'description': 'Provides configuration functionality for containers', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'define', 'node_id': 'define', 'description': 'Contains core definitions and types for VM management', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'vmconfigs', 'node_id': 'vmconfigs', 'description': 'Handles VM provider configurations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'applehv', 'node_id': 'applehv', 'description': 'Implementation for Apple Hypervisor', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'libkrun', 'node_id': 'libkrun', 'description': 'Implementation for LibKrun virtualization', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'semver', 'node_id': 'semver', 'description': 'Semantic versioning support', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'logrus', 'node_id': 'logrus', 'description': 'Logging functionality', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'config', 'node_id_to': 'vmconfigs', 'description': 'Provides configuration for VM providers'}, {'node_id_from': 'define', 'node_id_to': 'vmconfigs', 'description': 'Defines VM types used in configurations'}, {'node_id_from': 'applehv', 'node_id_to': 'vmconfigs', 'description': 'Implements VM provider interface'}, {'node_id_from': 'libkrun', 'node_id_to': 'vmconfigs', 'description': 'Implements VM provider interface'}, {'node_id_from': 'semver', 'node_id_to': 'applehv', 'description': 'Version checking for Apple Hypervisor'}, {'node_id_from': 'logrus', 'node_id_to': 'vmconfigs', 'description': 'Logging for VM operations'}], 'packages': [{'package_id': 'coreDependencies', 'children': ['config', 'define', 'vmconfigs'], 'description': 'Core packages for VM management'}, {'package_id': 'providers', 'children': ['applehv', 'libkrun'], 'description': 'VM provider implementations'}, {'package_id': 'utilities', 'children': ['semver', 'logrus'], 'description': 'Utility packages'}]}",
    "version": "full",
    "text_answer": "The core relationship revolves around vmconfigs package, which defines the VM provider interface. Config and define packages provide essential configuration and type definitions. AppleHV and LibKrun implement the VM provider interface, while utility packages (semver and logrus) support version checking and logging functionality.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Kotlin",
    "code": "\npackage com.matter.controller.commands.common\n\nimport java.util.ArrayList\nimport java.util.concurrent.atomic.AtomicBoolean\nimport java.util.concurrent.atomic.AtomicInteger\nimport java.util.concurrent.atomic.AtomicLong\n\n/**\n * @brief Matter Controller command\n * @details The base class of all the commands the Matter Controller supports, which are actions\n *   that may be performed. Commands are verb-like, such as pair a Matter device or discover Matter\n *   devices from the environment.\n */\nabstract class Command(val name: String, val helpText: String? = null) {\n  private val arguments = ArrayList<Argument>()\n\n  fun getArgumentName(index: Int): String {\n    return arguments[index].name\n  }\n\n  fun getArgumentsCount(): Int {\n    return arguments.size\n  }\n\n  fun getArgumentIsOptional(index: Int): Boolean {\n    return arguments[index].isOptional\n  }\n\n  /**\n   * @return A pointer to an Optional where the Attribute argument will be stored\n   * @brief Get attribute argument if it exists, there is at most one Attribute argument per command\n   */\n  fun getAttribute(): String? {\n    return arguments.find { arg -> arg.type === ArgumentType.ATTRIBUTE }?.value as? String\n  }\n\n  /**\n   * @return A pointer to an Optional where the argument description will be stored\n   * @brief Get argument description if it exists\n   */\n  fun getArgumentDescription(index: Int): String? {\n    return arguments[index].desc\n  }\n\n  fun addArgumentToList(arg: Argument) {\n    if (arg.isOptional || arguments.isEmpty()) {\n      // Safe to just append to the end of a list.\n      arguments.add(arg)\n      return\n    }\n\n    // mandatory arg needs to be inserted before the optional arguments.\n    var index = 0\n    while (index < arguments.size && !arguments[index].isOptional) {\n      index++\n    }\n\n    // Insert before the first optional arg.\n    arguments.add(index, arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param out A pointer to a AtomicBoolean where the argv value will be stored\n   * @param desc The description of the argument that will be displayed in the command help\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add a bool command argument\n   */\n  fun addArgument(name: String, out: AtomicBoolean, desc: String?, optional: Boolean) {\n    val arg = Argument(name, out, desc, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param min The minimum value of the argv value\n   * @param max The minimum value of the argv value\n   * @param out A pointer to a AtomicInteger where the argv value will be stored\n   * @param desc The description of the argument that will be displayed in the command help\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add a short command argument\n   */\n  fun addArgument(\n    name: String,\n    min: Short,\n    max: Short,\n    out: AtomicInteger,\n    desc: String?,\n    optional: Boolean\n  ) {\n    val arg = Argument(name, min, max, out, desc, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param min The minimum value of the argv value\n   * @param max The minimum value of the argv value\n   * @param out A pointer to a AtomicInteger where the argv value will be stored\n   * @param desc The description of the argument that will be displayed in the command help\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add an int command argument\n   */\n  fun addArgument(\n    name: String,\n    min: Int,\n    max: Int,\n    out: AtomicInteger,\n    desc: String?,\n    optional: Boolean\n  ) {\n    val arg = Argument(name, min, max, out, desc, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param min The minimum value of the argv value\n   * @param max The minimum value of the argv value\n   * @param out A pointer to a MutableInteger where the argv value will be stored\n   * @param desc The description of the argument that will be displayed in the command help\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add a long Integer command argument\n   */\n  fun addArgument(\n    name: String,\n    min: Short,\n    max: Short,\n    out: AtomicLong,\n    desc: String?,\n    optional: Boolean\n  ) {\n    val arg = Argument(name, min, max, out, desc, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param min The minimum value of the argv value\n   * @param max The minimum value of the argv value\n   * @param out A pointer to a AtomicLong where the argv value will be stored\n   * @param desc The description of the argument that will be displayed in the command help\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add a long Integer command argument\n   */\n  fun addArgument(\n    name: String,\n    min: Long,\n    max: Long,\n    out: AtomicLong,\n    desc: String?,\n    optional: Boolean\n  ) {\n    val arg = Argument(name, min, max, out, desc, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param out A pointer to a IPAddress where the argv value will be stored\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add an IP address command argument\n   */\n  fun addArgument(name: String, out: IPAddress, optional: Boolean) {\n    val arg = Argument(name, out, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param out A pointer to a StringBuffer where the argv value will be stored\n   * @param desc The description of the argument that will be displayed in the command help\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add a String command argument\n   */\n  fun addArgument(name: String, out: StringBuffer, desc: String?, optional: Boolean) {\n    val arg = Argument(name, out, desc, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param args Supplied command-line arguments as an array of String objects.\n   * @brief Initialize command arguments\n   */\n  fun setArgumentValues(args: Array<String>) {\n    val argc = args.size\n    var mandatoryArgsCount = 0\n    var currentIndex = 0\n    for (arg in arguments) {\n      if (!arg.isOptional) {\n        mandatoryArgsCount++\n      }\n    }\n    require(argc >= mandatoryArgsCount) {\n      \"setArgumentValues: Wrong arguments number: $argc instead of $mandatoryArgsCount\"\n    }\n\n    // Initialize mandatory arguments\n    for (i in 0 until mandatoryArgsCount) {\n      setArgumentValue(currentIndex++, args[i])\n    }\n\n    // Initialize optional arguments\n    // Optional arguments expect a name and a value, so it is increased by 2 on every step.\n    var i = mandatoryArgsCount\n    while (i < argc) {\n\n      // optional arguments starts with OPTIONAL_ARGUMENT_PREFIX\n      require(\n        !(args[i].length <= OPTIONAL_ARGUMENT_PREFIX_LENGTH &&\n          !args[i].startsWith(OPTIONAL_ARGUMENT_PREFIX))\n      ) {\n        \"setArgumentValues: Invalid optional argument: \" + args[i]\n      }\n      if (args[i].substring(OPTIONAL_ARGUMENT_PREFIX_LENGTH) == arguments[currentIndex].name) {\n        require(i + 1 < argc) {\n          \"setArgumentValues: Optional argument \" + args[i] + \" missing value\"\n        }\n        setArgumentValue(currentIndex++, args[i + 1])\n      }\n      i += 2\n    }\n  }\n\n  private fun setArgumentValue(argIndex: Int, argValue: String) {\n    arguments[argIndex].setValue(argValue)\n  }\n\n  @Throws(Exception::class) abstract fun run()\n\n  companion object {\n    private const val OPTIONAL_ARGUMENT_PREFIX = \"--\"\n    private const val OPTIONAL_ARGUMENT_PREFIX_LENGTH = 2\n  }\n}",
    "repo": "project-chip/connectedhomeip",
    "path": "./datasets/diagrams-repos/project-chip/connectedhomeip/examples/kotlin-matter-controller/java/src/com/matter/controller/commands/common/Command.kt",
    "query": "What is the process for adding different types of arguments in the Command class?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'Command', 'node_id': 'Command', 'description': 'Base class for Matter Controller commands that handles argument management', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'addArgumentToList', 'node_id': 'addArgumentToList', 'description': 'Core method to add arguments maintaining mandatory before optional order', 'visibility': 'private', 'return_type': 'void', 'params': 'arg: Argument', 'source_class_id': 'Command'}, {'type': 'method', 'name': 'addArgument', 'node_id': 'addArgument', 'description': 'Method overloads for adding different argument types', 'visibility': 'public', 'return_type': 'void', 'params': 'name: String, out: Type, desc: String?, optional: Boolean', 'source_class_id': 'Command'}], 'edges': [{'node_id_from': 'addArgument', 'node_id_to': 'addArgumentToList', 'description': 'calls'}, {'node_id_from': 'Command', 'node_id_to': 'addArgument', 'description': ''}, {'node_id_from': 'Command', 'node_id_to': 'addArgumentToList', 'description': ''}], 'packages': [{'package_id': 'argumentManagement', 'children': ['Command', 'addArgumentToList', 'addArgument'], 'description': 'Core argument handling functionality'}]}",
    "version": "minimal",
    "text_answer": "The Command class provides multiple overloaded addArgument methods for different data types (boolean, integer, long, IP address, string). Each method creates an Argument object and calls addArgumentToList, which maintains the order where mandatory arguments precede optional ones.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Kotlin",
    "code": "\npackage com.matter.controller.commands.common\n\nimport java.util.ArrayList\nimport java.util.concurrent.atomic.AtomicBoolean\nimport java.util.concurrent.atomic.AtomicInteger\nimport java.util.concurrent.atomic.AtomicLong\n\n/**\n * @brief Matter Controller command\n * @details The base class of all the commands the Matter Controller supports, which are actions\n *   that may be performed. Commands are verb-like, such as pair a Matter device or discover Matter\n *   devices from the environment.\n */\nabstract class Command(val name: String, val helpText: String? = null) {\n  private val arguments = ArrayList<Argument>()\n\n  fun getArgumentName(index: Int): String {\n    return arguments[index].name\n  }\n\n  fun getArgumentsCount(): Int {\n    return arguments.size\n  }\n\n  fun getArgumentIsOptional(index: Int): Boolean {\n    return arguments[index].isOptional\n  }\n\n  /**\n   * @return A pointer to an Optional where the Attribute argument will be stored\n   * @brief Get attribute argument if it exists, there is at most one Attribute argument per command\n   */\n  fun getAttribute(): String? {\n    return arguments.find { arg -> arg.type === ArgumentType.ATTRIBUTE }?.value as? String\n  }\n\n  /**\n   * @return A pointer to an Optional where the argument description will be stored\n   * @brief Get argument description if it exists\n   */\n  fun getArgumentDescription(index: Int): String? {\n    return arguments[index].desc\n  }\n\n  fun addArgumentToList(arg: Argument) {\n    if (arg.isOptional || arguments.isEmpty()) {\n      // Safe to just append to the end of a list.\n      arguments.add(arg)\n      return\n    }\n\n    // mandatory arg needs to be inserted before the optional arguments.\n    var index = 0\n    while (index < arguments.size && !arguments[index].isOptional) {\n      index++\n    }\n\n    // Insert before the first optional arg.\n    arguments.add(index, arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param out A pointer to a AtomicBoolean where the argv value will be stored\n   * @param desc The description of the argument that will be displayed in the command help\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add a bool command argument\n   */\n  fun addArgument(name: String, out: AtomicBoolean, desc: String?, optional: Boolean) {\n    val arg = Argument(name, out, desc, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param min The minimum value of the argv value\n   * @param max The minimum value of the argv value\n   * @param out A pointer to a AtomicInteger where the argv value will be stored\n   * @param desc The description of the argument that will be displayed in the command help\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add a short command argument\n   */\n  fun addArgument(\n    name: String,\n    min: Short,\n    max: Short,\n    out: AtomicInteger,\n    desc: String?,\n    optional: Boolean\n  ) {\n    val arg = Argument(name, min, max, out, desc, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param min The minimum value of the argv value\n   * @param max The minimum value of the argv value\n   * @param out A pointer to a AtomicInteger where the argv value will be stored\n   * @param desc The description of the argument that will be displayed in the command help\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add an int command argument\n   */\n  fun addArgument(\n    name: String,\n    min: Int,\n    max: Int,\n    out: AtomicInteger,\n    desc: String?,\n    optional: Boolean\n  ) {\n    val arg = Argument(name, min, max, out, desc, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param min The minimum value of the argv value\n   * @param max The minimum value of the argv value\n   * @param out A pointer to a MutableInteger where the argv value will be stored\n   * @param desc The description of the argument that will be displayed in the command help\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add a long Integer command argument\n   */\n  fun addArgument(\n    name: String,\n    min: Short,\n    max: Short,\n    out: AtomicLong,\n    desc: String?,\n    optional: Boolean\n  ) {\n    val arg = Argument(name, min, max, out, desc, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param min The minimum value of the argv value\n   * @param max The minimum value of the argv value\n   * @param out A pointer to a AtomicLong where the argv value will be stored\n   * @param desc The description of the argument that will be displayed in the command help\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add a long Integer command argument\n   */\n  fun addArgument(\n    name: String,\n    min: Long,\n    max: Long,\n    out: AtomicLong,\n    desc: String?,\n    optional: Boolean\n  ) {\n    val arg = Argument(name, min, max, out, desc, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param out A pointer to a IPAddress where the argv value will be stored\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add an IP address command argument\n   */\n  fun addArgument(name: String, out: IPAddress, optional: Boolean) {\n    val arg = Argument(name, out, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param out A pointer to a StringBuffer where the argv value will be stored\n   * @param desc The description of the argument that will be displayed in the command help\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add a String command argument\n   */\n  fun addArgument(name: String, out: StringBuffer, desc: String?, optional: Boolean) {\n    val arg = Argument(name, out, desc, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param args Supplied command-line arguments as an array of String objects.\n   * @brief Initialize command arguments\n   */\n  fun setArgumentValues(args: Array<String>) {\n    val argc = args.size\n    var mandatoryArgsCount = 0\n    var currentIndex = 0\n    for (arg in arguments) {\n      if (!arg.isOptional) {\n        mandatoryArgsCount++\n      }\n    }\n    require(argc >= mandatoryArgsCount) {\n      \"setArgumentValues: Wrong arguments number: $argc instead of $mandatoryArgsCount\"\n    }\n\n    // Initialize mandatory arguments\n    for (i in 0 until mandatoryArgsCount) {\n      setArgumentValue(currentIndex++, args[i])\n    }\n\n    // Initialize optional arguments\n    // Optional arguments expect a name and a value, so it is increased by 2 on every step.\n    var i = mandatoryArgsCount\n    while (i < argc) {\n\n      // optional arguments starts with OPTIONAL_ARGUMENT_PREFIX\n      require(\n        !(args[i].length <= OPTIONAL_ARGUMENT_PREFIX_LENGTH &&\n          !args[i].startsWith(OPTIONAL_ARGUMENT_PREFIX))\n      ) {\n        \"setArgumentValues: Invalid optional argument: \" + args[i]\n      }\n      if (args[i].substring(OPTIONAL_ARGUMENT_PREFIX_LENGTH) == arguments[currentIndex].name) {\n        require(i + 1 < argc) {\n          \"setArgumentValues: Optional argument \" + args[i] + \" missing value\"\n        }\n        setArgumentValue(currentIndex++, args[i + 1])\n      }\n      i += 2\n    }\n  }\n\n  private fun setArgumentValue(argIndex: Int, argValue: String) {\n    arguments[argIndex].setValue(argValue)\n  }\n\n  @Throws(Exception::class) abstract fun run()\n\n  companion object {\n    private const val OPTIONAL_ARGUMENT_PREFIX = \"--\"\n    private const val OPTIONAL_ARGUMENT_PREFIX_LENGTH = 2\n  }\n}",
    "repo": "project-chip/connectedhomeip",
    "path": "./datasets/diagrams-repos/project-chip/connectedhomeip/examples/kotlin-matter-controller/java/src/com/matter/controller/commands/common/Command.kt",
    "query": "What is the process for adding different types of arguments in the Command class?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'Command', 'node_id': 'Command', 'description': 'Base class for Matter Controller commands that handles argument management', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'addArgumentToList', 'node_id': 'addArgumentToList', 'description': 'Core method to add arguments maintaining mandatory before optional order', 'visibility': 'private', 'return_type': 'void', 'params': 'arg: Argument', 'source_class_id': 'Command'}, {'type': 'method', 'name': 'addArgument', 'node_id': 'addArgumentBoolean', 'description': 'Add boolean argument', 'visibility': 'public', 'return_type': 'void', 'params': 'name: String, out: AtomicBoolean, desc: String?, optional: Boolean', 'source_class_id': 'Command'}, {'type': 'method', 'name': 'addArgument', 'node_id': 'addArgumentInteger', 'description': 'Add integer argument with range', 'visibility': 'public', 'return_type': 'void', 'params': 'name: String, min: Int, max: Int, out: AtomicInteger, desc: String?, optional: Boolean', 'source_class_id': 'Command'}, {'type': 'method', 'name': 'addArgument', 'node_id': 'addArgumentString', 'description': 'Add string argument', 'visibility': 'public', 'return_type': 'void', 'params': 'name: String, out: StringBuffer, desc: String?, optional: Boolean', 'source_class_id': 'Command'}], 'edges': [{'node_id_from': 'addArgumentBoolean', 'node_id_to': 'addArgumentToList', 'description': 'calls'}, {'node_id_from': 'addArgumentInteger', 'node_id_to': 'addArgumentToList', 'description': 'calls'}, {'node_id_from': 'addArgumentString', 'node_id_to': 'addArgumentToList', 'description': 'calls'}, {'node_id_from': 'Command', 'node_id_to': 'addArgumentToList', 'description': ''}, {'node_id_from': 'Command', 'node_id_to': 'addArgumentBoolean', 'description': ''}, {'node_id_from': 'Command', 'node_id_to': 'addArgumentInteger', 'description': ''}, {'node_id_from': 'Command', 'node_id_to': 'addArgumentString', 'description': ''}], 'packages': [{'package_id': 'argumentTypes', 'children': ['addArgumentBoolean', 'addArgumentInteger', 'addArgumentString'], 'description': 'Different argument type handlers'}, {'package_id': 'core', 'children': ['Command', 'addArgumentToList', 'argumentTypes'], 'description': 'Core functionality'}]}",
    "version": "medium",
    "text_answer": "The Command class provides multiple overloaded addArgument methods for different data types (boolean, integer, long, IP address, string). Each method creates an Argument object and calls addArgumentToList, which maintains the order where mandatory arguments precede optional ones.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Kotlin",
    "code": "\npackage com.matter.controller.commands.common\n\nimport java.util.ArrayList\nimport java.util.concurrent.atomic.AtomicBoolean\nimport java.util.concurrent.atomic.AtomicInteger\nimport java.util.concurrent.atomic.AtomicLong\n\n/**\n * @brief Matter Controller command\n * @details The base class of all the commands the Matter Controller supports, which are actions\n *   that may be performed. Commands are verb-like, such as pair a Matter device or discover Matter\n *   devices from the environment.\n */\nabstract class Command(val name: String, val helpText: String? = null) {\n  private val arguments = ArrayList<Argument>()\n\n  fun getArgumentName(index: Int): String {\n    return arguments[index].name\n  }\n\n  fun getArgumentsCount(): Int {\n    return arguments.size\n  }\n\n  fun getArgumentIsOptional(index: Int): Boolean {\n    return arguments[index].isOptional\n  }\n\n  /**\n   * @return A pointer to an Optional where the Attribute argument will be stored\n   * @brief Get attribute argument if it exists, there is at most one Attribute argument per command\n   */\n  fun getAttribute(): String? {\n    return arguments.find { arg -> arg.type === ArgumentType.ATTRIBUTE }?.value as? String\n  }\n\n  /**\n   * @return A pointer to an Optional where the argument description will be stored\n   * @brief Get argument description if it exists\n   */\n  fun getArgumentDescription(index: Int): String? {\n    return arguments[index].desc\n  }\n\n  fun addArgumentToList(arg: Argument) {\n    if (arg.isOptional || arguments.isEmpty()) {\n      // Safe to just append to the end of a list.\n      arguments.add(arg)\n      return\n    }\n\n    // mandatory arg needs to be inserted before the optional arguments.\n    var index = 0\n    while (index < arguments.size && !arguments[index].isOptional) {\n      index++\n    }\n\n    // Insert before the first optional arg.\n    arguments.add(index, arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param out A pointer to a AtomicBoolean where the argv value will be stored\n   * @param desc The description of the argument that will be displayed in the command help\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add a bool command argument\n   */\n  fun addArgument(name: String, out: AtomicBoolean, desc: String?, optional: Boolean) {\n    val arg = Argument(name, out, desc, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param min The minimum value of the argv value\n   * @param max The minimum value of the argv value\n   * @param out A pointer to a AtomicInteger where the argv value will be stored\n   * @param desc The description of the argument that will be displayed in the command help\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add a short command argument\n   */\n  fun addArgument(\n    name: String,\n    min: Short,\n    max: Short,\n    out: AtomicInteger,\n    desc: String?,\n    optional: Boolean\n  ) {\n    val arg = Argument(name, min, max, out, desc, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param min The minimum value of the argv value\n   * @param max The minimum value of the argv value\n   * @param out A pointer to a AtomicInteger where the argv value will be stored\n   * @param desc The description of the argument that will be displayed in the command help\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add an int command argument\n   */\n  fun addArgument(\n    name: String,\n    min: Int,\n    max: Int,\n    out: AtomicInteger,\n    desc: String?,\n    optional: Boolean\n  ) {\n    val arg = Argument(name, min, max, out, desc, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param min The minimum value of the argv value\n   * @param max The minimum value of the argv value\n   * @param out A pointer to a MutableInteger where the argv value will be stored\n   * @param desc The description of the argument that will be displayed in the command help\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add a long Integer command argument\n   */\n  fun addArgument(\n    name: String,\n    min: Short,\n    max: Short,\n    out: AtomicLong,\n    desc: String?,\n    optional: Boolean\n  ) {\n    val arg = Argument(name, min, max, out, desc, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param min The minimum value of the argv value\n   * @param max The minimum value of the argv value\n   * @param out A pointer to a AtomicLong where the argv value will be stored\n   * @param desc The description of the argument that will be displayed in the command help\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add a long Integer command argument\n   */\n  fun addArgument(\n    name: String,\n    min: Long,\n    max: Long,\n    out: AtomicLong,\n    desc: String?,\n    optional: Boolean\n  ) {\n    val arg = Argument(name, min, max, out, desc, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param out A pointer to a IPAddress where the argv value will be stored\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add an IP address command argument\n   */\n  fun addArgument(name: String, out: IPAddress, optional: Boolean) {\n    val arg = Argument(name, out, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param name The name that will be displayed in the command help\n   * @param out A pointer to a StringBuffer where the argv value will be stored\n   * @param desc The description of the argument that will be displayed in the command help\n   * @param optional Indicate if an optional argument\n   * @return The number of arguments currently added to the command\n   * @brief Add a String command argument\n   */\n  fun addArgument(name: String, out: StringBuffer, desc: String?, optional: Boolean) {\n    val arg = Argument(name, out, desc, optional)\n    addArgumentToList(arg)\n  }\n\n  /**\n   * @param args Supplied command-line arguments as an array of String objects.\n   * @brief Initialize command arguments\n   */\n  fun setArgumentValues(args: Array<String>) {\n    val argc = args.size\n    var mandatoryArgsCount = 0\n    var currentIndex = 0\n    for (arg in arguments) {\n      if (!arg.isOptional) {\n        mandatoryArgsCount++\n      }\n    }\n    require(argc >= mandatoryArgsCount) {\n      \"setArgumentValues: Wrong arguments number: $argc instead of $mandatoryArgsCount\"\n    }\n\n    // Initialize mandatory arguments\n    for (i in 0 until mandatoryArgsCount) {\n      setArgumentValue(currentIndex++, args[i])\n    }\n\n    // Initialize optional arguments\n    // Optional arguments expect a name and a value, so it is increased by 2 on every step.\n    var i = mandatoryArgsCount\n    while (i < argc) {\n\n      // optional arguments starts with OPTIONAL_ARGUMENT_PREFIX\n      require(\n        !(args[i].length <= OPTIONAL_ARGUMENT_PREFIX_LENGTH &&\n          !args[i].startsWith(OPTIONAL_ARGUMENT_PREFIX))\n      ) {\n        \"setArgumentValues: Invalid optional argument: \" + args[i]\n      }\n      if (args[i].substring(OPTIONAL_ARGUMENT_PREFIX_LENGTH) == arguments[currentIndex].name) {\n        require(i + 1 < argc) {\n          \"setArgumentValues: Optional argument \" + args[i] + \" missing value\"\n        }\n        setArgumentValue(currentIndex++, args[i + 1])\n      }\n      i += 2\n    }\n  }\n\n  private fun setArgumentValue(argIndex: Int, argValue: String) {\n    arguments[argIndex].setValue(argValue)\n  }\n\n  @Throws(Exception::class) abstract fun run()\n\n  companion object {\n    private const val OPTIONAL_ARGUMENT_PREFIX = \"--\"\n    private const val OPTIONAL_ARGUMENT_PREFIX_LENGTH = 2\n  }\n}",
    "repo": "project-chip/connectedhomeip",
    "path": "./datasets/diagrams-repos/project-chip/connectedhomeip/examples/kotlin-matter-controller/java/src/com/matter/controller/commands/common/Command.kt",
    "query": "What is the process for adding different types of arguments in the Command class?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'Command', 'node_id': 'Command', 'description': 'Base class for Matter Controller commands that handles argument management', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'arguments', 'node_id': 'arguments', 'description': 'List storing command arguments', 'visibility': 'private', 'return_type': 'ArrayList<Argument>', 'params': None, 'source_class_id': 'Command'}, {'type': 'method', 'name': 'addArgumentToList', 'node_id': 'addArgumentToList', 'description': 'Core method to add arguments maintaining mandatory before optional order', 'visibility': 'private', 'return_type': 'void', 'params': 'arg: Argument', 'source_class_id': 'Command'}, {'type': 'method', 'name': 'addArgument', 'node_id': 'addArgumentBoolean', 'description': 'Add boolean argument', 'visibility': 'public', 'return_type': 'void', 'params': 'name: String, out: AtomicBoolean, desc: String?, optional: Boolean', 'source_class_id': 'Command'}, {'type': 'method', 'name': 'addArgument', 'node_id': 'addArgumentShort', 'description': 'Add short integer argument with range', 'visibility': 'public', 'return_type': 'void', 'params': 'name: String, min: Short, max: Short, out: AtomicInteger, desc: String?, optional: Boolean', 'source_class_id': 'Command'}, {'type': 'method', 'name': 'addArgument', 'node_id': 'addArgumentInteger', 'description': 'Add integer argument with range', 'visibility': 'public', 'return_type': 'void', 'params': 'name: String, min: Int, max: Int, out: AtomicInteger, desc: String?, optional: Boolean', 'source_class_id': 'Command'}, {'type': 'method', 'name': 'addArgument', 'node_id': 'addArgumentLongShort', 'description': 'Add long integer argument with short range', 'visibility': 'public', 'return_type': 'void', 'params': 'name: String, min: Short, max: Short, out: AtomicLong, desc: String?, optional: Boolean', 'source_class_id': 'Command'}, {'type': 'method', 'name': 'addArgument', 'node_id': 'addArgumentLong', 'description': 'Add long integer argument with long range', 'visibility': 'public', 'return_type': 'void', 'params': 'name: String, min: Long, max: Long, out: AtomicLong, desc: String?, optional: Boolean', 'source_class_id': 'Command'}, {'type': 'method', 'name': 'addArgument', 'node_id': 'addArgumentIPAddress', 'description': 'Add IP address argument', 'visibility': 'public', 'return_type': 'void', 'params': 'name: String, out: IPAddress, optional: Boolean', 'source_class_id': 'Command'}, {'type': 'method', 'name': 'addArgument', 'node_id': 'addArgumentString', 'description': 'Add string argument', 'visibility': 'public', 'return_type': 'void', 'params': 'name: String, out: StringBuffer, desc: String?, optional: Boolean', 'source_class_id': 'Command'}], 'edges': [{'node_id_from': 'Command', 'node_id_to': 'arguments', 'description': 'contains'}, {'node_id_from': 'addArgumentBoolean', 'node_id_to': 'addArgumentToList', 'description': 'calls'}, {'node_id_from': 'addArgumentShort', 'node_id_to': 'addArgumentToList', 'description': 'calls'}, {'node_id_from': 'addArgumentInteger', 'node_id_to': 'addArgumentToList', 'description': 'calls'}, {'node_id_from': 'addArgumentLongShort', 'node_id_to': 'addArgumentToList', 'description': 'calls'}, {'node_id_from': 'addArgumentLong', 'node_id_to': 'addArgumentToList', 'description': 'calls'}, {'node_id_from': 'addArgumentIPAddress', 'node_id_to': 'addArgumentToList', 'description': 'calls'}, {'node_id_from': 'addArgumentString', 'node_id_to': 'addArgumentToList', 'description': 'calls'}, {'node_id_from': 'Command', 'node_id_to': 'addArgumentToList', 'description': ''}, {'node_id_from': 'Command', 'node_id_to': 'addArgumentBoolean', 'description': ''}, {'node_id_from': 'Command', 'node_id_to': 'addArgumentInteger', 'description': ''}, {'node_id_from': 'Command', 'node_id_to': 'addArgumentString', 'description': ''}, {'node_id_from': 'Command', 'node_id_to': 'addArgumentShort', 'description': ''}, {'node_id_from': 'Command', 'node_id_to': 'addArgumentLongShort', 'description': ''}, {'node_id_from': 'Command', 'node_id_to': 'addArgumentLong', 'description': ''}, {'node_id_from': 'Command', 'node_id_to': 'addArgumentIPAddress', 'description': ''}], 'packages': [{'package_id': 'argumentTypes', 'children': ['addArgumentBoolean', 'addArgumentShort', 'addArgumentInteger', 'addArgumentLongShort', 'addArgumentLong', 'addArgumentIPAddress', 'addArgumentString'], 'description': 'Different argument type handlers'}, {'package_id': 'core', 'children': ['Command', 'arguments', 'addArgumentToList', 'argumentTypes'], 'description': 'Core functionality'}]}",
    "version": "full",
    "text_answer": "The Command class provides multiple overloaded addArgument methods for different data types (boolean, integer, long, IP address, string). Each method creates an Argument object and calls addArgumentToList, which maintains the order where mandatory arguments precede optional ones.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { Express, Application, Request, Response } from \"express\";\nimport { Server } from \"http\";\nimport { Server as HttpsServer } from \"https\";\nimport { ServeStaticOptions } from \"serve-static\";\n\ninterface RenderParams {\n  req: Request;\n  res: Response;\n}\n\ninterface RenderVueParams extends RenderParams, Record<string, any> {}\n\ninterface RenderError extends Error {\n  code: Response[\"statusCode\"];\n  url: Request[\"url\"];\n}\n\ninterface RenderErrorParams extends RenderParams {\n  err: RenderError;\n}\n\ninterface SsrMiddlewareResolve {\n  /**\n   * Whenever you define a route (with app.use(), app.get(), app.post() etc), you should use the resolve.urlPath() method so that you'll also keep into account the configured publicPath (quasar.config file > build > publicPath).\n   */\n  urlPath(url: string): string;\n  /**\n   * Resolve folder path to the root (of the project in dev and of the distributables in production). Under the hood, it does a path.join()\n   * @param paths paths to join\n   */\n  root(...paths: string[]): string;\n  /**\n   * Resolve folder path to the \"public\" folder. Under the hood, it does a path.join()\n   * @param paths paths to join\n   */\n  public(...paths: string[]): string;\n}\n\ninterface SsrMiddlewareFolders {\n  root: string;\n  public: string;\n}\n\ninterface SsrCreateParams {\n  /**\n   * Terminal PORT env var or the default configured port\n   * for the SSR webserver\n   */\n  port: number;\n  resolve: SsrMiddlewareResolve;\n  publicPath: string;\n  folders: SsrMiddlewareFolders;\n  /**\n   * Uses Vue and Vue Router to render the requested URL path.\n   * @returns the rendered HTML string to return to the client\n   */\n  render: (ssrContext: RenderVueParams) => Promise<string>;\n}\n\nexport type SsrCreateCallback = (\n  params: SsrCreateParams\n) => Express | Application | any | Promise<Express> | Promise<Application> | Promise<any>;\n\ninterface ssrServeStaticContentParams extends SsrCreateParams {\n  app: Express | Application | any;\n}\n\ninterface SsrServeStaticFnParams {\n  /**\n   * The URL path to serve the static content at (without publicPath).\n  * @default '/'\n   */\n  urlPath?: string;\n  /**\n   * The sub-path from the publicFolder or an absolute path.\n   * @default '.' (public folder itself)\n   */\n  pathToServe?: string;\n  /**\n   * Other custom options...\n   */\n  opts?: ServeStaticOptions<Response>;\n}\n\ntype SsrServeStaticFn = (params: SsrServeStaticFnParams) => void | Promise<void>;\n\nexport type SsrServeStaticContentCallback = (\n  params: ssrServeStaticContentParams\n) => SsrServeStaticFn;\n\ninterface SsrMiddlewareServe {\n  /**\n   * It's essentially a wrapper over express.static() with a few convenient tweaks:\n   * - the pathToServe is a path resolved to the \"public\" folder out of the box\n   * - the opts are the same as for express.static()\n   * - opts.maxAge is used by default, taking into account the quasar.config file > ssr > maxAge configuration; this sets how long the respective file(s) can live in browser's cache\n   */\n  static: SsrServeStaticFn;\n  /**\n   * Displays a wealth of useful debug information (including the stack trace).\n   * Warning: It's available only in development and NOT in production.\n   */\n  error(ssrContext: RenderErrorParams): void;\n}\n\ninterface SsrMiddlewareParams extends ssrServeStaticContentParams {\n  serve: SsrMiddlewareServe;\n  /**\n   * If you use HTTPS in development, this will be the\n   * actual server that listens for clients.\n   * It is a Node https.Server instance wrapper over the original \"app\".\n   */\n  devHttpsApp?: HttpsServer;\n}\n\nexport type SsrMiddlewareCallback = (\n  params: SsrMiddlewareParams\n) => void | Promise<void>;\n\ninterface SsrListenHandlerResult {\n  handler: Server | Application | void;\n}\n\nexport type SsrListenCallback = (\n  params: SsrMiddlewareParams\n) => Server | Application | SsrListenHandlerResult | any | Promise<Server> | Promise<Application> | Promise<SsrListenHandlerResult> | Promise<any>;\n\ninterface SsrCloseParams extends SsrMiddlewareParams {\n  listenResult: Server | Application | SsrListenHandlerResult | any;\n}\n\nexport type SsrCloseCallback = (\n  params: SsrCloseParams\n) => Server | Application | SsrListenHandlerResult | any | Promise<Server> | Promise<Application> | Promise<SsrListenHandlerResult> | Promise<any>;\n\ninterface SsrRenderPreloadTagCallbackOptions {\n  ssrContext: RenderVueParams;\n}\n\nexport type SsrRenderPreloadTagCallback = (\n  file: string,\n  options: SsrRenderPreloadTagCallbackOptions\n) => string;",
    "repo": "quasarframework/quasar",
    "path": "./datasets/diagrams-repos/quasarframework/quasar/app-vite/types/ssrmiddleware.d.ts",
    "query": "What is the structure of the Express server setup in the provided code?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'ExpressServerSetup', 'node_id': 'ExpressServerSetup', 'description': 'Core server setup components', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'SsrCreateParams', 'node_id': 'SsrCreateParams', 'description': 'Core parameters for creating SSR server', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'SsrMiddlewareParams', 'node_id': 'SsrMiddlewareParams', 'description': 'Parameters for middleware configuration', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SsrCreateCallback', 'node_id': 'SsrCreateCallback', 'description': 'Creates and configures Express application', 'visibility': 'public', 'return_type': 'Express | Application | Promise<Express>', 'params': 'params: SsrCreateParams', 'source_class_id': None}, {'type': 'function', 'name': 'SsrListenCallback', 'node_id': 'SsrListenCallback', 'description': 'Starts the server listening process', 'visibility': 'public', 'return_type': 'Server | Application | Promise<Server>', 'params': 'params: SsrMiddlewareParams', 'source_class_id': None}], 'edges': [{'node_id_from': 'ExpressServerSetup', 'node_id_to': 'SsrListenCallback', 'description': 'contains'}, {'node_id_from': 'ExpressServerSetup', 'node_id_to': 'SsrCreateCallback', 'description': 'contains'}, {'node_id_from': 'SsrCreateCallback', 'node_id_to': 'SsrCreateParams', 'description': 'uses'}, {'node_id_from': 'SsrListenCallback', 'node_id_to': 'SsrMiddlewareParams', 'description': 'uses'}], 'packages': [{'package_id': 'serverSetup', 'children': ['ExpressServerSetup', 'SsrCreateParams', 'SsrMiddlewareParams', 'SsrCreateCallback', 'SsrListenCallback'], 'description': 'Core server setup components'}]}",
    "version": "minimal",
    "text_answer": "The Express server setup consists of three main phases: creation (SsrCreateCallback), listening (SsrListenCallback), and shutdown (SsrCloseCallback). The server configuration is handled through various interfaces like SsrCreateParams and SsrMiddlewareParams, with support for static file serving and SSR rendering capabilities.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { Express, Application, Request, Response } from \"express\";\nimport { Server } from \"http\";\nimport { Server as HttpsServer } from \"https\";\nimport { ServeStaticOptions } from \"serve-static\";\n\ninterface RenderParams {\n  req: Request;\n  res: Response;\n}\n\ninterface RenderVueParams extends RenderParams, Record<string, any> {}\n\ninterface RenderError extends Error {\n  code: Response[\"statusCode\"];\n  url: Request[\"url\"];\n}\n\ninterface RenderErrorParams extends RenderParams {\n  err: RenderError;\n}\n\ninterface SsrMiddlewareResolve {\n  /**\n   * Whenever you define a route (with app.use(), app.get(), app.post() etc), you should use the resolve.urlPath() method so that you'll also keep into account the configured publicPath (quasar.config file > build > publicPath).\n   */\n  urlPath(url: string): string;\n  /**\n   * Resolve folder path to the root (of the project in dev and of the distributables in production). Under the hood, it does a path.join()\n   * @param paths paths to join\n   */\n  root(...paths: string[]): string;\n  /**\n   * Resolve folder path to the \"public\" folder. Under the hood, it does a path.join()\n   * @param paths paths to join\n   */\n  public(...paths: string[]): string;\n}\n\ninterface SsrMiddlewareFolders {\n  root: string;\n  public: string;\n}\n\ninterface SsrCreateParams {\n  /**\n   * Terminal PORT env var or the default configured port\n   * for the SSR webserver\n   */\n  port: number;\n  resolve: SsrMiddlewareResolve;\n  publicPath: string;\n  folders: SsrMiddlewareFolders;\n  /**\n   * Uses Vue and Vue Router to render the requested URL path.\n   * @returns the rendered HTML string to return to the client\n   */\n  render: (ssrContext: RenderVueParams) => Promise<string>;\n}\n\nexport type SsrCreateCallback = (\n  params: SsrCreateParams\n) => Express | Application | any | Promise<Express> | Promise<Application> | Promise<any>;\n\ninterface ssrServeStaticContentParams extends SsrCreateParams {\n  app: Express | Application | any;\n}\n\ninterface SsrServeStaticFnParams {\n  /**\n   * The URL path to serve the static content at (without publicPath).\n  * @default '/'\n   */\n  urlPath?: string;\n  /**\n   * The sub-path from the publicFolder or an absolute path.\n   * @default '.' (public folder itself)\n   */\n  pathToServe?: string;\n  /**\n   * Other custom options...\n   */\n  opts?: ServeStaticOptions<Response>;\n}\n\ntype SsrServeStaticFn = (params: SsrServeStaticFnParams) => void | Promise<void>;\n\nexport type SsrServeStaticContentCallback = (\n  params: ssrServeStaticContentParams\n) => SsrServeStaticFn;\n\ninterface SsrMiddlewareServe {\n  /**\n   * It's essentially a wrapper over express.static() with a few convenient tweaks:\n   * - the pathToServe is a path resolved to the \"public\" folder out of the box\n   * - the opts are the same as for express.static()\n   * - opts.maxAge is used by default, taking into account the quasar.config file > ssr > maxAge configuration; this sets how long the respective file(s) can live in browser's cache\n   */\n  static: SsrServeStaticFn;\n  /**\n   * Displays a wealth of useful debug information (including the stack trace).\n   * Warning: It's available only in development and NOT in production.\n   */\n  error(ssrContext: RenderErrorParams): void;\n}\n\ninterface SsrMiddlewareParams extends ssrServeStaticContentParams {\n  serve: SsrMiddlewareServe;\n  /**\n   * If you use HTTPS in development, this will be the\n   * actual server that listens for clients.\n   * It is a Node https.Server instance wrapper over the original \"app\".\n   */\n  devHttpsApp?: HttpsServer;\n}\n\nexport type SsrMiddlewareCallback = (\n  params: SsrMiddlewareParams\n) => void | Promise<void>;\n\ninterface SsrListenHandlerResult {\n  handler: Server | Application | void;\n}\n\nexport type SsrListenCallback = (\n  params: SsrMiddlewareParams\n) => Server | Application | SsrListenHandlerResult | any | Promise<Server> | Promise<Application> | Promise<SsrListenHandlerResult> | Promise<any>;\n\ninterface SsrCloseParams extends SsrMiddlewareParams {\n  listenResult: Server | Application | SsrListenHandlerResult | any;\n}\n\nexport type SsrCloseCallback = (\n  params: SsrCloseParams\n) => Server | Application | SsrListenHandlerResult | any | Promise<Server> | Promise<Application> | Promise<SsrListenHandlerResult> | Promise<any>;\n\ninterface SsrRenderPreloadTagCallbackOptions {\n  ssrContext: RenderVueParams;\n}\n\nexport type SsrRenderPreloadTagCallback = (\n  file: string,\n  options: SsrRenderPreloadTagCallbackOptions\n) => string;",
    "repo": "quasarframework/quasar",
    "path": "./datasets/diagrams-repos/quasarframework/quasar/app-vite/types/ssrmiddleware.d.ts",
    "query": "What is the structure of the Express server setup in the provided code?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'ExpressServerSetup', 'node_id': 'ExpressServerSetup', 'description': 'Core server setup components', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'SsrCreateParams', 'node_id': 'SsrCreateParams', 'description': 'Core parameters for creating SSR server', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'SsrMiddlewareParams', 'node_id': 'SsrMiddlewareParams', 'description': 'Parameters for middleware configuration', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'SsrMiddlewareServe', 'node_id': 'SsrMiddlewareServe', 'description': 'Static file serving and error handling utilities', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SsrCreateCallback', 'node_id': 'SsrCreateCallback', 'description': 'Creates and configures Express application', 'visibility': 'public', 'return_type': 'Express | Application | Promise<Express>', 'params': 'params: SsrCreateParams', 'source_class_id': None}, {'type': 'function', 'name': 'SsrListenCallback', 'node_id': 'SsrListenCallback', 'description': 'Starts the server listening process', 'visibility': 'public', 'return_type': 'Server | Application | Promise<Server>', 'params': 'params: SsrMiddlewareParams', 'source_class_id': None}, {'type': 'function', 'name': 'SsrCloseCallback', 'node_id': 'SsrCloseCallback', 'description': 'Handles server shutdown', 'visibility': 'public', 'return_type': 'Server | Application | Promise<Server>', 'params': 'params: SsrCloseParams', 'source_class_id': None}], 'edges': [{'node_id_from': 'ExpressServerSetup', 'node_id_to': 'SsrListenCallback', 'description': 'contains'}, {'node_id_from': 'ExpressServerSetup', 'node_id_to': 'SsrCreateCallback', 'description': 'contains'}, {'node_id_from': 'ExpressServerSetup', 'node_id_to': 'SsrCloseCallback', 'description': 'contains'}, {'node_id_from': 'SsrCreateCallback', 'node_id_to': 'SsrCreateParams', 'description': 'uses'}, {'node_id_from': 'SsrListenCallback', 'node_id_to': 'SsrMiddlewareParams', 'description': 'uses'}, {'node_id_from': 'SsrMiddlewareParams', 'node_id_to': 'SsrMiddlewareServe', 'description': 'includes'}, {'node_id_from': 'SsrCloseCallback', 'node_id_to': 'SsrMiddlewareParams', 'description': 'uses'}], 'packages': [{'package_id': 'serverCore', 'children': ['SsrCreateParams', 'SsrMiddlewareParams', 'SsrMiddlewareServe'], 'description': 'Core server interfaces'}, {'package_id': 'serverLifecycle', 'children': ['SsrCreateCallback', 'SsrListenCallback', 'SsrCloseCallback'], 'description': 'Server lifecycle management'}]}",
    "version": "medium",
    "text_answer": "The Express server setup consists of three main phases: creation (SsrCreateCallback), listening (SsrListenCallback), and shutdown (SsrCloseCallback). The server configuration is handled through various interfaces like SsrCreateParams and SsrMiddlewareParams, with support for static file serving and SSR rendering capabilities.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { Express, Application, Request, Response } from \"express\";\nimport { Server } from \"http\";\nimport { Server as HttpsServer } from \"https\";\nimport { ServeStaticOptions } from \"serve-static\";\n\ninterface RenderParams {\n  req: Request;\n  res: Response;\n}\n\ninterface RenderVueParams extends RenderParams, Record<string, any> {}\n\ninterface RenderError extends Error {\n  code: Response[\"statusCode\"];\n  url: Request[\"url\"];\n}\n\ninterface RenderErrorParams extends RenderParams {\n  err: RenderError;\n}\n\ninterface SsrMiddlewareResolve {\n  /**\n   * Whenever you define a route (with app.use(), app.get(), app.post() etc), you should use the resolve.urlPath() method so that you'll also keep into account the configured publicPath (quasar.config file > build > publicPath).\n   */\n  urlPath(url: string): string;\n  /**\n   * Resolve folder path to the root (of the project in dev and of the distributables in production). Under the hood, it does a path.join()\n   * @param paths paths to join\n   */\n  root(...paths: string[]): string;\n  /**\n   * Resolve folder path to the \"public\" folder. Under the hood, it does a path.join()\n   * @param paths paths to join\n   */\n  public(...paths: string[]): string;\n}\n\ninterface SsrMiddlewareFolders {\n  root: string;\n  public: string;\n}\n\ninterface SsrCreateParams {\n  /**\n   * Terminal PORT env var or the default configured port\n   * for the SSR webserver\n   */\n  port: number;\n  resolve: SsrMiddlewareResolve;\n  publicPath: string;\n  folders: SsrMiddlewareFolders;\n  /**\n   * Uses Vue and Vue Router to render the requested URL path.\n   * @returns the rendered HTML string to return to the client\n   */\n  render: (ssrContext: RenderVueParams) => Promise<string>;\n}\n\nexport type SsrCreateCallback = (\n  params: SsrCreateParams\n) => Express | Application | any | Promise<Express> | Promise<Application> | Promise<any>;\n\ninterface ssrServeStaticContentParams extends SsrCreateParams {\n  app: Express | Application | any;\n}\n\ninterface SsrServeStaticFnParams {\n  /**\n   * The URL path to serve the static content at (without publicPath).\n  * @default '/'\n   */\n  urlPath?: string;\n  /**\n   * The sub-path from the publicFolder or an absolute path.\n   * @default '.' (public folder itself)\n   */\n  pathToServe?: string;\n  /**\n   * Other custom options...\n   */\n  opts?: ServeStaticOptions<Response>;\n}\n\ntype SsrServeStaticFn = (params: SsrServeStaticFnParams) => void | Promise<void>;\n\nexport type SsrServeStaticContentCallback = (\n  params: ssrServeStaticContentParams\n) => SsrServeStaticFn;\n\ninterface SsrMiddlewareServe {\n  /**\n   * It's essentially a wrapper over express.static() with a few convenient tweaks:\n   * - the pathToServe is a path resolved to the \"public\" folder out of the box\n   * - the opts are the same as for express.static()\n   * - opts.maxAge is used by default, taking into account the quasar.config file > ssr > maxAge configuration; this sets how long the respective file(s) can live in browser's cache\n   */\n  static: SsrServeStaticFn;\n  /**\n   * Displays a wealth of useful debug information (including the stack trace).\n   * Warning: It's available only in development and NOT in production.\n   */\n  error(ssrContext: RenderErrorParams): void;\n}\n\ninterface SsrMiddlewareParams extends ssrServeStaticContentParams {\n  serve: SsrMiddlewareServe;\n  /**\n   * If you use HTTPS in development, this will be the\n   * actual server that listens for clients.\n   * It is a Node https.Server instance wrapper over the original \"app\".\n   */\n  devHttpsApp?: HttpsServer;\n}\n\nexport type SsrMiddlewareCallback = (\n  params: SsrMiddlewareParams\n) => void | Promise<void>;\n\ninterface SsrListenHandlerResult {\n  handler: Server | Application | void;\n}\n\nexport type SsrListenCallback = (\n  params: SsrMiddlewareParams\n) => Server | Application | SsrListenHandlerResult | any | Promise<Server> | Promise<Application> | Promise<SsrListenHandlerResult> | Promise<any>;\n\ninterface SsrCloseParams extends SsrMiddlewareParams {\n  listenResult: Server | Application | SsrListenHandlerResult | any;\n}\n\nexport type SsrCloseCallback = (\n  params: SsrCloseParams\n) => Server | Application | SsrListenHandlerResult | any | Promise<Server> | Promise<Application> | Promise<SsrListenHandlerResult> | Promise<any>;\n\ninterface SsrRenderPreloadTagCallbackOptions {\n  ssrContext: RenderVueParams;\n}\n\nexport type SsrRenderPreloadTagCallback = (\n  file: string,\n  options: SsrRenderPreloadTagCallbackOptions\n) => string;",
    "repo": "quasarframework/quasar",
    "path": "./datasets/diagrams-repos/quasarframework/quasar/app-vite/types/ssrmiddleware.d.ts",
    "query": "What is the structure of the Express server setup in the provided code?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'ExpressServerSetup', 'node_id': 'ExpressServerSetup', 'description': 'Core server setup components', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'SsrCreateParams', 'node_id': 'SsrCreateParams', 'description': 'Core parameters for creating SSR server', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'SsrMiddlewareResolve', 'node_id': 'SsrMiddlewareResolve', 'description': 'URL and path resolution utilities', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'SsrMiddlewareFolders', 'node_id': 'SsrMiddlewareFolders', 'description': 'Server folder structure configuration', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'SsrMiddlewareParams', 'node_id': 'SsrMiddlewareParams', 'description': 'Parameters for middleware configuration', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'SsrMiddlewareServe', 'node_id': 'SsrMiddlewareServe', 'description': 'Static file serving and error handling utilities', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'SsrServeStaticFnParams', 'node_id': 'SsrServeStaticFnParams', 'description': 'Static content serving parameters', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'SsrCreateCallback', 'node_id': 'SsrCreateCallback', 'description': 'Creates and configures Express application', 'visibility': 'public', 'return_type': 'Express | Application | Promise<Express>', 'params': 'params: SsrCreateParams', 'source_class_id': None}, {'type': 'function', 'name': 'SsrServeStaticContentCallback', 'node_id': 'SsrServeStaticContentCallback', 'description': 'Configures static content serving', 'visibility': 'public', 'return_type': 'SsrServeStaticFn', 'params': 'params: ssrServeStaticContentParams', 'source_class_id': None}, {'type': 'function', 'name': 'SsrListenCallback', 'node_id': 'SsrListenCallback', 'description': 'Starts the server listening process', 'visibility': 'public', 'return_type': 'Server | Application | Promise<Server>', 'params': 'params: SsrMiddlewareParams', 'source_class_id': None}, {'type': 'function', 'name': 'SsrCloseCallback', 'node_id': 'SsrCloseCallback', 'description': 'Handles server shutdown', 'visibility': 'public', 'return_type': 'Server | Application | Promise<Server>', 'params': 'params: SsrCloseParams', 'source_class_id': None}], 'edges': [{'node_id_from': 'ExpressServerSetup', 'node_id_to': 'SsrListenCallback', 'description': 'contains'}, {'node_id_from': 'ExpressServerSetup', 'node_id_to': 'SsrCreateCallback', 'description': 'contains'}, {'node_id_from': 'ExpressServerSetup', 'node_id_to': 'SsrCloseCallback', 'description': 'contains'}, {'node_id_from': 'ExpressServerSetup', 'node_id_to': 'SsrServeStaticContentCallback', 'description': 'contains'}, {'node_id_from': 'SsrCreateParams', 'node_id_to': 'SsrMiddlewareResolve', 'description': 'includes'}, {'node_id_from': 'SsrCreateParams', 'node_id_to': 'SsrMiddlewareFolders', 'description': 'includes'}, {'node_id_from': 'SsrCreateCallback', 'node_id_to': 'SsrCreateParams', 'description': 'uses'}, {'node_id_from': 'SsrMiddlewareParams', 'node_id_to': 'SsrMiddlewareServe', 'description': 'includes'}, {'node_id_from': 'SsrServeStaticContentCallback', 'node_id_to': 'SsrServeStaticFnParams', 'description': 'uses'}, {'node_id_from': 'SsrListenCallback', 'node_id_to': 'SsrMiddlewareParams', 'description': 'uses'}, {'node_id_from': 'SsrCloseCallback', 'node_id_to': 'SsrMiddlewareParams', 'description': 'uses'}], 'packages': [{'package_id': 'serverCore', 'children': ['SsrCreateParams', 'SsrMiddlewareResolve', 'SsrMiddlewareFolders', 'SsrMiddlewareParams', 'SsrMiddlewareServe'], 'description': 'Core server interfaces'}, {'package_id': 'staticServing', 'children': ['SsrServeStaticFnParams', 'SsrServeStaticContentCallback'], 'description': 'Static content serving functionality'}, {'package_id': 'serverLifecycle', 'children': ['SsrCreateCallback', 'SsrListenCallback', 'SsrCloseCallback'], 'description': 'Server lifecycle management'}]}",
    "version": "full",
    "text_answer": "The Express server setup consists of three main phases: creation (SsrCreateCallback), listening (SsrListenCallback), and shutdown (SsrCloseCallback). The server configuration is handled through various interfaces like SsrCreateParams and SsrMiddlewareParams, with support for static file serving and SSR rendering capabilities.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "PHP",
    "code": "\n<?php\n/**\n * Class for working with PO files\n *\n * @version $Id: po.php 1158 2015-11-20 04:31:23Z dd32 $\n * @package pomo\n * @subpackage po\n */\n\nrequire_once dirname(__FILE__) . '/translations.php';\n\nif ( ! defined( 'PO_MAX_LINE_LEN' ) ) {\n\tdefine('PO_MAX_LINE_LEN', 79);\n}\n\nini_set('auto_detect_line_endings', 1);\n\n/**\n * Routines for working with PO files\n */\nif ( ! class_exists( 'PO', false ) ):\nclass PO extends Gettext_Translations {\n\n\tvar $comments_before_headers = '';\n\n\t/**\n\t * Exports headers to a PO entry\n\t *\n\t * @return string msgid/msgstr PO entry for this PO file headers, doesn't contain newline at the end\n\t */\n\tfunction export_headers() {\n\t\t$header_string = '';\n\t\tforeach($this->headers as $header => $value) {\n\t\t\t$header_string.= \"$header: $value\\n\";\n\t\t}\n\t\t$poified = PO::poify($header_string);\n\t\tif ($this->comments_before_headers)\n\t\t\t$before_headers = $this->prepend_each_line(rtrim($this->comments_before_headers).\"\\n\", '# ');\n\t\telse\n\t\t\t$before_headers = '';\n\t\treturn rtrim(\"{$before_headers}msgid \\\"\\\"\\nmsgstr $poified\");\n\t}\n\n\t/**\n\t * Exports all entries to PO format\n\t *\n\t * @return string sequence of mgsgid/msgstr PO strings, doesn't containt newline at the end\n\t */\n\tfunction export_entries() {\n\t\t//TODO sorting\n\t\treturn implode(\"\\n\\n\", array_map(array('PO', 'export_entry'), $this->entries));\n\t}\n\n\t/**\n\t * Exports the whole PO file as a string\n\t *\n\t * @param bool $include_headers whether to include the headers in the export\n\t * @return string ready for inclusion in PO file string for headers and all the enrtries\n\t */\n\tfunction export($include_headers = true) {\n\t\t$res = '';\n\t\tif ($include_headers) {\n\t\t\t$res .= $this->export_headers();\n\t\t\t$res .= \"\\n\\n\";\n\t\t}\n\t\t$res .= $this->export_entries();\n\t\treturn $res;\n\t}\n\n\t/**\n\t * Same as {@link export}, but writes the result to a file\n\t *\n\t * @param string $filename where to write the PO string\n\t * @param bool $include_headers whether to include tje headers in the export\n\t * @return bool true on success, false on error\n\t */\n\tfunction export_to_file($filename, $include_headers = true) {\n\t\t$fh = fopen($filename, 'w');\n\t\tif (false === $fh) return false;\n\t\t$export = $this->export($include_headers);\n\t\t$res = fwrite($fh, $export);\n\t\tif (false === $res) return false;\n\t\treturn fclose($fh);\n\t}\n\n\t/**\n\t * Text to include as a comment before the start of the PO contents\n\t *\n\t * Doesn't need to include # in the beginning of lines, these are added automatically\n\t */\n\tfunction set_comment_before_headers( $text ) {\n\t\t$this->comments_before_headers = $text;\n\t}\n\n\t/**\n\t * Formats a string in PO-style\n\t *\n\t * @static\n\t * @param string $string the string to format\n\t * @return string the poified string\n\t */\n\tpublic static function poify($string) {\n\t\t$quote = '\"';\n\t\t$slash = '\\\\';\n\t\t$newline = \"\\n\";\n\n\t\t$replaces = array(\n\t\t\t\"$slash\" \t=> \"$slash$slash\",\n\t\t\t\"$quote\"\t=> \"$slash$quote\",\n\t\t\t\"\\t\" \t\t=> '\\t',\n\t\t);\n\n\t\t$string = str_replace(array_keys($replaces), array_values($replaces), $string);\n\n\t\t$po = $quote.implode(\"${slash}n$quote$newline$quote\", explode($newline, $string)).$quote;\n\t\t// add empty string on first line for readbility\n\t\tif (false !== strpos($string, $newline) &&\n\t\t\t\t(substr_count($string, $newline) > 1 || !($newline === substr($string, -strlen($newline))))) {\n\t\t\t$po = \"$quote$quote$newline$po\";\n\t\t}\n\t\t// remove empty strings\n\t\t$po = str_replace(\"$newline$quote$quote\", '', $po);\n\t\treturn $po;\n\t}\n\n\t/**\n\t * Gives back the original string from a PO-formatted string\n\t *\n\t * @static\n\t * @param string $string PO-formatted string\n\t * @return string enascaped string\n\t */\n\tpublic static function unpoify($string) {\n\t\t$escapes = array('t' => \"\\t\", 'n' => \"\\n\", 'r' => \"\\r\", '\\\\' => '\\\\');\n\t\t$lines = array_map('trim', explode(\"\\n\", $string));\n\t\t$lines = array_map(array('PO', 'trim_quotes'), $lines);\n\t\t$unpoified = '';\n\t\t$previous_is_backslash = false;\n\t\tforeach($lines as $line) {\n\t\t\tpreg_match_all('/./u', $line, $chars);\n\t\t\t$chars = $chars[0];\n\t\t\tforeach($chars as $char) {\n\t\t\t\tif (!$previous_is_backslash) {\n\t\t\t\t\tif ('\\\\' == $char)\n\t\t\t\t\t\t$previous_is_backslash = true;\n\t\t\t\t\telse\n\t\t\t\t\t\t$unpoified .= $char;\n\t\t\t\t} else {\n\t\t\t\t\t$previous_is_backslash = false;\n\t\t\t\t\t$unpoified .= isset($escapes[$char])? $escapes[$char] : $char;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Standardise the line endings on imported content, technically PO files shouldn't contain \\r\n\t\t$unpoified = str_replace( array( \"\\r\\n\", \"\\r\" ), \"\\n\", $unpoified );\n\n\t\treturn $unpoified;\n\t}\n\n\t/**\n\t * Inserts $with in the beginning of every new line of $string and\n\t * returns the modified string\n\t *\n\t * @static\n\t * @param string $string prepend lines in this string\n\t * @param string $with prepend lines with this string\n\t */\n\tpublic static function prepend_each_line($string, $with) {\n\t\t$php_with = var_export($with, true);\n\t\t$lines = explode(\"\\n\", $string);\n\t\t// do not prepend the string on the last empty line, artefact by explode\n\t\tif (\"\\n\" == substr($string, -1)) unset($lines[count($lines) - 1]);\n\t\t$res = implode(\"\\n\", array_map(create_function('$x', \"return $php_with.\\$x;\"), $lines));\n\t\t// give back the empty line, we ignored above\n\t\tif (\"\\n\" == substr($string, -1)) $res .= \"\\n\";\n\t\treturn $res;\n\t}\n\n\t/**\n\t * Prepare a text as a comment -- wraps the lines and prepends #\n\t * and a special character to each line\n\t *\n\t * @access private\n\t * @param string $text the comment text\n\t * @param string $char character to denote a special PO comment,\n\t * \tlike :, default is a space\n\t */\n\tpublic static function comment_block($text, $char=' ') {\n\t\t$text = wordwrap($text, PO_MAX_LINE_LEN - 3);\n\t\treturn PO::prepend_each_line($text, \"#$char \");\n\t}\n\n\t/**\n\t * Builds a string from the entry for inclusion in PO file\n\t *\n\t * @static\n\t * @param Translation_Entry &$entry the entry to convert to po string\n\t * @return false|string PO-style formatted string for the entry or\n\t * \tfalse if the entry is empty\n\t */\n\tpublic static function export_entry(&$entry) {\n\t\tif ( null === $entry->singular || '' === $entry->singular ) return false;\n\t\t$po = array();\n\t\tif (!empty($entry->translator_comments)) $po[] = PO::comment_block($entry->translator_comments);\n\t\tif (!empty($entry->extracted_comments)) $po[] = PO::comment_block($entry->extracted_comments, '.');\n\t\tif (!empty($entry->references)) $po[] = PO::comment_block(implode(' ', $entry->references), ':');\n\t\tif (!empty($entry->flags)) $po[] = PO::comment_block(implode(\", \", $entry->flags), ',');\n\t\tif ($entry->context) $po[] = 'msgctxt '.PO::poify($entry->context);\n\t\t$po[] = 'msgid '.PO::poify($entry->singular);\n\t\tif (!$entry->is_plural) {\n\t\t\t$translation = empty($entry->translations)? '' : $entry->translations[0];\n\t\t\t$translation = PO::match_begin_and_end_newlines( $translation, $entry->singular );\n\t\t\t$po[] = 'msgstr '.PO::poify($translation);\n\t\t} else {\n\t\t\t$po[] = 'msgid_plural '.PO::poify($entry->plural);\n\t\t\t$translations = empty($entry->translations)? array('', '') : $entry->translations;\n\t\t\tforeach($translations as $i => $translation) {\n\t\t\t\t$translation = PO::match_begin_and_end_newlines( $translation, $entry->plural );\n\t\t\t\t$po[] = \"msgstr[$i] \".PO::poify($translation);\n\t\t\t}\n\t\t}\n\t\treturn implode(\"\\n\", $po);\n\t}\n\n\tpublic static function match_begin_and_end_newlines( $translation, $original ) {\n\t\tif ( '' === $translation ) {\n\t\t\treturn $translation;\n\t\t}\n\n\t\t$original_begin = \"\\n\" === substr( $original, 0, 1 );\n\t\t$original_end = \"\\n\" === substr( $original, -1 );\n\t\t$translation_begin = \"\\n\" === substr( $translation, 0, 1 );\n\t\t$translation_end = \"\\n\" === substr( $translation, -1 );\n\n\t\tif ( $original_begin ) {\n\t\t\tif ( ! $translation_begin ) {\n\t\t\t\t$translation = \"\\n\" . $translation;\n\t\t\t}\n\t\t} elseif ( $translation_begin ) {\n\t\t\t$translation = ltrim( $translation, \"\\n\" );\n\t\t}\n\n\t\tif ( $original_end ) {\n\t\t\tif ( ! $translation_end ) {\n\t\t\t\t$translation .= \"\\n\";\n\t\t\t}\n\t\t} elseif ( $translation_end ) {\n\t\t\t$translation = rtrim( $translation, \"\\n\" );\n\t\t}\n\n\t\treturn $translation;\n\t}\n\n\t/**\n\t * @param string $filename\n\t * @return boolean\n\t */\n\tfunction import_from_file($filename) {\n\t\t$f = fopen($filename, 'r');\n\t\tif (!$f) return false;\n\t\t$lineno = 0;\n\t\twhile (true) {\n\t\t\t$res = $this->read_entry($f, $lineno);\n\t\t\tif (!$res) break;\n\t\t\tif ($res['entry']->singular == '') {\n\t\t\t\t$this->set_headers($this->make_headers($res['entry']->translations[0]));\n\t\t\t} else {\n\t\t\t\t$this->add_entry($res['entry']);\n\t\t\t}\n\t\t}\n\t\tPO::read_line($f, 'clear');\n\t\tif ( false === $res ) {\n\t\t\treturn false;\n\t\t}\n\t\tif ( ! $this->headers && ! $this->entries ) {\n\t\t\treturn false;\n\t\t}\n\t\treturn true;\n\t}\n\n\t/**\n\t * @param resource $f\n\t * @param int      $lineno\n\t * @return null|false|array\n\t */\n\tfunction read_entry($f, $lineno = 0) {\n\t\t$entry = new Translation_Entry();\n\t\t// where were we in the last step\n\t\t// can be: comment, msgctxt, msgid, msgid_plural, msgstr, msgstr_plural\n\t\t$context = '';\n\t\t$msgstr_index = 0;\n\t\t$is_final = create_function('$context', 'return $context == \"msgstr\" || $context == \"msgstr_plural\";');\n\t\twhile (true) {\n\t\t\t$lineno++;\n\t\t\t$line = PO::read_line($f);\n\t\t\tif (!$line)  {\n\t\t\t\tif (feof($f)) {\n\t\t\t\t\tif ($is_final($context))\n\t\t\t\t\t\tbreak;\n\t\t\t\t\telseif (!$context) // we haven't read a line and eof came\n\t\t\t\t\t\treturn null;\n\t\t\t\t\telse\n\t\t\t\t\t\treturn false;\n\t\t\t\t} else {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif ($line == \"\\n\") continue;\n\t\t\t$line = trim($line);\n\t\t\tif (preg_match('/^#/', $line, $m)) {\n\t\t\t\t// the comment is the start of a new entry\n\t\t\t\tif ($is_final($context)) {\n\t\t\t\t\tPO::read_line($f, 'put-back');\n\t\t\t\t\t$lineno--;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t// comments have to be at the beginning\n\t\t\t\tif ($context && $context != 'comment') {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t// add comment\n\t\t\t\t$this->add_comment_to_entry($entry, $line);\n\t\t\t} elseif (preg_match('/^msgctxt\\s+(\".*\")/', $line, $m)) {\n\t\t\t\tif ($is_final($context)) {\n\t\t\t\t\tPO::read_line($f, 'put-back');\n\t\t\t\t\t$lineno--;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif ($context && $context != 'comment') {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t$context = 'msgctxt';\n\t\t\t\t$entry->context .= PO::unpoify($m[1]);\n\t\t\t} elseif (preg_match('/^msgid\\s+(\".*\")/', $line, $m)) {\n\t\t\t\tif ($is_final($context)) {\n\t\t\t\t\tPO::read_line($f, 'put-back');\n\t\t\t\t\t$lineno--;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif ($context && $context != 'msgctxt' && $context != 'comment') {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t$context = 'msgid';\n\t\t\t\t$entry->singular .= PO::unpoify($m[1]);\n\t\t\t} elseif (preg_match('/^msgid_plural\\s+(\".*\")/', $line, $m)) {\n\t\t\t\tif ($context != 'msgid') {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t$context = 'msgid_plural';\n\t\t\t\t$entry->is_plural = true;\n\t\t\t\t$entry->plural .= PO::unpoify($m[1]);\n\t\t\t} elseif (preg_match('/^msgstr\\s+(\".*\")/', $line, $m)) {\n\t\t\t\tif ($context != 'msgid') {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t$context = 'msgstr';\n\t\t\t\t$entry->translations = array(PO::unpoify($m[1]));\n\t\t\t} elseif (preg_match('/^msgstr\\[(\\d+)\\]\\s+(\".*\")/', $line, $m)) {\n\t\t\t\tif ($context != 'msgid_plural' && $context != 'msgstr_plural') {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t$context = 'msgstr_plural';\n\t\t\t\t$msgstr_index = $m[1];\n\t\t\t\t$entry->translations[$m[1]] = PO::unpoify($m[2]);\n\t\t\t} elseif (preg_match('/^\".*\"$/', $line)) {\n\t\t\t\t$unpoified = PO::unpoify($line);\n\t\t\t\tswitch ($context) {\n\t\t\t\t\tcase 'msgid':\n\t\t\t\t\t\t$entry->singular .= $unpoified; break;\n\t\t\t\t\tcase 'msgctxt':\n\t\t\t\t\t\t$entry->context .= $unpoified; break;\n\t\t\t\t\tcase 'msgid_plural':\n\t\t\t\t\t\t$entry->plural .= $unpoified; break;\n\t\t\t\t\tcase 'msgstr':\n\t\t\t\t\t\t$entry->translations[0] .= $unpoified; break;\n\t\t\t\t\tcase 'msgstr_plural':\n\t\t\t\t\t\t$entry->translations[$msgstr_index] .= $unpoified; break;\n\t\t\t\t\tdefault:\n\t\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\tif (array() == array_filter($entry->translations, create_function('$t', 'return $t || \"0\" === $t;'))) {\n\t\t\t$entry->translations = array();\n\t\t}\n\t\treturn array('entry' => $entry, 'lineno' => $lineno);\n\t}\n\n\t/**\n\t * @staticvar string   $last_line\n\t * @staticvar boolean  $use_last_line\n\t *\n\t * @param     resource $f\n\t * @param     string   $action\n\t * @return boolean\n\t */\n\tfunction read_line($f, $action = 'read') {\n\t\tstatic $last_line = '';\n\t\tstatic $use_last_line = false;\n\t\tif ('clear' == $action) {\n\t\t\t$last_line = '';\n\t\t\treturn true;\n\t\t}\n\t\tif ('put-back' == $action) {\n\t\t\t$use_last_line = true;\n\t\t\treturn true;\n\t\t}\n\t\t$line = $use_last_line? $last_line : fgets($f);\n\t\t$line = ( \"\\r\\n\" == substr( $line, -2 ) ) ? rtrim( $line, \"\\r\\n\" ) . \"\\n\" : $line;\n\t\t$last_line = $line;\n\t\t$use_last_line = false;\n\t\treturn $line;\n\t}\n\n\t/**\n\t * @param Translation_Entry $entry\n\t * @param string            $po_comment_line\n\t */\n\tfunction add_comment_to_entry(&$entry, $po_comment_line) {\n\t\t$first_two = substr($po_comment_line, 0, 2);\n\t\t$comment = trim(substr($po_comment_line, 2));\n\t\tif ('#:' == $first_two) {\n\t\t\t$entry->references = array_merge($entry->references, preg_split('/\\s+/', $comment));\n\t\t} elseif ('#.' == $first_two) {\n\t\t\t$entry->extracted_comments = trim($entry->extracted_comments . \"\\n\" . $comment);\n\t\t} elseif ('#,' == $first_two) {\n\t\t\t$entry->flags = array_merge($entry->flags, preg_split('/,\\s*/', $comment));\n\t\t} else {\n\t\t\t$entry->translator_comments = trim($entry->translator_comments . \"\\n\" . $comment);\n\t\t}\n\t}\n\n\t/**\n\t * @param string $s\n\t * @return sring\n\t */\n\tpublic static function trim_quotes($s) {\n\t\tif ( substr($s, 0, 1) == '\"') $s = substr($s, 1);\n\t\tif ( substr($s, -1, 1) == '\"') $s = substr($s, 0, -1);\n\t\treturn $s;\n\t}\n}\nendif;",
    "repo": "docker/labs",
    "path": "./datasets/diagrams-repos/docker/labs/security/apparmor/wordpress/html/wp-includes/pomo/po.php",
    "query": "How is the PO class structured in the provided code?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'PO', 'node_id': 'PO', 'description': 'Main class for working with PO files, extends Gettext_Translations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'export', 'node_id': 'export', 'description': 'Exports PO file content as string', 'visibility': 'public', 'return_type': 'string', 'params': 'bool $include_headers = true', 'source_class_id': 'PO'}, {'type': 'method', 'name': 'import_from_file', 'node_id': 'import_from_file', 'description': 'Imports PO content from file', 'visibility': 'public', 'return_type': 'boolean', 'params': 'string $filename', 'source_class_id': 'PO'}], 'edges': [{'node_id_from': 'PO', 'node_id_to': 'export', 'description': 'contains'}, {'node_id_from': 'PO', 'node_id_to': 'import_from_file', 'description': 'contains'}], 'packages': [{'package_id': 'core', 'children': ['PO', 'export', 'import_from_file'], 'description': 'Core PO file functionality'}]}",
    "version": "minimal",
    "text_answer": "The PO class is a PHP class for working with PO files that extends Gettext_Translations. It primarily handles file I/O operations (import/export) and string formatting. The class maintains comments before headers and provides methods for reading and writing PO file entries, with support for both single-line and multi-line translations.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "PHP",
    "code": "\n<?php\n/**\n * Class for working with PO files\n *\n * @version $Id: po.php 1158 2015-11-20 04:31:23Z dd32 $\n * @package pomo\n * @subpackage po\n */\n\nrequire_once dirname(__FILE__) . '/translations.php';\n\nif ( ! defined( 'PO_MAX_LINE_LEN' ) ) {\n\tdefine('PO_MAX_LINE_LEN', 79);\n}\n\nini_set('auto_detect_line_endings', 1);\n\n/**\n * Routines for working with PO files\n */\nif ( ! class_exists( 'PO', false ) ):\nclass PO extends Gettext_Translations {\n\n\tvar $comments_before_headers = '';\n\n\t/**\n\t * Exports headers to a PO entry\n\t *\n\t * @return string msgid/msgstr PO entry for this PO file headers, doesn't contain newline at the end\n\t */\n\tfunction export_headers() {\n\t\t$header_string = '';\n\t\tforeach($this->headers as $header => $value) {\n\t\t\t$header_string.= \"$header: $value\\n\";\n\t\t}\n\t\t$poified = PO::poify($header_string);\n\t\tif ($this->comments_before_headers)\n\t\t\t$before_headers = $this->prepend_each_line(rtrim($this->comments_before_headers).\"\\n\", '# ');\n\t\telse\n\t\t\t$before_headers = '';\n\t\treturn rtrim(\"{$before_headers}msgid \\\"\\\"\\nmsgstr $poified\");\n\t}\n\n\t/**\n\t * Exports all entries to PO format\n\t *\n\t * @return string sequence of mgsgid/msgstr PO strings, doesn't containt newline at the end\n\t */\n\tfunction export_entries() {\n\t\t//TODO sorting\n\t\treturn implode(\"\\n\\n\", array_map(array('PO', 'export_entry'), $this->entries));\n\t}\n\n\t/**\n\t * Exports the whole PO file as a string\n\t *\n\t * @param bool $include_headers whether to include the headers in the export\n\t * @return string ready for inclusion in PO file string for headers and all the enrtries\n\t */\n\tfunction export($include_headers = true) {\n\t\t$res = '';\n\t\tif ($include_headers) {\n\t\t\t$res .= $this->export_headers();\n\t\t\t$res .= \"\\n\\n\";\n\t\t}\n\t\t$res .= $this->export_entries();\n\t\treturn $res;\n\t}\n\n\t/**\n\t * Same as {@link export}, but writes the result to a file\n\t *\n\t * @param string $filename where to write the PO string\n\t * @param bool $include_headers whether to include tje headers in the export\n\t * @return bool true on success, false on error\n\t */\n\tfunction export_to_file($filename, $include_headers = true) {\n\t\t$fh = fopen($filename, 'w');\n\t\tif (false === $fh) return false;\n\t\t$export = $this->export($include_headers);\n\t\t$res = fwrite($fh, $export);\n\t\tif (false === $res) return false;\n\t\treturn fclose($fh);\n\t}\n\n\t/**\n\t * Text to include as a comment before the start of the PO contents\n\t *\n\t * Doesn't need to include # in the beginning of lines, these are added automatically\n\t */\n\tfunction set_comment_before_headers( $text ) {\n\t\t$this->comments_before_headers = $text;\n\t}\n\n\t/**\n\t * Formats a string in PO-style\n\t *\n\t * @static\n\t * @param string $string the string to format\n\t * @return string the poified string\n\t */\n\tpublic static function poify($string) {\n\t\t$quote = '\"';\n\t\t$slash = '\\\\';\n\t\t$newline = \"\\n\";\n\n\t\t$replaces = array(\n\t\t\t\"$slash\" \t=> \"$slash$slash\",\n\t\t\t\"$quote\"\t=> \"$slash$quote\",\n\t\t\t\"\\t\" \t\t=> '\\t',\n\t\t);\n\n\t\t$string = str_replace(array_keys($replaces), array_values($replaces), $string);\n\n\t\t$po = $quote.implode(\"${slash}n$quote$newline$quote\", explode($newline, $string)).$quote;\n\t\t// add empty string on first line for readbility\n\t\tif (false !== strpos($string, $newline) &&\n\t\t\t\t(substr_count($string, $newline) > 1 || !($newline === substr($string, -strlen($newline))))) {\n\t\t\t$po = \"$quote$quote$newline$po\";\n\t\t}\n\t\t// remove empty strings\n\t\t$po = str_replace(\"$newline$quote$quote\", '', $po);\n\t\treturn $po;\n\t}\n\n\t/**\n\t * Gives back the original string from a PO-formatted string\n\t *\n\t * @static\n\t * @param string $string PO-formatted string\n\t * @return string enascaped string\n\t */\n\tpublic static function unpoify($string) {\n\t\t$escapes = array('t' => \"\\t\", 'n' => \"\\n\", 'r' => \"\\r\", '\\\\' => '\\\\');\n\t\t$lines = array_map('trim', explode(\"\\n\", $string));\n\t\t$lines = array_map(array('PO', 'trim_quotes'), $lines);\n\t\t$unpoified = '';\n\t\t$previous_is_backslash = false;\n\t\tforeach($lines as $line) {\n\t\t\tpreg_match_all('/./u', $line, $chars);\n\t\t\t$chars = $chars[0];\n\t\t\tforeach($chars as $char) {\n\t\t\t\tif (!$previous_is_backslash) {\n\t\t\t\t\tif ('\\\\' == $char)\n\t\t\t\t\t\t$previous_is_backslash = true;\n\t\t\t\t\telse\n\t\t\t\t\t\t$unpoified .= $char;\n\t\t\t\t} else {\n\t\t\t\t\t$previous_is_backslash = false;\n\t\t\t\t\t$unpoified .= isset($escapes[$char])? $escapes[$char] : $char;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Standardise the line endings on imported content, technically PO files shouldn't contain \\r\n\t\t$unpoified = str_replace( array( \"\\r\\n\", \"\\r\" ), \"\\n\", $unpoified );\n\n\t\treturn $unpoified;\n\t}\n\n\t/**\n\t * Inserts $with in the beginning of every new line of $string and\n\t * returns the modified string\n\t *\n\t * @static\n\t * @param string $string prepend lines in this string\n\t * @param string $with prepend lines with this string\n\t */\n\tpublic static function prepend_each_line($string, $with) {\n\t\t$php_with = var_export($with, true);\n\t\t$lines = explode(\"\\n\", $string);\n\t\t// do not prepend the string on the last empty line, artefact by explode\n\t\tif (\"\\n\" == substr($string, -1)) unset($lines[count($lines) - 1]);\n\t\t$res = implode(\"\\n\", array_map(create_function('$x', \"return $php_with.\\$x;\"), $lines));\n\t\t// give back the empty line, we ignored above\n\t\tif (\"\\n\" == substr($string, -1)) $res .= \"\\n\";\n\t\treturn $res;\n\t}\n\n\t/**\n\t * Prepare a text as a comment -- wraps the lines and prepends #\n\t * and a special character to each line\n\t *\n\t * @access private\n\t * @param string $text the comment text\n\t * @param string $char character to denote a special PO comment,\n\t * \tlike :, default is a space\n\t */\n\tpublic static function comment_block($text, $char=' ') {\n\t\t$text = wordwrap($text, PO_MAX_LINE_LEN - 3);\n\t\treturn PO::prepend_each_line($text, \"#$char \");\n\t}\n\n\t/**\n\t * Builds a string from the entry for inclusion in PO file\n\t *\n\t * @static\n\t * @param Translation_Entry &$entry the entry to convert to po string\n\t * @return false|string PO-style formatted string for the entry or\n\t * \tfalse if the entry is empty\n\t */\n\tpublic static function export_entry(&$entry) {\n\t\tif ( null === $entry->singular || '' === $entry->singular ) return false;\n\t\t$po = array();\n\t\tif (!empty($entry->translator_comments)) $po[] = PO::comment_block($entry->translator_comments);\n\t\tif (!empty($entry->extracted_comments)) $po[] = PO::comment_block($entry->extracted_comments, '.');\n\t\tif (!empty($entry->references)) $po[] = PO::comment_block(implode(' ', $entry->references), ':');\n\t\tif (!empty($entry->flags)) $po[] = PO::comment_block(implode(\", \", $entry->flags), ',');\n\t\tif ($entry->context) $po[] = 'msgctxt '.PO::poify($entry->context);\n\t\t$po[] = 'msgid '.PO::poify($entry->singular);\n\t\tif (!$entry->is_plural) {\n\t\t\t$translation = empty($entry->translations)? '' : $entry->translations[0];\n\t\t\t$translation = PO::match_begin_and_end_newlines( $translation, $entry->singular );\n\t\t\t$po[] = 'msgstr '.PO::poify($translation);\n\t\t} else {\n\t\t\t$po[] = 'msgid_plural '.PO::poify($entry->plural);\n\t\t\t$translations = empty($entry->translations)? array('', '') : $entry->translations;\n\t\t\tforeach($translations as $i => $translation) {\n\t\t\t\t$translation = PO::match_begin_and_end_newlines( $translation, $entry->plural );\n\t\t\t\t$po[] = \"msgstr[$i] \".PO::poify($translation);\n\t\t\t}\n\t\t}\n\t\treturn implode(\"\\n\", $po);\n\t}\n\n\tpublic static function match_begin_and_end_newlines( $translation, $original ) {\n\t\tif ( '' === $translation ) {\n\t\t\treturn $translation;\n\t\t}\n\n\t\t$original_begin = \"\\n\" === substr( $original, 0, 1 );\n\t\t$original_end = \"\\n\" === substr( $original, -1 );\n\t\t$translation_begin = \"\\n\" === substr( $translation, 0, 1 );\n\t\t$translation_end = \"\\n\" === substr( $translation, -1 );\n\n\t\tif ( $original_begin ) {\n\t\t\tif ( ! $translation_begin ) {\n\t\t\t\t$translation = \"\\n\" . $translation;\n\t\t\t}\n\t\t} elseif ( $translation_begin ) {\n\t\t\t$translation = ltrim( $translation, \"\\n\" );\n\t\t}\n\n\t\tif ( $original_end ) {\n\t\t\tif ( ! $translation_end ) {\n\t\t\t\t$translation .= \"\\n\";\n\t\t\t}\n\t\t} elseif ( $translation_end ) {\n\t\t\t$translation = rtrim( $translation, \"\\n\" );\n\t\t}\n\n\t\treturn $translation;\n\t}\n\n\t/**\n\t * @param string $filename\n\t * @return boolean\n\t */\n\tfunction import_from_file($filename) {\n\t\t$f = fopen($filename, 'r');\n\t\tif (!$f) return false;\n\t\t$lineno = 0;\n\t\twhile (true) {\n\t\t\t$res = $this->read_entry($f, $lineno);\n\t\t\tif (!$res) break;\n\t\t\tif ($res['entry']->singular == '') {\n\t\t\t\t$this->set_headers($this->make_headers($res['entry']->translations[0]));\n\t\t\t} else {\n\t\t\t\t$this->add_entry($res['entry']);\n\t\t\t}\n\t\t}\n\t\tPO::read_line($f, 'clear');\n\t\tif ( false === $res ) {\n\t\t\treturn false;\n\t\t}\n\t\tif ( ! $this->headers && ! $this->entries ) {\n\t\t\treturn false;\n\t\t}\n\t\treturn true;\n\t}\n\n\t/**\n\t * @param resource $f\n\t * @param int      $lineno\n\t * @return null|false|array\n\t */\n\tfunction read_entry($f, $lineno = 0) {\n\t\t$entry = new Translation_Entry();\n\t\t// where were we in the last step\n\t\t// can be: comment, msgctxt, msgid, msgid_plural, msgstr, msgstr_plural\n\t\t$context = '';\n\t\t$msgstr_index = 0;\n\t\t$is_final = create_function('$context', 'return $context == \"msgstr\" || $context == \"msgstr_plural\";');\n\t\twhile (true) {\n\t\t\t$lineno++;\n\t\t\t$line = PO::read_line($f);\n\t\t\tif (!$line)  {\n\t\t\t\tif (feof($f)) {\n\t\t\t\t\tif ($is_final($context))\n\t\t\t\t\t\tbreak;\n\t\t\t\t\telseif (!$context) // we haven't read a line and eof came\n\t\t\t\t\t\treturn null;\n\t\t\t\t\telse\n\t\t\t\t\t\treturn false;\n\t\t\t\t} else {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif ($line == \"\\n\") continue;\n\t\t\t$line = trim($line);\n\t\t\tif (preg_match('/^#/', $line, $m)) {\n\t\t\t\t// the comment is the start of a new entry\n\t\t\t\tif ($is_final($context)) {\n\t\t\t\t\tPO::read_line($f, 'put-back');\n\t\t\t\t\t$lineno--;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t// comments have to be at the beginning\n\t\t\t\tif ($context && $context != 'comment') {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t// add comment\n\t\t\t\t$this->add_comment_to_entry($entry, $line);\n\t\t\t} elseif (preg_match('/^msgctxt\\s+(\".*\")/', $line, $m)) {\n\t\t\t\tif ($is_final($context)) {\n\t\t\t\t\tPO::read_line($f, 'put-back');\n\t\t\t\t\t$lineno--;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif ($context && $context != 'comment') {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t$context = 'msgctxt';\n\t\t\t\t$entry->context .= PO::unpoify($m[1]);\n\t\t\t} elseif (preg_match('/^msgid\\s+(\".*\")/', $line, $m)) {\n\t\t\t\tif ($is_final($context)) {\n\t\t\t\t\tPO::read_line($f, 'put-back');\n\t\t\t\t\t$lineno--;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif ($context && $context != 'msgctxt' && $context != 'comment') {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t$context = 'msgid';\n\t\t\t\t$entry->singular .= PO::unpoify($m[1]);\n\t\t\t} elseif (preg_match('/^msgid_plural\\s+(\".*\")/', $line, $m)) {\n\t\t\t\tif ($context != 'msgid') {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t$context = 'msgid_plural';\n\t\t\t\t$entry->is_plural = true;\n\t\t\t\t$entry->plural .= PO::unpoify($m[1]);\n\t\t\t} elseif (preg_match('/^msgstr\\s+(\".*\")/', $line, $m)) {\n\t\t\t\tif ($context != 'msgid') {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t$context = 'msgstr';\n\t\t\t\t$entry->translations = array(PO::unpoify($m[1]));\n\t\t\t} elseif (preg_match('/^msgstr\\[(\\d+)\\]\\s+(\".*\")/', $line, $m)) {\n\t\t\t\tif ($context != 'msgid_plural' && $context != 'msgstr_plural') {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t$context = 'msgstr_plural';\n\t\t\t\t$msgstr_index = $m[1];\n\t\t\t\t$entry->translations[$m[1]] = PO::unpoify($m[2]);\n\t\t\t} elseif (preg_match('/^\".*\"$/', $line)) {\n\t\t\t\t$unpoified = PO::unpoify($line);\n\t\t\t\tswitch ($context) {\n\t\t\t\t\tcase 'msgid':\n\t\t\t\t\t\t$entry->singular .= $unpoified; break;\n\t\t\t\t\tcase 'msgctxt':\n\t\t\t\t\t\t$entry->context .= $unpoified; break;\n\t\t\t\t\tcase 'msgid_plural':\n\t\t\t\t\t\t$entry->plural .= $unpoified; break;\n\t\t\t\t\tcase 'msgstr':\n\t\t\t\t\t\t$entry->translations[0] .= $unpoified; break;\n\t\t\t\t\tcase 'msgstr_plural':\n\t\t\t\t\t\t$entry->translations[$msgstr_index] .= $unpoified; break;\n\t\t\t\t\tdefault:\n\t\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\tif (array() == array_filter($entry->translations, create_function('$t', 'return $t || \"0\" === $t;'))) {\n\t\t\t$entry->translations = array();\n\t\t}\n\t\treturn array('entry' => $entry, 'lineno' => $lineno);\n\t}\n\n\t/**\n\t * @staticvar string   $last_line\n\t * @staticvar boolean  $use_last_line\n\t *\n\t * @param     resource $f\n\t * @param     string   $action\n\t * @return boolean\n\t */\n\tfunction read_line($f, $action = 'read') {\n\t\tstatic $last_line = '';\n\t\tstatic $use_last_line = false;\n\t\tif ('clear' == $action) {\n\t\t\t$last_line = '';\n\t\t\treturn true;\n\t\t}\n\t\tif ('put-back' == $action) {\n\t\t\t$use_last_line = true;\n\t\t\treturn true;\n\t\t}\n\t\t$line = $use_last_line? $last_line : fgets($f);\n\t\t$line = ( \"\\r\\n\" == substr( $line, -2 ) ) ? rtrim( $line, \"\\r\\n\" ) . \"\\n\" : $line;\n\t\t$last_line = $line;\n\t\t$use_last_line = false;\n\t\treturn $line;\n\t}\n\n\t/**\n\t * @param Translation_Entry $entry\n\t * @param string            $po_comment_line\n\t */\n\tfunction add_comment_to_entry(&$entry, $po_comment_line) {\n\t\t$first_two = substr($po_comment_line, 0, 2);\n\t\t$comment = trim(substr($po_comment_line, 2));\n\t\tif ('#:' == $first_two) {\n\t\t\t$entry->references = array_merge($entry->references, preg_split('/\\s+/', $comment));\n\t\t} elseif ('#.' == $first_two) {\n\t\t\t$entry->extracted_comments = trim($entry->extracted_comments . \"\\n\" . $comment);\n\t\t} elseif ('#,' == $first_two) {\n\t\t\t$entry->flags = array_merge($entry->flags, preg_split('/,\\s*/', $comment));\n\t\t} else {\n\t\t\t$entry->translator_comments = trim($entry->translator_comments . \"\\n\" . $comment);\n\t\t}\n\t}\n\n\t/**\n\t * @param string $s\n\t * @return sring\n\t */\n\tpublic static function trim_quotes($s) {\n\t\tif ( substr($s, 0, 1) == '\"') $s = substr($s, 1);\n\t\tif ( substr($s, -1, 1) == '\"') $s = substr($s, 0, -1);\n\t\treturn $s;\n\t}\n}\nendif;",
    "repo": "docker/labs",
    "path": "./datasets/diagrams-repos/docker/labs/security/apparmor/wordpress/html/wp-includes/pomo/po.php",
    "query": "How is the PO class structured in the provided code?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'PO', 'node_id': 'PO', 'description': 'Main class for working with PO files, extends Gettext_Translations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'comments_before_headers', 'node_id': 'comments_before_headers', 'description': 'Comments to be included before headers', 'visibility': 'public', 'return_type': 'string', 'params': None, 'source_class_id': 'PO'}, {'type': 'method', 'name': 'export', 'node_id': 'export', 'description': 'Exports PO file content as string', 'visibility': 'public', 'return_type': 'string', 'params': 'bool $include_headers = true', 'source_class_id': 'PO'}, {'type': 'method', 'name': 'export_headers', 'node_id': 'export_headers', 'description': 'Exports headers to PO entry', 'visibility': 'public', 'return_type': 'string', 'params': '', 'source_class_id': 'PO'}, {'type': 'method', 'name': 'export_entries', 'node_id': 'export_entries', 'description': 'Exports all entries to PO format', 'visibility': 'public', 'return_type': 'string', 'params': '', 'source_class_id': 'PO'}, {'type': 'method', 'name': 'import_from_file', 'node_id': 'import_from_file', 'description': 'Imports PO content from file', 'visibility': 'public', 'return_type': 'boolean', 'params': 'string $filename', 'source_class_id': 'PO'}, {'type': 'method', 'name': 'read_entry', 'node_id': 'read_entry', 'description': 'Reads single entry from file', 'visibility': 'public', 'return_type': 'array|None|false', 'params': 'resource $f, int $lineno = 0', 'source_class_id': 'PO'}], 'edges': [{'node_id_from': 'PO', 'node_id_to': 'comments_before_headers', 'description': 'has'}, {'node_id_from': 'PO', 'node_id_to': 'export', 'description': 'contains'}, {'node_id_from': 'PO', 'node_id_to': 'export_headers', 'description': 'contains'}, {'node_id_from': 'PO', 'node_id_to': 'export_entries', 'description': 'contains'}, {'node_id_from': 'PO', 'node_id_to': 'read_entry', 'description': 'contains'}, {'node_id_from': 'export', 'node_id_to': 'export_headers', 'description': 'uses'}, {'node_id_from': 'export', 'node_id_to': 'export_entries', 'description': 'uses'}, {'node_id_from': 'PO', 'node_id_to': 'import_from_file', 'description': 'contains'}, {'node_id_from': 'import_from_file', 'node_id_to': 'read_entry', 'description': 'uses'}], 'packages': [{'package_id': 'io', 'children': ['import_from_file', 'export', 'export_headers', 'export_entries', 'read_entry'], 'description': 'Input/Output operations'}, {'package_id': 'data', 'children': ['PO', 'comments_before_headers', 'io'], 'description': 'Data structures'}]}",
    "version": "medium",
    "text_answer": "The PO class is a PHP class for working with PO files that extends Gettext_Translations. It primarily handles file I/O operations (import/export) and string formatting. The class maintains comments before headers and provides methods for reading and writing PO file entries, with support for both single-line and multi-line translations.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "PHP",
    "code": "\n<?php\n/**\n * Class for working with PO files\n *\n * @version $Id: po.php 1158 2015-11-20 04:31:23Z dd32 $\n * @package pomo\n * @subpackage po\n */\n\nrequire_once dirname(__FILE__) . '/translations.php';\n\nif ( ! defined( 'PO_MAX_LINE_LEN' ) ) {\n\tdefine('PO_MAX_LINE_LEN', 79);\n}\n\nini_set('auto_detect_line_endings', 1);\n\n/**\n * Routines for working with PO files\n */\nif ( ! class_exists( 'PO', false ) ):\nclass PO extends Gettext_Translations {\n\n\tvar $comments_before_headers = '';\n\n\t/**\n\t * Exports headers to a PO entry\n\t *\n\t * @return string msgid/msgstr PO entry for this PO file headers, doesn't contain newline at the end\n\t */\n\tfunction export_headers() {\n\t\t$header_string = '';\n\t\tforeach($this->headers as $header => $value) {\n\t\t\t$header_string.= \"$header: $value\\n\";\n\t\t}\n\t\t$poified = PO::poify($header_string);\n\t\tif ($this->comments_before_headers)\n\t\t\t$before_headers = $this->prepend_each_line(rtrim($this->comments_before_headers).\"\\n\", '# ');\n\t\telse\n\t\t\t$before_headers = '';\n\t\treturn rtrim(\"{$before_headers}msgid \\\"\\\"\\nmsgstr $poified\");\n\t}\n\n\t/**\n\t * Exports all entries to PO format\n\t *\n\t * @return string sequence of mgsgid/msgstr PO strings, doesn't containt newline at the end\n\t */\n\tfunction export_entries() {\n\t\t//TODO sorting\n\t\treturn implode(\"\\n\\n\", array_map(array('PO', 'export_entry'), $this->entries));\n\t}\n\n\t/**\n\t * Exports the whole PO file as a string\n\t *\n\t * @param bool $include_headers whether to include the headers in the export\n\t * @return string ready for inclusion in PO file string for headers and all the enrtries\n\t */\n\tfunction export($include_headers = true) {\n\t\t$res = '';\n\t\tif ($include_headers) {\n\t\t\t$res .= $this->export_headers();\n\t\t\t$res .= \"\\n\\n\";\n\t\t}\n\t\t$res .= $this->export_entries();\n\t\treturn $res;\n\t}\n\n\t/**\n\t * Same as {@link export}, but writes the result to a file\n\t *\n\t * @param string $filename where to write the PO string\n\t * @param bool $include_headers whether to include tje headers in the export\n\t * @return bool true on success, false on error\n\t */\n\tfunction export_to_file($filename, $include_headers = true) {\n\t\t$fh = fopen($filename, 'w');\n\t\tif (false === $fh) return false;\n\t\t$export = $this->export($include_headers);\n\t\t$res = fwrite($fh, $export);\n\t\tif (false === $res) return false;\n\t\treturn fclose($fh);\n\t}\n\n\t/**\n\t * Text to include as a comment before the start of the PO contents\n\t *\n\t * Doesn't need to include # in the beginning of lines, these are added automatically\n\t */\n\tfunction set_comment_before_headers( $text ) {\n\t\t$this->comments_before_headers = $text;\n\t}\n\n\t/**\n\t * Formats a string in PO-style\n\t *\n\t * @static\n\t * @param string $string the string to format\n\t * @return string the poified string\n\t */\n\tpublic static function poify($string) {\n\t\t$quote = '\"';\n\t\t$slash = '\\\\';\n\t\t$newline = \"\\n\";\n\n\t\t$replaces = array(\n\t\t\t\"$slash\" \t=> \"$slash$slash\",\n\t\t\t\"$quote\"\t=> \"$slash$quote\",\n\t\t\t\"\\t\" \t\t=> '\\t',\n\t\t);\n\n\t\t$string = str_replace(array_keys($replaces), array_values($replaces), $string);\n\n\t\t$po = $quote.implode(\"${slash}n$quote$newline$quote\", explode($newline, $string)).$quote;\n\t\t// add empty string on first line for readbility\n\t\tif (false !== strpos($string, $newline) &&\n\t\t\t\t(substr_count($string, $newline) > 1 || !($newline === substr($string, -strlen($newline))))) {\n\t\t\t$po = \"$quote$quote$newline$po\";\n\t\t}\n\t\t// remove empty strings\n\t\t$po = str_replace(\"$newline$quote$quote\", '', $po);\n\t\treturn $po;\n\t}\n\n\t/**\n\t * Gives back the original string from a PO-formatted string\n\t *\n\t * @static\n\t * @param string $string PO-formatted string\n\t * @return string enascaped string\n\t */\n\tpublic static function unpoify($string) {\n\t\t$escapes = array('t' => \"\\t\", 'n' => \"\\n\", 'r' => \"\\r\", '\\\\' => '\\\\');\n\t\t$lines = array_map('trim', explode(\"\\n\", $string));\n\t\t$lines = array_map(array('PO', 'trim_quotes'), $lines);\n\t\t$unpoified = '';\n\t\t$previous_is_backslash = false;\n\t\tforeach($lines as $line) {\n\t\t\tpreg_match_all('/./u', $line, $chars);\n\t\t\t$chars = $chars[0];\n\t\t\tforeach($chars as $char) {\n\t\t\t\tif (!$previous_is_backslash) {\n\t\t\t\t\tif ('\\\\' == $char)\n\t\t\t\t\t\t$previous_is_backslash = true;\n\t\t\t\t\telse\n\t\t\t\t\t\t$unpoified .= $char;\n\t\t\t\t} else {\n\t\t\t\t\t$previous_is_backslash = false;\n\t\t\t\t\t$unpoified .= isset($escapes[$char])? $escapes[$char] : $char;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Standardise the line endings on imported content, technically PO files shouldn't contain \\r\n\t\t$unpoified = str_replace( array( \"\\r\\n\", \"\\r\" ), \"\\n\", $unpoified );\n\n\t\treturn $unpoified;\n\t}\n\n\t/**\n\t * Inserts $with in the beginning of every new line of $string and\n\t * returns the modified string\n\t *\n\t * @static\n\t * @param string $string prepend lines in this string\n\t * @param string $with prepend lines with this string\n\t */\n\tpublic static function prepend_each_line($string, $with) {\n\t\t$php_with = var_export($with, true);\n\t\t$lines = explode(\"\\n\", $string);\n\t\t// do not prepend the string on the last empty line, artefact by explode\n\t\tif (\"\\n\" == substr($string, -1)) unset($lines[count($lines) - 1]);\n\t\t$res = implode(\"\\n\", array_map(create_function('$x', \"return $php_with.\\$x;\"), $lines));\n\t\t// give back the empty line, we ignored above\n\t\tif (\"\\n\" == substr($string, -1)) $res .= \"\\n\";\n\t\treturn $res;\n\t}\n\n\t/**\n\t * Prepare a text as a comment -- wraps the lines and prepends #\n\t * and a special character to each line\n\t *\n\t * @access private\n\t * @param string $text the comment text\n\t * @param string $char character to denote a special PO comment,\n\t * \tlike :, default is a space\n\t */\n\tpublic static function comment_block($text, $char=' ') {\n\t\t$text = wordwrap($text, PO_MAX_LINE_LEN - 3);\n\t\treturn PO::prepend_each_line($text, \"#$char \");\n\t}\n\n\t/**\n\t * Builds a string from the entry for inclusion in PO file\n\t *\n\t * @static\n\t * @param Translation_Entry &$entry the entry to convert to po string\n\t * @return false|string PO-style formatted string for the entry or\n\t * \tfalse if the entry is empty\n\t */\n\tpublic static function export_entry(&$entry) {\n\t\tif ( null === $entry->singular || '' === $entry->singular ) return false;\n\t\t$po = array();\n\t\tif (!empty($entry->translator_comments)) $po[] = PO::comment_block($entry->translator_comments);\n\t\tif (!empty($entry->extracted_comments)) $po[] = PO::comment_block($entry->extracted_comments, '.');\n\t\tif (!empty($entry->references)) $po[] = PO::comment_block(implode(' ', $entry->references), ':');\n\t\tif (!empty($entry->flags)) $po[] = PO::comment_block(implode(\", \", $entry->flags), ',');\n\t\tif ($entry->context) $po[] = 'msgctxt '.PO::poify($entry->context);\n\t\t$po[] = 'msgid '.PO::poify($entry->singular);\n\t\tif (!$entry->is_plural) {\n\t\t\t$translation = empty($entry->translations)? '' : $entry->translations[0];\n\t\t\t$translation = PO::match_begin_and_end_newlines( $translation, $entry->singular );\n\t\t\t$po[] = 'msgstr '.PO::poify($translation);\n\t\t} else {\n\t\t\t$po[] = 'msgid_plural '.PO::poify($entry->plural);\n\t\t\t$translations = empty($entry->translations)? array('', '') : $entry->translations;\n\t\t\tforeach($translations as $i => $translation) {\n\t\t\t\t$translation = PO::match_begin_and_end_newlines( $translation, $entry->plural );\n\t\t\t\t$po[] = \"msgstr[$i] \".PO::poify($translation);\n\t\t\t}\n\t\t}\n\t\treturn implode(\"\\n\", $po);\n\t}\n\n\tpublic static function match_begin_and_end_newlines( $translation, $original ) {\n\t\tif ( '' === $translation ) {\n\t\t\treturn $translation;\n\t\t}\n\n\t\t$original_begin = \"\\n\" === substr( $original, 0, 1 );\n\t\t$original_end = \"\\n\" === substr( $original, -1 );\n\t\t$translation_begin = \"\\n\" === substr( $translation, 0, 1 );\n\t\t$translation_end = \"\\n\" === substr( $translation, -1 );\n\n\t\tif ( $original_begin ) {\n\t\t\tif ( ! $translation_begin ) {\n\t\t\t\t$translation = \"\\n\" . $translation;\n\t\t\t}\n\t\t} elseif ( $translation_begin ) {\n\t\t\t$translation = ltrim( $translation, \"\\n\" );\n\t\t}\n\n\t\tif ( $original_end ) {\n\t\t\tif ( ! $translation_end ) {\n\t\t\t\t$translation .= \"\\n\";\n\t\t\t}\n\t\t} elseif ( $translation_end ) {\n\t\t\t$translation = rtrim( $translation, \"\\n\" );\n\t\t}\n\n\t\treturn $translation;\n\t}\n\n\t/**\n\t * @param string $filename\n\t * @return boolean\n\t */\n\tfunction import_from_file($filename) {\n\t\t$f = fopen($filename, 'r');\n\t\tif (!$f) return false;\n\t\t$lineno = 0;\n\t\twhile (true) {\n\t\t\t$res = $this->read_entry($f, $lineno);\n\t\t\tif (!$res) break;\n\t\t\tif ($res['entry']->singular == '') {\n\t\t\t\t$this->set_headers($this->make_headers($res['entry']->translations[0]));\n\t\t\t} else {\n\t\t\t\t$this->add_entry($res['entry']);\n\t\t\t}\n\t\t}\n\t\tPO::read_line($f, 'clear');\n\t\tif ( false === $res ) {\n\t\t\treturn false;\n\t\t}\n\t\tif ( ! $this->headers && ! $this->entries ) {\n\t\t\treturn false;\n\t\t}\n\t\treturn true;\n\t}\n\n\t/**\n\t * @param resource $f\n\t * @param int      $lineno\n\t * @return null|false|array\n\t */\n\tfunction read_entry($f, $lineno = 0) {\n\t\t$entry = new Translation_Entry();\n\t\t// where were we in the last step\n\t\t// can be: comment, msgctxt, msgid, msgid_plural, msgstr, msgstr_plural\n\t\t$context = '';\n\t\t$msgstr_index = 0;\n\t\t$is_final = create_function('$context', 'return $context == \"msgstr\" || $context == \"msgstr_plural\";');\n\t\twhile (true) {\n\t\t\t$lineno++;\n\t\t\t$line = PO::read_line($f);\n\t\t\tif (!$line)  {\n\t\t\t\tif (feof($f)) {\n\t\t\t\t\tif ($is_final($context))\n\t\t\t\t\t\tbreak;\n\t\t\t\t\telseif (!$context) // we haven't read a line and eof came\n\t\t\t\t\t\treturn null;\n\t\t\t\t\telse\n\t\t\t\t\t\treturn false;\n\t\t\t\t} else {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif ($line == \"\\n\") continue;\n\t\t\t$line = trim($line);\n\t\t\tif (preg_match('/^#/', $line, $m)) {\n\t\t\t\t// the comment is the start of a new entry\n\t\t\t\tif ($is_final($context)) {\n\t\t\t\t\tPO::read_line($f, 'put-back');\n\t\t\t\t\t$lineno--;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t// comments have to be at the beginning\n\t\t\t\tif ($context && $context != 'comment') {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t// add comment\n\t\t\t\t$this->add_comment_to_entry($entry, $line);\n\t\t\t} elseif (preg_match('/^msgctxt\\s+(\".*\")/', $line, $m)) {\n\t\t\t\tif ($is_final($context)) {\n\t\t\t\t\tPO::read_line($f, 'put-back');\n\t\t\t\t\t$lineno--;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif ($context && $context != 'comment') {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t$context = 'msgctxt';\n\t\t\t\t$entry->context .= PO::unpoify($m[1]);\n\t\t\t} elseif (preg_match('/^msgid\\s+(\".*\")/', $line, $m)) {\n\t\t\t\tif ($is_final($context)) {\n\t\t\t\t\tPO::read_line($f, 'put-back');\n\t\t\t\t\t$lineno--;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif ($context && $context != 'msgctxt' && $context != 'comment') {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t$context = 'msgid';\n\t\t\t\t$entry->singular .= PO::unpoify($m[1]);\n\t\t\t} elseif (preg_match('/^msgid_plural\\s+(\".*\")/', $line, $m)) {\n\t\t\t\tif ($context != 'msgid') {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t$context = 'msgid_plural';\n\t\t\t\t$entry->is_plural = true;\n\t\t\t\t$entry->plural .= PO::unpoify($m[1]);\n\t\t\t} elseif (preg_match('/^msgstr\\s+(\".*\")/', $line, $m)) {\n\t\t\t\tif ($context != 'msgid') {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t$context = 'msgstr';\n\t\t\t\t$entry->translations = array(PO::unpoify($m[1]));\n\t\t\t} elseif (preg_match('/^msgstr\\[(\\d+)\\]\\s+(\".*\")/', $line, $m)) {\n\t\t\t\tif ($context != 'msgid_plural' && $context != 'msgstr_plural') {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\t$context = 'msgstr_plural';\n\t\t\t\t$msgstr_index = $m[1];\n\t\t\t\t$entry->translations[$m[1]] = PO::unpoify($m[2]);\n\t\t\t} elseif (preg_match('/^\".*\"$/', $line)) {\n\t\t\t\t$unpoified = PO::unpoify($line);\n\t\t\t\tswitch ($context) {\n\t\t\t\t\tcase 'msgid':\n\t\t\t\t\t\t$entry->singular .= $unpoified; break;\n\t\t\t\t\tcase 'msgctxt':\n\t\t\t\t\t\t$entry->context .= $unpoified; break;\n\t\t\t\t\tcase 'msgid_plural':\n\t\t\t\t\t\t$entry->plural .= $unpoified; break;\n\t\t\t\t\tcase 'msgstr':\n\t\t\t\t\t\t$entry->translations[0] .= $unpoified; break;\n\t\t\t\t\tcase 'msgstr_plural':\n\t\t\t\t\t\t$entry->translations[$msgstr_index] .= $unpoified; break;\n\t\t\t\t\tdefault:\n\t\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\tif (array() == array_filter($entry->translations, create_function('$t', 'return $t || \"0\" === $t;'))) {\n\t\t\t$entry->translations = array();\n\t\t}\n\t\treturn array('entry' => $entry, 'lineno' => $lineno);\n\t}\n\n\t/**\n\t * @staticvar string   $last_line\n\t * @staticvar boolean  $use_last_line\n\t *\n\t * @param     resource $f\n\t * @param     string   $action\n\t * @return boolean\n\t */\n\tfunction read_line($f, $action = 'read') {\n\t\tstatic $last_line = '';\n\t\tstatic $use_last_line = false;\n\t\tif ('clear' == $action) {\n\t\t\t$last_line = '';\n\t\t\treturn true;\n\t\t}\n\t\tif ('put-back' == $action) {\n\t\t\t$use_last_line = true;\n\t\t\treturn true;\n\t\t}\n\t\t$line = $use_last_line? $last_line : fgets($f);\n\t\t$line = ( \"\\r\\n\" == substr( $line, -2 ) ) ? rtrim( $line, \"\\r\\n\" ) . \"\\n\" : $line;\n\t\t$last_line = $line;\n\t\t$use_last_line = false;\n\t\treturn $line;\n\t}\n\n\t/**\n\t * @param Translation_Entry $entry\n\t * @param string            $po_comment_line\n\t */\n\tfunction add_comment_to_entry(&$entry, $po_comment_line) {\n\t\t$first_two = substr($po_comment_line, 0, 2);\n\t\t$comment = trim(substr($po_comment_line, 2));\n\t\tif ('#:' == $first_two) {\n\t\t\t$entry->references = array_merge($entry->references, preg_split('/\\s+/', $comment));\n\t\t} elseif ('#.' == $first_two) {\n\t\t\t$entry->extracted_comments = trim($entry->extracted_comments . \"\\n\" . $comment);\n\t\t} elseif ('#,' == $first_two) {\n\t\t\t$entry->flags = array_merge($entry->flags, preg_split('/,\\s*/', $comment));\n\t\t} else {\n\t\t\t$entry->translator_comments = trim($entry->translator_comments . \"\\n\" . $comment);\n\t\t}\n\t}\n\n\t/**\n\t * @param string $s\n\t * @return sring\n\t */\n\tpublic static function trim_quotes($s) {\n\t\tif ( substr($s, 0, 1) == '\"') $s = substr($s, 1);\n\t\tif ( substr($s, -1, 1) == '\"') $s = substr($s, 0, -1);\n\t\treturn $s;\n\t}\n}\nendif;",
    "repo": "docker/labs",
    "path": "./datasets/diagrams-repos/docker/labs/security/apparmor/wordpress/html/wp-includes/pomo/po.php",
    "query": "How is the PO class structured in the provided code?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'PO', 'node_id': 'PO', 'description': 'Main class for working with PO files, extends Gettext_Translations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'comments_before_headers', 'node_id': 'comments_before_headers', 'description': 'Comments to be included before headers', 'visibility': 'public', 'return_type': 'string', 'params': None, 'source_class_id': 'PO'}, {'type': 'method', 'name': 'export', 'node_id': 'export', 'description': 'Exports PO file content as string', 'visibility': 'public', 'return_type': 'string', 'params': 'bool $include_headers = true', 'source_class_id': 'PO'}, {'type': 'method', 'name': 'export_headers', 'node_id': 'export_headers', 'description': 'Exports headers to PO entry', 'visibility': 'public', 'return_type': 'string', 'params': '', 'source_class_id': 'PO'}, {'type': 'method', 'name': 'export_entries', 'node_id': 'export_entries', 'description': 'Exports all entries to PO format', 'visibility': 'public', 'return_type': 'string', 'params': '', 'source_class_id': 'PO'}, {'type': 'method', 'name': 'export_to_file', 'node_id': 'export_to_file', 'description': 'Exports PO content to file', 'visibility': 'public', 'return_type': 'bool', 'params': 'string $filename, bool $include_headers = true', 'source_class_id': 'PO'}, {'type': 'method', 'name': 'set_comment_before_headers', 'node_id': 'set_comment_before_headers', 'description': 'Sets comment before headers', 'visibility': 'public', 'return_type': 'void', 'params': 'string $text', 'source_class_id': 'PO'}, {'type': 'method', 'name': 'poify', 'node_id': 'poify', 'description': 'Formats string in PO-style', 'visibility': 'public', 'return_type': 'string', 'params': 'string $string', 'source_class_id': 'PO'}, {'type': 'method', 'name': 'unpoify', 'node_id': 'unpoify', 'description': 'Converts PO-formatted string back to original', 'visibility': 'public', 'return_type': 'string', 'params': 'string $string', 'source_class_id': 'PO'}, {'type': 'method', 'name': 'import_from_file', 'node_id': 'import_from_file', 'description': 'Imports PO content from file', 'visibility': 'public', 'return_type': 'boolean', 'params': 'string $filename', 'source_class_id': 'PO'}, {'type': 'method', 'name': 'read_entry', 'node_id': 'read_entry', 'description': 'Reads single entry from file', 'visibility': 'public', 'return_type': 'array|None|false', 'params': 'resource $f, int $lineno = 0', 'source_class_id': 'PO'}, {'type': 'method', 'name': 'read_line', 'node_id': 'read_line', 'description': 'Reads line from file', 'visibility': 'public', 'return_type': 'string|bool', 'params': \"resource $f, string $action = 'read'\", 'source_class_id': 'PO'}, {'type': 'method', 'name': 'add_comment_to_entry', 'node_id': 'add_comment_to_entry', 'description': 'Adds comment to translation entry', 'visibility': 'public', 'return_type': 'void', 'params': 'Translation_Entry &$entry, string $po_comment_line', 'source_class_id': 'PO'}], 'edges': [{'node_id_from': 'PO', 'node_id_to': 'comments_before_headers', 'description': 'has'}, {'node_id_from': 'PO', 'node_id_to': 'export', 'description': 'contains'}, {'node_id_from': 'PO', 'node_id_to': 'export_headers', 'description': 'contains'}, {'node_id_from': 'PO', 'node_id_to': 'export_entries', 'description': 'contains'}, {'node_id_from': 'PO', 'node_id_to': 'read_entry', 'description': 'contains'}, {'node_id_from': 'PO', 'node_id_to': 'read_line', 'description': 'contains'}, {'node_id_from': 'PO', 'node_id_to': 'add_comment_to_entry', 'description': 'contains'}, {'node_id_from': 'export', 'node_id_to': 'export_headers', 'description': 'uses'}, {'node_id_from': 'export', 'node_id_to': 'export_entries', 'description': 'uses'}, {'node_id_from': 'PO', 'node_id_to': 'export_to_file', 'description': 'contains'}, {'node_id_from': 'export_to_file', 'node_id_to': 'export', 'description': 'uses'}, {'node_id_from': 'PO', 'node_id_to': 'set_comment_before_headers', 'description': 'contains'}, {'node_id_from': 'PO', 'node_id_to': 'poify', 'description': 'contains'}, {'node_id_from': 'PO', 'node_id_to': 'unpoify', 'description': 'contains'}, {'node_id_from': 'PO', 'node_id_to': 'import_from_file', 'description': 'contains'}, {'node_id_from': 'import_from_file', 'node_id_to': 'read_entry', 'description': 'uses'}, {'node_id_from': 'read_entry', 'node_id_to': 'read_line', 'description': 'uses'}, {'node_id_from': 'read_entry', 'node_id_to': 'add_comment_to_entry', 'description': 'uses'}], 'packages': [{'package_id': 'io', 'children': ['import_from_file', 'export', 'export_to_file', 'export_headers', 'export_entries', 'read_entry', 'read_line'], 'description': 'Input/Output operations'}, {'package_id': 'data', 'children': ['PO', 'comments_before_headers', 'io', 'formatting'], 'description': 'Data structures'}, {'package_id': 'formatting', 'children': ['poify', 'unpoify', 'add_comment_to_entry', 'set_comment_before_headers'], 'description': 'String formatting operations'}]}",
    "version": "full",
    "text_answer": "The PO class is a PHP class for working with PO files that extends Gettext_Translations. It primarily handles file I/O operations (import/export) and string formatting. The class maintains comments before headers and provides methods for reading and writing PO file entries, with support for both single-line and multi-line translations.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.apache.flink.runtime.entrypoint.component;\n\nimport org.apache.flink.configuration.Configuration;\nimport org.apache.flink.configuration.MetricOptions;\nimport org.apache.flink.configuration.RestOptions;\nimport org.apache.flink.core.failure.FailureEnricher;\nimport org.apache.flink.runtime.blob.BlobServer;\nimport org.apache.flink.runtime.clusterframework.types.ResourceID;\nimport org.apache.flink.runtime.dispatcher.DispatcherGateway;\nimport org.apache.flink.runtime.dispatcher.DispatcherId;\nimport org.apache.flink.runtime.dispatcher.DispatcherOperationCaches;\nimport org.apache.flink.runtime.dispatcher.ExecutionGraphInfoStore;\nimport org.apache.flink.runtime.dispatcher.HistoryServerArchivist;\nimport org.apache.flink.runtime.dispatcher.PartialDispatcherServices;\nimport org.apache.flink.runtime.dispatcher.SessionDispatcherFactory;\nimport org.apache.flink.runtime.dispatcher.runner.DefaultDispatcherRunnerFactory;\nimport org.apache.flink.runtime.dispatcher.runner.DispatcherRunner;\nimport org.apache.flink.runtime.dispatcher.runner.DispatcherRunnerFactory;\nimport org.apache.flink.runtime.entrypoint.ClusterInformation;\nimport org.apache.flink.runtime.heartbeat.HeartbeatServices;\nimport org.apache.flink.runtime.highavailability.HighAvailabilityServices;\nimport org.apache.flink.runtime.jobmanager.HaServicesJobPersistenceComponentFactory;\nimport org.apache.flink.runtime.leaderretrieval.LeaderRetrievalService;\nimport org.apache.flink.runtime.metrics.MetricRegistry;\nimport org.apache.flink.runtime.metrics.groups.JobManagerMetricGroup;\nimport org.apache.flink.runtime.resourcemanager.ResourceManagerFactory;\nimport org.apache.flink.runtime.resourcemanager.ResourceManagerGateway;\nimport org.apache.flink.runtime.resourcemanager.ResourceManagerId;\nimport org.apache.flink.runtime.resourcemanager.ResourceManagerService;\nimport org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl;\nimport org.apache.flink.runtime.rest.RestEndpointFactory;\nimport org.apache.flink.runtime.rest.SessionRestEndpointFactory;\nimport org.apache.flink.runtime.rest.handler.legacy.metrics.MetricFetcher;\nimport org.apache.flink.runtime.rest.handler.legacy.metrics.MetricFetcherImpl;\nimport org.apache.flink.runtime.rest.handler.legacy.metrics.VoidMetricFetcher;\nimport org.apache.flink.runtime.rpc.FatalErrorHandler;\nimport org.apache.flink.runtime.rpc.RpcService;\nimport org.apache.flink.runtime.rpc.RpcUtils;\nimport org.apache.flink.runtime.security.token.DelegationTokenManager;\nimport org.apache.flink.runtime.webmonitor.WebMonitorEndpoint;\nimport org.apache.flink.runtime.webmonitor.retriever.LeaderGatewayRetriever;\nimport org.apache.flink.runtime.webmonitor.retriever.MetricQueryServiceRetriever;\nimport org.apache.flink.runtime.webmonitor.retriever.impl.RpcGatewayRetriever;\nimport org.apache.flink.util.ExceptionUtils;\nimport org.apache.flink.util.FlinkException;\nimport org.apache.flink.util.concurrent.ExponentialBackoffRetryStrategy;\nimport org.apache.flink.util.concurrent.FutureUtils;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport javax.annotation.Nonnull;\n\nimport java.time.Duration;\nimport java.util.ArrayList;\nimport java.util.Collection;\nimport java.util.concurrent.CompletableFuture;\nimport java.util.concurrent.Executor;\nimport java.util.concurrent.ScheduledExecutorService;\n\n/**\n * Abstract class which implements the creation of the {@link DispatcherResourceManagerComponent}\n * components.\n */\npublic class DefaultDispatcherResourceManagerComponentFactory\n        implements DispatcherResourceManagerComponentFactory {\n\n    private final Logger log = LoggerFactory.getLogger(getClass());\n\n    @Nonnull private final DispatcherRunnerFactory dispatcherRunnerFactory;\n\n    @Nonnull private final ResourceManagerFactory<?> resourceManagerFactory;\n\n    @Nonnull private final RestEndpointFactory<?> restEndpointFactory;\n\n    public DefaultDispatcherResourceManagerComponentFactory(\n            @Nonnull DispatcherRunnerFactory dispatcherRunnerFactory,\n            @Nonnull ResourceManagerFactory<?> resourceManagerFactory,\n            @Nonnull RestEndpointFactory<?> restEndpointFactory) {\n        this.dispatcherRunnerFactory = dispatcherRunnerFactory;\n        this.resourceManagerFactory = resourceManagerFactory;\n        this.restEndpointFactory = restEndpointFactory;\n    }\n\n    @Override\n    public DispatcherResourceManagerComponent create(\n            Configuration configuration,\n            ResourceID resourceId,\n            Executor ioExecutor,\n            RpcService rpcService,\n            HighAvailabilityServices highAvailabilityServices,\n            BlobServer blobServer,\n            HeartbeatServices heartbeatServices,\n            DelegationTokenManager delegationTokenManager,\n            MetricRegistry metricRegistry,\n            ExecutionGraphInfoStore executionGraphInfoStore,\n            MetricQueryServiceRetriever metricQueryServiceRetriever,\n            Collection<FailureEnricher> failureEnrichers,\n            FatalErrorHandler fatalErrorHandler)\n            throws Exception {\n\n        LeaderRetrievalService dispatcherLeaderRetrievalService = null;\n        LeaderRetrievalService resourceManagerRetrievalService = null;\n        WebMonitorEndpoint<?> webMonitorEndpoint = null;\n        ResourceManagerService resourceManagerService = null;\n        DispatcherRunner dispatcherRunner = null;\n\n        try {\n            dispatcherLeaderRetrievalService =\n                    highAvailabilityServices.getDispatcherLeaderRetriever();\n\n            resourceManagerRetrievalService =\n                    highAvailabilityServices.getResourceManagerLeaderRetriever();\n\n            final LeaderGatewayRetriever<DispatcherGateway> dispatcherGatewayRetriever =\n                    new RpcGatewayRetriever<>(\n                            rpcService,\n                            DispatcherGateway.class,\n                            DispatcherId::fromUuid,\n                            new ExponentialBackoffRetryStrategy(\n                                    12, Duration.ofMillis(10), Duration.ofMillis(50)));\n\n            final LeaderGatewayRetriever<ResourceManagerGateway> resourceManagerGatewayRetriever =\n                    new RpcGatewayRetriever<>(\n                            rpcService,\n                            ResourceManagerGateway.class,\n                            ResourceManagerId::fromUuid,\n                            new ExponentialBackoffRetryStrategy(\n                                    12, Duration.ofMillis(10), Duration.ofMillis(50)));\n\n            final ScheduledExecutorService executor =\n                    WebMonitorEndpoint.createExecutorService(\n                            configuration.get(RestOptions.SERVER_NUM_THREADS),\n                            configuration.get(RestOptions.SERVER_THREAD_PRIORITY),\n                            \"DispatcherRestEndpoint\");\n\n            final long updateInterval =\n                    configuration.get(MetricOptions.METRIC_FETCHER_UPDATE_INTERVAL).toMillis();\n            final MetricFetcher metricFetcher =\n                    updateInterval == 0\n                            ? VoidMetricFetcher.INSTANCE\n                            : MetricFetcherImpl.fromConfiguration(\n                                    configuration,\n                                    metricQueryServiceRetriever,\n                                    dispatcherGatewayRetriever,\n                                    executor);\n\n            webMonitorEndpoint =\n                    restEndpointFactory.createRestEndpoint(\n                            configuration,\n                            dispatcherGatewayRetriever,\n                            resourceManagerGatewayRetriever,\n                            blobServer,\n                            executor,\n                            metricFetcher,\n                            highAvailabilityServices.getClusterRestEndpointLeaderElection(),\n                            fatalErrorHandler);\n\n            log.debug(\"Starting Dispatcher REST endpoint.\");\n            webMonitorEndpoint.start();\n\n            final String hostname = RpcUtils.getHostname(rpcService);\n\n            resourceManagerService =\n                    ResourceManagerServiceImpl.create(\n                            resourceManagerFactory,\n                            configuration,\n                            resourceId,\n                            rpcService,\n                            highAvailabilityServices,\n                            heartbeatServices,\n                            delegationTokenManager,\n                            fatalErrorHandler,\n                            new ClusterInformation(hostname, blobServer.getPort()),\n                            webMonitorEndpoint.getRestBaseUrl(),\n                            metricRegistry,\n                            hostname,\n                            ioExecutor);\n\n            final HistoryServerArchivist historyServerArchivist =\n                    HistoryServerArchivist.createHistoryServerArchivist(\n                            configuration, webMonitorEndpoint, ioExecutor);\n\n            final DispatcherOperationCaches dispatcherOperationCaches =\n                    new DispatcherOperationCaches(\n                            configuration.get(RestOptions.ASYNC_OPERATION_STORE_DURATION));\n\n            final PartialDispatcherServices partialDispatcherServices =\n                    new PartialDispatcherServices(\n                            configuration,\n                            highAvailabilityServices,\n                            resourceManagerGatewayRetriever,\n                            blobServer,\n                            heartbeatServices,\n                            () ->\n                                    JobManagerMetricGroup.createJobManagerMetricGroup(\n                                            metricRegistry, hostname),\n                            executionGraphInfoStore,\n                            fatalErrorHandler,\n                            historyServerArchivist,\n                            metricRegistry.getMetricQueryServiceGatewayRpcAddress(),\n                            ioExecutor,\n                            dispatcherOperationCaches,\n                            failureEnrichers);\n\n            log.debug(\"Starting Dispatcher.\");\n            dispatcherRunner =\n                    dispatcherRunnerFactory.createDispatcherRunner(\n                            highAvailabilityServices.getDispatcherLeaderElection(),\n                            fatalErrorHandler,\n                            new HaServicesJobPersistenceComponentFactory(highAvailabilityServices),\n                            ioExecutor,\n                            rpcService,\n                            partialDispatcherServices);\n\n            log.debug(\"Starting ResourceManagerService.\");\n            resourceManagerService.start();\n\n            resourceManagerRetrievalService.start(resourceManagerGatewayRetriever);\n            dispatcherLeaderRetrievalService.start(dispatcherGatewayRetriever);\n\n            return new DispatcherResourceManagerComponent(\n                    dispatcherRunner,\n                    resourceManagerService,\n                    dispatcherLeaderRetrievalService,\n                    resourceManagerRetrievalService,\n                    webMonitorEndpoint,\n                    fatalErrorHandler,\n                    dispatcherOperationCaches);\n\n        } catch (Exception exception) {\n            // clean up all started components\n            if (dispatcherLeaderRetrievalService != null) {\n                try {\n                    dispatcherLeaderRetrievalService.stop();\n                } catch (Exception e) {\n                    exception = ExceptionUtils.firstOrSuppressed(e, exception);\n                }\n            }\n\n            if (resourceManagerRetrievalService != null) {\n                try {\n                    resourceManagerRetrievalService.stop();\n                } catch (Exception e) {\n                    exception = ExceptionUtils.firstOrSuppressed(e, exception);\n                }\n            }\n\n            final Collection<CompletableFuture<Void>> terminationFutures = new ArrayList<>(3);\n\n            if (webMonitorEndpoint != null) {\n                terminationFutures.add(webMonitorEndpoint.closeAsync());\n            }\n\n            if (resourceManagerService != null) {\n                terminationFutures.add(resourceManagerService.closeAsync());\n            }\n\n            if (dispatcherRunner != null) {\n                terminationFutures.add(dispatcherRunner.closeAsync());\n            }\n\n            final FutureUtils.ConjunctFuture<Void> terminationFuture =\n                    FutureUtils.completeAll(terminationFutures);\n\n            try {\n                terminationFuture.get();\n            } catch (Exception e) {\n                exception = ExceptionUtils.firstOrSuppressed(e, exception);\n            }\n\n            throw new FlinkException(\n                    \"Could not create the DispatcherResourceManagerComponent.\", exception);\n        }\n    }\n\n    public static DefaultDispatcherResourceManagerComponentFactory createSessionComponentFactory(\n            ResourceManagerFactory<?> resourceManagerFactory) {\n        return new DefaultDispatcherResourceManagerComponentFactory(\n                DefaultDispatcherRunnerFactory.createSessionRunner(\n                        SessionDispatcherFactory.INSTANCE),\n                resourceManagerFactory,\n                SessionRestEndpointFactory.INSTANCE);\n    }\n}",
    "repo": "apache/flink",
    "path": "./datasets/diagrams-repos/apache/flink/flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/component/DefaultDispatcherResourceManagerComponentFactory.java",
    "query": "What are the class dependencies of DefaultDispatcherResourceManagerComponentFactory and how are they connected?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'DefaultDispatcherResourceManagerComponentFactory', 'node_id': 'DefaultDispatcherResourceManagerComponentFactory', 'description': 'Factory for creating DispatcherResourceManagerComponent instances', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'DispatcherResourceManagerComponent', 'node_id': 'DispatcherResourceManagerComponent', 'description': 'Main component containing dispatcher and resource manager', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'DispatcherRunner', 'node_id': 'DispatcherRunner', 'description': 'Handles dispatcher lifecycle', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'ResourceManagerService', 'node_id': 'ResourceManagerService', 'description': 'Service managing cluster resources', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'DefaultDispatcherResourceManagerComponentFactory', 'node_id_to': 'DispatcherResourceManagerComponent', 'description': 'creates'}, {'node_id_from': 'DefaultDispatcherResourceManagerComponentFactory', 'node_id_to': 'DispatcherRunner', 'description': 'creates'}, {'node_id_from': 'DefaultDispatcherResourceManagerComponentFactory', 'node_id_to': 'ResourceManagerService', 'description': 'creates'}], 'packages': [{'package_id': 'core_components', 'children': ['DefaultDispatcherResourceManagerComponentFactory', 'DispatcherResourceManagerComponent', 'DispatcherRunner', 'ResourceManagerService'], 'description': 'Core components for cluster management'}]}",
    "version": "minimal",
    "text_answer": "DefaultDispatcherResourceManagerComponentFactory is responsible for creating and managing core cluster components. It primarily creates DispatcherResourceManagerComponent, which contains DispatcherRunner and ResourceManagerService. It also manages WebMonitorEndpoint for REST operations and various supporting services like metrics and high availability.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.apache.flink.runtime.entrypoint.component;\n\nimport org.apache.flink.configuration.Configuration;\nimport org.apache.flink.configuration.MetricOptions;\nimport org.apache.flink.configuration.RestOptions;\nimport org.apache.flink.core.failure.FailureEnricher;\nimport org.apache.flink.runtime.blob.BlobServer;\nimport org.apache.flink.runtime.clusterframework.types.ResourceID;\nimport org.apache.flink.runtime.dispatcher.DispatcherGateway;\nimport org.apache.flink.runtime.dispatcher.DispatcherId;\nimport org.apache.flink.runtime.dispatcher.DispatcherOperationCaches;\nimport org.apache.flink.runtime.dispatcher.ExecutionGraphInfoStore;\nimport org.apache.flink.runtime.dispatcher.HistoryServerArchivist;\nimport org.apache.flink.runtime.dispatcher.PartialDispatcherServices;\nimport org.apache.flink.runtime.dispatcher.SessionDispatcherFactory;\nimport org.apache.flink.runtime.dispatcher.runner.DefaultDispatcherRunnerFactory;\nimport org.apache.flink.runtime.dispatcher.runner.DispatcherRunner;\nimport org.apache.flink.runtime.dispatcher.runner.DispatcherRunnerFactory;\nimport org.apache.flink.runtime.entrypoint.ClusterInformation;\nimport org.apache.flink.runtime.heartbeat.HeartbeatServices;\nimport org.apache.flink.runtime.highavailability.HighAvailabilityServices;\nimport org.apache.flink.runtime.jobmanager.HaServicesJobPersistenceComponentFactory;\nimport org.apache.flink.runtime.leaderretrieval.LeaderRetrievalService;\nimport org.apache.flink.runtime.metrics.MetricRegistry;\nimport org.apache.flink.runtime.metrics.groups.JobManagerMetricGroup;\nimport org.apache.flink.runtime.resourcemanager.ResourceManagerFactory;\nimport org.apache.flink.runtime.resourcemanager.ResourceManagerGateway;\nimport org.apache.flink.runtime.resourcemanager.ResourceManagerId;\nimport org.apache.flink.runtime.resourcemanager.ResourceManagerService;\nimport org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl;\nimport org.apache.flink.runtime.rest.RestEndpointFactory;\nimport org.apache.flink.runtime.rest.SessionRestEndpointFactory;\nimport org.apache.flink.runtime.rest.handler.legacy.metrics.MetricFetcher;\nimport org.apache.flink.runtime.rest.handler.legacy.metrics.MetricFetcherImpl;\nimport org.apache.flink.runtime.rest.handler.legacy.metrics.VoidMetricFetcher;\nimport org.apache.flink.runtime.rpc.FatalErrorHandler;\nimport org.apache.flink.runtime.rpc.RpcService;\nimport org.apache.flink.runtime.rpc.RpcUtils;\nimport org.apache.flink.runtime.security.token.DelegationTokenManager;\nimport org.apache.flink.runtime.webmonitor.WebMonitorEndpoint;\nimport org.apache.flink.runtime.webmonitor.retriever.LeaderGatewayRetriever;\nimport org.apache.flink.runtime.webmonitor.retriever.MetricQueryServiceRetriever;\nimport org.apache.flink.runtime.webmonitor.retriever.impl.RpcGatewayRetriever;\nimport org.apache.flink.util.ExceptionUtils;\nimport org.apache.flink.util.FlinkException;\nimport org.apache.flink.util.concurrent.ExponentialBackoffRetryStrategy;\nimport org.apache.flink.util.concurrent.FutureUtils;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport javax.annotation.Nonnull;\n\nimport java.time.Duration;\nimport java.util.ArrayList;\nimport java.util.Collection;\nimport java.util.concurrent.CompletableFuture;\nimport java.util.concurrent.Executor;\nimport java.util.concurrent.ScheduledExecutorService;\n\n/**\n * Abstract class which implements the creation of the {@link DispatcherResourceManagerComponent}\n * components.\n */\npublic class DefaultDispatcherResourceManagerComponentFactory\n        implements DispatcherResourceManagerComponentFactory {\n\n    private final Logger log = LoggerFactory.getLogger(getClass());\n\n    @Nonnull private final DispatcherRunnerFactory dispatcherRunnerFactory;\n\n    @Nonnull private final ResourceManagerFactory<?> resourceManagerFactory;\n\n    @Nonnull private final RestEndpointFactory<?> restEndpointFactory;\n\n    public DefaultDispatcherResourceManagerComponentFactory(\n            @Nonnull DispatcherRunnerFactory dispatcherRunnerFactory,\n            @Nonnull ResourceManagerFactory<?> resourceManagerFactory,\n            @Nonnull RestEndpointFactory<?> restEndpointFactory) {\n        this.dispatcherRunnerFactory = dispatcherRunnerFactory;\n        this.resourceManagerFactory = resourceManagerFactory;\n        this.restEndpointFactory = restEndpointFactory;\n    }\n\n    @Override\n    public DispatcherResourceManagerComponent create(\n            Configuration configuration,\n            ResourceID resourceId,\n            Executor ioExecutor,\n            RpcService rpcService,\n            HighAvailabilityServices highAvailabilityServices,\n            BlobServer blobServer,\n            HeartbeatServices heartbeatServices,\n            DelegationTokenManager delegationTokenManager,\n            MetricRegistry metricRegistry,\n            ExecutionGraphInfoStore executionGraphInfoStore,\n            MetricQueryServiceRetriever metricQueryServiceRetriever,\n            Collection<FailureEnricher> failureEnrichers,\n            FatalErrorHandler fatalErrorHandler)\n            throws Exception {\n\n        LeaderRetrievalService dispatcherLeaderRetrievalService = null;\n        LeaderRetrievalService resourceManagerRetrievalService = null;\n        WebMonitorEndpoint<?> webMonitorEndpoint = null;\n        ResourceManagerService resourceManagerService = null;\n        DispatcherRunner dispatcherRunner = null;\n\n        try {\n            dispatcherLeaderRetrievalService =\n                    highAvailabilityServices.getDispatcherLeaderRetriever();\n\n            resourceManagerRetrievalService =\n                    highAvailabilityServices.getResourceManagerLeaderRetriever();\n\n            final LeaderGatewayRetriever<DispatcherGateway> dispatcherGatewayRetriever =\n                    new RpcGatewayRetriever<>(\n                            rpcService,\n                            DispatcherGateway.class,\n                            DispatcherId::fromUuid,\n                            new ExponentialBackoffRetryStrategy(\n                                    12, Duration.ofMillis(10), Duration.ofMillis(50)));\n\n            final LeaderGatewayRetriever<ResourceManagerGateway> resourceManagerGatewayRetriever =\n                    new RpcGatewayRetriever<>(\n                            rpcService,\n                            ResourceManagerGateway.class,\n                            ResourceManagerId::fromUuid,\n                            new ExponentialBackoffRetryStrategy(\n                                    12, Duration.ofMillis(10), Duration.ofMillis(50)));\n\n            final ScheduledExecutorService executor =\n                    WebMonitorEndpoint.createExecutorService(\n                            configuration.get(RestOptions.SERVER_NUM_THREADS),\n                            configuration.get(RestOptions.SERVER_THREAD_PRIORITY),\n                            \"DispatcherRestEndpoint\");\n\n            final long updateInterval =\n                    configuration.get(MetricOptions.METRIC_FETCHER_UPDATE_INTERVAL).toMillis();\n            final MetricFetcher metricFetcher =\n                    updateInterval == 0\n                            ? VoidMetricFetcher.INSTANCE\n                            : MetricFetcherImpl.fromConfiguration(\n                                    configuration,\n                                    metricQueryServiceRetriever,\n                                    dispatcherGatewayRetriever,\n                                    executor);\n\n            webMonitorEndpoint =\n                    restEndpointFactory.createRestEndpoint(\n                            configuration,\n                            dispatcherGatewayRetriever,\n                            resourceManagerGatewayRetriever,\n                            blobServer,\n                            executor,\n                            metricFetcher,\n                            highAvailabilityServices.getClusterRestEndpointLeaderElection(),\n                            fatalErrorHandler);\n\n            log.debug(\"Starting Dispatcher REST endpoint.\");\n            webMonitorEndpoint.start();\n\n            final String hostname = RpcUtils.getHostname(rpcService);\n\n            resourceManagerService =\n                    ResourceManagerServiceImpl.create(\n                            resourceManagerFactory,\n                            configuration,\n                            resourceId,\n                            rpcService,\n                            highAvailabilityServices,\n                            heartbeatServices,\n                            delegationTokenManager,\n                            fatalErrorHandler,\n                            new ClusterInformation(hostname, blobServer.getPort()),\n                            webMonitorEndpoint.getRestBaseUrl(),\n                            metricRegistry,\n                            hostname,\n                            ioExecutor);\n\n            final HistoryServerArchivist historyServerArchivist =\n                    HistoryServerArchivist.createHistoryServerArchivist(\n                            configuration, webMonitorEndpoint, ioExecutor);\n\n            final DispatcherOperationCaches dispatcherOperationCaches =\n                    new DispatcherOperationCaches(\n                            configuration.get(RestOptions.ASYNC_OPERATION_STORE_DURATION));\n\n            final PartialDispatcherServices partialDispatcherServices =\n                    new PartialDispatcherServices(\n                            configuration,\n                            highAvailabilityServices,\n                            resourceManagerGatewayRetriever,\n                            blobServer,\n                            heartbeatServices,\n                            () ->\n                                    JobManagerMetricGroup.createJobManagerMetricGroup(\n                                            metricRegistry, hostname),\n                            executionGraphInfoStore,\n                            fatalErrorHandler,\n                            historyServerArchivist,\n                            metricRegistry.getMetricQueryServiceGatewayRpcAddress(),\n                            ioExecutor,\n                            dispatcherOperationCaches,\n                            failureEnrichers);\n\n            log.debug(\"Starting Dispatcher.\");\n            dispatcherRunner =\n                    dispatcherRunnerFactory.createDispatcherRunner(\n                            highAvailabilityServices.getDispatcherLeaderElection(),\n                            fatalErrorHandler,\n                            new HaServicesJobPersistenceComponentFactory(highAvailabilityServices),\n                            ioExecutor,\n                            rpcService,\n                            partialDispatcherServices);\n\n            log.debug(\"Starting ResourceManagerService.\");\n            resourceManagerService.start();\n\n            resourceManagerRetrievalService.start(resourceManagerGatewayRetriever);\n            dispatcherLeaderRetrievalService.start(dispatcherGatewayRetriever);\n\n            return new DispatcherResourceManagerComponent(\n                    dispatcherRunner,\n                    resourceManagerService,\n                    dispatcherLeaderRetrievalService,\n                    resourceManagerRetrievalService,\n                    webMonitorEndpoint,\n                    fatalErrorHandler,\n                    dispatcherOperationCaches);\n\n        } catch (Exception exception) {\n            // clean up all started components\n            if (dispatcherLeaderRetrievalService != null) {\n                try {\n                    dispatcherLeaderRetrievalService.stop();\n                } catch (Exception e) {\n                    exception = ExceptionUtils.firstOrSuppressed(e, exception);\n                }\n            }\n\n            if (resourceManagerRetrievalService != null) {\n                try {\n                    resourceManagerRetrievalService.stop();\n                } catch (Exception e) {\n                    exception = ExceptionUtils.firstOrSuppressed(e, exception);\n                }\n            }\n\n            final Collection<CompletableFuture<Void>> terminationFutures = new ArrayList<>(3);\n\n            if (webMonitorEndpoint != null) {\n                terminationFutures.add(webMonitorEndpoint.closeAsync());\n            }\n\n            if (resourceManagerService != null) {\n                terminationFutures.add(resourceManagerService.closeAsync());\n            }\n\n            if (dispatcherRunner != null) {\n                terminationFutures.add(dispatcherRunner.closeAsync());\n            }\n\n            final FutureUtils.ConjunctFuture<Void> terminationFuture =\n                    FutureUtils.completeAll(terminationFutures);\n\n            try {\n                terminationFuture.get();\n            } catch (Exception e) {\n                exception = ExceptionUtils.firstOrSuppressed(e, exception);\n            }\n\n            throw new FlinkException(\n                    \"Could not create the DispatcherResourceManagerComponent.\", exception);\n        }\n    }\n\n    public static DefaultDispatcherResourceManagerComponentFactory createSessionComponentFactory(\n            ResourceManagerFactory<?> resourceManagerFactory) {\n        return new DefaultDispatcherResourceManagerComponentFactory(\n                DefaultDispatcherRunnerFactory.createSessionRunner(\n                        SessionDispatcherFactory.INSTANCE),\n                resourceManagerFactory,\n                SessionRestEndpointFactory.INSTANCE);\n    }\n}",
    "repo": "apache/flink",
    "path": "./datasets/diagrams-repos/apache/flink/flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/component/DefaultDispatcherResourceManagerComponentFactory.java",
    "query": "What are the class dependencies of DefaultDispatcherResourceManagerComponentFactory and how are they connected?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'DefaultDispatcherResourceManagerComponentFactory', 'node_id': 'DefaultDispatcherResourceManagerComponentFactory', 'description': 'Factory for creating DispatcherResourceManagerComponent instances', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'DispatcherResourceManagerComponent', 'node_id': 'DispatcherResourceManagerComponent', 'description': 'Main component containing dispatcher and resource manager', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'DispatcherRunner', 'node_id': 'DispatcherRunner', 'description': 'Handles dispatcher lifecycle', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'ResourceManagerService', 'node_id': 'ResourceManagerService', 'description': 'Service managing cluster resources', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'WebMonitorEndpoint', 'node_id': 'WebMonitorEndpoint', 'description': 'REST endpoint for cluster monitoring', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'DispatcherOperationCaches', 'node_id': 'DispatcherOperationCaches', 'description': 'Caches for dispatcher operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'DefaultDispatcherResourceManagerComponentFactory', 'node_id_to': 'DispatcherResourceManagerComponent', 'description': 'creates'}, {'node_id_from': 'DefaultDispatcherResourceManagerComponentFactory', 'node_id_to': 'DispatcherRunner', 'description': 'creates'}, {'node_id_from': 'DefaultDispatcherResourceManagerComponentFactory', 'node_id_to': 'ResourceManagerService', 'description': 'creates'}, {'node_id_from': 'DefaultDispatcherResourceManagerComponentFactory', 'node_id_to': 'WebMonitorEndpoint', 'description': 'creates'}, {'node_id_from': 'DefaultDispatcherResourceManagerComponentFactory', 'node_id_to': 'DispatcherOperationCaches', 'description': 'creates'}], 'packages': [{'package_id': 'component_management', 'children': ['DefaultDispatcherResourceManagerComponentFactory', 'DispatcherResourceManagerComponent'], 'description': 'Core component management'}, {'package_id': 'services', 'children': ['DispatcherRunner', 'ResourceManagerService', 'WebMonitorEndpoint', 'DispatcherOperationCaches'], 'description': 'Various services'}]}",
    "version": "medium",
    "text_answer": "DefaultDispatcherResourceManagerComponentFactory is responsible for creating and managing core cluster components. It primarily creates DispatcherResourceManagerComponent, which contains DispatcherRunner and ResourceManagerService. It also manages WebMonitorEndpoint for REST operations and various supporting services like metrics and high availability.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage org.apache.flink.runtime.entrypoint.component;\n\nimport org.apache.flink.configuration.Configuration;\nimport org.apache.flink.configuration.MetricOptions;\nimport org.apache.flink.configuration.RestOptions;\nimport org.apache.flink.core.failure.FailureEnricher;\nimport org.apache.flink.runtime.blob.BlobServer;\nimport org.apache.flink.runtime.clusterframework.types.ResourceID;\nimport org.apache.flink.runtime.dispatcher.DispatcherGateway;\nimport org.apache.flink.runtime.dispatcher.DispatcherId;\nimport org.apache.flink.runtime.dispatcher.DispatcherOperationCaches;\nimport org.apache.flink.runtime.dispatcher.ExecutionGraphInfoStore;\nimport org.apache.flink.runtime.dispatcher.HistoryServerArchivist;\nimport org.apache.flink.runtime.dispatcher.PartialDispatcherServices;\nimport org.apache.flink.runtime.dispatcher.SessionDispatcherFactory;\nimport org.apache.flink.runtime.dispatcher.runner.DefaultDispatcherRunnerFactory;\nimport org.apache.flink.runtime.dispatcher.runner.DispatcherRunner;\nimport org.apache.flink.runtime.dispatcher.runner.DispatcherRunnerFactory;\nimport org.apache.flink.runtime.entrypoint.ClusterInformation;\nimport org.apache.flink.runtime.heartbeat.HeartbeatServices;\nimport org.apache.flink.runtime.highavailability.HighAvailabilityServices;\nimport org.apache.flink.runtime.jobmanager.HaServicesJobPersistenceComponentFactory;\nimport org.apache.flink.runtime.leaderretrieval.LeaderRetrievalService;\nimport org.apache.flink.runtime.metrics.MetricRegistry;\nimport org.apache.flink.runtime.metrics.groups.JobManagerMetricGroup;\nimport org.apache.flink.runtime.resourcemanager.ResourceManagerFactory;\nimport org.apache.flink.runtime.resourcemanager.ResourceManagerGateway;\nimport org.apache.flink.runtime.resourcemanager.ResourceManagerId;\nimport org.apache.flink.runtime.resourcemanager.ResourceManagerService;\nimport org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl;\nimport org.apache.flink.runtime.rest.RestEndpointFactory;\nimport org.apache.flink.runtime.rest.SessionRestEndpointFactory;\nimport org.apache.flink.runtime.rest.handler.legacy.metrics.MetricFetcher;\nimport org.apache.flink.runtime.rest.handler.legacy.metrics.MetricFetcherImpl;\nimport org.apache.flink.runtime.rest.handler.legacy.metrics.VoidMetricFetcher;\nimport org.apache.flink.runtime.rpc.FatalErrorHandler;\nimport org.apache.flink.runtime.rpc.RpcService;\nimport org.apache.flink.runtime.rpc.RpcUtils;\nimport org.apache.flink.runtime.security.token.DelegationTokenManager;\nimport org.apache.flink.runtime.webmonitor.WebMonitorEndpoint;\nimport org.apache.flink.runtime.webmonitor.retriever.LeaderGatewayRetriever;\nimport org.apache.flink.runtime.webmonitor.retriever.MetricQueryServiceRetriever;\nimport org.apache.flink.runtime.webmonitor.retriever.impl.RpcGatewayRetriever;\nimport org.apache.flink.util.ExceptionUtils;\nimport org.apache.flink.util.FlinkException;\nimport org.apache.flink.util.concurrent.ExponentialBackoffRetryStrategy;\nimport org.apache.flink.util.concurrent.FutureUtils;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport javax.annotation.Nonnull;\n\nimport java.time.Duration;\nimport java.util.ArrayList;\nimport java.util.Collection;\nimport java.util.concurrent.CompletableFuture;\nimport java.util.concurrent.Executor;\nimport java.util.concurrent.ScheduledExecutorService;\n\n/**\n * Abstract class which implements the creation of the {@link DispatcherResourceManagerComponent}\n * components.\n */\npublic class DefaultDispatcherResourceManagerComponentFactory\n        implements DispatcherResourceManagerComponentFactory {\n\n    private final Logger log = LoggerFactory.getLogger(getClass());\n\n    @Nonnull private final DispatcherRunnerFactory dispatcherRunnerFactory;\n\n    @Nonnull private final ResourceManagerFactory<?> resourceManagerFactory;\n\n    @Nonnull private final RestEndpointFactory<?> restEndpointFactory;\n\n    public DefaultDispatcherResourceManagerComponentFactory(\n            @Nonnull DispatcherRunnerFactory dispatcherRunnerFactory,\n            @Nonnull ResourceManagerFactory<?> resourceManagerFactory,\n            @Nonnull RestEndpointFactory<?> restEndpointFactory) {\n        this.dispatcherRunnerFactory = dispatcherRunnerFactory;\n        this.resourceManagerFactory = resourceManagerFactory;\n        this.restEndpointFactory = restEndpointFactory;\n    }\n\n    @Override\n    public DispatcherResourceManagerComponent create(\n            Configuration configuration,\n            ResourceID resourceId,\n            Executor ioExecutor,\n            RpcService rpcService,\n            HighAvailabilityServices highAvailabilityServices,\n            BlobServer blobServer,\n            HeartbeatServices heartbeatServices,\n            DelegationTokenManager delegationTokenManager,\n            MetricRegistry metricRegistry,\n            ExecutionGraphInfoStore executionGraphInfoStore,\n            MetricQueryServiceRetriever metricQueryServiceRetriever,\n            Collection<FailureEnricher> failureEnrichers,\n            FatalErrorHandler fatalErrorHandler)\n            throws Exception {\n\n        LeaderRetrievalService dispatcherLeaderRetrievalService = null;\n        LeaderRetrievalService resourceManagerRetrievalService = null;\n        WebMonitorEndpoint<?> webMonitorEndpoint = null;\n        ResourceManagerService resourceManagerService = null;\n        DispatcherRunner dispatcherRunner = null;\n\n        try {\n            dispatcherLeaderRetrievalService =\n                    highAvailabilityServices.getDispatcherLeaderRetriever();\n\n            resourceManagerRetrievalService =\n                    highAvailabilityServices.getResourceManagerLeaderRetriever();\n\n            final LeaderGatewayRetriever<DispatcherGateway> dispatcherGatewayRetriever =\n                    new RpcGatewayRetriever<>(\n                            rpcService,\n                            DispatcherGateway.class,\n                            DispatcherId::fromUuid,\n                            new ExponentialBackoffRetryStrategy(\n                                    12, Duration.ofMillis(10), Duration.ofMillis(50)));\n\n            final LeaderGatewayRetriever<ResourceManagerGateway> resourceManagerGatewayRetriever =\n                    new RpcGatewayRetriever<>(\n                            rpcService,\n                            ResourceManagerGateway.class,\n                            ResourceManagerId::fromUuid,\n                            new ExponentialBackoffRetryStrategy(\n                                    12, Duration.ofMillis(10), Duration.ofMillis(50)));\n\n            final ScheduledExecutorService executor =\n                    WebMonitorEndpoint.createExecutorService(\n                            configuration.get(RestOptions.SERVER_NUM_THREADS),\n                            configuration.get(RestOptions.SERVER_THREAD_PRIORITY),\n                            \"DispatcherRestEndpoint\");\n\n            final long updateInterval =\n                    configuration.get(MetricOptions.METRIC_FETCHER_UPDATE_INTERVAL).toMillis();\n            final MetricFetcher metricFetcher =\n                    updateInterval == 0\n                            ? VoidMetricFetcher.INSTANCE\n                            : MetricFetcherImpl.fromConfiguration(\n                                    configuration,\n                                    metricQueryServiceRetriever,\n                                    dispatcherGatewayRetriever,\n                                    executor);\n\n            webMonitorEndpoint =\n                    restEndpointFactory.createRestEndpoint(\n                            configuration,\n                            dispatcherGatewayRetriever,\n                            resourceManagerGatewayRetriever,\n                            blobServer,\n                            executor,\n                            metricFetcher,\n                            highAvailabilityServices.getClusterRestEndpointLeaderElection(),\n                            fatalErrorHandler);\n\n            log.debug(\"Starting Dispatcher REST endpoint.\");\n            webMonitorEndpoint.start();\n\n            final String hostname = RpcUtils.getHostname(rpcService);\n\n            resourceManagerService =\n                    ResourceManagerServiceImpl.create(\n                            resourceManagerFactory,\n                            configuration,\n                            resourceId,\n                            rpcService,\n                            highAvailabilityServices,\n                            heartbeatServices,\n                            delegationTokenManager,\n                            fatalErrorHandler,\n                            new ClusterInformation(hostname, blobServer.getPort()),\n                            webMonitorEndpoint.getRestBaseUrl(),\n                            metricRegistry,\n                            hostname,\n                            ioExecutor);\n\n            final HistoryServerArchivist historyServerArchivist =\n                    HistoryServerArchivist.createHistoryServerArchivist(\n                            configuration, webMonitorEndpoint, ioExecutor);\n\n            final DispatcherOperationCaches dispatcherOperationCaches =\n                    new DispatcherOperationCaches(\n                            configuration.get(RestOptions.ASYNC_OPERATION_STORE_DURATION));\n\n            final PartialDispatcherServices partialDispatcherServices =\n                    new PartialDispatcherServices(\n                            configuration,\n                            highAvailabilityServices,\n                            resourceManagerGatewayRetriever,\n                            blobServer,\n                            heartbeatServices,\n                            () ->\n                                    JobManagerMetricGroup.createJobManagerMetricGroup(\n                                            metricRegistry, hostname),\n                            executionGraphInfoStore,\n                            fatalErrorHandler,\n                            historyServerArchivist,\n                            metricRegistry.getMetricQueryServiceGatewayRpcAddress(),\n                            ioExecutor,\n                            dispatcherOperationCaches,\n                            failureEnrichers);\n\n            log.debug(\"Starting Dispatcher.\");\n            dispatcherRunner =\n                    dispatcherRunnerFactory.createDispatcherRunner(\n                            highAvailabilityServices.getDispatcherLeaderElection(),\n                            fatalErrorHandler,\n                            new HaServicesJobPersistenceComponentFactory(highAvailabilityServices),\n                            ioExecutor,\n                            rpcService,\n                            partialDispatcherServices);\n\n            log.debug(\"Starting ResourceManagerService.\");\n            resourceManagerService.start();\n\n            resourceManagerRetrievalService.start(resourceManagerGatewayRetriever);\n            dispatcherLeaderRetrievalService.start(dispatcherGatewayRetriever);\n\n            return new DispatcherResourceManagerComponent(\n                    dispatcherRunner,\n                    resourceManagerService,\n                    dispatcherLeaderRetrievalService,\n                    resourceManagerRetrievalService,\n                    webMonitorEndpoint,\n                    fatalErrorHandler,\n                    dispatcherOperationCaches);\n\n        } catch (Exception exception) {\n            // clean up all started components\n            if (dispatcherLeaderRetrievalService != null) {\n                try {\n                    dispatcherLeaderRetrievalService.stop();\n                } catch (Exception e) {\n                    exception = ExceptionUtils.firstOrSuppressed(e, exception);\n                }\n            }\n\n            if (resourceManagerRetrievalService != null) {\n                try {\n                    resourceManagerRetrievalService.stop();\n                } catch (Exception e) {\n                    exception = ExceptionUtils.firstOrSuppressed(e, exception);\n                }\n            }\n\n            final Collection<CompletableFuture<Void>> terminationFutures = new ArrayList<>(3);\n\n            if (webMonitorEndpoint != null) {\n                terminationFutures.add(webMonitorEndpoint.closeAsync());\n            }\n\n            if (resourceManagerService != null) {\n                terminationFutures.add(resourceManagerService.closeAsync());\n            }\n\n            if (dispatcherRunner != null) {\n                terminationFutures.add(dispatcherRunner.closeAsync());\n            }\n\n            final FutureUtils.ConjunctFuture<Void> terminationFuture =\n                    FutureUtils.completeAll(terminationFutures);\n\n            try {\n                terminationFuture.get();\n            } catch (Exception e) {\n                exception = ExceptionUtils.firstOrSuppressed(e, exception);\n            }\n\n            throw new FlinkException(\n                    \"Could not create the DispatcherResourceManagerComponent.\", exception);\n        }\n    }\n\n    public static DefaultDispatcherResourceManagerComponentFactory createSessionComponentFactory(\n            ResourceManagerFactory<?> resourceManagerFactory) {\n        return new DefaultDispatcherResourceManagerComponentFactory(\n                DefaultDispatcherRunnerFactory.createSessionRunner(\n                        SessionDispatcherFactory.INSTANCE),\n                resourceManagerFactory,\n                SessionRestEndpointFactory.INSTANCE);\n    }\n}",
    "repo": "apache/flink",
    "path": "./datasets/diagrams-repos/apache/flink/flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/component/DefaultDispatcherResourceManagerComponentFactory.java",
    "query": "What are the class dependencies of DefaultDispatcherResourceManagerComponentFactory and how are they connected?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'DefaultDispatcherResourceManagerComponentFactory', 'node_id': 'DefaultDispatcherResourceManagerComponentFactory', 'description': 'Factory for creating DispatcherResourceManagerComponent instances', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'DispatcherResourceManagerComponent', 'node_id': 'DispatcherResourceManagerComponent', 'description': 'Main component containing dispatcher and resource manager', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'DispatcherRunner', 'node_id': 'DispatcherRunner', 'description': 'Handles dispatcher lifecycle', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'ResourceManagerService', 'node_id': 'ResourceManagerService', 'description': 'Service managing cluster resources', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'WebMonitorEndpoint', 'node_id': 'WebMonitorEndpoint', 'description': 'REST endpoint for cluster monitoring', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'DispatcherOperationCaches', 'node_id': 'DispatcherOperationCaches', 'description': 'Caches for dispatcher operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'HighAvailabilityServices', 'node_id': 'HighAvailabilityServices', 'description': 'Services for high availability', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MetricFetcher', 'node_id': 'MetricFetcher', 'description': 'Fetches metrics from the system', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'HistoryServerArchivist', 'node_id': 'HistoryServerArchivist', 'description': 'Archives job history', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'DefaultDispatcherResourceManagerComponentFactory', 'node_id_to': 'DispatcherResourceManagerComponent', 'description': 'creates'}, {'node_id_from': 'DefaultDispatcherResourceManagerComponentFactory', 'node_id_to': 'DispatcherRunner', 'description': 'creates'}, {'node_id_from': 'DefaultDispatcherResourceManagerComponentFactory', 'node_id_to': 'ResourceManagerService', 'description': 'creates'}, {'node_id_from': 'DefaultDispatcherResourceManagerComponentFactory', 'node_id_to': 'WebMonitorEndpoint', 'description': 'creates'}, {'node_id_from': 'DefaultDispatcherResourceManagerComponentFactory', 'node_id_to': 'DispatcherOperationCaches', 'description': 'creates'}, {'node_id_from': 'DefaultDispatcherResourceManagerComponentFactory', 'node_id_to': 'HighAvailabilityServices', 'description': 'uses'}, {'node_id_from': 'DefaultDispatcherResourceManagerComponentFactory', 'node_id_to': 'MetricFetcher', 'description': 'creates'}, {'node_id_from': 'DefaultDispatcherResourceManagerComponentFactory', 'node_id_to': 'HistoryServerArchivist', 'description': 'creates'}], 'packages': [{'package_id': 'component_management', 'children': ['DefaultDispatcherResourceManagerComponentFactory', 'DispatcherResourceManagerComponent'], 'description': 'Core component management'}, {'package_id': 'services', 'children': ['DispatcherRunner', 'ResourceManagerService', 'WebMonitorEndpoint', 'DispatcherOperationCaches'], 'description': 'Various services'}, {'package_id': 'monitoring', 'children': ['MetricFetcher', 'HistoryServerArchivist'], 'description': 'Monitoring and history'}]}",
    "version": "full",
    "text_answer": "DefaultDispatcherResourceManagerComponentFactory is responsible for creating and managing core cluster components. It primarily creates DispatcherResourceManagerComponent, which contains DispatcherRunner and ResourceManagerService. It also manages WebMonitorEndpoint for REST operations and various supporting services like metrics and high availability.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Python",
    "code": "\nimport re\nimport sys\n\nimport cv2\nimport numpy as np\nimport torch\n\n\ndef read_pfm(path):\n    \"\"\"Read pfm file.\n\n    Args:\n        path (str): path to file\n\n    Returns:\n        tuple: (data, scale)\n    \"\"\"\n    with open(path, \"rb\") as file:\n        color = None\n        width = None\n        height = None\n        scale = None\n        endian = None\n\n        header = file.readline().rstrip()\n        if header.decode(\"ascii\") == \"PF\":\n            color = True\n        elif header.decode(\"ascii\") == \"Pf\":\n            color = False\n        else:\n            raise Exception(\"Not a PFM file: \" + path)\n\n        dim_match = re.match(r\"^(\\d+)\\s(\\d+)\\s$\", file.readline().decode(\"ascii\"))\n        if dim_match:\n            width, height = list(map(int, dim_match.groups()))\n        else:\n            raise Exception(\"Malformed PFM header.\")\n\n        scale = float(file.readline().decode(\"ascii\").rstrip())\n        if scale < 0:\n            # little-endian\n            endian = \"<\"\n            scale = -scale\n        else:\n            # big-endian\n            endian = \">\"\n\n        data = np.fromfile(file, endian + \"f\")\n        shape = (height, width, 3) if color else (height, width)\n\n        data = np.reshape(data, shape)\n        data = np.flipud(data)\n\n        return data, scale\n\n\ndef write_pfm(path, image, scale=1):\n    \"\"\"Write pfm file.\n\n    Args:\n        path (str): pathto file\n        image (array): data\n        scale (int, optional): Scale. Defaults to 1.\n    \"\"\"\n\n    with open(path, \"wb\") as file:\n        color = None\n\n        if image.dtype.name != \"float32\":\n            raise Exception(\"Image dtype must be float32.\")\n\n        image = np.flipud(image)\n\n        if len(image.shape) == 3 and image.shape[2] == 3:  # color image\n            color = True\n        elif len(image.shape) == 2 or len(image.shape) == 3 and image.shape[2] == 1:  # greyscale\n            color = False\n        else:\n            raise Exception(\"Image must have H x W x 3, H x W x 1 or H x W dimensions.\")\n\n        file.write(\"PF\\n\" if color else \"Pf\\n\".encode())\n        file.write(\"%d %d\\n\".encode() % (image.shape[1], image.shape[0]))\n\n        endian = image.dtype.byteorder\n\n        if endian == \"<\" or endian == \"=\" and sys.byteorder == \"little\":\n            scale = -scale\n\n        file.write(\"%f\\n\".encode() % scale)\n\n        image.tofile(file)\n\n\ndef read_image(path):\n    \"\"\"Read image and output RGB image (0-1).\n\n    Args:\n        path (str): path to file\n\n    Returns:\n        array: RGB image (0-1)\n    \"\"\"\n    img = cv2.imread(path)\n\n    if img.ndim == 2:\n        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) / 255.0\n\n    return img\n\n\ndef resize_image(img):\n    \"\"\"Resize image and make it fit for network.\n\n    Args:\n        img (array): image\n\n    Returns:\n        tensor: data ready for network\n    \"\"\"\n    height_orig = img.shape[0]\n    width_orig = img.shape[1]\n\n    if width_orig > height_orig:\n        scale = width_orig / 384\n    else:\n        scale = height_orig / 384\n\n    height = (np.ceil(height_orig / scale / 32) * 32).astype(int)\n    width = (np.ceil(width_orig / scale / 32) * 32).astype(int)\n\n    img_resized = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)\n\n    img_resized = torch.from_numpy(np.transpose(img_resized, (2, 0, 1))).contiguous().float()\n    img_resized = img_resized.unsqueeze(0)\n\n    return img_resized\n\n\ndef resize_depth(depth, width, height):\n    \"\"\"Resize depth map and bring to CPU (numpy).\n\n    Args:\n        depth (tensor): depth\n        width (int): image width\n        height (int): image height\n\n    Returns:\n        array: processed depth\n    \"\"\"\n    depth = torch.squeeze(depth[0, :, :, :]).to(\"cpu\")\n\n    depth_resized = cv2.resize(depth.numpy(), (width, height), interpolation=cv2.INTER_CUBIC)\n\n    return depth_resized\n\n\ndef write_depth(path, depth, bits=1):\n    \"\"\"Write depth map to pfm and png file.\n\n    Args:\n        path (str): filepath without extension\n        depth (array): depth\n    \"\"\"\n    write_pfm(path + \".pfm\", depth.astype(np.float32))\n\n    depth_min = depth.min()\n    depth_max = depth.max()\n\n    max_val = (2 ** (8 * bits)) - 1\n\n    if depth_max - depth_min > np.finfo(\"float\").eps:\n        out = max_val * (depth - depth_min) / (depth_max - depth_min)\n    else:\n        out = np.zeros(depth.shape, dtype=depth.type)\n\n    if bits == 1:\n        cv2.imwrite(path + \".png\", out.astype(\"uint8\"))\n    elif bits == 2:\n        cv2.imwrite(path + \".png\", out.astype(\"uint16\"))\n\n    return",
    "repo": "hpcaitech/ColossalAI",
    "path": "./datasets/diagrams-repos/hpcaitech/ColossalAI/examples/images/diffusion/ldm/modules/midas/utils.py",
    "query": "What are the module dependencies and their usage in the code?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'fileOperations', 'node_id': 'fileOperations', 'description': 'Functions for file I/O operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'imageProcessing', 'node_id': 'imageProcessing', 'description': 'Functions for image and depth map processing', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'numpy', 'node_id': 'numpy', 'description': 'Library for numerical computations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'cv2', 'node_id': 'cv2', 'description': 'OpenCV library for image processing', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'torch', 'node_id': 'torch', 'description': 'PyTorch library for deep learning', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'cv2', 'node_id_to': 'numpy', 'description': 'Uses for image data conversion'}, {'node_id_from': 'torch', 'node_id_to': 'numpy', 'description': 'Uses for tensor-array conversion'}, {'node_id_from': 'fileOperations', 'node_id_to': 'numpy', 'description': 'Uses for data handling'}, {'node_id_from': 'imageProcessing', 'node_id_to': 'cv2', 'description': 'Uses for image reading, conversion and resizing'}, {'node_id_from': 'imageProcessing', 'node_id_to': 'torch', 'description': 'Uses for tensor conversion'}], 'packages': [{'package_id': 'externalDependencies', 'children': ['numpy', 'cv2', 'torch'], 'description': 'External libraries used in the project'}]}",
    "version": "minimal",
    "text_answer": "The code primarily relies on three main external libraries: numpy for numerical operations, OpenCV (cv2) for image processing, and PyTorch (torch) for tensor operations. These libraries are interconnected, with cv2 and torch both depending on numpy for data conversion. The code includes functions for file operations (PFM format) and image processing, utilizing these dependencies for various tasks such as reading, writing, and resizing images and depth maps.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Python",
    "code": "\nimport re\nimport sys\n\nimport cv2\nimport numpy as np\nimport torch\n\n\ndef read_pfm(path):\n    \"\"\"Read pfm file.\n\n    Args:\n        path (str): path to file\n\n    Returns:\n        tuple: (data, scale)\n    \"\"\"\n    with open(path, \"rb\") as file:\n        color = None\n        width = None\n        height = None\n        scale = None\n        endian = None\n\n        header = file.readline().rstrip()\n        if header.decode(\"ascii\") == \"PF\":\n            color = True\n        elif header.decode(\"ascii\") == \"Pf\":\n            color = False\n        else:\n            raise Exception(\"Not a PFM file: \" + path)\n\n        dim_match = re.match(r\"^(\\d+)\\s(\\d+)\\s$\", file.readline().decode(\"ascii\"))\n        if dim_match:\n            width, height = list(map(int, dim_match.groups()))\n        else:\n            raise Exception(\"Malformed PFM header.\")\n\n        scale = float(file.readline().decode(\"ascii\").rstrip())\n        if scale < 0:\n            # little-endian\n            endian = \"<\"\n            scale = -scale\n        else:\n            # big-endian\n            endian = \">\"\n\n        data = np.fromfile(file, endian + \"f\")\n        shape = (height, width, 3) if color else (height, width)\n\n        data = np.reshape(data, shape)\n        data = np.flipud(data)\n\n        return data, scale\n\n\ndef write_pfm(path, image, scale=1):\n    \"\"\"Write pfm file.\n\n    Args:\n        path (str): pathto file\n        image (array): data\n        scale (int, optional): Scale. Defaults to 1.\n    \"\"\"\n\n    with open(path, \"wb\") as file:\n        color = None\n\n        if image.dtype.name != \"float32\":\n            raise Exception(\"Image dtype must be float32.\")\n\n        image = np.flipud(image)\n\n        if len(image.shape) == 3 and image.shape[2] == 3:  # color image\n            color = True\n        elif len(image.shape) == 2 or len(image.shape) == 3 and image.shape[2] == 1:  # greyscale\n            color = False\n        else:\n            raise Exception(\"Image must have H x W x 3, H x W x 1 or H x W dimensions.\")\n\n        file.write(\"PF\\n\" if color else \"Pf\\n\".encode())\n        file.write(\"%d %d\\n\".encode() % (image.shape[1], image.shape[0]))\n\n        endian = image.dtype.byteorder\n\n        if endian == \"<\" or endian == \"=\" and sys.byteorder == \"little\":\n            scale = -scale\n\n        file.write(\"%f\\n\".encode() % scale)\n\n        image.tofile(file)\n\n\ndef read_image(path):\n    \"\"\"Read image and output RGB image (0-1).\n\n    Args:\n        path (str): path to file\n\n    Returns:\n        array: RGB image (0-1)\n    \"\"\"\n    img = cv2.imread(path)\n\n    if img.ndim == 2:\n        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) / 255.0\n\n    return img\n\n\ndef resize_image(img):\n    \"\"\"Resize image and make it fit for network.\n\n    Args:\n        img (array): image\n\n    Returns:\n        tensor: data ready for network\n    \"\"\"\n    height_orig = img.shape[0]\n    width_orig = img.shape[1]\n\n    if width_orig > height_orig:\n        scale = width_orig / 384\n    else:\n        scale = height_orig / 384\n\n    height = (np.ceil(height_orig / scale / 32) * 32).astype(int)\n    width = (np.ceil(width_orig / scale / 32) * 32).astype(int)\n\n    img_resized = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)\n\n    img_resized = torch.from_numpy(np.transpose(img_resized, (2, 0, 1))).contiguous().float()\n    img_resized = img_resized.unsqueeze(0)\n\n    return img_resized\n\n\ndef resize_depth(depth, width, height):\n    \"\"\"Resize depth map and bring to CPU (numpy).\n\n    Args:\n        depth (tensor): depth\n        width (int): image width\n        height (int): image height\n\n    Returns:\n        array: processed depth\n    \"\"\"\n    depth = torch.squeeze(depth[0, :, :, :]).to(\"cpu\")\n\n    depth_resized = cv2.resize(depth.numpy(), (width, height), interpolation=cv2.INTER_CUBIC)\n\n    return depth_resized\n\n\ndef write_depth(path, depth, bits=1):\n    \"\"\"Write depth map to pfm and png file.\n\n    Args:\n        path (str): filepath without extension\n        depth (array): depth\n    \"\"\"\n    write_pfm(path + \".pfm\", depth.astype(np.float32))\n\n    depth_min = depth.min()\n    depth_max = depth.max()\n\n    max_val = (2 ** (8 * bits)) - 1\n\n    if depth_max - depth_min > np.finfo(\"float\").eps:\n        out = max_val * (depth - depth_min) / (depth_max - depth_min)\n    else:\n        out = np.zeros(depth.shape, dtype=depth.type)\n\n    if bits == 1:\n        cv2.imwrite(path + \".png\", out.astype(\"uint8\"))\n    elif bits == 2:\n        cv2.imwrite(path + \".png\", out.astype(\"uint16\"))\n\n    return",
    "repo": "hpcaitech/ColossalAI",
    "path": "./datasets/diagrams-repos/hpcaitech/ColossalAI/examples/images/diffusion/ldm/modules/midas/utils.py",
    "query": "What are the module dependencies and their usage in the code?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'imageProcessing', 'node_id': 'imageProcessing', 'description': 'Functions for image and depth map processing', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'numpy', 'node_id': 'numpy', 'description': 'Library for numerical computations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'cv2', 'node_id': 'cv2', 'description': 'OpenCV library for image processing', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'torch', 'node_id': 'torch', 'description': 'PyTorch library for deep learning', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 're', 'node_id': 're', 'description': 'Regular expressions library', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'sys', 'node_id': 'sys', 'description': 'System-specific parameters and functions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'read_pfm', 'node_id': 'read_pfm', 'description': 'Reads PFM file format', 'visibility': 'public', 'return_type': 'tuple', 'params': 'path: str', 'source_class_id': None}, {'type': 'function', 'name': 'write_pfm', 'node_id': 'write_pfm', 'description': 'Writes PFM file format', 'visibility': 'public', 'return_type': 'None', 'params': 'path: str, image: array, scale: int', 'source_class_id': None}], 'edges': [{'node_id_from': 'cv2', 'node_id_to': 'numpy', 'description': 'Uses for image data conversion'}, {'node_id_from': 'torch', 'node_id_to': 'numpy', 'description': 'Uses for tensor-array conversion'}, {'node_id_from': 'read_pfm', 'node_id_to': 're', 'description': 'Uses for header parsing'}, {'node_id_from': 'read_pfm', 'node_id_to': 'numpy', 'description': 'Uses for data handling'}, {'node_id_from': 'write_pfm', 'node_id_to': 'numpy', 'description': 'Uses for data handling'}, {'node_id_from': 'write_pfm', 'node_id_to': 'sys', 'description': 'Uses for endianness check'}, {'node_id_from': 'imageProcessing', 'node_id_to': 'cv2', 'description': 'Uses for image reading, conversion and resizing'}, {'node_id_from': 'imageProcessing', 'node_id_to': 'torch', 'description': 'Uses for tensor conversion'}], 'packages': [{'package_id': 'externalDependencies', 'children': ['numpy', 'cv2', 'torch', 're', 'sys'], 'description': 'External libraries used in the project'}, {'package_id': 'fileOperations', 'children': ['read_pfm', 'write_pfm'], 'description': 'Functions for PFM file handling'}]}",
    "version": "medium",
    "text_answer": "The code primarily relies on three main external libraries: numpy for numerical operations, OpenCV (cv2) for image processing, and PyTorch (torch) for tensor operations. These libraries are interconnected, with cv2 and torch both depending on numpy for data conversion. The code includes functions for file operations (PFM format) and image processing, utilizing these dependencies for various tasks such as reading, writing, and resizing images and depth maps.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Python",
    "code": "\nimport re\nimport sys\n\nimport cv2\nimport numpy as np\nimport torch\n\n\ndef read_pfm(path):\n    \"\"\"Read pfm file.\n\n    Args:\n        path (str): path to file\n\n    Returns:\n        tuple: (data, scale)\n    \"\"\"\n    with open(path, \"rb\") as file:\n        color = None\n        width = None\n        height = None\n        scale = None\n        endian = None\n\n        header = file.readline().rstrip()\n        if header.decode(\"ascii\") == \"PF\":\n            color = True\n        elif header.decode(\"ascii\") == \"Pf\":\n            color = False\n        else:\n            raise Exception(\"Not a PFM file: \" + path)\n\n        dim_match = re.match(r\"^(\\d+)\\s(\\d+)\\s$\", file.readline().decode(\"ascii\"))\n        if dim_match:\n            width, height = list(map(int, dim_match.groups()))\n        else:\n            raise Exception(\"Malformed PFM header.\")\n\n        scale = float(file.readline().decode(\"ascii\").rstrip())\n        if scale < 0:\n            # little-endian\n            endian = \"<\"\n            scale = -scale\n        else:\n            # big-endian\n            endian = \">\"\n\n        data = np.fromfile(file, endian + \"f\")\n        shape = (height, width, 3) if color else (height, width)\n\n        data = np.reshape(data, shape)\n        data = np.flipud(data)\n\n        return data, scale\n\n\ndef write_pfm(path, image, scale=1):\n    \"\"\"Write pfm file.\n\n    Args:\n        path (str): pathto file\n        image (array): data\n        scale (int, optional): Scale. Defaults to 1.\n    \"\"\"\n\n    with open(path, \"wb\") as file:\n        color = None\n\n        if image.dtype.name != \"float32\":\n            raise Exception(\"Image dtype must be float32.\")\n\n        image = np.flipud(image)\n\n        if len(image.shape) == 3 and image.shape[2] == 3:  # color image\n            color = True\n        elif len(image.shape) == 2 or len(image.shape) == 3 and image.shape[2] == 1:  # greyscale\n            color = False\n        else:\n            raise Exception(\"Image must have H x W x 3, H x W x 1 or H x W dimensions.\")\n\n        file.write(\"PF\\n\" if color else \"Pf\\n\".encode())\n        file.write(\"%d %d\\n\".encode() % (image.shape[1], image.shape[0]))\n\n        endian = image.dtype.byteorder\n\n        if endian == \"<\" or endian == \"=\" and sys.byteorder == \"little\":\n            scale = -scale\n\n        file.write(\"%f\\n\".encode() % scale)\n\n        image.tofile(file)\n\n\ndef read_image(path):\n    \"\"\"Read image and output RGB image (0-1).\n\n    Args:\n        path (str): path to file\n\n    Returns:\n        array: RGB image (0-1)\n    \"\"\"\n    img = cv2.imread(path)\n\n    if img.ndim == 2:\n        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) / 255.0\n\n    return img\n\n\ndef resize_image(img):\n    \"\"\"Resize image and make it fit for network.\n\n    Args:\n        img (array): image\n\n    Returns:\n        tensor: data ready for network\n    \"\"\"\n    height_orig = img.shape[0]\n    width_orig = img.shape[1]\n\n    if width_orig > height_orig:\n        scale = width_orig / 384\n    else:\n        scale = height_orig / 384\n\n    height = (np.ceil(height_orig / scale / 32) * 32).astype(int)\n    width = (np.ceil(width_orig / scale / 32) * 32).astype(int)\n\n    img_resized = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)\n\n    img_resized = torch.from_numpy(np.transpose(img_resized, (2, 0, 1))).contiguous().float()\n    img_resized = img_resized.unsqueeze(0)\n\n    return img_resized\n\n\ndef resize_depth(depth, width, height):\n    \"\"\"Resize depth map and bring to CPU (numpy).\n\n    Args:\n        depth (tensor): depth\n        width (int): image width\n        height (int): image height\n\n    Returns:\n        array: processed depth\n    \"\"\"\n    depth = torch.squeeze(depth[0, :, :, :]).to(\"cpu\")\n\n    depth_resized = cv2.resize(depth.numpy(), (width, height), interpolation=cv2.INTER_CUBIC)\n\n    return depth_resized\n\n\ndef write_depth(path, depth, bits=1):\n    \"\"\"Write depth map to pfm and png file.\n\n    Args:\n        path (str): filepath without extension\n        depth (array): depth\n    \"\"\"\n    write_pfm(path + \".pfm\", depth.astype(np.float32))\n\n    depth_min = depth.min()\n    depth_max = depth.max()\n\n    max_val = (2 ** (8 * bits)) - 1\n\n    if depth_max - depth_min > np.finfo(\"float\").eps:\n        out = max_val * (depth - depth_min) / (depth_max - depth_min)\n    else:\n        out = np.zeros(depth.shape, dtype=depth.type)\n\n    if bits == 1:\n        cv2.imwrite(path + \".png\", out.astype(\"uint8\"))\n    elif bits == 2:\n        cv2.imwrite(path + \".png\", out.astype(\"uint16\"))\n\n    return",
    "repo": "hpcaitech/ColossalAI",
    "path": "./datasets/diagrams-repos/hpcaitech/ColossalAI/examples/images/diffusion/ldm/modules/midas/utils.py",
    "query": "What are the module dependencies and their usage in the code?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'numpy', 'node_id': 'numpy', 'description': 'Library for numerical computations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'cv2', 'node_id': 'cv2', 'description': 'OpenCV library for image processing', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'torch', 'node_id': 'torch', 'description': 'PyTorch library for deep learning', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 're', 'node_id': 're', 'description': 'Regular expressions library', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'sys', 'node_id': 'sys', 'description': 'System-specific parameters and functions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'read_pfm', 'node_id': 'read_pfm', 'description': 'Reads PFM file format', 'visibility': 'public', 'return_type': 'tuple', 'params': 'path: str', 'source_class_id': None}, {'type': 'function', 'name': 'write_pfm', 'node_id': 'write_pfm', 'description': 'Writes PFM file format', 'visibility': 'public', 'return_type': 'None', 'params': 'path: str, image: array, scale: int', 'source_class_id': None}, {'type': 'function', 'name': 'read_image', 'node_id': 'read_image', 'description': 'Reads and processes image file', 'visibility': 'public', 'return_type': 'array', 'params': 'path: str', 'source_class_id': None}, {'type': 'function', 'name': 'resize_image', 'node_id': 'resize_image', 'description': 'Resizes image for network input', 'visibility': 'public', 'return_type': 'tensor', 'params': 'img: array', 'source_class_id': None}, {'type': 'function', 'name': 'resize_depth', 'node_id': 'resize_depth', 'description': 'Resizes depth map', 'visibility': 'public', 'return_type': 'array', 'params': 'depth: tensor, width: int, height: int', 'source_class_id': None}, {'type': 'function', 'name': 'write_depth', 'node_id': 'write_depth', 'description': 'Writes depth map to files', 'visibility': 'public', 'return_type': 'None', 'params': 'path: str, depth: array, bits: int', 'source_class_id': None}], 'edges': [{'node_id_from': 'cv2', 'node_id_to': 'numpy', 'description': 'Uses for image data conversion'}, {'node_id_from': 'torch', 'node_id_to': 'numpy', 'description': 'Uses for tensor-array conversion'}, {'node_id_from': 'read_pfm', 'node_id_to': 're', 'description': 'Uses for header parsing'}, {'node_id_from': 'read_pfm', 'node_id_to': 'numpy', 'description': 'Uses for data handling'}, {'node_id_from': 'write_pfm', 'node_id_to': 'numpy', 'description': 'Uses for data handling'}, {'node_id_from': 'write_pfm', 'node_id_to': 'sys', 'description': 'Uses for endianness check'}, {'node_id_from': 'read_image', 'node_id_to': 'cv2', 'description': 'Uses for image reading and conversion'}, {'node_id_from': 'resize_image', 'node_id_to': 'cv2', 'description': 'Uses for image resizing'}, {'node_id_from': 'resize_image', 'node_id_to': 'torch', 'description': 'Uses for tensor conversion'}, {'node_id_from': 'resize_depth', 'node_id_to': 'cv2', 'description': 'Uses for depth map resizing'}, {'node_id_from': 'write_depth', 'node_id_to': 'write_pfm', 'description': 'Uses for PFM file writing'}, {'node_id_from': 'write_depth', 'node_id_to': 'cv2', 'description': 'Uses for PNG file writing'}], 'packages': [{'package_id': 'externalDependencies', 'children': ['numpy', 'cv2', 'torch', 're', 'sys'], 'description': 'External libraries used in the project'}, {'package_id': 'fileOperations', 'children': ['read_pfm', 'write_pfm', 'read_image', 'write_depth'], 'description': 'Functions for file I/O operations'}, {'package_id': 'imageProcessing', 'children': ['resize_image', 'resize_depth'], 'description': 'Functions for image and depth map processing'}]}",
    "version": "full",
    "text_answer": "The code primarily relies on three main external libraries: numpy for numerical operations, OpenCV (cv2) for image processing, and PyTorch (torch) for tensor operations. These libraries are interconnected, with cv2 and torch both depending on numpy for data conversion. The code includes functions for file operations (PFM format) and image processing, utilizing these dependencies for various tasks such as reading, writing, and resizing images and depth maps.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C#",
    "code": "\nusing Antlr4.Runtime.Sharpen;\nusing Antlr4.Runtime.Tree;\n\nnamespace Antlr4.Runtime.Tree\n{\n    public abstract class AbstractParseTreeVisitor<Result> : IParseTreeVisitor<Result>\n    {\n        /// <summary>\n        /// <inheritDoc/>\n        /// <p>The default implementation calls\n        /// <see cref=\"IParseTree.Accept{T}(IParseTreeVisitor{T})\"/>\n        /// on the\n        /// specified tree.</p>\n        /// </summary>\n        public virtual Result Visit(IParseTree tree)\n        {\n            return tree.Accept(this);\n        }\n\n        /// <summary>\n        /// <inheritDoc/>\n        /// <p>The default implementation initializes the aggregate result to\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.DefaultResult()\">defaultResult()</see>\n        /// . Before visiting each child, it\n        /// calls\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.ShouldVisitNextChild(IRuleNode, Result)\">shouldVisitNextChild</see>\n        /// ; if the result\n        /// is\n        /// <see langword=\"false\"/>\n        /// no more children are visited and the current aggregate\n        /// result is returned. After visiting a child, the aggregate result is\n        /// updated by calling\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.AggregateResult(Result, Result)\">aggregateResult</see>\n        /// with the\n        /// previous aggregate result and the result of visiting the child.</p>\n        /// <p>The default implementation is not safe for use in visitors that modify\n        /// the tree structure. Visitors that modify the tree should override this\n        /// method to behave properly in respect to the specific algorithm in use.</p>\n        /// </summary>\n        public virtual Result VisitChildren(IRuleNode node)\n        {\n            Result result = DefaultResult;\n            int n = node.ChildCount;\n            for (int i = 0; i < n; i++)\n            {\n                if (!ShouldVisitNextChild(node, result))\n                {\n                    break;\n                }\n                IParseTree c = node.GetChild(i);\n                Result childResult = c.Accept(this);\n                result = AggregateResult(result, childResult);\n            }\n            return result;\n        }\n\n        /// <summary>\n        /// <inheritDoc/>\n        /// <p>The default implementation returns the result of\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.DefaultResult()\">defaultResult</see>\n        /// .</p>\n        /// </summary>\n        public virtual Result VisitTerminal(ITerminalNode node)\n        {\n            return DefaultResult;\n        }\n\n        /// <summary>\n        /// <inheritDoc/>\n        /// <p>The default implementation returns the result of\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.DefaultResult()\">defaultResult</see>\n        /// .</p>\n        /// </summary>\n        public virtual Result VisitErrorNode(IErrorNode node)\n        {\n            return DefaultResult;\n        }\n\n        /// <summary>Gets the default value returned by visitor methods.</summary>\n        /// <remarks>\n        /// Gets the default value returned by visitor methods. This value is\n        /// returned by the default implementations of\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitTerminal(ITerminalNode)\">visitTerminal</see>\n        /// ,\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitErrorNode(IErrorNode)\">visitErrorNode</see>\n        /// .\n        /// The default implementation of\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitChildren(IRuleNode)\">visitChildren</see>\n        /// initializes its aggregate result to this value.\n        /// <p>The base implementation returns\n        /// <see langword=\"null\"/>\n        /// .</p>\n        /// </remarks>\n        /// <returns>The default value returned by visitor methods.</returns>\n        protected internal virtual Result DefaultResult\n        {\n            get\n            {\n                return default(Result);\n            }\n        }\n\n        /// <summary>Aggregates the results of visiting multiple children of a node.</summary>\n        /// <remarks>\n        /// Aggregates the results of visiting multiple children of a node. After\n        /// either all children are visited or\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.ShouldVisitNextChild(IRuleNode, Result)\"/>\n        /// returns\n        /// <see langword=\"false\"/>\n        /// , the aggregate value is returned as the result of\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitChildren(IRuleNode)\"/>\n        /// .\n        /// <p>The default implementation returns\n        /// <paramref name=\"nextResult\"/>\n        /// , meaning\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitChildren(IRuleNode)\"/>\n        /// will return the result of the last child visited\n        /// (or return the initial value if the node has no children).</p>\n        /// </remarks>\n        /// <param name=\"aggregate\">\n        /// The previous aggregate value. In the default\n        /// implementation, the aggregate value is initialized to\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.DefaultResult()\"/>\n        /// , which is passed as the\n        /// <paramref name=\"aggregate\"/>\n        /// argument\n        /// to this method after the first child node is visited.\n        /// </param>\n        /// <param name=\"nextResult\">\n        /// The result of the immediately preceeding call to visit\n        /// a child node.\n        /// </param>\n        /// <returns>The updated aggregate result.</returns>\n        protected internal virtual Result AggregateResult(Result aggregate, Result nextResult)\n        {\n            return nextResult;\n        }\n\n        /// <summary>\n        /// This method is called after visiting each child in\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitChildren(IRuleNode)\"/>\n        /// . This method is first called before the first\n        /// child is visited; at that point\n        /// <paramref name=\"currentResult\"/>\n        /// will be the initial\n        /// value (in the default implementation, the initial value is returned by a\n        /// call to\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.DefaultResult()\"/>\n        /// . This method is not called after the last\n        /// child is visited.\n        /// <p>The default implementation always returns\n        /// <see langword=\"true\"/>\n        /// , indicating that\n        /// <c>visitChildren</c>\n        /// should only return after all children are visited.\n        /// One reason to override this method is to provide a \"short circuit\"\n        /// evaluation option for situations where the result of visiting a single\n        /// child has the potential to determine the result of the visit operation as\n        /// a whole.</p>\n        /// </summary>\n        /// <param name=\"node\">\n        /// The\n        /// <see cref=\"IRuleNode\"/>\n        /// whose children are currently being\n        /// visited.\n        /// </param>\n        /// <param name=\"currentResult\">\n        /// The current aggregate result of the children visited\n        /// to the current point.\n        /// </param>\n        /// <returns>\n        /// \n        /// <see langword=\"true\"/>\n        /// to continue visiting children. Otherwise return\n        /// <see langword=\"false\"/>\n        /// to stop visiting children and immediately return the\n        /// current aggregate result from\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitChildren(IRuleNode)\"/>\n        /// .\n        /// </returns>\n        protected internal virtual bool ShouldVisitNextChild(IRuleNode node, Result currentResult)\n        {\n            return true;\n        }\n    }\n}",
    "repo": "microsoft/microsoft-ui-xaml",
    "path": "./datasets/diagrams-repos/microsoft/microsoft-ui-xaml/src/src/XamlCompiler/BuildTasks/Antlr4.Runtime/Tree/AbstractParseTreeVisitor.cs",
    "query": "What is the structure of the AbstractParseTreeVisitor class hierarchy?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'AbstractParseTreeVisitor', 'node_id': 'AbstractParseTreeVisitor', 'description': 'Abstract base class for parse tree visitors with generic result type', 'visibility': 'public', 'return_type': 'Result', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'IParseTreeVisitor', 'node_id': 'IParseTreeVisitor', 'description': 'Interface for parse tree visitor pattern implementation', 'visibility': 'public', 'return_type': 'Result', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'AbstractParseTreeVisitor', 'node_id_to': 'IParseTreeVisitor', 'description': 'implements'}], 'packages': [{'package_id': 'TreeVisitor', 'children': ['AbstractParseTreeVisitor', 'IParseTreeVisitor'], 'description': 'Core visitor pattern implementation'}]}",
    "version": "minimal",
    "text_answer": "AbstractParseTreeVisitor is a generic abstract class that implements IParseTreeVisitor interface, providing a base implementation of the visitor pattern for parse trees. It includes methods for traversing the tree (Visit, VisitChildren), handling specific node types (VisitTerminal, VisitErrorNode), and controlling the visitation process (ShouldVisitNextChild, AggregateResult).",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C#",
    "code": "\nusing Antlr4.Runtime.Sharpen;\nusing Antlr4.Runtime.Tree;\n\nnamespace Antlr4.Runtime.Tree\n{\n    public abstract class AbstractParseTreeVisitor<Result> : IParseTreeVisitor<Result>\n    {\n        /// <summary>\n        /// <inheritDoc/>\n        /// <p>The default implementation calls\n        /// <see cref=\"IParseTree.Accept{T}(IParseTreeVisitor{T})\"/>\n        /// on the\n        /// specified tree.</p>\n        /// </summary>\n        public virtual Result Visit(IParseTree tree)\n        {\n            return tree.Accept(this);\n        }\n\n        /// <summary>\n        /// <inheritDoc/>\n        /// <p>The default implementation initializes the aggregate result to\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.DefaultResult()\">defaultResult()</see>\n        /// . Before visiting each child, it\n        /// calls\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.ShouldVisitNextChild(IRuleNode, Result)\">shouldVisitNextChild</see>\n        /// ; if the result\n        /// is\n        /// <see langword=\"false\"/>\n        /// no more children are visited and the current aggregate\n        /// result is returned. After visiting a child, the aggregate result is\n        /// updated by calling\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.AggregateResult(Result, Result)\">aggregateResult</see>\n        /// with the\n        /// previous aggregate result and the result of visiting the child.</p>\n        /// <p>The default implementation is not safe for use in visitors that modify\n        /// the tree structure. Visitors that modify the tree should override this\n        /// method to behave properly in respect to the specific algorithm in use.</p>\n        /// </summary>\n        public virtual Result VisitChildren(IRuleNode node)\n        {\n            Result result = DefaultResult;\n            int n = node.ChildCount;\n            for (int i = 0; i < n; i++)\n            {\n                if (!ShouldVisitNextChild(node, result))\n                {\n                    break;\n                }\n                IParseTree c = node.GetChild(i);\n                Result childResult = c.Accept(this);\n                result = AggregateResult(result, childResult);\n            }\n            return result;\n        }\n\n        /// <summary>\n        /// <inheritDoc/>\n        /// <p>The default implementation returns the result of\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.DefaultResult()\">defaultResult</see>\n        /// .</p>\n        /// </summary>\n        public virtual Result VisitTerminal(ITerminalNode node)\n        {\n            return DefaultResult;\n        }\n\n        /// <summary>\n        /// <inheritDoc/>\n        /// <p>The default implementation returns the result of\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.DefaultResult()\">defaultResult</see>\n        /// .</p>\n        /// </summary>\n        public virtual Result VisitErrorNode(IErrorNode node)\n        {\n            return DefaultResult;\n        }\n\n        /// <summary>Gets the default value returned by visitor methods.</summary>\n        /// <remarks>\n        /// Gets the default value returned by visitor methods. This value is\n        /// returned by the default implementations of\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitTerminal(ITerminalNode)\">visitTerminal</see>\n        /// ,\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitErrorNode(IErrorNode)\">visitErrorNode</see>\n        /// .\n        /// The default implementation of\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitChildren(IRuleNode)\">visitChildren</see>\n        /// initializes its aggregate result to this value.\n        /// <p>The base implementation returns\n        /// <see langword=\"null\"/>\n        /// .</p>\n        /// </remarks>\n        /// <returns>The default value returned by visitor methods.</returns>\n        protected internal virtual Result DefaultResult\n        {\n            get\n            {\n                return default(Result);\n            }\n        }\n\n        /// <summary>Aggregates the results of visiting multiple children of a node.</summary>\n        /// <remarks>\n        /// Aggregates the results of visiting multiple children of a node. After\n        /// either all children are visited or\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.ShouldVisitNextChild(IRuleNode, Result)\"/>\n        /// returns\n        /// <see langword=\"false\"/>\n        /// , the aggregate value is returned as the result of\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitChildren(IRuleNode)\"/>\n        /// .\n        /// <p>The default implementation returns\n        /// <paramref name=\"nextResult\"/>\n        /// , meaning\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitChildren(IRuleNode)\"/>\n        /// will return the result of the last child visited\n        /// (or return the initial value if the node has no children).</p>\n        /// </remarks>\n        /// <param name=\"aggregate\">\n        /// The previous aggregate value. In the default\n        /// implementation, the aggregate value is initialized to\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.DefaultResult()\"/>\n        /// , which is passed as the\n        /// <paramref name=\"aggregate\"/>\n        /// argument\n        /// to this method after the first child node is visited.\n        /// </param>\n        /// <param name=\"nextResult\">\n        /// The result of the immediately preceeding call to visit\n        /// a child node.\n        /// </param>\n        /// <returns>The updated aggregate result.</returns>\n        protected internal virtual Result AggregateResult(Result aggregate, Result nextResult)\n        {\n            return nextResult;\n        }\n\n        /// <summary>\n        /// This method is called after visiting each child in\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitChildren(IRuleNode)\"/>\n        /// . This method is first called before the first\n        /// child is visited; at that point\n        /// <paramref name=\"currentResult\"/>\n        /// will be the initial\n        /// value (in the default implementation, the initial value is returned by a\n        /// call to\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.DefaultResult()\"/>\n        /// . This method is not called after the last\n        /// child is visited.\n        /// <p>The default implementation always returns\n        /// <see langword=\"true\"/>\n        /// , indicating that\n        /// <c>visitChildren</c>\n        /// should only return after all children are visited.\n        /// One reason to override this method is to provide a \"short circuit\"\n        /// evaluation option for situations where the result of visiting a single\n        /// child has the potential to determine the result of the visit operation as\n        /// a whole.</p>\n        /// </summary>\n        /// <param name=\"node\">\n        /// The\n        /// <see cref=\"IRuleNode\"/>\n        /// whose children are currently being\n        /// visited.\n        /// </param>\n        /// <param name=\"currentResult\">\n        /// The current aggregate result of the children visited\n        /// to the current point.\n        /// </param>\n        /// <returns>\n        /// \n        /// <see langword=\"true\"/>\n        /// to continue visiting children. Otherwise return\n        /// <see langword=\"false\"/>\n        /// to stop visiting children and immediately return the\n        /// current aggregate result from\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitChildren(IRuleNode)\"/>\n        /// .\n        /// </returns>\n        protected internal virtual bool ShouldVisitNextChild(IRuleNode node, Result currentResult)\n        {\n            return true;\n        }\n    }\n}",
    "repo": "microsoft/microsoft-ui-xaml",
    "path": "./datasets/diagrams-repos/microsoft/microsoft-ui-xaml/src/src/XamlCompiler/BuildTasks/Antlr4.Runtime/Tree/AbstractParseTreeVisitor.cs",
    "query": "What is the structure of the AbstractParseTreeVisitor class hierarchy?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'AbstractParseTreeVisitor', 'node_id': 'AbstractParseTreeVisitor', 'description': 'Abstract base class for parse tree visitors with generic result type', 'visibility': 'public', 'return_type': 'Result', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'IParseTreeVisitor', 'node_id': 'IParseTreeVisitor', 'description': 'Interface for parse tree visitor pattern implementation', 'visibility': 'public', 'return_type': 'Result', 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'Visit', 'node_id': 'Visit', 'description': 'Main visit method for parse tree traversal', 'visibility': 'public', 'return_type': 'Result', 'params': 'IParseTree tree', 'source_class_id': 'AbstractParseTreeVisitor'}, {'type': 'method', 'name': 'VisitChildren', 'node_id': 'VisitChildren', 'description': 'Visits all children of a rule node', 'visibility': 'public', 'return_type': 'Result', 'params': 'IRuleNode node', 'source_class_id': 'AbstractParseTreeVisitor'}, {'type': 'method', 'name': 'DefaultResult', 'node_id': 'DefaultResult', 'description': 'Gets default value for visitor methods', 'visibility': 'package private', 'return_type': 'Result', 'params': '', 'source_class_id': 'AbstractParseTreeVisitor'}], 'edges': [{'node_id_from': 'AbstractParseTreeVisitor', 'node_id_to': 'IParseTreeVisitor', 'description': 'implements'}, {'node_id_from': 'AbstractParseTreeVisitor', 'node_id_to': 'Visit', 'description': ''}, {'node_id_from': 'AbstractParseTreeVisitor', 'node_id_to': 'VisitChildren', 'description': ''}, {'node_id_from': 'AbstractParseTreeVisitor', 'node_id_to': 'DefaultResult', 'description': ''}], 'packages': [{'package_id': 'TreeVisitor', 'children': ['AbstractParseTreeVisitor', 'IParseTreeVisitor', 'VisitorMethods'], 'description': 'Core visitor pattern implementation'}, {'package_id': 'VisitorMethods', 'children': ['Visit', 'VisitChildren', 'DefaultResult'], 'description': 'Main visitor pattern methods'}]}",
    "version": "medium",
    "text_answer": "AbstractParseTreeVisitor is a generic abstract class that implements IParseTreeVisitor interface, providing a base implementation of the visitor pattern for parse trees. It includes methods for traversing the tree (Visit, VisitChildren), handling specific node types (VisitTerminal, VisitErrorNode), and controlling the visitation process (ShouldVisitNextChild, AggregateResult).",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C#",
    "code": "\nusing Antlr4.Runtime.Sharpen;\nusing Antlr4.Runtime.Tree;\n\nnamespace Antlr4.Runtime.Tree\n{\n    public abstract class AbstractParseTreeVisitor<Result> : IParseTreeVisitor<Result>\n    {\n        /// <summary>\n        /// <inheritDoc/>\n        /// <p>The default implementation calls\n        /// <see cref=\"IParseTree.Accept{T}(IParseTreeVisitor{T})\"/>\n        /// on the\n        /// specified tree.</p>\n        /// </summary>\n        public virtual Result Visit(IParseTree tree)\n        {\n            return tree.Accept(this);\n        }\n\n        /// <summary>\n        /// <inheritDoc/>\n        /// <p>The default implementation initializes the aggregate result to\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.DefaultResult()\">defaultResult()</see>\n        /// . Before visiting each child, it\n        /// calls\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.ShouldVisitNextChild(IRuleNode, Result)\">shouldVisitNextChild</see>\n        /// ; if the result\n        /// is\n        /// <see langword=\"false\"/>\n        /// no more children are visited and the current aggregate\n        /// result is returned. After visiting a child, the aggregate result is\n        /// updated by calling\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.AggregateResult(Result, Result)\">aggregateResult</see>\n        /// with the\n        /// previous aggregate result and the result of visiting the child.</p>\n        /// <p>The default implementation is not safe for use in visitors that modify\n        /// the tree structure. Visitors that modify the tree should override this\n        /// method to behave properly in respect to the specific algorithm in use.</p>\n        /// </summary>\n        public virtual Result VisitChildren(IRuleNode node)\n        {\n            Result result = DefaultResult;\n            int n = node.ChildCount;\n            for (int i = 0; i < n; i++)\n            {\n                if (!ShouldVisitNextChild(node, result))\n                {\n                    break;\n                }\n                IParseTree c = node.GetChild(i);\n                Result childResult = c.Accept(this);\n                result = AggregateResult(result, childResult);\n            }\n            return result;\n        }\n\n        /// <summary>\n        /// <inheritDoc/>\n        /// <p>The default implementation returns the result of\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.DefaultResult()\">defaultResult</see>\n        /// .</p>\n        /// </summary>\n        public virtual Result VisitTerminal(ITerminalNode node)\n        {\n            return DefaultResult;\n        }\n\n        /// <summary>\n        /// <inheritDoc/>\n        /// <p>The default implementation returns the result of\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.DefaultResult()\">defaultResult</see>\n        /// .</p>\n        /// </summary>\n        public virtual Result VisitErrorNode(IErrorNode node)\n        {\n            return DefaultResult;\n        }\n\n        /// <summary>Gets the default value returned by visitor methods.</summary>\n        /// <remarks>\n        /// Gets the default value returned by visitor methods. This value is\n        /// returned by the default implementations of\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitTerminal(ITerminalNode)\">visitTerminal</see>\n        /// ,\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitErrorNode(IErrorNode)\">visitErrorNode</see>\n        /// .\n        /// The default implementation of\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitChildren(IRuleNode)\">visitChildren</see>\n        /// initializes its aggregate result to this value.\n        /// <p>The base implementation returns\n        /// <see langword=\"null\"/>\n        /// .</p>\n        /// </remarks>\n        /// <returns>The default value returned by visitor methods.</returns>\n        protected internal virtual Result DefaultResult\n        {\n            get\n            {\n                return default(Result);\n            }\n        }\n\n        /// <summary>Aggregates the results of visiting multiple children of a node.</summary>\n        /// <remarks>\n        /// Aggregates the results of visiting multiple children of a node. After\n        /// either all children are visited or\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.ShouldVisitNextChild(IRuleNode, Result)\"/>\n        /// returns\n        /// <see langword=\"false\"/>\n        /// , the aggregate value is returned as the result of\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitChildren(IRuleNode)\"/>\n        /// .\n        /// <p>The default implementation returns\n        /// <paramref name=\"nextResult\"/>\n        /// , meaning\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitChildren(IRuleNode)\"/>\n        /// will return the result of the last child visited\n        /// (or return the initial value if the node has no children).</p>\n        /// </remarks>\n        /// <param name=\"aggregate\">\n        /// The previous aggregate value. In the default\n        /// implementation, the aggregate value is initialized to\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.DefaultResult()\"/>\n        /// , which is passed as the\n        /// <paramref name=\"aggregate\"/>\n        /// argument\n        /// to this method after the first child node is visited.\n        /// </param>\n        /// <param name=\"nextResult\">\n        /// The result of the immediately preceeding call to visit\n        /// a child node.\n        /// </param>\n        /// <returns>The updated aggregate result.</returns>\n        protected internal virtual Result AggregateResult(Result aggregate, Result nextResult)\n        {\n            return nextResult;\n        }\n\n        /// <summary>\n        /// This method is called after visiting each child in\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitChildren(IRuleNode)\"/>\n        /// . This method is first called before the first\n        /// child is visited; at that point\n        /// <paramref name=\"currentResult\"/>\n        /// will be the initial\n        /// value (in the default implementation, the initial value is returned by a\n        /// call to\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.DefaultResult()\"/>\n        /// . This method is not called after the last\n        /// child is visited.\n        /// <p>The default implementation always returns\n        /// <see langword=\"true\"/>\n        /// , indicating that\n        /// <c>visitChildren</c>\n        /// should only return after all children are visited.\n        /// One reason to override this method is to provide a \"short circuit\"\n        /// evaluation option for situations where the result of visiting a single\n        /// child has the potential to determine the result of the visit operation as\n        /// a whole.</p>\n        /// </summary>\n        /// <param name=\"node\">\n        /// The\n        /// <see cref=\"IRuleNode\"/>\n        /// whose children are currently being\n        /// visited.\n        /// </param>\n        /// <param name=\"currentResult\">\n        /// The current aggregate result of the children visited\n        /// to the current point.\n        /// </param>\n        /// <returns>\n        /// \n        /// <see langword=\"true\"/>\n        /// to continue visiting children. Otherwise return\n        /// <see langword=\"false\"/>\n        /// to stop visiting children and immediately return the\n        /// current aggregate result from\n        /// <see cref=\"AbstractParseTreeVisitor{Result}.VisitChildren(IRuleNode)\"/>\n        /// .\n        /// </returns>\n        protected internal virtual bool ShouldVisitNextChild(IRuleNode node, Result currentResult)\n        {\n            return true;\n        }\n    }\n}",
    "repo": "microsoft/microsoft-ui-xaml",
    "path": "./datasets/diagrams-repos/microsoft/microsoft-ui-xaml/src/src/XamlCompiler/BuildTasks/Antlr4.Runtime/Tree/AbstractParseTreeVisitor.cs",
    "query": "What is the structure of the AbstractParseTreeVisitor class hierarchy?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'AbstractParseTreeVisitor', 'node_id': 'AbstractParseTreeVisitor', 'description': 'Abstract base class for parse tree visitors with generic result type', 'visibility': 'public', 'return_type': 'Result', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'IParseTreeVisitor', 'node_id': 'IParseTreeVisitor', 'description': 'Interface for parse tree visitor pattern implementation', 'visibility': 'public', 'return_type': 'Result', 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'Visit', 'node_id': 'Visit', 'description': 'Main visit method for parse tree traversal', 'visibility': 'public', 'return_type': 'Result', 'params': 'IParseTree tree', 'source_class_id': 'AbstractParseTreeVisitor'}, {'type': 'method', 'name': 'VisitChildren', 'node_id': 'VisitChildren', 'description': 'Visits all children of a rule node', 'visibility': 'public', 'return_type': 'Result', 'params': 'IRuleNode node', 'source_class_id': 'AbstractParseTreeVisitor'}, {'type': 'method', 'name': 'VisitTerminal', 'node_id': 'VisitTerminal', 'description': 'Visits terminal node', 'visibility': 'public', 'return_type': 'Result', 'params': 'ITerminalNode node', 'source_class_id': 'AbstractParseTreeVisitor'}, {'type': 'method', 'name': 'VisitErrorNode', 'node_id': 'VisitErrorNode', 'description': 'Visits error node', 'visibility': 'public', 'return_type': 'Result', 'params': 'IErrorNode node', 'source_class_id': 'AbstractParseTreeVisitor'}, {'type': 'method', 'name': 'DefaultResult', 'node_id': 'DefaultResult', 'description': 'Gets default value for visitor methods', 'visibility': 'package private', 'return_type': 'Result', 'params': '', 'source_class_id': 'AbstractParseTreeVisitor'}, {'type': 'method', 'name': 'AggregateResult', 'node_id': 'AggregateResult', 'description': 'Aggregates results of visiting multiple children', 'visibility': 'package private', 'return_type': 'Result', 'params': 'Result aggregate, Result nextResult', 'source_class_id': 'AbstractParseTreeVisitor'}, {'type': 'method', 'name': 'ShouldVisitNextChild', 'node_id': 'ShouldVisitNextChild', 'description': 'Controls child visitation process', 'visibility': 'package private', 'return_type': 'bool', 'params': 'IRuleNode node, Result currentResult', 'source_class_id': 'AbstractParseTreeVisitor'}], 'edges': [{'node_id_from': 'AbstractParseTreeVisitor', 'node_id_to': 'IParseTreeVisitor', 'description': 'implements'}, {'node_id_from': 'AbstractParseTreeVisitor', 'node_id_to': 'Visit', 'description': ''}, {'node_id_from': 'AbstractParseTreeVisitor', 'node_id_to': 'VisitChildren', 'description': ''}, {'node_id_from': 'AbstractParseTreeVisitor', 'node_id_to': 'DefaultResult', 'description': ''}, {'node_id_from': 'AbstractParseTreeVisitor', 'node_id_to': 'VisitTerminal', 'description': ''}, {'node_id_from': 'AbstractParseTreeVisitor', 'node_id_to': 'VisitErrorNode', 'description': ''}, {'node_id_from': 'AbstractParseTreeVisitor', 'node_id_to': 'AggregateResult', 'description': ''}, {'node_id_from': 'AbstractParseTreeVisitor', 'node_id_to': 'ShouldVisitNextChild', 'description': ''}], 'packages': [{'package_id': 'TreeVisitor', 'children': ['AbstractParseTreeVisitor', 'IParseTreeVisitor', 'PublicVisitorMethods', 'ProtectedVisitorMethods'], 'description': 'Core visitor pattern implementation'}, {'package_id': 'PublicVisitorMethods', 'children': ['Visit', 'VisitChildren', 'VisitTerminal', 'VisitErrorNode'], 'description': 'Public visitor pattern methods'}, {'package_id': 'ProtectedVisitorMethods', 'children': ['DefaultResult', 'AggregateResult', 'ShouldVisitNextChild'], 'description': 'Protected visitor pattern methods'}]}",
    "version": "full",
    "text_answer": "AbstractParseTreeVisitor is a generic abstract class that implements IParseTreeVisitor interface, providing a base implementation of the visitor pattern for parse trees. It includes methods for traversing the tree (Visit, VisitChildren), handling specific node types (VisitTerminal, VisitErrorNode), and controlling the visitation process (ShouldVisitNextChild, AggregateResult).",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nimport {css, html, QwcHotReloadElement} from 'qwc-hot-reload-element';\nimport {JsonRpc} from 'jsonrpc';\n\nimport '@vaadin/details';\nimport '@vaadin/horizontal-layout';\nimport 'echarts-gauge-grade';\nimport 'qui-badge';\nimport 'qwc-no-data';\n\n/**\n * This component shows the Rest Easy Reactive Endpoint scores\n */\nexport class QwcResteasyReactiveEndpointScores extends QwcHotReloadElement {\n    jsonRpc = new JsonRpc(this);\n\n    static styles = css`\n        \n        .heading{\n            display: flex;\n            gap: 20px;\n            width: 100em;\n            padding: 20px;\n            background: var(--lumo-contrast-5pct);\n            border-bottom: 1px solid var(--lumo-contrast-10pct);\n        }\n        .details {\n            display: flex;\n            flex-direction: column;\n            gap: 20px;\n        }\n        .diagnostics {\n            display: flex;\n            justify-content: space-evenly;\n            gap: 20px;\n            height: 350px;\n        }\n        .diagnosticsText {\n            display: flex;\n            justify-content: space-evenly;\n            gap: 20px;\n        }\n        .diagnostic {\n            display: flex;\n            flex-direction: column;\n            gap: 10px;\n            width: 100%;\n        }\n        .diagnosticText {\n            display: flex;\n            flex-direction: column;\n            gap: 10px;\n            width: 33%;\n            overflow-wrap: break-word;\n        }\n    \n        .information {\n            border-top: 1px solid var(--lumo-contrast-10pct);\n            display: flex;\n            flex-direction: column;\n            gap: 10px;\n        }\n        .message {\n            text-align: center;\n            padding-left: 20px;\n            padding-right: 20px;\n            color: var(--lumo-contrast-70pct);\n        }\n        .infoTable {\n            border: none;\n        }\n        .col1{\n            text-align: right;\n            width: 200px;\n            font-weight: bolder;\n        }\n        \n        .httpMethod{\n            color: var(--lumo-primary-text-color);\n        }\n    `;\n\n    static properties = {\n        _latestScores: {state: true}\n    };\n\n    constructor() {\n        super();\n        this._latestScores = null;\n    }\n\n    connectedCallback() {\n        super.connectedCallback();\n        this.hotReload();\n    }\n\n    render() {\n        if(this._latestScores){\n            if(this._latestScores.endpoints){\n                return html`${this._latestScores.endpoints.map(endpoint=>{\n                    return html`${this._renderEndpoint(endpoint)}`;\n                })}`;\n            }\n        }\n        return html`<qwc-no-data message=\"You do not have any REST endpoints.\" \n                                    link=\"https://quarkus.io/guides/resteasy-reactive\"\n                                    linkText=\"Learn how to write REST Services with Quarkus REST\">\n                </qwc-no-data>\n            `;\n    }\n\n    _renderEndpoint(endpoint){\n        let level = this._getLevel(endpoint.score);\n        \n        return html`\n            <vaadin-details opened theme=\"reverse\">\n                \n                <div class=\"heading\" slot=\"summary\">\n                    <qui-badge level='${level}'><span>${endpoint.score}/100</span></qui-badge>\n                    <div>\n                        <code class=\"httpMethod\">${endpoint.httpMethod}</code> <code>${endpoint.fullPath}</code>\n                    </div>\n                    \n                </div>\n                \n                <div class=\"details\">\n                    ${this._renderDiagnostics(endpoint.diagnostics)}\n                    ${this._renderInformation(endpoint)}\n                </div>\n          </vaadin-details>`;\n    }\n\n    _renderDiagnostics(diagnostics){\n        const map = new Map(Object.entries(diagnostics));\n        const graphTemplates = [];\n        const textTemplates = [];\n        for (let [key, value] of map) {\n            graphTemplates.push(html`${this._renderDiagnosticGraph(value, key)}`);\n            textTemplates.push(html`${this._renderDiagnosticText(value)}`);\n        }\n\n        return html`<div class=\"diagnostics\">\n                        ${graphTemplates}\n                    </div>\n                    <div class=\"diagnosticsText\">\n                        ${textTemplates}\n                    </div>`;\n    }\n\n    _renderDiagnosticGraph(diagnostic, heading){\n        let score = diagnostic[0].score;\n        let level = this._getLevel(score);\n        \n        return html`<div class=\"diagnostic\">\n                        <echarts-gauge-grade \n                            title=\"${heading}\" \n                            percentage=\"${score}\"\n                            sectionColors=\"--lumo-${level}-color\">\n                        </echarts-gauge-grade>    \n                    </div>`;\n    }\n    \n    _renderDiagnosticText(diagnostic){\n        let whatToDo = html``;\n        \n        return html`<div class=\"diagnosticText\">\n                        <div class=\"message\">${diagnostic[0].message}</div>\n                    </div>`;\n    }\n    \n    _renderInformation(endpoint){\n        return html`<div class=\"information\">\n                        <table class=\"infoTable\">\n                            ${this._renderMediaType(\"Produces\", endpoint.producesHeaders)}\n                            ${this._renderMediaType(\"Consumes\", endpoint.consumesHeaders)}\n                    \n                            <tr>\n                                <td class=\"col1\">Resource Class:</td>\n                                <td>${endpoint.className}</td>\n                            </tr>\n                        </table>\n                    </div>`;\n    }\n\n    _renderMediaType(type,mediaType) {\n        if(mediaType && mediaType.length>0){\n            return html`<tr>\n                            <td class=\"col1\">${type}:</td>\n                            <td>${mediaType.map(mt=>\n                                html`<qui-badge><span>${mt}</span></qui-badge>`\n                            )}</td>\n                        </tr>`;\n        }\n    }\n\n    _getLevel(score){\n        let level = \"error\";\n        if(score === 66){\n            level = \"warning\";\n        }else if(score === 100){\n            level = \"success\";\n        }\n        return level;\n    }\n\n    hotReload(){\n        this._latestScores = null;\n        this.jsonRpc.getEndpointScores().then(endpointScores => {\n            this._latestScores = endpointScores.result;\n        });\n    }\n\n}\ncustomElements.define('qwc-resteasy-reactive-endpoint-scores', QwcResteasyReactiveEndpointScores);",
    "repo": "quarkusio/quarkus",
    "path": "./datasets/diagrams-repos/quarkusio/quarkus/extensions/resteasy-reactive/rest/deployment/src/main/resources/dev-ui/qwc-resteasy-reactive-endpoint-scores.js",
    "query": "What is the relationship between the CSS classes and how do they contribute to the layout?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'heading', 'node_id': 'heading', 'description': 'Main container for endpoint header with flex layout', 'visibility': 'public', 'return_type': 'CSS class', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'details', 'node_id': 'details', 'description': 'Container for endpoint details with column layout', 'visibility': 'public', 'return_type': 'CSS class', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'diagnostics', 'node_id': 'diagnostics', 'description': 'Container for diagnostic graphs with evenly spaced layout', 'visibility': 'public', 'return_type': 'CSS class', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'heading', 'node_id_to': 'details', 'description': 'contains'}, {'node_id_from': 'details', 'node_id_to': 'diagnostics', 'description': 'contains'}], 'packages': [{'package_id': 'mainLayout', 'children': ['heading', 'details', 'diagnostics'], 'description': 'Core layout structure'}]}",
    "version": "minimal",
    "text_answer": "The CSS classes form a hierarchical layout structure where 'heading' contains the endpoint header, followed by 'details' which organizes three main sections: diagnostics (graphs), diagnosticsText (explanations), and information (endpoint metadata). Each section uses flex layouts with specific directions (row/column) and spacing to create a clean, organized interface.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nimport {css, html, QwcHotReloadElement} from 'qwc-hot-reload-element';\nimport {JsonRpc} from 'jsonrpc';\n\nimport '@vaadin/details';\nimport '@vaadin/horizontal-layout';\nimport 'echarts-gauge-grade';\nimport 'qui-badge';\nimport 'qwc-no-data';\n\n/**\n * This component shows the Rest Easy Reactive Endpoint scores\n */\nexport class QwcResteasyReactiveEndpointScores extends QwcHotReloadElement {\n    jsonRpc = new JsonRpc(this);\n\n    static styles = css`\n        \n        .heading{\n            display: flex;\n            gap: 20px;\n            width: 100em;\n            padding: 20px;\n            background: var(--lumo-contrast-5pct);\n            border-bottom: 1px solid var(--lumo-contrast-10pct);\n        }\n        .details {\n            display: flex;\n            flex-direction: column;\n            gap: 20px;\n        }\n        .diagnostics {\n            display: flex;\n            justify-content: space-evenly;\n            gap: 20px;\n            height: 350px;\n        }\n        .diagnosticsText {\n            display: flex;\n            justify-content: space-evenly;\n            gap: 20px;\n        }\n        .diagnostic {\n            display: flex;\n            flex-direction: column;\n            gap: 10px;\n            width: 100%;\n        }\n        .diagnosticText {\n            display: flex;\n            flex-direction: column;\n            gap: 10px;\n            width: 33%;\n            overflow-wrap: break-word;\n        }\n    \n        .information {\n            border-top: 1px solid var(--lumo-contrast-10pct);\n            display: flex;\n            flex-direction: column;\n            gap: 10px;\n        }\n        .message {\n            text-align: center;\n            padding-left: 20px;\n            padding-right: 20px;\n            color: var(--lumo-contrast-70pct);\n        }\n        .infoTable {\n            border: none;\n        }\n        .col1{\n            text-align: right;\n            width: 200px;\n            font-weight: bolder;\n        }\n        \n        .httpMethod{\n            color: var(--lumo-primary-text-color);\n        }\n    `;\n\n    static properties = {\n        _latestScores: {state: true}\n    };\n\n    constructor() {\n        super();\n        this._latestScores = null;\n    }\n\n    connectedCallback() {\n        super.connectedCallback();\n        this.hotReload();\n    }\n\n    render() {\n        if(this._latestScores){\n            if(this._latestScores.endpoints){\n                return html`${this._latestScores.endpoints.map(endpoint=>{\n                    return html`${this._renderEndpoint(endpoint)}`;\n                })}`;\n            }\n        }\n        return html`<qwc-no-data message=\"You do not have any REST endpoints.\" \n                                    link=\"https://quarkus.io/guides/resteasy-reactive\"\n                                    linkText=\"Learn how to write REST Services with Quarkus REST\">\n                </qwc-no-data>\n            `;\n    }\n\n    _renderEndpoint(endpoint){\n        let level = this._getLevel(endpoint.score);\n        \n        return html`\n            <vaadin-details opened theme=\"reverse\">\n                \n                <div class=\"heading\" slot=\"summary\">\n                    <qui-badge level='${level}'><span>${endpoint.score}/100</span></qui-badge>\n                    <div>\n                        <code class=\"httpMethod\">${endpoint.httpMethod}</code> <code>${endpoint.fullPath}</code>\n                    </div>\n                    \n                </div>\n                \n                <div class=\"details\">\n                    ${this._renderDiagnostics(endpoint.diagnostics)}\n                    ${this._renderInformation(endpoint)}\n                </div>\n          </vaadin-details>`;\n    }\n\n    _renderDiagnostics(diagnostics){\n        const map = new Map(Object.entries(diagnostics));\n        const graphTemplates = [];\n        const textTemplates = [];\n        for (let [key, value] of map) {\n            graphTemplates.push(html`${this._renderDiagnosticGraph(value, key)}`);\n            textTemplates.push(html`${this._renderDiagnosticText(value)}`);\n        }\n\n        return html`<div class=\"diagnostics\">\n                        ${graphTemplates}\n                    </div>\n                    <div class=\"diagnosticsText\">\n                        ${textTemplates}\n                    </div>`;\n    }\n\n    _renderDiagnosticGraph(diagnostic, heading){\n        let score = diagnostic[0].score;\n        let level = this._getLevel(score);\n        \n        return html`<div class=\"diagnostic\">\n                        <echarts-gauge-grade \n                            title=\"${heading}\" \n                            percentage=\"${score}\"\n                            sectionColors=\"--lumo-${level}-color\">\n                        </echarts-gauge-grade>    \n                    </div>`;\n    }\n    \n    _renderDiagnosticText(diagnostic){\n        let whatToDo = html``;\n        \n        return html`<div class=\"diagnosticText\">\n                        <div class=\"message\">${diagnostic[0].message}</div>\n                    </div>`;\n    }\n    \n    _renderInformation(endpoint){\n        return html`<div class=\"information\">\n                        <table class=\"infoTable\">\n                            ${this._renderMediaType(\"Produces\", endpoint.producesHeaders)}\n                            ${this._renderMediaType(\"Consumes\", endpoint.consumesHeaders)}\n                    \n                            <tr>\n                                <td class=\"col1\">Resource Class:</td>\n                                <td>${endpoint.className}</td>\n                            </tr>\n                        </table>\n                    </div>`;\n    }\n\n    _renderMediaType(type,mediaType) {\n        if(mediaType && mediaType.length>0){\n            return html`<tr>\n                            <td class=\"col1\">${type}:</td>\n                            <td>${mediaType.map(mt=>\n                                html`<qui-badge><span>${mt}</span></qui-badge>`\n                            )}</td>\n                        </tr>`;\n        }\n    }\n\n    _getLevel(score){\n        let level = \"error\";\n        if(score === 66){\n            level = \"warning\";\n        }else if(score === 100){\n            level = \"success\";\n        }\n        return level;\n    }\n\n    hotReload(){\n        this._latestScores = null;\n        this.jsonRpc.getEndpointScores().then(endpointScores => {\n            this._latestScores = endpointScores.result;\n        });\n    }\n\n}\ncustomElements.define('qwc-resteasy-reactive-endpoint-scores', QwcResteasyReactiveEndpointScores);",
    "repo": "quarkusio/quarkus",
    "path": "./datasets/diagrams-repos/quarkusio/quarkus/extensions/resteasy-reactive/rest/deployment/src/main/resources/dev-ui/qwc-resteasy-reactive-endpoint-scores.js",
    "query": "What is the relationship between the CSS classes and how do they contribute to the layout?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'heading', 'node_id': 'heading', 'description': 'Main container for endpoint header with flex layout', 'visibility': 'public', 'return_type': 'CSS class', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'details', 'node_id': 'details', 'description': 'Container for endpoint details with column layout', 'visibility': 'public', 'return_type': 'CSS class', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'diagnostics', 'node_id': 'diagnostics', 'description': 'Container for diagnostic graphs with evenly spaced layout', 'visibility': 'public', 'return_type': 'CSS class', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'diagnosticsText', 'node_id': 'diagnosticsText', 'description': 'Container for diagnostic text with evenly spaced layout', 'visibility': 'public', 'return_type': 'CSS class', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'information', 'node_id': 'information', 'description': 'Container for endpoint information with column layout', 'visibility': 'public', 'return_type': 'CSS class', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'heading', 'node_id_to': 'details', 'description': 'contains'}, {'node_id_from': 'details', 'node_id_to': 'diagnostics', 'description': 'contains'}, {'node_id_from': 'details', 'node_id_to': 'diagnosticsText', 'description': 'contains'}, {'node_id_from': 'details', 'node_id_to': 'information', 'description': 'contains'}], 'packages': [{'package_id': 'contentLayout', 'children': ['details', 'diagnostics', 'diagnosticsText', 'information'], 'description': 'Content section'}]}",
    "version": "medium",
    "text_answer": "The CSS classes form a hierarchical layout structure where 'heading' contains the endpoint header, followed by 'details' which organizes three main sections: diagnostics (graphs), diagnosticsText (explanations), and information (endpoint metadata). Each section uses flex layouts with specific directions (row/column) and spacing to create a clean, organized interface.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\nimport {css, html, QwcHotReloadElement} from 'qwc-hot-reload-element';\nimport {JsonRpc} from 'jsonrpc';\n\nimport '@vaadin/details';\nimport '@vaadin/horizontal-layout';\nimport 'echarts-gauge-grade';\nimport 'qui-badge';\nimport 'qwc-no-data';\n\n/**\n * This component shows the Rest Easy Reactive Endpoint scores\n */\nexport class QwcResteasyReactiveEndpointScores extends QwcHotReloadElement {\n    jsonRpc = new JsonRpc(this);\n\n    static styles = css`\n        \n        .heading{\n            display: flex;\n            gap: 20px;\n            width: 100em;\n            padding: 20px;\n            background: var(--lumo-contrast-5pct);\n            border-bottom: 1px solid var(--lumo-contrast-10pct);\n        }\n        .details {\n            display: flex;\n            flex-direction: column;\n            gap: 20px;\n        }\n        .diagnostics {\n            display: flex;\n            justify-content: space-evenly;\n            gap: 20px;\n            height: 350px;\n        }\n        .diagnosticsText {\n            display: flex;\n            justify-content: space-evenly;\n            gap: 20px;\n        }\n        .diagnostic {\n            display: flex;\n            flex-direction: column;\n            gap: 10px;\n            width: 100%;\n        }\n        .diagnosticText {\n            display: flex;\n            flex-direction: column;\n            gap: 10px;\n            width: 33%;\n            overflow-wrap: break-word;\n        }\n    \n        .information {\n            border-top: 1px solid var(--lumo-contrast-10pct);\n            display: flex;\n            flex-direction: column;\n            gap: 10px;\n        }\n        .message {\n            text-align: center;\n            padding-left: 20px;\n            padding-right: 20px;\n            color: var(--lumo-contrast-70pct);\n        }\n        .infoTable {\n            border: none;\n        }\n        .col1{\n            text-align: right;\n            width: 200px;\n            font-weight: bolder;\n        }\n        \n        .httpMethod{\n            color: var(--lumo-primary-text-color);\n        }\n    `;\n\n    static properties = {\n        _latestScores: {state: true}\n    };\n\n    constructor() {\n        super();\n        this._latestScores = null;\n    }\n\n    connectedCallback() {\n        super.connectedCallback();\n        this.hotReload();\n    }\n\n    render() {\n        if(this._latestScores){\n            if(this._latestScores.endpoints){\n                return html`${this._latestScores.endpoints.map(endpoint=>{\n                    return html`${this._renderEndpoint(endpoint)}`;\n                })}`;\n            }\n        }\n        return html`<qwc-no-data message=\"You do not have any REST endpoints.\" \n                                    link=\"https://quarkus.io/guides/resteasy-reactive\"\n                                    linkText=\"Learn how to write REST Services with Quarkus REST\">\n                </qwc-no-data>\n            `;\n    }\n\n    _renderEndpoint(endpoint){\n        let level = this._getLevel(endpoint.score);\n        \n        return html`\n            <vaadin-details opened theme=\"reverse\">\n                \n                <div class=\"heading\" slot=\"summary\">\n                    <qui-badge level='${level}'><span>${endpoint.score}/100</span></qui-badge>\n                    <div>\n                        <code class=\"httpMethod\">${endpoint.httpMethod}</code> <code>${endpoint.fullPath}</code>\n                    </div>\n                    \n                </div>\n                \n                <div class=\"details\">\n                    ${this._renderDiagnostics(endpoint.diagnostics)}\n                    ${this._renderInformation(endpoint)}\n                </div>\n          </vaadin-details>`;\n    }\n\n    _renderDiagnostics(diagnostics){\n        const map = new Map(Object.entries(diagnostics));\n        const graphTemplates = [];\n        const textTemplates = [];\n        for (let [key, value] of map) {\n            graphTemplates.push(html`${this._renderDiagnosticGraph(value, key)}`);\n            textTemplates.push(html`${this._renderDiagnosticText(value)}`);\n        }\n\n        return html`<div class=\"diagnostics\">\n                        ${graphTemplates}\n                    </div>\n                    <div class=\"diagnosticsText\">\n                        ${textTemplates}\n                    </div>`;\n    }\n\n    _renderDiagnosticGraph(diagnostic, heading){\n        let score = diagnostic[0].score;\n        let level = this._getLevel(score);\n        \n        return html`<div class=\"diagnostic\">\n                        <echarts-gauge-grade \n                            title=\"${heading}\" \n                            percentage=\"${score}\"\n                            sectionColors=\"--lumo-${level}-color\">\n                        </echarts-gauge-grade>    \n                    </div>`;\n    }\n    \n    _renderDiagnosticText(diagnostic){\n        let whatToDo = html``;\n        \n        return html`<div class=\"diagnosticText\">\n                        <div class=\"message\">${diagnostic[0].message}</div>\n                    </div>`;\n    }\n    \n    _renderInformation(endpoint){\n        return html`<div class=\"information\">\n                        <table class=\"infoTable\">\n                            ${this._renderMediaType(\"Produces\", endpoint.producesHeaders)}\n                            ${this._renderMediaType(\"Consumes\", endpoint.consumesHeaders)}\n                    \n                            <tr>\n                                <td class=\"col1\">Resource Class:</td>\n                                <td>${endpoint.className}</td>\n                            </tr>\n                        </table>\n                    </div>`;\n    }\n\n    _renderMediaType(type,mediaType) {\n        if(mediaType && mediaType.length>0){\n            return html`<tr>\n                            <td class=\"col1\">${type}:</td>\n                            <td>${mediaType.map(mt=>\n                                html`<qui-badge><span>${mt}</span></qui-badge>`\n                            )}</td>\n                        </tr>`;\n        }\n    }\n\n    _getLevel(score){\n        let level = \"error\";\n        if(score === 66){\n            level = \"warning\";\n        }else if(score === 100){\n            level = \"success\";\n        }\n        return level;\n    }\n\n    hotReload(){\n        this._latestScores = null;\n        this.jsonRpc.getEndpointScores().then(endpointScores => {\n            this._latestScores = endpointScores.result;\n        });\n    }\n\n}\ncustomElements.define('qwc-resteasy-reactive-endpoint-scores', QwcResteasyReactiveEndpointScores);",
    "repo": "quarkusio/quarkus",
    "path": "./datasets/diagrams-repos/quarkusio/quarkus/extensions/resteasy-reactive/rest/deployment/src/main/resources/dev-ui/qwc-resteasy-reactive-endpoint-scores.js",
    "query": "What is the relationship between the CSS classes and how do they contribute to the layout?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'heading', 'node_id': 'heading', 'description': 'Main container for endpoint header with flex layout', 'visibility': 'public', 'return_type': 'CSS class', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'details', 'node_id': 'details', 'description': 'Container for endpoint details with column layout', 'visibility': 'public', 'return_type': 'CSS class', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'diagnostics', 'node_id': 'diagnostics', 'description': 'Container for diagnostic graphs with evenly spaced layout', 'visibility': 'public', 'return_type': 'CSS class', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'diagnosticsText', 'node_id': 'diagnosticsText', 'description': 'Container for diagnostic text with evenly spaced layout', 'visibility': 'public', 'return_type': 'CSS class', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'diagnostic', 'node_id': 'diagnostic', 'description': 'Individual diagnostic container with column layout', 'visibility': 'public', 'return_type': 'CSS class', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'diagnosticText', 'node_id': 'diagnosticText', 'description': 'Individual diagnostic text container with column layout', 'visibility': 'public', 'return_type': 'CSS class', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'information', 'node_id': 'information', 'description': 'Container for endpoint information with column layout', 'visibility': 'public', 'return_type': 'CSS class', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'message', 'node_id': 'message', 'description': 'Style for centered message text', 'visibility': 'public', 'return_type': 'CSS class', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'infoTable', 'node_id': 'infoTable', 'description': 'Style for information table', 'visibility': 'public', 'return_type': 'CSS class', 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'httpMethod', 'node_id': 'httpMethod', 'description': 'Style for HTTP method text', 'visibility': 'public', 'return_type': 'CSS class', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'heading', 'node_id_to': 'details', 'description': 'contains'}, {'node_id_from': 'details', 'node_id_to': 'diagnostics', 'description': 'contains'}, {'node_id_from': 'details', 'node_id_to': 'diagnosticsText', 'description': 'contains'}, {'node_id_from': 'diagnostics', 'node_id_to': 'diagnostic', 'description': 'contains'}, {'node_id_from': 'diagnosticsText', 'node_id_to': 'diagnosticText', 'description': 'contains'}, {'node_id_from': 'details', 'node_id_to': 'information', 'description': 'contains'}, {'node_id_from': 'information', 'node_id_to': 'infoTable', 'description': 'contains'}, {'node_id_from': 'diagnosticText', 'node_id_to': 'message', 'description': 'contains'}, {'node_id_from': 'heading', 'node_id_to': 'httpMethod', 'description': 'contains'}], 'packages': [{'package_id': 'headerSection', 'children': ['heading', 'httpMethod'], 'description': 'Header layout components'}, {'package_id': 'diagnosticSection', 'children': ['diagnostics', 'diagnosticsText', 'diagnostic', 'diagnosticText', 'message'], 'description': 'Diagnostic layout components'}, {'package_id': 'informationSection', 'children': ['information', 'infoTable'], 'description': 'Information layout components'}]}",
    "version": "full",
    "text_answer": "The CSS classes form a hierarchical layout structure where 'heading' contains the endpoint header, followed by 'details' which organizes three main sections: diagnostics (graphs), diagnosticsText (explanations), and information (endpoint metadata). Each section uses flex layouts with specific directions (row/column) and spacing to create a clean, organized interface.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C",
    "code": "\n#include \"internal/cryptlib.h\"\n#include <openssl/x509.h>\n#include <openssl/x509v3.h>\n#include \"crypto/x509.h\"\n\n#include \"pcy_local.h\"\n\nstatic int policy_data_cmp(const X509_POLICY_DATA *const *a,\n                           const X509_POLICY_DATA *const *b);\nstatic int policy_cache_set_int(long *out, ASN1_INTEGER *value);\n\n/*\n * Set cache entry according to CertificatePolicies extension. Note: this\n * destroys the passed CERTIFICATEPOLICIES structure.\n */\n\nstatic int policy_cache_create(X509 *x,\n                               CERTIFICATEPOLICIES *policies, int crit)\n{\n    int i, num, ret = 0;\n    X509_POLICY_CACHE *cache = x->policy_cache;\n    X509_POLICY_DATA *data = NULL;\n    POLICYINFO *policy;\n\n    if ((num = sk_POLICYINFO_num(policies)) <= 0)\n        goto bad_policy;\n    cache->data = sk_X509_POLICY_DATA_new(policy_data_cmp);\n    if (cache->data == NULL) {\n        ERR_raise(ERR_LIB_X509V3, ERR_R_CRYPTO_LIB);\n        goto just_cleanup;\n    }\n    for (i = 0; i < num; i++) {\n        policy = sk_POLICYINFO_value(policies, i);\n        data = ossl_policy_data_new(policy, NULL, crit);\n        if (data == NULL) {\n            ERR_raise(ERR_LIB_X509V3, ERR_R_X509_LIB);\n            goto just_cleanup;\n        }\n        /*\n         * Duplicate policy OIDs are illegal: reject if matches found.\n         */\n        if (OBJ_obj2nid(data->valid_policy) == NID_any_policy) {\n            if (cache->anyPolicy) {\n                ret = -1;\n                goto bad_policy;\n            }\n            cache->anyPolicy = data;\n        } else if (sk_X509_POLICY_DATA_find(cache->data, data) >=0) {\n            ret = -1;\n            goto bad_policy;\n        } else if (!sk_X509_POLICY_DATA_push(cache->data, data)) {\n            ERR_raise(ERR_LIB_X509V3, ERR_R_CRYPTO_LIB);\n            goto bad_policy;\n        }\n        data = NULL;\n    }\n    /* Sort so we can find more quickly */\n    sk_X509_POLICY_DATA_sort(cache->data);\n    ret = 1;\n\n bad_policy:\n    if (ret == -1)\n        x->ex_flags |= EXFLAG_INVALID_POLICY;\n    ossl_policy_data_free(data);\n just_cleanup:\n    sk_POLICYINFO_pop_free(policies, POLICYINFO_free);\n    if (ret <= 0) {\n        sk_X509_POLICY_DATA_pop_free(cache->data, ossl_policy_data_free);\n        cache->data = NULL;\n    }\n    return ret;\n}\n\nstatic int policy_cache_new(X509 *x)\n{\n    X509_POLICY_CACHE *cache;\n    ASN1_INTEGER *ext_any = NULL;\n    POLICY_CONSTRAINTS *ext_pcons = NULL;\n    CERTIFICATEPOLICIES *ext_cpols = NULL;\n    POLICY_MAPPINGS *ext_pmaps = NULL;\n    int i;\n\n    if (x->policy_cache != NULL)\n        return 1;\n    cache = OPENSSL_malloc(sizeof(*cache));\n    if (cache == NULL)\n        return 0;\n    cache->anyPolicy = NULL;\n    cache->data = NULL;\n    cache->any_skip = -1;\n    cache->explicit_skip = -1;\n    cache->map_skip = -1;\n\n    x->policy_cache = cache;\n\n    /*\n     * Handle requireExplicitPolicy *first*. Need to process this even if we\n     * don't have any policies.\n     */\n    ext_pcons = X509_get_ext_d2i(x, NID_policy_constraints, &i, NULL);\n\n    if (!ext_pcons) {\n        if (i != -1)\n            goto bad_cache;\n    } else {\n        if (!ext_pcons->requireExplicitPolicy\n            && !ext_pcons->inhibitPolicyMapping)\n            goto bad_cache;\n        if (!policy_cache_set_int(&cache->explicit_skip,\n                                  ext_pcons->requireExplicitPolicy))\n            goto bad_cache;\n        if (!policy_cache_set_int(&cache->map_skip,\n                                  ext_pcons->inhibitPolicyMapping))\n            goto bad_cache;\n    }\n\n    /* Process CertificatePolicies */\n\n    ext_cpols = X509_get_ext_d2i(x, NID_certificate_policies, &i, NULL);\n    /*\n     * If no CertificatePolicies extension or problem decoding then there is\n     * no point continuing because the valid policies will be NULL.\n     */\n    if (!ext_cpols) {\n        /* If not absent some problem with extension */\n        if (i != -1)\n            goto bad_cache;\n        return 1;\n    }\n\n    i = policy_cache_create(x, ext_cpols, i);\n\n    /* NB: ext_cpols freed by policy_cache_set_policies */\n\n    if (i <= 0)\n        return i;\n\n    ext_pmaps = X509_get_ext_d2i(x, NID_policy_mappings, &i, NULL);\n\n    if (!ext_pmaps) {\n        /* If not absent some problem with extension */\n        if (i != -1)\n            goto bad_cache;\n    } else {\n        i = ossl_policy_cache_set_mapping(x, ext_pmaps);\n        if (i <= 0)\n            goto bad_cache;\n    }\n\n    ext_any = X509_get_ext_d2i(x, NID_inhibit_any_policy, &i, NULL);\n\n    if (!ext_any) {\n        if (i != -1)\n            goto bad_cache;\n    } else if (!policy_cache_set_int(&cache->any_skip, ext_any))\n        goto bad_cache;\n    goto just_cleanup;\n\n bad_cache:\n    x->ex_flags |= EXFLAG_INVALID_POLICY;\n\n just_cleanup:\n    POLICY_CONSTRAINTS_free(ext_pcons);\n    ASN1_INTEGER_free(ext_any);\n    return 1;\n\n}\n\nvoid ossl_policy_cache_free(X509_POLICY_CACHE *cache)\n{\n    if (!cache)\n        return;\n    ossl_policy_data_free(cache->anyPolicy);\n    sk_X509_POLICY_DATA_pop_free(cache->data, ossl_policy_data_free);\n    OPENSSL_free(cache);\n}\n\nconst X509_POLICY_CACHE *ossl_policy_cache_set(X509 *x)\n{\n\n    if (x->policy_cache == NULL) {\n        if (!CRYPTO_THREAD_write_lock(x->lock))\n            return NULL;\n        policy_cache_new(x);\n        CRYPTO_THREAD_unlock(x->lock);\n    }\n\n    return x->policy_cache;\n\n}\n\nX509_POLICY_DATA *ossl_policy_cache_find_data(const X509_POLICY_CACHE *cache,\n                                              const ASN1_OBJECT *id)\n{\n    int idx;\n    X509_POLICY_DATA tmp;\n    tmp.valid_policy = (ASN1_OBJECT *)id;\n    idx = sk_X509_POLICY_DATA_find(cache->data, &tmp);\n    return sk_X509_POLICY_DATA_value(cache->data, idx);\n}\n\nstatic int policy_data_cmp(const X509_POLICY_DATA *const *a,\n                           const X509_POLICY_DATA *const *b)\n{\n    return OBJ_cmp((*a)->valid_policy, (*b)->valid_policy);\n}\n\nstatic int policy_cache_set_int(long *out, ASN1_INTEGER *value)\n{\n    if (value == NULL)\n        return 1;\n    if (value->type == V_ASN1_NEG_INTEGER)\n        return 0;\n    *out = ASN1_INTEGER_get(value);\n    return 1;\n}",
    "repo": "openssl/openssl",
    "path": "./datasets/diagrams-repos/openssl/openssl/crypto/x509/pcy_cache.c",
    "query": "What is the structure of the policy cache in the provided code?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'X509_POLICY_CACHE', 'node_id': 'X509_POLICY_CACHE', 'description': 'Main structure for storing certificate policy information', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'anyPolicy', 'node_id': 'anyPolicy', 'description': 'Stores any-policy data', 'visibility': 'public', 'return_type': 'X509_POLICY_DATA', 'params': None, 'source_class_id': 'X509_POLICY_CACHE'}, {'type': 'field', 'name': 'data', 'node_id': 'data', 'description': 'Stack of policy data entries', 'visibility': 'public', 'return_type': 'STACK_OF(X509_POLICY_DATA)', 'params': None, 'source_class_id': 'X509_POLICY_CACHE'}], 'edges': [{'node_id_from': 'X509_POLICY_CACHE', 'node_id_to': 'anyPolicy', 'description': 'contains'}, {'node_id_from': 'X509_POLICY_CACHE', 'node_id_to': 'data', 'description': 'contains'}], 'packages': [{'package_id': 'policyCache', 'children': ['X509_POLICY_CACHE', 'anyPolicy', 'data'], 'description': 'Core policy cache components'}]}",
    "version": "minimal",
    "text_answer": "The policy cache is implemented as X509_POLICY_CACHE structure containing a stack of policy data entries and an any-policy field. It maintains skip counters for different policy types and provides functions for creation, manipulation, and cleanup of policy information.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C",
    "code": "\n#include \"internal/cryptlib.h\"\n#include <openssl/x509.h>\n#include <openssl/x509v3.h>\n#include \"crypto/x509.h\"\n\n#include \"pcy_local.h\"\n\nstatic int policy_data_cmp(const X509_POLICY_DATA *const *a,\n                           const X509_POLICY_DATA *const *b);\nstatic int policy_cache_set_int(long *out, ASN1_INTEGER *value);\n\n/*\n * Set cache entry according to CertificatePolicies extension. Note: this\n * destroys the passed CERTIFICATEPOLICIES structure.\n */\n\nstatic int policy_cache_create(X509 *x,\n                               CERTIFICATEPOLICIES *policies, int crit)\n{\n    int i, num, ret = 0;\n    X509_POLICY_CACHE *cache = x->policy_cache;\n    X509_POLICY_DATA *data = NULL;\n    POLICYINFO *policy;\n\n    if ((num = sk_POLICYINFO_num(policies)) <= 0)\n        goto bad_policy;\n    cache->data = sk_X509_POLICY_DATA_new(policy_data_cmp);\n    if (cache->data == NULL) {\n        ERR_raise(ERR_LIB_X509V3, ERR_R_CRYPTO_LIB);\n        goto just_cleanup;\n    }\n    for (i = 0; i < num; i++) {\n        policy = sk_POLICYINFO_value(policies, i);\n        data = ossl_policy_data_new(policy, NULL, crit);\n        if (data == NULL) {\n            ERR_raise(ERR_LIB_X509V3, ERR_R_X509_LIB);\n            goto just_cleanup;\n        }\n        /*\n         * Duplicate policy OIDs are illegal: reject if matches found.\n         */\n        if (OBJ_obj2nid(data->valid_policy) == NID_any_policy) {\n            if (cache->anyPolicy) {\n                ret = -1;\n                goto bad_policy;\n            }\n            cache->anyPolicy = data;\n        } else if (sk_X509_POLICY_DATA_find(cache->data, data) >=0) {\n            ret = -1;\n            goto bad_policy;\n        } else if (!sk_X509_POLICY_DATA_push(cache->data, data)) {\n            ERR_raise(ERR_LIB_X509V3, ERR_R_CRYPTO_LIB);\n            goto bad_policy;\n        }\n        data = NULL;\n    }\n    /* Sort so we can find more quickly */\n    sk_X509_POLICY_DATA_sort(cache->data);\n    ret = 1;\n\n bad_policy:\n    if (ret == -1)\n        x->ex_flags |= EXFLAG_INVALID_POLICY;\n    ossl_policy_data_free(data);\n just_cleanup:\n    sk_POLICYINFO_pop_free(policies, POLICYINFO_free);\n    if (ret <= 0) {\n        sk_X509_POLICY_DATA_pop_free(cache->data, ossl_policy_data_free);\n        cache->data = NULL;\n    }\n    return ret;\n}\n\nstatic int policy_cache_new(X509 *x)\n{\n    X509_POLICY_CACHE *cache;\n    ASN1_INTEGER *ext_any = NULL;\n    POLICY_CONSTRAINTS *ext_pcons = NULL;\n    CERTIFICATEPOLICIES *ext_cpols = NULL;\n    POLICY_MAPPINGS *ext_pmaps = NULL;\n    int i;\n\n    if (x->policy_cache != NULL)\n        return 1;\n    cache = OPENSSL_malloc(sizeof(*cache));\n    if (cache == NULL)\n        return 0;\n    cache->anyPolicy = NULL;\n    cache->data = NULL;\n    cache->any_skip = -1;\n    cache->explicit_skip = -1;\n    cache->map_skip = -1;\n\n    x->policy_cache = cache;\n\n    /*\n     * Handle requireExplicitPolicy *first*. Need to process this even if we\n     * don't have any policies.\n     */\n    ext_pcons = X509_get_ext_d2i(x, NID_policy_constraints, &i, NULL);\n\n    if (!ext_pcons) {\n        if (i != -1)\n            goto bad_cache;\n    } else {\n        if (!ext_pcons->requireExplicitPolicy\n            && !ext_pcons->inhibitPolicyMapping)\n            goto bad_cache;\n        if (!policy_cache_set_int(&cache->explicit_skip,\n                                  ext_pcons->requireExplicitPolicy))\n            goto bad_cache;\n        if (!policy_cache_set_int(&cache->map_skip,\n                                  ext_pcons->inhibitPolicyMapping))\n            goto bad_cache;\n    }\n\n    /* Process CertificatePolicies */\n\n    ext_cpols = X509_get_ext_d2i(x, NID_certificate_policies, &i, NULL);\n    /*\n     * If no CertificatePolicies extension or problem decoding then there is\n     * no point continuing because the valid policies will be NULL.\n     */\n    if (!ext_cpols) {\n        /* If not absent some problem with extension */\n        if (i != -1)\n            goto bad_cache;\n        return 1;\n    }\n\n    i = policy_cache_create(x, ext_cpols, i);\n\n    /* NB: ext_cpols freed by policy_cache_set_policies */\n\n    if (i <= 0)\n        return i;\n\n    ext_pmaps = X509_get_ext_d2i(x, NID_policy_mappings, &i, NULL);\n\n    if (!ext_pmaps) {\n        /* If not absent some problem with extension */\n        if (i != -1)\n            goto bad_cache;\n    } else {\n        i = ossl_policy_cache_set_mapping(x, ext_pmaps);\n        if (i <= 0)\n            goto bad_cache;\n    }\n\n    ext_any = X509_get_ext_d2i(x, NID_inhibit_any_policy, &i, NULL);\n\n    if (!ext_any) {\n        if (i != -1)\n            goto bad_cache;\n    } else if (!policy_cache_set_int(&cache->any_skip, ext_any))\n        goto bad_cache;\n    goto just_cleanup;\n\n bad_cache:\n    x->ex_flags |= EXFLAG_INVALID_POLICY;\n\n just_cleanup:\n    POLICY_CONSTRAINTS_free(ext_pcons);\n    ASN1_INTEGER_free(ext_any);\n    return 1;\n\n}\n\nvoid ossl_policy_cache_free(X509_POLICY_CACHE *cache)\n{\n    if (!cache)\n        return;\n    ossl_policy_data_free(cache->anyPolicy);\n    sk_X509_POLICY_DATA_pop_free(cache->data, ossl_policy_data_free);\n    OPENSSL_free(cache);\n}\n\nconst X509_POLICY_CACHE *ossl_policy_cache_set(X509 *x)\n{\n\n    if (x->policy_cache == NULL) {\n        if (!CRYPTO_THREAD_write_lock(x->lock))\n            return NULL;\n        policy_cache_new(x);\n        CRYPTO_THREAD_unlock(x->lock);\n    }\n\n    return x->policy_cache;\n\n}\n\nX509_POLICY_DATA *ossl_policy_cache_find_data(const X509_POLICY_CACHE *cache,\n                                              const ASN1_OBJECT *id)\n{\n    int idx;\n    X509_POLICY_DATA tmp;\n    tmp.valid_policy = (ASN1_OBJECT *)id;\n    idx = sk_X509_POLICY_DATA_find(cache->data, &tmp);\n    return sk_X509_POLICY_DATA_value(cache->data, idx);\n}\n\nstatic int policy_data_cmp(const X509_POLICY_DATA *const *a,\n                           const X509_POLICY_DATA *const *b)\n{\n    return OBJ_cmp((*a)->valid_policy, (*b)->valid_policy);\n}\n\nstatic int policy_cache_set_int(long *out, ASN1_INTEGER *value)\n{\n    if (value == NULL)\n        return 1;\n    if (value->type == V_ASN1_NEG_INTEGER)\n        return 0;\n    *out = ASN1_INTEGER_get(value);\n    return 1;\n}",
    "repo": "openssl/openssl",
    "path": "./datasets/diagrams-repos/openssl/openssl/crypto/x509/pcy_cache.c",
    "query": "What is the structure of the policy cache in the provided code?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'X509_POLICY_CACHE', 'node_id': 'X509_POLICY_CACHE', 'description': 'Main structure for storing certificate policy information', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'anyPolicy', 'node_id': 'anyPolicy', 'description': 'Stores any-policy data', 'visibility': 'public', 'return_type': 'X509_POLICY_DATA', 'params': None, 'source_class_id': 'X509_POLICY_CACHE'}, {'type': 'field', 'name': 'data', 'node_id': 'data', 'description': 'Stack of policy data entries', 'visibility': 'public', 'return_type': 'STACK_OF(X509_POLICY_DATA)', 'params': None, 'source_class_id': 'X509_POLICY_CACHE'}, {'type': 'field', 'name': 'any_skip', 'node_id': 'any_skip', 'description': 'Skip value for any policy', 'visibility': 'public', 'return_type': 'long', 'params': None, 'source_class_id': 'X509_POLICY_CACHE'}, {'type': 'field', 'name': 'explicit_skip', 'node_id': 'explicit_skip', 'description': 'Skip value for explicit policy', 'visibility': 'public', 'return_type': 'long', 'params': None, 'source_class_id': 'X509_POLICY_CACHE'}, {'type': 'function', 'name': 'policy_cache_new', 'node_id': 'policy_cache_new', 'description': 'Creates new policy cache', 'visibility': 'private', 'return_type': 'int', 'params': 'X509 *x', 'source_class_id': None}, {'type': 'function', 'name': 'ossl_policy_cache_free', 'node_id': 'ossl_policy_cache_free', 'description': 'Frees policy cache', 'visibility': 'public', 'return_type': 'void', 'params': 'X509_POLICY_CACHE *cache', 'source_class_id': None}], 'edges': [{'node_id_from': 'X509_POLICY_CACHE', 'node_id_to': 'anyPolicy', 'description': 'contains'}, {'node_id_from': 'X509_POLICY_CACHE', 'node_id_to': 'data', 'description': 'contains'}, {'node_id_from': 'policy_cache_new', 'node_id_to': 'X509_POLICY_CACHE', 'description': 'creates'}, {'node_id_from': 'ossl_policy_cache_free', 'node_id_to': 'X509_POLICY_CACHE', 'description': 'frees'}, {'node_id_from': 'X509_POLICY_CACHE', 'node_id_to': 'any_skip', 'description': ''}, {'node_id_from': 'X509_POLICY_CACHE', 'node_id_to': 'explicit_skip', 'description': ''}], 'packages': [{'package_id': 'policyCache', 'children': ['X509_POLICY_CACHE', 'anyPolicy', 'data', 'any_skip', 'explicit_skip'], 'description': 'Core policy cache components'}, {'package_id': 'policyOperations', 'children': ['policy_cache_new', 'ossl_policy_cache_free'], 'description': 'Policy cache management functions'}]}",
    "version": "medium",
    "text_answer": "The policy cache is implemented as X509_POLICY_CACHE structure containing a stack of policy data entries and an any-policy field. It maintains skip counters for different policy types and provides functions for creation, manipulation, and cleanup of policy information.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C",
    "code": "\n#include \"internal/cryptlib.h\"\n#include <openssl/x509.h>\n#include <openssl/x509v3.h>\n#include \"crypto/x509.h\"\n\n#include \"pcy_local.h\"\n\nstatic int policy_data_cmp(const X509_POLICY_DATA *const *a,\n                           const X509_POLICY_DATA *const *b);\nstatic int policy_cache_set_int(long *out, ASN1_INTEGER *value);\n\n/*\n * Set cache entry according to CertificatePolicies extension. Note: this\n * destroys the passed CERTIFICATEPOLICIES structure.\n */\n\nstatic int policy_cache_create(X509 *x,\n                               CERTIFICATEPOLICIES *policies, int crit)\n{\n    int i, num, ret = 0;\n    X509_POLICY_CACHE *cache = x->policy_cache;\n    X509_POLICY_DATA *data = NULL;\n    POLICYINFO *policy;\n\n    if ((num = sk_POLICYINFO_num(policies)) <= 0)\n        goto bad_policy;\n    cache->data = sk_X509_POLICY_DATA_new(policy_data_cmp);\n    if (cache->data == NULL) {\n        ERR_raise(ERR_LIB_X509V3, ERR_R_CRYPTO_LIB);\n        goto just_cleanup;\n    }\n    for (i = 0; i < num; i++) {\n        policy = sk_POLICYINFO_value(policies, i);\n        data = ossl_policy_data_new(policy, NULL, crit);\n        if (data == NULL) {\n            ERR_raise(ERR_LIB_X509V3, ERR_R_X509_LIB);\n            goto just_cleanup;\n        }\n        /*\n         * Duplicate policy OIDs are illegal: reject if matches found.\n         */\n        if (OBJ_obj2nid(data->valid_policy) == NID_any_policy) {\n            if (cache->anyPolicy) {\n                ret = -1;\n                goto bad_policy;\n            }\n            cache->anyPolicy = data;\n        } else if (sk_X509_POLICY_DATA_find(cache->data, data) >=0) {\n            ret = -1;\n            goto bad_policy;\n        } else if (!sk_X509_POLICY_DATA_push(cache->data, data)) {\n            ERR_raise(ERR_LIB_X509V3, ERR_R_CRYPTO_LIB);\n            goto bad_policy;\n        }\n        data = NULL;\n    }\n    /* Sort so we can find more quickly */\n    sk_X509_POLICY_DATA_sort(cache->data);\n    ret = 1;\n\n bad_policy:\n    if (ret == -1)\n        x->ex_flags |= EXFLAG_INVALID_POLICY;\n    ossl_policy_data_free(data);\n just_cleanup:\n    sk_POLICYINFO_pop_free(policies, POLICYINFO_free);\n    if (ret <= 0) {\n        sk_X509_POLICY_DATA_pop_free(cache->data, ossl_policy_data_free);\n        cache->data = NULL;\n    }\n    return ret;\n}\n\nstatic int policy_cache_new(X509 *x)\n{\n    X509_POLICY_CACHE *cache;\n    ASN1_INTEGER *ext_any = NULL;\n    POLICY_CONSTRAINTS *ext_pcons = NULL;\n    CERTIFICATEPOLICIES *ext_cpols = NULL;\n    POLICY_MAPPINGS *ext_pmaps = NULL;\n    int i;\n\n    if (x->policy_cache != NULL)\n        return 1;\n    cache = OPENSSL_malloc(sizeof(*cache));\n    if (cache == NULL)\n        return 0;\n    cache->anyPolicy = NULL;\n    cache->data = NULL;\n    cache->any_skip = -1;\n    cache->explicit_skip = -1;\n    cache->map_skip = -1;\n\n    x->policy_cache = cache;\n\n    /*\n     * Handle requireExplicitPolicy *first*. Need to process this even if we\n     * don't have any policies.\n     */\n    ext_pcons = X509_get_ext_d2i(x, NID_policy_constraints, &i, NULL);\n\n    if (!ext_pcons) {\n        if (i != -1)\n            goto bad_cache;\n    } else {\n        if (!ext_pcons->requireExplicitPolicy\n            && !ext_pcons->inhibitPolicyMapping)\n            goto bad_cache;\n        if (!policy_cache_set_int(&cache->explicit_skip,\n                                  ext_pcons->requireExplicitPolicy))\n            goto bad_cache;\n        if (!policy_cache_set_int(&cache->map_skip,\n                                  ext_pcons->inhibitPolicyMapping))\n            goto bad_cache;\n    }\n\n    /* Process CertificatePolicies */\n\n    ext_cpols = X509_get_ext_d2i(x, NID_certificate_policies, &i, NULL);\n    /*\n     * If no CertificatePolicies extension or problem decoding then there is\n     * no point continuing because the valid policies will be NULL.\n     */\n    if (!ext_cpols) {\n        /* If not absent some problem with extension */\n        if (i != -1)\n            goto bad_cache;\n        return 1;\n    }\n\n    i = policy_cache_create(x, ext_cpols, i);\n\n    /* NB: ext_cpols freed by policy_cache_set_policies */\n\n    if (i <= 0)\n        return i;\n\n    ext_pmaps = X509_get_ext_d2i(x, NID_policy_mappings, &i, NULL);\n\n    if (!ext_pmaps) {\n        /* If not absent some problem with extension */\n        if (i != -1)\n            goto bad_cache;\n    } else {\n        i = ossl_policy_cache_set_mapping(x, ext_pmaps);\n        if (i <= 0)\n            goto bad_cache;\n    }\n\n    ext_any = X509_get_ext_d2i(x, NID_inhibit_any_policy, &i, NULL);\n\n    if (!ext_any) {\n        if (i != -1)\n            goto bad_cache;\n    } else if (!policy_cache_set_int(&cache->any_skip, ext_any))\n        goto bad_cache;\n    goto just_cleanup;\n\n bad_cache:\n    x->ex_flags |= EXFLAG_INVALID_POLICY;\n\n just_cleanup:\n    POLICY_CONSTRAINTS_free(ext_pcons);\n    ASN1_INTEGER_free(ext_any);\n    return 1;\n\n}\n\nvoid ossl_policy_cache_free(X509_POLICY_CACHE *cache)\n{\n    if (!cache)\n        return;\n    ossl_policy_data_free(cache->anyPolicy);\n    sk_X509_POLICY_DATA_pop_free(cache->data, ossl_policy_data_free);\n    OPENSSL_free(cache);\n}\n\nconst X509_POLICY_CACHE *ossl_policy_cache_set(X509 *x)\n{\n\n    if (x->policy_cache == NULL) {\n        if (!CRYPTO_THREAD_write_lock(x->lock))\n            return NULL;\n        policy_cache_new(x);\n        CRYPTO_THREAD_unlock(x->lock);\n    }\n\n    return x->policy_cache;\n\n}\n\nX509_POLICY_DATA *ossl_policy_cache_find_data(const X509_POLICY_CACHE *cache,\n                                              const ASN1_OBJECT *id)\n{\n    int idx;\n    X509_POLICY_DATA tmp;\n    tmp.valid_policy = (ASN1_OBJECT *)id;\n    idx = sk_X509_POLICY_DATA_find(cache->data, &tmp);\n    return sk_X509_POLICY_DATA_value(cache->data, idx);\n}\n\nstatic int policy_data_cmp(const X509_POLICY_DATA *const *a,\n                           const X509_POLICY_DATA *const *b)\n{\n    return OBJ_cmp((*a)->valid_policy, (*b)->valid_policy);\n}\n\nstatic int policy_cache_set_int(long *out, ASN1_INTEGER *value)\n{\n    if (value == NULL)\n        return 1;\n    if (value->type == V_ASN1_NEG_INTEGER)\n        return 0;\n    *out = ASN1_INTEGER_get(value);\n    return 1;\n}",
    "repo": "openssl/openssl",
    "path": "./datasets/diagrams-repos/openssl/openssl/crypto/x509/pcy_cache.c",
    "query": "What is the structure of the policy cache in the provided code?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'X509_POLICY_CACHE', 'node_id': 'X509_POLICY_CACHE', 'description': 'Main structure for storing certificate policy information', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'anyPolicy', 'node_id': 'anyPolicy', 'description': 'Stores any-policy data', 'visibility': 'public', 'return_type': 'X509_POLICY_DATA', 'params': None, 'source_class_id': 'X509_POLICY_CACHE'}, {'type': 'field', 'name': 'data', 'node_id': 'data', 'description': 'Stack of policy data entries', 'visibility': 'public', 'return_type': 'STACK_OF(X509_POLICY_DATA)', 'params': None, 'source_class_id': 'X509_POLICY_CACHE'}, {'type': 'field', 'name': 'any_skip', 'node_id': 'any_skip', 'description': 'Skip value for any policy', 'visibility': 'public', 'return_type': 'long', 'params': None, 'source_class_id': 'X509_POLICY_CACHE'}, {'type': 'field', 'name': 'explicit_skip', 'node_id': 'explicit_skip', 'description': 'Skip value for explicit policy', 'visibility': 'public', 'return_type': 'long', 'params': None, 'source_class_id': 'X509_POLICY_CACHE'}, {'type': 'field', 'name': 'map_skip', 'node_id': 'map_skip', 'description': 'Skip value for policy mapping', 'visibility': 'public', 'return_type': 'long', 'params': None, 'source_class_id': 'X509_POLICY_CACHE'}, {'type': 'function', 'name': 'policy_cache_new', 'node_id': 'policy_cache_new', 'description': 'Creates new policy cache', 'visibility': 'private', 'return_type': 'int', 'params': 'X509 *x', 'source_class_id': None}, {'type': 'function', 'name': 'policy_cache_create', 'node_id': 'policy_cache_create', 'description': 'Sets cache entry according to CertificatePolicies extension', 'visibility': 'private', 'return_type': 'int', 'params': 'X509 *x, CERTIFICATEPOLICIES *policies, int crit', 'source_class_id': None}, {'type': 'function', 'name': 'ossl_policy_cache_free', 'node_id': 'ossl_policy_cache_free', 'description': 'Frees policy cache', 'visibility': 'public', 'return_type': 'void', 'params': 'X509_POLICY_CACHE *cache', 'source_class_id': None}, {'type': 'function', 'name': 'ossl_policy_cache_set', 'node_id': 'ossl_policy_cache_set', 'description': 'Sets or creates policy cache for certificate', 'visibility': 'public', 'return_type': 'const X509_POLICY_CACHE *', 'params': 'X509 *x', 'source_class_id': None}, {'type': 'function', 'name': 'ossl_policy_cache_find_data', 'node_id': 'ossl_policy_cache_find_data', 'description': 'Finds policy data by ID', 'visibility': 'public', 'return_type': 'X509_POLICY_DATA *', 'params': 'const X509_POLICY_CACHE *cache, const ASN1_OBJECT *id', 'source_class_id': None}, {'type': 'function', 'name': 'policy_data_cmp', 'node_id': 'policy_data_cmp', 'description': 'Compares policy data entries', 'visibility': 'private', 'return_type': 'int', 'params': 'const X509_POLICY_DATA *const *a, const X509_POLICY_DATA *const *b', 'source_class_id': None}], 'edges': [{'node_id_from': 'X509_POLICY_CACHE', 'node_id_to': 'anyPolicy', 'description': 'contains'}, {'node_id_from': 'X509_POLICY_CACHE', 'node_id_to': 'data', 'description': 'contains'}, {'node_id_from': 'policy_cache_new', 'node_id_to': 'X509_POLICY_CACHE', 'description': 'creates'}, {'node_id_from': 'policy_cache_create', 'node_id_to': 'X509_POLICY_CACHE', 'description': 'modifies'}, {'node_id_from': 'ossl_policy_cache_free', 'node_id_to': 'X509_POLICY_CACHE', 'description': 'frees'}, {'node_id_from': 'ossl_policy_cache_set', 'node_id_to': 'X509_POLICY_CACHE', 'description': 'manages'}, {'node_id_from': 'ossl_policy_cache_find_data', 'node_id_to': 'data', 'description': 'searches'}, {'node_id_from': 'policy_data_cmp', 'node_id_to': 'data', 'description': 'compares entries'}, {'node_id_from': 'X509_POLICY_CACHE', 'node_id_to': 'any_skip', 'description': ''}, {'node_id_from': 'X509_POLICY_CACHE', 'node_id_to': 'explicit_skip', 'description': ''}, {'node_id_from': 'X509_POLICY_CACHE', 'node_id_to': 'map_skip', 'description': ''}], 'packages': [{'package_id': 'policyCache', 'children': ['X509_POLICY_CACHE', 'anyPolicy', 'data', 'any_skip', 'explicit_skip', 'map_skip'], 'description': 'Core policy cache components'}, {'package_id': 'policyOperations', 'children': ['policy_cache_new', 'policy_cache_create', 'ossl_policy_cache_free', 'ossl_policy_cache_set'], 'description': 'Policy cache management functions'}, {'package_id': 'policyDataOperations', 'children': ['ossl_policy_cache_find_data', 'policy_data_cmp'], 'description': 'Policy data manipulation functions'}]}",
    "version": "full",
    "text_answer": "The policy cache is implemented as X509_POLICY_CACHE structure containing a stack of policy data entries and an any-policy field. It maintains skip counters for different policy types and provides functions for creation, manipulation, and cleanup of policy information.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C",
    "code": "\n#define DT_DRV_COMPAT seeed_grove_lcd_rgb\n\n#include <zephyr/device.h>\n#include <zephyr/drivers/i2c.h>\n#include <zephyr/drivers/misc/grove_lcd/grove_lcd.h>\n#include <zephyr/kernel.h>\n#include <zephyr/sys/util.h>\n\n#include <zephyr/logging/log.h>\nLOG_MODULE_REGISTER(grove_lcd, CONFIG_GROVE_LCD_RGB_LOG_LEVEL);\n\n#define GROVE_RGB_BACKLIGHT_ADDR\t(0x62)\n\nstruct glcd_data {\n\tuint8_t input_set;\n\tuint8_t display_switch;\n\tuint8_t function;\n};\n\nstruct glcd_config {\n\tstruct i2c_dt_spec bus;\n};\n\n/********************************************\n *  LCD FUNCTIONS\n *******************************************/\n\n/* GLCD_CMD_SCREEN_CLEAR has no options */\n/* GLCD_CMD_CURSOR_RETURN has no options */\n\n/* Defines for the GLCD_CMD_CURSOR_SHIFT */\n#define GLCD_CS_DISPLAY_SHIFT\t\t(1 << 3)\n#define GLCD_CS_RIGHT_SHIFT\t\t(1 << 2)\n\n/* LCD Display Commands */\n#define GLCD_CMD_SCREEN_CLEAR\t\t(1 << 0)\n#define GLCD_CMD_CURSOR_RETURN\t\t(1 << 1)\n#define GLCD_CMD_INPUT_SET\t\t(1 << 2)\n#define GLCD_CMD_DISPLAY_SWITCH\t\t(1 << 3)\n#define GLCD_CMD_CURSOR_SHIFT\t\t(1 << 4)\n#define GLCD_CMD_FUNCTION_SET\t\t(1 << 5)\n#define GLCD_CMD_SET_CGRAM_ADDR\t\t(1 << 6)\n#define GLCD_CMD_SET_DDRAM_ADDR\t\t(1 << 7)\n\n\n/********************************************\n *  RGB FUNCTIONS\n *******************************************/\n\n#define REGISTER_R\t0x04\n#define REGISTER_G\t0x03\n#define REGISTER_B\t0x02\n\nstatic uint8_t color_define[][3] = {\n\t{ 255, 255, 255 },\t/* white */\n\t{ 255, 0,   0   },      /* red */\n\t{ 0,   255, 0   },      /* green */\n\t{ 0,   0,   255 },      /* blue */\n};\n\n\n/********************************************\n *  PRIVATE FUNCTIONS\n *******************************************/\nstatic void rgb_reg_set(const struct device *i2c, uint8_t addr, uint8_t dta)\n{\n\tuint8_t data[2] = { addr, dta };\n\n\ti2c_write(i2c, data, sizeof(data), GROVE_RGB_BACKLIGHT_ADDR);\n}\n\n/********************************************\n *  PUBLIC FUNCTIONS\n *******************************************/\nvoid glcd_print(const struct device *dev, char *data, uint32_t size)\n{\n\tconst struct glcd_config *config = dev->config;\n\tuint8_t buf[] = { GLCD_CMD_SET_CGRAM_ADDR, 0 };\n\tint i;\n\n\tfor (i = 0; i < size; i++) {\n\t\tbuf[1] = data[i];\n\t\ti2c_write_dt(&config->bus, buf, sizeof(buf));\n\t}\n}\n\n\nvoid glcd_cursor_pos_set(const struct device *dev, uint8_t col, uint8_t row)\n{\n\tconst struct glcd_config *config = dev->config;\n\n\tunsigned char data[2];\n\n\tif (row == 0U) {\n\t\tcol |= 0x80;\n\t} else {\n\t\tcol |= 0xC0;\n\t}\n\n\tdata[0] = GLCD_CMD_SET_DDRAM_ADDR;\n\tdata[1] = col;\n\n\ti2c_write_dt(&config->bus, data, 2);\n}\n\n\nvoid glcd_clear(const struct device *dev)\n{\n\tconst struct glcd_config *config = dev->config;\n\tuint8_t clear[] = { 0, GLCD_CMD_SCREEN_CLEAR };\n\n\ti2c_write_dt(&config->bus, clear, sizeof(clear));\n\tLOG_DBG(\"clear, delay 20 ms\");\n\tk_sleep(K_MSEC(20));\n}\n\n\nvoid glcd_display_state_set(const struct device *dev, uint8_t opt)\n{\n\tconst struct glcd_config *config = dev->config;\n\tstruct glcd_data *data = dev->data;\n\tuint8_t buf[] = { 0, 0 };\n\n\tdata->display_switch = opt;\n\tbuf[1] = (opt | GLCD_CMD_DISPLAY_SWITCH);\n\n\ti2c_write_dt(&config->bus, buf, sizeof(buf));\n\n\tLOG_DBG(\"set display_state options, delay 5 ms\");\n\tk_sleep(K_MSEC(5));\n}\n\n\nuint8_t glcd_display_state_get(const struct device *dev)\n{\n\tstruct glcd_data *data = dev->data;\n\n\treturn data->display_switch;\n}\n\n\nvoid glcd_input_state_set(const struct device *dev, uint8_t opt)\n{\n\tconst struct glcd_config *config = dev->config;\n\tstruct glcd_data *data = dev->data;\n\tuint8_t buf[] = { 0, 0 };\n\n\tdata->input_set = opt;\n\tbuf[1] = (opt | GLCD_CMD_INPUT_SET);\n\n\ti2c_write_dt(&config->bus, buf, sizeof(buf));\n\tLOG_DBG(\"set the input_set, no delay\");\n}\n\n\nuint8_t glcd_input_state_get(const struct device *dev)\n{\n\tstruct glcd_data *data = dev->data;\n\n\treturn data->input_set;\n}\n\n\nvoid glcd_color_select(const struct device *dev, uint8_t color)\n{\n\tif (color > 3) {\n\t\tLOG_WRN(\"selected color is too high a value\");\n\t\treturn;\n\t}\n\tglcd_color_set(dev, color_define[color][0], color_define[color][1],\n\t\t       color_define[color][2]);\n}\n\n\nvoid glcd_color_set(const struct device *dev, uint8_t r, uint8_t g,\n\t\t    uint8_t b)\n{\n\tconst struct glcd_config *config = dev->config;\n\n\trgb_reg_set(config->bus.bus, REGISTER_R, r);\n\trgb_reg_set(config->bus.bus, REGISTER_G, g);\n\trgb_reg_set(config->bus.bus, REGISTER_B, b);\n}\n\n\nvoid glcd_function_set(const struct device *dev, uint8_t opt)\n{\n\tconst struct glcd_config *config = dev->config;\n\tstruct glcd_data *data = dev->data;\n\tuint8_t buf[] = { 0, 0 };\n\n\tdata->function = opt;\n\tbuf[1] = (opt | GLCD_CMD_FUNCTION_SET);\n\n\ti2c_write_dt(&config->bus, buf, sizeof(buf));\n\n\tLOG_DBG(\"set function options, delay 5 ms\");\n\tk_sleep(K_MSEC(5));\n}\n\n\nuint8_t glcd_function_get(const struct device *dev)\n{\n\tstruct glcd_data *data = dev->data;\n\n\treturn data->function;\n}\n\n\nstatic int glcd_initialize(const struct device *dev)\n{\n\tconst struct glcd_config *config = dev->config;\n\tuint8_t cmd;\n\n\tLOG_DBG(\"initialize called\");\n\n\tif (!device_is_ready(config->bus.bus)) {\n\t\treturn -ENODEV;\n\t}\n\n\t/*\n\t * Initialization sequence from the data sheet:\n\t * 1 - Power on\n\t *   - Wait for more than 30 ms AFTER VDD rises to 4.5v\n\t * 2 - Send FUNCTION set\n\t *   - Wait for 39 us\n\t * 3 - Send DISPLAY Control\n\t *   - wait for 39 us\n\t * 4 - send DISPLAY Clear\n\t *   - wait for 1.5 ms\n\t * 5 - send ENTRY Mode\n\t * 6 - Initialization is done\n\t */\n\n\n\t/*\n\t * We're here!  Let's just make sure we've had enough time for the\n\t * VDD to power on, so pause a little here, 30 ms min, so we go 50\n\t */\n\tLOG_DBG(\"delay 50 ms while the VDD powers on\");\n\tk_sleep(K_MSEC(50));\n\n\t/* Configure everything for the display function first */\n\tcmd = GLCD_CMD_FUNCTION_SET | GLCD_FS_ROWS_2;\n\tglcd_function_set(dev, cmd);\n\n\t/* turn the display on - by default no cursor and no blinking */\n\tcmd = GLCD_DS_DISPLAY_ON | GLCD_DS_CURSOR_OFF | GLCD_DS_BLINK_OFF;\n\n\tglcd_display_state_set(dev, cmd);\n\n\t/* Clear the screen */\n\tglcd_clear(dev);\n\n\t/* Initialize to the default text direction for romance languages */\n\tcmd = GLCD_IS_ENTRY_LEFT | GLCD_IS_SHIFT_DECREMENT;\n\n\tglcd_input_state_set(dev, cmd);\n\n\t/* Now power on the background RGB control */\n\tLOG_INF(\"configuring the RGB background\");\n\trgb_reg_set(config->bus.bus, 0x00, 0x00);\n\trgb_reg_set(config->bus.bus, 0x01, 0x05);\n\trgb_reg_set(config->bus.bus, 0x08, 0xAA);\n\n\t/* Now set the background color to white */\n\tLOG_DBG(\"background set to white\");\n\trgb_reg_set(config->bus.bus, REGISTER_R, color_define[GROVE_RGB_WHITE][0]);\n\trgb_reg_set(config->bus.bus, REGISTER_G, color_define[GROVE_RGB_WHITE][1]);\n\trgb_reg_set(config->bus.bus, REGISTER_B, color_define[GROVE_RGB_WHITE][2]);\n\n\treturn 0;\n}\n\nstatic const struct glcd_config grove_lcd_config = {\n\t.bus = I2C_DT_SPEC_INST_GET(0),\n};\n\nstatic struct glcd_data grove_lcd_data;\n\nDEVICE_DT_INST_DEFINE(0, glcd_initialize, NULL, &grove_lcd_data,\n\t\t      &grove_lcd_config, POST_KERNEL,\n\t\t      CONFIG_KERNEL_INIT_PRIORITY_DEVICE, NULL);",
    "repo": "zephyrproject-rtos/zephyr",
    "path": "./datasets/diagrams-repos/zephyrproject-rtos/zephyr/drivers/misc/grove_lcd_rgb/grove_lcd_rgb.c",
    "query": "Show the structure of the file including all the header files and their purposes?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'deviceTree', 'node_id': 'deviceTree', 'description': 'Device Tree configuration for Grove LCD', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'i2cDriver', 'node_id': 'i2cDriver', 'description': 'I2C communication interface', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'groveLcdDriver', 'node_id': 'groveLcdDriver', 'description': 'Main Grove LCD RGB driver', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'groveLcdDriver', 'node_id_to': 'i2cDriver', 'description': 'uses'}, {'node_id_from': 'groveLcdDriver', 'node_id_to': 'deviceTree', 'description': 'configured by'}], 'packages': [{'package_id': 'zephyrOS', 'children': ['deviceTree', 'i2cDriver', 'groveLcdDriver'], 'description': 'Zephyr RTOS components'}]}",
    "version": "minimal",
    "text_answer": "The project is a Zephyr RTOS driver for Grove LCD RGB display. It uses Zephyr's device abstraction layer, I2C communication interface, kernel functions, and logging system. The driver is implemented using two main structures (glcd_data and glcd_config) and various functions for LCD control and RGB backlight manipulation.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C",
    "code": "\n#define DT_DRV_COMPAT seeed_grove_lcd_rgb\n\n#include <zephyr/device.h>\n#include <zephyr/drivers/i2c.h>\n#include <zephyr/drivers/misc/grove_lcd/grove_lcd.h>\n#include <zephyr/kernel.h>\n#include <zephyr/sys/util.h>\n\n#include <zephyr/logging/log.h>\nLOG_MODULE_REGISTER(grove_lcd, CONFIG_GROVE_LCD_RGB_LOG_LEVEL);\n\n#define GROVE_RGB_BACKLIGHT_ADDR\t(0x62)\n\nstruct glcd_data {\n\tuint8_t input_set;\n\tuint8_t display_switch;\n\tuint8_t function;\n};\n\nstruct glcd_config {\n\tstruct i2c_dt_spec bus;\n};\n\n/********************************************\n *  LCD FUNCTIONS\n *******************************************/\n\n/* GLCD_CMD_SCREEN_CLEAR has no options */\n/* GLCD_CMD_CURSOR_RETURN has no options */\n\n/* Defines for the GLCD_CMD_CURSOR_SHIFT */\n#define GLCD_CS_DISPLAY_SHIFT\t\t(1 << 3)\n#define GLCD_CS_RIGHT_SHIFT\t\t(1 << 2)\n\n/* LCD Display Commands */\n#define GLCD_CMD_SCREEN_CLEAR\t\t(1 << 0)\n#define GLCD_CMD_CURSOR_RETURN\t\t(1 << 1)\n#define GLCD_CMD_INPUT_SET\t\t(1 << 2)\n#define GLCD_CMD_DISPLAY_SWITCH\t\t(1 << 3)\n#define GLCD_CMD_CURSOR_SHIFT\t\t(1 << 4)\n#define GLCD_CMD_FUNCTION_SET\t\t(1 << 5)\n#define GLCD_CMD_SET_CGRAM_ADDR\t\t(1 << 6)\n#define GLCD_CMD_SET_DDRAM_ADDR\t\t(1 << 7)\n\n\n/********************************************\n *  RGB FUNCTIONS\n *******************************************/\n\n#define REGISTER_R\t0x04\n#define REGISTER_G\t0x03\n#define REGISTER_B\t0x02\n\nstatic uint8_t color_define[][3] = {\n\t{ 255, 255, 255 },\t/* white */\n\t{ 255, 0,   0   },      /* red */\n\t{ 0,   255, 0   },      /* green */\n\t{ 0,   0,   255 },      /* blue */\n};\n\n\n/********************************************\n *  PRIVATE FUNCTIONS\n *******************************************/\nstatic void rgb_reg_set(const struct device *i2c, uint8_t addr, uint8_t dta)\n{\n\tuint8_t data[2] = { addr, dta };\n\n\ti2c_write(i2c, data, sizeof(data), GROVE_RGB_BACKLIGHT_ADDR);\n}\n\n/********************************************\n *  PUBLIC FUNCTIONS\n *******************************************/\nvoid glcd_print(const struct device *dev, char *data, uint32_t size)\n{\n\tconst struct glcd_config *config = dev->config;\n\tuint8_t buf[] = { GLCD_CMD_SET_CGRAM_ADDR, 0 };\n\tint i;\n\n\tfor (i = 0; i < size; i++) {\n\t\tbuf[1] = data[i];\n\t\ti2c_write_dt(&config->bus, buf, sizeof(buf));\n\t}\n}\n\n\nvoid glcd_cursor_pos_set(const struct device *dev, uint8_t col, uint8_t row)\n{\n\tconst struct glcd_config *config = dev->config;\n\n\tunsigned char data[2];\n\n\tif (row == 0U) {\n\t\tcol |= 0x80;\n\t} else {\n\t\tcol |= 0xC0;\n\t}\n\n\tdata[0] = GLCD_CMD_SET_DDRAM_ADDR;\n\tdata[1] = col;\n\n\ti2c_write_dt(&config->bus, data, 2);\n}\n\n\nvoid glcd_clear(const struct device *dev)\n{\n\tconst struct glcd_config *config = dev->config;\n\tuint8_t clear[] = { 0, GLCD_CMD_SCREEN_CLEAR };\n\n\ti2c_write_dt(&config->bus, clear, sizeof(clear));\n\tLOG_DBG(\"clear, delay 20 ms\");\n\tk_sleep(K_MSEC(20));\n}\n\n\nvoid glcd_display_state_set(const struct device *dev, uint8_t opt)\n{\n\tconst struct glcd_config *config = dev->config;\n\tstruct glcd_data *data = dev->data;\n\tuint8_t buf[] = { 0, 0 };\n\n\tdata->display_switch = opt;\n\tbuf[1] = (opt | GLCD_CMD_DISPLAY_SWITCH);\n\n\ti2c_write_dt(&config->bus, buf, sizeof(buf));\n\n\tLOG_DBG(\"set display_state options, delay 5 ms\");\n\tk_sleep(K_MSEC(5));\n}\n\n\nuint8_t glcd_display_state_get(const struct device *dev)\n{\n\tstruct glcd_data *data = dev->data;\n\n\treturn data->display_switch;\n}\n\n\nvoid glcd_input_state_set(const struct device *dev, uint8_t opt)\n{\n\tconst struct glcd_config *config = dev->config;\n\tstruct glcd_data *data = dev->data;\n\tuint8_t buf[] = { 0, 0 };\n\n\tdata->input_set = opt;\n\tbuf[1] = (opt | GLCD_CMD_INPUT_SET);\n\n\ti2c_write_dt(&config->bus, buf, sizeof(buf));\n\tLOG_DBG(\"set the input_set, no delay\");\n}\n\n\nuint8_t glcd_input_state_get(const struct device *dev)\n{\n\tstruct glcd_data *data = dev->data;\n\n\treturn data->input_set;\n}\n\n\nvoid glcd_color_select(const struct device *dev, uint8_t color)\n{\n\tif (color > 3) {\n\t\tLOG_WRN(\"selected color is too high a value\");\n\t\treturn;\n\t}\n\tglcd_color_set(dev, color_define[color][0], color_define[color][1],\n\t\t       color_define[color][2]);\n}\n\n\nvoid glcd_color_set(const struct device *dev, uint8_t r, uint8_t g,\n\t\t    uint8_t b)\n{\n\tconst struct glcd_config *config = dev->config;\n\n\trgb_reg_set(config->bus.bus, REGISTER_R, r);\n\trgb_reg_set(config->bus.bus, REGISTER_G, g);\n\trgb_reg_set(config->bus.bus, REGISTER_B, b);\n}\n\n\nvoid glcd_function_set(const struct device *dev, uint8_t opt)\n{\n\tconst struct glcd_config *config = dev->config;\n\tstruct glcd_data *data = dev->data;\n\tuint8_t buf[] = { 0, 0 };\n\n\tdata->function = opt;\n\tbuf[1] = (opt | GLCD_CMD_FUNCTION_SET);\n\n\ti2c_write_dt(&config->bus, buf, sizeof(buf));\n\n\tLOG_DBG(\"set function options, delay 5 ms\");\n\tk_sleep(K_MSEC(5));\n}\n\n\nuint8_t glcd_function_get(const struct device *dev)\n{\n\tstruct glcd_data *data = dev->data;\n\n\treturn data->function;\n}\n\n\nstatic int glcd_initialize(const struct device *dev)\n{\n\tconst struct glcd_config *config = dev->config;\n\tuint8_t cmd;\n\n\tLOG_DBG(\"initialize called\");\n\n\tif (!device_is_ready(config->bus.bus)) {\n\t\treturn -ENODEV;\n\t}\n\n\t/*\n\t * Initialization sequence from the data sheet:\n\t * 1 - Power on\n\t *   - Wait for more than 30 ms AFTER VDD rises to 4.5v\n\t * 2 - Send FUNCTION set\n\t *   - Wait for 39 us\n\t * 3 - Send DISPLAY Control\n\t *   - wait for 39 us\n\t * 4 - send DISPLAY Clear\n\t *   - wait for 1.5 ms\n\t * 5 - send ENTRY Mode\n\t * 6 - Initialization is done\n\t */\n\n\n\t/*\n\t * We're here!  Let's just make sure we've had enough time for the\n\t * VDD to power on, so pause a little here, 30 ms min, so we go 50\n\t */\n\tLOG_DBG(\"delay 50 ms while the VDD powers on\");\n\tk_sleep(K_MSEC(50));\n\n\t/* Configure everything for the display function first */\n\tcmd = GLCD_CMD_FUNCTION_SET | GLCD_FS_ROWS_2;\n\tglcd_function_set(dev, cmd);\n\n\t/* turn the display on - by default no cursor and no blinking */\n\tcmd = GLCD_DS_DISPLAY_ON | GLCD_DS_CURSOR_OFF | GLCD_DS_BLINK_OFF;\n\n\tglcd_display_state_set(dev, cmd);\n\n\t/* Clear the screen */\n\tglcd_clear(dev);\n\n\t/* Initialize to the default text direction for romance languages */\n\tcmd = GLCD_IS_ENTRY_LEFT | GLCD_IS_SHIFT_DECREMENT;\n\n\tglcd_input_state_set(dev, cmd);\n\n\t/* Now power on the background RGB control */\n\tLOG_INF(\"configuring the RGB background\");\n\trgb_reg_set(config->bus.bus, 0x00, 0x00);\n\trgb_reg_set(config->bus.bus, 0x01, 0x05);\n\trgb_reg_set(config->bus.bus, 0x08, 0xAA);\n\n\t/* Now set the background color to white */\n\tLOG_DBG(\"background set to white\");\n\trgb_reg_set(config->bus.bus, REGISTER_R, color_define[GROVE_RGB_WHITE][0]);\n\trgb_reg_set(config->bus.bus, REGISTER_G, color_define[GROVE_RGB_WHITE][1]);\n\trgb_reg_set(config->bus.bus, REGISTER_B, color_define[GROVE_RGB_WHITE][2]);\n\n\treturn 0;\n}\n\nstatic const struct glcd_config grove_lcd_config = {\n\t.bus = I2C_DT_SPEC_INST_GET(0),\n};\n\nstatic struct glcd_data grove_lcd_data;\n\nDEVICE_DT_INST_DEFINE(0, glcd_initialize, NULL, &grove_lcd_data,\n\t\t      &grove_lcd_config, POST_KERNEL,\n\t\t      CONFIG_KERNEL_INIT_PRIORITY_DEVICE, NULL);",
    "repo": "zephyrproject-rtos/zephyr",
    "path": "./datasets/diagrams-repos/zephyrproject-rtos/zephyr/drivers/misc/grove_lcd_rgb/grove_lcd_rgb.c",
    "query": "Show the structure of the file including all the header files and their purposes?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'driverFunctions', 'node_id': 'driverFunctions', 'description': 'Driver implementation functions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'driverStructures', 'node_id': 'driverStructures', 'description': 'Driver data structures', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'deviceHeader', 'node_id': 'deviceHeader', 'description': 'Zephyr device abstraction layer', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'i2cHeader', 'node_id': 'i2cHeader', 'description': 'I2C bus communication interface', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'groveLcdHeader', 'node_id': 'groveLcdHeader', 'description': 'Grove LCD specific definitions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'kernelHeader', 'node_id': 'kernelHeader', 'description': 'Zephyr kernel functionality', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'loggingHeader', 'node_id': 'loggingHeader', 'description': 'Zephyr logging system', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'utilHeader', 'node_id': 'utilHeader', 'description': 'Zephyr utility functions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'groveLcdHeader', 'node_id_to': 'i2cHeader', 'description': 'depends on'}, {'node_id_from': 'groveLcdHeader', 'node_id_to': 'deviceHeader', 'description': 'depends on'}, {'node_id_from': 'driverStructures', 'node_id_to': 'i2cHeader', 'description': 'uses'}, {'node_id_from': 'driverFunctions', 'node_id_to': 'loggingHeader', 'description': 'uses'}, {'node_id_from': 'driverFunctions', 'node_id_to': 'driverStructures', 'description': 'uses'}, {'node_id_from': 'driverFunctions', 'node_id_to': 'kernelHeader', 'description': 'uses'}, {'node_id_from': 'driverFunctions', 'node_id_to': 'utilHeader', 'description': 'uses'}], 'packages': [{'package_id': 'headers', 'children': ['deviceHeader', 'i2cHeader', 'groveLcdHeader', 'kernelHeader', 'loggingHeader', 'utilHeader'], 'description': 'System headers'}]}",
    "version": "medium",
    "text_answer": "The project is a Zephyr RTOS driver for Grove LCD RGB display. It uses Zephyr's device abstraction layer, I2C communication interface, kernel functions, and logging system. The driver is implemented using two main structures (glcd_data and glcd_config) and various functions for LCD control and RGB backlight manipulation.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C",
    "code": "\n#define DT_DRV_COMPAT seeed_grove_lcd_rgb\n\n#include <zephyr/device.h>\n#include <zephyr/drivers/i2c.h>\n#include <zephyr/drivers/misc/grove_lcd/grove_lcd.h>\n#include <zephyr/kernel.h>\n#include <zephyr/sys/util.h>\n\n#include <zephyr/logging/log.h>\nLOG_MODULE_REGISTER(grove_lcd, CONFIG_GROVE_LCD_RGB_LOG_LEVEL);\n\n#define GROVE_RGB_BACKLIGHT_ADDR\t(0x62)\n\nstruct glcd_data {\n\tuint8_t input_set;\n\tuint8_t display_switch;\n\tuint8_t function;\n};\n\nstruct glcd_config {\n\tstruct i2c_dt_spec bus;\n};\n\n/********************************************\n *  LCD FUNCTIONS\n *******************************************/\n\n/* GLCD_CMD_SCREEN_CLEAR has no options */\n/* GLCD_CMD_CURSOR_RETURN has no options */\n\n/* Defines for the GLCD_CMD_CURSOR_SHIFT */\n#define GLCD_CS_DISPLAY_SHIFT\t\t(1 << 3)\n#define GLCD_CS_RIGHT_SHIFT\t\t(1 << 2)\n\n/* LCD Display Commands */\n#define GLCD_CMD_SCREEN_CLEAR\t\t(1 << 0)\n#define GLCD_CMD_CURSOR_RETURN\t\t(1 << 1)\n#define GLCD_CMD_INPUT_SET\t\t(1 << 2)\n#define GLCD_CMD_DISPLAY_SWITCH\t\t(1 << 3)\n#define GLCD_CMD_CURSOR_SHIFT\t\t(1 << 4)\n#define GLCD_CMD_FUNCTION_SET\t\t(1 << 5)\n#define GLCD_CMD_SET_CGRAM_ADDR\t\t(1 << 6)\n#define GLCD_CMD_SET_DDRAM_ADDR\t\t(1 << 7)\n\n\n/********************************************\n *  RGB FUNCTIONS\n *******************************************/\n\n#define REGISTER_R\t0x04\n#define REGISTER_G\t0x03\n#define REGISTER_B\t0x02\n\nstatic uint8_t color_define[][3] = {\n\t{ 255, 255, 255 },\t/* white */\n\t{ 255, 0,   0   },      /* red */\n\t{ 0,   255, 0   },      /* green */\n\t{ 0,   0,   255 },      /* blue */\n};\n\n\n/********************************************\n *  PRIVATE FUNCTIONS\n *******************************************/\nstatic void rgb_reg_set(const struct device *i2c, uint8_t addr, uint8_t dta)\n{\n\tuint8_t data[2] = { addr, dta };\n\n\ti2c_write(i2c, data, sizeof(data), GROVE_RGB_BACKLIGHT_ADDR);\n}\n\n/********************************************\n *  PUBLIC FUNCTIONS\n *******************************************/\nvoid glcd_print(const struct device *dev, char *data, uint32_t size)\n{\n\tconst struct glcd_config *config = dev->config;\n\tuint8_t buf[] = { GLCD_CMD_SET_CGRAM_ADDR, 0 };\n\tint i;\n\n\tfor (i = 0; i < size; i++) {\n\t\tbuf[1] = data[i];\n\t\ti2c_write_dt(&config->bus, buf, sizeof(buf));\n\t}\n}\n\n\nvoid glcd_cursor_pos_set(const struct device *dev, uint8_t col, uint8_t row)\n{\n\tconst struct glcd_config *config = dev->config;\n\n\tunsigned char data[2];\n\n\tif (row == 0U) {\n\t\tcol |= 0x80;\n\t} else {\n\t\tcol |= 0xC0;\n\t}\n\n\tdata[0] = GLCD_CMD_SET_DDRAM_ADDR;\n\tdata[1] = col;\n\n\ti2c_write_dt(&config->bus, data, 2);\n}\n\n\nvoid glcd_clear(const struct device *dev)\n{\n\tconst struct glcd_config *config = dev->config;\n\tuint8_t clear[] = { 0, GLCD_CMD_SCREEN_CLEAR };\n\n\ti2c_write_dt(&config->bus, clear, sizeof(clear));\n\tLOG_DBG(\"clear, delay 20 ms\");\n\tk_sleep(K_MSEC(20));\n}\n\n\nvoid glcd_display_state_set(const struct device *dev, uint8_t opt)\n{\n\tconst struct glcd_config *config = dev->config;\n\tstruct glcd_data *data = dev->data;\n\tuint8_t buf[] = { 0, 0 };\n\n\tdata->display_switch = opt;\n\tbuf[1] = (opt | GLCD_CMD_DISPLAY_SWITCH);\n\n\ti2c_write_dt(&config->bus, buf, sizeof(buf));\n\n\tLOG_DBG(\"set display_state options, delay 5 ms\");\n\tk_sleep(K_MSEC(5));\n}\n\n\nuint8_t glcd_display_state_get(const struct device *dev)\n{\n\tstruct glcd_data *data = dev->data;\n\n\treturn data->display_switch;\n}\n\n\nvoid glcd_input_state_set(const struct device *dev, uint8_t opt)\n{\n\tconst struct glcd_config *config = dev->config;\n\tstruct glcd_data *data = dev->data;\n\tuint8_t buf[] = { 0, 0 };\n\n\tdata->input_set = opt;\n\tbuf[1] = (opt | GLCD_CMD_INPUT_SET);\n\n\ti2c_write_dt(&config->bus, buf, sizeof(buf));\n\tLOG_DBG(\"set the input_set, no delay\");\n}\n\n\nuint8_t glcd_input_state_get(const struct device *dev)\n{\n\tstruct glcd_data *data = dev->data;\n\n\treturn data->input_set;\n}\n\n\nvoid glcd_color_select(const struct device *dev, uint8_t color)\n{\n\tif (color > 3) {\n\t\tLOG_WRN(\"selected color is too high a value\");\n\t\treturn;\n\t}\n\tglcd_color_set(dev, color_define[color][0], color_define[color][1],\n\t\t       color_define[color][2]);\n}\n\n\nvoid glcd_color_set(const struct device *dev, uint8_t r, uint8_t g,\n\t\t    uint8_t b)\n{\n\tconst struct glcd_config *config = dev->config;\n\n\trgb_reg_set(config->bus.bus, REGISTER_R, r);\n\trgb_reg_set(config->bus.bus, REGISTER_G, g);\n\trgb_reg_set(config->bus.bus, REGISTER_B, b);\n}\n\n\nvoid glcd_function_set(const struct device *dev, uint8_t opt)\n{\n\tconst struct glcd_config *config = dev->config;\n\tstruct glcd_data *data = dev->data;\n\tuint8_t buf[] = { 0, 0 };\n\n\tdata->function = opt;\n\tbuf[1] = (opt | GLCD_CMD_FUNCTION_SET);\n\n\ti2c_write_dt(&config->bus, buf, sizeof(buf));\n\n\tLOG_DBG(\"set function options, delay 5 ms\");\n\tk_sleep(K_MSEC(5));\n}\n\n\nuint8_t glcd_function_get(const struct device *dev)\n{\n\tstruct glcd_data *data = dev->data;\n\n\treturn data->function;\n}\n\n\nstatic int glcd_initialize(const struct device *dev)\n{\n\tconst struct glcd_config *config = dev->config;\n\tuint8_t cmd;\n\n\tLOG_DBG(\"initialize called\");\n\n\tif (!device_is_ready(config->bus.bus)) {\n\t\treturn -ENODEV;\n\t}\n\n\t/*\n\t * Initialization sequence from the data sheet:\n\t * 1 - Power on\n\t *   - Wait for more than 30 ms AFTER VDD rises to 4.5v\n\t * 2 - Send FUNCTION set\n\t *   - Wait for 39 us\n\t * 3 - Send DISPLAY Control\n\t *   - wait for 39 us\n\t * 4 - send DISPLAY Clear\n\t *   - wait for 1.5 ms\n\t * 5 - send ENTRY Mode\n\t * 6 - Initialization is done\n\t */\n\n\n\t/*\n\t * We're here!  Let's just make sure we've had enough time for the\n\t * VDD to power on, so pause a little here, 30 ms min, so we go 50\n\t */\n\tLOG_DBG(\"delay 50 ms while the VDD powers on\");\n\tk_sleep(K_MSEC(50));\n\n\t/* Configure everything for the display function first */\n\tcmd = GLCD_CMD_FUNCTION_SET | GLCD_FS_ROWS_2;\n\tglcd_function_set(dev, cmd);\n\n\t/* turn the display on - by default no cursor and no blinking */\n\tcmd = GLCD_DS_DISPLAY_ON | GLCD_DS_CURSOR_OFF | GLCD_DS_BLINK_OFF;\n\n\tglcd_display_state_set(dev, cmd);\n\n\t/* Clear the screen */\n\tglcd_clear(dev);\n\n\t/* Initialize to the default text direction for romance languages */\n\tcmd = GLCD_IS_ENTRY_LEFT | GLCD_IS_SHIFT_DECREMENT;\n\n\tglcd_input_state_set(dev, cmd);\n\n\t/* Now power on the background RGB control */\n\tLOG_INF(\"configuring the RGB background\");\n\trgb_reg_set(config->bus.bus, 0x00, 0x00);\n\trgb_reg_set(config->bus.bus, 0x01, 0x05);\n\trgb_reg_set(config->bus.bus, 0x08, 0xAA);\n\n\t/* Now set the background color to white */\n\tLOG_DBG(\"background set to white\");\n\trgb_reg_set(config->bus.bus, REGISTER_R, color_define[GROVE_RGB_WHITE][0]);\n\trgb_reg_set(config->bus.bus, REGISTER_G, color_define[GROVE_RGB_WHITE][1]);\n\trgb_reg_set(config->bus.bus, REGISTER_B, color_define[GROVE_RGB_WHITE][2]);\n\n\treturn 0;\n}\n\nstatic const struct glcd_config grove_lcd_config = {\n\t.bus = I2C_DT_SPEC_INST_GET(0),\n};\n\nstatic struct glcd_data grove_lcd_data;\n\nDEVICE_DT_INST_DEFINE(0, glcd_initialize, NULL, &grove_lcd_data,\n\t\t      &grove_lcd_config, POST_KERNEL,\n\t\t      CONFIG_KERNEL_INIT_PRIORITY_DEVICE, NULL);",
    "repo": "zephyrproject-rtos/zephyr",
    "path": "./datasets/diagrams-repos/zephyrproject-rtos/zephyr/drivers/misc/grove_lcd_rgb/grove_lcd_rgb.c",
    "query": "Show the structure of the file including all the header files and their purposes?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'deviceHeader', 'node_id': 'deviceHeader', 'description': 'Zephyr device abstraction layer', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'i2cHeader', 'node_id': 'i2cHeader', 'description': 'I2C bus communication interface', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'groveLcdHeader', 'node_id': 'groveLcdHeader', 'description': 'Grove LCD specific definitions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'kernelHeader', 'node_id': 'kernelHeader', 'description': 'Zephyr kernel functionality', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'utilHeader', 'node_id': 'utilHeader', 'description': 'Zephyr utility functions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'loggingHeader', 'node_id': 'loggingHeader', 'description': 'Zephyr logging system', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'glcd_data', 'node_id': 'glcd_data', 'description': 'LCD driver data structure', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'glcd_config', 'node_id': 'glcd_config', 'description': 'LCD driver configuration structure', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'glcd_initialize', 'node_id': 'glcd_initialize', 'description': 'Initialize LCD display', 'visibility': 'private', 'return_type': 'int', 'params': 'const struct device *dev', 'source_class_id': None}, {'type': 'function', 'name': 'rgb_reg_set', 'node_id': 'rgb_reg_set', 'description': 'Set RGB register values', 'visibility': 'private', 'return_type': 'void', 'params': 'const struct device *i2c, uint8_t addr, uint8_t dta', 'source_class_id': None}], 'edges': [{'node_id_from': 'groveLcdHeader', 'node_id_to': 'i2cHeader', 'description': 'depends on'}, {'node_id_from': 'groveLcdHeader', 'node_id_to': 'deviceHeader', 'description': 'depends on'}, {'node_id_from': 'glcd_config', 'node_id_to': 'i2cHeader', 'description': 'uses'}, {'node_id_from': 'glcd_initialize', 'node_id_to': 'rgb_reg_set', 'description': 'calls'}, {'node_id_from': 'glcd_initialize', 'node_id_to': 'loggingHeader', 'description': 'uses'}, {'node_id_from': 'glcd_initialize', 'node_id_to': 'glcd_data', 'description': 'uses'}, {'node_id_from': 'glcd_initialize', 'node_id_to': 'kernelHeader', 'description': 'uses'}, {'node_id_from': 'glcd_initialize', 'node_id_to': 'glcd_config', 'description': 'uses'}, {'node_id_from': 'glcd_initialize', 'node_id_to': 'utilHeader', 'description': 'uses'}], 'packages': [{'package_id': 'zephyrHeaders', 'children': ['deviceHeader', 'i2cHeader', 'kernelHeader', 'utilHeader', 'loggingHeader'], 'description': 'Zephyr system headers'}, {'package_id': 'driverStructures', 'children': ['glcd_data', 'glcd_config'], 'description': 'Driver data structures'}, {'package_id': 'driverFunctions', 'children': ['glcd_initialize', 'rgb_reg_set'], 'description': 'Driver implementation functions'}]}",
    "version": "full",
    "text_answer": "The project is a Zephyr RTOS driver for Grove LCD RGB display. It uses Zephyr's device abstraction layer, I2C communication interface, kernel functions, and logging system. The driver is implemented using two main structures (glcd_data and glcd_config) and various functions for LCD control and RGB backlight manipulation.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { getCurrentInstance, type App } from '@vue/runtime-core';\nimport { renderToString } from '@vue/server-renderer';\nimport type { HippyAppOptions } from '@hippy-vue-next/index';\nimport { getObjectNodeList } from './util';\nimport type {\n  SsrCommonParams,\n  SsrNode,\n  SsrNodeProps,\n} from './index';\n\n/**\n * SSR Request context type\n *\n * @public\n */\nexport interface SsrRequestContext {\n  isIOS?: boolean;\n  dimensions?: {\n    screen: {\n      width: number;\n      height: number;\n      statusBarHeight: number;\n    }\n  }\n}\n\n/**\n * SSR render options type\n */\ninterface SsrRenderOption {\n  rootContainer: string;\n  ssrOptions?: HippyAppOptions;\n  context?: SsrRequestContext;\n}\n\n// native text input type\nconst INPUT_VALUE_MAP = {\n  number: 'numeric',\n  text: 'default',\n  search: 'web-search',\n};\n\n/**\n * merge default props to ssr node. some native node should have default props, so we need to add\n * to prop. the same logic with client runtime\n *\n * @param node - ssrNode\n * @param nodeList - ssrNodeList\n */\nfunction mergeDefaultNativeProps(\n  node: SsrNode,\n  nodeList: SsrNode[],\n): SsrNodeProps {\n  const commonProps = { id: '', class: '' };\n  let defaultNativeProps: SsrNodeProps = {};\n\n  switch (node.name) {\n    case 'ListView':\n      defaultNativeProps = {\n        // calculate child nums\n        numberOfRows: nodeList.filter(v => v.pId === node.id).length,\n      };\n      break;\n    case 'Text':\n      defaultNativeProps = { text: '' };\n      break;\n    case 'TextInput':\n      defaultNativeProps = { underlineColorAndroid: 0 };\n      if (node.tagName === 'textarea') {\n        defaultNativeProps.numberOfLines = 5;\n      }\n      break;\n    case 'ViewPager':\n      defaultNativeProps = { initialPage: node.props.current };\n      break;\n    case 'WebView':\n      defaultNativeProps = {\n        method: 'get',\n        userAgent: '',\n      };\n      break;\n    case 'Modal':\n      defaultNativeProps = {\n        transparent: true,\n        immersionStatusBar: true,\n        collapsable: false,\n      };\n      break;\n    case 'Image':\n      defaultNativeProps = {\n        backgroundColor: 0,\n      };\n      break;\n    default:\n      break;\n  }\n  return Object.assign(commonProps, defaultNativeProps);\n}\n\n/**\n * parse text input map props\n *\n * @param tagName\n * @param rawProps\n */\nfunction parseTextInputProps(tagName: string, rawProps: SsrCommonParams): SsrCommonParams {\n  const props = rawProps;\n\n  // handle common input props map\n  if (props.type) {\n    props.keyboardType = INPUT_VALUE_MAP[props.type] ?? props.type;\n    delete props.type;\n  }\n  if (props.disabled) {\n    props.editable = !props.disabled;\n    delete props.disabled;\n  }\n  if (typeof props.value !== 'undefined') {\n    props.defaultValue = props.value;\n    delete props.value;\n  }\n  if (props.maxlength) {\n    props.maxLength = props.maxlength;\n    delete props.maxlength;\n  }\n\n  if (tagName === 'textarea') {\n    props.multiline = true;\n    // handle textarea props map\n    if (props.rows) {\n      props.numberOfLines = props.rows;\n      delete props.rows;\n    }\n  } else {\n    props.numberOfLines = 1;\n    props.multiline = false;\n  }\n\n  return props;\n}\n\n/**\n * get node's props. merge all props need to merged\n *\n * @param node - ssr node\n * @param nodeList - ssr node list\n * @param isIOS - client is iOS or not\n */\nfunction getNodeProps(\n  node: SsrNode,\n  nodeList: SsrNode[],\n  isIOS?: boolean,\n): SsrNodeProps {\n  let { props } = node;\n  // merge all props\n  props = {\n    ...mergeDefaultNativeProps(node, nodeList),\n    ...props,\n    ...props.mergedProps,\n  };\n  delete props.mergedProps;\n  // assign id and class to attribute props. id & class should use for devtools at client side\n  // and use for ssr\n  props.attributes = {\n    id: props?.attributes?.id ?? props.id,\n    class: props?.attributes?.class ?? props.class,\n  };\n  // delete unnecessary props\n  delete props.id;\n  delete props.class;\n  delete props.attributes.style;\n  delete props.attributes.text;\n\n  // compatible iOS image src and fontWeight\n  if (\n    isIOS && node.name === 'Image' && props.src\n  ) {\n    props.source = [{ uri: props.src }];\n    delete props.src;\n  }\n  // compatible fontWeight\n  if (props?.style?.fontWeight) {\n    props.style.fontWeight = String(props.style.fontWeight);\n  }\n  // compatible placeholder\n  if (typeof props.placeholder !== 'undefined') {\n    props.placeholder = String(props.placeholder);\n  }\n\n  if (node.name === 'TextInput') {\n    parseTextInputProps(node.tagName ?? '', props);\n  }\n\n  if (node.name === 'WebView') {\n    props.source = {\n      uri: props.src,\n    };\n    delete props.src;\n  }\n\n  return props;\n}\n\n/**\n * convert ssr node's special kebabCase props name to camelCase name\n *\n * @param rawProps\n */\nfunction convertSpecialKebabCaseToCamelCase(rawProps: SsrNodeProps): SsrNodeProps {\n  const props = rawProps;\n\n  if (props['caret-color']) {\n    props.caretColor = props['caret-color'];\n    delete props['caret-color'];\n  }\n\n  if (props['underline-color-android']) {\n    props.underlineColorAndroid = props['underline-color-android'];\n    delete props['underline-color-android'];\n  }\n\n  if (props['placeholder-text-color']) {\n    props.placeholderTextColor = props['placeholder-text-color'];\n    delete props['placeholder-text-color'];\n  }\n\n  if (props['break-strategy']) {\n    props.breakStrategy = props['break-strategy'];\n    delete props['break-strategy'];\n  }\n\n  return props;\n}\n\n/**\n * convert ssr node list to hippy node list, add props for every node\n *\n * @param nodeList - ssr node list\n * @param options - hippy context\n */\nfunction convertToHippyNodeList(\n  nodeList: SsrNode[],\n  options: SsrRenderOption,\n): SsrNode[] {\n  return nodeList.map((item) => {\n    // add props for every node\n    const props = convertSpecialKebabCaseToCamelCase(getNodeProps(item, nodeList, options?.context?.isIOS));\n    return {\n      ...item,\n      props,\n    };\n  });\n}\n\n/**\n * flat hippy node tree to list structure\n *\n * @param parentNode - parent node\n * @param nodeList - flatted node list\n * @param pId - parent id\n * @param index - the index position of the current node among sibling nodes\n */\nfunction treeToList(\n  parentNode: SsrNode,\n  nodeList: SsrNode[] = [],\n  pId?: number,\n  index?: number,\n): SsrNode[] {\n  // parent node\n  nodeList.push({\n    id: parentNode.id,\n    pId: parentNode.pId ?? pId ?? 0,\n    index: index ?? 0,\n    name: parentNode.name,\n    props: parentNode.props,\n    tagName: parentNode.tagName,\n  });\n  // child node\n  const { children } = parentNode;\n  children?.forEach((v, i) => {\n    // filter native do not display node\n    let insertIndex = children.filter(c => c.name !== 'comment').indexOf(v);\n    // record the comment node index as the serial number of the current\n    // insertable child node, which is convenient for rebuilding the tree structure\n    if (v.name === 'comment') {\n      insertIndex = children\n        .slice(0, i)\n        .filter(c => c.name !== 'comment').length;\n    }\n    // handle all list\n    treeToList(v, nodeList, parentNode.id, insertIndex);\n  });\n\n  return nodeList;\n}\n\n/**\n * create ssr root node\n *\n * @param rootContainer - id of root node\n */\nfunction createSSRRootNode(rootContainer: string): SsrNode {\n  return {\n    id: 1, // root node id hardcode to 1\n    pId: 0, // root node's parent id set to 0, reset at client side\n    index: 0,\n    name: 'View',\n    props: {\n      style: { flex: 1, display: 'flex' },\n      attributes: { id: rootContainer, class: '' },\n    },\n    tagName: 'div',\n    children: [],\n  };\n}\n\n/**\n * key of ssr unique id\n */\nexport const SSR_UNIQUE_ID_KEY = 'ssrUniqueIdKey';\n\n/**\n * generate unique id base on currentId. if no currentId provide. 1 will be the default value\n *\n * @param currentId - current used unique Id\n */\nfunction generateUniqueId(currentId?: number): number {\n  let ssrUniqueId = currentId;\n  if (!ssrUniqueId) ssrUniqueId = 1;\n  ssrUniqueId += 1;\n\n  // ids divisible by 10 are used by the native\n  if (ssrUniqueId % 10 === 0) {\n    ssrUniqueId += 1;\n  }\n\n  return ssrUniqueId;\n}\n\n/**\n * generate hippy unique id at ssr. this is ssr helper\n *\n * @public\n */\nexport function ssrGetUniqueId(): number {\n  const currentInstance = getCurrentInstance();\n  const uniqueIdContext = currentInstance?.appContext?.provides[\n    SSR_UNIQUE_ID_KEY\n  ] as {\n    ssrUniqueId?: number;\n  };\n\n  // generate unique id, and save in global context\n  // unique id generated by current unique id\n  uniqueIdContext.ssrUniqueId = generateUniqueId(uniqueIdContext?.ssrUniqueId);\n  return uniqueIdContext.ssrUniqueId;\n}\n\n/**\n * get unique id at current vue app instance\n *\n * @param app - vue app instance\n *\n * @public\n */\nexport function getCurrentUniqueId(app: App): number {\n  return app._context.provides[SSR_UNIQUE_ID_KEY].ssrUniqueId;\n}\n\n/**\n * convert hippy node list json string to hippy native node tree\n *\n * @param app - vue ssr app\n * @param options - ssr options\n *\n * @public\n */\nexport async function renderToHippyList(\n  app: App,\n  options: SsrRenderOption,\n): Promise<SsrNode[] | null> {\n  const startUniqueId = 1;\n  const uniqueIdContext = { ssrUniqueId: startUniqueId };\n  // An additional context needs to be provided here because ssrContext is mounted after\n  // the render function is called, but ssrGetUniqueId will be called in the render function\n  app.provide(SSR_UNIQUE_ID_KEY, uniqueIdContext);\n  const { rootContainer } = options;\n  // first, create root node with rootContainer.\n  // In the non-hydration mode of the client, the rootContainer node is created by the client\n  const rootNode = createSSRRootNode(rootContainer);\n  // second, we get hippy native node list string generated by ssr\n  const appContent = await renderToString(app, options);\n  // third, make ssr node list as children of rootContainer\n  const ssrNodeTree = getObjectNodeList([appContent], rootNode);\n  // render failure, return null\n  if (!ssrNodeTree) {\n    return null;\n  }\n  // flat node tree to array list\n  const nodeList = treeToList(ssrNodeTree);\n  // comment list append at the end\n  const commentList = nodeList.filter(v => v.name === 'comment');\n  // last, convert ssr node list to hippy node list, we add node props and return with comment list\n  return convertToHippyNodeList(\n    nodeList.filter(v => v.name !== 'comment'),\n    options,\n  ).concat(commentList);\n}",
    "repo": "Tencent/Hippy",
    "path": "./datasets/diagrams-repos/Tencent/Hippy/driver/js/packages/hippy-vue-next-server-renderer/src/renderer.ts",
    "query": "What is the flow of data through the `getNodeProps` function and how are props merged?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'getNodeProps', 'node_id': 'getNodeProps', 'description': 'Processes and merges node properties for SSR', 'visibility': 'private', 'return_type': 'SsrNodeProps', 'params': '(node: SsrNode, nodeList: SsrNode[], isIOS?: boolean)', 'source_class_id': None}, {'type': 'function', 'name': 'mergeDefaultNativeProps', 'node_id': 'mergeDefaultNativeProps', 'description': 'Provides default props based on node type', 'visibility': 'private', 'return_type': 'SsrNodeProps', 'params': '(node: SsrNode, nodeList: SsrNode[])', 'source_class_id': None}, {'type': 'function', 'name': 'parseTextInputProps', 'node_id': 'parseTextInputProps', 'description': 'Transforms input properties for TextInput nodes', 'visibility': 'private', 'return_type': 'SsrCommonParams', 'params': '(tagName: string, rawProps: SsrCommonParams)', 'source_class_id': None}], 'edges': [{'node_id_from': 'getNodeProps', 'node_id_to': 'mergeDefaultNativeProps', 'description': 'Merges default props'}, {'node_id_from': 'getNodeProps', 'node_id_to': 'parseTextInputProps', 'description': 'Processes TextInput props'}], 'packages': [{'package_id': 'propProcessing', 'children': ['getNodeProps', 'mergeDefaultNativeProps', 'parseTextInputProps'], 'description': 'Core prop processing functionality'}]}",
    "version": "minimal",
    "text_answer": "The getNodeProps function processes props in three main steps: 1) merges default native props specific to node type, 2) combines them with existing props and merged props, 3) applies special handling for attributes, iOS compatibility, and TextInput nodes.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { getCurrentInstance, type App } from '@vue/runtime-core';\nimport { renderToString } from '@vue/server-renderer';\nimport type { HippyAppOptions } from '@hippy-vue-next/index';\nimport { getObjectNodeList } from './util';\nimport type {\n  SsrCommonParams,\n  SsrNode,\n  SsrNodeProps,\n} from './index';\n\n/**\n * SSR Request context type\n *\n * @public\n */\nexport interface SsrRequestContext {\n  isIOS?: boolean;\n  dimensions?: {\n    screen: {\n      width: number;\n      height: number;\n      statusBarHeight: number;\n    }\n  }\n}\n\n/**\n * SSR render options type\n */\ninterface SsrRenderOption {\n  rootContainer: string;\n  ssrOptions?: HippyAppOptions;\n  context?: SsrRequestContext;\n}\n\n// native text input type\nconst INPUT_VALUE_MAP = {\n  number: 'numeric',\n  text: 'default',\n  search: 'web-search',\n};\n\n/**\n * merge default props to ssr node. some native node should have default props, so we need to add\n * to prop. the same logic with client runtime\n *\n * @param node - ssrNode\n * @param nodeList - ssrNodeList\n */\nfunction mergeDefaultNativeProps(\n  node: SsrNode,\n  nodeList: SsrNode[],\n): SsrNodeProps {\n  const commonProps = { id: '', class: '' };\n  let defaultNativeProps: SsrNodeProps = {};\n\n  switch (node.name) {\n    case 'ListView':\n      defaultNativeProps = {\n        // calculate child nums\n        numberOfRows: nodeList.filter(v => v.pId === node.id).length,\n      };\n      break;\n    case 'Text':\n      defaultNativeProps = { text: '' };\n      break;\n    case 'TextInput':\n      defaultNativeProps = { underlineColorAndroid: 0 };\n      if (node.tagName === 'textarea') {\n        defaultNativeProps.numberOfLines = 5;\n      }\n      break;\n    case 'ViewPager':\n      defaultNativeProps = { initialPage: node.props.current };\n      break;\n    case 'WebView':\n      defaultNativeProps = {\n        method: 'get',\n        userAgent: '',\n      };\n      break;\n    case 'Modal':\n      defaultNativeProps = {\n        transparent: true,\n        immersionStatusBar: true,\n        collapsable: false,\n      };\n      break;\n    case 'Image':\n      defaultNativeProps = {\n        backgroundColor: 0,\n      };\n      break;\n    default:\n      break;\n  }\n  return Object.assign(commonProps, defaultNativeProps);\n}\n\n/**\n * parse text input map props\n *\n * @param tagName\n * @param rawProps\n */\nfunction parseTextInputProps(tagName: string, rawProps: SsrCommonParams): SsrCommonParams {\n  const props = rawProps;\n\n  // handle common input props map\n  if (props.type) {\n    props.keyboardType = INPUT_VALUE_MAP[props.type] ?? props.type;\n    delete props.type;\n  }\n  if (props.disabled) {\n    props.editable = !props.disabled;\n    delete props.disabled;\n  }\n  if (typeof props.value !== 'undefined') {\n    props.defaultValue = props.value;\n    delete props.value;\n  }\n  if (props.maxlength) {\n    props.maxLength = props.maxlength;\n    delete props.maxlength;\n  }\n\n  if (tagName === 'textarea') {\n    props.multiline = true;\n    // handle textarea props map\n    if (props.rows) {\n      props.numberOfLines = props.rows;\n      delete props.rows;\n    }\n  } else {\n    props.numberOfLines = 1;\n    props.multiline = false;\n  }\n\n  return props;\n}\n\n/**\n * get node's props. merge all props need to merged\n *\n * @param node - ssr node\n * @param nodeList - ssr node list\n * @param isIOS - client is iOS or not\n */\nfunction getNodeProps(\n  node: SsrNode,\n  nodeList: SsrNode[],\n  isIOS?: boolean,\n): SsrNodeProps {\n  let { props } = node;\n  // merge all props\n  props = {\n    ...mergeDefaultNativeProps(node, nodeList),\n    ...props,\n    ...props.mergedProps,\n  };\n  delete props.mergedProps;\n  // assign id and class to attribute props. id & class should use for devtools at client side\n  // and use for ssr\n  props.attributes = {\n    id: props?.attributes?.id ?? props.id,\n    class: props?.attributes?.class ?? props.class,\n  };\n  // delete unnecessary props\n  delete props.id;\n  delete props.class;\n  delete props.attributes.style;\n  delete props.attributes.text;\n\n  // compatible iOS image src and fontWeight\n  if (\n    isIOS && node.name === 'Image' && props.src\n  ) {\n    props.source = [{ uri: props.src }];\n    delete props.src;\n  }\n  // compatible fontWeight\n  if (props?.style?.fontWeight) {\n    props.style.fontWeight = String(props.style.fontWeight);\n  }\n  // compatible placeholder\n  if (typeof props.placeholder !== 'undefined') {\n    props.placeholder = String(props.placeholder);\n  }\n\n  if (node.name === 'TextInput') {\n    parseTextInputProps(node.tagName ?? '', props);\n  }\n\n  if (node.name === 'WebView') {\n    props.source = {\n      uri: props.src,\n    };\n    delete props.src;\n  }\n\n  return props;\n}\n\n/**\n * convert ssr node's special kebabCase props name to camelCase name\n *\n * @param rawProps\n */\nfunction convertSpecialKebabCaseToCamelCase(rawProps: SsrNodeProps): SsrNodeProps {\n  const props = rawProps;\n\n  if (props['caret-color']) {\n    props.caretColor = props['caret-color'];\n    delete props['caret-color'];\n  }\n\n  if (props['underline-color-android']) {\n    props.underlineColorAndroid = props['underline-color-android'];\n    delete props['underline-color-android'];\n  }\n\n  if (props['placeholder-text-color']) {\n    props.placeholderTextColor = props['placeholder-text-color'];\n    delete props['placeholder-text-color'];\n  }\n\n  if (props['break-strategy']) {\n    props.breakStrategy = props['break-strategy'];\n    delete props['break-strategy'];\n  }\n\n  return props;\n}\n\n/**\n * convert ssr node list to hippy node list, add props for every node\n *\n * @param nodeList - ssr node list\n * @param options - hippy context\n */\nfunction convertToHippyNodeList(\n  nodeList: SsrNode[],\n  options: SsrRenderOption,\n): SsrNode[] {\n  return nodeList.map((item) => {\n    // add props for every node\n    const props = convertSpecialKebabCaseToCamelCase(getNodeProps(item, nodeList, options?.context?.isIOS));\n    return {\n      ...item,\n      props,\n    };\n  });\n}\n\n/**\n * flat hippy node tree to list structure\n *\n * @param parentNode - parent node\n * @param nodeList - flatted node list\n * @param pId - parent id\n * @param index - the index position of the current node among sibling nodes\n */\nfunction treeToList(\n  parentNode: SsrNode,\n  nodeList: SsrNode[] = [],\n  pId?: number,\n  index?: number,\n): SsrNode[] {\n  // parent node\n  nodeList.push({\n    id: parentNode.id,\n    pId: parentNode.pId ?? pId ?? 0,\n    index: index ?? 0,\n    name: parentNode.name,\n    props: parentNode.props,\n    tagName: parentNode.tagName,\n  });\n  // child node\n  const { children } = parentNode;\n  children?.forEach((v, i) => {\n    // filter native do not display node\n    let insertIndex = children.filter(c => c.name !== 'comment').indexOf(v);\n    // record the comment node index as the serial number of the current\n    // insertable child node, which is convenient for rebuilding the tree structure\n    if (v.name === 'comment') {\n      insertIndex = children\n        .slice(0, i)\n        .filter(c => c.name !== 'comment').length;\n    }\n    // handle all list\n    treeToList(v, nodeList, parentNode.id, insertIndex);\n  });\n\n  return nodeList;\n}\n\n/**\n * create ssr root node\n *\n * @param rootContainer - id of root node\n */\nfunction createSSRRootNode(rootContainer: string): SsrNode {\n  return {\n    id: 1, // root node id hardcode to 1\n    pId: 0, // root node's parent id set to 0, reset at client side\n    index: 0,\n    name: 'View',\n    props: {\n      style: { flex: 1, display: 'flex' },\n      attributes: { id: rootContainer, class: '' },\n    },\n    tagName: 'div',\n    children: [],\n  };\n}\n\n/**\n * key of ssr unique id\n */\nexport const SSR_UNIQUE_ID_KEY = 'ssrUniqueIdKey';\n\n/**\n * generate unique id base on currentId. if no currentId provide. 1 will be the default value\n *\n * @param currentId - current used unique Id\n */\nfunction generateUniqueId(currentId?: number): number {\n  let ssrUniqueId = currentId;\n  if (!ssrUniqueId) ssrUniqueId = 1;\n  ssrUniqueId += 1;\n\n  // ids divisible by 10 are used by the native\n  if (ssrUniqueId % 10 === 0) {\n    ssrUniqueId += 1;\n  }\n\n  return ssrUniqueId;\n}\n\n/**\n * generate hippy unique id at ssr. this is ssr helper\n *\n * @public\n */\nexport function ssrGetUniqueId(): number {\n  const currentInstance = getCurrentInstance();\n  const uniqueIdContext = currentInstance?.appContext?.provides[\n    SSR_UNIQUE_ID_KEY\n  ] as {\n    ssrUniqueId?: number;\n  };\n\n  // generate unique id, and save in global context\n  // unique id generated by current unique id\n  uniqueIdContext.ssrUniqueId = generateUniqueId(uniqueIdContext?.ssrUniqueId);\n  return uniqueIdContext.ssrUniqueId;\n}\n\n/**\n * get unique id at current vue app instance\n *\n * @param app - vue app instance\n *\n * @public\n */\nexport function getCurrentUniqueId(app: App): number {\n  return app._context.provides[SSR_UNIQUE_ID_KEY].ssrUniqueId;\n}\n\n/**\n * convert hippy node list json string to hippy native node tree\n *\n * @param app - vue ssr app\n * @param options - ssr options\n *\n * @public\n */\nexport async function renderToHippyList(\n  app: App,\n  options: SsrRenderOption,\n): Promise<SsrNode[] | null> {\n  const startUniqueId = 1;\n  const uniqueIdContext = { ssrUniqueId: startUniqueId };\n  // An additional context needs to be provided here because ssrContext is mounted after\n  // the render function is called, but ssrGetUniqueId will be called in the render function\n  app.provide(SSR_UNIQUE_ID_KEY, uniqueIdContext);\n  const { rootContainer } = options;\n  // first, create root node with rootContainer.\n  // In the non-hydration mode of the client, the rootContainer node is created by the client\n  const rootNode = createSSRRootNode(rootContainer);\n  // second, we get hippy native node list string generated by ssr\n  const appContent = await renderToString(app, options);\n  // third, make ssr node list as children of rootContainer\n  const ssrNodeTree = getObjectNodeList([appContent], rootNode);\n  // render failure, return null\n  if (!ssrNodeTree) {\n    return null;\n  }\n  // flat node tree to array list\n  const nodeList = treeToList(ssrNodeTree);\n  // comment list append at the end\n  const commentList = nodeList.filter(v => v.name === 'comment');\n  // last, convert ssr node list to hippy node list, we add node props and return with comment list\n  return convertToHippyNodeList(\n    nodeList.filter(v => v.name !== 'comment'),\n    options,\n  ).concat(commentList);\n}",
    "repo": "Tencent/Hippy",
    "path": "./datasets/diagrams-repos/Tencent/Hippy/driver/js/packages/hippy-vue-next-server-renderer/src/renderer.ts",
    "query": "What is the flow of data through the `getNodeProps` function and how are props merged?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'getNodeProps', 'node_id': 'getNodeProps', 'description': 'Processes and merges node properties for SSR', 'visibility': 'private', 'return_type': 'SsrNodeProps', 'params': '(node: SsrNode, nodeList: SsrNode[], isIOS?: boolean)', 'source_class_id': None}, {'type': 'function', 'name': 'mergeDefaultNativeProps', 'node_id': 'mergeDefaultNativeProps', 'description': 'Provides default props based on node type', 'visibility': 'private', 'return_type': 'SsrNodeProps', 'params': '(node: SsrNode, nodeList: SsrNode[])', 'source_class_id': None}, {'type': 'function', 'name': 'parseTextInputProps', 'node_id': 'parseTextInputProps', 'description': 'Transforms input properties for TextInput nodes', 'visibility': 'private', 'return_type': 'SsrCommonParams', 'params': '(tagName: string, rawProps: SsrCommonParams)', 'source_class_id': None}, {'type': 'variable', 'name': 'INPUT_VALUE_MAP', 'node_id': 'INPUT_VALUE_MAP', 'description': 'Mapping for input types', 'visibility': 'private', 'return_type': 'object', 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'defaultProps', 'node_id': 'defaultProps', 'description': 'Default properties for different node types', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'getNodeProps', 'node_id_to': 'mergeDefaultNativeProps', 'description': 'Merges default props'}, {'node_id_from': 'getNodeProps', 'node_id_to': 'parseTextInputProps', 'description': 'Processes TextInput props'}, {'node_id_from': 'mergeDefaultNativeProps', 'node_id_to': 'defaultProps', 'description': 'Uses default props'}, {'node_id_from': 'parseTextInputProps', 'node_id_to': 'INPUT_VALUE_MAP', 'description': 'Uses input type mapping'}], 'packages': [{'package_id': 'propProcessing', 'children': ['getNodeProps', 'mergeDefaultNativeProps', 'parseTextInputProps'], 'description': 'Core prop processing functionality'}, {'package_id': 'constants', 'children': ['INPUT_VALUE_MAP', 'defaultProps'], 'description': 'Constants and default values'}]}",
    "version": "medium",
    "text_answer": "The getNodeProps function processes props in three main steps: 1) merges default native props specific to node type, 2) combines them with existing props and merged props, 3) applies special handling for attributes, iOS compatibility, and TextInput nodes.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport { getCurrentInstance, type App } from '@vue/runtime-core';\nimport { renderToString } from '@vue/server-renderer';\nimport type { HippyAppOptions } from '@hippy-vue-next/index';\nimport { getObjectNodeList } from './util';\nimport type {\n  SsrCommonParams,\n  SsrNode,\n  SsrNodeProps,\n} from './index';\n\n/**\n * SSR Request context type\n *\n * @public\n */\nexport interface SsrRequestContext {\n  isIOS?: boolean;\n  dimensions?: {\n    screen: {\n      width: number;\n      height: number;\n      statusBarHeight: number;\n    }\n  }\n}\n\n/**\n * SSR render options type\n */\ninterface SsrRenderOption {\n  rootContainer: string;\n  ssrOptions?: HippyAppOptions;\n  context?: SsrRequestContext;\n}\n\n// native text input type\nconst INPUT_VALUE_MAP = {\n  number: 'numeric',\n  text: 'default',\n  search: 'web-search',\n};\n\n/**\n * merge default props to ssr node. some native node should have default props, so we need to add\n * to prop. the same logic with client runtime\n *\n * @param node - ssrNode\n * @param nodeList - ssrNodeList\n */\nfunction mergeDefaultNativeProps(\n  node: SsrNode,\n  nodeList: SsrNode[],\n): SsrNodeProps {\n  const commonProps = { id: '', class: '' };\n  let defaultNativeProps: SsrNodeProps = {};\n\n  switch (node.name) {\n    case 'ListView':\n      defaultNativeProps = {\n        // calculate child nums\n        numberOfRows: nodeList.filter(v => v.pId === node.id).length,\n      };\n      break;\n    case 'Text':\n      defaultNativeProps = { text: '' };\n      break;\n    case 'TextInput':\n      defaultNativeProps = { underlineColorAndroid: 0 };\n      if (node.tagName === 'textarea') {\n        defaultNativeProps.numberOfLines = 5;\n      }\n      break;\n    case 'ViewPager':\n      defaultNativeProps = { initialPage: node.props.current };\n      break;\n    case 'WebView':\n      defaultNativeProps = {\n        method: 'get',\n        userAgent: '',\n      };\n      break;\n    case 'Modal':\n      defaultNativeProps = {\n        transparent: true,\n        immersionStatusBar: true,\n        collapsable: false,\n      };\n      break;\n    case 'Image':\n      defaultNativeProps = {\n        backgroundColor: 0,\n      };\n      break;\n    default:\n      break;\n  }\n  return Object.assign(commonProps, defaultNativeProps);\n}\n\n/**\n * parse text input map props\n *\n * @param tagName\n * @param rawProps\n */\nfunction parseTextInputProps(tagName: string, rawProps: SsrCommonParams): SsrCommonParams {\n  const props = rawProps;\n\n  // handle common input props map\n  if (props.type) {\n    props.keyboardType = INPUT_VALUE_MAP[props.type] ?? props.type;\n    delete props.type;\n  }\n  if (props.disabled) {\n    props.editable = !props.disabled;\n    delete props.disabled;\n  }\n  if (typeof props.value !== 'undefined') {\n    props.defaultValue = props.value;\n    delete props.value;\n  }\n  if (props.maxlength) {\n    props.maxLength = props.maxlength;\n    delete props.maxlength;\n  }\n\n  if (tagName === 'textarea') {\n    props.multiline = true;\n    // handle textarea props map\n    if (props.rows) {\n      props.numberOfLines = props.rows;\n      delete props.rows;\n    }\n  } else {\n    props.numberOfLines = 1;\n    props.multiline = false;\n  }\n\n  return props;\n}\n\n/**\n * get node's props. merge all props need to merged\n *\n * @param node - ssr node\n * @param nodeList - ssr node list\n * @param isIOS - client is iOS or not\n */\nfunction getNodeProps(\n  node: SsrNode,\n  nodeList: SsrNode[],\n  isIOS?: boolean,\n): SsrNodeProps {\n  let { props } = node;\n  // merge all props\n  props = {\n    ...mergeDefaultNativeProps(node, nodeList),\n    ...props,\n    ...props.mergedProps,\n  };\n  delete props.mergedProps;\n  // assign id and class to attribute props. id & class should use for devtools at client side\n  // and use for ssr\n  props.attributes = {\n    id: props?.attributes?.id ?? props.id,\n    class: props?.attributes?.class ?? props.class,\n  };\n  // delete unnecessary props\n  delete props.id;\n  delete props.class;\n  delete props.attributes.style;\n  delete props.attributes.text;\n\n  // compatible iOS image src and fontWeight\n  if (\n    isIOS && node.name === 'Image' && props.src\n  ) {\n    props.source = [{ uri: props.src }];\n    delete props.src;\n  }\n  // compatible fontWeight\n  if (props?.style?.fontWeight) {\n    props.style.fontWeight = String(props.style.fontWeight);\n  }\n  // compatible placeholder\n  if (typeof props.placeholder !== 'undefined') {\n    props.placeholder = String(props.placeholder);\n  }\n\n  if (node.name === 'TextInput') {\n    parseTextInputProps(node.tagName ?? '', props);\n  }\n\n  if (node.name === 'WebView') {\n    props.source = {\n      uri: props.src,\n    };\n    delete props.src;\n  }\n\n  return props;\n}\n\n/**\n * convert ssr node's special kebabCase props name to camelCase name\n *\n * @param rawProps\n */\nfunction convertSpecialKebabCaseToCamelCase(rawProps: SsrNodeProps): SsrNodeProps {\n  const props = rawProps;\n\n  if (props['caret-color']) {\n    props.caretColor = props['caret-color'];\n    delete props['caret-color'];\n  }\n\n  if (props['underline-color-android']) {\n    props.underlineColorAndroid = props['underline-color-android'];\n    delete props['underline-color-android'];\n  }\n\n  if (props['placeholder-text-color']) {\n    props.placeholderTextColor = props['placeholder-text-color'];\n    delete props['placeholder-text-color'];\n  }\n\n  if (props['break-strategy']) {\n    props.breakStrategy = props['break-strategy'];\n    delete props['break-strategy'];\n  }\n\n  return props;\n}\n\n/**\n * convert ssr node list to hippy node list, add props for every node\n *\n * @param nodeList - ssr node list\n * @param options - hippy context\n */\nfunction convertToHippyNodeList(\n  nodeList: SsrNode[],\n  options: SsrRenderOption,\n): SsrNode[] {\n  return nodeList.map((item) => {\n    // add props for every node\n    const props = convertSpecialKebabCaseToCamelCase(getNodeProps(item, nodeList, options?.context?.isIOS));\n    return {\n      ...item,\n      props,\n    };\n  });\n}\n\n/**\n * flat hippy node tree to list structure\n *\n * @param parentNode - parent node\n * @param nodeList - flatted node list\n * @param pId - parent id\n * @param index - the index position of the current node among sibling nodes\n */\nfunction treeToList(\n  parentNode: SsrNode,\n  nodeList: SsrNode[] = [],\n  pId?: number,\n  index?: number,\n): SsrNode[] {\n  // parent node\n  nodeList.push({\n    id: parentNode.id,\n    pId: parentNode.pId ?? pId ?? 0,\n    index: index ?? 0,\n    name: parentNode.name,\n    props: parentNode.props,\n    tagName: parentNode.tagName,\n  });\n  // child node\n  const { children } = parentNode;\n  children?.forEach((v, i) => {\n    // filter native do not display node\n    let insertIndex = children.filter(c => c.name !== 'comment').indexOf(v);\n    // record the comment node index as the serial number of the current\n    // insertable child node, which is convenient for rebuilding the tree structure\n    if (v.name === 'comment') {\n      insertIndex = children\n        .slice(0, i)\n        .filter(c => c.name !== 'comment').length;\n    }\n    // handle all list\n    treeToList(v, nodeList, parentNode.id, insertIndex);\n  });\n\n  return nodeList;\n}\n\n/**\n * create ssr root node\n *\n * @param rootContainer - id of root node\n */\nfunction createSSRRootNode(rootContainer: string): SsrNode {\n  return {\n    id: 1, // root node id hardcode to 1\n    pId: 0, // root node's parent id set to 0, reset at client side\n    index: 0,\n    name: 'View',\n    props: {\n      style: { flex: 1, display: 'flex' },\n      attributes: { id: rootContainer, class: '' },\n    },\n    tagName: 'div',\n    children: [],\n  };\n}\n\n/**\n * key of ssr unique id\n */\nexport const SSR_UNIQUE_ID_KEY = 'ssrUniqueIdKey';\n\n/**\n * generate unique id base on currentId. if no currentId provide. 1 will be the default value\n *\n * @param currentId - current used unique Id\n */\nfunction generateUniqueId(currentId?: number): number {\n  let ssrUniqueId = currentId;\n  if (!ssrUniqueId) ssrUniqueId = 1;\n  ssrUniqueId += 1;\n\n  // ids divisible by 10 are used by the native\n  if (ssrUniqueId % 10 === 0) {\n    ssrUniqueId += 1;\n  }\n\n  return ssrUniqueId;\n}\n\n/**\n * generate hippy unique id at ssr. this is ssr helper\n *\n * @public\n */\nexport function ssrGetUniqueId(): number {\n  const currentInstance = getCurrentInstance();\n  const uniqueIdContext = currentInstance?.appContext?.provides[\n    SSR_UNIQUE_ID_KEY\n  ] as {\n    ssrUniqueId?: number;\n  };\n\n  // generate unique id, and save in global context\n  // unique id generated by current unique id\n  uniqueIdContext.ssrUniqueId = generateUniqueId(uniqueIdContext?.ssrUniqueId);\n  return uniqueIdContext.ssrUniqueId;\n}\n\n/**\n * get unique id at current vue app instance\n *\n * @param app - vue app instance\n *\n * @public\n */\nexport function getCurrentUniqueId(app: App): number {\n  return app._context.provides[SSR_UNIQUE_ID_KEY].ssrUniqueId;\n}\n\n/**\n * convert hippy node list json string to hippy native node tree\n *\n * @param app - vue ssr app\n * @param options - ssr options\n *\n * @public\n */\nexport async function renderToHippyList(\n  app: App,\n  options: SsrRenderOption,\n): Promise<SsrNode[] | null> {\n  const startUniqueId = 1;\n  const uniqueIdContext = { ssrUniqueId: startUniqueId };\n  // An additional context needs to be provided here because ssrContext is mounted after\n  // the render function is called, but ssrGetUniqueId will be called in the render function\n  app.provide(SSR_UNIQUE_ID_KEY, uniqueIdContext);\n  const { rootContainer } = options;\n  // first, create root node with rootContainer.\n  // In the non-hydration mode of the client, the rootContainer node is created by the client\n  const rootNode = createSSRRootNode(rootContainer);\n  // second, we get hippy native node list string generated by ssr\n  const appContent = await renderToString(app, options);\n  // third, make ssr node list as children of rootContainer\n  const ssrNodeTree = getObjectNodeList([appContent], rootNode);\n  // render failure, return null\n  if (!ssrNodeTree) {\n    return null;\n  }\n  // flat node tree to array list\n  const nodeList = treeToList(ssrNodeTree);\n  // comment list append at the end\n  const commentList = nodeList.filter(v => v.name === 'comment');\n  // last, convert ssr node list to hippy node list, we add node props and return with comment list\n  return convertToHippyNodeList(\n    nodeList.filter(v => v.name !== 'comment'),\n    options,\n  ).concat(commentList);\n}",
    "repo": "Tencent/Hippy",
    "path": "./datasets/diagrams-repos/Tencent/Hippy/driver/js/packages/hippy-vue-next-server-renderer/src/renderer.ts",
    "query": "What is the flow of data through the `getNodeProps` function and how are props merged?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'getNodeProps', 'node_id': 'getNodeProps', 'description': 'Processes and merges node properties for SSR', 'visibility': 'private', 'return_type': 'SsrNodeProps', 'params': '(node: SsrNode, nodeList: SsrNode[], isIOS?: boolean)', 'source_class_id': None}, {'type': 'function', 'name': 'mergeDefaultNativeProps', 'node_id': 'mergeDefaultNativeProps', 'description': 'Provides default props based on node type', 'visibility': 'private', 'return_type': 'SsrNodeProps', 'params': '(node: SsrNode, nodeList: SsrNode[])', 'source_class_id': None}, {'type': 'function', 'name': 'parseTextInputProps', 'node_id': 'parseTextInputProps', 'description': 'Transforms input properties for TextInput nodes', 'visibility': 'private', 'return_type': 'SsrCommonParams', 'params': '(tagName: string, rawProps: SsrCommonParams)', 'source_class_id': None}, {'type': 'variable', 'name': 'INPUT_VALUE_MAP', 'node_id': 'INPUT_VALUE_MAP', 'description': 'Mapping for input types', 'visibility': 'private', 'return_type': 'object', 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'defaultProps', 'node_id': 'defaultProps', 'description': 'Default properties for different node types', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'commonProps', 'node_id': 'commonProps', 'description': 'Common properties for all nodes', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'nodeSpecificProps', 'node_id': 'nodeSpecificProps', 'description': 'Specific properties for different node types', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'iOSSpecificProps', 'node_id': 'iOSSpecificProps', 'description': 'iOS-specific property handling', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'attributeProps', 'node_id': 'attributeProps', 'description': 'Properties related to attributes', 'visibility': 'private', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'getNodeProps', 'node_id_to': 'mergeDefaultNativeProps', 'description': 'Merges default props'}, {'node_id_from': 'getNodeProps', 'node_id_to': 'parseTextInputProps', 'description': 'Processes TextInput props'}, {'node_id_from': 'mergeDefaultNativeProps', 'node_id_to': 'defaultProps', 'description': 'Uses default props'}, {'node_id_from': 'parseTextInputProps', 'node_id_to': 'INPUT_VALUE_MAP', 'description': 'Uses input type mapping'}, {'node_id_from': 'getNodeProps', 'node_id_to': 'commonProps', 'description': 'Merges common props'}, {'node_id_from': 'getNodeProps', 'node_id_to': 'nodeSpecificProps', 'description': 'Handles node-specific props'}, {'node_id_from': 'getNodeProps', 'node_id_to': 'iOSSpecificProps', 'description': 'Processes iOS-specific props'}, {'node_id_from': 'getNodeProps', 'node_id_to': 'attributeProps', 'description': 'Handles attribute props'}], 'packages': [{'package_id': 'propProcessing', 'children': ['getNodeProps', 'mergeDefaultNativeProps', 'parseTextInputProps'], 'description': 'Core prop processing functionality'}, {'package_id': 'constants', 'children': ['INPUT_VALUE_MAP', 'defaultProps'], 'description': 'Constants and default values'}, {'package_id': 'propTypes', 'children': ['commonProps', 'nodeSpecificProps', 'iOSSpecificProps', 'attributeProps'], 'description': 'Different types of properties'}]}",
    "version": "full",
    "text_answer": "The getNodeProps function processes props in three main steps: 1) merges default native props specific to node type, 2) combines them with existing props and merged props, 3) applies special handling for attributes, iOS compatibility, and TextInput nodes.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Kotlin",
    "code": "\npackage androidx.privacysandbox.ads.adservices.topics\n\nimport android.adservices.topics.EncryptedTopic\nimport android.adservices.topics.GetTopicsResponse\nimport android.adservices.topics.Topic\nimport android.annotation.SuppressLint\nimport androidx.privacysandbox.ads.adservices.common.ExperimentalFeatures\nimport androidx.privacysandbox.ads.adservices.internal.AdServicesInfo\nimport androidx.test.ext.junit.runners.AndroidJUnit4\nimport androidx.test.filters.SmallTest\nimport kotlin.test.assertContains\nimport kotlin.test.assertEquals\nimport org.junit.Assume\nimport org.junit.Test\nimport org.junit.runner.RunWith\n\n@SuppressLint(\"NewApi\")\n@SmallTest\n@RunWith(AndroidJUnit4::class)\n@ExperimentalFeatures.Ext11OptIn\nclass GetTopicsResponseHelperTest {\n    private val mValidAdServicesSdkExt4Version = AdServicesInfo.adServicesVersion() >= 4\n    private val mValidAdServicesSdkExt11Version = AdServicesInfo.adServicesVersion() >= 11\n    private val mValidAdExtServicesSdkExt9Version = AdServicesInfo.extServicesVersionS() >= 9\n    private val mValidAdExtServicesSdkExt11Version = AdServicesInfo.extServicesVersionS() >= 11\n\n    // Verify legacy tests with just plaintext topics\n    @Suppress(\"DEPRECATION\")\n    @Test\n    fun testResponse() {\n        Assume.assumeTrue(\n            \"minSdkVersion = API 33 ext 4 or API 31/32 ext 9\",\n            mValidAdServicesSdkExt4Version || mValidAdExtServicesSdkExt9Version,\n        )\n\n        var topic1 = Topic(3, 7, 10023)\n        var topic2 = Topic(3, 7, 10024)\n\n        var response = GetTopicsResponse.Builder(listOf(topic1, topic2)).build()\n        var convertedResponse = GetTopicsResponseHelper.convertResponse(response)\n\n        assertEquals(2, convertedResponse.topics.size)\n        assertContains(\n            convertedResponse.topics,\n            androidx.privacysandbox.ads.adservices.topics.Topic(3, 7, 10023),\n        )\n    }\n\n    @Test\n    fun testResponseWithEncryptedTopics() {\n        Assume.assumeTrue(\n            \"minSdkVersion = API 33 ext 11 or API 31/32 ext 11\",\n            mValidAdServicesSdkExt11Version || mValidAdExtServicesSdkExt11Version,\n        )\n\n        var topic1 = Topic(3, 7, 10023)\n        var topic2 = Topic(3, 7, 10024)\n        var encryptedTopic1 =\n            EncryptedTopic(\n                \"encryptedTopic\".toByteArray(),\n                \"publicKey\",\n                \"encapsulatedKey\".toByteArray(),\n            )\n\n        var response =\n            GetTopicsResponse.Builder(listOf(topic1, topic2), listOf(encryptedTopic1)).build()\n        var convertedResponse = GetTopicsResponseHelper.convertResponseWithEncryptedTopics(response)\n\n        assertEquals(2, convertedResponse.topics.size)\n        assertEquals(1, convertedResponse.encryptedTopics.size)\n        assertContains(\n            convertedResponse.topics,\n            androidx.privacysandbox.ads.adservices.topics.Topic(3, 7, 10023),\n        )\n        assertContains(\n            convertedResponse.encryptedTopics,\n            androidx.privacysandbox.ads.adservices.topics.EncryptedTopic(\n                \"encryptedTopic\".toByteArray(),\n                \"publicKey\",\n                \"encapsulatedKey\".toByteArray(),\n            ),\n        )\n    }\n}",
    "repo": "androidx/androidx",
    "path": "./datasets/diagrams-repos/androidx/androidx/privacysandbox/ads/ads-adservices/src/androidTest/java/androidx/privacysandbox/ads/adservices/topics/GetTopicsResponseHelperTest.kt",
    "query": "How are AdServices SDK versions checked in the tests?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'GetTopicsResponseHelperTest', 'node_id': 'GetTopicsResponseHelperTest', 'description': 'Test class for GetTopicsResponseHelper', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'mValidAdServicesSdkExt4Version', 'node_id': 'mValidAdServicesSdkExt4Version', 'description': 'Flag indicating if AdServices SDK version is >= 4', 'visibility': 'private', 'return_type': 'Boolean', 'params': None, 'source_class_id': 'GetTopicsResponseHelperTest'}, {'type': 'field', 'name': 'mValidAdServicesSdkExt11Version', 'node_id': 'mValidAdServicesSdkExt11Version', 'description': 'Flag indicating if AdServices SDK version is >= 11', 'visibility': 'private', 'return_type': 'Boolean', 'params': None, 'source_class_id': 'GetTopicsResponseHelperTest'}, {'type': 'function', 'name': 'adServicesVersion', 'node_id': 'adServicesVersion', 'description': 'Returns current AdServices SDK version', 'visibility': 'public', 'return_type': 'Int', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'adServicesVersion', 'node_id_to': 'mValidAdServicesSdkExt4Version', 'description': 'used to check version >= 4'}, {'node_id_from': 'adServicesVersion', 'node_id_to': 'mValidAdServicesSdkExt11Version', 'description': 'used to check version >= 11'}, {'node_id_from': 'GetTopicsResponseHelperTest', 'node_id_to': 'mValidAdServicesSdkExt4Version', 'description': ''}, {'node_id_from': 'GetTopicsResponseHelperTest', 'node_id_to': 'mValidAdServicesSdkExt11Version', 'description': ''}], 'packages': [{'package_id': 'versionChecks', 'children': ['mValidAdServicesSdkExt4Version', 'mValidAdServicesSdkExt11Version', 'adServicesVersion'], 'description': 'Version checking functionality'}]}",
    "version": "minimal",
    "text_answer": "AdServices SDK versions are checked using four boolean fields that compare the current SDK versions against specific thresholds (4, 9, 11) using AdServicesInfo.adServicesVersion() and AdServicesInfo.extServicesVersionS() methods. These checks are used to ensure compatibility before running specific tests.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Kotlin",
    "code": "\npackage androidx.privacysandbox.ads.adservices.topics\n\nimport android.adservices.topics.EncryptedTopic\nimport android.adservices.topics.GetTopicsResponse\nimport android.adservices.topics.Topic\nimport android.annotation.SuppressLint\nimport androidx.privacysandbox.ads.adservices.common.ExperimentalFeatures\nimport androidx.privacysandbox.ads.adservices.internal.AdServicesInfo\nimport androidx.test.ext.junit.runners.AndroidJUnit4\nimport androidx.test.filters.SmallTest\nimport kotlin.test.assertContains\nimport kotlin.test.assertEquals\nimport org.junit.Assume\nimport org.junit.Test\nimport org.junit.runner.RunWith\n\n@SuppressLint(\"NewApi\")\n@SmallTest\n@RunWith(AndroidJUnit4::class)\n@ExperimentalFeatures.Ext11OptIn\nclass GetTopicsResponseHelperTest {\n    private val mValidAdServicesSdkExt4Version = AdServicesInfo.adServicesVersion() >= 4\n    private val mValidAdServicesSdkExt11Version = AdServicesInfo.adServicesVersion() >= 11\n    private val mValidAdExtServicesSdkExt9Version = AdServicesInfo.extServicesVersionS() >= 9\n    private val mValidAdExtServicesSdkExt11Version = AdServicesInfo.extServicesVersionS() >= 11\n\n    // Verify legacy tests with just plaintext topics\n    @Suppress(\"DEPRECATION\")\n    @Test\n    fun testResponse() {\n        Assume.assumeTrue(\n            \"minSdkVersion = API 33 ext 4 or API 31/32 ext 9\",\n            mValidAdServicesSdkExt4Version || mValidAdExtServicesSdkExt9Version,\n        )\n\n        var topic1 = Topic(3, 7, 10023)\n        var topic2 = Topic(3, 7, 10024)\n\n        var response = GetTopicsResponse.Builder(listOf(topic1, topic2)).build()\n        var convertedResponse = GetTopicsResponseHelper.convertResponse(response)\n\n        assertEquals(2, convertedResponse.topics.size)\n        assertContains(\n            convertedResponse.topics,\n            androidx.privacysandbox.ads.adservices.topics.Topic(3, 7, 10023),\n        )\n    }\n\n    @Test\n    fun testResponseWithEncryptedTopics() {\n        Assume.assumeTrue(\n            \"minSdkVersion = API 33 ext 11 or API 31/32 ext 11\",\n            mValidAdServicesSdkExt11Version || mValidAdExtServicesSdkExt11Version,\n        )\n\n        var topic1 = Topic(3, 7, 10023)\n        var topic2 = Topic(3, 7, 10024)\n        var encryptedTopic1 =\n            EncryptedTopic(\n                \"encryptedTopic\".toByteArray(),\n                \"publicKey\",\n                \"encapsulatedKey\".toByteArray(),\n            )\n\n        var response =\n            GetTopicsResponse.Builder(listOf(topic1, topic2), listOf(encryptedTopic1)).build()\n        var convertedResponse = GetTopicsResponseHelper.convertResponseWithEncryptedTopics(response)\n\n        assertEquals(2, convertedResponse.topics.size)\n        assertEquals(1, convertedResponse.encryptedTopics.size)\n        assertContains(\n            convertedResponse.topics,\n            androidx.privacysandbox.ads.adservices.topics.Topic(3, 7, 10023),\n        )\n        assertContains(\n            convertedResponse.encryptedTopics,\n            androidx.privacysandbox.ads.adservices.topics.EncryptedTopic(\n                \"encryptedTopic\".toByteArray(),\n                \"publicKey\",\n                \"encapsulatedKey\".toByteArray(),\n            ),\n        )\n    }\n}",
    "repo": "androidx/androidx",
    "path": "./datasets/diagrams-repos/androidx/androidx/privacysandbox/ads/ads-adservices/src/androidTest/java/androidx/privacysandbox/ads/adservices/topics/GetTopicsResponseHelperTest.kt",
    "query": "How are AdServices SDK versions checked in the tests?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'GetTopicsResponseHelperTest', 'node_id': 'GetTopicsResponseHelperTest', 'description': 'Test class for GetTopicsResponseHelper', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'mValidAdServicesSdkExt4Version', 'node_id': 'mValidAdServicesSdkExt4Version', 'description': 'Flag indicating if AdServices SDK version is >= 4', 'visibility': 'private', 'return_type': 'Boolean', 'params': None, 'source_class_id': 'GetTopicsResponseHelperTest'}, {'type': 'field', 'name': 'mValidAdServicesSdkExt11Version', 'node_id': 'mValidAdServicesSdkExt11Version', 'description': 'Flag indicating if AdServices SDK version is >= 11', 'visibility': 'private', 'return_type': 'Boolean', 'params': None, 'source_class_id': 'GetTopicsResponseHelperTest'}, {'type': 'field', 'name': 'mValidAdExtServicesSdkExt9Version', 'node_id': 'mValidAdExtServicesSdkExt9Version', 'description': 'Flag indicating if AdExt Services SDK version is >= 9', 'visibility': 'private', 'return_type': 'Boolean', 'params': None, 'source_class_id': 'GetTopicsResponseHelperTest'}, {'type': 'field', 'name': 'mValidAdExtServicesSdkExt11Version', 'node_id': 'mValidAdExtServicesSdkExt11Version', 'description': 'Flag indicating if AdExt Services SDK version is >= 11', 'visibility': 'private', 'return_type': 'Boolean', 'params': None, 'source_class_id': 'GetTopicsResponseHelperTest'}, {'type': 'function', 'name': 'adServicesVersion', 'node_id': 'adServicesVersion', 'description': 'Returns current AdServices SDK version', 'visibility': 'public', 'return_type': 'Int', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'extServicesVersionS', 'node_id': 'extServicesVersionS', 'description': 'Returns current AdExt Services SDK version', 'visibility': 'public', 'return_type': 'Int', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'adServicesVersion', 'node_id_to': 'mValidAdServicesSdkExt4Version', 'description': 'used to check version >= 4'}, {'node_id_from': 'adServicesVersion', 'node_id_to': 'mValidAdServicesSdkExt11Version', 'description': 'used to check version >= 11'}, {'node_id_from': 'extServicesVersionS', 'node_id_to': 'mValidAdExtServicesSdkExt9Version', 'description': 'used to check version >= 9'}, {'node_id_from': 'extServicesVersionS', 'node_id_to': 'mValidAdExtServicesSdkExt11Version', 'description': 'used to check version >= 11'}, {'node_id_from': 'GetTopicsResponseHelperTest', 'node_id_to': 'mValidAdServicesSdkExt4Version', 'description': ''}, {'node_id_from': 'GetTopicsResponseHelperTest', 'node_id_to': 'mValidAdServicesSdkExt11Version', 'description': ''}, {'node_id_from': 'GetTopicsResponseHelperTest', 'node_id_to': 'mValidAdExtServicesSdkExt9Version', 'description': ''}, {'node_id_from': 'GetTopicsResponseHelperTest', 'node_id_to': 'mValidAdExtServicesSdkExt11Version', 'description': ''}], 'packages': [{'package_id': 'versionChecks', 'children': ['mValidAdServicesSdkExt4Version', 'mValidAdServicesSdkExt11Version', 'mValidAdExtServicesSdkExt9Version', 'mValidAdExtServicesSdkExt11Version', 'adServicesVersion', 'extServicesVersionS'], 'description': 'Version checking functionality'}]}",
    "version": "medium",
    "text_answer": "AdServices SDK versions are checked using four boolean fields that compare the current SDK versions against specific thresholds (4, 9, 11) using AdServicesInfo.adServicesVersion() and AdServicesInfo.extServicesVersionS() methods. These checks are used to ensure compatibility before running specific tests.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Kotlin",
    "code": "\npackage androidx.privacysandbox.ads.adservices.topics\n\nimport android.adservices.topics.EncryptedTopic\nimport android.adservices.topics.GetTopicsResponse\nimport android.adservices.topics.Topic\nimport android.annotation.SuppressLint\nimport androidx.privacysandbox.ads.adservices.common.ExperimentalFeatures\nimport androidx.privacysandbox.ads.adservices.internal.AdServicesInfo\nimport androidx.test.ext.junit.runners.AndroidJUnit4\nimport androidx.test.filters.SmallTest\nimport kotlin.test.assertContains\nimport kotlin.test.assertEquals\nimport org.junit.Assume\nimport org.junit.Test\nimport org.junit.runner.RunWith\n\n@SuppressLint(\"NewApi\")\n@SmallTest\n@RunWith(AndroidJUnit4::class)\n@ExperimentalFeatures.Ext11OptIn\nclass GetTopicsResponseHelperTest {\n    private val mValidAdServicesSdkExt4Version = AdServicesInfo.adServicesVersion() >= 4\n    private val mValidAdServicesSdkExt11Version = AdServicesInfo.adServicesVersion() >= 11\n    private val mValidAdExtServicesSdkExt9Version = AdServicesInfo.extServicesVersionS() >= 9\n    private val mValidAdExtServicesSdkExt11Version = AdServicesInfo.extServicesVersionS() >= 11\n\n    // Verify legacy tests with just plaintext topics\n    @Suppress(\"DEPRECATION\")\n    @Test\n    fun testResponse() {\n        Assume.assumeTrue(\n            \"minSdkVersion = API 33 ext 4 or API 31/32 ext 9\",\n            mValidAdServicesSdkExt4Version || mValidAdExtServicesSdkExt9Version,\n        )\n\n        var topic1 = Topic(3, 7, 10023)\n        var topic2 = Topic(3, 7, 10024)\n\n        var response = GetTopicsResponse.Builder(listOf(topic1, topic2)).build()\n        var convertedResponse = GetTopicsResponseHelper.convertResponse(response)\n\n        assertEquals(2, convertedResponse.topics.size)\n        assertContains(\n            convertedResponse.topics,\n            androidx.privacysandbox.ads.adservices.topics.Topic(3, 7, 10023),\n        )\n    }\n\n    @Test\n    fun testResponseWithEncryptedTopics() {\n        Assume.assumeTrue(\n            \"minSdkVersion = API 33 ext 11 or API 31/32 ext 11\",\n            mValidAdServicesSdkExt11Version || mValidAdExtServicesSdkExt11Version,\n        )\n\n        var topic1 = Topic(3, 7, 10023)\n        var topic2 = Topic(3, 7, 10024)\n        var encryptedTopic1 =\n            EncryptedTopic(\n                \"encryptedTopic\".toByteArray(),\n                \"publicKey\",\n                \"encapsulatedKey\".toByteArray(),\n            )\n\n        var response =\n            GetTopicsResponse.Builder(listOf(topic1, topic2), listOf(encryptedTopic1)).build()\n        var convertedResponse = GetTopicsResponseHelper.convertResponseWithEncryptedTopics(response)\n\n        assertEquals(2, convertedResponse.topics.size)\n        assertEquals(1, convertedResponse.encryptedTopics.size)\n        assertContains(\n            convertedResponse.topics,\n            androidx.privacysandbox.ads.adservices.topics.Topic(3, 7, 10023),\n        )\n        assertContains(\n            convertedResponse.encryptedTopics,\n            androidx.privacysandbox.ads.adservices.topics.EncryptedTopic(\n                \"encryptedTopic\".toByteArray(),\n                \"publicKey\",\n                \"encapsulatedKey\".toByteArray(),\n            ),\n        )\n    }\n}",
    "repo": "androidx/androidx",
    "path": "./datasets/diagrams-repos/androidx/androidx/privacysandbox/ads/ads-adservices/src/androidTest/java/androidx/privacysandbox/ads/adservices/topics/GetTopicsResponseHelperTest.kt",
    "query": "How are AdServices SDK versions checked in the tests?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'GetTopicsResponseHelperTest', 'node_id': 'GetTopicsResponseHelperTest', 'description': 'Test class for GetTopicsResponseHelper', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'mValidAdServicesSdkExt4Version', 'node_id': 'mValidAdServicesSdkExt4Version', 'description': 'Flag indicating if AdServices SDK version is >= 4', 'visibility': 'private', 'return_type': 'Boolean', 'params': None, 'source_class_id': 'GetTopicsResponseHelperTest'}, {'type': 'field', 'name': 'mValidAdServicesSdkExt11Version', 'node_id': 'mValidAdServicesSdkExt11Version', 'description': 'Flag indicating if AdServices SDK version is >= 11', 'visibility': 'private', 'return_type': 'Boolean', 'params': None, 'source_class_id': 'GetTopicsResponseHelperTest'}, {'type': 'field', 'name': 'mValidAdExtServicesSdkExt9Version', 'node_id': 'mValidAdExtServicesSdkExt9Version', 'description': 'Flag indicating if AdExt Services SDK version is >= 9', 'visibility': 'private', 'return_type': 'Boolean', 'params': None, 'source_class_id': 'GetTopicsResponseHelperTest'}, {'type': 'field', 'name': 'mValidAdExtServicesSdkExt11Version', 'node_id': 'mValidAdExtServicesSdkExt11Version', 'description': 'Flag indicating if AdExt Services SDK version is >= 11', 'visibility': 'private', 'return_type': 'Boolean', 'params': None, 'source_class_id': 'GetTopicsResponseHelperTest'}, {'type': 'function', 'name': 'adServicesVersion', 'node_id': 'adServicesVersion', 'description': 'Returns current AdServices SDK version', 'visibility': 'public', 'return_type': 'Int', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'extServicesVersionS', 'node_id': 'extServicesVersionS', 'description': 'Returns current AdExt Services SDK version', 'visibility': 'public', 'return_type': 'Int', 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'testResponse', 'node_id': 'testResponse', 'description': 'Tests response with plaintext topics', 'visibility': 'public', 'return_type': 'void', 'params': None, 'source_class_id': 'GetTopicsResponseHelperTest'}, {'type': 'method', 'name': 'testResponseWithEncryptedTopics', 'node_id': 'testResponseWithEncryptedTopics', 'description': 'Tests response with encrypted topics', 'visibility': 'public', 'return_type': 'void', 'params': None, 'source_class_id': 'GetTopicsResponseHelperTest'}], 'edges': [{'node_id_from': 'adServicesVersion', 'node_id_to': 'mValidAdServicesSdkExt4Version', 'description': 'used to check version >= 4'}, {'node_id_from': 'adServicesVersion', 'node_id_to': 'mValidAdServicesSdkExt11Version', 'description': 'used to check version >= 11'}, {'node_id_from': 'extServicesVersionS', 'node_id_to': 'mValidAdExtServicesSdkExt9Version', 'description': 'used to check version >= 9'}, {'node_id_from': 'extServicesVersionS', 'node_id_to': 'mValidAdExtServicesSdkExt11Version', 'description': 'used to check version >= 11'}, {'node_id_from': 'testResponse', 'node_id_to': 'mValidAdServicesSdkExt4Version', 'description': 'checks version compatibility'}, {'node_id_from': 'testResponse', 'node_id_to': 'mValidAdExtServicesSdkExt9Version', 'description': 'checks version compatibility'}, {'node_id_from': 'testResponseWithEncryptedTopics', 'node_id_to': 'mValidAdServicesSdkExt11Version', 'description': 'checks version compatibility'}, {'node_id_from': 'testResponseWithEncryptedTopics', 'node_id_to': 'mValidAdExtServicesSdkExt11Version', 'description': 'checks version compatibility'}, {'node_id_from': 'GetTopicsResponseHelperTest', 'node_id_to': 'testResponse', 'description': ''}, {'node_id_from': 'GetTopicsResponseHelperTest', 'node_id_to': 'testResponseWithEncryptedTopics', 'description': ''}, {'node_id_from': 'GetTopicsResponseHelperTest', 'node_id_to': 'mValidAdServicesSdkExt4Version', 'description': ''}, {'node_id_from': 'GetTopicsResponseHelperTest', 'node_id_to': 'mValidAdServicesSdkExt11Version', 'description': ''}, {'node_id_from': 'GetTopicsResponseHelperTest', 'node_id_to': 'mValidAdExtServicesSdkExt9Version', 'description': ''}, {'node_id_from': 'GetTopicsResponseHelperTest', 'node_id_to': 'mValidAdExtServicesSdkExt11Version', 'description': ''}], 'packages': [{'package_id': 'versionChecks', 'children': ['mValidAdServicesSdkExt4Version', 'mValidAdServicesSdkExt11Version', 'mValidAdExtServicesSdkExt9Version', 'mValidAdExtServicesSdkExt11Version', 'adServicesVersion', 'extServicesVersionS'], 'description': 'Version checking functionality'}, {'package_id': 'tests', 'children': ['testResponse', 'testResponseWithEncryptedTopics'], 'description': 'Test methods'}]}",
    "version": "full",
    "text_answer": "AdServices SDK versions are checked using four boolean fields that compare the current SDK versions against specific thresholds (4, 9, 11) using AdServicesInfo.adServicesVersion() and AdServicesInfo.extServicesVersionS() methods. These checks are used to ensure compatibility before running specific tests.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage com.lmax.disruptor.alternatives;\n\nimport com.lmax.disruptor.AbstractSequencer;\nimport com.lmax.disruptor.InsufficientCapacityException;\nimport com.lmax.disruptor.Sequence;\nimport com.lmax.disruptor.Sequencer;\nimport com.lmax.disruptor.WaitStrategy;\nimport com.lmax.disruptor.util.UnsafeAccess;\nimport com.lmax.disruptor.util.Util;\nimport sun.misc.Unsafe;\n\nimport java.util.concurrent.locks.LockSupport;\n\n\n/**\n * Coordinator for claiming sequences for access to a data structure while tracking dependent {@link Sequence}s.\n * Suitable for use for sequencing across multiple publisher threads.</p>\n *\n * <p> * Note on {@link Sequencer#getCursor()}:  With this sequencer the cursor value is updated after the call\n * to {@link Sequencer#next()}, to determine the highest available sequence that can be read, then\n * {@link Sequencer#getHighestPublishedSequence(long, long)} should be used.</p>\n */\npublic final class MultiProducerSequencerUnsafe extends AbstractSequencer\n{\n    private static final Unsafe UNSAFE = UnsafeAccess.getUnsafe();\n    private static final long BASE = UNSAFE.arrayBaseOffset(int[].class);\n    private static final long SCALE = UNSAFE.arrayIndexScale(int[].class);\n\n    private final Sequence gatingSequenceCache = new Sequence(Sequencer.INITIAL_CURSOR_VALUE);\n\n    // availableBuffer tracks the state of each ringbuffer slot\n    // see below for more details on the approach\n    private final int[] availableBuffer;\n    private final int indexMask;\n    private final int indexShift;\n\n    /**\n     * Construct a Sequencer with the selected wait strategy and buffer size.\n     *\n     * @param bufferSize   the size of the buffer that this will sequence over.\n     * @param waitStrategy for those waiting on sequences.\n     */\n    public MultiProducerSequencerUnsafe(final int bufferSize, final WaitStrategy waitStrategy)\n    {\n        super(bufferSize, waitStrategy);\n        availableBuffer = new int[bufferSize];\n        indexMask = bufferSize - 1;\n        indexShift = Util.log2(bufferSize);\n        initialiseAvailableBuffer();\n    }\n\n    /**\n     * @see Sequencer#hasAvailableCapacity(int)\n     */\n    @Override\n    public boolean hasAvailableCapacity(final int requiredCapacity)\n    {\n        return hasAvailableCapacity(gatingSequences, requiredCapacity, cursor.get());\n    }\n\n    private boolean hasAvailableCapacity(final Sequence[] gatingSequences, final int requiredCapacity, final long cursorValue)\n    {\n        long wrapPoint = (cursorValue + requiredCapacity) - bufferSize;\n        long cachedGatingSequence = gatingSequenceCache.get();\n\n        if (wrapPoint > cachedGatingSequence || cachedGatingSequence > cursorValue)\n        {\n            long minSequence = Util.getMinimumSequence(gatingSequences, cursorValue);\n            gatingSequenceCache.set(minSequence);\n\n            if (wrapPoint > minSequence)\n            {\n                return false;\n            }\n        }\n\n        return true;\n    }\n\n    /**\n     * @see Sequencer#claim(long)\n     */\n    @Override\n    public void claim(final long sequence)\n    {\n        cursor.set(sequence);\n    }\n\n    /**\n     * @see Sequencer#next()\n     */\n    @Override\n    public long next()\n    {\n        return next(1);\n    }\n\n    /**\n     * @see Sequencer#next(int)\n     */\n    @Override\n    public long next(final int n)\n    {\n        if (n < 1 || n > bufferSize)\n        {\n            throw new IllegalArgumentException(\"n must be > 0 and < bufferSize\");\n        }\n\n        long current;\n        long next;\n\n        do\n        {\n            current = cursor.get();\n            next = current + n;\n\n            long wrapPoint = next - bufferSize;\n            long cachedGatingSequence = gatingSequenceCache.get();\n\n            if (wrapPoint > cachedGatingSequence || cachedGatingSequence > current)\n            {\n                long gatingSequence = Util.getMinimumSequence(gatingSequences, current);\n\n                if (wrapPoint > gatingSequence)\n                {\n                    LockSupport.parkNanos(1); // TODO, should we spin based on the wait strategy?\n                    continue;\n                }\n\n                gatingSequenceCache.set(gatingSequence);\n            }\n            else if (cursor.compareAndSet(current, next))\n            {\n                break;\n            }\n        }\n        while (true);\n\n        return next;\n    }\n\n    /**\n     * @see Sequencer#tryNext()\n     */\n    @Override\n    public long tryNext() throws InsufficientCapacityException\n    {\n        return tryNext(1);\n    }\n\n    /**\n     * @see Sequencer#tryNext(int)\n     */\n    @Override\n    public long tryNext(final int n) throws InsufficientCapacityException\n    {\n        if (n < 1)\n        {\n            throw new IllegalArgumentException(\"n must be > 0\");\n        }\n\n        long current;\n        long next;\n\n        do\n        {\n            current = cursor.get();\n            next = current + n;\n\n            if (!hasAvailableCapacity(gatingSequences, n, current))\n            {\n                throw InsufficientCapacityException.INSTANCE;\n            }\n        }\n        while (!cursor.compareAndSet(current, next));\n\n        return next;\n    }\n\n    /**\n     * @see Sequencer#remainingCapacity()\n     */\n    @Override\n    public long remainingCapacity()\n    {\n        long consumed = Util.getMinimumSequence(gatingSequences, cursor.get());\n        long produced = cursor.get();\n        return getBufferSize() - (produced - consumed);\n    }\n\n    private void initialiseAvailableBuffer()\n    {\n        for (int i = availableBuffer.length - 1; i != 0; i--)\n        {\n            setAvailableBufferValue(i, -1);\n        }\n\n        setAvailableBufferValue(0, -1);\n    }\n\n    /**\n     * @see Sequencer#publish(long)\n     */\n    @Override\n    public void publish(final long sequence)\n    {\n        setAvailable(sequence);\n        waitStrategy.signalAllWhenBlocking();\n    }\n\n    /**\n     * @see Sequencer#publish(long, long)\n     */\n    @Override\n    public void publish(final long lo, final long hi)\n    {\n        for (long l = lo; l <= hi; l++)\n        {\n            setAvailable(l);\n        }\n        waitStrategy.signalAllWhenBlocking();\n    }\n\n    /**\n     * The below methods work on the availableBuffer flag.\n     *\n     * <p>The prime reason is to avoid a shared sequence object between publisher threads.\n     * (Keeping single pointers tracking start and end would require coordination\n     * between the threads).\n     *\n     * <p>--  Firstly we have the constraint that the delta between the cursor and minimum\n     * gating sequence will never be larger than the buffer size (the code in\n     * next/tryNext in the Sequence takes care of that).\n     * -- Given that; take the sequence value and mask off the lower portion of the\n     * sequence as the index into the buffer (indexMask). (aka modulo operator)\n     * -- The upper portion of the sequence becomes the value to check for availability.\n     * ie: it tells us how many times around the ring buffer we've been (aka division)\n     * -- Because we can't wrap without the gating sequences moving forward (i.e. the\n     * minimum gating sequence is effectively our last available position in the\n     * buffer), when we have new data and successfully claimed a slot we can simply\n     * write over the top.\n     */\n    private void setAvailable(final long sequence)\n    {\n        setAvailableBufferValue(calculateIndex(sequence), calculateAvailabilityFlag(sequence));\n    }\n\n    private void setAvailableBufferValue(final int index, final int flag)\n    {\n        long bufferAddress = (index * SCALE) + BASE;\n        UNSAFE.putOrderedInt(availableBuffer, bufferAddress, flag);\n    }\n\n    /**\n     * @see Sequencer#isAvailable(long)\n     */\n    @Override\n    public boolean isAvailable(final long sequence)\n    {\n        int index = calculateIndex(sequence);\n        int flag = calculateAvailabilityFlag(sequence);\n        long bufferAddress = (index * SCALE) + BASE;\n        return UNSAFE.getIntVolatile(availableBuffer, bufferAddress) == flag;\n    }\n\n    @Override\n    public long getHighestPublishedSequence(final long lowerBound, final long availableSequence)\n    {\n        for (long sequence = lowerBound; sequence <= availableSequence; sequence++)\n        {\n            if (!isAvailable(sequence))\n            {\n                return sequence - 1;\n            }\n        }\n\n        return availableSequence;\n    }\n\n    private int calculateAvailabilityFlag(final long sequence)\n    {\n        return (int) (sequence >>> indexShift);\n    }\n\n    private int calculateIndex(final long sequence)\n    {\n        return ((int) sequence) & indexMask;\n    }\n}",
    "repo": "LMAX-Exchange/disruptor",
    "path": "./datasets/diagrams-repos/LMAX-Exchange/disruptor/src/test/java/com/lmax/disruptor/alternatives/MultiProducerSequencerUnsafe.java",
    "query": "What is the class structure of MultiProducerSequencerUnsafe?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'AbstractSequencer', 'node_id': 'AbstractSequencer', 'description': 'Base class for sequencer implementations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MultiProducerSequencerUnsafe', 'node_id': 'MultiProducerSequencerUnsafe', 'description': 'Sequencer implementation for multiple producer threads using unsafe operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'availableBuffer', 'node_id': 'availableBuffer', 'description': 'Tracks state of ringbuffer slots', 'visibility': 'private', 'return_type': 'int[]', 'params': None, 'source_class_id': 'MultiProducerSequencerUnsafe'}, {'type': 'field', 'name': 'gatingSequenceCache', 'node_id': 'gatingSequenceCache', 'description': 'Caches the gating sequence value', 'visibility': 'private', 'return_type': 'Sequence', 'params': None, 'source_class_id': 'MultiProducerSequencerUnsafe'}], 'edges': [{'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'AbstractSequencer', 'description': 'extends'}, {'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'availableBuffer', 'description': ''}, {'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'gatingSequenceCache', 'description': ''}], 'packages': [{'package_id': 'disruptor', 'children': ['AbstractSequencer', 'MultiProducerSequencerUnsafe', 'availableBuffer', 'gatingSequenceCache'], 'description': 'Core disruptor package'}]}",
    "version": "minimal",
    "text_answer": "MultiProducerSequencerUnsafe extends AbstractSequencer and implements a thread-safe sequencer for multiple producers using unsafe operations. It maintains internal state through availableBuffer and gatingSequenceCache fields, providing methods for sequence management and publication.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage com.lmax.disruptor.alternatives;\n\nimport com.lmax.disruptor.AbstractSequencer;\nimport com.lmax.disruptor.InsufficientCapacityException;\nimport com.lmax.disruptor.Sequence;\nimport com.lmax.disruptor.Sequencer;\nimport com.lmax.disruptor.WaitStrategy;\nimport com.lmax.disruptor.util.UnsafeAccess;\nimport com.lmax.disruptor.util.Util;\nimport sun.misc.Unsafe;\n\nimport java.util.concurrent.locks.LockSupport;\n\n\n/**\n * Coordinator for claiming sequences for access to a data structure while tracking dependent {@link Sequence}s.\n * Suitable for use for sequencing across multiple publisher threads.</p>\n *\n * <p> * Note on {@link Sequencer#getCursor()}:  With this sequencer the cursor value is updated after the call\n * to {@link Sequencer#next()}, to determine the highest available sequence that can be read, then\n * {@link Sequencer#getHighestPublishedSequence(long, long)} should be used.</p>\n */\npublic final class MultiProducerSequencerUnsafe extends AbstractSequencer\n{\n    private static final Unsafe UNSAFE = UnsafeAccess.getUnsafe();\n    private static final long BASE = UNSAFE.arrayBaseOffset(int[].class);\n    private static final long SCALE = UNSAFE.arrayIndexScale(int[].class);\n\n    private final Sequence gatingSequenceCache = new Sequence(Sequencer.INITIAL_CURSOR_VALUE);\n\n    // availableBuffer tracks the state of each ringbuffer slot\n    // see below for more details on the approach\n    private final int[] availableBuffer;\n    private final int indexMask;\n    private final int indexShift;\n\n    /**\n     * Construct a Sequencer with the selected wait strategy and buffer size.\n     *\n     * @param bufferSize   the size of the buffer that this will sequence over.\n     * @param waitStrategy for those waiting on sequences.\n     */\n    public MultiProducerSequencerUnsafe(final int bufferSize, final WaitStrategy waitStrategy)\n    {\n        super(bufferSize, waitStrategy);\n        availableBuffer = new int[bufferSize];\n        indexMask = bufferSize - 1;\n        indexShift = Util.log2(bufferSize);\n        initialiseAvailableBuffer();\n    }\n\n    /**\n     * @see Sequencer#hasAvailableCapacity(int)\n     */\n    @Override\n    public boolean hasAvailableCapacity(final int requiredCapacity)\n    {\n        return hasAvailableCapacity(gatingSequences, requiredCapacity, cursor.get());\n    }\n\n    private boolean hasAvailableCapacity(final Sequence[] gatingSequences, final int requiredCapacity, final long cursorValue)\n    {\n        long wrapPoint = (cursorValue + requiredCapacity) - bufferSize;\n        long cachedGatingSequence = gatingSequenceCache.get();\n\n        if (wrapPoint > cachedGatingSequence || cachedGatingSequence > cursorValue)\n        {\n            long minSequence = Util.getMinimumSequence(gatingSequences, cursorValue);\n            gatingSequenceCache.set(minSequence);\n\n            if (wrapPoint > minSequence)\n            {\n                return false;\n            }\n        }\n\n        return true;\n    }\n\n    /**\n     * @see Sequencer#claim(long)\n     */\n    @Override\n    public void claim(final long sequence)\n    {\n        cursor.set(sequence);\n    }\n\n    /**\n     * @see Sequencer#next()\n     */\n    @Override\n    public long next()\n    {\n        return next(1);\n    }\n\n    /**\n     * @see Sequencer#next(int)\n     */\n    @Override\n    public long next(final int n)\n    {\n        if (n < 1 || n > bufferSize)\n        {\n            throw new IllegalArgumentException(\"n must be > 0 and < bufferSize\");\n        }\n\n        long current;\n        long next;\n\n        do\n        {\n            current = cursor.get();\n            next = current + n;\n\n            long wrapPoint = next - bufferSize;\n            long cachedGatingSequence = gatingSequenceCache.get();\n\n            if (wrapPoint > cachedGatingSequence || cachedGatingSequence > current)\n            {\n                long gatingSequence = Util.getMinimumSequence(gatingSequences, current);\n\n                if (wrapPoint > gatingSequence)\n                {\n                    LockSupport.parkNanos(1); // TODO, should we spin based on the wait strategy?\n                    continue;\n                }\n\n                gatingSequenceCache.set(gatingSequence);\n            }\n            else if (cursor.compareAndSet(current, next))\n            {\n                break;\n            }\n        }\n        while (true);\n\n        return next;\n    }\n\n    /**\n     * @see Sequencer#tryNext()\n     */\n    @Override\n    public long tryNext() throws InsufficientCapacityException\n    {\n        return tryNext(1);\n    }\n\n    /**\n     * @see Sequencer#tryNext(int)\n     */\n    @Override\n    public long tryNext(final int n) throws InsufficientCapacityException\n    {\n        if (n < 1)\n        {\n            throw new IllegalArgumentException(\"n must be > 0\");\n        }\n\n        long current;\n        long next;\n\n        do\n        {\n            current = cursor.get();\n            next = current + n;\n\n            if (!hasAvailableCapacity(gatingSequences, n, current))\n            {\n                throw InsufficientCapacityException.INSTANCE;\n            }\n        }\n        while (!cursor.compareAndSet(current, next));\n\n        return next;\n    }\n\n    /**\n     * @see Sequencer#remainingCapacity()\n     */\n    @Override\n    public long remainingCapacity()\n    {\n        long consumed = Util.getMinimumSequence(gatingSequences, cursor.get());\n        long produced = cursor.get();\n        return getBufferSize() - (produced - consumed);\n    }\n\n    private void initialiseAvailableBuffer()\n    {\n        for (int i = availableBuffer.length - 1; i != 0; i--)\n        {\n            setAvailableBufferValue(i, -1);\n        }\n\n        setAvailableBufferValue(0, -1);\n    }\n\n    /**\n     * @see Sequencer#publish(long)\n     */\n    @Override\n    public void publish(final long sequence)\n    {\n        setAvailable(sequence);\n        waitStrategy.signalAllWhenBlocking();\n    }\n\n    /**\n     * @see Sequencer#publish(long, long)\n     */\n    @Override\n    public void publish(final long lo, final long hi)\n    {\n        for (long l = lo; l <= hi; l++)\n        {\n            setAvailable(l);\n        }\n        waitStrategy.signalAllWhenBlocking();\n    }\n\n    /**\n     * The below methods work on the availableBuffer flag.\n     *\n     * <p>The prime reason is to avoid a shared sequence object between publisher threads.\n     * (Keeping single pointers tracking start and end would require coordination\n     * between the threads).\n     *\n     * <p>--  Firstly we have the constraint that the delta between the cursor and minimum\n     * gating sequence will never be larger than the buffer size (the code in\n     * next/tryNext in the Sequence takes care of that).\n     * -- Given that; take the sequence value and mask off the lower portion of the\n     * sequence as the index into the buffer (indexMask). (aka modulo operator)\n     * -- The upper portion of the sequence becomes the value to check for availability.\n     * ie: it tells us how many times around the ring buffer we've been (aka division)\n     * -- Because we can't wrap without the gating sequences moving forward (i.e. the\n     * minimum gating sequence is effectively our last available position in the\n     * buffer), when we have new data and successfully claimed a slot we can simply\n     * write over the top.\n     */\n    private void setAvailable(final long sequence)\n    {\n        setAvailableBufferValue(calculateIndex(sequence), calculateAvailabilityFlag(sequence));\n    }\n\n    private void setAvailableBufferValue(final int index, final int flag)\n    {\n        long bufferAddress = (index * SCALE) + BASE;\n        UNSAFE.putOrderedInt(availableBuffer, bufferAddress, flag);\n    }\n\n    /**\n     * @see Sequencer#isAvailable(long)\n     */\n    @Override\n    public boolean isAvailable(final long sequence)\n    {\n        int index = calculateIndex(sequence);\n        int flag = calculateAvailabilityFlag(sequence);\n        long bufferAddress = (index * SCALE) + BASE;\n        return UNSAFE.getIntVolatile(availableBuffer, bufferAddress) == flag;\n    }\n\n    @Override\n    public long getHighestPublishedSequence(final long lowerBound, final long availableSequence)\n    {\n        for (long sequence = lowerBound; sequence <= availableSequence; sequence++)\n        {\n            if (!isAvailable(sequence))\n            {\n                return sequence - 1;\n            }\n        }\n\n        return availableSequence;\n    }\n\n    private int calculateAvailabilityFlag(final long sequence)\n    {\n        return (int) (sequence >>> indexShift);\n    }\n\n    private int calculateIndex(final long sequence)\n    {\n        return ((int) sequence) & indexMask;\n    }\n}",
    "repo": "LMAX-Exchange/disruptor",
    "path": "./datasets/diagrams-repos/LMAX-Exchange/disruptor/src/test/java/com/lmax/disruptor/alternatives/MultiProducerSequencerUnsafe.java",
    "query": "What is the class structure of MultiProducerSequencerUnsafe?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'AbstractSequencer', 'node_id': 'AbstractSequencer', 'description': 'Base class for sequencer implementations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MultiProducerSequencerUnsafe', 'node_id': 'MultiProducerSequencerUnsafe', 'description': 'Sequencer implementation for multiple producer threads using unsafe operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'UNSAFE', 'node_id': 'UNSAFE', 'description': 'Unsafe instance for low-level memory operations', 'visibility': 'private', 'return_type': 'Unsafe', 'params': None, 'source_class_id': 'MultiProducerSequencerUnsafe'}, {'type': 'field', 'name': 'availableBuffer', 'node_id': 'availableBuffer', 'description': 'Tracks state of ringbuffer slots', 'visibility': 'private', 'return_type': 'int[]', 'params': None, 'source_class_id': 'MultiProducerSequencerUnsafe'}, {'type': 'field', 'name': 'gatingSequenceCache', 'node_id': 'gatingSequenceCache', 'description': 'Caches the gating sequence value', 'visibility': 'private', 'return_type': 'Sequence', 'params': None, 'source_class_id': 'MultiProducerSequencerUnsafe'}, {'type': 'method', 'name': 'next', 'node_id': 'next', 'description': 'Gets next sequence', 'visibility': 'public', 'return_type': 'long', 'params': 'int n', 'source_class_id': 'MultiProducerSequencerUnsafe'}, {'type': 'method', 'name': 'publish', 'node_id': 'publish', 'description': 'Publishes sequence', 'visibility': 'public', 'return_type': 'void', 'params': 'long sequence', 'source_class_id': 'MultiProducerSequencerUnsafe'}], 'edges': [{'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'AbstractSequencer', 'description': 'extends'}, {'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'availableBuffer', 'description': ''}, {'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'gatingSequenceCache', 'description': ''}, {'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'UNSAFE', 'description': ''}, {'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'next', 'description': ''}, {'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'publish', 'description': ''}], 'packages': [{'package_id': 'disruptor', 'children': ['AbstractSequencer', 'MultiProducerSequencerUnsafe', 'UNSAFE', 'availableBuffer', 'gatingSequenceCache', 'next', 'publish'], 'description': 'Core disruptor package'}]}",
    "version": "medium",
    "text_answer": "MultiProducerSequencerUnsafe extends AbstractSequencer and implements a thread-safe sequencer for multiple producers using unsafe operations. It maintains internal state through availableBuffer and gatingSequenceCache fields, providing methods for sequence management and publication.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage com.lmax.disruptor.alternatives;\n\nimport com.lmax.disruptor.AbstractSequencer;\nimport com.lmax.disruptor.InsufficientCapacityException;\nimport com.lmax.disruptor.Sequence;\nimport com.lmax.disruptor.Sequencer;\nimport com.lmax.disruptor.WaitStrategy;\nimport com.lmax.disruptor.util.UnsafeAccess;\nimport com.lmax.disruptor.util.Util;\nimport sun.misc.Unsafe;\n\nimport java.util.concurrent.locks.LockSupport;\n\n\n/**\n * Coordinator for claiming sequences for access to a data structure while tracking dependent {@link Sequence}s.\n * Suitable for use for sequencing across multiple publisher threads.</p>\n *\n * <p> * Note on {@link Sequencer#getCursor()}:  With this sequencer the cursor value is updated after the call\n * to {@link Sequencer#next()}, to determine the highest available sequence that can be read, then\n * {@link Sequencer#getHighestPublishedSequence(long, long)} should be used.</p>\n */\npublic final class MultiProducerSequencerUnsafe extends AbstractSequencer\n{\n    private static final Unsafe UNSAFE = UnsafeAccess.getUnsafe();\n    private static final long BASE = UNSAFE.arrayBaseOffset(int[].class);\n    private static final long SCALE = UNSAFE.arrayIndexScale(int[].class);\n\n    private final Sequence gatingSequenceCache = new Sequence(Sequencer.INITIAL_CURSOR_VALUE);\n\n    // availableBuffer tracks the state of each ringbuffer slot\n    // see below for more details on the approach\n    private final int[] availableBuffer;\n    private final int indexMask;\n    private final int indexShift;\n\n    /**\n     * Construct a Sequencer with the selected wait strategy and buffer size.\n     *\n     * @param bufferSize   the size of the buffer that this will sequence over.\n     * @param waitStrategy for those waiting on sequences.\n     */\n    public MultiProducerSequencerUnsafe(final int bufferSize, final WaitStrategy waitStrategy)\n    {\n        super(bufferSize, waitStrategy);\n        availableBuffer = new int[bufferSize];\n        indexMask = bufferSize - 1;\n        indexShift = Util.log2(bufferSize);\n        initialiseAvailableBuffer();\n    }\n\n    /**\n     * @see Sequencer#hasAvailableCapacity(int)\n     */\n    @Override\n    public boolean hasAvailableCapacity(final int requiredCapacity)\n    {\n        return hasAvailableCapacity(gatingSequences, requiredCapacity, cursor.get());\n    }\n\n    private boolean hasAvailableCapacity(final Sequence[] gatingSequences, final int requiredCapacity, final long cursorValue)\n    {\n        long wrapPoint = (cursorValue + requiredCapacity) - bufferSize;\n        long cachedGatingSequence = gatingSequenceCache.get();\n\n        if (wrapPoint > cachedGatingSequence || cachedGatingSequence > cursorValue)\n        {\n            long minSequence = Util.getMinimumSequence(gatingSequences, cursorValue);\n            gatingSequenceCache.set(minSequence);\n\n            if (wrapPoint > minSequence)\n            {\n                return false;\n            }\n        }\n\n        return true;\n    }\n\n    /**\n     * @see Sequencer#claim(long)\n     */\n    @Override\n    public void claim(final long sequence)\n    {\n        cursor.set(sequence);\n    }\n\n    /**\n     * @see Sequencer#next()\n     */\n    @Override\n    public long next()\n    {\n        return next(1);\n    }\n\n    /**\n     * @see Sequencer#next(int)\n     */\n    @Override\n    public long next(final int n)\n    {\n        if (n < 1 || n > bufferSize)\n        {\n            throw new IllegalArgumentException(\"n must be > 0 and < bufferSize\");\n        }\n\n        long current;\n        long next;\n\n        do\n        {\n            current = cursor.get();\n            next = current + n;\n\n            long wrapPoint = next - bufferSize;\n            long cachedGatingSequence = gatingSequenceCache.get();\n\n            if (wrapPoint > cachedGatingSequence || cachedGatingSequence > current)\n            {\n                long gatingSequence = Util.getMinimumSequence(gatingSequences, current);\n\n                if (wrapPoint > gatingSequence)\n                {\n                    LockSupport.parkNanos(1); // TODO, should we spin based on the wait strategy?\n                    continue;\n                }\n\n                gatingSequenceCache.set(gatingSequence);\n            }\n            else if (cursor.compareAndSet(current, next))\n            {\n                break;\n            }\n        }\n        while (true);\n\n        return next;\n    }\n\n    /**\n     * @see Sequencer#tryNext()\n     */\n    @Override\n    public long tryNext() throws InsufficientCapacityException\n    {\n        return tryNext(1);\n    }\n\n    /**\n     * @see Sequencer#tryNext(int)\n     */\n    @Override\n    public long tryNext(final int n) throws InsufficientCapacityException\n    {\n        if (n < 1)\n        {\n            throw new IllegalArgumentException(\"n must be > 0\");\n        }\n\n        long current;\n        long next;\n\n        do\n        {\n            current = cursor.get();\n            next = current + n;\n\n            if (!hasAvailableCapacity(gatingSequences, n, current))\n            {\n                throw InsufficientCapacityException.INSTANCE;\n            }\n        }\n        while (!cursor.compareAndSet(current, next));\n\n        return next;\n    }\n\n    /**\n     * @see Sequencer#remainingCapacity()\n     */\n    @Override\n    public long remainingCapacity()\n    {\n        long consumed = Util.getMinimumSequence(gatingSequences, cursor.get());\n        long produced = cursor.get();\n        return getBufferSize() - (produced - consumed);\n    }\n\n    private void initialiseAvailableBuffer()\n    {\n        for (int i = availableBuffer.length - 1; i != 0; i--)\n        {\n            setAvailableBufferValue(i, -1);\n        }\n\n        setAvailableBufferValue(0, -1);\n    }\n\n    /**\n     * @see Sequencer#publish(long)\n     */\n    @Override\n    public void publish(final long sequence)\n    {\n        setAvailable(sequence);\n        waitStrategy.signalAllWhenBlocking();\n    }\n\n    /**\n     * @see Sequencer#publish(long, long)\n     */\n    @Override\n    public void publish(final long lo, final long hi)\n    {\n        for (long l = lo; l <= hi; l++)\n        {\n            setAvailable(l);\n        }\n        waitStrategy.signalAllWhenBlocking();\n    }\n\n    /**\n     * The below methods work on the availableBuffer flag.\n     *\n     * <p>The prime reason is to avoid a shared sequence object between publisher threads.\n     * (Keeping single pointers tracking start and end would require coordination\n     * between the threads).\n     *\n     * <p>--  Firstly we have the constraint that the delta between the cursor and minimum\n     * gating sequence will never be larger than the buffer size (the code in\n     * next/tryNext in the Sequence takes care of that).\n     * -- Given that; take the sequence value and mask off the lower portion of the\n     * sequence as the index into the buffer (indexMask). (aka modulo operator)\n     * -- The upper portion of the sequence becomes the value to check for availability.\n     * ie: it tells us how many times around the ring buffer we've been (aka division)\n     * -- Because we can't wrap without the gating sequences moving forward (i.e. the\n     * minimum gating sequence is effectively our last available position in the\n     * buffer), when we have new data and successfully claimed a slot we can simply\n     * write over the top.\n     */\n    private void setAvailable(final long sequence)\n    {\n        setAvailableBufferValue(calculateIndex(sequence), calculateAvailabilityFlag(sequence));\n    }\n\n    private void setAvailableBufferValue(final int index, final int flag)\n    {\n        long bufferAddress = (index * SCALE) + BASE;\n        UNSAFE.putOrderedInt(availableBuffer, bufferAddress, flag);\n    }\n\n    /**\n     * @see Sequencer#isAvailable(long)\n     */\n    @Override\n    public boolean isAvailable(final long sequence)\n    {\n        int index = calculateIndex(sequence);\n        int flag = calculateAvailabilityFlag(sequence);\n        long bufferAddress = (index * SCALE) + BASE;\n        return UNSAFE.getIntVolatile(availableBuffer, bufferAddress) == flag;\n    }\n\n    @Override\n    public long getHighestPublishedSequence(final long lowerBound, final long availableSequence)\n    {\n        for (long sequence = lowerBound; sequence <= availableSequence; sequence++)\n        {\n            if (!isAvailable(sequence))\n            {\n                return sequence - 1;\n            }\n        }\n\n        return availableSequence;\n    }\n\n    private int calculateAvailabilityFlag(final long sequence)\n    {\n        return (int) (sequence >>> indexShift);\n    }\n\n    private int calculateIndex(final long sequence)\n    {\n        return ((int) sequence) & indexMask;\n    }\n}",
    "repo": "LMAX-Exchange/disruptor",
    "path": "./datasets/diagrams-repos/LMAX-Exchange/disruptor/src/test/java/com/lmax/disruptor/alternatives/MultiProducerSequencerUnsafe.java",
    "query": "What is the class structure of MultiProducerSequencerUnsafe?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'AbstractSequencer', 'node_id': 'AbstractSequencer', 'description': 'Base class for sequencer implementations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'MultiProducerSequencerUnsafe', 'node_id': 'MultiProducerSequencerUnsafe', 'description': 'Sequencer implementation for multiple producer threads using unsafe operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'UNSAFE', 'node_id': 'UNSAFE', 'description': 'Unsafe instance for low-level memory operations', 'visibility': 'private', 'return_type': 'Unsafe', 'params': None, 'source_class_id': 'MultiProducerSequencerUnsafe'}, {'type': 'field', 'name': 'BASE', 'node_id': 'BASE', 'description': 'Base offset for array access', 'visibility': 'private', 'return_type': 'long', 'params': None, 'source_class_id': 'MultiProducerSequencerUnsafe'}, {'type': 'field', 'name': 'SCALE', 'node_id': 'SCALE', 'description': 'Scale factor for array indexing', 'visibility': 'private', 'return_type': 'long', 'params': None, 'source_class_id': 'MultiProducerSequencerUnsafe'}, {'type': 'field', 'name': 'availableBuffer', 'node_id': 'availableBuffer', 'description': 'Tracks state of ringbuffer slots', 'visibility': 'private', 'return_type': 'int[]', 'params': None, 'source_class_id': 'MultiProducerSequencerUnsafe'}, {'type': 'field', 'name': 'gatingSequenceCache', 'node_id': 'gatingSequenceCache', 'description': 'Caches the gating sequence value', 'visibility': 'private', 'return_type': 'Sequence', 'params': None, 'source_class_id': 'MultiProducerSequencerUnsafe'}, {'type': 'field', 'name': 'indexMask', 'node_id': 'indexMask', 'description': 'Mask for index calculations', 'visibility': 'private', 'return_type': 'int', 'params': None, 'source_class_id': 'MultiProducerSequencerUnsafe'}, {'type': 'field', 'name': 'indexShift', 'node_id': 'indexShift', 'description': 'Shift value for index calculations', 'visibility': 'private', 'return_type': 'int', 'params': None, 'source_class_id': 'MultiProducerSequencerUnsafe'}, {'type': 'method', 'name': 'next', 'node_id': 'next', 'description': 'Gets next sequence', 'visibility': 'public', 'return_type': 'long', 'params': 'int n', 'source_class_id': 'MultiProducerSequencerUnsafe'}, {'type': 'method', 'name': 'tryNext', 'node_id': 'tryNext', 'description': 'Tries to get next sequence', 'visibility': 'public', 'return_type': 'long', 'params': 'int n', 'source_class_id': 'MultiProducerSequencerUnsafe'}, {'type': 'method', 'name': 'publish', 'node_id': 'publish', 'description': 'Publishes sequence', 'visibility': 'public', 'return_type': 'void', 'params': 'long sequence', 'source_class_id': 'MultiProducerSequencerUnsafe'}, {'type': 'method', 'name': 'isAvailable', 'node_id': 'isAvailable', 'description': 'Checks if sequence is available', 'visibility': 'public', 'return_type': 'boolean', 'params': 'long sequence', 'source_class_id': 'MultiProducerSequencerUnsafe'}], 'edges': [{'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'AbstractSequencer', 'description': 'extends'}, {'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'availableBuffer', 'description': ''}, {'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'gatingSequenceCache', 'description': ''}, {'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'UNSAFE', 'description': ''}, {'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'next', 'description': ''}, {'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'publish', 'description': ''}, {'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'BASE', 'description': ''}, {'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'SCALE', 'description': ''}, {'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'indexMask', 'description': ''}, {'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'indexShift', 'description': ''}, {'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'tryNext', 'description': ''}, {'node_id_from': 'MultiProducerSequencerUnsafe', 'node_id_to': 'isAvailable', 'description': ''}], 'packages': [{'package_id': 'disruptor', 'children': ['AbstractSequencer', 'MultiProducerSequencerUnsafe', 'UNSAFE', 'BASE', 'SCALE', 'availableBuffer', 'gatingSequenceCache', 'indexMask', 'indexShift', 'next', 'tryNext', 'publish', 'isAvailable'], 'description': 'Core disruptor package'}]}",
    "version": "full",
    "text_answer": "MultiProducerSequencerUnsafe extends AbstractSequencer and implements a thread-safe sequencer for multiple producers using unsafe operations. It maintains internal state through availableBuffer and gatingSequenceCache fields, providing methods for sequence management and publication.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\ndefine(['isSVG'], function(isSVG) {\n  /**\n   * @optionName html5shiv\n   * @optionProp html5shiv\n   */\n\n  // Take the html5 variable out of the html5shiv scope so we can return it.\n  var html5;\n  if (!isSVG) {\n    /**\n     * @preserve HTML5 Shiv 3.7.3 | @afarkas @jdalton @jon_neal @rem | MIT/GPL2 Licensed\n     */\n    ;(function(window, document) {\n      /*jshint evil:true */\n      /** version */\n      var version = '3.7.3';\n\n      /** Preset options */\n      var options = window.html5 || {};\n\n      /** Used to skip problem elements */\n      var reSkip = /^<|^(?:button|map|select|textarea|object|iframe|option|optgroup)$/i;\n\n      /** Not all elements can be cloned in IE **/\n      var saveClones = /^(?:a|b|code|div|fieldset|h1|h2|h3|h4|h5|h6|i|label|li|ol|p|q|span|strong|style|table|tbody|td|th|tr|ul)$/i;\n\n      /** Detect whether the browser supports default html5 styles */\n      var supportsHtml5Styles;\n\n      /** Name of the expando, to work with multiple documents or to re-shiv one document */\n      var expando = '_html5shiv';\n\n      /** The id for the the documents expando */\n      var expanID = 0;\n\n      /** Cached data for each document */\n      var expandoData = {};\n\n      /** Detect whether the browser supports unknown elements */\n      var supportsUnknownElements;\n\n      (function() {\n        try {\n          var a = document.createElement('a');\n          a.innerHTML = '<xyz></xyz>';\n          //if the hidden property is implemented we can assume, that the browser supports basic HTML5 Styles\n          supportsHtml5Styles = ('hidden' in a);\n\n          supportsUnknownElements = a.childNodes.length == 1 || (function() {\n            // assign a false positive if unable to shiv\n            (document.createElement)('a');\n            var frag = document.createDocumentFragment();\n            return (\n              typeof frag.cloneNode == 'undefined' ||\n              typeof frag.createDocumentFragment == 'undefined' ||\n              typeof frag.createElement == 'undefined'\n            );\n          }());\n        } catch(e) {\n          // assign a false positive if detection fails => unable to shiv\n          supportsHtml5Styles = true;\n          supportsUnknownElements = true;\n        }\n\n      }());\n\n      /*--------------------------------------------------------------------------*/\n\n      /**\n       * Creates a style sheet with the given CSS text and adds it to the document.\n       * @private\n       * @param {Document} ownerDocument The document.\n       * @param {String} cssText The CSS text.\n       * @returns {StyleSheet} The style element.\n       */\n      function addStyleSheet(ownerDocument, cssText) {\n        var p = ownerDocument.createElement('p'),\n          parent = ownerDocument.getElementsByTagName('head')[0] || ownerDocument.documentElement;\n\n        p.innerHTML = 'x<style>' + cssText + '</style>';\n        return parent.insertBefore(p.lastChild, parent.firstChild);\n      }\n\n      /**\n       * Returns the value of `html5.elements` as an array.\n       * @private\n       * @returns {Array} An array of shived element node names.\n       */\n      function getElements() {\n        var elements = html5.elements;\n        return typeof elements == 'string' ? elements.split(' ') : elements;\n      }\n\n      /**\n       * Extends the built-in list of html5 elements\n       * @memberOf html5\n       * @param {String|Array} newElements whitespace separated list or array of new element names to shiv\n       * @param {Document} ownerDocument The context document.\n       */\n      function addElements(newElements, ownerDocument) {\n        var elements = html5.elements;\n        if(typeof elements != 'string'){\n          elements = elements.join(' ');\n        }\n        if(typeof newElements != 'string'){\n          newElements = newElements.join(' ');\n        }\n        html5.elements = elements +' '+ newElements;\n        shivDocument(ownerDocument);\n      }\n\n      /**\n       * Returns the data associated to the given document\n       * @private\n       * @param {Document} ownerDocument The document.\n       * @returns {Object} An object of data.\n       */\n      function getExpandoData(ownerDocument) {\n        var data = expandoData[ownerDocument[expando]];\n        if (!data) {\n          data = {};\n          expanID++;\n          ownerDocument[expando] = expanID;\n          expandoData[expanID] = data;\n        }\n        return data;\n      }\n\n      /**\n       * returns a shived element for the given nodeName and document\n       * @memberOf html5\n       * @param {String} nodeName name of the element\n       * @param {Document|DocumentFragment} ownerDocument The context document.\n       * @returns {Object} The shived element.\n       */\n      function createElement(nodeName, ownerDocument, data){\n        if (!ownerDocument) {\n          ownerDocument = document;\n        }\n        if(supportsUnknownElements){\n          return ownerDocument.createElement(nodeName);\n        }\n        if (!data) {\n          data = getExpandoData(ownerDocument);\n        }\n        var node;\n\n        if (data.cache[nodeName]) {\n          node = data.cache[nodeName].cloneNode();\n        } else if (saveClones.test(nodeName)) {\n          node = (data.cache[nodeName] = data.createElem(nodeName)).cloneNode();\n        } else {\n          node = data.createElem(nodeName);\n        }\n\n        // Avoid adding some elements to fragments in IE < 9 because\n        // * Attributes like `name` or `type` cannot be set/changed once an element\n        //   is inserted into a document/fragment\n        // * Link elements with `src` attributes that are inaccessible, as with\n        //   a 403 response, will cause the tab/window to crash\n        // * Script elements appended to fragments will execute when their `src`\n        //   or `text` property is set\n        return node.canHaveChildren && !reSkip.test(nodeName) && !node.tagUrn ? data.frag.appendChild(node) : node;\n      }\n\n      /**\n       * returns a shived DocumentFragment for the given document\n       * @memberOf html5\n       * @param {Document} ownerDocument The context document.\n       * @returns {Object} The shived DocumentFragment.\n       */\n      function createDocumentFragment(ownerDocument, data){\n        if (!ownerDocument) {\n          ownerDocument = document;\n        }\n        if(supportsUnknownElements){\n          return ownerDocument.createDocumentFragment();\n        }\n        data = data || getExpandoData(ownerDocument);\n        var clone = data.frag.cloneNode(),\n          i = 0,\n          elems = getElements(),\n          l = elems.length;\n        for(;i<l;i++){\n          clone.createElement(elems[i]);\n        }\n        return clone;\n      }\n\n      /**\n       * Shivs the `createElement` and `createDocumentFragment` methods of the document.\n       * @private\n       * @param {Document|DocumentFragment} ownerDocument The document.\n       * @param {Object} data of the document.\n       */\n      function shivMethods(ownerDocument, data) {\n        if (!data.cache) {\n          data.cache = {};\n          data.createElem = ownerDocument.createElement;\n          data.createFrag = ownerDocument.createDocumentFragment;\n          data.frag = data.createFrag();\n        }\n\n\n        ownerDocument.createElement = function(nodeName) {\n          //abort shiv\n          if (!html5.shivMethods) {\n            return data.createElem(nodeName);\n          }\n          return createElement(nodeName, ownerDocument, data);\n        };\n\n        ownerDocument.createDocumentFragment = Function('h,f', 'return function(){' +\n          'var n=f.cloneNode(),c=n.createElement;' +\n          'h.shivMethods&&(' +\n          // unroll the `createElement` calls\n          getElements().join().replace(/[\\w\\-:]+/g, function(nodeName) {\n            data.createElem(nodeName);\n            data.frag.createElement(nodeName);\n            return 'c(\"' + nodeName + '\")';\n          }) +\n          ');return n}'\n        )(html5, data.frag);\n      }\n\n      /*--------------------------------------------------------------------------*/\n\n      /**\n       * Shivs the given document.\n       * @memberOf html5\n       * @param {Document} ownerDocument The document to shiv.\n       * @returns {Document} The shived document.\n       */\n      function shivDocument(ownerDocument) {\n        if (!ownerDocument) {\n          ownerDocument = document;\n        }\n        var data = getExpandoData(ownerDocument);\n\n        if (html5.shivCSS && !supportsHtml5Styles && !data.hasCSS) {\n          data.hasCSS = !!addStyleSheet(ownerDocument,\n            // corrects block display not defined in IE6/7/8/9\n            'article,aside,dialog,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}' +\n            // adds styling not present in IE6/7/8/9\n            'mark{background:#FF0;color:#000}' +\n            // hides non-rendered elements\n            'template{display:none}'\n          );\n        }\n        if (!supportsUnknownElements) {\n          shivMethods(ownerDocument, data);\n        }\n        return ownerDocument;\n      }\n\n      /*--------------------------------------------------------------------------*/\n\n      /**\n       * The `html5` object is exposed so that more elements can be shived and\n       * existing shiving can be detected on iframes.\n       * @type Object\n       * @example\n       *\n       * // options can be changed before the script is included\n       * html5 = { 'elements': 'mark section', 'shivCSS': false, 'shivMethods': false };\n       */\n      var html5 = {\n\n        /**\n         * An array or space separated string of node names of the elements to shiv.\n         * @memberOf html5\n         * @type Array|String\n         */\n        'elements': options.elements || 'abbr article aside audio bdi canvas data datalist details dialog figcaption figure footer header hgroup main mark meter nav output picture progress section summary template time video',\n\n        /**\n         * current version of html5shiv\n         */\n        'version': version,\n\n        /**\n         * A flag to indicate that the HTML5 style sheet should be inserted.\n         * @memberOf html5\n         * @type Boolean\n         */\n        'shivCSS': (options.shivCSS !== false),\n\n        /**\n         * Is equal to true if a browser supports creating unknown/HTML5 elements\n         * @memberOf html5\n         * @type boolean\n         */\n        'supportsUnknownElements': supportsUnknownElements,\n\n        /**\n         * A flag to indicate that the document's `createElement` and `createDocumentFragment`\n         * methods should be overwritten.\n         * @memberOf html5\n         * @type Boolean\n         */\n        'shivMethods': (options.shivMethods !== false),\n\n        /**\n         * A string to describe the type of `html5` object (\"default\" or \"default print\").\n         * @memberOf html5\n         * @type String\n         */\n        'type': 'default',\n\n        // shivs the document according to the specified `html5` object options\n        'shivDocument': shivDocument,\n\n        //creates a shived element\n        createElement: createElement,\n\n        //creates a shived documentFragment\n        createDocumentFragment: createDocumentFragment,\n\n        //extends list of elements\n        addElements: addElements\n      };\n\n      /*--------------------------------------------------------------------------*/\n\n      // expose html5\n      window.html5 = html5;\n\n      // shiv the document\n      shivDocument(document);\n\n      if(typeof module == 'object' && module.exports){\n        module.exports = html5;\n      }\n\n    }(typeof window !== \"undefined\" ? window : this, document));\n  }\n  return html5;\n});",
    "repo": "Modernizr/Modernizr",
    "path": "./datasets/diagrams-repos/Modernizr/Modernizr/src/html5shiv.js",
    "query": "How do the functions within the html5shiv module interact with each other?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'shivDocument', 'node_id': 'shivDocument', 'description': 'Main function that applies HTML5 shiv to the document', 'visibility': 'public', 'return_type': None, 'params': 'ownerDocument', 'source_class_id': None}, {'type': 'function', 'name': 'shivMethods', 'node_id': 'shivMethods', 'description': 'Overrides createElement and createDocumentFragment methods', 'visibility': 'private', 'return_type': None, 'params': 'ownerDocument, data', 'source_class_id': None}, {'type': 'function', 'name': 'createElement', 'node_id': 'createElement', 'description': 'Creates shived HTML5 elements', 'visibility': 'public', 'return_type': None, 'params': 'nodeName, ownerDocument, data', 'source_class_id': None}, {'type': 'function', 'name': 'createDocumentFragment', 'node_id': 'createDocumentFragment', 'description': 'Creates shived document fragment', 'visibility': 'public', 'return_type': None, 'params': 'ownerDocument, data', 'source_class_id': None}], 'edges': [{'node_id_from': 'shivDocument', 'node_id_to': 'shivMethods', 'description': 'calls if unknown elements not supported'}, {'node_id_from': 'shivMethods', 'node_id_to': 'createElement', 'description': 'overrides with shived version'}, {'node_id_from': 'shivMethods', 'node_id_to': 'createDocumentFragment', 'description': 'overrides with shived version'}], 'packages': [{'package_id': 'html5shiv', 'children': ['shivDocument', 'shivMethods', 'createElement', 'createDocumentFragment'], 'description': 'Core HTML5 shiv functionality'}]}",
    "version": "minimal",
    "text_answer": "The html5shiv module centers around shivDocument as the main function, which coordinates with shivMethods to override document creation methods. createElement and createDocumentFragment are the primary element creation functions, supported by utility functions for managing data and styles.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\ndefine(['isSVG'], function(isSVG) {\n  /**\n   * @optionName html5shiv\n   * @optionProp html5shiv\n   */\n\n  // Take the html5 variable out of the html5shiv scope so we can return it.\n  var html5;\n  if (!isSVG) {\n    /**\n     * @preserve HTML5 Shiv 3.7.3 | @afarkas @jdalton @jon_neal @rem | MIT/GPL2 Licensed\n     */\n    ;(function(window, document) {\n      /*jshint evil:true */\n      /** version */\n      var version = '3.7.3';\n\n      /** Preset options */\n      var options = window.html5 || {};\n\n      /** Used to skip problem elements */\n      var reSkip = /^<|^(?:button|map|select|textarea|object|iframe|option|optgroup)$/i;\n\n      /** Not all elements can be cloned in IE **/\n      var saveClones = /^(?:a|b|code|div|fieldset|h1|h2|h3|h4|h5|h6|i|label|li|ol|p|q|span|strong|style|table|tbody|td|th|tr|ul)$/i;\n\n      /** Detect whether the browser supports default html5 styles */\n      var supportsHtml5Styles;\n\n      /** Name of the expando, to work with multiple documents or to re-shiv one document */\n      var expando = '_html5shiv';\n\n      /** The id for the the documents expando */\n      var expanID = 0;\n\n      /** Cached data for each document */\n      var expandoData = {};\n\n      /** Detect whether the browser supports unknown elements */\n      var supportsUnknownElements;\n\n      (function() {\n        try {\n          var a = document.createElement('a');\n          a.innerHTML = '<xyz></xyz>';\n          //if the hidden property is implemented we can assume, that the browser supports basic HTML5 Styles\n          supportsHtml5Styles = ('hidden' in a);\n\n          supportsUnknownElements = a.childNodes.length == 1 || (function() {\n            // assign a false positive if unable to shiv\n            (document.createElement)('a');\n            var frag = document.createDocumentFragment();\n            return (\n              typeof frag.cloneNode == 'undefined' ||\n              typeof frag.createDocumentFragment == 'undefined' ||\n              typeof frag.createElement == 'undefined'\n            );\n          }());\n        } catch(e) {\n          // assign a false positive if detection fails => unable to shiv\n          supportsHtml5Styles = true;\n          supportsUnknownElements = true;\n        }\n\n      }());\n\n      /*--------------------------------------------------------------------------*/\n\n      /**\n       * Creates a style sheet with the given CSS text and adds it to the document.\n       * @private\n       * @param {Document} ownerDocument The document.\n       * @param {String} cssText The CSS text.\n       * @returns {StyleSheet} The style element.\n       */\n      function addStyleSheet(ownerDocument, cssText) {\n        var p = ownerDocument.createElement('p'),\n          parent = ownerDocument.getElementsByTagName('head')[0] || ownerDocument.documentElement;\n\n        p.innerHTML = 'x<style>' + cssText + '</style>';\n        return parent.insertBefore(p.lastChild, parent.firstChild);\n      }\n\n      /**\n       * Returns the value of `html5.elements` as an array.\n       * @private\n       * @returns {Array} An array of shived element node names.\n       */\n      function getElements() {\n        var elements = html5.elements;\n        return typeof elements == 'string' ? elements.split(' ') : elements;\n      }\n\n      /**\n       * Extends the built-in list of html5 elements\n       * @memberOf html5\n       * @param {String|Array} newElements whitespace separated list or array of new element names to shiv\n       * @param {Document} ownerDocument The context document.\n       */\n      function addElements(newElements, ownerDocument) {\n        var elements = html5.elements;\n        if(typeof elements != 'string'){\n          elements = elements.join(' ');\n        }\n        if(typeof newElements != 'string'){\n          newElements = newElements.join(' ');\n        }\n        html5.elements = elements +' '+ newElements;\n        shivDocument(ownerDocument);\n      }\n\n      /**\n       * Returns the data associated to the given document\n       * @private\n       * @param {Document} ownerDocument The document.\n       * @returns {Object} An object of data.\n       */\n      function getExpandoData(ownerDocument) {\n        var data = expandoData[ownerDocument[expando]];\n        if (!data) {\n          data = {};\n          expanID++;\n          ownerDocument[expando] = expanID;\n          expandoData[expanID] = data;\n        }\n        return data;\n      }\n\n      /**\n       * returns a shived element for the given nodeName and document\n       * @memberOf html5\n       * @param {String} nodeName name of the element\n       * @param {Document|DocumentFragment} ownerDocument The context document.\n       * @returns {Object} The shived element.\n       */\n      function createElement(nodeName, ownerDocument, data){\n        if (!ownerDocument) {\n          ownerDocument = document;\n        }\n        if(supportsUnknownElements){\n          return ownerDocument.createElement(nodeName);\n        }\n        if (!data) {\n          data = getExpandoData(ownerDocument);\n        }\n        var node;\n\n        if (data.cache[nodeName]) {\n          node = data.cache[nodeName].cloneNode();\n        } else if (saveClones.test(nodeName)) {\n          node = (data.cache[nodeName] = data.createElem(nodeName)).cloneNode();\n        } else {\n          node = data.createElem(nodeName);\n        }\n\n        // Avoid adding some elements to fragments in IE < 9 because\n        // * Attributes like `name` or `type` cannot be set/changed once an element\n        //   is inserted into a document/fragment\n        // * Link elements with `src` attributes that are inaccessible, as with\n        //   a 403 response, will cause the tab/window to crash\n        // * Script elements appended to fragments will execute when their `src`\n        //   or `text` property is set\n        return node.canHaveChildren && !reSkip.test(nodeName) && !node.tagUrn ? data.frag.appendChild(node) : node;\n      }\n\n      /**\n       * returns a shived DocumentFragment for the given document\n       * @memberOf html5\n       * @param {Document} ownerDocument The context document.\n       * @returns {Object} The shived DocumentFragment.\n       */\n      function createDocumentFragment(ownerDocument, data){\n        if (!ownerDocument) {\n          ownerDocument = document;\n        }\n        if(supportsUnknownElements){\n          return ownerDocument.createDocumentFragment();\n        }\n        data = data || getExpandoData(ownerDocument);\n        var clone = data.frag.cloneNode(),\n          i = 0,\n          elems = getElements(),\n          l = elems.length;\n        for(;i<l;i++){\n          clone.createElement(elems[i]);\n        }\n        return clone;\n      }\n\n      /**\n       * Shivs the `createElement` and `createDocumentFragment` methods of the document.\n       * @private\n       * @param {Document|DocumentFragment} ownerDocument The document.\n       * @param {Object} data of the document.\n       */\n      function shivMethods(ownerDocument, data) {\n        if (!data.cache) {\n          data.cache = {};\n          data.createElem = ownerDocument.createElement;\n          data.createFrag = ownerDocument.createDocumentFragment;\n          data.frag = data.createFrag();\n        }\n\n\n        ownerDocument.createElement = function(nodeName) {\n          //abort shiv\n          if (!html5.shivMethods) {\n            return data.createElem(nodeName);\n          }\n          return createElement(nodeName, ownerDocument, data);\n        };\n\n        ownerDocument.createDocumentFragment = Function('h,f', 'return function(){' +\n          'var n=f.cloneNode(),c=n.createElement;' +\n          'h.shivMethods&&(' +\n          // unroll the `createElement` calls\n          getElements().join().replace(/[\\w\\-:]+/g, function(nodeName) {\n            data.createElem(nodeName);\n            data.frag.createElement(nodeName);\n            return 'c(\"' + nodeName + '\")';\n          }) +\n          ');return n}'\n        )(html5, data.frag);\n      }\n\n      /*--------------------------------------------------------------------------*/\n\n      /**\n       * Shivs the given document.\n       * @memberOf html5\n       * @param {Document} ownerDocument The document to shiv.\n       * @returns {Document} The shived document.\n       */\n      function shivDocument(ownerDocument) {\n        if (!ownerDocument) {\n          ownerDocument = document;\n        }\n        var data = getExpandoData(ownerDocument);\n\n        if (html5.shivCSS && !supportsHtml5Styles && !data.hasCSS) {\n          data.hasCSS = !!addStyleSheet(ownerDocument,\n            // corrects block display not defined in IE6/7/8/9\n            'article,aside,dialog,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}' +\n            // adds styling not present in IE6/7/8/9\n            'mark{background:#FF0;color:#000}' +\n            // hides non-rendered elements\n            'template{display:none}'\n          );\n        }\n        if (!supportsUnknownElements) {\n          shivMethods(ownerDocument, data);\n        }\n        return ownerDocument;\n      }\n\n      /*--------------------------------------------------------------------------*/\n\n      /**\n       * The `html5` object is exposed so that more elements can be shived and\n       * existing shiving can be detected on iframes.\n       * @type Object\n       * @example\n       *\n       * // options can be changed before the script is included\n       * html5 = { 'elements': 'mark section', 'shivCSS': false, 'shivMethods': false };\n       */\n      var html5 = {\n\n        /**\n         * An array or space separated string of node names of the elements to shiv.\n         * @memberOf html5\n         * @type Array|String\n         */\n        'elements': options.elements || 'abbr article aside audio bdi canvas data datalist details dialog figcaption figure footer header hgroup main mark meter nav output picture progress section summary template time video',\n\n        /**\n         * current version of html5shiv\n         */\n        'version': version,\n\n        /**\n         * A flag to indicate that the HTML5 style sheet should be inserted.\n         * @memberOf html5\n         * @type Boolean\n         */\n        'shivCSS': (options.shivCSS !== false),\n\n        /**\n         * Is equal to true if a browser supports creating unknown/HTML5 elements\n         * @memberOf html5\n         * @type boolean\n         */\n        'supportsUnknownElements': supportsUnknownElements,\n\n        /**\n         * A flag to indicate that the document's `createElement` and `createDocumentFragment`\n         * methods should be overwritten.\n         * @memberOf html5\n         * @type Boolean\n         */\n        'shivMethods': (options.shivMethods !== false),\n\n        /**\n         * A string to describe the type of `html5` object (\"default\" or \"default print\").\n         * @memberOf html5\n         * @type String\n         */\n        'type': 'default',\n\n        // shivs the document according to the specified `html5` object options\n        'shivDocument': shivDocument,\n\n        //creates a shived element\n        createElement: createElement,\n\n        //creates a shived documentFragment\n        createDocumentFragment: createDocumentFragment,\n\n        //extends list of elements\n        addElements: addElements\n      };\n\n      /*--------------------------------------------------------------------------*/\n\n      // expose html5\n      window.html5 = html5;\n\n      // shiv the document\n      shivDocument(document);\n\n      if(typeof module == 'object' && module.exports){\n        module.exports = html5;\n      }\n\n    }(typeof window !== \"undefined\" ? window : this, document));\n  }\n  return html5;\n});",
    "repo": "Modernizr/Modernizr",
    "path": "./datasets/diagrams-repos/Modernizr/Modernizr/src/html5shiv.js",
    "query": "How do the functions within the html5shiv module interact with each other?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'shivDocument', 'node_id': 'shivDocument', 'description': 'Main function that applies HTML5 shiv to the document', 'visibility': 'public', 'return_type': None, 'params': 'ownerDocument', 'source_class_id': None}, {'type': 'function', 'name': 'shivMethods', 'node_id': 'shivMethods', 'description': 'Overrides createElement and createDocumentFragment methods', 'visibility': 'private', 'return_type': None, 'params': 'ownerDocument, data', 'source_class_id': None}, {'type': 'function', 'name': 'createElement', 'node_id': 'createElement', 'description': 'Creates shived HTML5 elements', 'visibility': 'public', 'return_type': None, 'params': 'nodeName, ownerDocument, data', 'source_class_id': None}, {'type': 'function', 'name': 'createDocumentFragment', 'node_id': 'createDocumentFragment', 'description': 'Creates shived document fragment', 'visibility': 'public', 'return_type': None, 'params': 'ownerDocument, data', 'source_class_id': None}, {'type': 'function', 'name': 'addStyleSheet', 'node_id': 'addStyleSheet', 'description': 'Creates and adds style sheet to document', 'visibility': 'private', 'return_type': None, 'params': 'ownerDocument, cssText', 'source_class_id': None}, {'type': 'function', 'name': 'getExpandoData', 'node_id': 'getExpandoData', 'description': 'Returns data associated with document', 'visibility': 'private', 'return_type': None, 'params': 'ownerDocument', 'source_class_id': None}, {'type': 'function', 'name': 'getElements', 'node_id': 'getElements', 'description': 'Returns array of HTML5 elements to shiv', 'visibility': 'private', 'return_type': None, 'params': '', 'source_class_id': None}], 'edges': [{'node_id_from': 'shivDocument', 'node_id_to': 'shivMethods', 'description': 'calls if unknown elements not supported'}, {'node_id_from': 'shivDocument', 'node_id_to': 'addStyleSheet', 'description': 'adds HTML5 styles'}, {'node_id_from': 'shivDocument', 'node_id_to': 'getExpandoData', 'description': 'gets document data'}, {'node_id_from': 'shivMethods', 'node_id_to': 'createElement', 'description': 'overrides with shived version'}, {'node_id_from': 'shivMethods', 'node_id_to': 'createDocumentFragment', 'description': 'overrides with shived version'}, {'node_id_from': 'createElement', 'node_id_to': 'getExpandoData', 'description': 'gets cache data'}, {'node_id_from': 'createDocumentFragment', 'node_id_to': 'getElements', 'description': 'gets elements to create'}], 'packages': [{'package_id': 'html5shiv', 'children': ['core', 'utils'], 'description': 'HTML5 shiv module'}, {'package_id': 'core', 'children': ['shivDocument', 'shivMethods', 'createElement', 'createDocumentFragment'], 'description': 'Core shiv functions'}, {'package_id': 'utils', 'children': ['addStyleSheet', 'getExpandoData', 'getElements'], 'description': 'Utility functions'}]}",
    "version": "medium",
    "text_answer": "The html5shiv module centers around shivDocument as the main function, which coordinates with shivMethods to override document creation methods. createElement and createDocumentFragment are the primary element creation functions, supported by utility functions for managing data and styles.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "JavaScript",
    "code": "\ndefine(['isSVG'], function(isSVG) {\n  /**\n   * @optionName html5shiv\n   * @optionProp html5shiv\n   */\n\n  // Take the html5 variable out of the html5shiv scope so we can return it.\n  var html5;\n  if (!isSVG) {\n    /**\n     * @preserve HTML5 Shiv 3.7.3 | @afarkas @jdalton @jon_neal @rem | MIT/GPL2 Licensed\n     */\n    ;(function(window, document) {\n      /*jshint evil:true */\n      /** version */\n      var version = '3.7.3';\n\n      /** Preset options */\n      var options = window.html5 || {};\n\n      /** Used to skip problem elements */\n      var reSkip = /^<|^(?:button|map|select|textarea|object|iframe|option|optgroup)$/i;\n\n      /** Not all elements can be cloned in IE **/\n      var saveClones = /^(?:a|b|code|div|fieldset|h1|h2|h3|h4|h5|h6|i|label|li|ol|p|q|span|strong|style|table|tbody|td|th|tr|ul)$/i;\n\n      /** Detect whether the browser supports default html5 styles */\n      var supportsHtml5Styles;\n\n      /** Name of the expando, to work with multiple documents or to re-shiv one document */\n      var expando = '_html5shiv';\n\n      /** The id for the the documents expando */\n      var expanID = 0;\n\n      /** Cached data for each document */\n      var expandoData = {};\n\n      /** Detect whether the browser supports unknown elements */\n      var supportsUnknownElements;\n\n      (function() {\n        try {\n          var a = document.createElement('a');\n          a.innerHTML = '<xyz></xyz>';\n          //if the hidden property is implemented we can assume, that the browser supports basic HTML5 Styles\n          supportsHtml5Styles = ('hidden' in a);\n\n          supportsUnknownElements = a.childNodes.length == 1 || (function() {\n            // assign a false positive if unable to shiv\n            (document.createElement)('a');\n            var frag = document.createDocumentFragment();\n            return (\n              typeof frag.cloneNode == 'undefined' ||\n              typeof frag.createDocumentFragment == 'undefined' ||\n              typeof frag.createElement == 'undefined'\n            );\n          }());\n        } catch(e) {\n          // assign a false positive if detection fails => unable to shiv\n          supportsHtml5Styles = true;\n          supportsUnknownElements = true;\n        }\n\n      }());\n\n      /*--------------------------------------------------------------------------*/\n\n      /**\n       * Creates a style sheet with the given CSS text and adds it to the document.\n       * @private\n       * @param {Document} ownerDocument The document.\n       * @param {String} cssText The CSS text.\n       * @returns {StyleSheet} The style element.\n       */\n      function addStyleSheet(ownerDocument, cssText) {\n        var p = ownerDocument.createElement('p'),\n          parent = ownerDocument.getElementsByTagName('head')[0] || ownerDocument.documentElement;\n\n        p.innerHTML = 'x<style>' + cssText + '</style>';\n        return parent.insertBefore(p.lastChild, parent.firstChild);\n      }\n\n      /**\n       * Returns the value of `html5.elements` as an array.\n       * @private\n       * @returns {Array} An array of shived element node names.\n       */\n      function getElements() {\n        var elements = html5.elements;\n        return typeof elements == 'string' ? elements.split(' ') : elements;\n      }\n\n      /**\n       * Extends the built-in list of html5 elements\n       * @memberOf html5\n       * @param {String|Array} newElements whitespace separated list or array of new element names to shiv\n       * @param {Document} ownerDocument The context document.\n       */\n      function addElements(newElements, ownerDocument) {\n        var elements = html5.elements;\n        if(typeof elements != 'string'){\n          elements = elements.join(' ');\n        }\n        if(typeof newElements != 'string'){\n          newElements = newElements.join(' ');\n        }\n        html5.elements = elements +' '+ newElements;\n        shivDocument(ownerDocument);\n      }\n\n      /**\n       * Returns the data associated to the given document\n       * @private\n       * @param {Document} ownerDocument The document.\n       * @returns {Object} An object of data.\n       */\n      function getExpandoData(ownerDocument) {\n        var data = expandoData[ownerDocument[expando]];\n        if (!data) {\n          data = {};\n          expanID++;\n          ownerDocument[expando] = expanID;\n          expandoData[expanID] = data;\n        }\n        return data;\n      }\n\n      /**\n       * returns a shived element for the given nodeName and document\n       * @memberOf html5\n       * @param {String} nodeName name of the element\n       * @param {Document|DocumentFragment} ownerDocument The context document.\n       * @returns {Object} The shived element.\n       */\n      function createElement(nodeName, ownerDocument, data){\n        if (!ownerDocument) {\n          ownerDocument = document;\n        }\n        if(supportsUnknownElements){\n          return ownerDocument.createElement(nodeName);\n        }\n        if (!data) {\n          data = getExpandoData(ownerDocument);\n        }\n        var node;\n\n        if (data.cache[nodeName]) {\n          node = data.cache[nodeName].cloneNode();\n        } else if (saveClones.test(nodeName)) {\n          node = (data.cache[nodeName] = data.createElem(nodeName)).cloneNode();\n        } else {\n          node = data.createElem(nodeName);\n        }\n\n        // Avoid adding some elements to fragments in IE < 9 because\n        // * Attributes like `name` or `type` cannot be set/changed once an element\n        //   is inserted into a document/fragment\n        // * Link elements with `src` attributes that are inaccessible, as with\n        //   a 403 response, will cause the tab/window to crash\n        // * Script elements appended to fragments will execute when their `src`\n        //   or `text` property is set\n        return node.canHaveChildren && !reSkip.test(nodeName) && !node.tagUrn ? data.frag.appendChild(node) : node;\n      }\n\n      /**\n       * returns a shived DocumentFragment for the given document\n       * @memberOf html5\n       * @param {Document} ownerDocument The context document.\n       * @returns {Object} The shived DocumentFragment.\n       */\n      function createDocumentFragment(ownerDocument, data){\n        if (!ownerDocument) {\n          ownerDocument = document;\n        }\n        if(supportsUnknownElements){\n          return ownerDocument.createDocumentFragment();\n        }\n        data = data || getExpandoData(ownerDocument);\n        var clone = data.frag.cloneNode(),\n          i = 0,\n          elems = getElements(),\n          l = elems.length;\n        for(;i<l;i++){\n          clone.createElement(elems[i]);\n        }\n        return clone;\n      }\n\n      /**\n       * Shivs the `createElement` and `createDocumentFragment` methods of the document.\n       * @private\n       * @param {Document|DocumentFragment} ownerDocument The document.\n       * @param {Object} data of the document.\n       */\n      function shivMethods(ownerDocument, data) {\n        if (!data.cache) {\n          data.cache = {};\n          data.createElem = ownerDocument.createElement;\n          data.createFrag = ownerDocument.createDocumentFragment;\n          data.frag = data.createFrag();\n        }\n\n\n        ownerDocument.createElement = function(nodeName) {\n          //abort shiv\n          if (!html5.shivMethods) {\n            return data.createElem(nodeName);\n          }\n          return createElement(nodeName, ownerDocument, data);\n        };\n\n        ownerDocument.createDocumentFragment = Function('h,f', 'return function(){' +\n          'var n=f.cloneNode(),c=n.createElement;' +\n          'h.shivMethods&&(' +\n          // unroll the `createElement` calls\n          getElements().join().replace(/[\\w\\-:]+/g, function(nodeName) {\n            data.createElem(nodeName);\n            data.frag.createElement(nodeName);\n            return 'c(\"' + nodeName + '\")';\n          }) +\n          ');return n}'\n        )(html5, data.frag);\n      }\n\n      /*--------------------------------------------------------------------------*/\n\n      /**\n       * Shivs the given document.\n       * @memberOf html5\n       * @param {Document} ownerDocument The document to shiv.\n       * @returns {Document} The shived document.\n       */\n      function shivDocument(ownerDocument) {\n        if (!ownerDocument) {\n          ownerDocument = document;\n        }\n        var data = getExpandoData(ownerDocument);\n\n        if (html5.shivCSS && !supportsHtml5Styles && !data.hasCSS) {\n          data.hasCSS = !!addStyleSheet(ownerDocument,\n            // corrects block display not defined in IE6/7/8/9\n            'article,aside,dialog,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}' +\n            // adds styling not present in IE6/7/8/9\n            'mark{background:#FF0;color:#000}' +\n            // hides non-rendered elements\n            'template{display:none}'\n          );\n        }\n        if (!supportsUnknownElements) {\n          shivMethods(ownerDocument, data);\n        }\n        return ownerDocument;\n      }\n\n      /*--------------------------------------------------------------------------*/\n\n      /**\n       * The `html5` object is exposed so that more elements can be shived and\n       * existing shiving can be detected on iframes.\n       * @type Object\n       * @example\n       *\n       * // options can be changed before the script is included\n       * html5 = { 'elements': 'mark section', 'shivCSS': false, 'shivMethods': false };\n       */\n      var html5 = {\n\n        /**\n         * An array or space separated string of node names of the elements to shiv.\n         * @memberOf html5\n         * @type Array|String\n         */\n        'elements': options.elements || 'abbr article aside audio bdi canvas data datalist details dialog figcaption figure footer header hgroup main mark meter nav output picture progress section summary template time video',\n\n        /**\n         * current version of html5shiv\n         */\n        'version': version,\n\n        /**\n         * A flag to indicate that the HTML5 style sheet should be inserted.\n         * @memberOf html5\n         * @type Boolean\n         */\n        'shivCSS': (options.shivCSS !== false),\n\n        /**\n         * Is equal to true if a browser supports creating unknown/HTML5 elements\n         * @memberOf html5\n         * @type boolean\n         */\n        'supportsUnknownElements': supportsUnknownElements,\n\n        /**\n         * A flag to indicate that the document's `createElement` and `createDocumentFragment`\n         * methods should be overwritten.\n         * @memberOf html5\n         * @type Boolean\n         */\n        'shivMethods': (options.shivMethods !== false),\n\n        /**\n         * A string to describe the type of `html5` object (\"default\" or \"default print\").\n         * @memberOf html5\n         * @type String\n         */\n        'type': 'default',\n\n        // shivs the document according to the specified `html5` object options\n        'shivDocument': shivDocument,\n\n        //creates a shived element\n        createElement: createElement,\n\n        //creates a shived documentFragment\n        createDocumentFragment: createDocumentFragment,\n\n        //extends list of elements\n        addElements: addElements\n      };\n\n      /*--------------------------------------------------------------------------*/\n\n      // expose html5\n      window.html5 = html5;\n\n      // shiv the document\n      shivDocument(document);\n\n      if(typeof module == 'object' && module.exports){\n        module.exports = html5;\n      }\n\n    }(typeof window !== \"undefined\" ? window : this, document));\n  }\n  return html5;\n});",
    "repo": "Modernizr/Modernizr",
    "path": "./datasets/diagrams-repos/Modernizr/Modernizr/src/html5shiv.js",
    "query": "How do the functions within the html5shiv module interact with each other?",
    "diagram": "{'nodes': [{'type': 'variable', 'name': 'version', 'node_id': 'version', 'description': 'HTML5 shiv version', 'visibility': 'private', 'return_type': 'string', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'options', 'node_id': 'options', 'description': 'Configuration options', 'visibility': 'private', 'return_type': 'object', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'supportsHtml5Styles', 'node_id': 'supportsHtml5Styles', 'description': 'Browser support flag for HTML5 styles', 'visibility': 'private', 'return_type': 'boolean', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'supportsUnknownElements', 'node_id': 'supportsUnknownElements', 'description': 'Browser support flag for unknown elements', 'visibility': 'private', 'return_type': 'boolean', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'html5', 'node_id': 'html5', 'description': 'Main html5 object with configuration and methods', 'visibility': 'public', 'return_type': 'object', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'shivDocument', 'node_id': 'shivDocument', 'description': 'Main function that applies HTML5 shiv to the document', 'visibility': 'public', 'return_type': None, 'params': 'ownerDocument', 'source_class_id': None}, {'type': 'function', 'name': 'shivMethods', 'node_id': 'shivMethods', 'description': 'Overrides createElement and createDocumentFragment methods', 'visibility': 'private', 'return_type': None, 'params': 'ownerDocument, data', 'source_class_id': None}, {'type': 'function', 'name': 'createElement', 'node_id': 'createElement', 'description': 'Creates shived HTML5 elements', 'visibility': 'public', 'return_type': None, 'params': 'nodeName, ownerDocument, data', 'source_class_id': None}, {'type': 'function', 'name': 'createDocumentFragment', 'node_id': 'createDocumentFragment', 'description': 'Creates shived document fragment', 'visibility': 'public', 'return_type': None, 'params': 'ownerDocument, data', 'source_class_id': None}, {'type': 'function', 'name': 'addStyleSheet', 'node_id': 'addStyleSheet', 'description': 'Creates and adds style sheet to document', 'visibility': 'private', 'return_type': None, 'params': 'ownerDocument, cssText', 'source_class_id': None}, {'type': 'function', 'name': 'getExpandoData', 'node_id': 'getExpandoData', 'description': 'Returns data associated with document', 'visibility': 'private', 'return_type': None, 'params': 'ownerDocument', 'source_class_id': None}, {'type': 'function', 'name': 'getElements', 'node_id': 'getElements', 'description': 'Returns array of HTML5 elements to shiv', 'visibility': 'private', 'return_type': None, 'params': '', 'source_class_id': None}, {'type': 'function', 'name': 'addElements', 'node_id': 'addElements', 'description': 'Extends list of HTML5 elements to shiv', 'visibility': 'public', 'return_type': None, 'params': 'newElements, ownerDocument', 'source_class_id': None}], 'edges': [{'node_id_from': 'shivDocument', 'node_id_to': 'shivMethods', 'description': 'calls if unknown elements not supported'}, {'node_id_from': 'shivDocument', 'node_id_to': 'addStyleSheet', 'description': 'adds HTML5 styles'}, {'node_id_from': 'shivDocument', 'node_id_to': 'getExpandoData', 'description': 'gets document data'}, {'node_id_from': 'shivMethods', 'node_id_to': 'createElement', 'description': 'overrides with shived version'}, {'node_id_from': 'shivMethods', 'node_id_to': 'createDocumentFragment', 'description': 'overrides with shived version'}, {'node_id_from': 'createElement', 'node_id_to': 'getExpandoData', 'description': 'gets cache data'}, {'node_id_from': 'createDocumentFragment', 'node_id_to': 'getElements', 'description': 'gets elements to create'}, {'node_id_from': 'addElements', 'node_id_to': 'shivDocument', 'description': 'reshivs document with new elements'}, {'node_id_from': 'version', 'node_id_to': 'html5', 'description': 'stored as html5.version'}, {'node_id_from': 'html5', 'node_id_to': 'shivDocument', 'description': 'exposes shiv functionality'}, {'node_id_from': 'html5', 'node_id_to': 'createElement', 'description': 'exposes element creation'}, {'node_id_from': 'html5', 'node_id_to': 'createDocumentFragment', 'description': 'exposes fragment creation'}, {'node_id_from': 'html5', 'node_id_to': 'addElements', 'description': 'exposes element addition'}, {'node_id_from': 'options', 'node_id_to': 'html5', 'description': 'configures html5 object'}, {'node_id_from': 'supportsHtml5Styles', 'node_id_to': 'shivDocument', 'description': 'controls CSS injection'}, {'node_id_from': 'supportsUnknownElements', 'node_id_to': 'shivDocument', 'description': 'determines if shivMethods is called'}], 'packages': [{'package_id': 'html5shiv', 'children': ['configuration', 'core', 'utils'], 'description': 'HTML5 shiv module'}, {'package_id': 'configuration', 'children': ['version', 'options', 'supportsHtml5Styles', 'supportsUnknownElements', 'html5'], 'description': 'Configuration and state'}, {'package_id': 'core', 'children': ['shivDocument', 'shivMethods', 'createElement', 'createDocumentFragment', 'addElements'], 'description': 'Core shiv functions'}, {'package_id': 'utils', 'children': ['addStyleSheet', 'getExpandoData', 'getElements'], 'description': 'Utility functions'}]}",
    "version": "full",
    "text_answer": "The html5shiv module centers around shivDocument as the main function, which coordinates with shivMethods to override document creation methods. createElement and createDocumentFragment are the primary element creation functions, supported by utility functions for managing data and styles.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Go",
    "code": "\npackage imop\n\nimport (\n\t\"image\"\n\t\"image/color\"\n\t\"image/draw\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestComp_Basic(t *testing.T) {\n\tassert := assert.New(t)\n\n\top := InitOp()\n\terr := op.Set(\"unsupported_composite_operation\")\n\tassert.Error(err)\n\n\top.Set(Clear)\n\tassert.Equal(Clear, op.Get())\n\tassert.NotEqual(\"unsupported_composite_operation\", op.Get())\n\n\top.Set(Dst)\n\tassert.Equal(Dst, op.Get())\n}\n\nfunc TestComp_Ops(t *testing.T) {\n\tassert := assert.New(t)\n\top := InitOp()\n\n\ttransparent := color.NRGBA{R: 0, G: 0, B: 0, A: 0}\n\tcyan := color.NRGBA{R: 33, G: 150, B: 243, A: 255}\n\tmagenta := color.NRGBA{R: 233, G: 30, B: 99, A: 255}\n\n\trect := image.Rect(0, 0, 10, 10)\n\tbmp := NewBitmap(rect)\n\tsource := image.NewNRGBA(rect)\n\tbackdrop := image.NewNRGBA(rect)\n\n\t// No composition operation applied. The SrcOver is the default one.\n\tdraw.Draw(source, image.Rect(0, 4, 6, 10), &image.Uniform{cyan}, image.Point{}, draw.Src)\n\tdraw.Draw(backdrop, image.Rect(4, 0, 10, 6), &image.Uniform{magenta}, image.Point{}, draw.Src)\n\top.Draw(bmp, source, backdrop, nil)\n\n\t// Pick three representative points/pixels from the generated image output.\n\t// Depending on the applied composition operation the colors of the\n\t// selected pixels should be the source color, the destination color or transparent.\n\ttopRight := bmp.Img.At(9, 0)\n\tbottomLeft := bmp.Img.At(0, 9)\n\tcenter := bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, cyan)\n\n\t// Clear\n\top.Set(Clear)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, transparent)\n\tassert.EqualValues(center, transparent)\n\n\t// Copy\n\top.Set(Copy)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, cyan)\n\n\t// Dst\n\top.Set(Dst)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, transparent)\n\tassert.EqualValues(center, magenta)\n\n\t// SrcOver\n\top.Set(SrcOver)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, cyan)\n\n\t// DstOver\n\top.Set(DstOver)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, magenta)\n\n\t// SrcIn\n\top.Set(SrcIn)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, transparent)\n\tassert.EqualValues(center, cyan)\n\n\t// DstIn\n\top.Set(DstIn)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, transparent)\n\tassert.EqualValues(center, magenta)\n\n\t// SrcOut\n\top.Set(SrcOut)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, transparent)\n\n\t// DstOut\n\top.Set(DstOut)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, transparent)\n\tassert.EqualValues(center, transparent)\n\n\t// SrcAtop\n\top.Set(SrcAtop)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, transparent)\n\tassert.EqualValues(center, cyan)\n\n\t// DstAtop\n\top.Set(DstAtop)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, magenta)\n\n\t// Xor\n\top.Set(Xor)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, transparent)\n\t// DstAtop\n\top.Set(DstAtop)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, magenta)\n}",
    "repo": "esimov/caire",
    "path": "./datasets/diagrams-repos/esimov/caire/imop/composite_test.go",
    "query": "What is the effect of each composite operation on the final image output?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'TestComp_Ops', 'node_id': 'TestComp_Ops', 'description': 'Tests different composite operations on image manipulation', 'visibility': 'public', 'return_type': None, 'params': '*testing.T', 'source_class_id': None}, {'type': 'entity', 'name': 'CompositeOperations', 'node_id': 'CompositeOperations', 'description': 'Different types of image composition operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'TestComp_Ops', 'node_id_to': 'CompositeOperations', 'description': 'tests effects'}], 'packages': [{'package_id': 'ImageOperations', 'children': ['CompositeOperations', 'TestComp_Ops'], 'description': 'Image manipulation and testing functionality'}]}",
    "version": "minimal",
    "text_answer": "Each composite operation affects the final image differently: Clear makes everything transparent, Copy only shows source pixels, Dst preserves only destination pixels, SrcOver/DstOver layers one image over another, SrcIn/DstIn shows one image only where the other exists, SrcOut/DstOut shows one image only where the other is transparent, SrcAtop/DstAtop combines images while preserving one's alpha channel, and Xor shows non-overlapping parts of both images.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Go",
    "code": "\npackage imop\n\nimport (\n\t\"image\"\n\t\"image/color\"\n\t\"image/draw\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestComp_Basic(t *testing.T) {\n\tassert := assert.New(t)\n\n\top := InitOp()\n\terr := op.Set(\"unsupported_composite_operation\")\n\tassert.Error(err)\n\n\top.Set(Clear)\n\tassert.Equal(Clear, op.Get())\n\tassert.NotEqual(\"unsupported_composite_operation\", op.Get())\n\n\top.Set(Dst)\n\tassert.Equal(Dst, op.Get())\n}\n\nfunc TestComp_Ops(t *testing.T) {\n\tassert := assert.New(t)\n\top := InitOp()\n\n\ttransparent := color.NRGBA{R: 0, G: 0, B: 0, A: 0}\n\tcyan := color.NRGBA{R: 33, G: 150, B: 243, A: 255}\n\tmagenta := color.NRGBA{R: 233, G: 30, B: 99, A: 255}\n\n\trect := image.Rect(0, 0, 10, 10)\n\tbmp := NewBitmap(rect)\n\tsource := image.NewNRGBA(rect)\n\tbackdrop := image.NewNRGBA(rect)\n\n\t// No composition operation applied. The SrcOver is the default one.\n\tdraw.Draw(source, image.Rect(0, 4, 6, 10), &image.Uniform{cyan}, image.Point{}, draw.Src)\n\tdraw.Draw(backdrop, image.Rect(4, 0, 10, 6), &image.Uniform{magenta}, image.Point{}, draw.Src)\n\top.Draw(bmp, source, backdrop, nil)\n\n\t// Pick three representative points/pixels from the generated image output.\n\t// Depending on the applied composition operation the colors of the\n\t// selected pixels should be the source color, the destination color or transparent.\n\ttopRight := bmp.Img.At(9, 0)\n\tbottomLeft := bmp.Img.At(0, 9)\n\tcenter := bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, cyan)\n\n\t// Clear\n\top.Set(Clear)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, transparent)\n\tassert.EqualValues(center, transparent)\n\n\t// Copy\n\top.Set(Copy)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, cyan)\n\n\t// Dst\n\top.Set(Dst)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, transparent)\n\tassert.EqualValues(center, magenta)\n\n\t// SrcOver\n\top.Set(SrcOver)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, cyan)\n\n\t// DstOver\n\top.Set(DstOver)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, magenta)\n\n\t// SrcIn\n\top.Set(SrcIn)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, transparent)\n\tassert.EqualValues(center, cyan)\n\n\t// DstIn\n\top.Set(DstIn)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, transparent)\n\tassert.EqualValues(center, magenta)\n\n\t// SrcOut\n\top.Set(SrcOut)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, transparent)\n\n\t// DstOut\n\top.Set(DstOut)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, transparent)\n\tassert.EqualValues(center, transparent)\n\n\t// SrcAtop\n\top.Set(SrcAtop)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, transparent)\n\tassert.EqualValues(center, cyan)\n\n\t// DstAtop\n\top.Set(DstAtop)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, magenta)\n\n\t// Xor\n\top.Set(Xor)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, transparent)\n\t// DstAtop\n\top.Set(DstAtop)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, magenta)\n}",
    "repo": "esimov/caire",
    "path": "./datasets/diagrams-repos/esimov/caire/imop/composite_test.go",
    "query": "What is the effect of each composite operation on the final image output?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'TestComp_Ops', 'node_id': 'TestComp_Ops', 'description': 'Tests different composite operations on image manipulation', 'visibility': 'public', 'return_type': None, 'params': '*testing.T', 'source_class_id': None}, {'type': 'entity', 'name': 'CompositeOperations', 'node_id': 'CompositeOperations', 'description': 'Different types of image composition operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'PixelColors', 'node_id': 'PixelColors', 'description': 'Test colors used in composition', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'TestPoints', 'node_id': 'TestPoints', 'description': 'Representative points for testing (topRight, bottomLeft, center)', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'TestComp_Ops', 'node_id_to': 'CompositeOperations', 'description': 'tests effects'}, {'node_id_from': 'TestComp_Ops', 'node_id_to': 'PixelColors', 'description': 'uses'}, {'node_id_from': 'TestComp_Ops', 'node_id_to': 'TestPoints', 'description': 'verifies'}], 'packages': [{'package_id': 'ImageOperations', 'children': ['CompositeOperations', 'TestComp_Ops', 'PixelColors', 'TestPoints'], 'description': 'Image manipulation and testing functionality'}]}",
    "version": "medium",
    "text_answer": "Each composite operation affects the final image differently: Clear makes everything transparent, Copy only shows source pixels, Dst preserves only destination pixels, SrcOver/DstOver layers one image over another, SrcIn/DstIn shows one image only where the other exists, SrcOut/DstOut shows one image only where the other is transparent, SrcAtop/DstAtop combines images while preserving one's alpha channel, and Xor shows non-overlapping parts of both images.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Go",
    "code": "\npackage imop\n\nimport (\n\t\"image\"\n\t\"image/color\"\n\t\"image/draw\"\n\t\"testing\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestComp_Basic(t *testing.T) {\n\tassert := assert.New(t)\n\n\top := InitOp()\n\terr := op.Set(\"unsupported_composite_operation\")\n\tassert.Error(err)\n\n\top.Set(Clear)\n\tassert.Equal(Clear, op.Get())\n\tassert.NotEqual(\"unsupported_composite_operation\", op.Get())\n\n\top.Set(Dst)\n\tassert.Equal(Dst, op.Get())\n}\n\nfunc TestComp_Ops(t *testing.T) {\n\tassert := assert.New(t)\n\top := InitOp()\n\n\ttransparent := color.NRGBA{R: 0, G: 0, B: 0, A: 0}\n\tcyan := color.NRGBA{R: 33, G: 150, B: 243, A: 255}\n\tmagenta := color.NRGBA{R: 233, G: 30, B: 99, A: 255}\n\n\trect := image.Rect(0, 0, 10, 10)\n\tbmp := NewBitmap(rect)\n\tsource := image.NewNRGBA(rect)\n\tbackdrop := image.NewNRGBA(rect)\n\n\t// No composition operation applied. The SrcOver is the default one.\n\tdraw.Draw(source, image.Rect(0, 4, 6, 10), &image.Uniform{cyan}, image.Point{}, draw.Src)\n\tdraw.Draw(backdrop, image.Rect(4, 0, 10, 6), &image.Uniform{magenta}, image.Point{}, draw.Src)\n\top.Draw(bmp, source, backdrop, nil)\n\n\t// Pick three representative points/pixels from the generated image output.\n\t// Depending on the applied composition operation the colors of the\n\t// selected pixels should be the source color, the destination color or transparent.\n\ttopRight := bmp.Img.At(9, 0)\n\tbottomLeft := bmp.Img.At(0, 9)\n\tcenter := bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, cyan)\n\n\t// Clear\n\top.Set(Clear)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, transparent)\n\tassert.EqualValues(center, transparent)\n\n\t// Copy\n\top.Set(Copy)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, cyan)\n\n\t// Dst\n\top.Set(Dst)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, transparent)\n\tassert.EqualValues(center, magenta)\n\n\t// SrcOver\n\top.Set(SrcOver)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, cyan)\n\n\t// DstOver\n\top.Set(DstOver)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, magenta)\n\n\t// SrcIn\n\top.Set(SrcIn)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, transparent)\n\tassert.EqualValues(center, cyan)\n\n\t// DstIn\n\top.Set(DstIn)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, transparent)\n\tassert.EqualValues(center, magenta)\n\n\t// SrcOut\n\top.Set(SrcOut)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, transparent)\n\n\t// DstOut\n\top.Set(DstOut)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, transparent)\n\tassert.EqualValues(center, transparent)\n\n\t// SrcAtop\n\top.Set(SrcAtop)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, transparent)\n\tassert.EqualValues(center, cyan)\n\n\t// DstAtop\n\top.Set(DstAtop)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, magenta)\n\n\t// Xor\n\top.Set(Xor)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, magenta)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, transparent)\n\t// DstAtop\n\top.Set(DstAtop)\n\top.Draw(bmp, source, backdrop, nil)\n\n\ttopRight = bmp.Img.At(9, 0)\n\tbottomLeft = bmp.Img.At(0, 9)\n\tcenter = bmp.Img.At(5, 5)\n\n\tassert.EqualValues(topRight, transparent)\n\tassert.EqualValues(bottomLeft, cyan)\n\tassert.EqualValues(center, magenta)\n}",
    "repo": "esimov/caire",
    "path": "./datasets/diagrams-repos/esimov/caire/imop/composite_test.go",
    "query": "What is the effect of each composite operation on the final image output?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'TestComp_Ops', 'node_id': 'TestComp_Ops', 'description': 'Tests different composite operations on image manipulation', 'visibility': 'public', 'return_type': None, 'params': '*testing.T', 'source_class_id': None}, {'type': 'entity', 'name': 'Clear', 'node_id': 'Clear', 'description': 'Sets all pixels to transparent', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'Copy', 'node_id': 'Copy', 'description': 'Copies source pixels to destination', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'Dst', 'node_id': 'Dst', 'description': 'Keeps only destination pixels', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SrcOver', 'node_id': 'SrcOver', 'description': 'Places source over destination', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'DstOver', 'node_id': 'DstOver', 'description': 'Places destination over source', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SrcIn', 'node_id': 'SrcIn', 'description': 'Shows source where destination exists', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'DstIn', 'node_id': 'DstIn', 'description': 'Shows destination where source exists', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SrcOut', 'node_id': 'SrcOut', 'description': 'Shows source where destination is transparent', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'DstOut', 'node_id': 'DstOut', 'description': 'Shows destination where source is transparent', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'SrcAtop', 'node_id': 'SrcAtop', 'description': 'Source above destination, keeping destination alpha', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'DstAtop', 'node_id': 'DstAtop', 'description': 'Destination above source, keeping source alpha', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'Xor', 'node_id': 'Xor', 'description': 'Exclusive OR of source and destination', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'TestComp_Ops', 'node_id_to': 'Clear', 'description': 'tests'}, {'node_id_from': 'TestComp_Ops', 'node_id_to': 'Copy', 'description': 'tests'}, {'node_id_from': 'TestComp_Ops', 'node_id_to': 'Dst', 'description': 'tests'}, {'node_id_from': 'TestComp_Ops', 'node_id_to': 'SrcOver', 'description': 'tests'}, {'node_id_from': 'TestComp_Ops', 'node_id_to': 'DstOver', 'description': 'tests'}, {'node_id_from': 'TestComp_Ops', 'node_id_to': 'SrcIn', 'description': 'tests'}, {'node_id_from': 'TestComp_Ops', 'node_id_to': 'DstIn', 'description': 'tests'}, {'node_id_from': 'TestComp_Ops', 'node_id_to': 'SrcOut', 'description': 'tests'}, {'node_id_from': 'TestComp_Ops', 'node_id_to': 'DstOut', 'description': 'tests'}, {'node_id_from': 'TestComp_Ops', 'node_id_to': 'SrcAtop', 'description': 'tests'}, {'node_id_from': 'TestComp_Ops', 'node_id_to': 'DstAtop', 'description': 'tests'}, {'node_id_from': 'TestComp_Ops', 'node_id_to': 'Xor', 'description': 'tests'}], 'packages': [{'package_id': 'CompositeOperations', 'children': ['Clear', 'Copy', 'Dst', 'SrcOver', 'DstOver', 'SrcIn', 'DstIn', 'SrcOut', 'DstOut', 'SrcAtop', 'DstAtop', 'Xor'], 'description': 'Available composite operations'}]}",
    "version": "full",
    "text_answer": "Each composite operation affects the final image differently: Clear makes everything transparent, Copy only shows source pixels, Dst preserves only destination pixels, SrcOver/DstOver layers one image over another, SrcIn/DstIn shows one image only where the other exists, SrcOut/DstOut shows one image only where the other is transparent, SrcAtop/DstAtop combines images while preserving one's alpha channel, and Xor shows non-overlapping parts of both images.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C++",
    "code": "\n#ifndef TENSORFLOW_CORE_GRAPPLER_OPTIMIZERS_DATA_GRAPH_UTILS_H_\n#define TENSORFLOW_CORE_GRAPPLER_OPTIMIZERS_DATA_GRAPH_UTILS_H_\n\n#include \"tensorflow/core/framework/attr_value.pb.h\"\n#include \"tensorflow/core/framework/function.pb.h\"\n#include \"tensorflow/core/framework/graph.pb.h\"\n#include \"tensorflow/core/framework/node_def.pb.h\"\n#include \"tensorflow/core/framework/tensor.pb.h\"\n#include \"tensorflow/core/framework/tensor_shape.pb.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/graph/graph.h\"\n#include \"tensorflow/core/grappler/grappler_item.h\"\n#include \"tensorflow/core/grappler/mutable_graph_view.h\"\n#include \"tensorflow/core/grappler/utils.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n\nnamespace tensorflow {\nnamespace grappler {\nnamespace graph_utils {\n\n// Returns the index of the first element in collection that fulfills predicate.\n// If no such element exists, returns -1.\ntemplate <typename Predicate, typename Collection>\nint GetFirstElementIndexWithPredicate(const Predicate& predicate,\n                                      const Collection& collection) {\n  unsigned idx = 0;\n  for (auto&& element : collection) {\n    if (predicate(element)) {\n      return idx;\n    }\n    idx++;\n  }\n  return -1;\n}\n\n// Adds a node to the graph.\nNodeDef* AddNode(absl::string_view name, absl::string_view op,\n                 const std::vector<string>& inputs,\n                 const std::vector<std::pair<string, AttrValue>>& attributes,\n                 MutableGraphView* graph);\n\n// Adds Placeholder node for given type.\nNodeDef* AddScalarPlaceholder(DataType dtype, MutableGraphView* graph);\n\n// Adds a Const node with the given value to the graph.\ntemplate <typename T>\nNodeDef* AddScalarConstNode(T v, MutableGraphView* graph) {\n  // is_same is an idiomatic hack for making it compile if not instantiated.\n  // Replacing with false will result in a compile-time error.\n  static_assert(!std::is_same<T, T>::value,\n                \"Invalid specialization of this method for type T.\");\n  return {};\n}\n\ntemplate <>\nNodeDef* AddScalarConstNode(bool v, MutableGraphView* graph);\ntemplate <>\nNodeDef* AddScalarConstNode(double v, MutableGraphView* graph);\ntemplate <>\nNodeDef* AddScalarConstNode(float v, MutableGraphView* graph);\ntemplate <>\nNodeDef* AddScalarConstNode(int v, MutableGraphView* graph);\ntemplate <>\nNodeDef* AddScalarConstNode(int64_t v, MutableGraphView* graph);\ntemplate <>\nNodeDef* AddScalarConstNode(absl::string_view v, MutableGraphView* graph);\n\n// Retrieves the value of a const node. Returns an error\n// if the node is not const, or its value is of a different type.\ntemplate <typename T>\nabsl::Status GetScalarConstNodeValue(const NodeDef& node, T* value) {\n  // is_same is an idiomatic hack for making it compile if not instantiated.\n  // Replacing with false will result in a compile-time error.\n  static_assert(!std::is_same<T, T>::value,\n                \"Invalid specialization of this method fo rtype T.\");\n}\n\ntemplate <>\nabsl::Status GetScalarConstNodeValue(const NodeDef& node, int64_t* value);\ntemplate <>\nabsl::Status GetScalarConstNodeValue(const NodeDef& node, bool* value);\n\n// Checks whether the two graphs are the same.\nbool Compare(const GraphDef& g1, const GraphDef& g2);\n\n// Checks whether the graph contains a node with the given name.\nbool ContainsGraphNodeWithName(absl::string_view name, const GraphDef& graph);\n\n// Checks whether the library contains a function with the given name.\nbool ContainsGraphFunctionWithName(absl::string_view name,\n                                   const FunctionDefLibrary& library);\n\n// Checks whether the graph contains a node with the given op.\nbool ContainsNodeWithOp(absl::string_view op, const GraphDef& graph);\n\n// Returns the index of the node with the given name or -1 if the node does\n// not exist.\nint FindGraphNodeWithName(absl::string_view name, const GraphDef& graph);\n\n// Returns the index of the function with the given name or -1 if the function\n// does not exist.\nint FindGraphFunctionWithName(absl::string_view name,\n                              const FunctionDefLibrary& library);\n\n// Returns the index of the first node with the given op or -1 if no such  node\n// exists.\nint FindGraphNodeWithOp(absl::string_view op, const GraphDef& graph);\n\n// Gets the 0th input to a node in the graph.\nNodeDef* GetInputNode(const NodeDef& node, const MutableGraphView& graph);\n\n// Gets the ith input to a node in the graph.\nNodeDef* GetInputNode(const NodeDef& node, const MutableGraphView& graph,\n                      int64_t i);\n\n// Gets the attr corresponding to a dataset node's output types, if it exists.\nabsl::Status GetDatasetOutputTypesAttr(const NodeDef& node,\n                                       DataTypeVector* output_types);\n\n// Returns the list of indices of all nodes with the given op or empty list if\n// no such node exists.\nstd::vector<int> FindAllGraphNodesWithOp(const string& op,\n                                         const GraphDef& graph);\n\n// Sets the node name using `prefix` as a prefix while guaranteeing the name\n// is unique across the graph.\nvoid SetUniqueGraphNodeName(absl::string_view prefix, GraphDef* graph,\n                            NodeDef* node);\n\n// Sets the function name using the `prefix` name as a prefix while guaranteeing\n// the name is unique across the function library.\nvoid SetUniqueGraphFunctionName(absl::string_view prefix,\n                                const FunctionDefLibrary* library,\n                                FunctionDef* function);\n\n// Copies attribute having name `attribute_name` from node `from` to node\n// `to_node`.\nvoid CopyAttribute(const string& attribute_name, const NodeDef& from,\n                   NodeDef* to_node);\n\n// Concatenates list attribute having name `attribute_name` from `first` and\n// `second` node, setting it to `to_node`.\nvoid ConcatAttributeList(const string& attribute_name, const NodeDef& first,\n                         const NodeDef& second, NodeDef* to_node);\n\n// Checks that all nodes in the graphs have unique names, and sets their names\n// to be unique if they are not already.  This is necessary as Graph does not\n// have the provisions to deduplicate names, and name deduplication elsewhere\n// in tensorflow happens in other layers (for example, in the Scope class of the\n// C++ API). Note that the nodes in the graph are identified by their id,\n// and renaming nodes does not mutate any edges.\nabsl::Status EnsureNodeNamesUnique(Graph* g);\n\n// Returns the item's fetch node, if there is exactly one. Otherwise, returns an\n// error.\nabsl::Status GetFetchNode(const MutableGraphView& graph,\n                          const GrapplerItem& item, NodeDef** fetch_node);\n\n// Returns true if `item` is derived from a `FunctionDef`, false otherwise.\n// Currently, we determine this heuristically: If we don't have any fetch nodes\n// or all fetch nodes are `Retval` ops, then we consider this item as derived\n// from a `FunctionDef`.\nbool IsItemDerivedFromFunctionDef(const GrapplerItem& item,\n                                  const MutableGraphView& graph_view);\n\n// If both input nodes have the \"metadata\" attribute set, it populates the\n// \"metadata\" attribute for the fused node.\nvoid MaybeSetFusedMetadata(const NodeDef& node1, const NodeDef& node2,\n                           NodeDef* fused_node);\n\n// Copies the attributes `output_shapes`, `output_types` from node `from` to\n// node `to_node` if they exist. The method will return `true` if attributes\n// copied successfully, otherwise it will return `false`.\n//\n// Some tf.data transformations set `Toutput_types` instead of `output_types`\n// when the attribute describes type of tensor inputs (e.g. TensorDataset,\n// TensorSliceDataset, and PaddedBatchDataset). In this case the method copies\n// the attribute `Toutput_types` of node `from` to the attribute `output_types`\n// of node `to_node`.\nbool CopyShapesAndTypesAttrs(const NodeDef& from, NodeDef* to_node);\n\n// Checks whether the op has a \"sloppy\" attribute.\nbool HasSloppyAttr(const string& op);\n\n// Checks whether the op has a \"replicate_on_split\" attribute.\nbool HasReplicateOnSplitAttr(const string& op);\n\n// Checks whether the op has a \"deterministic\" attribute.\nbool HasDeterministicAttr(const string& op);\n\n// Sets the `name` as the metadata name of the `node`. It returns an error if\n// the `node` already has a metadata name.\nabsl::Status SetMetadataName(const std::string& name, NodeDef* node);\n\n}  // namespace graph_utils\n}  // namespace grappler\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_CORE_GRAPPLER_OPTIMIZERS_DATA_GRAPH_UTILS_H_",
    "repo": "tensorflow/tensorflow",
    "path": "./datasets/diagrams-repos/tensorflow/tensorflow/tensorflow/core/grappler/optimizers/data/graph_utils.h",
    "query": "What is the inheritance hierarchy of the AddScalarConstNode function templates?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'AddScalarConstNode', 'node_id': 'AddScalarConstNode', 'description': 'Base template function for adding const nodes', 'visibility': 'public', 'return_type': 'NodeDef*', 'params': 'T v, MutableGraphView* graph', 'source_class_id': None}, {'type': 'function', 'name': 'AddScalarConstNode', 'node_id': 'AddScalarConstNode_bool', 'description': 'Specialization for boolean values', 'visibility': 'public', 'return_type': 'NodeDef*', 'params': 'bool v, MutableGraphView* graph', 'source_class_id': None}, {'type': 'function', 'name': 'AddScalarConstNode', 'node_id': 'AddScalarConstNode_double', 'description': 'Specialization for double values', 'visibility': 'public', 'return_type': 'NodeDef*', 'params': 'double v, MutableGraphView* graph', 'source_class_id': None}, {'type': 'function', 'name': 'AddScalarConstNode', 'node_id': 'AddScalarConstNode_float', 'description': 'Specialization for float values', 'visibility': 'public', 'return_type': 'NodeDef*', 'params': 'float v, MutableGraphView* graph', 'source_class_id': None}, {'type': 'function', 'name': 'AddScalarConstNode', 'node_id': 'AddScalarConstNode_int', 'description': 'Specialization for int values', 'visibility': 'public', 'return_type': 'NodeDef*', 'params': 'int v, MutableGraphView* graph', 'source_class_id': None}, {'type': 'function', 'name': 'AddScalarConstNode', 'node_id': 'AddScalarConstNode_int64', 'description': 'Specialization for int64 values', 'visibility': 'public', 'return_type': 'NodeDef*', 'params': 'int64_t v, MutableGraphView* graph', 'source_class_id': None}, {'type': 'function', 'name': 'AddScalarConstNode', 'node_id': 'AddScalarConstNode_string', 'description': 'Specialization for string values', 'visibility': 'public', 'return_type': 'NodeDef*', 'params': 'string_view v, MutableGraphView* graph', 'source_class_id': None}], 'edges': [{'node_id_from': 'AddScalarConstNode', 'node_id_to': 'AddScalarConstNode_bool', 'description': 'specializes'}, {'node_id_from': 'AddScalarConstNode', 'node_id_to': 'AddScalarConstNode_double', 'description': 'specializes'}, {'node_id_from': 'AddScalarConstNode', 'node_id_to': 'AddScalarConstNode_float', 'description': 'specializes'}, {'node_id_from': 'AddScalarConstNode', 'node_id_to': 'AddScalarConstNode_int', 'description': 'specializes'}, {'node_id_from': 'AddScalarConstNode', 'node_id_to': 'AddScalarConstNode_int64', 'description': 'specializes'}, {'node_id_from': 'AddScalarConstNode', 'node_id_to': 'AddScalarConstNode_string', 'description': 'specializes'}], 'packages': [{'package_id': 'templateSpecializations', 'children': ['AddScalarConstNode', 'AddScalarConstNode_bool', 'AddScalarConstNode_double', 'AddScalarConstNode_float', 'AddScalarConstNode_int', 'AddScalarConstNode_int64', 'AddScalarConstNode_string'], 'description': 'Template function and its specializations'}]}",
    "version": "medium",
    "text_answer": "AddScalarConstNode is a template function with specializations for bool, double, float, int, int64_t, and string_view types. The base template is undefined and will cause a compile-time error if instantiated with unsupported types.",
    "possible_version": [
      "minimal",
      "medium"
    ]
  },
  {
    "language": "C++",
    "code": "\n#ifndef TENSORFLOW_CORE_GRAPPLER_OPTIMIZERS_DATA_GRAPH_UTILS_H_\n#define TENSORFLOW_CORE_GRAPPLER_OPTIMIZERS_DATA_GRAPH_UTILS_H_\n\n#include \"tensorflow/core/framework/attr_value.pb.h\"\n#include \"tensorflow/core/framework/function.pb.h\"\n#include \"tensorflow/core/framework/graph.pb.h\"\n#include \"tensorflow/core/framework/node_def.pb.h\"\n#include \"tensorflow/core/framework/tensor.pb.h\"\n#include \"tensorflow/core/framework/tensor_shape.pb.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/graph/graph.h\"\n#include \"tensorflow/core/grappler/grappler_item.h\"\n#include \"tensorflow/core/grappler/mutable_graph_view.h\"\n#include \"tensorflow/core/grappler/utils.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n\nnamespace tensorflow {\nnamespace grappler {\nnamespace graph_utils {\n\n// Returns the index of the first element in collection that fulfills predicate.\n// If no such element exists, returns -1.\ntemplate <typename Predicate, typename Collection>\nint GetFirstElementIndexWithPredicate(const Predicate& predicate,\n                                      const Collection& collection) {\n  unsigned idx = 0;\n  for (auto&& element : collection) {\n    if (predicate(element)) {\n      return idx;\n    }\n    idx++;\n  }\n  return -1;\n}\n\n// Adds a node to the graph.\nNodeDef* AddNode(absl::string_view name, absl::string_view op,\n                 const std::vector<string>& inputs,\n                 const std::vector<std::pair<string, AttrValue>>& attributes,\n                 MutableGraphView* graph);\n\n// Adds Placeholder node for given type.\nNodeDef* AddScalarPlaceholder(DataType dtype, MutableGraphView* graph);\n\n// Adds a Const node with the given value to the graph.\ntemplate <typename T>\nNodeDef* AddScalarConstNode(T v, MutableGraphView* graph) {\n  // is_same is an idiomatic hack for making it compile if not instantiated.\n  // Replacing with false will result in a compile-time error.\n  static_assert(!std::is_same<T, T>::value,\n                \"Invalid specialization of this method for type T.\");\n  return {};\n}\n\ntemplate <>\nNodeDef* AddScalarConstNode(bool v, MutableGraphView* graph);\ntemplate <>\nNodeDef* AddScalarConstNode(double v, MutableGraphView* graph);\ntemplate <>\nNodeDef* AddScalarConstNode(float v, MutableGraphView* graph);\ntemplate <>\nNodeDef* AddScalarConstNode(int v, MutableGraphView* graph);\ntemplate <>\nNodeDef* AddScalarConstNode(int64_t v, MutableGraphView* graph);\ntemplate <>\nNodeDef* AddScalarConstNode(absl::string_view v, MutableGraphView* graph);\n\n// Retrieves the value of a const node. Returns an error\n// if the node is not const, or its value is of a different type.\ntemplate <typename T>\nabsl::Status GetScalarConstNodeValue(const NodeDef& node, T* value) {\n  // is_same is an idiomatic hack for making it compile if not instantiated.\n  // Replacing with false will result in a compile-time error.\n  static_assert(!std::is_same<T, T>::value,\n                \"Invalid specialization of this method fo rtype T.\");\n}\n\ntemplate <>\nabsl::Status GetScalarConstNodeValue(const NodeDef& node, int64_t* value);\ntemplate <>\nabsl::Status GetScalarConstNodeValue(const NodeDef& node, bool* value);\n\n// Checks whether the two graphs are the same.\nbool Compare(const GraphDef& g1, const GraphDef& g2);\n\n// Checks whether the graph contains a node with the given name.\nbool ContainsGraphNodeWithName(absl::string_view name, const GraphDef& graph);\n\n// Checks whether the library contains a function with the given name.\nbool ContainsGraphFunctionWithName(absl::string_view name,\n                                   const FunctionDefLibrary& library);\n\n// Checks whether the graph contains a node with the given op.\nbool ContainsNodeWithOp(absl::string_view op, const GraphDef& graph);\n\n// Returns the index of the node with the given name or -1 if the node does\n// not exist.\nint FindGraphNodeWithName(absl::string_view name, const GraphDef& graph);\n\n// Returns the index of the function with the given name or -1 if the function\n// does not exist.\nint FindGraphFunctionWithName(absl::string_view name,\n                              const FunctionDefLibrary& library);\n\n// Returns the index of the first node with the given op or -1 if no such  node\n// exists.\nint FindGraphNodeWithOp(absl::string_view op, const GraphDef& graph);\n\n// Gets the 0th input to a node in the graph.\nNodeDef* GetInputNode(const NodeDef& node, const MutableGraphView& graph);\n\n// Gets the ith input to a node in the graph.\nNodeDef* GetInputNode(const NodeDef& node, const MutableGraphView& graph,\n                      int64_t i);\n\n// Gets the attr corresponding to a dataset node's output types, if it exists.\nabsl::Status GetDatasetOutputTypesAttr(const NodeDef& node,\n                                       DataTypeVector* output_types);\n\n// Returns the list of indices of all nodes with the given op or empty list if\n// no such node exists.\nstd::vector<int> FindAllGraphNodesWithOp(const string& op,\n                                         const GraphDef& graph);\n\n// Sets the node name using `prefix` as a prefix while guaranteeing the name\n// is unique across the graph.\nvoid SetUniqueGraphNodeName(absl::string_view prefix, GraphDef* graph,\n                            NodeDef* node);\n\n// Sets the function name using the `prefix` name as a prefix while guaranteeing\n// the name is unique across the function library.\nvoid SetUniqueGraphFunctionName(absl::string_view prefix,\n                                const FunctionDefLibrary* library,\n                                FunctionDef* function);\n\n// Copies attribute having name `attribute_name` from node `from` to node\n// `to_node`.\nvoid CopyAttribute(const string& attribute_name, const NodeDef& from,\n                   NodeDef* to_node);\n\n// Concatenates list attribute having name `attribute_name` from `first` and\n// `second` node, setting it to `to_node`.\nvoid ConcatAttributeList(const string& attribute_name, const NodeDef& first,\n                         const NodeDef& second, NodeDef* to_node);\n\n// Checks that all nodes in the graphs have unique names, and sets their names\n// to be unique if they are not already.  This is necessary as Graph does not\n// have the provisions to deduplicate names, and name deduplication elsewhere\n// in tensorflow happens in other layers (for example, in the Scope class of the\n// C++ API). Note that the nodes in the graph are identified by their id,\n// and renaming nodes does not mutate any edges.\nabsl::Status EnsureNodeNamesUnique(Graph* g);\n\n// Returns the item's fetch node, if there is exactly one. Otherwise, returns an\n// error.\nabsl::Status GetFetchNode(const MutableGraphView& graph,\n                          const GrapplerItem& item, NodeDef** fetch_node);\n\n// Returns true if `item` is derived from a `FunctionDef`, false otherwise.\n// Currently, we determine this heuristically: If we don't have any fetch nodes\n// or all fetch nodes are `Retval` ops, then we consider this item as derived\n// from a `FunctionDef`.\nbool IsItemDerivedFromFunctionDef(const GrapplerItem& item,\n                                  const MutableGraphView& graph_view);\n\n// If both input nodes have the \"metadata\" attribute set, it populates the\n// \"metadata\" attribute for the fused node.\nvoid MaybeSetFusedMetadata(const NodeDef& node1, const NodeDef& node2,\n                           NodeDef* fused_node);\n\n// Copies the attributes `output_shapes`, `output_types` from node `from` to\n// node `to_node` if they exist. The method will return `true` if attributes\n// copied successfully, otherwise it will return `false`.\n//\n// Some tf.data transformations set `Toutput_types` instead of `output_types`\n// when the attribute describes type of tensor inputs (e.g. TensorDataset,\n// TensorSliceDataset, and PaddedBatchDataset). In this case the method copies\n// the attribute `Toutput_types` of node `from` to the attribute `output_types`\n// of node `to_node`.\nbool CopyShapesAndTypesAttrs(const NodeDef& from, NodeDef* to_node);\n\n// Checks whether the op has a \"sloppy\" attribute.\nbool HasSloppyAttr(const string& op);\n\n// Checks whether the op has a \"replicate_on_split\" attribute.\nbool HasReplicateOnSplitAttr(const string& op);\n\n// Checks whether the op has a \"deterministic\" attribute.\nbool HasDeterministicAttr(const string& op);\n\n// Sets the `name` as the metadata name of the `node`. It returns an error if\n// the `node` already has a metadata name.\nabsl::Status SetMetadataName(const std::string& name, NodeDef* node);\n\n}  // namespace graph_utils\n}  // namespace grappler\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_CORE_GRAPPLER_OPTIMIZERS_DATA_GRAPH_UTILS_H_",
    "repo": "tensorflow/tensorflow",
    "path": "./datasets/diagrams-repos/tensorflow/tensorflow/tensorflow/core/grappler/optimizers/data/graph_utils.h",
    "query": "What is the inheritance hierarchy of the AddScalarConstNode function templates?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'AddScalarConstNode', 'node_id': 'AddScalarConstNode', 'description': 'Base template function for adding const nodes', 'visibility': 'public', 'return_type': 'NodeDef*', 'params': 'T v, MutableGraphView* graph', 'source_class_id': None}, {'type': 'function', 'name': 'AddScalarConstNode', 'node_id': 'AddScalarConstNode_bool', 'description': 'Specialization for boolean values', 'visibility': 'public', 'return_type': 'NodeDef*', 'params': 'bool v, MutableGraphView* graph', 'source_class_id': None}, {'type': 'function', 'name': 'AddScalarConstNode', 'node_id': 'AddScalarConstNode_double', 'description': 'Specialization for double values', 'visibility': 'public', 'return_type': 'NodeDef*', 'params': 'double v, MutableGraphView* graph', 'source_class_id': None}, {'type': 'function', 'name': 'AddScalarConstNode', 'node_id': 'AddScalarConstNode_float', 'description': 'Specialization for float values', 'visibility': 'public', 'return_type': 'NodeDef*', 'params': 'float v, MutableGraphView* graph', 'source_class_id': None}, {'type': 'function', 'name': 'AddScalarConstNode', 'node_id': 'AddScalarConstNode_int', 'description': 'Specialization for int values', 'visibility': 'public', 'return_type': 'NodeDef*', 'params': 'int v, MutableGraphView* graph', 'source_class_id': None}, {'type': 'function', 'name': 'AddScalarConstNode', 'node_id': 'AddScalarConstNode_int64', 'description': 'Specialization for int64 values', 'visibility': 'public', 'return_type': 'NodeDef*', 'params': 'int64_t v, MutableGraphView* graph', 'source_class_id': None}, {'type': 'function', 'name': 'AddScalarConstNode', 'node_id': 'AddScalarConstNode_string', 'description': 'Specialization for string values', 'visibility': 'public', 'return_type': 'NodeDef*', 'params': 'string_view v, MutableGraphView* graph', 'source_class_id': None}, {'type': 'entity', 'name': 'NodeDef', 'node_id': 'NodeDef', 'description': 'Protocol buffer for node definition', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'MutableGraphView', 'node_id': 'MutableGraphView', 'description': 'Class for graph modification', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'AddScalarConstNode', 'node_id_to': 'AddScalarConstNode_bool', 'description': 'specializes'}, {'node_id_from': 'AddScalarConstNode', 'node_id_to': 'AddScalarConstNode_double', 'description': 'specializes'}, {'node_id_from': 'AddScalarConstNode', 'node_id_to': 'AddScalarConstNode_float', 'description': 'specializes'}, {'node_id_from': 'AddScalarConstNode', 'node_id_to': 'AddScalarConstNode_int', 'description': 'specializes'}, {'node_id_from': 'AddScalarConstNode', 'node_id_to': 'AddScalarConstNode_int64', 'description': 'specializes'}, {'node_id_from': 'AddScalarConstNode', 'node_id_to': 'AddScalarConstNode_string', 'description': 'specializes'}, {'node_id_from': 'AddScalarConstNode', 'node_id_to': 'NodeDef', 'description': 'returns'}, {'node_id_from': 'AddScalarConstNode', 'node_id_to': 'MutableGraphView', 'description': 'uses'}], 'packages': [{'package_id': 'templateSpecializations', 'children': ['AddScalarConstNode', 'AddScalarConstNode_bool', 'AddScalarConstNode_double', 'AddScalarConstNode_float', 'AddScalarConstNode_int', 'AddScalarConstNode_int64', 'AddScalarConstNode_string'], 'description': 'Template function and its specializations'}, {'package_id': 'dependencies', 'children': ['NodeDef', 'MutableGraphView'], 'description': 'External dependencies'}]}",
    "version": "full",
    "text_answer": "AddScalarConstNode is a template function with specializations for bool, double, float, int, int64_t, and string_view types. The base template is undefined and will cause a compile-time error if instantiated with unsupported types.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Scala",
    "code": "\npackage dotty.tools\npackage dotc\npackage reporting\n\nimport scala.language.unsafeNulls\n\nimport java.lang.System.{lineSeparator => EOL}\n\nimport core.Contexts.*\nimport core.Decorators.*\nimport printing.Highlighting.{Blue, Red, Yellow}\nimport printing.SyntaxHighlighting\nimport Diagnostic.*\nimport util.{ SourcePosition, NoSourcePosition }\nimport util.Chars.{ LF, CR, FF, SU }\nimport scala.annotation.switch\n\nimport scala.collection.mutable.StringBuilder\n\ntrait MessageRendering {\n  import Highlight.*\n  import Offsets.*\n\n  /** Remove ANSI coloring from `str`, useful for getting real length of\n    * strings\n    *\n    * @return string stripped of ANSI escape codes\n    */\n  def stripColor(str: String): String =\n    str.replaceAll(\"\\u001b\\\\[.*?m\", \"\")\n\n  /** List of all the inline calls that surround the position */\n  def inlinePosStack(pos: SourcePosition): List[SourcePosition] =\n    if pos.outer != null && pos.outer.exists then pos :: inlinePosStack(pos.outer)\n    else Nil\n\n  /** Get the sourcelines before and after the position, as well as the offset\n    * for rendering line numbers\n    *\n    * @return (lines before error, lines after error, line numbers offset)\n    */\n  private def sourceLines(pos: SourcePosition)(using Context, Level, Offset): (List[String], List[String], Int) = {\n    assert(pos.exists && pos.source.file.exists)\n    var maxLen = Int.MinValue\n    def render(offsetAndLine: (Int, String)): String = {\n      val (offset1, line) = offsetAndLine\n      val lineNbr = (pos.source.offsetToLine(offset1) + 1).toString\n      val prefix = String.format(s\"%${offset - 2}s |\", lineNbr)\n      maxLen = math.max(maxLen, prefix.length)\n      val lnum = hl(\" \" * math.max(0, maxLen - prefix.length - 1) + prefix)\n      lnum + line.stripLineEnd\n    }\n\n    def linesFrom(arr: Array[Char]): List[String] = {\n      def pred(c: Char) = (c: @switch) match {\n        case LF | CR | FF | SU => true\n        case _ => false\n      }\n      val (line, rest0) = arr.span(!pred(_))\n      val (_, rest) = rest0.span(pred)\n      new String(line) :: { if (rest.isEmpty) Nil else linesFrom(rest) }\n    }\n\n    val syntax =\n      if (ctx.settings.color.value != \"never\")\n        SyntaxHighlighting.highlight(new String(pos.linesSlice)).toCharArray\n      else pos.linesSlice\n    val lines = linesFrom(syntax)\n    val (before, after) = pos.beforeAndAfterPoint\n\n    (\n      before.zip(lines).map(render),\n      after.zip(lines.drop(before.length)).map(render),\n      maxLen\n    )\n  }\n\n  /** Generate box containing the report title\n   *\n   *  ```\n   *  -- Error: source.scala ---------------------\n   *  ```\n   */\n  private def boxTitle(title: String)(using Context, Level, Offset): String =\n    val pageWidth = ctx.settings.pageWidth.value\n    val line = \"-\" * (pageWidth - title.length - 4)\n    hl(s\"-- $title $line\")\n\n  /** The position markers aligned under the error\n   *\n   *  ```\n   *    |         ^^^^^\n   *  ```\n   */\n  private def positionMarker(pos: SourcePosition)(using Context, Level, Offset): String = {\n    val padding = pos.startColumnPadding\n    val carets =\n      if (pos.startLine == pos.endLine)\n        \"^\" * math.max(1, pos.endColumn - pos.startColumn)\n      else \"^\"\n    hl(s\"$offsetBox$padding$carets\")\n  }\n\n  /** The horizontal line with the given offset\n   *\n   *  ```\n   *    |\n   *  ```\n   */\n  private def offsetBox(using Context, Level, Offset): String =\n    val prefix = \" \" * (offset - 1)\n    hl(s\"$prefix|\")\n\n  /** The end of a box section\n   *\n   *  ```\n   *    |---------------\n   *  ```\n   *  Or if there `soft` is true,\n   *  ```\n   *    |- - - - - - - -\n   *  ```\n   */\n  private def newBox(soft: Boolean = false)(using Context, Level, Offset): String =\n    val pageWidth = ctx.settings.pageWidth.value\n    val prefix = \" \" * (offset - 1)\n    val lineWidth = (pageWidth - offset)\n    val line = if soft then (\"- \" * ((lineWidth + 1) / 2)).trim else \"-\" * lineWidth\n    hl(s\"$prefix|$line\")\n\n  /** The end of a box section\n   *\n   *  ```\n   *     ----------------\n   *  ```\n   */\n  private def endBox(using Context, Level, Offset): String =\n    val pageWidth = ctx.settings.pageWidth.value\n    val prefix = \" \" * (offset - 1)\n    val line = \"-\" * (pageWidth - offset)\n    hl(s\"${prefix} $line\")\n\n  /** The error message (`msg`) aligned under `pos`\n    *\n    * @return aligned error message\n    */\n  private def errorMsg(pos: SourcePosition, msg: String)(using Context, Level, Offset): String = {\n    val padding = msg.linesIterator.foldLeft(pos.startColumnPadding) { (pad, line) =>\n      val lineLength = stripColor(line).length\n      val maxPad = math.max(0, ctx.settings.pageWidth.value - offset - lineLength) - offset\n\n      if (maxPad < pad.length) \" \" * maxPad\n      else pad\n    }\n\n    msg.linesIterator\n      .map { line => offsetBox + (if line.isEmpty then \"\" else padding + line) }\n      .mkString(EOL)\n  }\n\n  /** The source file path, line and column numbers from the given SourcePosition */\n  protected def posFileStr(pos: SourcePosition): String =\n    val path = pos.source.file.path\n    if pos.exists then s\"$path:${pos.line + 1}:${pos.column}\" else path\n\n  /** The separator between errors containing the source file and error type\n    *\n    * @return separator containing error location and kind\n    */\n  private def posStr(\n    pos: SourcePosition,\n    message: Message,\n    diagnosticString: String\n  )(using Context, Level, Offset): String =\n    assert(\n      message.errorId.isActive,\n      \"\"\"|Attempting to use an ErrorMessageID that is marked as inactive.\n         |The ID either needs to be marked as active or you need to use another.\"\"\".stripMargin\n    )\n    if (pos.source != NoSourcePosition.source) then\n      hl({\n        val realPos = pos.nonInlined\n        val fileAndPos = posFileStr(realPos)\n        val errId =\n          if (message.errorId != ErrorMessageID.NoExplanationID) then\n            val errorNumber = message.errorId.errorNumber\n            s\"[E${\"0\" * (3 - errorNumber.toString.length) + errorNumber}] \"\n          else \"\"\n        val kind =\n          if (message.kind == MessageKind.NoKind) then diagnosticString\n          else s\"${message.kind.message} $diagnosticString\"\n        val title =\n          if fileAndPos.isEmpty then s\"$errId$kind:\" // this happens in dotty.tools.repl.ScriptedTests // TODO add name of source or remove `:` (and update test files)\n          else s\"$errId$kind: $fileAndPos\"\n        boxTitle(title)\n      })\n    else \"\"\n  end posStr\n\n  /** Explanation rendered under \"Explanation\" header */\n  def explanation(m: Message)(using Context): String = {\n    val sb = new StringBuilder(\n      s\"\"\"|\n          |${Blue(\"Explanation\").show}\n          |${Blue(\"===========\").show}\"\"\".stripMargin\n    )\n    sb.append(EOL).append(m.explanation)\n    if (!m.explanation.endsWith(EOL)) sb.append(EOL)\n    sb.toString\n  }\n\n  private def appendFilterHelp(dia: Diagnostic, sb: StringBuilder)(using Context, Level, Offset): Unit =\n    extension (sb: StringBuilder) def nl: sb.type = sb.append(EOL).append(offsetBox)\n    import dia.msg\n    val hasId = msg.errorId.errorNumber >= 0\n    val (category, origin) = dia match\n      case _: UncheckedWarning   => (\"unchecked\", \"\")\n      case w: DeprecationWarning => (\"deprecation\", w.origin)\n      case _: FeatureWarning     => (\"feature\", \"\")\n      case _                     => (\"\", \"\")\n    var entitled = false\n    def addHelp(what: String)(value: String): Unit =\n      if !entitled then\n        sb.nl.append(\"Matching filters for @nowarn or -Wconf:\")\n        entitled = true\n      sb.nl.append(\"  - \").append(what).append(value)\n    if hasId then\n      addHelp(\"id=E\")(msg.errorId.errorNumber.toString)\n      addHelp(\"name=\")(msg.errorId.productPrefix.stripSuffix(\"ID\"))\n    if category.nonEmpty then\n      addHelp(\"cat=\")(category)\n    if origin.nonEmpty then\n      addHelp(\"origin=\")(origin)\n\n  /** The whole message rendered from `msg` */\n  def messageAndPos(dia: Diagnostic)(using Context): String = {\n    import dia.*\n    val pos1 = pos.nonInlined\n    val inlineStack = inlinePosStack(pos).filter(_ != pos1)\n    val maxLineNumber =\n      if pos.exists then (pos1 :: inlineStack).map(_.endLine).max + 1\n      else 0\n    given Level = Level(level)\n    given Offset = Offset(maxLineNumber.toString.length + 2)\n    val sb = StringBuilder()\n    val posString = posStr(pos, msg, diagnosticLevel(dia))\n    if (posString.nonEmpty) sb.append(posString).append(EOL)\n    if (pos.exists) {\n      val pos1 = pos.nonInlined\n      if (pos1.exists && pos1.source.file.exists) {\n        val (srcBefore, srcAfter, offset) = sourceLines(pos1)\n        val marker = positionMarker(pos1)\n        val err = errorMsg(pos1, msg.message)\n        sb.append((srcBefore ::: marker :: err :: srcAfter).mkString(EOL))\n\n        if inlineStack.nonEmpty then\n          sb.append(EOL).append(newBox())\n          sb.append(EOL).append(offsetBox).append(i\"Inline stack trace\")\n          for inlinedPos <- inlineStack if inlinedPos != pos1 do\n            sb.append(EOL).append(newBox(soft = true))\n            sb.append(EOL).append(offsetBox).append(i\"This location contains code that was inlined from $pos\")\n            if inlinedPos.source.file.exists then\n              val (srcBefore, srcAfter, _) = sourceLines(inlinedPos)\n              val marker = positionMarker(inlinedPos)\n              sb.append(EOL).append((srcBefore ::: marker :: srcAfter).mkString(EOL))\n          sb.append(EOL).append(endBox)\n      }\n      else sb.append(msg.message)\n    }\n    else sb.append(msg.message)\n    if (dia.isVerbose)\n      appendFilterHelp(dia, sb)\n\n    if Diagnostic.shouldExplain(dia) then\n      sb.append(EOL).append(newBox())\n      sb.append(EOL).append(offsetBox).append(\" Explanation (enabled by `-explain`)\")\n      sb.append(EOL).append(newBox(soft = true))\n      dia.msg.explanation.split(raw\"\\R\").foreach { line =>\n        sb.append(EOL).append(offsetBox).append(if line.isEmpty then \"\" else \" \").append(line)\n      }\n      sb.append(EOL).append(endBox)\n    else if dia.msg.canExplain then\n      sb.append(EOL).append(offsetBox)\n      sb.append(EOL).append(offsetBox).append(\" longer explanation available when compiling with `-explain`\")\n\n    sb.toString\n  }\n\n  private  def hl(str: String)(using Context, Level): String =\n    summon[Level].value match\n      case interfaces.Diagnostic.ERROR   => Red(str).show\n      case interfaces.Diagnostic.WARNING => Yellow(str).show\n      case interfaces.Diagnostic.INFO    => Blue(str).show\n\n  private def diagnosticLevel(dia: Diagnostic): String =\n    dia match {\n      case dia: FeatureWarning => \"Feature Warning\"\n      case dia: DeprecationWarning => \"Deprecation Warning\"\n      case dia: UncheckedWarning => \"Unchecked Warning\"\n      case dia: MigrationWarning => \"Migration Warning\"\n      case _ => dia.level match // Diagnostic isn't sealed (e.g. created in the REPL) so provide a fallback\n        case interfaces.Diagnostic.ERROR   => \"Error\"\n        case interfaces.Diagnostic.WARNING => \"Warning\"\n        case interfaces.Diagnostic.INFO    => \"Info\"\n    }\n\n}\n\nprivate object Highlight {\n  opaque type Level = Int\n  extension (level: Level) def value: Int = level\n  object Level:\n    def apply(level: Int): Level = level\n}\n\n/** Size of the left offset added by the box\n *\n *  ```\n *  -- Error: ... ------------\n *  4 |  foo\n *    |  ^^^\n *  ^^^ // size of this offset\n *  ```\n */\nprivate object Offsets {\n  opaque type Offset = Int\n  def offset(using o: Offset): Int = o\n  object Offset:\n    def apply(level: Int): Offset = level\n}",
    "repo": "lampepfl/dotty",
    "path": "./datasets/diagrams-repos/lampepfl/dotty/compiler/src/dotty/tools/dotc/reporting/MessageRendering.scala",
    "query": "What is the process for formatting error messages with boxes and lines?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'MessageRendering', 'node_id': 'MessageRendering', 'description': 'Main trait responsible for rendering error messages with formatting', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'messageAndPos', 'node_id': 'messageAndPos', 'description': 'Main method that renders complete error message with position and formatting', 'visibility': 'public', 'return_type': 'String', 'params': 'dia: Diagnostic', 'source_class_id': 'MessageRendering'}, {'type': 'method', 'name': 'boxTitle', 'node_id': 'boxTitle', 'description': 'Generates box containing error title', 'visibility': 'private', 'return_type': 'String', 'params': 'title: String', 'source_class_id': 'MessageRendering'}, {'type': 'method', 'name': 'positionMarker', 'node_id': 'positionMarker', 'description': 'Creates position markers (carets) under the error', 'visibility': 'private', 'return_type': 'String', 'params': 'pos: SourcePosition', 'source_class_id': 'MessageRendering'}], 'edges': [{'node_id_from': 'messageAndPos', 'node_id_to': 'boxTitle', 'description': 'calls to create title box'}, {'node_id_from': 'messageAndPos', 'node_id_to': 'positionMarker', 'description': 'calls to mark error position'}, {'node_id_from': 'MessageRendering', 'node_id_to': 'messageAndPos', 'description': ''}, {'node_id_from': 'MessageRendering', 'node_id_to': 'boxTitle', 'description': ''}, {'node_id_from': 'MessageRendering', 'node_id_to': 'positionMarker', 'description': ''}], 'packages': [{'package_id': 'errorFormatting', 'children': ['MessageRendering', 'messageAndPos', 'boxTitle', 'positionMarker'], 'description': 'Core error message formatting functionality'}]}",
    "version": "minimal",
    "text_answer": "Error messages are formatted using a box-style layout where messageAndPos orchestrates the process by combining a title box, source code context with position markers (carets), aligned error messages, and optional explanations. The formatting includes visual elements like borders and highlighting based on the diagnostic level.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Scala",
    "code": "\npackage dotty.tools\npackage dotc\npackage reporting\n\nimport scala.language.unsafeNulls\n\nimport java.lang.System.{lineSeparator => EOL}\n\nimport core.Contexts.*\nimport core.Decorators.*\nimport printing.Highlighting.{Blue, Red, Yellow}\nimport printing.SyntaxHighlighting\nimport Diagnostic.*\nimport util.{ SourcePosition, NoSourcePosition }\nimport util.Chars.{ LF, CR, FF, SU }\nimport scala.annotation.switch\n\nimport scala.collection.mutable.StringBuilder\n\ntrait MessageRendering {\n  import Highlight.*\n  import Offsets.*\n\n  /** Remove ANSI coloring from `str`, useful for getting real length of\n    * strings\n    *\n    * @return string stripped of ANSI escape codes\n    */\n  def stripColor(str: String): String =\n    str.replaceAll(\"\\u001b\\\\[.*?m\", \"\")\n\n  /** List of all the inline calls that surround the position */\n  def inlinePosStack(pos: SourcePosition): List[SourcePosition] =\n    if pos.outer != null && pos.outer.exists then pos :: inlinePosStack(pos.outer)\n    else Nil\n\n  /** Get the sourcelines before and after the position, as well as the offset\n    * for rendering line numbers\n    *\n    * @return (lines before error, lines after error, line numbers offset)\n    */\n  private def sourceLines(pos: SourcePosition)(using Context, Level, Offset): (List[String], List[String], Int) = {\n    assert(pos.exists && pos.source.file.exists)\n    var maxLen = Int.MinValue\n    def render(offsetAndLine: (Int, String)): String = {\n      val (offset1, line) = offsetAndLine\n      val lineNbr = (pos.source.offsetToLine(offset1) + 1).toString\n      val prefix = String.format(s\"%${offset - 2}s |\", lineNbr)\n      maxLen = math.max(maxLen, prefix.length)\n      val lnum = hl(\" \" * math.max(0, maxLen - prefix.length - 1) + prefix)\n      lnum + line.stripLineEnd\n    }\n\n    def linesFrom(arr: Array[Char]): List[String] = {\n      def pred(c: Char) = (c: @switch) match {\n        case LF | CR | FF | SU => true\n        case _ => false\n      }\n      val (line, rest0) = arr.span(!pred(_))\n      val (_, rest) = rest0.span(pred)\n      new String(line) :: { if (rest.isEmpty) Nil else linesFrom(rest) }\n    }\n\n    val syntax =\n      if (ctx.settings.color.value != \"never\")\n        SyntaxHighlighting.highlight(new String(pos.linesSlice)).toCharArray\n      else pos.linesSlice\n    val lines = linesFrom(syntax)\n    val (before, after) = pos.beforeAndAfterPoint\n\n    (\n      before.zip(lines).map(render),\n      after.zip(lines.drop(before.length)).map(render),\n      maxLen\n    )\n  }\n\n  /** Generate box containing the report title\n   *\n   *  ```\n   *  -- Error: source.scala ---------------------\n   *  ```\n   */\n  private def boxTitle(title: String)(using Context, Level, Offset): String =\n    val pageWidth = ctx.settings.pageWidth.value\n    val line = \"-\" * (pageWidth - title.length - 4)\n    hl(s\"-- $title $line\")\n\n  /** The position markers aligned under the error\n   *\n   *  ```\n   *    |         ^^^^^\n   *  ```\n   */\n  private def positionMarker(pos: SourcePosition)(using Context, Level, Offset): String = {\n    val padding = pos.startColumnPadding\n    val carets =\n      if (pos.startLine == pos.endLine)\n        \"^\" * math.max(1, pos.endColumn - pos.startColumn)\n      else \"^\"\n    hl(s\"$offsetBox$padding$carets\")\n  }\n\n  /** The horizontal line with the given offset\n   *\n   *  ```\n   *    |\n   *  ```\n   */\n  private def offsetBox(using Context, Level, Offset): String =\n    val prefix = \" \" * (offset - 1)\n    hl(s\"$prefix|\")\n\n  /** The end of a box section\n   *\n   *  ```\n   *    |---------------\n   *  ```\n   *  Or if there `soft` is true,\n   *  ```\n   *    |- - - - - - - -\n   *  ```\n   */\n  private def newBox(soft: Boolean = false)(using Context, Level, Offset): String =\n    val pageWidth = ctx.settings.pageWidth.value\n    val prefix = \" \" * (offset - 1)\n    val lineWidth = (pageWidth - offset)\n    val line = if soft then (\"- \" * ((lineWidth + 1) / 2)).trim else \"-\" * lineWidth\n    hl(s\"$prefix|$line\")\n\n  /** The end of a box section\n   *\n   *  ```\n   *     ----------------\n   *  ```\n   */\n  private def endBox(using Context, Level, Offset): String =\n    val pageWidth = ctx.settings.pageWidth.value\n    val prefix = \" \" * (offset - 1)\n    val line = \"-\" * (pageWidth - offset)\n    hl(s\"${prefix} $line\")\n\n  /** The error message (`msg`) aligned under `pos`\n    *\n    * @return aligned error message\n    */\n  private def errorMsg(pos: SourcePosition, msg: String)(using Context, Level, Offset): String = {\n    val padding = msg.linesIterator.foldLeft(pos.startColumnPadding) { (pad, line) =>\n      val lineLength = stripColor(line).length\n      val maxPad = math.max(0, ctx.settings.pageWidth.value - offset - lineLength) - offset\n\n      if (maxPad < pad.length) \" \" * maxPad\n      else pad\n    }\n\n    msg.linesIterator\n      .map { line => offsetBox + (if line.isEmpty then \"\" else padding + line) }\n      .mkString(EOL)\n  }\n\n  /** The source file path, line and column numbers from the given SourcePosition */\n  protected def posFileStr(pos: SourcePosition): String =\n    val path = pos.source.file.path\n    if pos.exists then s\"$path:${pos.line + 1}:${pos.column}\" else path\n\n  /** The separator between errors containing the source file and error type\n    *\n    * @return separator containing error location and kind\n    */\n  private def posStr(\n    pos: SourcePosition,\n    message: Message,\n    diagnosticString: String\n  )(using Context, Level, Offset): String =\n    assert(\n      message.errorId.isActive,\n      \"\"\"|Attempting to use an ErrorMessageID that is marked as inactive.\n         |The ID either needs to be marked as active or you need to use another.\"\"\".stripMargin\n    )\n    if (pos.source != NoSourcePosition.source) then\n      hl({\n        val realPos = pos.nonInlined\n        val fileAndPos = posFileStr(realPos)\n        val errId =\n          if (message.errorId != ErrorMessageID.NoExplanationID) then\n            val errorNumber = message.errorId.errorNumber\n            s\"[E${\"0\" * (3 - errorNumber.toString.length) + errorNumber}] \"\n          else \"\"\n        val kind =\n          if (message.kind == MessageKind.NoKind) then diagnosticString\n          else s\"${message.kind.message} $diagnosticString\"\n        val title =\n          if fileAndPos.isEmpty then s\"$errId$kind:\" // this happens in dotty.tools.repl.ScriptedTests // TODO add name of source or remove `:` (and update test files)\n          else s\"$errId$kind: $fileAndPos\"\n        boxTitle(title)\n      })\n    else \"\"\n  end posStr\n\n  /** Explanation rendered under \"Explanation\" header */\n  def explanation(m: Message)(using Context): String = {\n    val sb = new StringBuilder(\n      s\"\"\"|\n          |${Blue(\"Explanation\").show}\n          |${Blue(\"===========\").show}\"\"\".stripMargin\n    )\n    sb.append(EOL).append(m.explanation)\n    if (!m.explanation.endsWith(EOL)) sb.append(EOL)\n    sb.toString\n  }\n\n  private def appendFilterHelp(dia: Diagnostic, sb: StringBuilder)(using Context, Level, Offset): Unit =\n    extension (sb: StringBuilder) def nl: sb.type = sb.append(EOL).append(offsetBox)\n    import dia.msg\n    val hasId = msg.errorId.errorNumber >= 0\n    val (category, origin) = dia match\n      case _: UncheckedWarning   => (\"unchecked\", \"\")\n      case w: DeprecationWarning => (\"deprecation\", w.origin)\n      case _: FeatureWarning     => (\"feature\", \"\")\n      case _                     => (\"\", \"\")\n    var entitled = false\n    def addHelp(what: String)(value: String): Unit =\n      if !entitled then\n        sb.nl.append(\"Matching filters for @nowarn or -Wconf:\")\n        entitled = true\n      sb.nl.append(\"  - \").append(what).append(value)\n    if hasId then\n      addHelp(\"id=E\")(msg.errorId.errorNumber.toString)\n      addHelp(\"name=\")(msg.errorId.productPrefix.stripSuffix(\"ID\"))\n    if category.nonEmpty then\n      addHelp(\"cat=\")(category)\n    if origin.nonEmpty then\n      addHelp(\"origin=\")(origin)\n\n  /** The whole message rendered from `msg` */\n  def messageAndPos(dia: Diagnostic)(using Context): String = {\n    import dia.*\n    val pos1 = pos.nonInlined\n    val inlineStack = inlinePosStack(pos).filter(_ != pos1)\n    val maxLineNumber =\n      if pos.exists then (pos1 :: inlineStack).map(_.endLine).max + 1\n      else 0\n    given Level = Level(level)\n    given Offset = Offset(maxLineNumber.toString.length + 2)\n    val sb = StringBuilder()\n    val posString = posStr(pos, msg, diagnosticLevel(dia))\n    if (posString.nonEmpty) sb.append(posString).append(EOL)\n    if (pos.exists) {\n      val pos1 = pos.nonInlined\n      if (pos1.exists && pos1.source.file.exists) {\n        val (srcBefore, srcAfter, offset) = sourceLines(pos1)\n        val marker = positionMarker(pos1)\n        val err = errorMsg(pos1, msg.message)\n        sb.append((srcBefore ::: marker :: err :: srcAfter).mkString(EOL))\n\n        if inlineStack.nonEmpty then\n          sb.append(EOL).append(newBox())\n          sb.append(EOL).append(offsetBox).append(i\"Inline stack trace\")\n          for inlinedPos <- inlineStack if inlinedPos != pos1 do\n            sb.append(EOL).append(newBox(soft = true))\n            sb.append(EOL).append(offsetBox).append(i\"This location contains code that was inlined from $pos\")\n            if inlinedPos.source.file.exists then\n              val (srcBefore, srcAfter, _) = sourceLines(inlinedPos)\n              val marker = positionMarker(inlinedPos)\n              sb.append(EOL).append((srcBefore ::: marker :: srcAfter).mkString(EOL))\n          sb.append(EOL).append(endBox)\n      }\n      else sb.append(msg.message)\n    }\n    else sb.append(msg.message)\n    if (dia.isVerbose)\n      appendFilterHelp(dia, sb)\n\n    if Diagnostic.shouldExplain(dia) then\n      sb.append(EOL).append(newBox())\n      sb.append(EOL).append(offsetBox).append(\" Explanation (enabled by `-explain`)\")\n      sb.append(EOL).append(newBox(soft = true))\n      dia.msg.explanation.split(raw\"\\R\").foreach { line =>\n        sb.append(EOL).append(offsetBox).append(if line.isEmpty then \"\" else \" \").append(line)\n      }\n      sb.append(EOL).append(endBox)\n    else if dia.msg.canExplain then\n      sb.append(EOL).append(offsetBox)\n      sb.append(EOL).append(offsetBox).append(\" longer explanation available when compiling with `-explain`\")\n\n    sb.toString\n  }\n\n  private  def hl(str: String)(using Context, Level): String =\n    summon[Level].value match\n      case interfaces.Diagnostic.ERROR   => Red(str).show\n      case interfaces.Diagnostic.WARNING => Yellow(str).show\n      case interfaces.Diagnostic.INFO    => Blue(str).show\n\n  private def diagnosticLevel(dia: Diagnostic): String =\n    dia match {\n      case dia: FeatureWarning => \"Feature Warning\"\n      case dia: DeprecationWarning => \"Deprecation Warning\"\n      case dia: UncheckedWarning => \"Unchecked Warning\"\n      case dia: MigrationWarning => \"Migration Warning\"\n      case _ => dia.level match // Diagnostic isn't sealed (e.g. created in the REPL) so provide a fallback\n        case interfaces.Diagnostic.ERROR   => \"Error\"\n        case interfaces.Diagnostic.WARNING => \"Warning\"\n        case interfaces.Diagnostic.INFO    => \"Info\"\n    }\n\n}\n\nprivate object Highlight {\n  opaque type Level = Int\n  extension (level: Level) def value: Int = level\n  object Level:\n    def apply(level: Int): Level = level\n}\n\n/** Size of the left offset added by the box\n *\n *  ```\n *  -- Error: ... ------------\n *  4 |  foo\n *    |  ^^^\n *  ^^^ // size of this offset\n *  ```\n */\nprivate object Offsets {\n  opaque type Offset = Int\n  def offset(using o: Offset): Int = o\n  object Offset:\n    def apply(level: Int): Offset = level\n}",
    "repo": "lampepfl/dotty",
    "path": "./datasets/diagrams-repos/lampepfl/dotty/compiler/src/dotty/tools/dotc/reporting/MessageRendering.scala",
    "query": "What is the process for formatting error messages with boxes and lines?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'MessageRendering', 'node_id': 'MessageRendering', 'description': 'Main trait responsible for rendering error messages with formatting', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'messageAndPos', 'node_id': 'messageAndPos', 'description': 'Main method that renders complete error message with position and formatting', 'visibility': 'public', 'return_type': 'String', 'params': 'dia: Diagnostic', 'source_class_id': 'MessageRendering'}, {'type': 'method', 'name': 'boxTitle', 'node_id': 'boxTitle', 'description': 'Generates box containing error title', 'visibility': 'private', 'return_type': 'String', 'params': 'title: String', 'source_class_id': 'MessageRendering'}, {'type': 'method', 'name': 'positionMarker', 'node_id': 'positionMarker', 'description': 'Creates position markers (carets) under the error', 'visibility': 'private', 'return_type': 'String', 'params': 'pos: SourcePosition', 'source_class_id': 'MessageRendering'}, {'type': 'method', 'name': 'sourceLines', 'node_id': 'sourceLines', 'description': 'Gets source lines before and after error position', 'visibility': 'private', 'return_type': '(List[String], List[String], Int)', 'params': 'pos: SourcePosition', 'source_class_id': 'MessageRendering'}, {'type': 'method', 'name': 'errorMsg', 'node_id': 'errorMsg', 'description': 'Aligns error message under position', 'visibility': 'private', 'return_type': 'String', 'params': 'pos: SourcePosition, msg: String', 'source_class_id': 'MessageRendering'}, {'type': 'method', 'name': 'newBox', 'node_id': 'newBox', 'description': 'Creates box section separator', 'visibility': 'private', 'return_type': 'String', 'params': 'soft: Boolean', 'source_class_id': 'MessageRendering'}], 'edges': [{'node_id_from': 'messageAndPos', 'node_id_to': 'boxTitle', 'description': 'calls to create title box'}, {'node_id_from': 'messageAndPos', 'node_id_to': 'sourceLines', 'description': 'gets source code context'}, {'node_id_from': 'messageAndPos', 'node_id_to': 'positionMarker', 'description': 'calls to mark error position'}, {'node_id_from': 'messageAndPos', 'node_id_to': 'errorMsg', 'description': 'formats error message'}, {'node_id_from': 'messageAndPos', 'node_id_to': 'newBox', 'description': 'adds box separators'}, {'node_id_from': 'MessageRendering', 'node_id_to': 'messageAndPos', 'description': ''}, {'node_id_from': 'MessageRendering', 'node_id_to': 'boxTitle', 'description': ''}, {'node_id_from': 'MessageRendering', 'node_id_to': 'positionMarker', 'description': ''}, {'node_id_from': 'MessageRendering', 'node_id_to': 'sourceLines', 'description': ''}, {'node_id_from': 'MessageRendering', 'node_id_to': 'errorMsg', 'description': ''}, {'node_id_from': 'MessageRendering', 'node_id_to': 'newBox', 'description': ''}], 'packages': [{'package_id': 'errorFormatting', 'children': ['MessageRendering', 'messageAndPos', 'boxTitle', 'positionMarker', 'sourceLines', 'errorMsg', 'newBox'], 'description': 'Core error message formatting functionality'}]}",
    "version": "medium",
    "text_answer": "Error messages are formatted using a box-style layout where messageAndPos orchestrates the process by combining a title box, source code context with position markers (carets), aligned error messages, and optional explanations. The formatting includes visual elements like borders and highlighting based on the diagnostic level.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Scala",
    "code": "\npackage dotty.tools\npackage dotc\npackage reporting\n\nimport scala.language.unsafeNulls\n\nimport java.lang.System.{lineSeparator => EOL}\n\nimport core.Contexts.*\nimport core.Decorators.*\nimport printing.Highlighting.{Blue, Red, Yellow}\nimport printing.SyntaxHighlighting\nimport Diagnostic.*\nimport util.{ SourcePosition, NoSourcePosition }\nimport util.Chars.{ LF, CR, FF, SU }\nimport scala.annotation.switch\n\nimport scala.collection.mutable.StringBuilder\n\ntrait MessageRendering {\n  import Highlight.*\n  import Offsets.*\n\n  /** Remove ANSI coloring from `str`, useful for getting real length of\n    * strings\n    *\n    * @return string stripped of ANSI escape codes\n    */\n  def stripColor(str: String): String =\n    str.replaceAll(\"\\u001b\\\\[.*?m\", \"\")\n\n  /** List of all the inline calls that surround the position */\n  def inlinePosStack(pos: SourcePosition): List[SourcePosition] =\n    if pos.outer != null && pos.outer.exists then pos :: inlinePosStack(pos.outer)\n    else Nil\n\n  /** Get the sourcelines before and after the position, as well as the offset\n    * for rendering line numbers\n    *\n    * @return (lines before error, lines after error, line numbers offset)\n    */\n  private def sourceLines(pos: SourcePosition)(using Context, Level, Offset): (List[String], List[String], Int) = {\n    assert(pos.exists && pos.source.file.exists)\n    var maxLen = Int.MinValue\n    def render(offsetAndLine: (Int, String)): String = {\n      val (offset1, line) = offsetAndLine\n      val lineNbr = (pos.source.offsetToLine(offset1) + 1).toString\n      val prefix = String.format(s\"%${offset - 2}s |\", lineNbr)\n      maxLen = math.max(maxLen, prefix.length)\n      val lnum = hl(\" \" * math.max(0, maxLen - prefix.length - 1) + prefix)\n      lnum + line.stripLineEnd\n    }\n\n    def linesFrom(arr: Array[Char]): List[String] = {\n      def pred(c: Char) = (c: @switch) match {\n        case LF | CR | FF | SU => true\n        case _ => false\n      }\n      val (line, rest0) = arr.span(!pred(_))\n      val (_, rest) = rest0.span(pred)\n      new String(line) :: { if (rest.isEmpty) Nil else linesFrom(rest) }\n    }\n\n    val syntax =\n      if (ctx.settings.color.value != \"never\")\n        SyntaxHighlighting.highlight(new String(pos.linesSlice)).toCharArray\n      else pos.linesSlice\n    val lines = linesFrom(syntax)\n    val (before, after) = pos.beforeAndAfterPoint\n\n    (\n      before.zip(lines).map(render),\n      after.zip(lines.drop(before.length)).map(render),\n      maxLen\n    )\n  }\n\n  /** Generate box containing the report title\n   *\n   *  ```\n   *  -- Error: source.scala ---------------------\n   *  ```\n   */\n  private def boxTitle(title: String)(using Context, Level, Offset): String =\n    val pageWidth = ctx.settings.pageWidth.value\n    val line = \"-\" * (pageWidth - title.length - 4)\n    hl(s\"-- $title $line\")\n\n  /** The position markers aligned under the error\n   *\n   *  ```\n   *    |         ^^^^^\n   *  ```\n   */\n  private def positionMarker(pos: SourcePosition)(using Context, Level, Offset): String = {\n    val padding = pos.startColumnPadding\n    val carets =\n      if (pos.startLine == pos.endLine)\n        \"^\" * math.max(1, pos.endColumn - pos.startColumn)\n      else \"^\"\n    hl(s\"$offsetBox$padding$carets\")\n  }\n\n  /** The horizontal line with the given offset\n   *\n   *  ```\n   *    |\n   *  ```\n   */\n  private def offsetBox(using Context, Level, Offset): String =\n    val prefix = \" \" * (offset - 1)\n    hl(s\"$prefix|\")\n\n  /** The end of a box section\n   *\n   *  ```\n   *    |---------------\n   *  ```\n   *  Or if there `soft` is true,\n   *  ```\n   *    |- - - - - - - -\n   *  ```\n   */\n  private def newBox(soft: Boolean = false)(using Context, Level, Offset): String =\n    val pageWidth = ctx.settings.pageWidth.value\n    val prefix = \" \" * (offset - 1)\n    val lineWidth = (pageWidth - offset)\n    val line = if soft then (\"- \" * ((lineWidth + 1) / 2)).trim else \"-\" * lineWidth\n    hl(s\"$prefix|$line\")\n\n  /** The end of a box section\n   *\n   *  ```\n   *     ----------------\n   *  ```\n   */\n  private def endBox(using Context, Level, Offset): String =\n    val pageWidth = ctx.settings.pageWidth.value\n    val prefix = \" \" * (offset - 1)\n    val line = \"-\" * (pageWidth - offset)\n    hl(s\"${prefix} $line\")\n\n  /** The error message (`msg`) aligned under `pos`\n    *\n    * @return aligned error message\n    */\n  private def errorMsg(pos: SourcePosition, msg: String)(using Context, Level, Offset): String = {\n    val padding = msg.linesIterator.foldLeft(pos.startColumnPadding) { (pad, line) =>\n      val lineLength = stripColor(line).length\n      val maxPad = math.max(0, ctx.settings.pageWidth.value - offset - lineLength) - offset\n\n      if (maxPad < pad.length) \" \" * maxPad\n      else pad\n    }\n\n    msg.linesIterator\n      .map { line => offsetBox + (if line.isEmpty then \"\" else padding + line) }\n      .mkString(EOL)\n  }\n\n  /** The source file path, line and column numbers from the given SourcePosition */\n  protected def posFileStr(pos: SourcePosition): String =\n    val path = pos.source.file.path\n    if pos.exists then s\"$path:${pos.line + 1}:${pos.column}\" else path\n\n  /** The separator between errors containing the source file and error type\n    *\n    * @return separator containing error location and kind\n    */\n  private def posStr(\n    pos: SourcePosition,\n    message: Message,\n    diagnosticString: String\n  )(using Context, Level, Offset): String =\n    assert(\n      message.errorId.isActive,\n      \"\"\"|Attempting to use an ErrorMessageID that is marked as inactive.\n         |The ID either needs to be marked as active or you need to use another.\"\"\".stripMargin\n    )\n    if (pos.source != NoSourcePosition.source) then\n      hl({\n        val realPos = pos.nonInlined\n        val fileAndPos = posFileStr(realPos)\n        val errId =\n          if (message.errorId != ErrorMessageID.NoExplanationID) then\n            val errorNumber = message.errorId.errorNumber\n            s\"[E${\"0\" * (3 - errorNumber.toString.length) + errorNumber}] \"\n          else \"\"\n        val kind =\n          if (message.kind == MessageKind.NoKind) then diagnosticString\n          else s\"${message.kind.message} $diagnosticString\"\n        val title =\n          if fileAndPos.isEmpty then s\"$errId$kind:\" // this happens in dotty.tools.repl.ScriptedTests // TODO add name of source or remove `:` (and update test files)\n          else s\"$errId$kind: $fileAndPos\"\n        boxTitle(title)\n      })\n    else \"\"\n  end posStr\n\n  /** Explanation rendered under \"Explanation\" header */\n  def explanation(m: Message)(using Context): String = {\n    val sb = new StringBuilder(\n      s\"\"\"|\n          |${Blue(\"Explanation\").show}\n          |${Blue(\"===========\").show}\"\"\".stripMargin\n    )\n    sb.append(EOL).append(m.explanation)\n    if (!m.explanation.endsWith(EOL)) sb.append(EOL)\n    sb.toString\n  }\n\n  private def appendFilterHelp(dia: Diagnostic, sb: StringBuilder)(using Context, Level, Offset): Unit =\n    extension (sb: StringBuilder) def nl: sb.type = sb.append(EOL).append(offsetBox)\n    import dia.msg\n    val hasId = msg.errorId.errorNumber >= 0\n    val (category, origin) = dia match\n      case _: UncheckedWarning   => (\"unchecked\", \"\")\n      case w: DeprecationWarning => (\"deprecation\", w.origin)\n      case _: FeatureWarning     => (\"feature\", \"\")\n      case _                     => (\"\", \"\")\n    var entitled = false\n    def addHelp(what: String)(value: String): Unit =\n      if !entitled then\n        sb.nl.append(\"Matching filters for @nowarn or -Wconf:\")\n        entitled = true\n      sb.nl.append(\"  - \").append(what).append(value)\n    if hasId then\n      addHelp(\"id=E\")(msg.errorId.errorNumber.toString)\n      addHelp(\"name=\")(msg.errorId.productPrefix.stripSuffix(\"ID\"))\n    if category.nonEmpty then\n      addHelp(\"cat=\")(category)\n    if origin.nonEmpty then\n      addHelp(\"origin=\")(origin)\n\n  /** The whole message rendered from `msg` */\n  def messageAndPos(dia: Diagnostic)(using Context): String = {\n    import dia.*\n    val pos1 = pos.nonInlined\n    val inlineStack = inlinePosStack(pos).filter(_ != pos1)\n    val maxLineNumber =\n      if pos.exists then (pos1 :: inlineStack).map(_.endLine).max + 1\n      else 0\n    given Level = Level(level)\n    given Offset = Offset(maxLineNumber.toString.length + 2)\n    val sb = StringBuilder()\n    val posString = posStr(pos, msg, diagnosticLevel(dia))\n    if (posString.nonEmpty) sb.append(posString).append(EOL)\n    if (pos.exists) {\n      val pos1 = pos.nonInlined\n      if (pos1.exists && pos1.source.file.exists) {\n        val (srcBefore, srcAfter, offset) = sourceLines(pos1)\n        val marker = positionMarker(pos1)\n        val err = errorMsg(pos1, msg.message)\n        sb.append((srcBefore ::: marker :: err :: srcAfter).mkString(EOL))\n\n        if inlineStack.nonEmpty then\n          sb.append(EOL).append(newBox())\n          sb.append(EOL).append(offsetBox).append(i\"Inline stack trace\")\n          for inlinedPos <- inlineStack if inlinedPos != pos1 do\n            sb.append(EOL).append(newBox(soft = true))\n            sb.append(EOL).append(offsetBox).append(i\"This location contains code that was inlined from $pos\")\n            if inlinedPos.source.file.exists then\n              val (srcBefore, srcAfter, _) = sourceLines(inlinedPos)\n              val marker = positionMarker(inlinedPos)\n              sb.append(EOL).append((srcBefore ::: marker :: srcAfter).mkString(EOL))\n          sb.append(EOL).append(endBox)\n      }\n      else sb.append(msg.message)\n    }\n    else sb.append(msg.message)\n    if (dia.isVerbose)\n      appendFilterHelp(dia, sb)\n\n    if Diagnostic.shouldExplain(dia) then\n      sb.append(EOL).append(newBox())\n      sb.append(EOL).append(offsetBox).append(\" Explanation (enabled by `-explain`)\")\n      sb.append(EOL).append(newBox(soft = true))\n      dia.msg.explanation.split(raw\"\\R\").foreach { line =>\n        sb.append(EOL).append(offsetBox).append(if line.isEmpty then \"\" else \" \").append(line)\n      }\n      sb.append(EOL).append(endBox)\n    else if dia.msg.canExplain then\n      sb.append(EOL).append(offsetBox)\n      sb.append(EOL).append(offsetBox).append(\" longer explanation available when compiling with `-explain`\")\n\n    sb.toString\n  }\n\n  private  def hl(str: String)(using Context, Level): String =\n    summon[Level].value match\n      case interfaces.Diagnostic.ERROR   => Red(str).show\n      case interfaces.Diagnostic.WARNING => Yellow(str).show\n      case interfaces.Diagnostic.INFO    => Blue(str).show\n\n  private def diagnosticLevel(dia: Diagnostic): String =\n    dia match {\n      case dia: FeatureWarning => \"Feature Warning\"\n      case dia: DeprecationWarning => \"Deprecation Warning\"\n      case dia: UncheckedWarning => \"Unchecked Warning\"\n      case dia: MigrationWarning => \"Migration Warning\"\n      case _ => dia.level match // Diagnostic isn't sealed (e.g. created in the REPL) so provide a fallback\n        case interfaces.Diagnostic.ERROR   => \"Error\"\n        case interfaces.Diagnostic.WARNING => \"Warning\"\n        case interfaces.Diagnostic.INFO    => \"Info\"\n    }\n\n}\n\nprivate object Highlight {\n  opaque type Level = Int\n  extension (level: Level) def value: Int = level\n  object Level:\n    def apply(level: Int): Level = level\n}\n\n/** Size of the left offset added by the box\n *\n *  ```\n *  -- Error: ... ------------\n *  4 |  foo\n *    |  ^^^\n *  ^^^ // size of this offset\n *  ```\n */\nprivate object Offsets {\n  opaque type Offset = Int\n  def offset(using o: Offset): Int = o\n  object Offset:\n    def apply(level: Int): Offset = level\n}",
    "repo": "lampepfl/dotty",
    "path": "./datasets/diagrams-repos/lampepfl/dotty/compiler/src/dotty/tools/dotc/reporting/MessageRendering.scala",
    "query": "What is the process for formatting error messages with boxes and lines?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'MessageRendering', 'node_id': 'MessageRendering', 'description': 'Main trait responsible for rendering error messages with formatting', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'messageAndPos', 'node_id': 'messageAndPos', 'description': 'Main method that renders complete error message with position and formatting', 'visibility': 'public', 'return_type': 'String', 'params': 'dia: Diagnostic', 'source_class_id': 'MessageRendering'}, {'type': 'method', 'name': 'boxTitle', 'node_id': 'boxTitle', 'description': 'Generates box containing error title', 'visibility': 'private', 'return_type': 'String', 'params': 'title: String', 'source_class_id': 'MessageRendering'}, {'type': 'method', 'name': 'positionMarker', 'node_id': 'positionMarker', 'description': 'Creates position markers (carets) under the error', 'visibility': 'private', 'return_type': 'String', 'params': 'pos: SourcePosition', 'source_class_id': 'MessageRendering'}, {'type': 'method', 'name': 'sourceLines', 'node_id': 'sourceLines', 'description': 'Gets source lines before and after error position', 'visibility': 'private', 'return_type': '(List[String], List[String], Int)', 'params': 'pos: SourcePosition', 'source_class_id': 'MessageRendering'}, {'type': 'method', 'name': 'errorMsg', 'node_id': 'errorMsg', 'description': 'Aligns error message under position', 'visibility': 'private', 'return_type': 'String', 'params': 'pos: SourcePosition, msg: String', 'source_class_id': 'MessageRendering'}, {'type': 'method', 'name': 'newBox', 'node_id': 'newBox', 'description': 'Creates box section separator', 'visibility': 'private', 'return_type': 'String', 'params': 'soft: Boolean', 'source_class_id': 'MessageRendering'}, {'type': 'method', 'name': 'endBox', 'node_id': 'endBox', 'description': 'Creates end of box section', 'visibility': 'private', 'return_type': 'String', 'params': '', 'source_class_id': 'MessageRendering'}, {'type': 'method', 'name': 'offsetBox', 'node_id': 'offsetBox', 'description': 'Creates horizontal line with offset', 'visibility': 'private', 'return_type': 'String', 'params': '', 'source_class_id': 'MessageRendering'}, {'type': 'method', 'name': 'stripColor', 'node_id': 'stripColor', 'description': 'Removes ANSI coloring from string', 'visibility': 'public', 'return_type': 'String', 'params': 'str: String', 'source_class_id': 'MessageRendering'}, {'type': 'method', 'name': 'explanation', 'node_id': 'explanation', 'description': 'Renders explanation under header', 'visibility': 'public', 'return_type': 'String', 'params': 'm: Message', 'source_class_id': 'MessageRendering'}, {'type': 'method', 'name': 'hl', 'node_id': 'hl', 'description': 'Highlights text with color based on diagnostic level', 'visibility': 'private', 'return_type': 'String', 'params': 'str: String', 'source_class_id': 'MessageRendering'}], 'edges': [{'node_id_from': 'messageAndPos', 'node_id_to': 'boxTitle', 'description': 'calls to create title box'}, {'node_id_from': 'messageAndPos', 'node_id_to': 'sourceLines', 'description': 'gets source code context'}, {'node_id_from': 'messageAndPos', 'node_id_to': 'positionMarker', 'description': 'calls to mark error position'}, {'node_id_from': 'messageAndPos', 'node_id_to': 'errorMsg', 'description': 'formats error message'}, {'node_id_from': 'messageAndPos', 'node_id_to': 'newBox', 'description': 'adds box separators'}, {'node_id_from': 'messageAndPos', 'node_id_to': 'endBox', 'description': 'adds box ending'}, {'node_id_from': 'messageAndPos', 'node_id_to': 'explanation', 'description': 'adds explanation if needed'}, {'node_id_from': 'errorMsg', 'node_id_to': 'stripColor', 'description': 'removes colors for length calculation'}, {'node_id_from': 'boxTitle', 'node_id_to': 'hl', 'description': 'adds highlighting'}, {'node_id_from': 'MessageRendering', 'node_id_to': 'messageAndPos', 'description': ''}, {'node_id_from': 'MessageRendering', 'node_id_to': 'offsetBox', 'description': ''}, {'node_id_from': 'MessageRendering', 'node_id_to': 'boxTitle', 'description': ''}, {'node_id_from': 'MessageRendering', 'node_id_to': 'positionMarker', 'description': ''}, {'node_id_from': 'MessageRendering', 'node_id_to': 'sourceLines', 'description': ''}, {'node_id_from': 'MessageRendering', 'node_id_to': 'errorMsg', 'description': ''}, {'node_id_from': 'MessageRendering', 'node_id_to': 'newBox', 'description': ''}, {'node_id_from': 'MessageRendering', 'node_id_to': 'endBox', 'description': ''}, {'node_id_from': 'MessageRendering', 'node_id_to': 'stripColor', 'description': ''}, {'node_id_from': 'MessageRendering', 'node_id_to': 'explanation', 'description': ''}, {'node_id_from': 'MessageRendering', 'node_id_to': 'hl', 'description': ''}], 'packages': [{'package_id': 'errorFormatting', 'children': ['MessageRendering', 'messageAndPos', 'boxRendering', 'messageContent', 'styling'], 'description': 'Core error message formatting functionality'}, {'package_id': 'boxRendering', 'children': ['boxTitle', 'newBox', 'endBox', 'offsetBox'], 'description': 'Box drawing functionality'}, {'package_id': 'messageContent', 'children': ['sourceLines', 'positionMarker', 'errorMsg', 'explanation'], 'description': 'Message content formatting'}, {'package_id': 'styling', 'children': ['stripColor', 'hl'], 'description': 'Text styling utilities'}]}",
    "version": "full",
    "text_answer": "Error messages are formatted using a box-style layout where messageAndPos orchestrates the process by combining a title box, source code context with position markers (carets), aligned error messages, and optional explanations. The formatting includes visual elements like borders and highlighting based on the diagnostic level.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include <algorithm>\n#include <iostream>\n#include <math.h>\n#include <numeric>\n#include \"layout.h\"\n\nnamespace clip {\n\nconstexpr double TAU = M_PI * 2;\n\nvec2::vec2() :\n    x(0.0),\n    y(0.0) {}\n\nvec2::vec2(\n    double _x,\n    double _y) :\n    x(_x),\n    y(_y) {}\n\nvec2::vec2(\n    const vec3& v) :\n    x(v.x),\n    y(v.y) {}\n\ndouble& vec2::operator[] (size_t idx) {\n  static double invalid = std::nan(\"\");\n\n  switch (idx) {\n    case 0: return x;\n    case 1: return y;\n    default: return invalid;\n  }\n}\n\ndouble vec2::operator[] (size_t idx) const {\n  switch (idx) {\n    case 0: return x;\n    case 1: return y;\n    default: return std::nan(\"\");\n  }\n}\n\nvec3::vec3() :\n    x(0.0),\n    y(0.0),\n    z(0.0) {}\n\nvec3::vec3(\n    double _x,\n    double _y,\n    double _z) :\n    x(_x),\n    y(_y),\n    z(_z) {}\n\nvec3::vec3(\n    const vec2& v,\n    double _z) :\n    x(v.x),\n    y(v.y),\n    z(_z) {}\n\nmat3::mat3() :\n    a(0.0),\n    b(0.0),\n    c(0.0),\n    d(0.0),\n    e(0.0),\n    f(0.0),\n    g(0.0),\n    h(0.0),\n    i(0.0) {}\n\ndouble magnitude(const vec2& v) {\n  return sqrt(v.x * v.x + v.y * v.y);\n}\n\nvec2 normalize(const vec2& v) {\n  auto m = magnitude(v);\n  return {v.x / m, v.y / m};\n}\n\nvec2 add(const vec2& a, const vec2& b) {\n  return {a.x + b.x, a.y + b.y};\n}\n\nvec2 sub(const vec2& a, const vec2& b) {\n  return {a.x - b.x, a.y - b.y};\n}\n\nvec2 mul(const vec2& v, double s) {\n  return {v.x * s, v.y * s};\n}\n\nmat3 mul(const mat3& a, const mat3& b) {\n  mat3 m;\n\n  m.a = a.a * b.a + a.b * b.d + a.c * b.g;\n  m.b = a.a * b.b + a.b * b.e + a.c * b.h;\n  m.c = a.a * b.c + a.b * b.f + a.c * b.i;\n  m.d = a.d * b.a + a.e * b.d + a.f * b.g;\n  m.e = a.d * b.b + a.e * b.e + a.f * b.h;\n  m.f = a.d * b.c + a.e * b.f + a.f * b.i;\n  m.g = a.g * b.a + a.h * b.d + a.i * b.g;\n  m.h = a.g * b.b + a.h * b.e + a.i * b.h;\n  m.i = a.g * b.c + a.h * b.f + a.i * b.i;\n\n  return m;\n}\n\nvec3 mul(const mat3& m, const vec3& v) {\n  return vec3(\n      m.a * v.x + m.b * v.y + m.c * v.z,\n      m.d * v.x + m.e * v.y + m.f * v.z,\n      m.g * v.x + m.h * v.y + m.i * v.z);\n}\n\ndouble dot(const vec2& a, const vec2& b) {\n  return a.x * b.x + a.y * b.y;\n}\n\nvec2 from_deg(double deg) {\n  double a = -deg / 180.0 * M_PI;\n  return {cos(a), sin(a)};\n}\n\nvec2 mean(const vec2* v, size_t v_len) {\n  vec2 m;\n\n  for (size_t i = 0; i < v_len; ++i) {\n    m = add(m, v[i]);\n  }\n\n  return mul(m, 1.0 / v_len);\n}\n\nmat3 rotate2(double angle) {\n  double angle_tau = (-angle / 360) * TAU;\n  mat3 m;\n  m.a = cos(angle_tau);\n  m.b = sin(angle_tau) * -1;\n  m.d = sin(angle_tau);\n  m.e = cos(angle_tau);\n  m.i = 1.0;\n  return m;\n}\n\nmat3 scale2(const vec2& s) {\n  mat3 m;\n  m.a = s.x;\n  m.e = s.y;\n  m.i = 1.0;\n  return m;\n}\n\nmat3 translate2(const vec2& t) {\n  mat3 m;\n  m.a = 1.0;\n  m.e = 1.0;\n  m.i = 1.0;\n  m.c = t.x;\n  m.f = t.y;\n  return m;\n}\n\nmat3 invert_y2() {\n  mat3 m;\n  m.a = 1.0;\n  m.e = -1.0;\n  m.i = 1.0;\n  return m;\n}\n\nvoid sort_cw(vec2* v, size_t v_len) {\n  auto m = mean(v, v_len);\n\n  std::sort(v, v + v_len, [&m] (const auto& a, const auto& b) {\n    auto da = sub(a, m);\n    auto db = sub(b, m);\n    return atan2(db.y, db.x) < atan2(da.y, da.x);\n  });\n}\n\nvoid sort_ccw(vec2* v, size_t v_len) {\n  auto m = mean(v, v_len);\n\n  std::sort(v, v + v_len, [&m] (const auto& a, const auto& b) {\n    auto da = sub(a, m);\n    auto db = sub(b, m);\n    return atan2(da.y, da.x) < atan2(db.y, db.x);\n  });\n}\n\nstd::ostream& operator <<(std::ostream& os, const vec2& p) {\n  os << \"vec2(\";\n  os << p.x;\n  os << \", \";\n  os << p.y;\n  os << \")\";\n  return os;\n}\n\n} // namespace clip",
    "repo": "asmuth/clip",
    "path": "./datasets/diagrams-repos/asmuth/clip/src/vmath.cc",
    "query": "How are the operator overloads in the code structured?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'vec2', 'node_id': 'vec2', 'description': '2D vector class with basic operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'vec2_subscript_operator', 'node_id': 'vec2_subscript_operator', 'description': 'Allows array-style access to vector components', 'visibility': 'public', 'return_type': 'double&', 'params': 'size_t idx', 'source_class_id': 'vec2'}, {'type': 'method', 'name': 'vec2_const_subscript_operator', 'node_id': 'vec2_const_subscript_operator', 'description': 'Const version of array-style access', 'visibility': 'public', 'return_type': 'double', 'params': 'size_t idx const', 'source_class_id': 'vec2'}, {'type': 'method', 'name': 'vec2_stream_operator', 'node_id': 'vec2_stream_operator', 'description': 'Outputs vector to stream in readable format', 'visibility': 'public', 'return_type': 'std::ostream&', 'params': 'std::ostream& os, const vec2& p', 'source_class_id': 'vec2'}], 'edges': [{'node_id_from': 'vec2', 'node_id_to': 'vec2_subscript_operator', 'description': None}, {'node_id_from': 'vec2', 'node_id_to': 'vec2_const_subscript_operator', 'description': None}, {'node_id_from': 'vec2', 'node_id_to': 'vec2_stream_operator', 'description': None}], 'packages': [{'package_id': 'operators', 'children': ['vec2_subscript_operator', 'vec2_const_subscript_operator', 'vec2_stream_operator'], 'description': 'Operator overloads for vector operations'}]}",
    "version": "minimal",
    "text_answer": "The code implements three operator overloads for the vec2 class: two subscript operators ([]) for accessing vector components (both const and non-const versions) and a stream insertion operator (<<) for output formatting. The subscript operators provide array-style access to x/y components with bounds checking, returning NaN for invalid indices.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include <algorithm>\n#include <iostream>\n#include <math.h>\n#include <numeric>\n#include \"layout.h\"\n\nnamespace clip {\n\nconstexpr double TAU = M_PI * 2;\n\nvec2::vec2() :\n    x(0.0),\n    y(0.0) {}\n\nvec2::vec2(\n    double _x,\n    double _y) :\n    x(_x),\n    y(_y) {}\n\nvec2::vec2(\n    const vec3& v) :\n    x(v.x),\n    y(v.y) {}\n\ndouble& vec2::operator[] (size_t idx) {\n  static double invalid = std::nan(\"\");\n\n  switch (idx) {\n    case 0: return x;\n    case 1: return y;\n    default: return invalid;\n  }\n}\n\ndouble vec2::operator[] (size_t idx) const {\n  switch (idx) {\n    case 0: return x;\n    case 1: return y;\n    default: return std::nan(\"\");\n  }\n}\n\nvec3::vec3() :\n    x(0.0),\n    y(0.0),\n    z(0.0) {}\n\nvec3::vec3(\n    double _x,\n    double _y,\n    double _z) :\n    x(_x),\n    y(_y),\n    z(_z) {}\n\nvec3::vec3(\n    const vec2& v,\n    double _z) :\n    x(v.x),\n    y(v.y),\n    z(_z) {}\n\nmat3::mat3() :\n    a(0.0),\n    b(0.0),\n    c(0.0),\n    d(0.0),\n    e(0.0),\n    f(0.0),\n    g(0.0),\n    h(0.0),\n    i(0.0) {}\n\ndouble magnitude(const vec2& v) {\n  return sqrt(v.x * v.x + v.y * v.y);\n}\n\nvec2 normalize(const vec2& v) {\n  auto m = magnitude(v);\n  return {v.x / m, v.y / m};\n}\n\nvec2 add(const vec2& a, const vec2& b) {\n  return {a.x + b.x, a.y + b.y};\n}\n\nvec2 sub(const vec2& a, const vec2& b) {\n  return {a.x - b.x, a.y - b.y};\n}\n\nvec2 mul(const vec2& v, double s) {\n  return {v.x * s, v.y * s};\n}\n\nmat3 mul(const mat3& a, const mat3& b) {\n  mat3 m;\n\n  m.a = a.a * b.a + a.b * b.d + a.c * b.g;\n  m.b = a.a * b.b + a.b * b.e + a.c * b.h;\n  m.c = a.a * b.c + a.b * b.f + a.c * b.i;\n  m.d = a.d * b.a + a.e * b.d + a.f * b.g;\n  m.e = a.d * b.b + a.e * b.e + a.f * b.h;\n  m.f = a.d * b.c + a.e * b.f + a.f * b.i;\n  m.g = a.g * b.a + a.h * b.d + a.i * b.g;\n  m.h = a.g * b.b + a.h * b.e + a.i * b.h;\n  m.i = a.g * b.c + a.h * b.f + a.i * b.i;\n\n  return m;\n}\n\nvec3 mul(const mat3& m, const vec3& v) {\n  return vec3(\n      m.a * v.x + m.b * v.y + m.c * v.z,\n      m.d * v.x + m.e * v.y + m.f * v.z,\n      m.g * v.x + m.h * v.y + m.i * v.z);\n}\n\ndouble dot(const vec2& a, const vec2& b) {\n  return a.x * b.x + a.y * b.y;\n}\n\nvec2 from_deg(double deg) {\n  double a = -deg / 180.0 * M_PI;\n  return {cos(a), sin(a)};\n}\n\nvec2 mean(const vec2* v, size_t v_len) {\n  vec2 m;\n\n  for (size_t i = 0; i < v_len; ++i) {\n    m = add(m, v[i]);\n  }\n\n  return mul(m, 1.0 / v_len);\n}\n\nmat3 rotate2(double angle) {\n  double angle_tau = (-angle / 360) * TAU;\n  mat3 m;\n  m.a = cos(angle_tau);\n  m.b = sin(angle_tau) * -1;\n  m.d = sin(angle_tau);\n  m.e = cos(angle_tau);\n  m.i = 1.0;\n  return m;\n}\n\nmat3 scale2(const vec2& s) {\n  mat3 m;\n  m.a = s.x;\n  m.e = s.y;\n  m.i = 1.0;\n  return m;\n}\n\nmat3 translate2(const vec2& t) {\n  mat3 m;\n  m.a = 1.0;\n  m.e = 1.0;\n  m.i = 1.0;\n  m.c = t.x;\n  m.f = t.y;\n  return m;\n}\n\nmat3 invert_y2() {\n  mat3 m;\n  m.a = 1.0;\n  m.e = -1.0;\n  m.i = 1.0;\n  return m;\n}\n\nvoid sort_cw(vec2* v, size_t v_len) {\n  auto m = mean(v, v_len);\n\n  std::sort(v, v + v_len, [&m] (const auto& a, const auto& b) {\n    auto da = sub(a, m);\n    auto db = sub(b, m);\n    return atan2(db.y, db.x) < atan2(da.y, da.x);\n  });\n}\n\nvoid sort_ccw(vec2* v, size_t v_len) {\n  auto m = mean(v, v_len);\n\n  std::sort(v, v + v_len, [&m] (const auto& a, const auto& b) {\n    auto da = sub(a, m);\n    auto db = sub(b, m);\n    return atan2(da.y, da.x) < atan2(db.y, db.x);\n  });\n}\n\nstd::ostream& operator <<(std::ostream& os, const vec2& p) {\n  os << \"vec2(\";\n  os << p.x;\n  os << \", \";\n  os << p.y;\n  os << \")\";\n  return os;\n}\n\n} // namespace clip",
    "repo": "asmuth/clip",
    "path": "./datasets/diagrams-repos/asmuth/clip/src/vmath.cc",
    "query": "How are the operator overloads in the code structured?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'vec2', 'node_id': 'vec2', 'description': '2D vector class with basic operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'x', 'node_id': 'vec2_x', 'description': 'X coordinate', 'visibility': 'public', 'return_type': 'double', 'params': None, 'source_class_id': 'vec2'}, {'type': 'field', 'name': 'y', 'node_id': 'vec2_y', 'description': 'Y coordinate', 'visibility': 'public', 'return_type': 'double', 'params': None, 'source_class_id': 'vec2'}, {'type': 'method', 'name': 'vec2_subscript_operator', 'node_id': 'vec2_subscript_operator', 'description': 'Allows array-style access to vector components', 'visibility': 'public', 'return_type': 'double&', 'params': 'size_t idx', 'source_class_id': 'vec2'}, {'type': 'method', 'name': 'vec2_const_subscript_operator', 'node_id': 'vec2_const_subscript_operator', 'description': 'Const version of array-style access', 'visibility': 'public', 'return_type': 'double', 'params': 'size_t idx const', 'source_class_id': 'vec2'}, {'type': 'method', 'name': 'vec2_stream_operator', 'node_id': 'vec2_stream_operator', 'description': 'Outputs vector to stream in readable format', 'visibility': 'public', 'return_type': 'std::ostream&', 'params': 'std::ostream& os, const vec2& p', 'source_class_id': 'vec2'}, {'type': 'variable', 'name': 'invalid', 'node_id': 'invalid', 'description': 'Static variable for invalid index access', 'visibility': 'private', 'return_type': 'double', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'vec2', 'node_id_to': 'vec2_subscript_operator', 'description': None}, {'node_id_from': 'vec2', 'node_id_to': 'vec2_const_subscript_operator', 'description': None}, {'node_id_from': 'vec2', 'node_id_to': 'vec2_stream_operator', 'description': None}, {'node_id_from': 'vec2', 'node_id_to': 'vec2_x', 'description': None}, {'node_id_from': 'vec2', 'node_id_to': 'vec2_y', 'description': None}, {'node_id_from': 'vec2_subscript_operator', 'node_id_to': 'invalid', 'description': None}, {'node_id_from': 'vec2_subscript_operator', 'node_id_to': 'vec2_x', 'description': None}, {'node_id_from': 'vec2_subscript_operator', 'node_id_to': 'vec2_y', 'description': None}], 'packages': [{'package_id': 'operators', 'children': ['vec2_subscript_operator', 'vec2_const_subscript_operator', 'vec2_stream_operator'], 'description': 'Operator overloads for vector operations'}, {'package_id': 'vectorComponents', 'children': ['vec2_x', 'vec2_y'], 'description': 'Vector component fields'}]}",
    "version": "medium",
    "text_answer": "The code implements three operator overloads for the vec2 class: two subscript operators ([]) for accessing vector components (both const and non-const versions) and a stream insertion operator (<<) for output formatting. The subscript operators provide array-style access to x/y components with bounds checking, returning NaN for invalid indices.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include <algorithm>\n#include <iostream>\n#include <math.h>\n#include <numeric>\n#include \"layout.h\"\n\nnamespace clip {\n\nconstexpr double TAU = M_PI * 2;\n\nvec2::vec2() :\n    x(0.0),\n    y(0.0) {}\n\nvec2::vec2(\n    double _x,\n    double _y) :\n    x(_x),\n    y(_y) {}\n\nvec2::vec2(\n    const vec3& v) :\n    x(v.x),\n    y(v.y) {}\n\ndouble& vec2::operator[] (size_t idx) {\n  static double invalid = std::nan(\"\");\n\n  switch (idx) {\n    case 0: return x;\n    case 1: return y;\n    default: return invalid;\n  }\n}\n\ndouble vec2::operator[] (size_t idx) const {\n  switch (idx) {\n    case 0: return x;\n    case 1: return y;\n    default: return std::nan(\"\");\n  }\n}\n\nvec3::vec3() :\n    x(0.0),\n    y(0.0),\n    z(0.0) {}\n\nvec3::vec3(\n    double _x,\n    double _y,\n    double _z) :\n    x(_x),\n    y(_y),\n    z(_z) {}\n\nvec3::vec3(\n    const vec2& v,\n    double _z) :\n    x(v.x),\n    y(v.y),\n    z(_z) {}\n\nmat3::mat3() :\n    a(0.0),\n    b(0.0),\n    c(0.0),\n    d(0.0),\n    e(0.0),\n    f(0.0),\n    g(0.0),\n    h(0.0),\n    i(0.0) {}\n\ndouble magnitude(const vec2& v) {\n  return sqrt(v.x * v.x + v.y * v.y);\n}\n\nvec2 normalize(const vec2& v) {\n  auto m = magnitude(v);\n  return {v.x / m, v.y / m};\n}\n\nvec2 add(const vec2& a, const vec2& b) {\n  return {a.x + b.x, a.y + b.y};\n}\n\nvec2 sub(const vec2& a, const vec2& b) {\n  return {a.x - b.x, a.y - b.y};\n}\n\nvec2 mul(const vec2& v, double s) {\n  return {v.x * s, v.y * s};\n}\n\nmat3 mul(const mat3& a, const mat3& b) {\n  mat3 m;\n\n  m.a = a.a * b.a + a.b * b.d + a.c * b.g;\n  m.b = a.a * b.b + a.b * b.e + a.c * b.h;\n  m.c = a.a * b.c + a.b * b.f + a.c * b.i;\n  m.d = a.d * b.a + a.e * b.d + a.f * b.g;\n  m.e = a.d * b.b + a.e * b.e + a.f * b.h;\n  m.f = a.d * b.c + a.e * b.f + a.f * b.i;\n  m.g = a.g * b.a + a.h * b.d + a.i * b.g;\n  m.h = a.g * b.b + a.h * b.e + a.i * b.h;\n  m.i = a.g * b.c + a.h * b.f + a.i * b.i;\n\n  return m;\n}\n\nvec3 mul(const mat3& m, const vec3& v) {\n  return vec3(\n      m.a * v.x + m.b * v.y + m.c * v.z,\n      m.d * v.x + m.e * v.y + m.f * v.z,\n      m.g * v.x + m.h * v.y + m.i * v.z);\n}\n\ndouble dot(const vec2& a, const vec2& b) {\n  return a.x * b.x + a.y * b.y;\n}\n\nvec2 from_deg(double deg) {\n  double a = -deg / 180.0 * M_PI;\n  return {cos(a), sin(a)};\n}\n\nvec2 mean(const vec2* v, size_t v_len) {\n  vec2 m;\n\n  for (size_t i = 0; i < v_len; ++i) {\n    m = add(m, v[i]);\n  }\n\n  return mul(m, 1.0 / v_len);\n}\n\nmat3 rotate2(double angle) {\n  double angle_tau = (-angle / 360) * TAU;\n  mat3 m;\n  m.a = cos(angle_tau);\n  m.b = sin(angle_tau) * -1;\n  m.d = sin(angle_tau);\n  m.e = cos(angle_tau);\n  m.i = 1.0;\n  return m;\n}\n\nmat3 scale2(const vec2& s) {\n  mat3 m;\n  m.a = s.x;\n  m.e = s.y;\n  m.i = 1.0;\n  return m;\n}\n\nmat3 translate2(const vec2& t) {\n  mat3 m;\n  m.a = 1.0;\n  m.e = 1.0;\n  m.i = 1.0;\n  m.c = t.x;\n  m.f = t.y;\n  return m;\n}\n\nmat3 invert_y2() {\n  mat3 m;\n  m.a = 1.0;\n  m.e = -1.0;\n  m.i = 1.0;\n  return m;\n}\n\nvoid sort_cw(vec2* v, size_t v_len) {\n  auto m = mean(v, v_len);\n\n  std::sort(v, v + v_len, [&m] (const auto& a, const auto& b) {\n    auto da = sub(a, m);\n    auto db = sub(b, m);\n    return atan2(db.y, db.x) < atan2(da.y, da.x);\n  });\n}\n\nvoid sort_ccw(vec2* v, size_t v_len) {\n  auto m = mean(v, v_len);\n\n  std::sort(v, v + v_len, [&m] (const auto& a, const auto& b) {\n    auto da = sub(a, m);\n    auto db = sub(b, m);\n    return atan2(da.y, da.x) < atan2(db.y, db.x);\n  });\n}\n\nstd::ostream& operator <<(std::ostream& os, const vec2& p) {\n  os << \"vec2(\";\n  os << p.x;\n  os << \", \";\n  os << p.y;\n  os << \")\";\n  return os;\n}\n\n} // namespace clip",
    "repo": "asmuth/clip",
    "path": "./datasets/diagrams-repos/asmuth/clip/src/vmath.cc",
    "query": "How are the operator overloads in the code structured?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'vec2', 'node_id': 'vec2', 'description': '2D vector class with basic operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'vec3', 'node_id': 'vec3', 'description': '3D vector class', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'x', 'node_id': 'vec2_x', 'description': 'X coordinate', 'visibility': 'public', 'return_type': 'double', 'params': None, 'source_class_id': 'vec2'}, {'type': 'field', 'name': 'y', 'node_id': 'vec2_y', 'description': 'Y coordinate', 'visibility': 'public', 'return_type': 'double', 'params': None, 'source_class_id': 'vec2'}, {'type': 'method', 'name': 'vec2_subscript_operator', 'node_id': 'vec2_subscript_operator', 'description': 'Allows array-style access to vector components', 'visibility': 'public', 'return_type': 'double&', 'params': 'size_t idx', 'source_class_id': 'vec2'}, {'type': 'method', 'name': 'vec2_const_subscript_operator', 'node_id': 'vec2_const_subscript_operator', 'description': 'Const version of array-style access', 'visibility': 'public', 'return_type': 'double', 'params': 'size_t idx const', 'source_class_id': 'vec2'}, {'type': 'method', 'name': 'vec2_stream_operator', 'node_id': 'vec2_stream_operator', 'description': 'Outputs vector to stream in readable format', 'visibility': 'public', 'return_type': 'std::ostream&', 'params': 'std::ostream& os, const vec2& p', 'source_class_id': 'vec2'}, {'type': 'variable', 'name': 'invalid', 'node_id': 'invalid', 'description': 'Static variable for invalid index access', 'visibility': 'private', 'return_type': 'double', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'vec2', 'node_id_to': 'vec2_subscript_operator', 'description': None}, {'node_id_from': 'vec2', 'node_id_to': 'vec2_const_subscript_operator', 'description': None}, {'node_id_from': 'vec2', 'node_id_to': 'vec2_stream_operator', 'description': None}, {'node_id_from': 'vec2', 'node_id_to': 'vec2_x', 'description': None}, {'node_id_from': 'vec2', 'node_id_to': 'vec2_y', 'description': None}, {'node_id_from': 'vec2_subscript_operator', 'node_id_to': 'invalid', 'description': None}, {'node_id_from': 'vec2_subscript_operator', 'node_id_to': 'vec2_x', 'description': None}, {'node_id_from': 'vec2_subscript_operator', 'node_id_to': 'vec2_y', 'description': None}, {'node_id_from': 'vec2', 'node_id_to': 'vec3', 'description': 'Conversion constructor'}], 'packages': [{'package_id': 'operators', 'children': ['vec2_subscript_operator', 'vec2_const_subscript_operator', 'vec2_stream_operator'], 'description': 'Operator overloads for vector operations'}, {'package_id': 'vectorComponents', 'children': ['vec2_x', 'vec2_y'], 'description': 'Vector component fields'}, {'package_id': 'clip', 'children': ['operators', 'vectorComponents', 'vec2', 'vec3'], 'description': 'Main namespace containing all vector operations'}]}",
    "version": "full",
    "text_answer": "The code implements three operator overloads for the vec2 class: two subscript operators ([]) for accessing vector components (both const and non-const versions) and a stream insertion operator (<<) for output formatting. The subscript operators provide array-style access to x/y components with bounds checking, returning NaN for invalid indices.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport * as React from 'react';\nimport { expect } from 'chai';\nimport PropTypes from 'prop-types';\nimport { createRenderer, waitFor, reactMajor } from '@mui/internal-test-utils';\nimport elementAcceptingRef from './elementAcceptingRef';\n\ndescribe('elementAcceptingRef', () => {\n  const { render } = createRenderer();\n\n  function checkPropType(element: any, required = false) {\n    PropTypes.checkPropTypes(\n      { children: required ? elementAcceptingRef.isRequired : elementAcceptingRef },\n      { children: element },\n      'props',\n      'DummyComponent',\n    );\n  }\n\n  beforeEach(() => {\n    PropTypes.resetWarningCache();\n  });\n\n  describe('acceptance when not required', () => {\n    before(function beforeCallback() {\n      if (reactMajor >= 19) {\n        // React 19 removed prop types support\n        this.skip();\n      }\n    });\n\n    function assertPass(element: any, { shouldMount = true } = {}) {\n      function testAct() {\n        checkPropType(element);\n        if (shouldMount) {\n          render(React.cloneElement(element, { ref: React.createRef() }));\n        }\n      }\n\n      expect(testAct).not.toErrorDev();\n    }\n\n    it('accepts nully values', () => {\n      assertPass(undefined, { shouldMount: false });\n      assertPass(null, { shouldMount: false });\n    });\n\n    it('accepts host components', () => {\n      assertPass(<div />);\n    });\n\n    it('class components', () => {\n      class Component extends React.Component {\n        render() {\n          return null;\n        }\n      }\n\n      assertPass(<Component />);\n    });\n\n    it('accepts pure class components', () => {\n      class Component extends React.PureComponent {\n        render() {\n          return null;\n        }\n      }\n\n      assertPass(<Component />);\n    });\n\n    it('accepts forwardRef', () => {\n      const Component = React.forwardRef(() => null);\n\n      assertPass(<Component />);\n    });\n\n    it('accepts memo', () => {\n      const Component = React.memo(React.forwardRef(() => null));\n\n      assertPass(<Component />);\n    });\n\n    it('accepts lazy', async () => {\n      const Component = React.lazy(() =>\n        Promise.resolve({\n          default: React.forwardRef<HTMLDivElement>((props, ref) => <div {...props} ref={ref} />),\n        }),\n      );\n\n      function testAct() {\n        checkPropType(<Component />);\n        render(\n          <React.Suspense fallback={<p />}>\n            {React.cloneElement(<Component />, { ref: React.createRef() })}\n          </React.Suspense>,\n        );\n      }\n\n      await waitFor(() => {\n        expect(testAct).not.toErrorDev();\n      });\n    });\n\n    it('technically allows other exotics like strict mode', () => {\n      assertPass(<React.StrictMode />);\n    });\n\n    // undesired behavior\n    it('accepts Fragment', () => {\n      // eslint-disable-next-line react/jsx-no-useless-fragment\n      assertPass(<React.Fragment />);\n    });\n  });\n\n  describe('rejections', () => {\n    before(function beforeCallback() {\n      if (reactMajor >= 19) {\n        // React 19 removed prop types support\n        this.skip();\n      }\n    });\n\n    function assertFail(Component: any, hint: string) {\n      expect(() => {\n        checkPropType(Component);\n      }).toErrorDev(\n        'Invalid props `children` supplied to `DummyComponent`. ' +\n          `Expected an element that can hold a ref. ${hint}`,\n      );\n    }\n\n    it('rejects undefined values when required', () => {\n      expect(() => {\n        checkPropType(undefined, true);\n      }).toErrorDev('marked as required');\n    });\n\n    it('rejects null values when required', () => {\n      expect(() => {\n        checkPropType(null, true);\n      }).toErrorDev('marked as required');\n    });\n\n    it('rejects function components', () => {\n      function Component() {\n        return null;\n      }\n\n      assertFail(\n        <Component />,\n        'Did you accidentally use a plain function component for an element instead?',\n      );\n    });\n  });\n});",
    "repo": "mui/material-ui",
    "path": "./datasets/diagrams-repos/mui/material-ui/packages/mui-utils/src/elementAcceptingRef/elementAcceptingRef.test.tsx",
    "query": "What are the interactions between components when using refs?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'elementAcceptingRef', 'node_id': 'elementAcceptingRef', 'description': 'PropType validator that checks if a component can accept refs', 'visibility': 'public', 'return_type': 'boolean', 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'forwardRef', 'node_id': 'forwardRef', 'description': 'React mechanism to forward refs to child components', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'createRef', 'node_id': 'createRef', 'description': 'React API to create refs', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'elementAcceptingRef', 'node_id_to': 'forwardRef', 'description': 'validates'}, {'node_id_from': 'forwardRef', 'node_id_to': 'createRef', 'description': 'uses'}], 'packages': [{'package_id': 'refValidation', 'children': ['elementAcceptingRef', 'forwardRef', 'createRef'], 'description': 'Core ref validation functionality'}]}",
    "version": "minimal",
    "text_answer": "Refs can be used with class components, PureComponents, and components wrapped in forwardRef. Function components need forwardRef to accept refs. The elementAcceptingRef validator ensures proper ref handling, supporting both direct usage and advanced patterns like memo and lazy loading.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport * as React from 'react';\nimport { expect } from 'chai';\nimport PropTypes from 'prop-types';\nimport { createRenderer, waitFor, reactMajor } from '@mui/internal-test-utils';\nimport elementAcceptingRef from './elementAcceptingRef';\n\ndescribe('elementAcceptingRef', () => {\n  const { render } = createRenderer();\n\n  function checkPropType(element: any, required = false) {\n    PropTypes.checkPropTypes(\n      { children: required ? elementAcceptingRef.isRequired : elementAcceptingRef },\n      { children: element },\n      'props',\n      'DummyComponent',\n    );\n  }\n\n  beforeEach(() => {\n    PropTypes.resetWarningCache();\n  });\n\n  describe('acceptance when not required', () => {\n    before(function beforeCallback() {\n      if (reactMajor >= 19) {\n        // React 19 removed prop types support\n        this.skip();\n      }\n    });\n\n    function assertPass(element: any, { shouldMount = true } = {}) {\n      function testAct() {\n        checkPropType(element);\n        if (shouldMount) {\n          render(React.cloneElement(element, { ref: React.createRef() }));\n        }\n      }\n\n      expect(testAct).not.toErrorDev();\n    }\n\n    it('accepts nully values', () => {\n      assertPass(undefined, { shouldMount: false });\n      assertPass(null, { shouldMount: false });\n    });\n\n    it('accepts host components', () => {\n      assertPass(<div />);\n    });\n\n    it('class components', () => {\n      class Component extends React.Component {\n        render() {\n          return null;\n        }\n      }\n\n      assertPass(<Component />);\n    });\n\n    it('accepts pure class components', () => {\n      class Component extends React.PureComponent {\n        render() {\n          return null;\n        }\n      }\n\n      assertPass(<Component />);\n    });\n\n    it('accepts forwardRef', () => {\n      const Component = React.forwardRef(() => null);\n\n      assertPass(<Component />);\n    });\n\n    it('accepts memo', () => {\n      const Component = React.memo(React.forwardRef(() => null));\n\n      assertPass(<Component />);\n    });\n\n    it('accepts lazy', async () => {\n      const Component = React.lazy(() =>\n        Promise.resolve({\n          default: React.forwardRef<HTMLDivElement>((props, ref) => <div {...props} ref={ref} />),\n        }),\n      );\n\n      function testAct() {\n        checkPropType(<Component />);\n        render(\n          <React.Suspense fallback={<p />}>\n            {React.cloneElement(<Component />, { ref: React.createRef() })}\n          </React.Suspense>,\n        );\n      }\n\n      await waitFor(() => {\n        expect(testAct).not.toErrorDev();\n      });\n    });\n\n    it('technically allows other exotics like strict mode', () => {\n      assertPass(<React.StrictMode />);\n    });\n\n    // undesired behavior\n    it('accepts Fragment', () => {\n      // eslint-disable-next-line react/jsx-no-useless-fragment\n      assertPass(<React.Fragment />);\n    });\n  });\n\n  describe('rejections', () => {\n    before(function beforeCallback() {\n      if (reactMajor >= 19) {\n        // React 19 removed prop types support\n        this.skip();\n      }\n    });\n\n    function assertFail(Component: any, hint: string) {\n      expect(() => {\n        checkPropType(Component);\n      }).toErrorDev(\n        'Invalid props `children` supplied to `DummyComponent`. ' +\n          `Expected an element that can hold a ref. ${hint}`,\n      );\n    }\n\n    it('rejects undefined values when required', () => {\n      expect(() => {\n        checkPropType(undefined, true);\n      }).toErrorDev('marked as required');\n    });\n\n    it('rejects null values when required', () => {\n      expect(() => {\n        checkPropType(null, true);\n      }).toErrorDev('marked as required');\n    });\n\n    it('rejects function components', () => {\n      function Component() {\n        return null;\n      }\n\n      assertFail(\n        <Component />,\n        'Did you accidentally use a plain function component for an element instead?',\n      );\n    });\n  });\n});",
    "repo": "mui/material-ui",
    "path": "./datasets/diagrams-repos/mui/material-ui/packages/mui-utils/src/elementAcceptingRef/elementAcceptingRef.test.tsx",
    "query": "What are the interactions between components when using refs?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'elementAcceptingRef', 'node_id': 'elementAcceptingRef', 'description': 'PropType validator that checks if a component can accept refs', 'visibility': 'public', 'return_type': 'boolean', 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'forwardRef', 'node_id': 'forwardRef', 'description': 'React mechanism to forward refs to child components', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'createRef', 'node_id': 'createRef', 'description': 'React API to create refs', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'Component', 'node_id': 'Component', 'description': 'Basic React class component', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'PureComponent', 'node_id': 'PureComponent', 'description': 'Optimized React class component', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'memo', 'node_id': 'memo', 'description': 'React performance optimization wrapper', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'elementAcceptingRef', 'node_id_to': 'forwardRef', 'description': 'validates'}, {'node_id_from': 'forwardRef', 'node_id_to': 'createRef', 'description': 'uses'}, {'node_id_from': 'elementAcceptingRef', 'node_id_to': 'Component', 'description': 'validates'}, {'node_id_from': 'elementAcceptingRef', 'node_id_to': 'PureComponent', 'description': 'validates'}, {'node_id_from': 'memo', 'node_id_to': 'forwardRef', 'description': 'wraps'}], 'packages': [{'package_id': 'reactCore', 'children': ['forwardRef', 'createRef', 'Component', 'PureComponent', 'memo'], 'description': 'Core React components and utilities'}]}",
    "version": "medium",
    "text_answer": "Refs can be used with class components, PureComponents, and components wrapped in forwardRef. Function components need forwardRef to accept refs. The elementAcceptingRef validator ensures proper ref handling, supporting both direct usage and advanced patterns like memo and lazy loading.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "TypeScript",
    "code": "\nimport * as React from 'react';\nimport { expect } from 'chai';\nimport PropTypes from 'prop-types';\nimport { createRenderer, waitFor, reactMajor } from '@mui/internal-test-utils';\nimport elementAcceptingRef from './elementAcceptingRef';\n\ndescribe('elementAcceptingRef', () => {\n  const { render } = createRenderer();\n\n  function checkPropType(element: any, required = false) {\n    PropTypes.checkPropTypes(\n      { children: required ? elementAcceptingRef.isRequired : elementAcceptingRef },\n      { children: element },\n      'props',\n      'DummyComponent',\n    );\n  }\n\n  beforeEach(() => {\n    PropTypes.resetWarningCache();\n  });\n\n  describe('acceptance when not required', () => {\n    before(function beforeCallback() {\n      if (reactMajor >= 19) {\n        // React 19 removed prop types support\n        this.skip();\n      }\n    });\n\n    function assertPass(element: any, { shouldMount = true } = {}) {\n      function testAct() {\n        checkPropType(element);\n        if (shouldMount) {\n          render(React.cloneElement(element, { ref: React.createRef() }));\n        }\n      }\n\n      expect(testAct).not.toErrorDev();\n    }\n\n    it('accepts nully values', () => {\n      assertPass(undefined, { shouldMount: false });\n      assertPass(null, { shouldMount: false });\n    });\n\n    it('accepts host components', () => {\n      assertPass(<div />);\n    });\n\n    it('class components', () => {\n      class Component extends React.Component {\n        render() {\n          return null;\n        }\n      }\n\n      assertPass(<Component />);\n    });\n\n    it('accepts pure class components', () => {\n      class Component extends React.PureComponent {\n        render() {\n          return null;\n        }\n      }\n\n      assertPass(<Component />);\n    });\n\n    it('accepts forwardRef', () => {\n      const Component = React.forwardRef(() => null);\n\n      assertPass(<Component />);\n    });\n\n    it('accepts memo', () => {\n      const Component = React.memo(React.forwardRef(() => null));\n\n      assertPass(<Component />);\n    });\n\n    it('accepts lazy', async () => {\n      const Component = React.lazy(() =>\n        Promise.resolve({\n          default: React.forwardRef<HTMLDivElement>((props, ref) => <div {...props} ref={ref} />),\n        }),\n      );\n\n      function testAct() {\n        checkPropType(<Component />);\n        render(\n          <React.Suspense fallback={<p />}>\n            {React.cloneElement(<Component />, { ref: React.createRef() })}\n          </React.Suspense>,\n        );\n      }\n\n      await waitFor(() => {\n        expect(testAct).not.toErrorDev();\n      });\n    });\n\n    it('technically allows other exotics like strict mode', () => {\n      assertPass(<React.StrictMode />);\n    });\n\n    // undesired behavior\n    it('accepts Fragment', () => {\n      // eslint-disable-next-line react/jsx-no-useless-fragment\n      assertPass(<React.Fragment />);\n    });\n  });\n\n  describe('rejections', () => {\n    before(function beforeCallback() {\n      if (reactMajor >= 19) {\n        // React 19 removed prop types support\n        this.skip();\n      }\n    });\n\n    function assertFail(Component: any, hint: string) {\n      expect(() => {\n        checkPropType(Component);\n      }).toErrorDev(\n        'Invalid props `children` supplied to `DummyComponent`. ' +\n          `Expected an element that can hold a ref. ${hint}`,\n      );\n    }\n\n    it('rejects undefined values when required', () => {\n      expect(() => {\n        checkPropType(undefined, true);\n      }).toErrorDev('marked as required');\n    });\n\n    it('rejects null values when required', () => {\n      expect(() => {\n        checkPropType(null, true);\n      }).toErrorDev('marked as required');\n    });\n\n    it('rejects function components', () => {\n      function Component() {\n        return null;\n      }\n\n      assertFail(\n        <Component />,\n        'Did you accidentally use a plain function component for an element instead?',\n      );\n    });\n  });\n});",
    "repo": "mui/material-ui",
    "path": "./datasets/diagrams-repos/mui/material-ui/packages/mui-utils/src/elementAcceptingRef/elementAcceptingRef.test.tsx",
    "query": "What are the interactions between components when using refs?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'elementAcceptingRef', 'node_id': 'elementAcceptingRef', 'description': 'PropType validator that checks if a component can accept refs', 'visibility': 'public', 'return_type': 'boolean', 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'forwardRef', 'node_id': 'forwardRef', 'description': 'React mechanism to forward refs to child components', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'createRef', 'node_id': 'createRef', 'description': 'React API to create refs', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'Component', 'node_id': 'Component', 'description': 'Basic React class component', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'PureComponent', 'node_id': 'PureComponent', 'description': 'Optimized React class component', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'memo', 'node_id': 'memo', 'description': 'React performance optimization wrapper', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'lazy', 'node_id': 'lazy', 'description': 'React lazy loading mechanism', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'Suspense', 'node_id': 'Suspense', 'description': 'React component for handling async operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'checkPropType', 'node_id': 'checkPropType', 'description': 'Utility function to check prop types', 'visibility': 'private', 'return_type': None, 'params': '(element: any, required: boolean)', 'source_class_id': None}, {'type': 'entity', 'name': 'Fragment', 'node_id': 'Fragment', 'description': 'React Fragment component', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'elementAcceptingRef', 'node_id_to': 'forwardRef', 'description': 'validates'}, {'node_id_from': 'forwardRef', 'node_id_to': 'createRef', 'description': 'uses'}, {'node_id_from': 'elementAcceptingRef', 'node_id_to': 'Component', 'description': 'validates'}, {'node_id_from': 'elementAcceptingRef', 'node_id_to': 'PureComponent', 'description': 'validates'}, {'node_id_from': 'memo', 'node_id_to': 'forwardRef', 'description': 'wraps'}, {'node_id_from': 'lazy', 'node_id_to': 'Suspense', 'description': 'requires'}, {'node_id_from': 'checkPropType', 'node_id_to': 'elementAcceptingRef', 'description': 'uses'}, {'node_id_from': 'elementAcceptingRef', 'node_id_to': 'Fragment', 'description': 'validates'}, {'node_id_from': 'elementAcceptingRef', 'node_id_to': 'lazy', 'description': 'validates'}, {'node_id_from': 'lazy', 'node_id_to': 'forwardRef', 'description': 'can resolve to'}, {'node_id_from': 'Suspense', 'node_id_to': 'createRef', 'description': 'enables use of'}], 'packages': [{'package_id': 'validation', 'children': ['elementAcceptingRef', 'checkPropType'], 'description': 'Validation utilities'}, {'package_id': 'reactCore', 'children': ['forwardRef', 'createRef', 'Component', 'PureComponent', 'memo'], 'description': 'Core React components'}, {'package_id': 'asyncComponents', 'children': ['lazy', 'Suspense'], 'description': 'Async loading utilities'}]}",
    "version": "full",
    "text_answer": "Refs can be used with class components, PureComponents, and components wrapped in forwardRef. Function components need forwardRef to accept refs. The elementAcceptingRef validator ensures proper ref handling, supporting both direct usage and advanced patterns like memo and lazy loading.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include \"src/vizier/services/agent/shared/manager/k8s_update.h\"\n\n#include <memory>\n#include <utility>\n#include <vector>\n\n#include \"src/vizier/services/agent/shared/manager/manager.h\"\n\nnamespace px {\nnamespace vizier {\nnamespace agent {\n\nK8sUpdateHandler::K8sUpdateHandler(Dispatcher* d, px::md::AgentMetadataStateManager* mds_manager,\n                                   Info* agent_info, Manager::VizierNATSConnector* nats_conn,\n                                   const std::string& update_selector, size_t max_update_queue_size)\n    : MessageHandler(d, agent_info, nats_conn),\n      mds_manager_(mds_manager),\n      update_selector_(update_selector),\n      missing_metadata_request_timer_(\n          dispatcher()->CreateTimer(std::bind(&K8sUpdateHandler::RequestMissingMetadata, this))),\n      update_backlog_([](const ResourceUpdate& left, const ResourceUpdate& right) {\n        return left.update_version() > right.update_version();\n      }),\n      max_update_queue_size_(max_update_queue_size) {\n  // Request the initial backlog of missing metadata.\n  missing_metadata_request_timer_->EnableTimer(std::chrono::milliseconds(0));\n}\n\nStatus K8sUpdateHandler::AddK8sUpdate(const ResourceUpdate& update) {\n  current_update_version_ = update.update_version();\n  return mds_manager_->AddK8sUpdate(std::make_unique<ResourceUpdate>(update));\n}\n\nStatus K8sUpdateHandler::HandleMissingK8sMetadataResponse(const MissingK8sMetadataResponse& resp) {\n  if (resp.updates().size() > 0) {\n    auto first_update = resp.updates()[0];\n    // If the metadata service tells us that update N is the earliest update it has,\n    // then we should consider that the new starting point, even if we are at an update\n    // smaller than N-1.\n    if (current_update_version_ < first_update.update_version() &&\n        first_update.update_version() == resp.first_update_available()) {\n      current_update_version_ = first_update.prev_update_version();\n    }\n  }\n\n  if (resp.updates().size() == 0 && update_backlog_.size() > 0) {\n    // If our backlog now predates the earliest updates known by the metadata service,\n    // we need to write out the backlog, and stop trying to find missing updates that\n    // no longer exist in the metadata service.\n    if (resp.first_update_available() >= update_backlog_.top().update_version()) {\n      current_update_version_ = update_backlog_.top().prev_update_version();\n    }\n  }\n\n  for (const auto& update : resp.updates()) {\n    PX_RETURN_IF_ERROR(HandleK8sUpdate(update));\n  }\n\n  // Check and flush backlog.\n  // if backlog is done, disable timer\n  while (update_backlog_.size()) {\n    auto next = update_backlog_.top();\n    // Break out of the loop if the backlog is still ahead of the\n    // current resource version.\n    if (current_update_version_ < next.prev_update_version()) {\n      break;\n    }\n\n    // If this is the update that we need, then add it.\n    if (current_update_version_ == next.prev_update_version()) {\n      PX_RETURN_IF_ERROR(AddK8sUpdate(next));\n    }\n    update_backlog_.pop();\n  }\n\n  // Check to see if we have now received the initial batch of metadata, after startup.\n  if (!initial_metadata_received_) {\n    // Check to see if we have received the full batch of initial metadata.\n    if (current_update_version_ >= resp.last_update_available()) {\n      initial_metadata_received_ = true;\n    }\n  }\n\n  // Two cases here:\n  // 1. We were waiting on the initial set of metadata from the metadata service. If we\n  // received it all, then we can disable the timer.\n  // 2. We had received an out of order update. In that case, we needed to make a re-request\n  // for the missing metadata in between. In that scenario, checking that the backlog is\n  // empty will suffice.\n  // If we are still waiting on data, then the timer will go off eventually and the missing\n  // metadata will be re-requested.\n  if (initial_metadata_received_ && !update_backlog_.size()) {\n    missing_metadata_request_timer_->DisableTimer();\n  }\n\n  return Status::OK();\n}\n\nvoid K8sUpdateHandler::RequestMissingMetadata() {\n  // If there is no backlog, then we don't have any missing metadata that we know of.\n  if (!update_backlog_.size() && initial_metadata_received_) {\n    return;\n  }\n\n  // Send the registration request.\n  // Note that we will re-request an update we already have in the range of [from, to),\n  // because we have to use our current resource version as the `from` value.\n  messages::VizierMessage msg;\n  auto req = msg.mutable_k8s_metadata_message()->mutable_missing_k8s_metadata_request();\n  req->set_selector(update_selector_);\n\n  if (current_update_version_) {\n    // We don't know the resource numbers, but we know they will always be greater by at\n    // least 1 than the most recent one we received. However, we keep it as a 0 if we haven't\n    // received any updates yet.\n    req->set_from_update_version(current_update_version_ + 1);\n  }\n  // Keep this as a 0 if we don't know the upper bound of the range we are asking for.\n  // Note: requesting [from: 0, to: 0) is the same as requesting all\n  if (update_backlog_.size()) {\n    req->set_to_update_version(update_backlog_.top().update_version());\n  }\n\n  auto s = nats_conn()->Publish(msg);\n  if (!s.ok()) {\n    LOG(ERROR) << absl::Substitute(\"Failed to request missing K8s updates, retrying in $0 s\",\n                                   kMissingMetadataTimeout.count());\n  }\n\n  // Enable the timer once we make the request for the initial missing metadata.\n  // It will get disabled if we see all of the initial data in time.\n  missing_metadata_request_timer_->EnableTimer(kMissingMetadataTimeout);\n}\n\nStatus K8sUpdateHandler::HandleK8sUpdate(const ResourceUpdate& update) {\n  if (current_update_version_ == update.prev_update_version()) {\n    return AddK8sUpdate(update);\n  }\n\n  // This was probably a duplicate, ignore.\n  if (current_update_version_ > update.prev_update_version()) {\n    return Status::OK();\n  }\n\n  // If this update is further along than we expect, add it to the backlog.\n  update_backlog_.push(update);\n  // Keep the most recent updates so that we know how far ahead the mds is.\n  // Re-request updates that we dropped once we catch up.\n  if (update_backlog_.size() > max_update_queue_size_) {\n    update_backlog_.pop();\n  }\n\n  // If we have missing metadata (which we do if we have reached this part of the\n  // logic) and we haven't made a recent outbound request for that missing metadata,\n  // we should make that request now.\n  if (!missing_metadata_request_timer_->Enabled()) {\n    RequestMissingMetadata();\n  }\n\n  return Status::OK();\n}\n\nStatus K8sUpdateHandler::HandleMessage(std::unique_ptr<messages::VizierMessage> msg) {\n  LOG_IF(FATAL, !msg->has_k8s_metadata_message()) << \"Expected K8sMetadataMessage\";\n  auto k8s_msg = msg->k8s_metadata_message();\n\n  if (k8s_msg.has_k8s_metadata_update()) {\n    return HandleK8sUpdate(k8s_msg.k8s_metadata_update());\n  }\n  if (k8s_msg.has_missing_k8s_metadata_response()) {\n    return HandleMissingK8sMetadataResponse(k8s_msg.missing_k8s_metadata_response());\n  }\n\n  return error::Internal(\n      \"Expected either ResourceUpdate or MissingK8sMetadataResponse in K8sMetadataMessage\");\n}\n\n}  // namespace agent\n}  // namespace vizier\n}  // namespace px",
    "repo": "pixie-io/pixie",
    "path": "./datasets/diagrams-repos/pixie-io/pixie/src/vizier/services/agent/shared/manager/k8s_update.cc",
    "query": "What is the workflow for requesting missing K8s metadata?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'K8sUpdateHandler', 'node_id': 'K8sUpdateHandler', 'description': 'Handles K8s metadata updates and requests', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'RequestMissingMetadata', 'node_id': 'RequestMissingMetadata', 'description': 'Sends request for missing K8s metadata updates', 'visibility': 'public', 'return_type': 'void', 'params': None, 'source_class_id': 'K8sUpdateHandler'}, {'type': 'method', 'name': 'HandleMissingK8sMetadataResponse', 'node_id': 'HandleMissingK8sMetadataResponse', 'description': 'Processes response with missing K8s metadata', 'visibility': 'public', 'return_type': 'Status', 'params': 'const MissingK8sMetadataResponse& resp', 'source_class_id': 'K8sUpdateHandler'}, {'type': 'field', 'name': 'missing_metadata_request_timer_', 'node_id': 'missing_metadata_request_timer_', 'description': 'Timer for scheduling metadata requests', 'visibility': 'private', 'return_type': 'Timer*', 'params': None, 'source_class_id': 'K8sUpdateHandler'}], 'edges': [{'node_id_from': 'RequestMissingMetadata', 'node_id_to': 'HandleMissingK8sMetadataResponse', 'description': 'triggers request and awaits response'}, {'node_id_from': 'missing_metadata_request_timer_', 'node_id_to': 'RequestMissingMetadata', 'description': 'schedules'}, {'node_id_from': 'K8sUpdateHandler', 'node_id_to': 'RequestMissingMetadata', 'description': ''}, {'node_id_from': 'K8sUpdateHandler', 'node_id_to': 'HandleMissingK8sMetadataResponse', 'description': ''}, {'node_id_from': 'K8sUpdateHandler', 'node_id_to': 'missing_metadata_request_timer_', 'description': ''}], 'packages': [{'package_id': 'metadataRequestFlow', 'children': ['RequestMissingMetadata', 'HandleMissingK8sMetadataResponse', 'missing_metadata_request_timer_'], 'description': 'Core metadata request workflow'}]}",
    "version": "minimal",
    "text_answer": "The missing K8s metadata request workflow starts with RequestMissingMetadata method, which is triggered by a timer. It sends a request for missing updates and awaits response through HandleMissingK8sMetadataResponse, which processes the received updates using HandleK8sUpdate. The system maintains a backlog for out-of-order updates and tracks the current update version to ensure proper synchronization.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include \"src/vizier/services/agent/shared/manager/k8s_update.h\"\n\n#include <memory>\n#include <utility>\n#include <vector>\n\n#include \"src/vizier/services/agent/shared/manager/manager.h\"\n\nnamespace px {\nnamespace vizier {\nnamespace agent {\n\nK8sUpdateHandler::K8sUpdateHandler(Dispatcher* d, px::md::AgentMetadataStateManager* mds_manager,\n                                   Info* agent_info, Manager::VizierNATSConnector* nats_conn,\n                                   const std::string& update_selector, size_t max_update_queue_size)\n    : MessageHandler(d, agent_info, nats_conn),\n      mds_manager_(mds_manager),\n      update_selector_(update_selector),\n      missing_metadata_request_timer_(\n          dispatcher()->CreateTimer(std::bind(&K8sUpdateHandler::RequestMissingMetadata, this))),\n      update_backlog_([](const ResourceUpdate& left, const ResourceUpdate& right) {\n        return left.update_version() > right.update_version();\n      }),\n      max_update_queue_size_(max_update_queue_size) {\n  // Request the initial backlog of missing metadata.\n  missing_metadata_request_timer_->EnableTimer(std::chrono::milliseconds(0));\n}\n\nStatus K8sUpdateHandler::AddK8sUpdate(const ResourceUpdate& update) {\n  current_update_version_ = update.update_version();\n  return mds_manager_->AddK8sUpdate(std::make_unique<ResourceUpdate>(update));\n}\n\nStatus K8sUpdateHandler::HandleMissingK8sMetadataResponse(const MissingK8sMetadataResponse& resp) {\n  if (resp.updates().size() > 0) {\n    auto first_update = resp.updates()[0];\n    // If the metadata service tells us that update N is the earliest update it has,\n    // then we should consider that the new starting point, even if we are at an update\n    // smaller than N-1.\n    if (current_update_version_ < first_update.update_version() &&\n        first_update.update_version() == resp.first_update_available()) {\n      current_update_version_ = first_update.prev_update_version();\n    }\n  }\n\n  if (resp.updates().size() == 0 && update_backlog_.size() > 0) {\n    // If our backlog now predates the earliest updates known by the metadata service,\n    // we need to write out the backlog, and stop trying to find missing updates that\n    // no longer exist in the metadata service.\n    if (resp.first_update_available() >= update_backlog_.top().update_version()) {\n      current_update_version_ = update_backlog_.top().prev_update_version();\n    }\n  }\n\n  for (const auto& update : resp.updates()) {\n    PX_RETURN_IF_ERROR(HandleK8sUpdate(update));\n  }\n\n  // Check and flush backlog.\n  // if backlog is done, disable timer\n  while (update_backlog_.size()) {\n    auto next = update_backlog_.top();\n    // Break out of the loop if the backlog is still ahead of the\n    // current resource version.\n    if (current_update_version_ < next.prev_update_version()) {\n      break;\n    }\n\n    // If this is the update that we need, then add it.\n    if (current_update_version_ == next.prev_update_version()) {\n      PX_RETURN_IF_ERROR(AddK8sUpdate(next));\n    }\n    update_backlog_.pop();\n  }\n\n  // Check to see if we have now received the initial batch of metadata, after startup.\n  if (!initial_metadata_received_) {\n    // Check to see if we have received the full batch of initial metadata.\n    if (current_update_version_ >= resp.last_update_available()) {\n      initial_metadata_received_ = true;\n    }\n  }\n\n  // Two cases here:\n  // 1. We were waiting on the initial set of metadata from the metadata service. If we\n  // received it all, then we can disable the timer.\n  // 2. We had received an out of order update. In that case, we needed to make a re-request\n  // for the missing metadata in between. In that scenario, checking that the backlog is\n  // empty will suffice.\n  // If we are still waiting on data, then the timer will go off eventually and the missing\n  // metadata will be re-requested.\n  if (initial_metadata_received_ && !update_backlog_.size()) {\n    missing_metadata_request_timer_->DisableTimer();\n  }\n\n  return Status::OK();\n}\n\nvoid K8sUpdateHandler::RequestMissingMetadata() {\n  // If there is no backlog, then we don't have any missing metadata that we know of.\n  if (!update_backlog_.size() && initial_metadata_received_) {\n    return;\n  }\n\n  // Send the registration request.\n  // Note that we will re-request an update we already have in the range of [from, to),\n  // because we have to use our current resource version as the `from` value.\n  messages::VizierMessage msg;\n  auto req = msg.mutable_k8s_metadata_message()->mutable_missing_k8s_metadata_request();\n  req->set_selector(update_selector_);\n\n  if (current_update_version_) {\n    // We don't know the resource numbers, but we know they will always be greater by at\n    // least 1 than the most recent one we received. However, we keep it as a 0 if we haven't\n    // received any updates yet.\n    req->set_from_update_version(current_update_version_ + 1);\n  }\n  // Keep this as a 0 if we don't know the upper bound of the range we are asking for.\n  // Note: requesting [from: 0, to: 0) is the same as requesting all\n  if (update_backlog_.size()) {\n    req->set_to_update_version(update_backlog_.top().update_version());\n  }\n\n  auto s = nats_conn()->Publish(msg);\n  if (!s.ok()) {\n    LOG(ERROR) << absl::Substitute(\"Failed to request missing K8s updates, retrying in $0 s\",\n                                   kMissingMetadataTimeout.count());\n  }\n\n  // Enable the timer once we make the request for the initial missing metadata.\n  // It will get disabled if we see all of the initial data in time.\n  missing_metadata_request_timer_->EnableTimer(kMissingMetadataTimeout);\n}\n\nStatus K8sUpdateHandler::HandleK8sUpdate(const ResourceUpdate& update) {\n  if (current_update_version_ == update.prev_update_version()) {\n    return AddK8sUpdate(update);\n  }\n\n  // This was probably a duplicate, ignore.\n  if (current_update_version_ > update.prev_update_version()) {\n    return Status::OK();\n  }\n\n  // If this update is further along than we expect, add it to the backlog.\n  update_backlog_.push(update);\n  // Keep the most recent updates so that we know how far ahead the mds is.\n  // Re-request updates that we dropped once we catch up.\n  if (update_backlog_.size() > max_update_queue_size_) {\n    update_backlog_.pop();\n  }\n\n  // If we have missing metadata (which we do if we have reached this part of the\n  // logic) and we haven't made a recent outbound request for that missing metadata,\n  // we should make that request now.\n  if (!missing_metadata_request_timer_->Enabled()) {\n    RequestMissingMetadata();\n  }\n\n  return Status::OK();\n}\n\nStatus K8sUpdateHandler::HandleMessage(std::unique_ptr<messages::VizierMessage> msg) {\n  LOG_IF(FATAL, !msg->has_k8s_metadata_message()) << \"Expected K8sMetadataMessage\";\n  auto k8s_msg = msg->k8s_metadata_message();\n\n  if (k8s_msg.has_k8s_metadata_update()) {\n    return HandleK8sUpdate(k8s_msg.k8s_metadata_update());\n  }\n  if (k8s_msg.has_missing_k8s_metadata_response()) {\n    return HandleMissingK8sMetadataResponse(k8s_msg.missing_k8s_metadata_response());\n  }\n\n  return error::Internal(\n      \"Expected either ResourceUpdate or MissingK8sMetadataResponse in K8sMetadataMessage\");\n}\n\n}  // namespace agent\n}  // namespace vizier\n}  // namespace px",
    "repo": "pixie-io/pixie",
    "path": "./datasets/diagrams-repos/pixie-io/pixie/src/vizier/services/agent/shared/manager/k8s_update.cc",
    "query": "What is the workflow for requesting missing K8s metadata?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'K8sUpdateHandler', 'node_id': 'K8sUpdateHandler', 'description': 'Handles K8s metadata updates and requests', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'RequestMissingMetadata', 'node_id': 'RequestMissingMetadata', 'description': 'Sends request for missing K8s metadata updates', 'visibility': 'public', 'return_type': 'void', 'params': None, 'source_class_id': 'K8sUpdateHandler'}, {'type': 'method', 'name': 'HandleMissingK8sMetadataResponse', 'node_id': 'HandleMissingK8sMetadataResponse', 'description': 'Processes response with missing K8s metadata', 'visibility': 'public', 'return_type': 'Status', 'params': 'const MissingK8sMetadataResponse& resp', 'source_class_id': 'K8sUpdateHandler'}, {'type': 'method', 'name': 'HandleK8sUpdate', 'node_id': 'HandleK8sUpdate', 'description': 'Processes individual K8s update', 'visibility': 'public', 'return_type': 'Status', 'params': 'const ResourceUpdate& update', 'source_class_id': 'K8sUpdateHandler'}, {'type': 'field', 'name': 'missing_metadata_request_timer_', 'node_id': 'missing_metadata_request_timer_', 'description': 'Timer for scheduling metadata requests', 'visibility': 'private', 'return_type': 'Timer*', 'params': None, 'source_class_id': 'K8sUpdateHandler'}, {'type': 'field', 'name': 'update_backlog_', 'node_id': 'update_backlog_', 'description': 'Queue for out-of-order updates', 'visibility': 'private', 'return_type': 'priority_queue', 'params': None, 'source_class_id': 'K8sUpdateHandler'}], 'edges': [{'node_id_from': 'K8sUpdateHandler', 'node_id_to': 'RequestMissingMetadata', 'description': 'owns'}, {'node_id_from': 'RequestMissingMetadata', 'node_id_to': 'HandleMissingK8sMetadataResponse', 'description': 'triggers request and awaits response'}, {'node_id_from': 'HandleMissingK8sMetadataResponse', 'node_id_to': 'HandleK8sUpdate', 'description': 'processes updates'}, {'node_id_from': 'missing_metadata_request_timer_', 'node_id_to': 'RequestMissingMetadata', 'description': 'schedules'}, {'node_id_from': 'K8sUpdateHandler', 'node_id_to': 'missing_metadata_request_timer_', 'description': ''}, {'node_id_from': 'K8sUpdateHandler', 'node_id_to': 'update_backlog_', 'description': ''}, {'node_id_from': 'K8sUpdateHandler', 'node_id_to': 'HandleMissingK8sMetadataResponse', 'description': ''}, {'node_id_from': 'K8sUpdateHandler', 'node_id_to': 'HandleK8sUpdate', 'description': ''}], 'packages': [{'package_id': 'k8sMetadataHandling', 'children': ['K8sUpdateHandler', 'metadataRequestFlow'], 'description': 'K8s metadata handling system'}, {'package_id': 'metadataRequestFlow', 'children': ['RequestMissingMetadata', 'HandleMissingK8sMetadataResponse', 'HandleK8sUpdate', 'missing_metadata_request_timer_', 'update_backlog_'], 'description': 'Metadata request and processing workflow'}]}",
    "version": "medium",
    "text_answer": "The missing K8s metadata request workflow starts with RequestMissingMetadata method, which is triggered by a timer. It sends a request for missing updates and awaits response through HandleMissingK8sMetadataResponse, which processes the received updates using HandleK8sUpdate. The system maintains a backlog for out-of-order updates and tracks the current update version to ensure proper synchronization.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include \"src/vizier/services/agent/shared/manager/k8s_update.h\"\n\n#include <memory>\n#include <utility>\n#include <vector>\n\n#include \"src/vizier/services/agent/shared/manager/manager.h\"\n\nnamespace px {\nnamespace vizier {\nnamespace agent {\n\nK8sUpdateHandler::K8sUpdateHandler(Dispatcher* d, px::md::AgentMetadataStateManager* mds_manager,\n                                   Info* agent_info, Manager::VizierNATSConnector* nats_conn,\n                                   const std::string& update_selector, size_t max_update_queue_size)\n    : MessageHandler(d, agent_info, nats_conn),\n      mds_manager_(mds_manager),\n      update_selector_(update_selector),\n      missing_metadata_request_timer_(\n          dispatcher()->CreateTimer(std::bind(&K8sUpdateHandler::RequestMissingMetadata, this))),\n      update_backlog_([](const ResourceUpdate& left, const ResourceUpdate& right) {\n        return left.update_version() > right.update_version();\n      }),\n      max_update_queue_size_(max_update_queue_size) {\n  // Request the initial backlog of missing metadata.\n  missing_metadata_request_timer_->EnableTimer(std::chrono::milliseconds(0));\n}\n\nStatus K8sUpdateHandler::AddK8sUpdate(const ResourceUpdate& update) {\n  current_update_version_ = update.update_version();\n  return mds_manager_->AddK8sUpdate(std::make_unique<ResourceUpdate>(update));\n}\n\nStatus K8sUpdateHandler::HandleMissingK8sMetadataResponse(const MissingK8sMetadataResponse& resp) {\n  if (resp.updates().size() > 0) {\n    auto first_update = resp.updates()[0];\n    // If the metadata service tells us that update N is the earliest update it has,\n    // then we should consider that the new starting point, even if we are at an update\n    // smaller than N-1.\n    if (current_update_version_ < first_update.update_version() &&\n        first_update.update_version() == resp.first_update_available()) {\n      current_update_version_ = first_update.prev_update_version();\n    }\n  }\n\n  if (resp.updates().size() == 0 && update_backlog_.size() > 0) {\n    // If our backlog now predates the earliest updates known by the metadata service,\n    // we need to write out the backlog, and stop trying to find missing updates that\n    // no longer exist in the metadata service.\n    if (resp.first_update_available() >= update_backlog_.top().update_version()) {\n      current_update_version_ = update_backlog_.top().prev_update_version();\n    }\n  }\n\n  for (const auto& update : resp.updates()) {\n    PX_RETURN_IF_ERROR(HandleK8sUpdate(update));\n  }\n\n  // Check and flush backlog.\n  // if backlog is done, disable timer\n  while (update_backlog_.size()) {\n    auto next = update_backlog_.top();\n    // Break out of the loop if the backlog is still ahead of the\n    // current resource version.\n    if (current_update_version_ < next.prev_update_version()) {\n      break;\n    }\n\n    // If this is the update that we need, then add it.\n    if (current_update_version_ == next.prev_update_version()) {\n      PX_RETURN_IF_ERROR(AddK8sUpdate(next));\n    }\n    update_backlog_.pop();\n  }\n\n  // Check to see if we have now received the initial batch of metadata, after startup.\n  if (!initial_metadata_received_) {\n    // Check to see if we have received the full batch of initial metadata.\n    if (current_update_version_ >= resp.last_update_available()) {\n      initial_metadata_received_ = true;\n    }\n  }\n\n  // Two cases here:\n  // 1. We were waiting on the initial set of metadata from the metadata service. If we\n  // received it all, then we can disable the timer.\n  // 2. We had received an out of order update. In that case, we needed to make a re-request\n  // for the missing metadata in between. In that scenario, checking that the backlog is\n  // empty will suffice.\n  // If we are still waiting on data, then the timer will go off eventually and the missing\n  // metadata will be re-requested.\n  if (initial_metadata_received_ && !update_backlog_.size()) {\n    missing_metadata_request_timer_->DisableTimer();\n  }\n\n  return Status::OK();\n}\n\nvoid K8sUpdateHandler::RequestMissingMetadata() {\n  // If there is no backlog, then we don't have any missing metadata that we know of.\n  if (!update_backlog_.size() && initial_metadata_received_) {\n    return;\n  }\n\n  // Send the registration request.\n  // Note that we will re-request an update we already have in the range of [from, to),\n  // because we have to use our current resource version as the `from` value.\n  messages::VizierMessage msg;\n  auto req = msg.mutable_k8s_metadata_message()->mutable_missing_k8s_metadata_request();\n  req->set_selector(update_selector_);\n\n  if (current_update_version_) {\n    // We don't know the resource numbers, but we know they will always be greater by at\n    // least 1 than the most recent one we received. However, we keep it as a 0 if we haven't\n    // received any updates yet.\n    req->set_from_update_version(current_update_version_ + 1);\n  }\n  // Keep this as a 0 if we don't know the upper bound of the range we are asking for.\n  // Note: requesting [from: 0, to: 0) is the same as requesting all\n  if (update_backlog_.size()) {\n    req->set_to_update_version(update_backlog_.top().update_version());\n  }\n\n  auto s = nats_conn()->Publish(msg);\n  if (!s.ok()) {\n    LOG(ERROR) << absl::Substitute(\"Failed to request missing K8s updates, retrying in $0 s\",\n                                   kMissingMetadataTimeout.count());\n  }\n\n  // Enable the timer once we make the request for the initial missing metadata.\n  // It will get disabled if we see all of the initial data in time.\n  missing_metadata_request_timer_->EnableTimer(kMissingMetadataTimeout);\n}\n\nStatus K8sUpdateHandler::HandleK8sUpdate(const ResourceUpdate& update) {\n  if (current_update_version_ == update.prev_update_version()) {\n    return AddK8sUpdate(update);\n  }\n\n  // This was probably a duplicate, ignore.\n  if (current_update_version_ > update.prev_update_version()) {\n    return Status::OK();\n  }\n\n  // If this update is further along than we expect, add it to the backlog.\n  update_backlog_.push(update);\n  // Keep the most recent updates so that we know how far ahead the mds is.\n  // Re-request updates that we dropped once we catch up.\n  if (update_backlog_.size() > max_update_queue_size_) {\n    update_backlog_.pop();\n  }\n\n  // If we have missing metadata (which we do if we have reached this part of the\n  // logic) and we haven't made a recent outbound request for that missing metadata,\n  // we should make that request now.\n  if (!missing_metadata_request_timer_->Enabled()) {\n    RequestMissingMetadata();\n  }\n\n  return Status::OK();\n}\n\nStatus K8sUpdateHandler::HandleMessage(std::unique_ptr<messages::VizierMessage> msg) {\n  LOG_IF(FATAL, !msg->has_k8s_metadata_message()) << \"Expected K8sMetadataMessage\";\n  auto k8s_msg = msg->k8s_metadata_message();\n\n  if (k8s_msg.has_k8s_metadata_update()) {\n    return HandleK8sUpdate(k8s_msg.k8s_metadata_update());\n  }\n  if (k8s_msg.has_missing_k8s_metadata_response()) {\n    return HandleMissingK8sMetadataResponse(k8s_msg.missing_k8s_metadata_response());\n  }\n\n  return error::Internal(\n      \"Expected either ResourceUpdate or MissingK8sMetadataResponse in K8sMetadataMessage\");\n}\n\n}  // namespace agent\n}  // namespace vizier\n}  // namespace px",
    "repo": "pixie-io/pixie",
    "path": "./datasets/diagrams-repos/pixie-io/pixie/src/vizier/services/agent/shared/manager/k8s_update.cc",
    "query": "What is the workflow for requesting missing K8s metadata?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'K8sUpdateHandler', 'node_id': 'K8sUpdateHandler', 'description': 'Handles K8s metadata updates and requests', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'RequestMissingMetadata', 'node_id': 'RequestMissingMetadata', 'description': 'Sends request for missing K8s metadata updates', 'visibility': 'public', 'return_type': 'void', 'params': None, 'source_class_id': 'K8sUpdateHandler'}, {'type': 'method', 'name': 'HandleMissingK8sMetadataResponse', 'node_id': 'HandleMissingK8sMetadataResponse', 'description': 'Processes response with missing K8s metadata', 'visibility': 'public', 'return_type': 'Status', 'params': 'const MissingK8sMetadataResponse& resp', 'source_class_id': 'K8sUpdateHandler'}, {'type': 'method', 'name': 'HandleK8sUpdate', 'node_id': 'HandleK8sUpdate', 'description': 'Processes individual K8s update', 'visibility': 'public', 'return_type': 'Status', 'params': 'const ResourceUpdate& update', 'source_class_id': 'K8sUpdateHandler'}, {'type': 'method', 'name': 'AddK8sUpdate', 'node_id': 'AddK8sUpdate', 'description': 'Adds K8s update to the manager', 'visibility': 'private', 'return_type': 'Status', 'params': 'const ResourceUpdate& update', 'source_class_id': 'K8sUpdateHandler'}, {'type': 'method', 'name': 'HandleMessage', 'node_id': 'HandleMessage', 'description': 'Handles incoming Vizier messages', 'visibility': 'public', 'return_type': 'Status', 'params': 'std::unique_ptr<messages::VizierMessage> msg', 'source_class_id': 'K8sUpdateHandler'}, {'type': 'field', 'name': 'missing_metadata_request_timer_', 'node_id': 'missing_metadata_request_timer_', 'description': 'Timer for scheduling metadata requests', 'visibility': 'private', 'return_type': 'Timer*', 'params': None, 'source_class_id': 'K8sUpdateHandler'}, {'type': 'field', 'name': 'update_backlog_', 'node_id': 'update_backlog_', 'description': 'Queue for out-of-order updates', 'visibility': 'private', 'return_type': 'priority_queue', 'params': None, 'source_class_id': 'K8sUpdateHandler'}, {'type': 'field', 'name': 'current_update_version_', 'node_id': 'current_update_version_', 'description': 'Current update version', 'visibility': 'private', 'return_type': 'int64_t', 'params': None, 'source_class_id': 'K8sUpdateHandler'}, {'type': 'field', 'name': 'initial_metadata_received_', 'node_id': 'initial_metadata_received_', 'description': 'Flag indicating if initial metadata was received', 'visibility': 'private', 'return_type': 'bool', 'params': None, 'source_class_id': 'K8sUpdateHandler'}], 'edges': [{'node_id_from': 'K8sUpdateHandler', 'node_id_to': 'RequestMissingMetadata', 'description': 'owns'}, {'node_id_from': 'HandleMessage', 'node_id_to': 'HandleMissingK8sMetadataResponse', 'description': 'routes metadata response'}, {'node_id_from': 'HandleMessage', 'node_id_to': 'HandleK8sUpdate', 'description': 'routes update'}, {'node_id_from': 'RequestMissingMetadata', 'node_id_to': 'HandleMissingK8sMetadataResponse', 'description': 'triggers request and awaits response'}, {'node_id_from': 'HandleMissingK8sMetadataResponse', 'node_id_to': 'HandleK8sUpdate', 'description': 'processes updates'}, {'node_id_from': 'HandleK8sUpdate', 'node_id_to': 'AddK8sUpdate', 'description': 'adds update'}, {'node_id_from': 'missing_metadata_request_timer_', 'node_id_to': 'RequestMissingMetadata', 'description': 'schedules'}, {'node_id_from': 'K8sUpdateHandler', 'node_id_to': 'missing_metadata_request_timer_', 'description': ''}, {'node_id_from': 'K8sUpdateHandler', 'node_id_to': 'update_backlog_', 'description': ''}, {'node_id_from': 'K8sUpdateHandler', 'node_id_to': 'HandleMessage', 'description': ''}, {'node_id_from': 'K8sUpdateHandler', 'node_id_to': 'current_update_version_', 'description': ''}, {'node_id_from': 'K8sUpdateHandler', 'node_id_to': 'initial_metadata_received_', 'description': ''}, {'node_id_from': 'K8sUpdateHandler', 'node_id_to': 'HandleMissingK8sMetadataResponse', 'description': ''}, {'node_id_from': 'K8sUpdateHandler', 'node_id_to': 'HandleK8sUpdate', 'description': ''}, {'node_id_from': 'K8sUpdateHandler', 'node_id_to': 'AddK8sUpdate', 'description': ''}], 'packages': [{'package_id': 'k8sMetadataHandling', 'children': ['K8sUpdateHandler', 'HandleMessage', 'metadataRequestFlow', 'state'], 'description': 'K8s metadata handling system'}, {'package_id': 'metadataRequestFlow', 'children': ['RequestMissingMetadata', 'HandleMissingK8sMetadataResponse', 'HandleK8sUpdate', 'AddK8sUpdate', 'missing_metadata_request_timer_', 'update_backlog_'], 'description': 'Metadata request and processing workflow'}, {'package_id': 'state', 'children': ['current_update_version_', 'initial_metadata_received_'], 'description': 'State tracking'}]}",
    "version": "full",
    "text_answer": "The missing K8s metadata request workflow starts with RequestMissingMetadata method, which is triggered by a timer. It sends a request for missing updates and awaits response through HandleMissingK8sMetadataResponse, which processes the received updates using HandleK8sUpdate. The system maintains a backlog for out-of-order updates and tracks the current update version to ensure proper synchronization.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage com.facebook.presto.example;\n\nimport com.facebook.presto.spi.ColumnHandle;\nimport com.facebook.presto.spi.ColumnMetadata;\nimport com.facebook.presto.spi.ConnectorSession;\nimport com.facebook.presto.spi.ConnectorTableHandle;\nimport com.facebook.presto.spi.ConnectorTableLayout;\nimport com.facebook.presto.spi.ConnectorTableLayoutHandle;\nimport com.facebook.presto.spi.ConnectorTableLayoutResult;\nimport com.facebook.presto.spi.ConnectorTableMetadata;\nimport com.facebook.presto.spi.Constraint;\nimport com.facebook.presto.spi.SchemaTableName;\nimport com.facebook.presto.spi.SchemaTablePrefix;\nimport com.facebook.presto.spi.TableNotFoundException;\nimport com.facebook.presto.spi.connector.ConnectorMetadata;\nimport com.google.common.collect.ImmutableList;\nimport com.google.common.collect.ImmutableMap;\nimport com.google.common.collect.ImmutableSet;\n\nimport javax.inject.Inject;\n\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Optional;\nimport java.util.Set;\n\nimport static com.google.common.base.Preconditions.checkArgument;\nimport static java.util.Objects.requireNonNull;\n\npublic class ExampleMetadata\n        implements ConnectorMetadata\n{\n    private final String connectorId;\n\n    private final ExampleClient exampleClient;\n\n    @Inject\n    public ExampleMetadata(ExampleConnectorId connectorId, ExampleClient exampleClient)\n    {\n        this.connectorId = requireNonNull(connectorId, \"connectorId is null\").toString();\n        this.exampleClient = requireNonNull(exampleClient, \"client is null\");\n    }\n\n    @Override\n    public List<String> listSchemaNames(ConnectorSession session)\n    {\n        return listSchemaNames();\n    }\n\n    public List<String> listSchemaNames()\n    {\n        return ImmutableList.copyOf(exampleClient.getSchemaNames());\n    }\n\n    @Override\n    public ExampleTableHandle getTableHandle(ConnectorSession session, SchemaTableName tableName)\n    {\n        if (!listSchemaNames(session).contains(tableName.getSchemaName())) {\n            return null;\n        }\n\n        ExampleTable table = exampleClient.getTable(tableName.getSchemaName(), tableName.getTableName());\n        if (table == null) {\n            return null;\n        }\n\n        return new ExampleTableHandle(connectorId, tableName.getSchemaName(), tableName.getTableName());\n    }\n\n    @Override\n    public List<ConnectorTableLayoutResult> getTableLayouts(ConnectorSession session, ConnectorTableHandle table, Constraint<ColumnHandle> constraint, Optional<Set<ColumnHandle>> desiredColumns)\n    {\n        ExampleTableHandle tableHandle = (ExampleTableHandle) table;\n        ConnectorTableLayout layout = new ConnectorTableLayout(new ExampleTableLayoutHandle(tableHandle));\n        return ImmutableList.of(new ConnectorTableLayoutResult(layout, constraint.getSummary()));\n    }\n\n    @Override\n    public ConnectorTableLayout getTableLayout(ConnectorSession session, ConnectorTableLayoutHandle handle)\n    {\n        return new ConnectorTableLayout(handle);\n    }\n\n    @Override\n    public ConnectorTableMetadata getTableMetadata(ConnectorSession session, ConnectorTableHandle table)\n    {\n        ExampleTableHandle exampleTableHandle = (ExampleTableHandle) table;\n        checkArgument(exampleTableHandle.getConnectorId().equals(connectorId), \"tableHandle is not for this connector\");\n        SchemaTableName tableName = new SchemaTableName(exampleTableHandle.getSchemaName(), exampleTableHandle.getTableName());\n\n        return getTableMetadata(tableName);\n    }\n\n    @Override\n    public List<SchemaTableName> listTables(ConnectorSession session, String schemaNameOrNull)\n    {\n        Set<String> schemaNames;\n        if (schemaNameOrNull != null) {\n            schemaNames = ImmutableSet.of(schemaNameOrNull);\n        }\n        else {\n            schemaNames = exampleClient.getSchemaNames();\n        }\n\n        ImmutableList.Builder<SchemaTableName> builder = ImmutableList.builder();\n        for (String schemaName : schemaNames) {\n            for (String tableName : exampleClient.getTableNames(schemaName)) {\n                builder.add(new SchemaTableName(schemaName, tableName));\n            }\n        }\n        return builder.build();\n    }\n\n    @Override\n    public Map<String, ColumnHandle> getColumnHandles(ConnectorSession session, ConnectorTableHandle tableHandle)\n    {\n        ExampleTableHandle exampleTableHandle = (ExampleTableHandle) tableHandle;\n        checkArgument(exampleTableHandle.getConnectorId().equals(connectorId), \"tableHandle is not for this connector\");\n\n        ExampleTable table = exampleClient.getTable(exampleTableHandle.getSchemaName(), exampleTableHandle.getTableName());\n        if (table == null) {\n            throw new TableNotFoundException(exampleTableHandle.toSchemaTableName());\n        }\n\n        ImmutableMap.Builder<String, ColumnHandle> columnHandles = ImmutableMap.builder();\n        int index = 0;\n        for (ColumnMetadata column : table.getColumnsMetadata()) {\n            columnHandles.put(column.getName(), new ExampleColumnHandle(connectorId, column.getName(), column.getType(), index));\n            index++;\n        }\n        return columnHandles.build();\n    }\n\n    @Override\n    public Map<SchemaTableName, List<ColumnMetadata>> listTableColumns(ConnectorSession session, SchemaTablePrefix prefix)\n    {\n        requireNonNull(prefix, \"prefix is null\");\n        ImmutableMap.Builder<SchemaTableName, List<ColumnMetadata>> columns = ImmutableMap.builder();\n        for (SchemaTableName tableName : listTables(session, prefix)) {\n            ConnectorTableMetadata tableMetadata = getTableMetadata(tableName);\n            // table can disappear during listing operation\n            if (tableMetadata != null) {\n                columns.put(tableName, tableMetadata.getColumns());\n            }\n        }\n        return columns.build();\n    }\n\n    private ConnectorTableMetadata getTableMetadata(SchemaTableName tableName)\n    {\n        if (!listSchemaNames().contains(tableName.getSchemaName())) {\n            return null;\n        }\n\n        ExampleTable table = exampleClient.getTable(tableName.getSchemaName(), tableName.getTableName());\n        if (table == null) {\n            return null;\n        }\n\n        return new ConnectorTableMetadata(tableName, table.getColumnsMetadata());\n    }\n\n    private List<SchemaTableName> listTables(ConnectorSession session, SchemaTablePrefix prefix)\n    {\n        if (prefix.getSchemaName() == null) {\n            return listTables(session, prefix.getSchemaName());\n        }\n        return ImmutableList.of(new SchemaTableName(prefix.getSchemaName(), prefix.getTableName()));\n    }\n\n    @Override\n    public ColumnMetadata getColumnMetadata(ConnectorSession session, ConnectorTableHandle tableHandle, ColumnHandle columnHandle)\n    {\n        return ((ExampleColumnHandle) columnHandle).getColumnMetadata();\n    }\n}",
    "repo": "prestodb/presto",
    "path": "./datasets/diagrams-repos/prestodb/presto/presto-example-http/src/main/java/com/facebook/presto/example/ExampleMetadata.java",
    "query": "What is the sequence of method calls when retrieving table metadata?",
    "diagram": "{'nodes': [{'type': 'method', 'name': 'getTableMetadata', 'node_id': 'getTableMetadata', 'description': 'Main method to retrieve table metadata for a given table handle', 'visibility': 'public', 'return_type': 'ConnectorTableMetadata', 'params': 'ConnectorSession session, ConnectorTableHandle table', 'source_class_id': 'ExampleMetadata'}, {'type': 'method', 'name': 'getTableMetadata', 'node_id': 'getTableMetadataInternal', 'description': 'Internal helper method to get table metadata by table name', 'visibility': 'private', 'return_type': 'ConnectorTableMetadata', 'params': 'SchemaTableName tableName', 'source_class_id': 'ExampleMetadata'}, {'type': 'method', 'name': 'getTable', 'node_id': 'getTable', 'description': 'Retrieves table information from example client', 'visibility': 'public', 'return_type': 'ExampleTable', 'params': 'String schemaName, String tableName', 'source_class_id': 'ExampleClient'}, {'type': 'class', 'name': 'ExampleMetadata', 'node_id': 'ExampleMetadata', 'description': 'Main metadata handler class', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'ExampleClient', 'node_id': 'ExampleClient', 'description': 'Client for accessing example data source', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'getTableMetadata', 'node_id_to': 'getTableMetadataInternal', 'description': 'calls'}, {'node_id_from': 'getTableMetadataInternal', 'node_id_to': 'getTable', 'description': 'calls'}, {'node_id_from': 'ExampleMetadata', 'node_id_to': 'ExampleClient', 'description': 'contains'}, {'node_id_from': 'ExampleMetadata', 'node_id_to': 'getTableMetadata', 'description': ''}, {'node_id_from': 'ExampleMetadata', 'node_id_to': 'getTableMetadataInternal', 'description': ''}, {'node_id_from': 'ExampleClient', 'node_id_to': 'getTable', 'description': ''}], 'packages': [{'package_id': 'metadata', 'children': ['getTableMetadata', 'getTableMetadataInternal'], 'description': 'Table metadata related methods'}]}",
    "version": "minimal",
    "text_answer": "When retrieving table metadata, the process starts with getTableMetadata() method, which calls private getTableMetadataInternal(). The latter validates schema existence using listSchemaNames() and then retrieves table information through exampleClient.getTable(). If table exists, its metadata including columns information is returned.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage com.facebook.presto.example;\n\nimport com.facebook.presto.spi.ColumnHandle;\nimport com.facebook.presto.spi.ColumnMetadata;\nimport com.facebook.presto.spi.ConnectorSession;\nimport com.facebook.presto.spi.ConnectorTableHandle;\nimport com.facebook.presto.spi.ConnectorTableLayout;\nimport com.facebook.presto.spi.ConnectorTableLayoutHandle;\nimport com.facebook.presto.spi.ConnectorTableLayoutResult;\nimport com.facebook.presto.spi.ConnectorTableMetadata;\nimport com.facebook.presto.spi.Constraint;\nimport com.facebook.presto.spi.SchemaTableName;\nimport com.facebook.presto.spi.SchemaTablePrefix;\nimport com.facebook.presto.spi.TableNotFoundException;\nimport com.facebook.presto.spi.connector.ConnectorMetadata;\nimport com.google.common.collect.ImmutableList;\nimport com.google.common.collect.ImmutableMap;\nimport com.google.common.collect.ImmutableSet;\n\nimport javax.inject.Inject;\n\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Optional;\nimport java.util.Set;\n\nimport static com.google.common.base.Preconditions.checkArgument;\nimport static java.util.Objects.requireNonNull;\n\npublic class ExampleMetadata\n        implements ConnectorMetadata\n{\n    private final String connectorId;\n\n    private final ExampleClient exampleClient;\n\n    @Inject\n    public ExampleMetadata(ExampleConnectorId connectorId, ExampleClient exampleClient)\n    {\n        this.connectorId = requireNonNull(connectorId, \"connectorId is null\").toString();\n        this.exampleClient = requireNonNull(exampleClient, \"client is null\");\n    }\n\n    @Override\n    public List<String> listSchemaNames(ConnectorSession session)\n    {\n        return listSchemaNames();\n    }\n\n    public List<String> listSchemaNames()\n    {\n        return ImmutableList.copyOf(exampleClient.getSchemaNames());\n    }\n\n    @Override\n    public ExampleTableHandle getTableHandle(ConnectorSession session, SchemaTableName tableName)\n    {\n        if (!listSchemaNames(session).contains(tableName.getSchemaName())) {\n            return null;\n        }\n\n        ExampleTable table = exampleClient.getTable(tableName.getSchemaName(), tableName.getTableName());\n        if (table == null) {\n            return null;\n        }\n\n        return new ExampleTableHandle(connectorId, tableName.getSchemaName(), tableName.getTableName());\n    }\n\n    @Override\n    public List<ConnectorTableLayoutResult> getTableLayouts(ConnectorSession session, ConnectorTableHandle table, Constraint<ColumnHandle> constraint, Optional<Set<ColumnHandle>> desiredColumns)\n    {\n        ExampleTableHandle tableHandle = (ExampleTableHandle) table;\n        ConnectorTableLayout layout = new ConnectorTableLayout(new ExampleTableLayoutHandle(tableHandle));\n        return ImmutableList.of(new ConnectorTableLayoutResult(layout, constraint.getSummary()));\n    }\n\n    @Override\n    public ConnectorTableLayout getTableLayout(ConnectorSession session, ConnectorTableLayoutHandle handle)\n    {\n        return new ConnectorTableLayout(handle);\n    }\n\n    @Override\n    public ConnectorTableMetadata getTableMetadata(ConnectorSession session, ConnectorTableHandle table)\n    {\n        ExampleTableHandle exampleTableHandle = (ExampleTableHandle) table;\n        checkArgument(exampleTableHandle.getConnectorId().equals(connectorId), \"tableHandle is not for this connector\");\n        SchemaTableName tableName = new SchemaTableName(exampleTableHandle.getSchemaName(), exampleTableHandle.getTableName());\n\n        return getTableMetadata(tableName);\n    }\n\n    @Override\n    public List<SchemaTableName> listTables(ConnectorSession session, String schemaNameOrNull)\n    {\n        Set<String> schemaNames;\n        if (schemaNameOrNull != null) {\n            schemaNames = ImmutableSet.of(schemaNameOrNull);\n        }\n        else {\n            schemaNames = exampleClient.getSchemaNames();\n        }\n\n        ImmutableList.Builder<SchemaTableName> builder = ImmutableList.builder();\n        for (String schemaName : schemaNames) {\n            for (String tableName : exampleClient.getTableNames(schemaName)) {\n                builder.add(new SchemaTableName(schemaName, tableName));\n            }\n        }\n        return builder.build();\n    }\n\n    @Override\n    public Map<String, ColumnHandle> getColumnHandles(ConnectorSession session, ConnectorTableHandle tableHandle)\n    {\n        ExampleTableHandle exampleTableHandle = (ExampleTableHandle) tableHandle;\n        checkArgument(exampleTableHandle.getConnectorId().equals(connectorId), \"tableHandle is not for this connector\");\n\n        ExampleTable table = exampleClient.getTable(exampleTableHandle.getSchemaName(), exampleTableHandle.getTableName());\n        if (table == null) {\n            throw new TableNotFoundException(exampleTableHandle.toSchemaTableName());\n        }\n\n        ImmutableMap.Builder<String, ColumnHandle> columnHandles = ImmutableMap.builder();\n        int index = 0;\n        for (ColumnMetadata column : table.getColumnsMetadata()) {\n            columnHandles.put(column.getName(), new ExampleColumnHandle(connectorId, column.getName(), column.getType(), index));\n            index++;\n        }\n        return columnHandles.build();\n    }\n\n    @Override\n    public Map<SchemaTableName, List<ColumnMetadata>> listTableColumns(ConnectorSession session, SchemaTablePrefix prefix)\n    {\n        requireNonNull(prefix, \"prefix is null\");\n        ImmutableMap.Builder<SchemaTableName, List<ColumnMetadata>> columns = ImmutableMap.builder();\n        for (SchemaTableName tableName : listTables(session, prefix)) {\n            ConnectorTableMetadata tableMetadata = getTableMetadata(tableName);\n            // table can disappear during listing operation\n            if (tableMetadata != null) {\n                columns.put(tableName, tableMetadata.getColumns());\n            }\n        }\n        return columns.build();\n    }\n\n    private ConnectorTableMetadata getTableMetadata(SchemaTableName tableName)\n    {\n        if (!listSchemaNames().contains(tableName.getSchemaName())) {\n            return null;\n        }\n\n        ExampleTable table = exampleClient.getTable(tableName.getSchemaName(), tableName.getTableName());\n        if (table == null) {\n            return null;\n        }\n\n        return new ConnectorTableMetadata(tableName, table.getColumnsMetadata());\n    }\n\n    private List<SchemaTableName> listTables(ConnectorSession session, SchemaTablePrefix prefix)\n    {\n        if (prefix.getSchemaName() == null) {\n            return listTables(session, prefix.getSchemaName());\n        }\n        return ImmutableList.of(new SchemaTableName(prefix.getSchemaName(), prefix.getTableName()));\n    }\n\n    @Override\n    public ColumnMetadata getColumnMetadata(ConnectorSession session, ConnectorTableHandle tableHandle, ColumnHandle columnHandle)\n    {\n        return ((ExampleColumnHandle) columnHandle).getColumnMetadata();\n    }\n}",
    "repo": "prestodb/presto",
    "path": "./datasets/diagrams-repos/prestodb/presto/presto-example-http/src/main/java/com/facebook/presto/example/ExampleMetadata.java",
    "query": "What is the sequence of method calls when retrieving table metadata?",
    "diagram": "{'nodes': [{'type': 'method', 'name': 'getTableMetadata', 'node_id': 'getTableMetadata', 'description': 'Main method to retrieve table metadata for a given table handle', 'visibility': 'public', 'return_type': 'ConnectorTableMetadata', 'params': 'ConnectorSession session, ConnectorTableHandle table', 'source_class_id': 'ExampleMetadata'}, {'type': 'method', 'name': 'getTableMetadata', 'node_id': 'getTableMetadataInternal', 'description': 'Internal helper method to get table metadata by table name', 'visibility': 'private', 'return_type': 'ConnectorTableMetadata', 'params': 'SchemaTableName tableName', 'source_class_id': 'ExampleMetadata'}, {'type': 'method', 'name': 'listSchemaNames', 'node_id': 'listSchemaNames', 'description': 'Lists all available schema names', 'visibility': 'public', 'return_type': 'List<String>', 'params': '', 'source_class_id': 'ExampleMetadata'}, {'type': 'method', 'name': 'getTable', 'node_id': 'getTable', 'description': 'Retrieves table information from example client', 'visibility': 'public', 'return_type': 'ExampleTable', 'params': 'String schemaName, String tableName', 'source_class_id': 'ExampleClient'}, {'type': 'class', 'name': 'ExampleClient', 'node_id': 'ExampleClient', 'description': 'Client for accessing example data source', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'ExampleMetadata', 'node_id': 'ExampleMetadata', 'description': 'Main metadata handler class', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'getTableMetadata', 'node_id_to': 'getTableMetadataInternal', 'description': 'calls'}, {'node_id_from': 'getTableMetadataInternal', 'node_id_to': 'listSchemaNames', 'description': 'validates schema'}, {'node_id_from': 'getTableMetadataInternal', 'node_id_to': 'getTable', 'description': 'retrieves table'}, {'node_id_from': 'ExampleMetadata', 'node_id_to': 'ExampleClient', 'description': 'contains'}, {'node_id_from': 'ExampleMetadata', 'node_id_to': 'getTableMetadata', 'description': ''}, {'node_id_from': 'ExampleMetadata', 'node_id_to': 'getTableMetadataInternal', 'description': ''}, {'node_id_from': 'ExampleMetadata', 'node_id_to': 'listSchemaNames', 'description': ''}, {'node_id_from': 'ExampleClient', 'node_id_to': 'getTable', 'description': ''}], 'packages': [{'package_id': 'metadata', 'children': ['getTableMetadata', 'getTableMetadataInternal', 'listSchemaNames'], 'description': 'Table metadata related methods'}, {'package_id': 'client', 'children': ['ExampleClient', 'getTable'], 'description': 'Client-related components'}]}",
    "version": "medium",
    "text_answer": "When retrieving table metadata, the process starts with getTableMetadata() method, which calls private getTableMetadataInternal(). The latter validates schema existence using listSchemaNames() and then retrieves table information through exampleClient.getTable(). If table exists, its metadata including columns information is returned.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage com.facebook.presto.example;\n\nimport com.facebook.presto.spi.ColumnHandle;\nimport com.facebook.presto.spi.ColumnMetadata;\nimport com.facebook.presto.spi.ConnectorSession;\nimport com.facebook.presto.spi.ConnectorTableHandle;\nimport com.facebook.presto.spi.ConnectorTableLayout;\nimport com.facebook.presto.spi.ConnectorTableLayoutHandle;\nimport com.facebook.presto.spi.ConnectorTableLayoutResult;\nimport com.facebook.presto.spi.ConnectorTableMetadata;\nimport com.facebook.presto.spi.Constraint;\nimport com.facebook.presto.spi.SchemaTableName;\nimport com.facebook.presto.spi.SchemaTablePrefix;\nimport com.facebook.presto.spi.TableNotFoundException;\nimport com.facebook.presto.spi.connector.ConnectorMetadata;\nimport com.google.common.collect.ImmutableList;\nimport com.google.common.collect.ImmutableMap;\nimport com.google.common.collect.ImmutableSet;\n\nimport javax.inject.Inject;\n\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Optional;\nimport java.util.Set;\n\nimport static com.google.common.base.Preconditions.checkArgument;\nimport static java.util.Objects.requireNonNull;\n\npublic class ExampleMetadata\n        implements ConnectorMetadata\n{\n    private final String connectorId;\n\n    private final ExampleClient exampleClient;\n\n    @Inject\n    public ExampleMetadata(ExampleConnectorId connectorId, ExampleClient exampleClient)\n    {\n        this.connectorId = requireNonNull(connectorId, \"connectorId is null\").toString();\n        this.exampleClient = requireNonNull(exampleClient, \"client is null\");\n    }\n\n    @Override\n    public List<String> listSchemaNames(ConnectorSession session)\n    {\n        return listSchemaNames();\n    }\n\n    public List<String> listSchemaNames()\n    {\n        return ImmutableList.copyOf(exampleClient.getSchemaNames());\n    }\n\n    @Override\n    public ExampleTableHandle getTableHandle(ConnectorSession session, SchemaTableName tableName)\n    {\n        if (!listSchemaNames(session).contains(tableName.getSchemaName())) {\n            return null;\n        }\n\n        ExampleTable table = exampleClient.getTable(tableName.getSchemaName(), tableName.getTableName());\n        if (table == null) {\n            return null;\n        }\n\n        return new ExampleTableHandle(connectorId, tableName.getSchemaName(), tableName.getTableName());\n    }\n\n    @Override\n    public List<ConnectorTableLayoutResult> getTableLayouts(ConnectorSession session, ConnectorTableHandle table, Constraint<ColumnHandle> constraint, Optional<Set<ColumnHandle>> desiredColumns)\n    {\n        ExampleTableHandle tableHandle = (ExampleTableHandle) table;\n        ConnectorTableLayout layout = new ConnectorTableLayout(new ExampleTableLayoutHandle(tableHandle));\n        return ImmutableList.of(new ConnectorTableLayoutResult(layout, constraint.getSummary()));\n    }\n\n    @Override\n    public ConnectorTableLayout getTableLayout(ConnectorSession session, ConnectorTableLayoutHandle handle)\n    {\n        return new ConnectorTableLayout(handle);\n    }\n\n    @Override\n    public ConnectorTableMetadata getTableMetadata(ConnectorSession session, ConnectorTableHandle table)\n    {\n        ExampleTableHandle exampleTableHandle = (ExampleTableHandle) table;\n        checkArgument(exampleTableHandle.getConnectorId().equals(connectorId), \"tableHandle is not for this connector\");\n        SchemaTableName tableName = new SchemaTableName(exampleTableHandle.getSchemaName(), exampleTableHandle.getTableName());\n\n        return getTableMetadata(tableName);\n    }\n\n    @Override\n    public List<SchemaTableName> listTables(ConnectorSession session, String schemaNameOrNull)\n    {\n        Set<String> schemaNames;\n        if (schemaNameOrNull != null) {\n            schemaNames = ImmutableSet.of(schemaNameOrNull);\n        }\n        else {\n            schemaNames = exampleClient.getSchemaNames();\n        }\n\n        ImmutableList.Builder<SchemaTableName> builder = ImmutableList.builder();\n        for (String schemaName : schemaNames) {\n            for (String tableName : exampleClient.getTableNames(schemaName)) {\n                builder.add(new SchemaTableName(schemaName, tableName));\n            }\n        }\n        return builder.build();\n    }\n\n    @Override\n    public Map<String, ColumnHandle> getColumnHandles(ConnectorSession session, ConnectorTableHandle tableHandle)\n    {\n        ExampleTableHandle exampleTableHandle = (ExampleTableHandle) tableHandle;\n        checkArgument(exampleTableHandle.getConnectorId().equals(connectorId), \"tableHandle is not for this connector\");\n\n        ExampleTable table = exampleClient.getTable(exampleTableHandle.getSchemaName(), exampleTableHandle.getTableName());\n        if (table == null) {\n            throw new TableNotFoundException(exampleTableHandle.toSchemaTableName());\n        }\n\n        ImmutableMap.Builder<String, ColumnHandle> columnHandles = ImmutableMap.builder();\n        int index = 0;\n        for (ColumnMetadata column : table.getColumnsMetadata()) {\n            columnHandles.put(column.getName(), new ExampleColumnHandle(connectorId, column.getName(), column.getType(), index));\n            index++;\n        }\n        return columnHandles.build();\n    }\n\n    @Override\n    public Map<SchemaTableName, List<ColumnMetadata>> listTableColumns(ConnectorSession session, SchemaTablePrefix prefix)\n    {\n        requireNonNull(prefix, \"prefix is null\");\n        ImmutableMap.Builder<SchemaTableName, List<ColumnMetadata>> columns = ImmutableMap.builder();\n        for (SchemaTableName tableName : listTables(session, prefix)) {\n            ConnectorTableMetadata tableMetadata = getTableMetadata(tableName);\n            // table can disappear during listing operation\n            if (tableMetadata != null) {\n                columns.put(tableName, tableMetadata.getColumns());\n            }\n        }\n        return columns.build();\n    }\n\n    private ConnectorTableMetadata getTableMetadata(SchemaTableName tableName)\n    {\n        if (!listSchemaNames().contains(tableName.getSchemaName())) {\n            return null;\n        }\n\n        ExampleTable table = exampleClient.getTable(tableName.getSchemaName(), tableName.getTableName());\n        if (table == null) {\n            return null;\n        }\n\n        return new ConnectorTableMetadata(tableName, table.getColumnsMetadata());\n    }\n\n    private List<SchemaTableName> listTables(ConnectorSession session, SchemaTablePrefix prefix)\n    {\n        if (prefix.getSchemaName() == null) {\n            return listTables(session, prefix.getSchemaName());\n        }\n        return ImmutableList.of(new SchemaTableName(prefix.getSchemaName(), prefix.getTableName()));\n    }\n\n    @Override\n    public ColumnMetadata getColumnMetadata(ConnectorSession session, ConnectorTableHandle tableHandle, ColumnHandle columnHandle)\n    {\n        return ((ExampleColumnHandle) columnHandle).getColumnMetadata();\n    }\n}",
    "repo": "prestodb/presto",
    "path": "./datasets/diagrams-repos/prestodb/presto/presto-example-http/src/main/java/com/facebook/presto/example/ExampleMetadata.java",
    "query": "What is the sequence of method calls when retrieving table metadata?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'ExampleMetadata', 'node_id': 'ExampleMetadata', 'description': 'Main metadata handler class', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'connectorId', 'node_id': 'connectorId', 'description': 'Unique identifier for the connector', 'visibility': 'private', 'return_type': 'String', 'params': None, 'source_class_id': 'ExampleMetadata'}, {'type': 'field', 'name': 'exampleClient', 'node_id': 'exampleClient', 'description': 'Client instance for data access', 'visibility': 'private', 'return_type': 'ExampleClient', 'params': None, 'source_class_id': 'ExampleMetadata'}, {'type': 'method', 'name': 'getTableMetadata', 'node_id': 'getTableMetadata', 'description': 'Main method to retrieve table metadata for a given table handle', 'visibility': 'public', 'return_type': 'ConnectorTableMetadata', 'params': 'ConnectorSession session, ConnectorTableHandle table', 'source_class_id': 'ExampleMetadata'}, {'type': 'method', 'name': 'getTableMetadata', 'node_id': 'getTableMetadataInternal', 'description': 'Internal helper method to get table metadata by table name', 'visibility': 'private', 'return_type': 'ConnectorTableMetadata', 'params': 'SchemaTableName tableName', 'source_class_id': 'ExampleMetadata'}, {'type': 'method', 'name': 'listSchemaNames', 'node_id': 'listSchemaNames', 'description': 'Lists all available schema names', 'visibility': 'public', 'return_type': 'List<String>', 'params': '', 'source_class_id': 'ExampleMetadata'}, {'type': 'method', 'name': 'getTable', 'node_id': 'getTable', 'description': 'Retrieves table information from example client', 'visibility': 'public', 'return_type': 'ExampleTable', 'params': 'String schemaName, String tableName', 'source_class_id': 'ExampleClient'}, {'type': 'class', 'name': 'ExampleTable', 'node_id': 'ExampleTable', 'description': 'Represents table structure', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'method', 'name': 'getColumnsMetadata', 'node_id': 'getColumnsMetadata', 'description': 'Returns columns metadata for table', 'visibility': 'public', 'return_type': 'List<ColumnMetadata>', 'params': '', 'source_class_id': 'ExampleTable'}, {'type': 'class', 'name': 'ExampleClient', 'node_id': 'ExampleClient', 'description': 'Client for accessing example data source', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'getTableMetadata', 'node_id_to': 'getTableMetadataInternal', 'description': 'calls'}, {'node_id_from': 'getTableMetadataInternal', 'node_id_to': 'listSchemaNames', 'description': 'validates schema'}, {'node_id_from': 'getTableMetadataInternal', 'node_id_to': 'getTable', 'description': 'retrieves table'}, {'node_id_from': 'ExampleMetadata', 'node_id_to': 'exampleClient', 'description': 'has'}, {'node_id_from': 'getTable', 'node_id_to': 'ExampleTable', 'description': 'returns'}, {'node_id_from': 'ExampleTable', 'node_id_to': 'getColumnsMetadata', 'description': 'provides'}, {'node_id_from': 'exampleClient', 'node_id_to': 'ExampleClient', 'description': 'instance of'}, {'node_id_from': 'ExampleMetadata', 'node_id_to': 'getTableMetadata', 'description': ''}, {'node_id_from': 'ExampleMetadata', 'node_id_to': 'connectorId', 'description': ''}, {'node_id_from': 'ExampleMetadata', 'node_id_to': 'getTableMetadataInternal', 'description': ''}, {'node_id_from': 'ExampleMetadata', 'node_id_to': 'listSchemaNames', 'description': ''}, {'node_id_from': 'ExampleClient', 'node_id_to': 'getTable', 'description': ''}], 'packages': [{'package_id': 'metadata', 'children': ['ExampleMetadata', 'getTableMetadata', 'getTableMetadataInternal', 'listSchemaNames', 'connectorId', 'exampleClient'], 'description': 'Metadata handling components'}, {'package_id': 'client', 'children': ['ExampleClient', 'getTable'], 'description': 'Client-related components'}, {'package_id': 'model', 'children': ['ExampleTable', 'getColumnsMetadata'], 'description': 'Data model components'}]}",
    "version": "full",
    "text_answer": "When retrieving table metadata, the process starts with getTableMetadata() method, which calls private getTableMetadataInternal(). The latter validates schema existence using listSchemaNames() and then retrieves table information through exampleClient.getTable(). If table exists, its metadata including columns information is returned.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C",
    "code": "\n#include <zephyr/drivers/comparator.h>\n#include <zephyr/drivers/comparator/fake_comp.h>\n#include <zephyr/fff.h>\n#include <zephyr/kernel.h>\n#include <zephyr/shell/shell.h>\n#include <zephyr/shell/shell_dummy.h>\n#include <zephyr/ztest.h>\n\nDEFINE_FFF_GLOBALS;\n\n#define FAKE_COMP_NODE DT_NODELABEL(fake_comp)\n#define FAKE_COMP_NAME DEVICE_DT_NAME(FAKE_COMP_NODE)\n\n#define TEST_TRIGGER_DELAY K_SECONDS(1)\n\n#define TEST_AWAIT_TRIGGER_TIMEOUT_BELOW_MIN_CMD \\\n\t(\"comp await_trigger \" FAKE_COMP_NAME \" 0\")\n\n#define TEST_AWAIT_TRIGGER_TIMEOUT_ABOVE_MAX_CMD\t\t\t\t\t\t\\\n\t(\"comp await_trigger \" FAKE_COMP_NAME \" \"\t\t\t\t\t\t\\\n\t STRINGIFY(CONFIG_COMPARATOR_SHELL_AWAIT_TRIGGER_MAX_TIMEOUT + 1))\n\n#define TEST_AWAIT_TRIGGER_TIMEOUT_BROKEN_CMD \\\n\t(\"comp await_trigger \" FAKE_COMP_NAME \" d\")\n\nstatic const struct shell *test_sh;\nstatic const struct device *test_dev = DEVICE_DT_GET(FAKE_COMP_NODE);\nstatic comparator_callback_t test_callback;\nstatic void *test_callback_user_data;\nstatic struct k_spinlock test_callback_spinlock;\nstatic struct k_work_delayable test_trigger_dwork;\n\nstatic int test_get_output_stub_1(const struct device *dev)\n{\n\tARG_UNUSED(dev);\n\n\treturn 1;\n}\n\nstatic int test_get_output_stub_0(const struct device *dev)\n{\n\tARG_UNUSED(dev);\n\n\treturn 0;\n}\n\nstatic int test_get_output_stub_eio(const struct device *dev)\n{\n\tARG_UNUSED(dev);\n\n\treturn -EIO;\n}\n\nstatic int test_set_trigger_stub_ok(const struct device *dev, enum comparator_trigger trigger)\n{\n\tARG_UNUSED(dev);\n\tARG_UNUSED(trigger);\n\n\treturn 0;\n}\n\nstatic int test_set_trigger_stub_eio(const struct device *dev, enum comparator_trigger trigger)\n{\n\tARG_UNUSED(dev);\n\tARG_UNUSED(trigger);\n\n\treturn -EIO;\n}\n\nstatic int test_set_trigger_callback_mock_0(const struct device *dev,\n\t\t\t\t\t    comparator_callback_t callback,\n\t\t\t\t\t    void *user_data)\n{\n\tARG_UNUSED(dev);\n\n\tK_SPINLOCK(&test_callback_spinlock) {\n\t\ttest_callback = callback;\n\t\ttest_callback_user_data = user_data;\n\t}\n\n\treturn 0;\n}\n\nstatic int test_set_trigger_callback_stub_0(const struct device *dev,\n\t\t\t\t\t    comparator_callback_t callback,\n\t\t\t\t\t    void *user_data)\n{\n\tARG_UNUSED(dev);\n\tARG_UNUSED(callback);\n\tARG_UNUSED(user_data);\n\n\treturn 0;\n}\n\nstatic int test_set_trigger_callback_stub_eio(const struct device *dev,\n\t\t\t\t\t      comparator_callback_t callback,\n\t\t\t\t\t      void *user_data)\n{\n\tARG_UNUSED(dev);\n\tARG_UNUSED(callback);\n\tARG_UNUSED(user_data);\n\n\treturn -EIO;\n}\n\nstatic int test_trigger_is_pending_stub_1(const struct device *dev)\n{\n\tARG_UNUSED(dev);\n\n\treturn 1;\n}\n\nstatic int test_trigger_is_pending_stub_0(const struct device *dev)\n{\n\tARG_UNUSED(dev);\n\n\treturn 0;\n}\n\nstatic int test_trigger_is_pending_stub_eio(const struct device *dev)\n{\n\tARG_UNUSED(dev);\n\n\treturn -EIO;\n}\n\n\nstatic void test_trigger_handler(struct k_work *work)\n{\n\tARG_UNUSED(work);\n\n\ttest_callback(test_dev, test_callback_user_data);\n}\n\nstatic void test_schedule_trigger(void)\n{\n\tk_work_schedule(&test_trigger_dwork, TEST_TRIGGER_DELAY);\n}\n\nstatic void test_cancel_trigger(void)\n{\n\tstruct k_work_sync sync;\n\n\tk_work_cancel_delayable_sync(&test_trigger_dwork, &sync);\n}\n\nstatic void *test_setup(void)\n{\n\tk_work_init_delayable(&test_trigger_dwork, test_trigger_handler);\n\ttest_sh = shell_backend_dummy_get_ptr();\n\tWAIT_FOR(shell_ready(test_sh), 20000, k_msleep(1));\n\tzassert_true(shell_ready(test_sh), \"timed out waiting for dummy shell backend\");\n\treturn NULL;\n}\n\nstatic void test_after(void *f)\n{\n\tARG_UNUSED(f);\n\n\ttest_cancel_trigger();\n}\n\nZTEST(comparator_shell, test_get_output)\n{\n\tint ret;\n\tconst char *out;\n\tsize_t out_size;\n\n\tshell_backend_dummy_clear_output(test_sh);\n\tcomp_fake_comp_get_output_fake.custom_fake = test_get_output_stub_1;\n\tret = shell_execute_cmd(test_sh, \"comp get_output \" FAKE_COMP_NAME);\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_get_output_fake.call_count, 1);\n\tzassert_equal(comp_fake_comp_get_output_fake.arg0_val, test_dev);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\n1\\r\\n\");\n\n\tcomp_fake_comp_get_output_fake.custom_fake = test_get_output_stub_0;\n\tret = shell_execute_cmd(test_sh, \"comp get_output \" FAKE_COMP_NAME);\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_get_output_fake.call_count, 2);\n\tzassert_equal(comp_fake_comp_get_output_fake.arg0_val, test_dev);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\n0\\r\\n\");\n\n\tcomp_fake_comp_get_output_fake.custom_fake = test_get_output_stub_eio;\n\tret = shell_execute_cmd(test_sh, \"comp get_output \" FAKE_COMP_NAME);\n\tzassert_equal(ret, -EIO);\n\tzassert_equal(comp_fake_comp_get_output_fake.call_count, 3);\n\tzassert_equal(comp_fake_comp_get_output_fake.arg0_val, test_dev);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\nfailed to get output\\r\\n\");\n}\n\nZTEST(comparator_shell, test_set_trigger)\n{\n\tint ret;\n\tconst char *out;\n\tsize_t out_size;\n\n\tcomp_fake_comp_set_trigger_fake.custom_fake = test_set_trigger_stub_ok;\n\n\tret = shell_execute_cmd(test_sh, \"comp set_trigger \" FAKE_COMP_NAME \" NONE\");\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.call_count, 1);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg0_val, test_dev);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg1_val, COMPARATOR_TRIGGER_NONE);\n\n\tret = shell_execute_cmd(test_sh, \"comp set_trigger \" FAKE_COMP_NAME \" RISING_EDGE\");\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.call_count, 2);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg0_val, test_dev);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg1_val, COMPARATOR_TRIGGER_RISING_EDGE);\n\n\tret = shell_execute_cmd(test_sh, \"comp set_trigger \" FAKE_COMP_NAME \" FALLING_EDGE\");\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.call_count, 3);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg0_val, test_dev);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg1_val, COMPARATOR_TRIGGER_FALLING_EDGE);\n\n\tret = shell_execute_cmd(test_sh, \"comp set_trigger \" FAKE_COMP_NAME \" BOTH_EDGES\");\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.call_count, 4);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg0_val, test_dev);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg1_val, COMPARATOR_TRIGGER_BOTH_EDGES);\n\n\tret = shell_execute_cmd(test_sh, \"comp set_trigger \" FAKE_COMP_NAME \" INVALID\");\n\tzassert_equal(ret, -EINVAL);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.call_count, 4);\n\n\tcomp_fake_comp_set_trigger_fake.custom_fake = test_set_trigger_stub_eio;\n\n\tshell_backend_dummy_clear_output(test_sh);\n\tret = shell_execute_cmd(test_sh, \"comp set_trigger \" FAKE_COMP_NAME \" BOTH_EDGES\");\n\tzassert_equal(ret, -EIO);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.call_count, 5);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg0_val, test_dev);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg1_val, COMPARATOR_TRIGGER_BOTH_EDGES);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\nfailed to set trigger\\r\\n\");\n}\n\nZTEST(comparator_shell, test_await_trigger_set_callback_fail)\n{\n\tint ret;\n\tconst char *out;\n\tsize_t out_size;\n\n\tshell_backend_dummy_clear_output(test_sh);\n\tcomp_fake_comp_set_trigger_callback_fake.custom_fake = test_set_trigger_callback_stub_eio;\n\tret = shell_execute_cmd(test_sh, \"comp await_trigger \" FAKE_COMP_NAME);\n\tzassert_ok(0);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.call_count, 1);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.return_val, 0);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\nfailed to set trigger callback\\r\\n\");\n}\n\nZTEST(comparator_shell, test_await_trigger_timeout)\n{\n\tint ret;\n\tconst char *out;\n\tsize_t out_size;\n\n\tshell_backend_dummy_clear_output(test_sh);\n\tcomp_fake_comp_set_trigger_callback_fake.custom_fake = test_set_trigger_callback_stub_0;\n\tret = shell_execute_cmd(test_sh, \"comp await_trigger \" FAKE_COMP_NAME);\n\tzassert_ok(0);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.call_count, 2);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.return_val_history[0], 0);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.return_val_history[1], 0);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\ntimed out\\r\\n\");\n}\n\nZTEST(comparator_shell, test_await_trigger_invalid_timeout_arg)\n{\n\tint ret;\n\n\tret = shell_execute_cmd(test_sh, TEST_AWAIT_TRIGGER_TIMEOUT_BELOW_MIN_CMD);\n\tzassert_not_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.call_count, 0);\n\n\tret = shell_execute_cmd(test_sh, TEST_AWAIT_TRIGGER_TIMEOUT_ABOVE_MAX_CMD);\n\tzassert_not_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.call_count, 0);\n\n\tret = shell_execute_cmd(test_sh, TEST_AWAIT_TRIGGER_TIMEOUT_BROKEN_CMD);\n\tzassert_not_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.call_count, 0);\n}\n\nZTEST(comparator_shell, test_await_trigger)\n{\n\tint ret;\n\tconst char *out;\n\tsize_t out_size;\n\tcomparator_api_set_trigger_callback seq[2];\n\n\tshell_backend_dummy_clear_output(test_sh);\n\tseq[0] = test_set_trigger_callback_mock_0;\n\tseq[1] = test_set_trigger_callback_stub_0;\n\tcomp_fake_comp_set_trigger_callback_fake.custom_fake_seq = seq;\n\tcomp_fake_comp_set_trigger_callback_fake.custom_fake_seq_len = ARRAY_SIZE(seq);\n\ttest_schedule_trigger();\n\tret = shell_execute_cmd(test_sh, \"comp await_trigger \" FAKE_COMP_NAME);\n\tzassert_ok(0);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.call_count, 2);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.arg0_history[0], test_dev);\n\tzassert_not_equal(comp_fake_comp_set_trigger_callback_fake.arg1_history[0], NULL);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.return_val_history[0], 0);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.arg0_history[1], test_dev);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.arg1_history[1], NULL);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.return_val_history[1], 0);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\ntriggered\\r\\n\");\n}\n\nZTEST(comparator_shell, test_trigger_is_pending)\n{\n\tint ret;\n\tconst char *out;\n\tsize_t out_size;\n\n\tshell_backend_dummy_clear_output(test_sh);\n\tcomp_fake_comp_trigger_is_pending_fake.custom_fake = test_trigger_is_pending_stub_1;\n\tret = shell_execute_cmd(test_sh, \"comp trigger_is_pending \" FAKE_COMP_NAME);\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_trigger_is_pending_fake.call_count, 1);\n\tzassert_equal(comp_fake_comp_trigger_is_pending_fake.arg0_val, test_dev);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\n1\\r\\n\");\n\n\tcomp_fake_comp_trigger_is_pending_fake.custom_fake = test_trigger_is_pending_stub_0;\n\tret = shell_execute_cmd(test_sh, \"comp trigger_is_pending \" FAKE_COMP_NAME);\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_trigger_is_pending_fake.call_count, 2);\n\tzassert_equal(comp_fake_comp_trigger_is_pending_fake.arg0_val, test_dev);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\n0\\r\\n\");\n\n\tcomp_fake_comp_trigger_is_pending_fake.custom_fake = test_trigger_is_pending_stub_eio;\n\tret = shell_execute_cmd(test_sh, \"comp trigger_is_pending \" FAKE_COMP_NAME);\n\tzassert_equal(ret, -EIO);\n\tzassert_equal(comp_fake_comp_trigger_is_pending_fake.call_count, 3);\n\tzassert_equal(comp_fake_comp_trigger_is_pending_fake.arg0_val, test_dev);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\nfailed to get trigger status\\r\\n\");\n}\n\nZTEST_SUITE(comparator_shell, NULL, test_setup, test_after, NULL, NULL);",
    "repo": "zephyrproject-rtos/zephyr",
    "path": "./datasets/diagrams-repos/zephyrproject-rtos/zephyr/tests/drivers/comparator/shell/src/test.c",
    "query": "How are the test cases in this code organized and structured?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'testSuite', 'node_id': 'testSuite', 'description': 'Main test suite for comparator shell tests', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'test_setup', 'node_id': 'test_setup', 'description': 'Setup function for test suite initialization', 'visibility': 'private', 'return_type': 'void*', 'params': 'void', 'source_class_id': None}, {'type': 'function', 'name': 'test_after', 'node_id': 'test_after', 'description': 'Cleanup function after each test', 'visibility': 'private', 'return_type': 'void', 'params': 'void *f', 'source_class_id': None}], 'edges': [{'node_id_from': 'testSuite', 'node_id_to': 'test_setup', 'description': 'uses for initialization'}, {'node_id_from': 'testSuite', 'node_id_to': 'test_after', 'description': 'uses for cleanup'}], 'packages': [{'package_id': 'comparatorShellTests', 'children': ['testSuite', 'test_setup', 'test_after'], 'description': 'Main test package for comparator shell functionality'}]}",
    "version": "minimal",
    "text_answer": "The test cases are organized in a single test suite 'comparator_shell' with setup and cleanup functions. The tests cover different shell commands (get_output, set_trigger) and trigger-related functionality, with multiple test cases verifying both success and failure scenarios for each command.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C",
    "code": "\n#include <zephyr/drivers/comparator.h>\n#include <zephyr/drivers/comparator/fake_comp.h>\n#include <zephyr/fff.h>\n#include <zephyr/kernel.h>\n#include <zephyr/shell/shell.h>\n#include <zephyr/shell/shell_dummy.h>\n#include <zephyr/ztest.h>\n\nDEFINE_FFF_GLOBALS;\n\n#define FAKE_COMP_NODE DT_NODELABEL(fake_comp)\n#define FAKE_COMP_NAME DEVICE_DT_NAME(FAKE_COMP_NODE)\n\n#define TEST_TRIGGER_DELAY K_SECONDS(1)\n\n#define TEST_AWAIT_TRIGGER_TIMEOUT_BELOW_MIN_CMD \\\n\t(\"comp await_trigger \" FAKE_COMP_NAME \" 0\")\n\n#define TEST_AWAIT_TRIGGER_TIMEOUT_ABOVE_MAX_CMD\t\t\t\t\t\t\\\n\t(\"comp await_trigger \" FAKE_COMP_NAME \" \"\t\t\t\t\t\t\\\n\t STRINGIFY(CONFIG_COMPARATOR_SHELL_AWAIT_TRIGGER_MAX_TIMEOUT + 1))\n\n#define TEST_AWAIT_TRIGGER_TIMEOUT_BROKEN_CMD \\\n\t(\"comp await_trigger \" FAKE_COMP_NAME \" d\")\n\nstatic const struct shell *test_sh;\nstatic const struct device *test_dev = DEVICE_DT_GET(FAKE_COMP_NODE);\nstatic comparator_callback_t test_callback;\nstatic void *test_callback_user_data;\nstatic struct k_spinlock test_callback_spinlock;\nstatic struct k_work_delayable test_trigger_dwork;\n\nstatic int test_get_output_stub_1(const struct device *dev)\n{\n\tARG_UNUSED(dev);\n\n\treturn 1;\n}\n\nstatic int test_get_output_stub_0(const struct device *dev)\n{\n\tARG_UNUSED(dev);\n\n\treturn 0;\n}\n\nstatic int test_get_output_stub_eio(const struct device *dev)\n{\n\tARG_UNUSED(dev);\n\n\treturn -EIO;\n}\n\nstatic int test_set_trigger_stub_ok(const struct device *dev, enum comparator_trigger trigger)\n{\n\tARG_UNUSED(dev);\n\tARG_UNUSED(trigger);\n\n\treturn 0;\n}\n\nstatic int test_set_trigger_stub_eio(const struct device *dev, enum comparator_trigger trigger)\n{\n\tARG_UNUSED(dev);\n\tARG_UNUSED(trigger);\n\n\treturn -EIO;\n}\n\nstatic int test_set_trigger_callback_mock_0(const struct device *dev,\n\t\t\t\t\t    comparator_callback_t callback,\n\t\t\t\t\t    void *user_data)\n{\n\tARG_UNUSED(dev);\n\n\tK_SPINLOCK(&test_callback_spinlock) {\n\t\ttest_callback = callback;\n\t\ttest_callback_user_data = user_data;\n\t}\n\n\treturn 0;\n}\n\nstatic int test_set_trigger_callback_stub_0(const struct device *dev,\n\t\t\t\t\t    comparator_callback_t callback,\n\t\t\t\t\t    void *user_data)\n{\n\tARG_UNUSED(dev);\n\tARG_UNUSED(callback);\n\tARG_UNUSED(user_data);\n\n\treturn 0;\n}\n\nstatic int test_set_trigger_callback_stub_eio(const struct device *dev,\n\t\t\t\t\t      comparator_callback_t callback,\n\t\t\t\t\t      void *user_data)\n{\n\tARG_UNUSED(dev);\n\tARG_UNUSED(callback);\n\tARG_UNUSED(user_data);\n\n\treturn -EIO;\n}\n\nstatic int test_trigger_is_pending_stub_1(const struct device *dev)\n{\n\tARG_UNUSED(dev);\n\n\treturn 1;\n}\n\nstatic int test_trigger_is_pending_stub_0(const struct device *dev)\n{\n\tARG_UNUSED(dev);\n\n\treturn 0;\n}\n\nstatic int test_trigger_is_pending_stub_eio(const struct device *dev)\n{\n\tARG_UNUSED(dev);\n\n\treturn -EIO;\n}\n\n\nstatic void test_trigger_handler(struct k_work *work)\n{\n\tARG_UNUSED(work);\n\n\ttest_callback(test_dev, test_callback_user_data);\n}\n\nstatic void test_schedule_trigger(void)\n{\n\tk_work_schedule(&test_trigger_dwork, TEST_TRIGGER_DELAY);\n}\n\nstatic void test_cancel_trigger(void)\n{\n\tstruct k_work_sync sync;\n\n\tk_work_cancel_delayable_sync(&test_trigger_dwork, &sync);\n}\n\nstatic void *test_setup(void)\n{\n\tk_work_init_delayable(&test_trigger_dwork, test_trigger_handler);\n\ttest_sh = shell_backend_dummy_get_ptr();\n\tWAIT_FOR(shell_ready(test_sh), 20000, k_msleep(1));\n\tzassert_true(shell_ready(test_sh), \"timed out waiting for dummy shell backend\");\n\treturn NULL;\n}\n\nstatic void test_after(void *f)\n{\n\tARG_UNUSED(f);\n\n\ttest_cancel_trigger();\n}\n\nZTEST(comparator_shell, test_get_output)\n{\n\tint ret;\n\tconst char *out;\n\tsize_t out_size;\n\n\tshell_backend_dummy_clear_output(test_sh);\n\tcomp_fake_comp_get_output_fake.custom_fake = test_get_output_stub_1;\n\tret = shell_execute_cmd(test_sh, \"comp get_output \" FAKE_COMP_NAME);\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_get_output_fake.call_count, 1);\n\tzassert_equal(comp_fake_comp_get_output_fake.arg0_val, test_dev);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\n1\\r\\n\");\n\n\tcomp_fake_comp_get_output_fake.custom_fake = test_get_output_stub_0;\n\tret = shell_execute_cmd(test_sh, \"comp get_output \" FAKE_COMP_NAME);\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_get_output_fake.call_count, 2);\n\tzassert_equal(comp_fake_comp_get_output_fake.arg0_val, test_dev);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\n0\\r\\n\");\n\n\tcomp_fake_comp_get_output_fake.custom_fake = test_get_output_stub_eio;\n\tret = shell_execute_cmd(test_sh, \"comp get_output \" FAKE_COMP_NAME);\n\tzassert_equal(ret, -EIO);\n\tzassert_equal(comp_fake_comp_get_output_fake.call_count, 3);\n\tzassert_equal(comp_fake_comp_get_output_fake.arg0_val, test_dev);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\nfailed to get output\\r\\n\");\n}\n\nZTEST(comparator_shell, test_set_trigger)\n{\n\tint ret;\n\tconst char *out;\n\tsize_t out_size;\n\n\tcomp_fake_comp_set_trigger_fake.custom_fake = test_set_trigger_stub_ok;\n\n\tret = shell_execute_cmd(test_sh, \"comp set_trigger \" FAKE_COMP_NAME \" NONE\");\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.call_count, 1);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg0_val, test_dev);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg1_val, COMPARATOR_TRIGGER_NONE);\n\n\tret = shell_execute_cmd(test_sh, \"comp set_trigger \" FAKE_COMP_NAME \" RISING_EDGE\");\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.call_count, 2);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg0_val, test_dev);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg1_val, COMPARATOR_TRIGGER_RISING_EDGE);\n\n\tret = shell_execute_cmd(test_sh, \"comp set_trigger \" FAKE_COMP_NAME \" FALLING_EDGE\");\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.call_count, 3);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg0_val, test_dev);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg1_val, COMPARATOR_TRIGGER_FALLING_EDGE);\n\n\tret = shell_execute_cmd(test_sh, \"comp set_trigger \" FAKE_COMP_NAME \" BOTH_EDGES\");\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.call_count, 4);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg0_val, test_dev);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg1_val, COMPARATOR_TRIGGER_BOTH_EDGES);\n\n\tret = shell_execute_cmd(test_sh, \"comp set_trigger \" FAKE_COMP_NAME \" INVALID\");\n\tzassert_equal(ret, -EINVAL);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.call_count, 4);\n\n\tcomp_fake_comp_set_trigger_fake.custom_fake = test_set_trigger_stub_eio;\n\n\tshell_backend_dummy_clear_output(test_sh);\n\tret = shell_execute_cmd(test_sh, \"comp set_trigger \" FAKE_COMP_NAME \" BOTH_EDGES\");\n\tzassert_equal(ret, -EIO);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.call_count, 5);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg0_val, test_dev);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg1_val, COMPARATOR_TRIGGER_BOTH_EDGES);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\nfailed to set trigger\\r\\n\");\n}\n\nZTEST(comparator_shell, test_await_trigger_set_callback_fail)\n{\n\tint ret;\n\tconst char *out;\n\tsize_t out_size;\n\n\tshell_backend_dummy_clear_output(test_sh);\n\tcomp_fake_comp_set_trigger_callback_fake.custom_fake = test_set_trigger_callback_stub_eio;\n\tret = shell_execute_cmd(test_sh, \"comp await_trigger \" FAKE_COMP_NAME);\n\tzassert_ok(0);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.call_count, 1);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.return_val, 0);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\nfailed to set trigger callback\\r\\n\");\n}\n\nZTEST(comparator_shell, test_await_trigger_timeout)\n{\n\tint ret;\n\tconst char *out;\n\tsize_t out_size;\n\n\tshell_backend_dummy_clear_output(test_sh);\n\tcomp_fake_comp_set_trigger_callback_fake.custom_fake = test_set_trigger_callback_stub_0;\n\tret = shell_execute_cmd(test_sh, \"comp await_trigger \" FAKE_COMP_NAME);\n\tzassert_ok(0);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.call_count, 2);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.return_val_history[0], 0);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.return_val_history[1], 0);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\ntimed out\\r\\n\");\n}\n\nZTEST(comparator_shell, test_await_trigger_invalid_timeout_arg)\n{\n\tint ret;\n\n\tret = shell_execute_cmd(test_sh, TEST_AWAIT_TRIGGER_TIMEOUT_BELOW_MIN_CMD);\n\tzassert_not_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.call_count, 0);\n\n\tret = shell_execute_cmd(test_sh, TEST_AWAIT_TRIGGER_TIMEOUT_ABOVE_MAX_CMD);\n\tzassert_not_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.call_count, 0);\n\n\tret = shell_execute_cmd(test_sh, TEST_AWAIT_TRIGGER_TIMEOUT_BROKEN_CMD);\n\tzassert_not_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.call_count, 0);\n}\n\nZTEST(comparator_shell, test_await_trigger)\n{\n\tint ret;\n\tconst char *out;\n\tsize_t out_size;\n\tcomparator_api_set_trigger_callback seq[2];\n\n\tshell_backend_dummy_clear_output(test_sh);\n\tseq[0] = test_set_trigger_callback_mock_0;\n\tseq[1] = test_set_trigger_callback_stub_0;\n\tcomp_fake_comp_set_trigger_callback_fake.custom_fake_seq = seq;\n\tcomp_fake_comp_set_trigger_callback_fake.custom_fake_seq_len = ARRAY_SIZE(seq);\n\ttest_schedule_trigger();\n\tret = shell_execute_cmd(test_sh, \"comp await_trigger \" FAKE_COMP_NAME);\n\tzassert_ok(0);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.call_count, 2);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.arg0_history[0], test_dev);\n\tzassert_not_equal(comp_fake_comp_set_trigger_callback_fake.arg1_history[0], NULL);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.return_val_history[0], 0);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.arg0_history[1], test_dev);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.arg1_history[1], NULL);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.return_val_history[1], 0);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\ntriggered\\r\\n\");\n}\n\nZTEST(comparator_shell, test_trigger_is_pending)\n{\n\tint ret;\n\tconst char *out;\n\tsize_t out_size;\n\n\tshell_backend_dummy_clear_output(test_sh);\n\tcomp_fake_comp_trigger_is_pending_fake.custom_fake = test_trigger_is_pending_stub_1;\n\tret = shell_execute_cmd(test_sh, \"comp trigger_is_pending \" FAKE_COMP_NAME);\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_trigger_is_pending_fake.call_count, 1);\n\tzassert_equal(comp_fake_comp_trigger_is_pending_fake.arg0_val, test_dev);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\n1\\r\\n\");\n\n\tcomp_fake_comp_trigger_is_pending_fake.custom_fake = test_trigger_is_pending_stub_0;\n\tret = shell_execute_cmd(test_sh, \"comp trigger_is_pending \" FAKE_COMP_NAME);\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_trigger_is_pending_fake.call_count, 2);\n\tzassert_equal(comp_fake_comp_trigger_is_pending_fake.arg0_val, test_dev);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\n0\\r\\n\");\n\n\tcomp_fake_comp_trigger_is_pending_fake.custom_fake = test_trigger_is_pending_stub_eio;\n\tret = shell_execute_cmd(test_sh, \"comp trigger_is_pending \" FAKE_COMP_NAME);\n\tzassert_equal(ret, -EIO);\n\tzassert_equal(comp_fake_comp_trigger_is_pending_fake.call_count, 3);\n\tzassert_equal(comp_fake_comp_trigger_is_pending_fake.arg0_val, test_dev);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\nfailed to get trigger status\\r\\n\");\n}\n\nZTEST_SUITE(comparator_shell, NULL, test_setup, test_after, NULL, NULL);",
    "repo": "zephyrproject-rtos/zephyr",
    "path": "./datasets/diagrams-repos/zephyrproject-rtos/zephyr/tests/drivers/comparator/shell/src/test.c",
    "query": "How are the test cases in this code organized and structured?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'testSuite', 'node_id': 'testSuite', 'description': 'Main test suite for comparator shell tests', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'test_setup', 'node_id': 'test_setup', 'description': 'Setup function for test suite initialization', 'visibility': 'private', 'return_type': 'void*', 'params': 'void', 'source_class_id': None}, {'type': 'function', 'name': 'test_after', 'node_id': 'test_after', 'description': 'Cleanup function after each test', 'visibility': 'private', 'return_type': 'void', 'params': 'void *f', 'source_class_id': None}, {'type': 'function', 'name': 'test_get_output', 'node_id': 'test_get_output', 'description': 'Test case for get_output command', 'visibility': 'public', 'return_type': 'void', 'params': 'void', 'source_class_id': None}, {'type': 'function', 'name': 'test_set_trigger', 'node_id': 'test_set_trigger', 'description': 'Test case for set_trigger command', 'visibility': 'public', 'return_type': 'void', 'params': 'void', 'source_class_id': None}, {'type': 'function', 'name': 'test_await_trigger', 'node_id': 'test_await_trigger', 'description': 'Test case for await_trigger command', 'visibility': 'public', 'return_type': 'void', 'params': 'void', 'source_class_id': None}], 'edges': [{'node_id_from': 'testSuite', 'node_id_to': 'test_setup', 'description': 'uses for initialization'}, {'node_id_from': 'testSuite', 'node_id_to': 'test_after', 'description': 'uses for cleanup'}, {'node_id_from': 'testSuite', 'node_id_to': 'test_get_output', 'description': 'contains'}, {'node_id_from': 'testSuite', 'node_id_to': 'test_set_trigger', 'description': 'contains'}, {'node_id_from': 'testSuite', 'node_id_to': 'test_await_trigger', 'description': 'contains'}], 'packages': [{'package_id': 'comparatorShellTests', 'children': ['testSuite', 'test_setup', 'test_after', 'test_get_output', 'test_set_trigger', 'test_await_trigger'], 'description': 'Main test package for comparator shell functionality'}]}",
    "version": "medium",
    "text_answer": "The test cases are organized in a single test suite 'comparator_shell' with setup and cleanup functions. The tests cover different shell commands (get_output, set_trigger) and trigger-related functionality, with multiple test cases verifying both success and failure scenarios for each command.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C",
    "code": "\n#include <zephyr/drivers/comparator.h>\n#include <zephyr/drivers/comparator/fake_comp.h>\n#include <zephyr/fff.h>\n#include <zephyr/kernel.h>\n#include <zephyr/shell/shell.h>\n#include <zephyr/shell/shell_dummy.h>\n#include <zephyr/ztest.h>\n\nDEFINE_FFF_GLOBALS;\n\n#define FAKE_COMP_NODE DT_NODELABEL(fake_comp)\n#define FAKE_COMP_NAME DEVICE_DT_NAME(FAKE_COMP_NODE)\n\n#define TEST_TRIGGER_DELAY K_SECONDS(1)\n\n#define TEST_AWAIT_TRIGGER_TIMEOUT_BELOW_MIN_CMD \\\n\t(\"comp await_trigger \" FAKE_COMP_NAME \" 0\")\n\n#define TEST_AWAIT_TRIGGER_TIMEOUT_ABOVE_MAX_CMD\t\t\t\t\t\t\\\n\t(\"comp await_trigger \" FAKE_COMP_NAME \" \"\t\t\t\t\t\t\\\n\t STRINGIFY(CONFIG_COMPARATOR_SHELL_AWAIT_TRIGGER_MAX_TIMEOUT + 1))\n\n#define TEST_AWAIT_TRIGGER_TIMEOUT_BROKEN_CMD \\\n\t(\"comp await_trigger \" FAKE_COMP_NAME \" d\")\n\nstatic const struct shell *test_sh;\nstatic const struct device *test_dev = DEVICE_DT_GET(FAKE_COMP_NODE);\nstatic comparator_callback_t test_callback;\nstatic void *test_callback_user_data;\nstatic struct k_spinlock test_callback_spinlock;\nstatic struct k_work_delayable test_trigger_dwork;\n\nstatic int test_get_output_stub_1(const struct device *dev)\n{\n\tARG_UNUSED(dev);\n\n\treturn 1;\n}\n\nstatic int test_get_output_stub_0(const struct device *dev)\n{\n\tARG_UNUSED(dev);\n\n\treturn 0;\n}\n\nstatic int test_get_output_stub_eio(const struct device *dev)\n{\n\tARG_UNUSED(dev);\n\n\treturn -EIO;\n}\n\nstatic int test_set_trigger_stub_ok(const struct device *dev, enum comparator_trigger trigger)\n{\n\tARG_UNUSED(dev);\n\tARG_UNUSED(trigger);\n\n\treturn 0;\n}\n\nstatic int test_set_trigger_stub_eio(const struct device *dev, enum comparator_trigger trigger)\n{\n\tARG_UNUSED(dev);\n\tARG_UNUSED(trigger);\n\n\treturn -EIO;\n}\n\nstatic int test_set_trigger_callback_mock_0(const struct device *dev,\n\t\t\t\t\t    comparator_callback_t callback,\n\t\t\t\t\t    void *user_data)\n{\n\tARG_UNUSED(dev);\n\n\tK_SPINLOCK(&test_callback_spinlock) {\n\t\ttest_callback = callback;\n\t\ttest_callback_user_data = user_data;\n\t}\n\n\treturn 0;\n}\n\nstatic int test_set_trigger_callback_stub_0(const struct device *dev,\n\t\t\t\t\t    comparator_callback_t callback,\n\t\t\t\t\t    void *user_data)\n{\n\tARG_UNUSED(dev);\n\tARG_UNUSED(callback);\n\tARG_UNUSED(user_data);\n\n\treturn 0;\n}\n\nstatic int test_set_trigger_callback_stub_eio(const struct device *dev,\n\t\t\t\t\t      comparator_callback_t callback,\n\t\t\t\t\t      void *user_data)\n{\n\tARG_UNUSED(dev);\n\tARG_UNUSED(callback);\n\tARG_UNUSED(user_data);\n\n\treturn -EIO;\n}\n\nstatic int test_trigger_is_pending_stub_1(const struct device *dev)\n{\n\tARG_UNUSED(dev);\n\n\treturn 1;\n}\n\nstatic int test_trigger_is_pending_stub_0(const struct device *dev)\n{\n\tARG_UNUSED(dev);\n\n\treturn 0;\n}\n\nstatic int test_trigger_is_pending_stub_eio(const struct device *dev)\n{\n\tARG_UNUSED(dev);\n\n\treturn -EIO;\n}\n\n\nstatic void test_trigger_handler(struct k_work *work)\n{\n\tARG_UNUSED(work);\n\n\ttest_callback(test_dev, test_callback_user_data);\n}\n\nstatic void test_schedule_trigger(void)\n{\n\tk_work_schedule(&test_trigger_dwork, TEST_TRIGGER_DELAY);\n}\n\nstatic void test_cancel_trigger(void)\n{\n\tstruct k_work_sync sync;\n\n\tk_work_cancel_delayable_sync(&test_trigger_dwork, &sync);\n}\n\nstatic void *test_setup(void)\n{\n\tk_work_init_delayable(&test_trigger_dwork, test_trigger_handler);\n\ttest_sh = shell_backend_dummy_get_ptr();\n\tWAIT_FOR(shell_ready(test_sh), 20000, k_msleep(1));\n\tzassert_true(shell_ready(test_sh), \"timed out waiting for dummy shell backend\");\n\treturn NULL;\n}\n\nstatic void test_after(void *f)\n{\n\tARG_UNUSED(f);\n\n\ttest_cancel_trigger();\n}\n\nZTEST(comparator_shell, test_get_output)\n{\n\tint ret;\n\tconst char *out;\n\tsize_t out_size;\n\n\tshell_backend_dummy_clear_output(test_sh);\n\tcomp_fake_comp_get_output_fake.custom_fake = test_get_output_stub_1;\n\tret = shell_execute_cmd(test_sh, \"comp get_output \" FAKE_COMP_NAME);\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_get_output_fake.call_count, 1);\n\tzassert_equal(comp_fake_comp_get_output_fake.arg0_val, test_dev);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\n1\\r\\n\");\n\n\tcomp_fake_comp_get_output_fake.custom_fake = test_get_output_stub_0;\n\tret = shell_execute_cmd(test_sh, \"comp get_output \" FAKE_COMP_NAME);\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_get_output_fake.call_count, 2);\n\tzassert_equal(comp_fake_comp_get_output_fake.arg0_val, test_dev);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\n0\\r\\n\");\n\n\tcomp_fake_comp_get_output_fake.custom_fake = test_get_output_stub_eio;\n\tret = shell_execute_cmd(test_sh, \"comp get_output \" FAKE_COMP_NAME);\n\tzassert_equal(ret, -EIO);\n\tzassert_equal(comp_fake_comp_get_output_fake.call_count, 3);\n\tzassert_equal(comp_fake_comp_get_output_fake.arg0_val, test_dev);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\nfailed to get output\\r\\n\");\n}\n\nZTEST(comparator_shell, test_set_trigger)\n{\n\tint ret;\n\tconst char *out;\n\tsize_t out_size;\n\n\tcomp_fake_comp_set_trigger_fake.custom_fake = test_set_trigger_stub_ok;\n\n\tret = shell_execute_cmd(test_sh, \"comp set_trigger \" FAKE_COMP_NAME \" NONE\");\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.call_count, 1);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg0_val, test_dev);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg1_val, COMPARATOR_TRIGGER_NONE);\n\n\tret = shell_execute_cmd(test_sh, \"comp set_trigger \" FAKE_COMP_NAME \" RISING_EDGE\");\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.call_count, 2);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg0_val, test_dev);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg1_val, COMPARATOR_TRIGGER_RISING_EDGE);\n\n\tret = shell_execute_cmd(test_sh, \"comp set_trigger \" FAKE_COMP_NAME \" FALLING_EDGE\");\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.call_count, 3);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg0_val, test_dev);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg1_val, COMPARATOR_TRIGGER_FALLING_EDGE);\n\n\tret = shell_execute_cmd(test_sh, \"comp set_trigger \" FAKE_COMP_NAME \" BOTH_EDGES\");\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.call_count, 4);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg0_val, test_dev);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg1_val, COMPARATOR_TRIGGER_BOTH_EDGES);\n\n\tret = shell_execute_cmd(test_sh, \"comp set_trigger \" FAKE_COMP_NAME \" INVALID\");\n\tzassert_equal(ret, -EINVAL);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.call_count, 4);\n\n\tcomp_fake_comp_set_trigger_fake.custom_fake = test_set_trigger_stub_eio;\n\n\tshell_backend_dummy_clear_output(test_sh);\n\tret = shell_execute_cmd(test_sh, \"comp set_trigger \" FAKE_COMP_NAME \" BOTH_EDGES\");\n\tzassert_equal(ret, -EIO);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.call_count, 5);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg0_val, test_dev);\n\tzassert_equal(comp_fake_comp_set_trigger_fake.arg1_val, COMPARATOR_TRIGGER_BOTH_EDGES);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\nfailed to set trigger\\r\\n\");\n}\n\nZTEST(comparator_shell, test_await_trigger_set_callback_fail)\n{\n\tint ret;\n\tconst char *out;\n\tsize_t out_size;\n\n\tshell_backend_dummy_clear_output(test_sh);\n\tcomp_fake_comp_set_trigger_callback_fake.custom_fake = test_set_trigger_callback_stub_eio;\n\tret = shell_execute_cmd(test_sh, \"comp await_trigger \" FAKE_COMP_NAME);\n\tzassert_ok(0);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.call_count, 1);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.return_val, 0);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\nfailed to set trigger callback\\r\\n\");\n}\n\nZTEST(comparator_shell, test_await_trigger_timeout)\n{\n\tint ret;\n\tconst char *out;\n\tsize_t out_size;\n\n\tshell_backend_dummy_clear_output(test_sh);\n\tcomp_fake_comp_set_trigger_callback_fake.custom_fake = test_set_trigger_callback_stub_0;\n\tret = shell_execute_cmd(test_sh, \"comp await_trigger \" FAKE_COMP_NAME);\n\tzassert_ok(0);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.call_count, 2);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.return_val_history[0], 0);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.return_val_history[1], 0);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\ntimed out\\r\\n\");\n}\n\nZTEST(comparator_shell, test_await_trigger_invalid_timeout_arg)\n{\n\tint ret;\n\n\tret = shell_execute_cmd(test_sh, TEST_AWAIT_TRIGGER_TIMEOUT_BELOW_MIN_CMD);\n\tzassert_not_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.call_count, 0);\n\n\tret = shell_execute_cmd(test_sh, TEST_AWAIT_TRIGGER_TIMEOUT_ABOVE_MAX_CMD);\n\tzassert_not_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.call_count, 0);\n\n\tret = shell_execute_cmd(test_sh, TEST_AWAIT_TRIGGER_TIMEOUT_BROKEN_CMD);\n\tzassert_not_ok(ret);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.call_count, 0);\n}\n\nZTEST(comparator_shell, test_await_trigger)\n{\n\tint ret;\n\tconst char *out;\n\tsize_t out_size;\n\tcomparator_api_set_trigger_callback seq[2];\n\n\tshell_backend_dummy_clear_output(test_sh);\n\tseq[0] = test_set_trigger_callback_mock_0;\n\tseq[1] = test_set_trigger_callback_stub_0;\n\tcomp_fake_comp_set_trigger_callback_fake.custom_fake_seq = seq;\n\tcomp_fake_comp_set_trigger_callback_fake.custom_fake_seq_len = ARRAY_SIZE(seq);\n\ttest_schedule_trigger();\n\tret = shell_execute_cmd(test_sh, \"comp await_trigger \" FAKE_COMP_NAME);\n\tzassert_ok(0);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.call_count, 2);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.arg0_history[0], test_dev);\n\tzassert_not_equal(comp_fake_comp_set_trigger_callback_fake.arg1_history[0], NULL);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.return_val_history[0], 0);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.arg0_history[1], test_dev);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.arg1_history[1], NULL);\n\tzassert_equal(comp_fake_comp_set_trigger_callback_fake.return_val_history[1], 0);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\ntriggered\\r\\n\");\n}\n\nZTEST(comparator_shell, test_trigger_is_pending)\n{\n\tint ret;\n\tconst char *out;\n\tsize_t out_size;\n\n\tshell_backend_dummy_clear_output(test_sh);\n\tcomp_fake_comp_trigger_is_pending_fake.custom_fake = test_trigger_is_pending_stub_1;\n\tret = shell_execute_cmd(test_sh, \"comp trigger_is_pending \" FAKE_COMP_NAME);\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_trigger_is_pending_fake.call_count, 1);\n\tzassert_equal(comp_fake_comp_trigger_is_pending_fake.arg0_val, test_dev);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\n1\\r\\n\");\n\n\tcomp_fake_comp_trigger_is_pending_fake.custom_fake = test_trigger_is_pending_stub_0;\n\tret = shell_execute_cmd(test_sh, \"comp trigger_is_pending \" FAKE_COMP_NAME);\n\tzassert_ok(ret);\n\tzassert_equal(comp_fake_comp_trigger_is_pending_fake.call_count, 2);\n\tzassert_equal(comp_fake_comp_trigger_is_pending_fake.arg0_val, test_dev);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\n0\\r\\n\");\n\n\tcomp_fake_comp_trigger_is_pending_fake.custom_fake = test_trigger_is_pending_stub_eio;\n\tret = shell_execute_cmd(test_sh, \"comp trigger_is_pending \" FAKE_COMP_NAME);\n\tzassert_equal(ret, -EIO);\n\tzassert_equal(comp_fake_comp_trigger_is_pending_fake.call_count, 3);\n\tzassert_equal(comp_fake_comp_trigger_is_pending_fake.arg0_val, test_dev);\n\tout = shell_backend_dummy_get_output(test_sh, &out_size);\n\tzassert_str_equal(out, \"\\r\\nfailed to get trigger status\\r\\n\");\n}\n\nZTEST_SUITE(comparator_shell, NULL, test_setup, test_after, NULL, NULL);",
    "repo": "zephyrproject-rtos/zephyr",
    "path": "./datasets/diagrams-repos/zephyrproject-rtos/zephyr/tests/drivers/comparator/shell/src/test.c",
    "query": "How are the test cases in this code organized and structured?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'testSuite', 'node_id': 'testSuite', 'description': 'Main test suite for comparator shell tests', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'test_setup', 'node_id': 'test_setup', 'description': 'Setup function for test suite initialization', 'visibility': 'private', 'return_type': 'void*', 'params': 'void', 'source_class_id': None}, {'type': 'function', 'name': 'test_after', 'node_id': 'test_after', 'description': 'Cleanup function after each test', 'visibility': 'private', 'return_type': 'void', 'params': 'void *f', 'source_class_id': None}, {'type': 'function', 'name': 'test_get_output', 'node_id': 'test_get_output', 'description': 'Test case for get_output command', 'visibility': 'public', 'return_type': 'void', 'params': 'void', 'source_class_id': None}, {'type': 'function', 'name': 'test_set_trigger', 'node_id': 'test_set_trigger', 'description': 'Test case for set_trigger command', 'visibility': 'public', 'return_type': 'void', 'params': 'void', 'source_class_id': None}, {'type': 'function', 'name': 'test_await_trigger', 'node_id': 'test_await_trigger', 'description': 'Test case for await_trigger command', 'visibility': 'public', 'return_type': 'void', 'params': 'void', 'source_class_id': None}, {'type': 'function', 'name': 'test_await_trigger_set_callback_fail', 'node_id': 'test_await_trigger_set_callback_fail', 'description': 'Test case for await_trigger callback failure', 'visibility': 'public', 'return_type': 'void', 'params': 'void', 'source_class_id': None}, {'type': 'function', 'name': 'test_await_trigger_timeout', 'node_id': 'test_await_trigger_timeout', 'description': 'Test case for await_trigger timeout', 'visibility': 'public', 'return_type': 'void', 'params': 'void', 'source_class_id': None}, {'type': 'function', 'name': 'test_await_trigger_invalid_timeout_arg', 'node_id': 'test_await_trigger_invalid_timeout_arg', 'description': 'Test case for invalid timeout arguments', 'visibility': 'public', 'return_type': 'void', 'params': 'void', 'source_class_id': None}, {'type': 'function', 'name': 'test_trigger_is_pending', 'node_id': 'test_trigger_is_pending', 'description': 'Test case for trigger_is_pending command', 'visibility': 'public', 'return_type': 'void', 'params': 'void', 'source_class_id': None}, {'type': 'function', 'name': 'test_trigger_handler', 'node_id': 'test_trigger_handler', 'description': 'Handler for trigger events', 'visibility': 'private', 'return_type': 'void', 'params': 'struct k_work *work', 'source_class_id': None}], 'edges': [{'node_id_from': 'testSuite', 'node_id_to': 'test_setup', 'description': 'uses for initialization'}, {'node_id_from': 'testSuite', 'node_id_to': 'test_after', 'description': 'uses for cleanup'}, {'node_id_from': 'testSuite', 'node_id_to': 'test_get_output', 'description': 'contains'}, {'node_id_from': 'testSuite', 'node_id_to': 'test_set_trigger', 'description': 'contains'}, {'node_id_from': 'testSuite', 'node_id_to': 'test_await_trigger', 'description': 'contains'}, {'node_id_from': 'testSuite', 'node_id_to': 'test_await_trigger_set_callback_fail', 'description': 'contains'}, {'node_id_from': 'testSuite', 'node_id_to': 'test_await_trigger_timeout', 'description': 'contains'}, {'node_id_from': 'testSuite', 'node_id_to': 'test_await_trigger_invalid_timeout_arg', 'description': 'contains'}, {'node_id_from': 'testSuite', 'node_id_to': 'test_trigger_is_pending', 'description': 'contains'}, {'node_id_from': 'test_await_trigger', 'node_id_to': 'test_trigger_handler', 'description': 'uses'}], 'packages': [{'package_id': 'comparatorShellTests', 'children': ['testSuite', 'test_setup', 'test_after'], 'description': 'Main test package for comparator shell functionality'}, {'package_id': 'commandTests', 'children': ['test_get_output', 'test_set_trigger', 'test_trigger_is_pending'], 'description': 'Tests for basic comparator commands'}, {'package_id': 'triggerTests', 'children': ['test_await_trigger', 'test_await_trigger_set_callback_fail', 'test_await_trigger_timeout', 'test_await_trigger_invalid_timeout_arg', 'test_trigger_handler'], 'description': 'Tests for trigger-related functionality'}]}",
    "version": "full",
    "text_answer": "The test cases are organized in a single test suite 'comparator_shell' with setup and cleanup functions. The tests cover different shell commands (get_output, set_trigger) and trigger-related functionality, with multiple test cases verifying both success and failure scenarios for each command.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Python",
    "code": "\nfrom __future__ import annotations\n\nfrom collections.abc import Awaitable, Callable\nfrom dataclasses import dataclass\nfrom typing import Any\n\nfrom intellifire4py.control import IntelliFireController\nfrom intellifire4py.model import IntelliFirePollData\n\nfrom homeassistant.components.light import (\n    ATTR_BRIGHTNESS,\n    ColorMode,\n    LightEntity,\n    LightEntityDescription,\n)\nfrom homeassistant.config_entries import ConfigEntry\nfrom homeassistant.core import HomeAssistant\nfrom homeassistant.helpers.entity_platform import AddEntitiesCallback\n\nfrom .const import DOMAIN, LOGGER\nfrom .coordinator import IntellifireDataUpdateCoordinator\nfrom .entity import IntellifireEntity\n\n\n@dataclass(frozen=True)\nclass IntellifireLightRequiredKeysMixin:\n    \"\"\"Required keys for fan entity.\"\"\"\n\n    set_fn: Callable[[IntelliFireController, int], Awaitable]\n    value_fn: Callable[[IntelliFirePollData], int]\n\n\n@dataclass(frozen=True)\nclass IntellifireLightEntityDescription(\n    LightEntityDescription, IntellifireLightRequiredKeysMixin\n):\n    \"\"\"Describes a light entity.\"\"\"\n\n\nINTELLIFIRE_LIGHTS: tuple[IntellifireLightEntityDescription, ...] = (\n    IntellifireLightEntityDescription(\n        key=\"lights\",\n        translation_key=\"lights\",\n        set_fn=lambda control_api, level: control_api.set_lights(level=level),\n        value_fn=lambda data: data.light_level,\n    ),\n)\n\n\nclass IntellifireLight(IntellifireEntity, LightEntity):\n    \"\"\"Light entity for the fireplace.\"\"\"\n\n    entity_description: IntellifireLightEntityDescription\n    _attr_color_mode = ColorMode.BRIGHTNESS\n    _attr_supported_color_modes = {ColorMode.BRIGHTNESS}\n\n    @property\n    def brightness(self) -> int:\n        \"\"\"Return the current brightness 0-255.\"\"\"\n        return 85 * self.entity_description.value_fn(self.coordinator.read_api.data)\n\n    @property\n    def is_on(self):\n        \"\"\"Return true if light is on.\"\"\"\n        return self.entity_description.value_fn(self.coordinator.read_api.data) >= 1\n\n    async def async_turn_on(self, **kwargs: Any) -> None:\n        \"\"\"Instruct the light to turn on.\"\"\"\n        if ATTR_BRIGHTNESS in kwargs:\n            light_level = int(kwargs[ATTR_BRIGHTNESS] / 85)\n        else:\n            light_level = 2\n\n        await self.entity_description.set_fn(self.coordinator.control_api, light_level)\n        await self.coordinator.async_request_refresh()\n\n    async def async_turn_off(self, **kwargs: Any) -> None:\n        \"\"\"Instruct the light to turn off.\"\"\"\n        await self.entity_description.set_fn(self.coordinator.control_api, 0)\n        await self.coordinator.async_request_refresh()\n\n\nasync def async_setup_entry(\n    hass: HomeAssistant,\n    entry: ConfigEntry,\n    async_add_entities: AddEntitiesCallback,\n) -> None:\n    \"\"\"Set up the fans.\"\"\"\n    coordinator: IntellifireDataUpdateCoordinator = hass.data[DOMAIN][entry.entry_id]\n\n    if coordinator.data.has_light:\n        async_add_entities(\n            IntellifireLight(coordinator=coordinator, description=description)\n            for description in INTELLIFIRE_LIGHTS\n        )\n        return\n    LOGGER.debug(\"Disabling Lights - IntelliFire device does not appear to have one\")",
    "repo": "home-assistant/core",
    "path": "./datasets/diagrams-repos/home-assistant/core/homeassistant/components/intellifire/light.py",
    "query": "What is the relationship between the IntellifireLightEntityDescription and IntellifireLight classes?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'IntellifireLightEntityDescription', 'node_id': 'IntellifireLightEntityDescription', 'description': 'Describes light entity properties and functions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'IntellifireLight', 'node_id': 'IntellifireLight', 'description': 'Light entity implementation for fireplace', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'entity_description', 'node_id': 'entity_description', 'description': 'Reference to light entity description', 'visibility': 'public', 'return_type': 'IntellifireLightEntityDescription', 'params': None, 'source_class_id': 'IntellifireLight'}], 'edges': [{'node_id_from': 'IntellifireLight', 'node_id_to': 'entity_description', 'description': 'has'}, {'node_id_from': 'entity_description', 'node_id_to': 'IntellifireLightEntityDescription', 'description': 'type of'}], 'packages': []}",
    "version": "minimal",
    "text_answer": "IntellifireLight uses IntellifireLightEntityDescription through its entity_description field to define and control light behavior. The description class provides the necessary functions for setting and getting light values, which are used by IntellifireLight's methods for operations like brightness control and power toggling.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Python",
    "code": "\nfrom __future__ import annotations\n\nfrom collections.abc import Awaitable, Callable\nfrom dataclasses import dataclass\nfrom typing import Any\n\nfrom intellifire4py.control import IntelliFireController\nfrom intellifire4py.model import IntelliFirePollData\n\nfrom homeassistant.components.light import (\n    ATTR_BRIGHTNESS,\n    ColorMode,\n    LightEntity,\n    LightEntityDescription,\n)\nfrom homeassistant.config_entries import ConfigEntry\nfrom homeassistant.core import HomeAssistant\nfrom homeassistant.helpers.entity_platform import AddEntitiesCallback\n\nfrom .const import DOMAIN, LOGGER\nfrom .coordinator import IntellifireDataUpdateCoordinator\nfrom .entity import IntellifireEntity\n\n\n@dataclass(frozen=True)\nclass IntellifireLightRequiredKeysMixin:\n    \"\"\"Required keys for fan entity.\"\"\"\n\n    set_fn: Callable[[IntelliFireController, int], Awaitable]\n    value_fn: Callable[[IntelliFirePollData], int]\n\n\n@dataclass(frozen=True)\nclass IntellifireLightEntityDescription(\n    LightEntityDescription, IntellifireLightRequiredKeysMixin\n):\n    \"\"\"Describes a light entity.\"\"\"\n\n\nINTELLIFIRE_LIGHTS: tuple[IntellifireLightEntityDescription, ...] = (\n    IntellifireLightEntityDescription(\n        key=\"lights\",\n        translation_key=\"lights\",\n        set_fn=lambda control_api, level: control_api.set_lights(level=level),\n        value_fn=lambda data: data.light_level,\n    ),\n)\n\n\nclass IntellifireLight(IntellifireEntity, LightEntity):\n    \"\"\"Light entity for the fireplace.\"\"\"\n\n    entity_description: IntellifireLightEntityDescription\n    _attr_color_mode = ColorMode.BRIGHTNESS\n    _attr_supported_color_modes = {ColorMode.BRIGHTNESS}\n\n    @property\n    def brightness(self) -> int:\n        \"\"\"Return the current brightness 0-255.\"\"\"\n        return 85 * self.entity_description.value_fn(self.coordinator.read_api.data)\n\n    @property\n    def is_on(self):\n        \"\"\"Return true if light is on.\"\"\"\n        return self.entity_description.value_fn(self.coordinator.read_api.data) >= 1\n\n    async def async_turn_on(self, **kwargs: Any) -> None:\n        \"\"\"Instruct the light to turn on.\"\"\"\n        if ATTR_BRIGHTNESS in kwargs:\n            light_level = int(kwargs[ATTR_BRIGHTNESS] / 85)\n        else:\n            light_level = 2\n\n        await self.entity_description.set_fn(self.coordinator.control_api, light_level)\n        await self.coordinator.async_request_refresh()\n\n    async def async_turn_off(self, **kwargs: Any) -> None:\n        \"\"\"Instruct the light to turn off.\"\"\"\n        await self.entity_description.set_fn(self.coordinator.control_api, 0)\n        await self.coordinator.async_request_refresh()\n\n\nasync def async_setup_entry(\n    hass: HomeAssistant,\n    entry: ConfigEntry,\n    async_add_entities: AddEntitiesCallback,\n) -> None:\n    \"\"\"Set up the fans.\"\"\"\n    coordinator: IntellifireDataUpdateCoordinator = hass.data[DOMAIN][entry.entry_id]\n\n    if coordinator.data.has_light:\n        async_add_entities(\n            IntellifireLight(coordinator=coordinator, description=description)\n            for description in INTELLIFIRE_LIGHTS\n        )\n        return\n    LOGGER.debug(\"Disabling Lights - IntelliFire device does not appear to have one\")",
    "repo": "home-assistant/core",
    "path": "./datasets/diagrams-repos/home-assistant/core/homeassistant/components/intellifire/light.py",
    "query": "What is the relationship between the IntellifireLightEntityDescription and IntellifireLight classes?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'IntellifireLightEntityDescription', 'node_id': 'IntellifireLightEntityDescription', 'description': 'Describes light entity properties and functions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'IntellifireLight', 'node_id': 'IntellifireLight', 'description': 'Light entity implementation for fireplace', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'entity_description', 'node_id': 'entity_description', 'description': 'Reference to light entity description', 'visibility': 'public', 'return_type': 'IntellifireLightEntityDescription', 'params': None, 'source_class_id': 'IntellifireLight'}, {'type': 'method', 'name': 'brightness', 'node_id': 'brightness', 'description': 'Returns current brightness level', 'visibility': 'public', 'return_type': 'int', 'params': '', 'source_class_id': 'IntellifireLight'}, {'type': 'method', 'name': 'is_on', 'node_id': 'is_on', 'description': 'Checks if light is on', 'visibility': 'public', 'return_type': 'bool', 'params': '', 'source_class_id': 'IntellifireLight'}], 'edges': [{'node_id_from': 'IntellifireLight', 'node_id_to': 'entity_description', 'description': 'has'}, {'node_id_from': 'entity_description', 'node_id_to': 'IntellifireLightEntityDescription', 'description': 'type of'}, {'node_id_from': 'brightness', 'node_id_to': 'entity_description', 'description': 'uses'}, {'node_id_from': 'is_on', 'node_id_to': 'entity_description', 'description': 'uses'}, {'node_id_from': 'IntellifireLight', 'node_id_to': 'brightness', 'description': ''}, {'node_id_from': 'IntellifireLight', 'node_id_to': 'is_on', 'description': ''}], 'packages': []}",
    "version": "medium",
    "text_answer": "IntellifireLight uses IntellifireLightEntityDescription through its entity_description field to define and control light behavior. The description class provides the necessary functions for setting and getting light values, which are used by IntellifireLight's methods for operations like brightness control and power toggling.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Python",
    "code": "\nfrom __future__ import annotations\n\nfrom collections.abc import Awaitable, Callable\nfrom dataclasses import dataclass\nfrom typing import Any\n\nfrom intellifire4py.control import IntelliFireController\nfrom intellifire4py.model import IntelliFirePollData\n\nfrom homeassistant.components.light import (\n    ATTR_BRIGHTNESS,\n    ColorMode,\n    LightEntity,\n    LightEntityDescription,\n)\nfrom homeassistant.config_entries import ConfigEntry\nfrom homeassistant.core import HomeAssistant\nfrom homeassistant.helpers.entity_platform import AddEntitiesCallback\n\nfrom .const import DOMAIN, LOGGER\nfrom .coordinator import IntellifireDataUpdateCoordinator\nfrom .entity import IntellifireEntity\n\n\n@dataclass(frozen=True)\nclass IntellifireLightRequiredKeysMixin:\n    \"\"\"Required keys for fan entity.\"\"\"\n\n    set_fn: Callable[[IntelliFireController, int], Awaitable]\n    value_fn: Callable[[IntelliFirePollData], int]\n\n\n@dataclass(frozen=True)\nclass IntellifireLightEntityDescription(\n    LightEntityDescription, IntellifireLightRequiredKeysMixin\n):\n    \"\"\"Describes a light entity.\"\"\"\n\n\nINTELLIFIRE_LIGHTS: tuple[IntellifireLightEntityDescription, ...] = (\n    IntellifireLightEntityDescription(\n        key=\"lights\",\n        translation_key=\"lights\",\n        set_fn=lambda control_api, level: control_api.set_lights(level=level),\n        value_fn=lambda data: data.light_level,\n    ),\n)\n\n\nclass IntellifireLight(IntellifireEntity, LightEntity):\n    \"\"\"Light entity for the fireplace.\"\"\"\n\n    entity_description: IntellifireLightEntityDescription\n    _attr_color_mode = ColorMode.BRIGHTNESS\n    _attr_supported_color_modes = {ColorMode.BRIGHTNESS}\n\n    @property\n    def brightness(self) -> int:\n        \"\"\"Return the current brightness 0-255.\"\"\"\n        return 85 * self.entity_description.value_fn(self.coordinator.read_api.data)\n\n    @property\n    def is_on(self):\n        \"\"\"Return true if light is on.\"\"\"\n        return self.entity_description.value_fn(self.coordinator.read_api.data) >= 1\n\n    async def async_turn_on(self, **kwargs: Any) -> None:\n        \"\"\"Instruct the light to turn on.\"\"\"\n        if ATTR_BRIGHTNESS in kwargs:\n            light_level = int(kwargs[ATTR_BRIGHTNESS] / 85)\n        else:\n            light_level = 2\n\n        await self.entity_description.set_fn(self.coordinator.control_api, light_level)\n        await self.coordinator.async_request_refresh()\n\n    async def async_turn_off(self, **kwargs: Any) -> None:\n        \"\"\"Instruct the light to turn off.\"\"\"\n        await self.entity_description.set_fn(self.coordinator.control_api, 0)\n        await self.coordinator.async_request_refresh()\n\n\nasync def async_setup_entry(\n    hass: HomeAssistant,\n    entry: ConfigEntry,\n    async_add_entities: AddEntitiesCallback,\n) -> None:\n    \"\"\"Set up the fans.\"\"\"\n    coordinator: IntellifireDataUpdateCoordinator = hass.data[DOMAIN][entry.entry_id]\n\n    if coordinator.data.has_light:\n        async_add_entities(\n            IntellifireLight(coordinator=coordinator, description=description)\n            for description in INTELLIFIRE_LIGHTS\n        )\n        return\n    LOGGER.debug(\"Disabling Lights - IntelliFire device does not appear to have one\")",
    "repo": "home-assistant/core",
    "path": "./datasets/diagrams-repos/home-assistant/core/homeassistant/components/intellifire/light.py",
    "query": "What is the relationship between the IntellifireLightEntityDescription and IntellifireLight classes?",
    "diagram": "{'nodes': [{'type': 'class', 'name': 'IntellifireLightRequiredKeysMixin', 'node_id': 'IntellifireLightRequiredKeysMixin', 'description': 'Mixin defining required keys for light entity', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'IntellifireLightEntityDescription', 'node_id': 'IntellifireLightEntityDescription', 'description': 'Describes light entity properties and functions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'class', 'name': 'IntellifireLight', 'node_id': 'IntellifireLight', 'description': 'Light entity implementation for fireplace', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'field', 'name': 'entity_description', 'node_id': 'entity_description', 'description': 'Reference to light entity description', 'visibility': 'public', 'return_type': 'IntellifireLightEntityDescription', 'params': None, 'source_class_id': 'IntellifireLight'}, {'type': 'field', 'name': '_attr_color_mode', 'node_id': '_attr_color_mode', 'description': 'Color mode attribute', 'visibility': 'protected', 'return_type': 'ColorMode', 'params': None, 'source_class_id': 'IntellifireLight'}, {'type': 'field', 'name': '_attr_supported_color_modes', 'node_id': '_attr_supported_color_modes', 'description': 'Supported color modes', 'visibility': 'protected', 'return_type': 'set', 'params': None, 'source_class_id': 'IntellifireLight'}, {'type': 'method', 'name': 'brightness', 'node_id': 'brightness', 'description': 'Returns current brightness level', 'visibility': 'public', 'return_type': 'int', 'params': '', 'source_class_id': 'IntellifireLight'}, {'type': 'method', 'name': 'is_on', 'node_id': 'is_on', 'description': 'Checks if light is on', 'visibility': 'public', 'return_type': 'bool', 'params': '', 'source_class_id': 'IntellifireLight'}, {'type': 'method', 'name': 'async_turn_on', 'node_id': 'async_turn_on', 'description': 'Turns light on', 'visibility': 'public', 'return_type': 'None', 'params': '**kwargs: Any', 'source_class_id': 'IntellifireLight'}, {'type': 'method', 'name': 'async_turn_off', 'node_id': 'async_turn_off', 'description': 'Turns light off', 'visibility': 'public', 'return_type': 'None', 'params': '**kwargs: Any', 'source_class_id': 'IntellifireLight'}], 'edges': [{'node_id_from': 'IntellifireLightEntityDescription', 'node_id_to': 'IntellifireLightRequiredKeysMixin', 'description': 'inherits'}, {'node_id_from': 'IntellifireLight', 'node_id_to': 'entity_description', 'description': 'has'}, {'node_id_from': 'entity_description', 'node_id_to': 'IntellifireLightEntityDescription', 'description': 'type of'}, {'node_id_from': 'brightness', 'node_id_to': 'entity_description', 'description': 'uses'}, {'node_id_from': 'is_on', 'node_id_to': 'entity_description', 'description': 'uses'}, {'node_id_from': 'async_turn_on', 'node_id_to': 'entity_description', 'description': 'uses'}, {'node_id_from': 'async_turn_off', 'node_id_to': 'entity_description', 'description': 'uses'}, {'node_id_from': 'IntellifireLight', 'node_id_to': 'brightness', 'description': ''}, {'node_id_from': 'IntellifireLight', 'node_id_to': 'is_on', 'description': ''}, {'node_id_from': 'IntellifireLight', 'node_id_to': '_attr_color_mode', 'description': ''}, {'node_id_from': 'IntellifireLight', 'node_id_to': '_attr_supported_color_modes', 'description': ''}, {'node_id_from': 'IntellifireLight', 'node_id_to': 'async_turn_on', 'description': ''}, {'node_id_from': 'IntellifireLight', 'node_id_to': 'async_turn_off', 'description': ''}], 'packages': [{'package_id': 'lightEntity', 'children': ['IntellifireLightEntityDescription', 'IntellifireLightRequiredKeysMixin'], 'description': 'Light entity description components'}, {'package_id': 'lightImplementation', 'children': ['IntellifireLight', 'brightness', 'is_on', 'async_turn_on', 'async_turn_off', '_attr_color_mode', '_attr_supported_color_modes', 'entity_description'], 'description': 'Light entity implementation components'}]}",
    "version": "full",
    "text_answer": "IntellifireLight uses IntellifireLightEntityDescription through its entity_description field to define and control light behavior. The description class provides the necessary functions for setting and getting light values, which are used by IntellifireLight's methods for operations like brightness control and power toggling.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage com.alibaba.druid.bvt.sql.oracle.createTable;\n\nimport com.alibaba.druid.sql.OracleTest;\nimport com.alibaba.druid.sql.ast.SQLStatement;\nimport com.alibaba.druid.sql.dialect.oracle.parser.OracleStatementParser;\nimport com.alibaba.druid.sql.dialect.oracle.visitor.OracleSchemaStatVisitor;\nimport org.junit.Assert;\n\nimport java.util.List;\n\npublic class OracleCreateTableTest89 extends OracleTest {\n    public void test_0() throws Exception {\n        String sql = //\n                \"CREATE TABLE \\\"ACCOUNT\\\".\\\"GROUP_BILLGEN_REQUEST\\\" \\n\" +\n                        \"   (  \\\"BG_REQ_ID\\\" NUMBER(12,0) NOT NULL ENABLE, \\n\" +\n                        \"  \\\"HOME_CITY\\\" NUMBER(3,0) NOT NULL ENABLE, \\n\" +\n                        \"  \\\"DETAILBILL_ID\\\" NUMBER(12,0), \\n\" +\n                        \"  \\\"USER_ID\\\" NUMBER(15,0) NOT NULL ENABLE, \\n\" +\n                        \"  \\\"CREATE_TIME\\\" DATE NOT NULL ENABLE, \\n\" +\n                        \"  \\\"REQUEST_SOURCE\\\" NUMBER(6,0) NOT NULL ENABLE, \\n\" +\n                        \"  \\\"EXEC_STATUS\\\" NUMBER(2,0) NOT NULL ENABLE, \\n\" +\n                        \"  \\\"EXEC_TIME\\\" DATE, \\n\" +\n                        \"  \\\"OPERATOR\\\" NUMBER(8,0)\\n\" +\n                        \"   )\\n\" +\n                        \"    PCTFREE 10 PCTUSED 40 INITRANS 1 MAXTRANS 255  NOLOGGING \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \"  \\n\" +\n                        \"  PARTITION BY RANGE (\\\"HOME_CITY\\\") \\n\" +\n                        \"  SUBPARTITION BY LIST (\\\"EXEC_STATUS\\\") \\n\" +\n                        \" (PARTITION \\\"FZ\\\"  VALUES LESS THAN (592) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"FZ_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"FZ_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"FZ_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"FZ_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"FZ_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"XM\\\"  VALUES LESS THAN (593) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"XM_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"XM_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"XM_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"XM_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"XM_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"ND\\\"  VALUES LESS THAN (594) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"ND_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ND_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ND_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ND_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ND_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"PT\\\"  VALUES LESS THAN (595) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"PT_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"PT_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"PT_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"PT_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"PT_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"QZ\\\"  VALUES LESS THAN (596) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"QZ_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"QZ_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"QZ_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"QZ_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"QZ_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"ZZ\\\"  VALUES LESS THAN (597) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"ZZ_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ZZ_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ZZ_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ZZ_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ZZ_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"LY\\\"  VALUES LESS THAN (598) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"LY_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"LY_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"LY_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"LY_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"LY_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"SM\\\"  VALUES LESS THAN (599) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"SM_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"SM_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"SM_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"SM_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"SM_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"NP\\\"  VALUES LESS THAN (MAXVALUE) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"NP_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"NP_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"NP_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"NP_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"NP_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) )  ENABLE ROW MOVEMENT \";\n\n        OracleStatementParser parser = new OracleStatementParser(sql);\n        List<SQLStatement> statementList = parser.parseStatementList();\n        SQLStatement statemen = statementList.get(0);\n        print(statementList);\n\n        Assert.assertEquals(1, statementList.size());\n\n        OracleSchemaStatVisitor visitor = new OracleSchemaStatVisitor();\n        statemen.accept(visitor);\n\n        System.out.println(\"Tables : \" + visitor.getTables());\n        System.out.println(\"fields : \" + visitor.getColumns());\n        System.out.println(\"coditions : \" + visitor.getConditions());\n        System.out.println(\"relationships : \" + visitor.getRelationships());\n        System.out.println(\"orderBy : \" + visitor.getOrderByColumns());\n\n        Assert.assertEquals(1, visitor.getTables().size());\n\n    }\n}",
    "repo": "alibaba/druid",
    "path": "./datasets/diagrams-repos/alibaba/druid/core/src/test/java/com/alibaba/druid/bvt/sql/oracle/createTable/OracleCreateTableTest89.java",
    "query": "What is the structure of the table created in the SQL statement, including its partitions and subpartitions?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'GROUP_BILLGEN_REQUEST', 'node_id': 'GROUP_BILLGEN_REQUEST', 'description': 'Main table with billing request information', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'RangePartitioning', 'node_id': 'RangePartitioning', 'description': 'Partitioning by HOME_CITY column', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'ListSubpartitioning', 'node_id': 'ListSubpartitioning', 'description': 'Subpartitioning by EXEC_STATUS column', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'GROUP_BILLGEN_REQUEST', 'node_id_to': 'RangePartitioning', 'description': 'partitioned by'}, {'node_id_from': 'RangePartitioning', 'node_id_to': 'ListSubpartitioning', 'description': 'contains'}], 'packages': [{'package_id': 'TableStructure', 'children': ['GROUP_BILLGEN_REQUEST', 'RangePartitioning', 'ListSubpartitioning'], 'description': 'Basic table structure components'}]}",
    "version": "minimal",
    "text_answer": "The GROUP_BILLGEN_REQUEST table uses a two-level partitioning strategy: range partitioning by HOME_CITY column and list subpartitioning by EXEC_STATUS column. It has 9 main partitions for different cities (FZ, XM, ND, PT, QZ, ZZ, LY, SM, NP) and each partition is further divided into 5 subpartitions based on execution status (STA01-STA04, STA99).",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage com.alibaba.druid.bvt.sql.oracle.createTable;\n\nimport com.alibaba.druid.sql.OracleTest;\nimport com.alibaba.druid.sql.ast.SQLStatement;\nimport com.alibaba.druid.sql.dialect.oracle.parser.OracleStatementParser;\nimport com.alibaba.druid.sql.dialect.oracle.visitor.OracleSchemaStatVisitor;\nimport org.junit.Assert;\n\nimport java.util.List;\n\npublic class OracleCreateTableTest89 extends OracleTest {\n    public void test_0() throws Exception {\n        String sql = //\n                \"CREATE TABLE \\\"ACCOUNT\\\".\\\"GROUP_BILLGEN_REQUEST\\\" \\n\" +\n                        \"   (  \\\"BG_REQ_ID\\\" NUMBER(12,0) NOT NULL ENABLE, \\n\" +\n                        \"  \\\"HOME_CITY\\\" NUMBER(3,0) NOT NULL ENABLE, \\n\" +\n                        \"  \\\"DETAILBILL_ID\\\" NUMBER(12,0), \\n\" +\n                        \"  \\\"USER_ID\\\" NUMBER(15,0) NOT NULL ENABLE, \\n\" +\n                        \"  \\\"CREATE_TIME\\\" DATE NOT NULL ENABLE, \\n\" +\n                        \"  \\\"REQUEST_SOURCE\\\" NUMBER(6,0) NOT NULL ENABLE, \\n\" +\n                        \"  \\\"EXEC_STATUS\\\" NUMBER(2,0) NOT NULL ENABLE, \\n\" +\n                        \"  \\\"EXEC_TIME\\\" DATE, \\n\" +\n                        \"  \\\"OPERATOR\\\" NUMBER(8,0)\\n\" +\n                        \"   )\\n\" +\n                        \"    PCTFREE 10 PCTUSED 40 INITRANS 1 MAXTRANS 255  NOLOGGING \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \"  \\n\" +\n                        \"  PARTITION BY RANGE (\\\"HOME_CITY\\\") \\n\" +\n                        \"  SUBPARTITION BY LIST (\\\"EXEC_STATUS\\\") \\n\" +\n                        \" (PARTITION \\\"FZ\\\"  VALUES LESS THAN (592) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"FZ_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"FZ_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"FZ_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"FZ_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"FZ_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"XM\\\"  VALUES LESS THAN (593) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"XM_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"XM_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"XM_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"XM_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"XM_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"ND\\\"  VALUES LESS THAN (594) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"ND_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ND_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ND_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ND_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ND_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"PT\\\"  VALUES LESS THAN (595) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"PT_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"PT_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"PT_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"PT_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"PT_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"QZ\\\"  VALUES LESS THAN (596) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"QZ_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"QZ_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"QZ_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"QZ_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"QZ_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"ZZ\\\"  VALUES LESS THAN (597) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"ZZ_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ZZ_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ZZ_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ZZ_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ZZ_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"LY\\\"  VALUES LESS THAN (598) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"LY_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"LY_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"LY_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"LY_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"LY_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"SM\\\"  VALUES LESS THAN (599) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"SM_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"SM_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"SM_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"SM_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"SM_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"NP\\\"  VALUES LESS THAN (MAXVALUE) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"NP_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"NP_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"NP_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"NP_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"NP_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) )  ENABLE ROW MOVEMENT \";\n\n        OracleStatementParser parser = new OracleStatementParser(sql);\n        List<SQLStatement> statementList = parser.parseStatementList();\n        SQLStatement statemen = statementList.get(0);\n        print(statementList);\n\n        Assert.assertEquals(1, statementList.size());\n\n        OracleSchemaStatVisitor visitor = new OracleSchemaStatVisitor();\n        statemen.accept(visitor);\n\n        System.out.println(\"Tables : \" + visitor.getTables());\n        System.out.println(\"fields : \" + visitor.getColumns());\n        System.out.println(\"coditions : \" + visitor.getConditions());\n        System.out.println(\"relationships : \" + visitor.getRelationships());\n        System.out.println(\"orderBy : \" + visitor.getOrderByColumns());\n\n        Assert.assertEquals(1, visitor.getTables().size());\n\n    }\n}",
    "repo": "alibaba/druid",
    "path": "./datasets/diagrams-repos/alibaba/druid/core/src/test/java/com/alibaba/druid/bvt/sql/oracle/createTable/OracleCreateTableTest89.java",
    "query": "What is the structure of the table created in the SQL statement, including its partitions and subpartitions?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'GROUP_BILLGEN_REQUEST', 'node_id': 'GROUP_BILLGEN_REQUEST', 'description': 'Main table with billing request information', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'TableColumns', 'node_id': 'TableColumns', 'description': 'Collection of table columns including BG_REQ_ID, HOME_CITY, etc.', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'RangePartitioning', 'node_id': 'RangePartitioning', 'description': 'Partitioning by HOME_CITY column', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'CityPartitions', 'node_id': 'CityPartitions', 'description': 'City-based partitions (FZ, XM, ND, etc.)', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'ListSubpartitioning', 'node_id': 'ListSubpartitioning', 'description': 'Subpartitioning by EXEC_STATUS column', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'StatusSubpartitions', 'node_id': 'StatusSubpartitions', 'description': 'Status-based subpartitions (STA01, STA02, etc.)', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'GROUP_BILLGEN_REQUEST', 'node_id_to': 'TableColumns', 'description': 'contains'}, {'node_id_from': 'GROUP_BILLGEN_REQUEST', 'node_id_to': 'RangePartitioning', 'description': 'partitioned by'}, {'node_id_from': 'RangePartitioning', 'node_id_to': 'CityPartitions', 'description': 'consists of'}, {'node_id_from': 'CityPartitions', 'node_id_to': 'ListSubpartitioning', 'description': 'further divided by'}, {'node_id_from': 'ListSubpartitioning', 'node_id_to': 'StatusSubpartitions', 'description': 'consists of'}], 'packages': [{'package_id': 'TableStructure', 'children': ['GROUP_BILLGEN_REQUEST', 'TableColumns'], 'description': 'Basic table structure'}, {'package_id': 'PartitioningScheme', 'children': ['RangePartitioning', 'CityPartitions', 'ListSubpartitioning', 'StatusSubpartitions'], 'description': 'Partitioning hierarchy'}]}",
    "version": "medium",
    "text_answer": "The GROUP_BILLGEN_REQUEST table uses a two-level partitioning strategy: range partitioning by HOME_CITY column and list subpartitioning by EXEC_STATUS column. It has 9 main partitions for different cities (FZ, XM, ND, PT, QZ, ZZ, LY, SM, NP) and each partition is further divided into 5 subpartitions based on execution status (STA01-STA04, STA99).",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "Java",
    "code": "\npackage com.alibaba.druid.bvt.sql.oracle.createTable;\n\nimport com.alibaba.druid.sql.OracleTest;\nimport com.alibaba.druid.sql.ast.SQLStatement;\nimport com.alibaba.druid.sql.dialect.oracle.parser.OracleStatementParser;\nimport com.alibaba.druid.sql.dialect.oracle.visitor.OracleSchemaStatVisitor;\nimport org.junit.Assert;\n\nimport java.util.List;\n\npublic class OracleCreateTableTest89 extends OracleTest {\n    public void test_0() throws Exception {\n        String sql = //\n                \"CREATE TABLE \\\"ACCOUNT\\\".\\\"GROUP_BILLGEN_REQUEST\\\" \\n\" +\n                        \"   (  \\\"BG_REQ_ID\\\" NUMBER(12,0) NOT NULL ENABLE, \\n\" +\n                        \"  \\\"HOME_CITY\\\" NUMBER(3,0) NOT NULL ENABLE, \\n\" +\n                        \"  \\\"DETAILBILL_ID\\\" NUMBER(12,0), \\n\" +\n                        \"  \\\"USER_ID\\\" NUMBER(15,0) NOT NULL ENABLE, \\n\" +\n                        \"  \\\"CREATE_TIME\\\" DATE NOT NULL ENABLE, \\n\" +\n                        \"  \\\"REQUEST_SOURCE\\\" NUMBER(6,0) NOT NULL ENABLE, \\n\" +\n                        \"  \\\"EXEC_STATUS\\\" NUMBER(2,0) NOT NULL ENABLE, \\n\" +\n                        \"  \\\"EXEC_TIME\\\" DATE, \\n\" +\n                        \"  \\\"OPERATOR\\\" NUMBER(8,0)\\n\" +\n                        \"   )\\n\" +\n                        \"    PCTFREE 10 PCTUSED 40 INITRANS 1 MAXTRANS 255  NOLOGGING \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \"  \\n\" +\n                        \"  PARTITION BY RANGE (\\\"HOME_CITY\\\") \\n\" +\n                        \"  SUBPARTITION BY LIST (\\\"EXEC_STATUS\\\") \\n\" +\n                        \" (PARTITION \\\"FZ\\\"  VALUES LESS THAN (592) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"FZ_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"FZ_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"FZ_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"FZ_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"FZ_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"XM\\\"  VALUES LESS THAN (593) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"XM_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"XM_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"XM_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"XM_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"XM_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"ND\\\"  VALUES LESS THAN (594) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"ND_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ND_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ND_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ND_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ND_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"PT\\\"  VALUES LESS THAN (595) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"PT_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"PT_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"PT_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"PT_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"PT_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"QZ\\\"  VALUES LESS THAN (596) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"QZ_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"QZ_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"QZ_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"QZ_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"QZ_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"ZZ\\\"  VALUES LESS THAN (597) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"ZZ_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ZZ_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ZZ_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ZZ_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"ZZ_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"LY\\\"  VALUES LESS THAN (598) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"LY_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"LY_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"LY_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"LY_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"LY_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"SM\\\"  VALUES LESS THAN (599) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"SM_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"SM_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"SM_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"SM_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"SM_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) , \\n\" +\n                        \" PARTITION \\\"NP\\\"  VALUES LESS THAN (MAXVALUE) \\n\" +\n                        \"PCTFREE 5 PCTUSED 40 INITRANS 10 MAXTRANS 255 \\n\" +\n                        \"  STORAGE(\\n\" +\n                        \"  BUFFER_POOL DEFAULT FLASH_CACHE DEFAULT CELL_FLASH_CACHE DEFAULT)\\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" ( SUBPARTITION \\\"NP_STA01\\\"  VALUES (0) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"NP_STA02\\\"  VALUES (1) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"NP_STA03\\\"  VALUES (2) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"NP_STA04\\\"  VALUES (3, 7) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS , \\n\" +\n                        \"  SUBPARTITION \\\"NP_STA99\\\"  VALUES (default) \\n\" +\n                        \"  TABLESPACE \\\"ACCOUNT_DATA_TS\\\" \\n\" +\n                        \" NOCOMPRESS ) )  ENABLE ROW MOVEMENT \";\n\n        OracleStatementParser parser = new OracleStatementParser(sql);\n        List<SQLStatement> statementList = parser.parseStatementList();\n        SQLStatement statemen = statementList.get(0);\n        print(statementList);\n\n        Assert.assertEquals(1, statementList.size());\n\n        OracleSchemaStatVisitor visitor = new OracleSchemaStatVisitor();\n        statemen.accept(visitor);\n\n        System.out.println(\"Tables : \" + visitor.getTables());\n        System.out.println(\"fields : \" + visitor.getColumns());\n        System.out.println(\"coditions : \" + visitor.getConditions());\n        System.out.println(\"relationships : \" + visitor.getRelationships());\n        System.out.println(\"orderBy : \" + visitor.getOrderByColumns());\n\n        Assert.assertEquals(1, visitor.getTables().size());\n\n    }\n}",
    "repo": "alibaba/druid",
    "path": "./datasets/diagrams-repos/alibaba/druid/core/src/test/java/com/alibaba/druid/bvt/sql/oracle/createTable/OracleCreateTableTest89.java",
    "query": "What is the structure of the table created in the SQL statement, including its partitions and subpartitions?",
    "diagram": "{'nodes': [{'type': 'entity', 'name': 'GROUP_BILLGEN_REQUEST', 'node_id': 'GROUP_BILLGEN_REQUEST', 'description': 'Main table with billing request information', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'TableColumns', 'node_id': 'TableColumns', 'description': 'Collection of table columns', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'BG_REQ_ID', 'node_id': 'BG_REQ_ID', 'description': 'Primary billing request identifier', 'visibility': 'public', 'return_type': 'NUMBER(12,0)', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'HOME_CITY', 'node_id': 'HOME_CITY', 'description': 'City identifier used for partitioning', 'visibility': 'public', 'return_type': 'NUMBER(3,0)', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'EXEC_STATUS', 'node_id': 'EXEC_STATUS', 'description': 'Execution status used for subpartitioning', 'visibility': 'public', 'return_type': 'NUMBER(2,0)', 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'StorageParams', 'node_id': 'StorageParams', 'description': 'Storage parameters including PCTFREE, PCTUSED, etc.', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'RangePartitioning', 'node_id': 'RangePartitioning', 'description': 'Partitioning by HOME_CITY column', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'CityPartitions', 'node_id': 'CityPartitions', 'description': 'City-based partitions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'FZ_Partition', 'node_id': 'FZ_Partition', 'description': 'Partition for values less than 592', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'XM_Partition', 'node_id': 'XM_Partition', 'description': 'Partition for values less than 593', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'ListSubpartitioning', 'node_id': 'ListSubpartitioning', 'description': 'Subpartitioning by EXEC_STATUS column', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'StatusSubpartitions', 'node_id': 'StatusSubpartitions', 'description': 'Status-based subpartitions', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'TablespaceInfo', 'node_id': 'TablespaceInfo', 'description': 'Tablespace configuration ACCOUNT_DATA_TS', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'GROUP_BILLGEN_REQUEST', 'node_id_to': 'TableColumns', 'description': 'contains'}, {'node_id_from': 'TableColumns', 'node_id_to': 'BG_REQ_ID', 'description': 'includes'}, {'node_id_from': 'TableColumns', 'node_id_to': 'HOME_CITY', 'description': 'includes'}, {'node_id_from': 'TableColumns', 'node_id_to': 'EXEC_STATUS', 'description': 'includes'}, {'node_id_from': 'GROUP_BILLGEN_REQUEST', 'node_id_to': 'StorageParams', 'description': 'configured with'}, {'node_id_from': 'GROUP_BILLGEN_REQUEST', 'node_id_to': 'RangePartitioning', 'description': 'partitioned by'}, {'node_id_from': 'RangePartitioning', 'node_id_to': 'CityPartitions', 'description': 'consists of'}, {'node_id_from': 'CityPartitions', 'node_id_to': 'FZ_Partition', 'description': 'includes'}, {'node_id_from': 'CityPartitions', 'node_id_to': 'XM_Partition', 'description': 'includes'}, {'node_id_from': 'CityPartitions', 'node_id_to': 'ListSubpartitioning', 'description': 'further divided by'}, {'node_id_from': 'ListSubpartitioning', 'node_id_to': 'StatusSubpartitions', 'description': 'consists of'}, {'node_id_from': 'GROUP_BILLGEN_REQUEST', 'node_id_to': 'TablespaceInfo', 'description': 'stored in'}], 'packages': [{'package_id': 'TableDefinition', 'children': ['GROUP_BILLGEN_REQUEST', 'TableColumns', 'BG_REQ_ID', 'HOME_CITY', 'EXEC_STATUS', 'StorageParams', 'TablespaceInfo'], 'description': 'Basic table definition components'}, {'package_id': 'PartitioningHierarchy', 'children': ['RangePartitioning', 'CityPartitions', 'FZ_Partition', 'XM_Partition', 'ListSubpartitioning', 'StatusSubpartitions'], 'description': 'Complete partitioning structure'}]}",
    "version": "full",
    "text_answer": "The GROUP_BILLGEN_REQUEST table uses a two-level partitioning strategy: range partitioning by HOME_CITY column and list subpartitioning by EXEC_STATUS column. It has 9 main partitions for different cities (FZ, XM, ND, PT, QZ, ZZ, LY, SM, NP) and each partition is further divided into 5 subpartitions based on execution status (STA01-STA04, STA99).",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C",
    "code": "\n#define _C99_SOURCE 1\n#include <stdio.h>\n#include <math.h>\n#include <stdlib.h>\n\n/* pngpriv.h includes the definition of 'PNG_sRGB_FROM_LINEAR' which is required\n * to verify the actual code.\n */\n#include \"../../pngpriv.h\"\n\n#include \"sRGB.h\"\n\n/* The tables are declared 'const' in pngpriv.h, so this redefines the tables to\n * be used.\n */\n#define png_sRGB_table sRGB_table\n#define png_sRGB_base sRGB_base\n#define png_sRGB_delta sRGB_delta\n\nstatic png_uint_16 png_sRGB_table[256];\nstatic png_uint_16 png_sRGB_base[512];\nstatic png_byte png_sRGB_delta[512];\n\nstatic const unsigned int max_input = 255*65535;\n\ndouble\nfsRGB(double l)\n{\n   return sRGB_from_linear(l/max_input);\n}\n\ndouble\nsRGB(unsigned int i)\n{\n   return fsRGB(i);\n}\n\ndouble\nfinvsRGB(unsigned int i)\n{\n   return 65535 * linear_from_sRGB(i/255.);\n}\n\npng_uint_16\ninvsRGB(unsigned int i)\n{\n   unsigned int x = nearbyint(finvsRGB(i));\n\n   if (x > 65535)\n   {\n      fprintf(stderr, \"invsRGB(%u) overflows to %u\\n\", i, x);\n      exit(1);\n   }\n\n   return (png_uint_16)x;\n}\n\nint\nmain(int argc, char **argv)\n{\n   unsigned int i, i16, ibase;\n   double min_error = 0;\n   double max_error = 0;\n   double min_error16 = 0;\n   double max_error16 = 0;\n   double adjust;\n   double adjust_lo = 0.4, adjust_hi = 0.6, adjust_mid = 0.5;\n   unsigned int ec_lo = 0, ec_hi = 0, ec_mid = 0;\n   unsigned int error_count = 0;\n   unsigned int error_count16 = 0;\n   int test_only = 0;\n\n   if (argc > 1)\n      test_only = strcmp(\"--test\", argv[1]) == 0;\n\n   /* Initialize the encoding table first. */\n   for (i=0; i<256; ++i)\n   {\n      png_sRGB_table[i] = invsRGB(i);\n   }\n\n   /* Now work out the decoding tables (this is where the error comes in because\n    * there are 512 set points and 512 straight lines between them.)\n    */\n   for (;;)\n   {\n      if (ec_lo == 0)\n         adjust = adjust_lo;\n\n      else if (ec_hi == 0)\n         adjust = adjust_hi;\n\n      else if (ec_mid == 0)\n         adjust = adjust_mid;\n\n      else if (ec_mid < ec_hi)\n         adjust = (adjust_mid + adjust_hi)/2;\n\n      else if (ec_mid < ec_lo)\n         adjust = (adjust_mid + adjust_lo)/2;\n\n      else\n      {\n         fprintf(stderr, \"not reached: %u .. %u .. %u\\n\", ec_lo, ec_mid, ec_hi);\n         exit(1);\n      }\n\n      /* Calculate the table using the current 'adjust' */\n      for (i=0; i<=511; ++i)\n      {\n         double lo = 255 * sRGB(i << 15);\n         double hi = 255 * sRGB((i+1) << 15);\n         unsigned int calc;\n\n         calc = nearbyint((lo+adjust) * 256);\n         if (calc > 65535)\n         {\n            fprintf(stderr, \"table[%d][0]: overflow %08x (%d)\\n\", i, calc,\n               calc);\n            exit(1);\n         }\n         png_sRGB_base[i] = calc;\n\n         calc = nearbyint((hi-lo) * 32);\n         if (calc > 255)\n         {\n            fprintf(stderr, \"table[%d][1]: overflow %08x (%d)\\n\", i, calc,\n               calc);\n            exit(1);\n         }\n         png_sRGB_delta[i] = calc;\n      }\n\n      /* Check the 16-bit linear values alone: */\n      error_count16 = 0;\n      for (i16=0; i16 <= 65535; ++i16)\n      {\n         unsigned int i = 255*i16;\n         unsigned int iexact = nearbyint(255*sRGB(i));\n         unsigned int icalc = PNG_sRGB_FROM_LINEAR(i);\n\n         if (icalc != iexact)\n            ++error_count16;\n      }\n\n      /* Now try changing the adjustment. */\n      if (ec_lo == 0)\n         ec_lo = error_count16;\n\n      else if (ec_hi == 0)\n         ec_hi = error_count16;\n\n      else if (ec_mid == 0)\n      {\n         ec_mid = error_count16;\n         printf(\"/* initial error counts: %u .. %u .. %u */\\n\", ec_lo, ec_mid,\n            ec_hi);\n      }\n\n      else if (error_count16 < ec_mid)\n      {\n         printf(\"/* adjust (mid ): %f: %u -> %u */\\n\", adjust, ec_mid,\n            error_count16);\n         ec_mid = error_count16;\n         adjust_mid = adjust;\n      }\n\n      else if (adjust < adjust_mid && error_count16 < ec_lo)\n      {\n         printf(\"/* adjust (low ): %f: %u -> %u */\\n\", adjust, ec_lo,\n            error_count16);\n         ec_lo = error_count16;\n         adjust_lo = adjust;\n      }\n\n      else if (adjust > adjust_mid && error_count16 < ec_hi)\n      {\n         printf(\"/* adjust (high): %f: %u -> %u */\\n\", adjust, ec_hi,\n            error_count16);\n         ec_hi = error_count16;\n         adjust_hi = adjust;\n      }\n\n      else\n      {\n         adjust = adjust_mid;\n         printf(\"/* adjust: %f: %u */\\n\", adjust, ec_mid);\n         break;\n      }\n   }\n\n   /* For each entry in the table try to adjust it to minimize the error count\n    * in that entry.  Each entry corresponds to 128 input values.\n    */\n   for (ibase=0; ibase<65536; ibase+=128)\n   {\n      png_uint_16 base = png_sRGB_base[ibase >> 7], trybase = base, ob=base;\n      png_byte delta = png_sRGB_delta[ibase >> 7], trydelta = delta, od=delta;\n      unsigned int ecbase = 0, eco;\n\n      for (;;)\n      {\n         png_sRGB_base[ibase >> 7] = trybase;\n         png_sRGB_delta[ibase >> 7] = trydelta;\n\n         /* Check the 16-bit linear values alone: */\n         error_count16 = 0;\n         for (i16=ibase; i16 < ibase+128; ++i16)\n         {\n            unsigned int i = 255*i16;\n            unsigned int iexact = nearbyint(255*sRGB(i));\n            unsigned int icalc = PNG_sRGB_FROM_LINEAR(i);\n\n            if (icalc != iexact)\n               ++error_count16;\n         }\n\n         if (error_count16 == 0)\n            break;\n\n         if (ecbase == 0)\n         {\n            eco = ecbase = error_count16;\n            ++trybase; /* First test */\n         }\n\n         else if (error_count16 < ecbase)\n         {\n            if (trybase > base)\n            {\n               base = trybase;\n               ++trybase;\n            }\n            else if (trybase < base)\n            {\n               base = trybase;\n               --trybase;\n            }\n            else if (trydelta > delta)\n            {\n               delta = trydelta;\n               ++trydelta;\n            }\n            else if (trydelta < delta)\n            {\n               delta = trydelta;\n               --trydelta;\n            }\n            else\n            {\n               fprintf(stderr, \"makesRGB: impossible\\n\");\n               exit(1);\n            }\n            ecbase = error_count16;\n         }\n\n         else\n         {\n            if (trybase > base)\n               trybase = base-1;\n            else if (trybase < base)\n            {\n               trybase = base;\n               ++trydelta;\n            }\n            else if (trydelta > delta)\n               trydelta = delta-1;\n            else if (trydelta < delta)\n               break; /* end of tests */\n         }\n      }\n\n      png_sRGB_base[ibase >> 7] = base;\n      png_sRGB_delta[ibase >> 7] = delta;\n      if (base != ob || delta != od)\n      {\n         printf(\"/* table[%u]={%u,%u} -> {%u,%u} %u -> %u errors */\\n\",\n            ibase>>7, ob, od, base, delta, eco, ecbase);\n      }\n      else if (0)\n         printf(\"/* table[%u]={%u,%u} %u errors */\\n\", ibase>>7, ob, od,\n            ecbase);\n   }\n\n   /* Only do the full (slow) test at the end: */\n   min_error = -.4999;\n   max_error = .4999;\n   error_count = 0;\n\n   for (i=0; i <= max_input; ++i)\n   {\n      unsigned int iexact = nearbyint(255*sRGB(i));\n      unsigned int icalc = PNG_sRGB_FROM_LINEAR(i);\n\n      if (icalc != iexact)\n      {\n         double err = 255*sRGB(i) - icalc;\n\n         if (err > (max_error+.001) || err < (min_error-.001))\n         {\n            printf(\n               \"/* 0x%08x: exact: %3d, got: %3d [tables: %08x, %08x] (%f) */\\n\",\n               i, iexact, icalc, png_sRGB_base[i>>15],\n               png_sRGB_delta[i>>15], err);\n         }\n\n         ++error_count;\n         if (err > max_error)\n            max_error = err;\n         else if (err < min_error)\n            min_error = err;\n      }\n   }\n\n   /* Re-check the 16-bit cases too, including the warning if there is an error\n    * bigger than 1.\n    */\n   error_count16 = 0;\n   max_error16 = 0;\n   min_error16 = 0;\n   for (i16=0; i16 <= 65535; ++i16)\n   {\n      unsigned int i = 255*i16;\n      unsigned int iexact = nearbyint(255*sRGB(i));\n      unsigned int icalc = PNG_sRGB_FROM_LINEAR(i);\n\n      if (icalc != iexact)\n      {\n         double err = 255*sRGB(i) - icalc;\n\n         ++error_count16;\n         if (err > max_error16)\n            max_error16 = err;\n         else if (err < min_error16)\n            min_error16 = err;\n\n         if (abs(icalc - iexact) > 1)\n            printf(\n               \"/* 0x%04x: exact: %3d, got: %3d [tables: %08x, %08x] (%f) */\\n\",\n               i16, iexact, icalc, png_sRGB_base[i>>15],\n               png_sRGB_delta[i>>15], err);\n      }\n   }\n\n   /* Check the round trip for each 8-bit sRGB value. */\n   for (i16=0; i16 <= 255; ++i16)\n   {\n      unsigned int i = 255 * png_sRGB_table[i16];\n      unsigned int iexact = nearbyint(255*sRGB(i));\n      unsigned int icalc = PNG_sRGB_FROM_LINEAR(i);\n\n      if (i16 != iexact)\n      {\n         fprintf(stderr, \"8-bit rounding error: %d -> %d\\n\", i16, iexact);\n         exit(1);\n      }\n\n      if (icalc != i16)\n      {\n         double finv = finvsRGB(i16);\n\n         printf(\"/* 8-bit roundtrip error: %d -> %f -> %d(%f) */\\n\",\n            i16, finv, icalc, fsRGB(255*finv));\n      }\n   }\n\n\n   printf(\"/* error: %g - %g, %u (%g%%) of readings inexact */\\n\",\n      min_error, max_error, error_count, (100.*error_count)/max_input);\n   printf(\"/* 16-bit error: %g - %g, %u (%g%%) of readings inexact */\\n\",\n      min_error16, max_error16, error_count16, (100.*error_count16)/65535);\n\n   if (!test_only)\n   {\n      printf(\"const png_uint_16 png_sRGB_table[256] =\\n{\\n   \");\n      for (i=0; i<255; )\n      {\n         do\n         {\n            printf(\"%d,\", png_sRGB_table[i++]);\n         }\n         while ((i & 0x7) != 0 && i<255);\n         if (i<255) printf(\"\\n   \");\n      }\n      printf(\"%d\\n};\\n\\n\", png_sRGB_table[i]);\n\n\n      printf(\"const png_uint_16 png_sRGB_base[512] =\\n{\\n   \");\n      for (i=0; i<511; )\n      {\n         do\n         {\n            printf(\"%d,\", png_sRGB_base[i++]);\n         }\n         while ((i & 0x7) != 0 && i<511);\n         if (i<511) printf(\"\\n   \");\n      }\n      printf(\"%d\\n};\\n\\n\", png_sRGB_base[i]);\n\n      printf(\"const png_byte png_sRGB_delta[512] =\\n{\\n   \");\n      for (i=0; i<511; )\n      {\n         do\n         {\n            printf(\"%d,\", png_sRGB_delta[i++]);\n         }\n         while ((i & 0xf) != 0 && i<511);\n         if (i<511) printf(\"\\n   \");\n      }\n      printf(\"%d\\n};\\n\\n\", png_sRGB_delta[i]);\n   }\n\n   return 0;\n}",
    "repo": "nesbox/TIC-80",
    "path": "./datasets/diagrams-repos/nesbox/TIC-80/vendor/libpng/contrib/tools/makesRGB.c",
    "query": "Illustrate the relationships between the png_sRGB_table, png_sRGB_base, and png_sRGB_delta tables.",
    "diagram": "{'nodes': [{'type': 'variable', 'name': 'png_sRGB_table', 'node_id': 'png_sRGB_table', 'description': 'Table for sRGB encoding (256 entries)', 'visibility': 'private', 'return_type': 'png_uint_16[]', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'png_sRGB_base', 'node_id': 'png_sRGB_base', 'description': 'Base values for sRGB decoding (512 entries)', 'visibility': 'private', 'return_type': 'png_uint_16[]', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'png_sRGB_delta', 'node_id': 'png_sRGB_delta', 'description': 'Delta values for sRGB decoding (512 entries)', 'visibility': 'private', 'return_type': 'png_byte[]', 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'png_sRGB_table', 'node_id_to': 'png_sRGB_base', 'description': 'Used for roundtrip conversion'}, {'node_id_from': 'png_sRGB_base', 'node_id_to': 'png_sRGB_delta', 'description': 'Used together for decoding'}], 'packages': [{'package_id': 'sRGBTables', 'children': ['png_sRGB_table', 'png_sRGB_base', 'png_sRGB_delta'], 'description': 'Tables for sRGB color space conversion'}]}",
    "version": "minimal",
    "text_answer": "The png_sRGB_table (256 entries) is used for encoding, while png_sRGB_base and png_sRGB_delta (512 entries each) work together for decoding. The tables are interconnected for roundtrip color space conversion between linear RGB and sRGB.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C",
    "code": "\n#define _C99_SOURCE 1\n#include <stdio.h>\n#include <math.h>\n#include <stdlib.h>\n\n/* pngpriv.h includes the definition of 'PNG_sRGB_FROM_LINEAR' which is required\n * to verify the actual code.\n */\n#include \"../../pngpriv.h\"\n\n#include \"sRGB.h\"\n\n/* The tables are declared 'const' in pngpriv.h, so this redefines the tables to\n * be used.\n */\n#define png_sRGB_table sRGB_table\n#define png_sRGB_base sRGB_base\n#define png_sRGB_delta sRGB_delta\n\nstatic png_uint_16 png_sRGB_table[256];\nstatic png_uint_16 png_sRGB_base[512];\nstatic png_byte png_sRGB_delta[512];\n\nstatic const unsigned int max_input = 255*65535;\n\ndouble\nfsRGB(double l)\n{\n   return sRGB_from_linear(l/max_input);\n}\n\ndouble\nsRGB(unsigned int i)\n{\n   return fsRGB(i);\n}\n\ndouble\nfinvsRGB(unsigned int i)\n{\n   return 65535 * linear_from_sRGB(i/255.);\n}\n\npng_uint_16\ninvsRGB(unsigned int i)\n{\n   unsigned int x = nearbyint(finvsRGB(i));\n\n   if (x > 65535)\n   {\n      fprintf(stderr, \"invsRGB(%u) overflows to %u\\n\", i, x);\n      exit(1);\n   }\n\n   return (png_uint_16)x;\n}\n\nint\nmain(int argc, char **argv)\n{\n   unsigned int i, i16, ibase;\n   double min_error = 0;\n   double max_error = 0;\n   double min_error16 = 0;\n   double max_error16 = 0;\n   double adjust;\n   double adjust_lo = 0.4, adjust_hi = 0.6, adjust_mid = 0.5;\n   unsigned int ec_lo = 0, ec_hi = 0, ec_mid = 0;\n   unsigned int error_count = 0;\n   unsigned int error_count16 = 0;\n   int test_only = 0;\n\n   if (argc > 1)\n      test_only = strcmp(\"--test\", argv[1]) == 0;\n\n   /* Initialize the encoding table first. */\n   for (i=0; i<256; ++i)\n   {\n      png_sRGB_table[i] = invsRGB(i);\n   }\n\n   /* Now work out the decoding tables (this is where the error comes in because\n    * there are 512 set points and 512 straight lines between them.)\n    */\n   for (;;)\n   {\n      if (ec_lo == 0)\n         adjust = adjust_lo;\n\n      else if (ec_hi == 0)\n         adjust = adjust_hi;\n\n      else if (ec_mid == 0)\n         adjust = adjust_mid;\n\n      else if (ec_mid < ec_hi)\n         adjust = (adjust_mid + adjust_hi)/2;\n\n      else if (ec_mid < ec_lo)\n         adjust = (adjust_mid + adjust_lo)/2;\n\n      else\n      {\n         fprintf(stderr, \"not reached: %u .. %u .. %u\\n\", ec_lo, ec_mid, ec_hi);\n         exit(1);\n      }\n\n      /* Calculate the table using the current 'adjust' */\n      for (i=0; i<=511; ++i)\n      {\n         double lo = 255 * sRGB(i << 15);\n         double hi = 255 * sRGB((i+1) << 15);\n         unsigned int calc;\n\n         calc = nearbyint((lo+adjust) * 256);\n         if (calc > 65535)\n         {\n            fprintf(stderr, \"table[%d][0]: overflow %08x (%d)\\n\", i, calc,\n               calc);\n            exit(1);\n         }\n         png_sRGB_base[i] = calc;\n\n         calc = nearbyint((hi-lo) * 32);\n         if (calc > 255)\n         {\n            fprintf(stderr, \"table[%d][1]: overflow %08x (%d)\\n\", i, calc,\n               calc);\n            exit(1);\n         }\n         png_sRGB_delta[i] = calc;\n      }\n\n      /* Check the 16-bit linear values alone: */\n      error_count16 = 0;\n      for (i16=0; i16 <= 65535; ++i16)\n      {\n         unsigned int i = 255*i16;\n         unsigned int iexact = nearbyint(255*sRGB(i));\n         unsigned int icalc = PNG_sRGB_FROM_LINEAR(i);\n\n         if (icalc != iexact)\n            ++error_count16;\n      }\n\n      /* Now try changing the adjustment. */\n      if (ec_lo == 0)\n         ec_lo = error_count16;\n\n      else if (ec_hi == 0)\n         ec_hi = error_count16;\n\n      else if (ec_mid == 0)\n      {\n         ec_mid = error_count16;\n         printf(\"/* initial error counts: %u .. %u .. %u */\\n\", ec_lo, ec_mid,\n            ec_hi);\n      }\n\n      else if (error_count16 < ec_mid)\n      {\n         printf(\"/* adjust (mid ): %f: %u -> %u */\\n\", adjust, ec_mid,\n            error_count16);\n         ec_mid = error_count16;\n         adjust_mid = adjust;\n      }\n\n      else if (adjust < adjust_mid && error_count16 < ec_lo)\n      {\n         printf(\"/* adjust (low ): %f: %u -> %u */\\n\", adjust, ec_lo,\n            error_count16);\n         ec_lo = error_count16;\n         adjust_lo = adjust;\n      }\n\n      else if (adjust > adjust_mid && error_count16 < ec_hi)\n      {\n         printf(\"/* adjust (high): %f: %u -> %u */\\n\", adjust, ec_hi,\n            error_count16);\n         ec_hi = error_count16;\n         adjust_hi = adjust;\n      }\n\n      else\n      {\n         adjust = adjust_mid;\n         printf(\"/* adjust: %f: %u */\\n\", adjust, ec_mid);\n         break;\n      }\n   }\n\n   /* For each entry in the table try to adjust it to minimize the error count\n    * in that entry.  Each entry corresponds to 128 input values.\n    */\n   for (ibase=0; ibase<65536; ibase+=128)\n   {\n      png_uint_16 base = png_sRGB_base[ibase >> 7], trybase = base, ob=base;\n      png_byte delta = png_sRGB_delta[ibase >> 7], trydelta = delta, od=delta;\n      unsigned int ecbase = 0, eco;\n\n      for (;;)\n      {\n         png_sRGB_base[ibase >> 7] = trybase;\n         png_sRGB_delta[ibase >> 7] = trydelta;\n\n         /* Check the 16-bit linear values alone: */\n         error_count16 = 0;\n         for (i16=ibase; i16 < ibase+128; ++i16)\n         {\n            unsigned int i = 255*i16;\n            unsigned int iexact = nearbyint(255*sRGB(i));\n            unsigned int icalc = PNG_sRGB_FROM_LINEAR(i);\n\n            if (icalc != iexact)\n               ++error_count16;\n         }\n\n         if (error_count16 == 0)\n            break;\n\n         if (ecbase == 0)\n         {\n            eco = ecbase = error_count16;\n            ++trybase; /* First test */\n         }\n\n         else if (error_count16 < ecbase)\n         {\n            if (trybase > base)\n            {\n               base = trybase;\n               ++trybase;\n            }\n            else if (trybase < base)\n            {\n               base = trybase;\n               --trybase;\n            }\n            else if (trydelta > delta)\n            {\n               delta = trydelta;\n               ++trydelta;\n            }\n            else if (trydelta < delta)\n            {\n               delta = trydelta;\n               --trydelta;\n            }\n            else\n            {\n               fprintf(stderr, \"makesRGB: impossible\\n\");\n               exit(1);\n            }\n            ecbase = error_count16;\n         }\n\n         else\n         {\n            if (trybase > base)\n               trybase = base-1;\n            else if (trybase < base)\n            {\n               trybase = base;\n               ++trydelta;\n            }\n            else if (trydelta > delta)\n               trydelta = delta-1;\n            else if (trydelta < delta)\n               break; /* end of tests */\n         }\n      }\n\n      png_sRGB_base[ibase >> 7] = base;\n      png_sRGB_delta[ibase >> 7] = delta;\n      if (base != ob || delta != od)\n      {\n         printf(\"/* table[%u]={%u,%u} -> {%u,%u} %u -> %u errors */\\n\",\n            ibase>>7, ob, od, base, delta, eco, ecbase);\n      }\n      else if (0)\n         printf(\"/* table[%u]={%u,%u} %u errors */\\n\", ibase>>7, ob, od,\n            ecbase);\n   }\n\n   /* Only do the full (slow) test at the end: */\n   min_error = -.4999;\n   max_error = .4999;\n   error_count = 0;\n\n   for (i=0; i <= max_input; ++i)\n   {\n      unsigned int iexact = nearbyint(255*sRGB(i));\n      unsigned int icalc = PNG_sRGB_FROM_LINEAR(i);\n\n      if (icalc != iexact)\n      {\n         double err = 255*sRGB(i) - icalc;\n\n         if (err > (max_error+.001) || err < (min_error-.001))\n         {\n            printf(\n               \"/* 0x%08x: exact: %3d, got: %3d [tables: %08x, %08x] (%f) */\\n\",\n               i, iexact, icalc, png_sRGB_base[i>>15],\n               png_sRGB_delta[i>>15], err);\n         }\n\n         ++error_count;\n         if (err > max_error)\n            max_error = err;\n         else if (err < min_error)\n            min_error = err;\n      }\n   }\n\n   /* Re-check the 16-bit cases too, including the warning if there is an error\n    * bigger than 1.\n    */\n   error_count16 = 0;\n   max_error16 = 0;\n   min_error16 = 0;\n   for (i16=0; i16 <= 65535; ++i16)\n   {\n      unsigned int i = 255*i16;\n      unsigned int iexact = nearbyint(255*sRGB(i));\n      unsigned int icalc = PNG_sRGB_FROM_LINEAR(i);\n\n      if (icalc != iexact)\n      {\n         double err = 255*sRGB(i) - icalc;\n\n         ++error_count16;\n         if (err > max_error16)\n            max_error16 = err;\n         else if (err < min_error16)\n            min_error16 = err;\n\n         if (abs(icalc - iexact) > 1)\n            printf(\n               \"/* 0x%04x: exact: %3d, got: %3d [tables: %08x, %08x] (%f) */\\n\",\n               i16, iexact, icalc, png_sRGB_base[i>>15],\n               png_sRGB_delta[i>>15], err);\n      }\n   }\n\n   /* Check the round trip for each 8-bit sRGB value. */\n   for (i16=0; i16 <= 255; ++i16)\n   {\n      unsigned int i = 255 * png_sRGB_table[i16];\n      unsigned int iexact = nearbyint(255*sRGB(i));\n      unsigned int icalc = PNG_sRGB_FROM_LINEAR(i);\n\n      if (i16 != iexact)\n      {\n         fprintf(stderr, \"8-bit rounding error: %d -> %d\\n\", i16, iexact);\n         exit(1);\n      }\n\n      if (icalc != i16)\n      {\n         double finv = finvsRGB(i16);\n\n         printf(\"/* 8-bit roundtrip error: %d -> %f -> %d(%f) */\\n\",\n            i16, finv, icalc, fsRGB(255*finv));\n      }\n   }\n\n\n   printf(\"/* error: %g - %g, %u (%g%%) of readings inexact */\\n\",\n      min_error, max_error, error_count, (100.*error_count)/max_input);\n   printf(\"/* 16-bit error: %g - %g, %u (%g%%) of readings inexact */\\n\",\n      min_error16, max_error16, error_count16, (100.*error_count16)/65535);\n\n   if (!test_only)\n   {\n      printf(\"const png_uint_16 png_sRGB_table[256] =\\n{\\n   \");\n      for (i=0; i<255; )\n      {\n         do\n         {\n            printf(\"%d,\", png_sRGB_table[i++]);\n         }\n         while ((i & 0x7) != 0 && i<255);\n         if (i<255) printf(\"\\n   \");\n      }\n      printf(\"%d\\n};\\n\\n\", png_sRGB_table[i]);\n\n\n      printf(\"const png_uint_16 png_sRGB_base[512] =\\n{\\n   \");\n      for (i=0; i<511; )\n      {\n         do\n         {\n            printf(\"%d,\", png_sRGB_base[i++]);\n         }\n         while ((i & 0x7) != 0 && i<511);\n         if (i<511) printf(\"\\n   \");\n      }\n      printf(\"%d\\n};\\n\\n\", png_sRGB_base[i]);\n\n      printf(\"const png_byte png_sRGB_delta[512] =\\n{\\n   \");\n      for (i=0; i<511; )\n      {\n         do\n         {\n            printf(\"%d,\", png_sRGB_delta[i++]);\n         }\n         while ((i & 0xf) != 0 && i<511);\n         if (i<511) printf(\"\\n   \");\n      }\n      printf(\"%d\\n};\\n\\n\", png_sRGB_delta[i]);\n   }\n\n   return 0;\n}",
    "repo": "nesbox/TIC-80",
    "path": "./datasets/diagrams-repos/nesbox/TIC-80/vendor/libpng/contrib/tools/makesRGB.c",
    "query": "Illustrate the relationships between the png_sRGB_table, png_sRGB_base, and png_sRGB_delta tables.",
    "diagram": "{'nodes': [{'type': 'variable', 'name': 'png_sRGB_table', 'node_id': 'png_sRGB_table', 'description': 'Table for sRGB encoding (256 entries)', 'visibility': 'private', 'return_type': 'png_uint_16[]', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'png_sRGB_base', 'node_id': 'png_sRGB_base', 'description': 'Base values for sRGB decoding (512 entries)', 'visibility': 'private', 'return_type': 'png_uint_16[]', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'png_sRGB_delta', 'node_id': 'png_sRGB_delta', 'description': 'Delta values for sRGB decoding (512 entries)', 'visibility': 'private', 'return_type': 'png_byte[]', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'invsRGB', 'node_id': 'invsRGB', 'description': 'Converts sRGB to linear RGB', 'visibility': 'public', 'return_type': 'png_uint_16', 'params': 'unsigned int i', 'source_class_id': None}, {'type': 'entity', 'name': 'sRGBEncoding', 'node_id': 'sRGBEncoding', 'description': 'Process of encoding linear RGB to sRGB', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'sRGBDecoding', 'node_id': 'sRGBDecoding', 'description': 'Process of decoding sRGB to linear RGB', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'png_sRGB_table', 'node_id_to': 'png_sRGB_base', 'description': 'Used for roundtrip conversion'}, {'node_id_from': 'png_sRGB_base', 'node_id_to': 'png_sRGB_delta', 'description': 'Used together for decoding'}, {'node_id_from': 'invsRGB', 'node_id_to': 'png_sRGB_table', 'description': 'Initializes table'}, {'node_id_from': 'sRGBEncoding', 'node_id_to': 'png_sRGB_table', 'description': 'Uses for encoding'}, {'node_id_from': 'sRGBDecoding', 'node_id_to': 'png_sRGB_base', 'description': 'Uses for decoding'}, {'node_id_from': 'sRGBDecoding', 'node_id_to': 'png_sRGB_delta', 'description': 'Uses for decoding'}], 'packages': [{'package_id': 'sRGBTables', 'children': ['png_sRGB_table', 'png_sRGB_base', 'png_sRGB_delta'], 'description': 'Tables for sRGB color space conversion'}, {'package_id': 'sRGBOperations', 'children': ['sRGBEncoding', 'sRGBDecoding', 'invsRGB'], 'description': 'Operations for sRGB conversion'}]}",
    "version": "medium",
    "text_answer": "The png_sRGB_table (256 entries) is used for encoding, while png_sRGB_base and png_sRGB_delta (512 entries each) work together for decoding. The tables are interconnected for roundtrip color space conversion between linear RGB and sRGB.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C",
    "code": "\n#define _C99_SOURCE 1\n#include <stdio.h>\n#include <math.h>\n#include <stdlib.h>\n\n/* pngpriv.h includes the definition of 'PNG_sRGB_FROM_LINEAR' which is required\n * to verify the actual code.\n */\n#include \"../../pngpriv.h\"\n\n#include \"sRGB.h\"\n\n/* The tables are declared 'const' in pngpriv.h, so this redefines the tables to\n * be used.\n */\n#define png_sRGB_table sRGB_table\n#define png_sRGB_base sRGB_base\n#define png_sRGB_delta sRGB_delta\n\nstatic png_uint_16 png_sRGB_table[256];\nstatic png_uint_16 png_sRGB_base[512];\nstatic png_byte png_sRGB_delta[512];\n\nstatic const unsigned int max_input = 255*65535;\n\ndouble\nfsRGB(double l)\n{\n   return sRGB_from_linear(l/max_input);\n}\n\ndouble\nsRGB(unsigned int i)\n{\n   return fsRGB(i);\n}\n\ndouble\nfinvsRGB(unsigned int i)\n{\n   return 65535 * linear_from_sRGB(i/255.);\n}\n\npng_uint_16\ninvsRGB(unsigned int i)\n{\n   unsigned int x = nearbyint(finvsRGB(i));\n\n   if (x > 65535)\n   {\n      fprintf(stderr, \"invsRGB(%u) overflows to %u\\n\", i, x);\n      exit(1);\n   }\n\n   return (png_uint_16)x;\n}\n\nint\nmain(int argc, char **argv)\n{\n   unsigned int i, i16, ibase;\n   double min_error = 0;\n   double max_error = 0;\n   double min_error16 = 0;\n   double max_error16 = 0;\n   double adjust;\n   double adjust_lo = 0.4, adjust_hi = 0.6, adjust_mid = 0.5;\n   unsigned int ec_lo = 0, ec_hi = 0, ec_mid = 0;\n   unsigned int error_count = 0;\n   unsigned int error_count16 = 0;\n   int test_only = 0;\n\n   if (argc > 1)\n      test_only = strcmp(\"--test\", argv[1]) == 0;\n\n   /* Initialize the encoding table first. */\n   for (i=0; i<256; ++i)\n   {\n      png_sRGB_table[i] = invsRGB(i);\n   }\n\n   /* Now work out the decoding tables (this is where the error comes in because\n    * there are 512 set points and 512 straight lines between them.)\n    */\n   for (;;)\n   {\n      if (ec_lo == 0)\n         adjust = adjust_lo;\n\n      else if (ec_hi == 0)\n         adjust = adjust_hi;\n\n      else if (ec_mid == 0)\n         adjust = adjust_mid;\n\n      else if (ec_mid < ec_hi)\n         adjust = (adjust_mid + adjust_hi)/2;\n\n      else if (ec_mid < ec_lo)\n         adjust = (adjust_mid + adjust_lo)/2;\n\n      else\n      {\n         fprintf(stderr, \"not reached: %u .. %u .. %u\\n\", ec_lo, ec_mid, ec_hi);\n         exit(1);\n      }\n\n      /* Calculate the table using the current 'adjust' */\n      for (i=0; i<=511; ++i)\n      {\n         double lo = 255 * sRGB(i << 15);\n         double hi = 255 * sRGB((i+1) << 15);\n         unsigned int calc;\n\n         calc = nearbyint((lo+adjust) * 256);\n         if (calc > 65535)\n         {\n            fprintf(stderr, \"table[%d][0]: overflow %08x (%d)\\n\", i, calc,\n               calc);\n            exit(1);\n         }\n         png_sRGB_base[i] = calc;\n\n         calc = nearbyint((hi-lo) * 32);\n         if (calc > 255)\n         {\n            fprintf(stderr, \"table[%d][1]: overflow %08x (%d)\\n\", i, calc,\n               calc);\n            exit(1);\n         }\n         png_sRGB_delta[i] = calc;\n      }\n\n      /* Check the 16-bit linear values alone: */\n      error_count16 = 0;\n      for (i16=0; i16 <= 65535; ++i16)\n      {\n         unsigned int i = 255*i16;\n         unsigned int iexact = nearbyint(255*sRGB(i));\n         unsigned int icalc = PNG_sRGB_FROM_LINEAR(i);\n\n         if (icalc != iexact)\n            ++error_count16;\n      }\n\n      /* Now try changing the adjustment. */\n      if (ec_lo == 0)\n         ec_lo = error_count16;\n\n      else if (ec_hi == 0)\n         ec_hi = error_count16;\n\n      else if (ec_mid == 0)\n      {\n         ec_mid = error_count16;\n         printf(\"/* initial error counts: %u .. %u .. %u */\\n\", ec_lo, ec_mid,\n            ec_hi);\n      }\n\n      else if (error_count16 < ec_mid)\n      {\n         printf(\"/* adjust (mid ): %f: %u -> %u */\\n\", adjust, ec_mid,\n            error_count16);\n         ec_mid = error_count16;\n         adjust_mid = adjust;\n      }\n\n      else if (adjust < adjust_mid && error_count16 < ec_lo)\n      {\n         printf(\"/* adjust (low ): %f: %u -> %u */\\n\", adjust, ec_lo,\n            error_count16);\n         ec_lo = error_count16;\n         adjust_lo = adjust;\n      }\n\n      else if (adjust > adjust_mid && error_count16 < ec_hi)\n      {\n         printf(\"/* adjust (high): %f: %u -> %u */\\n\", adjust, ec_hi,\n            error_count16);\n         ec_hi = error_count16;\n         adjust_hi = adjust;\n      }\n\n      else\n      {\n         adjust = adjust_mid;\n         printf(\"/* adjust: %f: %u */\\n\", adjust, ec_mid);\n         break;\n      }\n   }\n\n   /* For each entry in the table try to adjust it to minimize the error count\n    * in that entry.  Each entry corresponds to 128 input values.\n    */\n   for (ibase=0; ibase<65536; ibase+=128)\n   {\n      png_uint_16 base = png_sRGB_base[ibase >> 7], trybase = base, ob=base;\n      png_byte delta = png_sRGB_delta[ibase >> 7], trydelta = delta, od=delta;\n      unsigned int ecbase = 0, eco;\n\n      for (;;)\n      {\n         png_sRGB_base[ibase >> 7] = trybase;\n         png_sRGB_delta[ibase >> 7] = trydelta;\n\n         /* Check the 16-bit linear values alone: */\n         error_count16 = 0;\n         for (i16=ibase; i16 < ibase+128; ++i16)\n         {\n            unsigned int i = 255*i16;\n            unsigned int iexact = nearbyint(255*sRGB(i));\n            unsigned int icalc = PNG_sRGB_FROM_LINEAR(i);\n\n            if (icalc != iexact)\n               ++error_count16;\n         }\n\n         if (error_count16 == 0)\n            break;\n\n         if (ecbase == 0)\n         {\n            eco = ecbase = error_count16;\n            ++trybase; /* First test */\n         }\n\n         else if (error_count16 < ecbase)\n         {\n            if (trybase > base)\n            {\n               base = trybase;\n               ++trybase;\n            }\n            else if (trybase < base)\n            {\n               base = trybase;\n               --trybase;\n            }\n            else if (trydelta > delta)\n            {\n               delta = trydelta;\n               ++trydelta;\n            }\n            else if (trydelta < delta)\n            {\n               delta = trydelta;\n               --trydelta;\n            }\n            else\n            {\n               fprintf(stderr, \"makesRGB: impossible\\n\");\n               exit(1);\n            }\n            ecbase = error_count16;\n         }\n\n         else\n         {\n            if (trybase > base)\n               trybase = base-1;\n            else if (trybase < base)\n            {\n               trybase = base;\n               ++trydelta;\n            }\n            else if (trydelta > delta)\n               trydelta = delta-1;\n            else if (trydelta < delta)\n               break; /* end of tests */\n         }\n      }\n\n      png_sRGB_base[ibase >> 7] = base;\n      png_sRGB_delta[ibase >> 7] = delta;\n      if (base != ob || delta != od)\n      {\n         printf(\"/* table[%u]={%u,%u} -> {%u,%u} %u -> %u errors */\\n\",\n            ibase>>7, ob, od, base, delta, eco, ecbase);\n      }\n      else if (0)\n         printf(\"/* table[%u]={%u,%u} %u errors */\\n\", ibase>>7, ob, od,\n            ecbase);\n   }\n\n   /* Only do the full (slow) test at the end: */\n   min_error = -.4999;\n   max_error = .4999;\n   error_count = 0;\n\n   for (i=0; i <= max_input; ++i)\n   {\n      unsigned int iexact = nearbyint(255*sRGB(i));\n      unsigned int icalc = PNG_sRGB_FROM_LINEAR(i);\n\n      if (icalc != iexact)\n      {\n         double err = 255*sRGB(i) - icalc;\n\n         if (err > (max_error+.001) || err < (min_error-.001))\n         {\n            printf(\n               \"/* 0x%08x: exact: %3d, got: %3d [tables: %08x, %08x] (%f) */\\n\",\n               i, iexact, icalc, png_sRGB_base[i>>15],\n               png_sRGB_delta[i>>15], err);\n         }\n\n         ++error_count;\n         if (err > max_error)\n            max_error = err;\n         else if (err < min_error)\n            min_error = err;\n      }\n   }\n\n   /* Re-check the 16-bit cases too, including the warning if there is an error\n    * bigger than 1.\n    */\n   error_count16 = 0;\n   max_error16 = 0;\n   min_error16 = 0;\n   for (i16=0; i16 <= 65535; ++i16)\n   {\n      unsigned int i = 255*i16;\n      unsigned int iexact = nearbyint(255*sRGB(i));\n      unsigned int icalc = PNG_sRGB_FROM_LINEAR(i);\n\n      if (icalc != iexact)\n      {\n         double err = 255*sRGB(i) - icalc;\n\n         ++error_count16;\n         if (err > max_error16)\n            max_error16 = err;\n         else if (err < min_error16)\n            min_error16 = err;\n\n         if (abs(icalc - iexact) > 1)\n            printf(\n               \"/* 0x%04x: exact: %3d, got: %3d [tables: %08x, %08x] (%f) */\\n\",\n               i16, iexact, icalc, png_sRGB_base[i>>15],\n               png_sRGB_delta[i>>15], err);\n      }\n   }\n\n   /* Check the round trip for each 8-bit sRGB value. */\n   for (i16=0; i16 <= 255; ++i16)\n   {\n      unsigned int i = 255 * png_sRGB_table[i16];\n      unsigned int iexact = nearbyint(255*sRGB(i));\n      unsigned int icalc = PNG_sRGB_FROM_LINEAR(i);\n\n      if (i16 != iexact)\n      {\n         fprintf(stderr, \"8-bit rounding error: %d -> %d\\n\", i16, iexact);\n         exit(1);\n      }\n\n      if (icalc != i16)\n      {\n         double finv = finvsRGB(i16);\n\n         printf(\"/* 8-bit roundtrip error: %d -> %f -> %d(%f) */\\n\",\n            i16, finv, icalc, fsRGB(255*finv));\n      }\n   }\n\n\n   printf(\"/* error: %g - %g, %u (%g%%) of readings inexact */\\n\",\n      min_error, max_error, error_count, (100.*error_count)/max_input);\n   printf(\"/* 16-bit error: %g - %g, %u (%g%%) of readings inexact */\\n\",\n      min_error16, max_error16, error_count16, (100.*error_count16)/65535);\n\n   if (!test_only)\n   {\n      printf(\"const png_uint_16 png_sRGB_table[256] =\\n{\\n   \");\n      for (i=0; i<255; )\n      {\n         do\n         {\n            printf(\"%d,\", png_sRGB_table[i++]);\n         }\n         while ((i & 0x7) != 0 && i<255);\n         if (i<255) printf(\"\\n   \");\n      }\n      printf(\"%d\\n};\\n\\n\", png_sRGB_table[i]);\n\n\n      printf(\"const png_uint_16 png_sRGB_base[512] =\\n{\\n   \");\n      for (i=0; i<511; )\n      {\n         do\n         {\n            printf(\"%d,\", png_sRGB_base[i++]);\n         }\n         while ((i & 0x7) != 0 && i<511);\n         if (i<511) printf(\"\\n   \");\n      }\n      printf(\"%d\\n};\\n\\n\", png_sRGB_base[i]);\n\n      printf(\"const png_byte png_sRGB_delta[512] =\\n{\\n   \");\n      for (i=0; i<511; )\n      {\n         do\n         {\n            printf(\"%d,\", png_sRGB_delta[i++]);\n         }\n         while ((i & 0xf) != 0 && i<511);\n         if (i<511) printf(\"\\n   \");\n      }\n      printf(\"%d\\n};\\n\\n\", png_sRGB_delta[i]);\n   }\n\n   return 0;\n}",
    "repo": "nesbox/TIC-80",
    "path": "./datasets/diagrams-repos/nesbox/TIC-80/vendor/libpng/contrib/tools/makesRGB.c",
    "query": "Illustrate the relationships between the png_sRGB_table, png_sRGB_base, and png_sRGB_delta tables.",
    "diagram": "{'nodes': [{'type': 'variable', 'name': 'png_sRGB_table', 'node_id': 'png_sRGB_table', 'description': 'Table for sRGB encoding (256 entries)', 'visibility': 'private', 'return_type': 'png_uint_16[]', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'png_sRGB_base', 'node_id': 'png_sRGB_base', 'description': 'Base values for sRGB decoding (512 entries)', 'visibility': 'private', 'return_type': 'png_uint_16[]', 'params': None, 'source_class_id': None}, {'type': 'variable', 'name': 'png_sRGB_delta', 'node_id': 'png_sRGB_delta', 'description': 'Delta values for sRGB decoding (512 entries)', 'visibility': 'private', 'return_type': 'png_byte[]', 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'invsRGB', 'node_id': 'invsRGB', 'description': 'Converts sRGB to linear RGB', 'visibility': 'public', 'return_type': 'png_uint_16', 'params': 'unsigned int i', 'source_class_id': None}, {'type': 'function', 'name': 'fsRGB', 'node_id': 'fsRGB', 'description': 'Floating-point sRGB conversion', 'visibility': 'public', 'return_type': 'double', 'params': 'double l', 'source_class_id': None}, {'type': 'function', 'name': 'sRGB', 'node_id': 'sRGB', 'description': 'Integer sRGB conversion', 'visibility': 'public', 'return_type': 'double', 'params': 'unsigned int i', 'source_class_id': None}, {'type': 'function', 'name': 'finvsRGB', 'node_id': 'finvsRGB', 'description': 'Floating-point inverse sRGB conversion', 'visibility': 'public', 'return_type': 'double', 'params': 'unsigned int i', 'source_class_id': None}, {'type': 'entity', 'name': 'sRGBEncoding', 'node_id': 'sRGBEncoding', 'description': 'Process of encoding linear RGB to sRGB', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'sRGBDecoding', 'node_id': 'sRGBDecoding', 'description': 'Process of decoding sRGB to linear RGB', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'ErrorChecking', 'node_id': 'ErrorChecking', 'description': 'Validation of conversion accuracy', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'png_sRGB_table', 'node_id_to': 'png_sRGB_base', 'description': 'Used for roundtrip conversion'}, {'node_id_from': 'png_sRGB_base', 'node_id_to': 'png_sRGB_delta', 'description': 'Used together for decoding'}, {'node_id_from': 'invsRGB', 'node_id_to': 'png_sRGB_table', 'description': 'Initializes table'}, {'node_id_from': 'fsRGB', 'node_id_to': 'sRGB', 'description': 'Called by'}, {'node_id_from': 'sRGB', 'node_id_to': 'ErrorChecking', 'description': 'Used for validation'}, {'node_id_from': 'finvsRGB', 'node_id_to': 'invsRGB', 'description': 'Used by'}, {'node_id_from': 'sRGBEncoding', 'node_id_to': 'png_sRGB_table', 'description': 'Uses for encoding'}, {'node_id_from': 'sRGBDecoding', 'node_id_to': 'png_sRGB_base', 'description': 'Uses for decoding'}, {'node_id_from': 'sRGBDecoding', 'node_id_to': 'png_sRGB_delta', 'description': 'Uses for decoding'}, {'node_id_from': 'ErrorChecking', 'node_id_to': 'png_sRGB_table', 'description': 'Validates'}, {'node_id_from': 'ErrorChecking', 'node_id_to': 'png_sRGB_base', 'description': 'Validates'}, {'node_id_from': 'ErrorChecking', 'node_id_to': 'png_sRGB_delta', 'description': 'Validates'}], 'packages': [{'package_id': 'sRGBTables', 'children': ['png_sRGB_table', 'png_sRGB_base', 'png_sRGB_delta'], 'description': 'Tables for sRGB color space conversion'}, {'package_id': 'sRGBOperations', 'children': ['sRGBEncoding', 'sRGBDecoding', 'invsRGB', 'fsRGB', 'sRGB', 'finvsRGB'], 'description': 'Operations for sRGB conversion'}]}",
    "version": "full",
    "text_answer": "The png_sRGB_table (256 entries) is used for encoding, while png_sRGB_base and png_sRGB_delta (512 entries each) work together for decoding. The tables are interconnected for roundtrip color space conversion between linear RGB and sRGB.",
    "possible_version": [
      "full"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include \"mlir/Dialect/Arith/IR/Arith.h\"\n\n#include <variant>  // NOLINT\n\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/Support/ErrorHandling.h\"\n#include \"mlir/IR/Builders.h\"\n#include \"mlir/IR/BuiltinAttributes.h\"\n#include \"mlir/IR/BuiltinTypeInterfaces.h\"\n#include \"mlir/IR/Types.h\"\n#include \"mlir/Support/LLVM.h\"\n#include \"xla/mlir/tools/mlir_interpreter/dialects/comparators.h\"\n#include \"xla/mlir/tools/mlir_interpreter/dialects/cwise_math.h\"\n#include \"xla/mlir/tools/mlir_interpreter/framework/interpreter.h\"\n#include \"xla/mlir/tools/mlir_interpreter/framework/interpreter_value.h\"\n#include \"xla/mlir/tools/mlir_interpreter/framework/interpreter_value_util.h\"\n#include \"xla/mlir/tools/mlir_interpreter/framework/registration.h\"\n#include \"xla/mlir/tools/mlir_interpreter/framework/tensor_or_memref.h\"\n\nnamespace mlir {\nnamespace interpreter {\nnamespace {\n\nInterpreterValue Bitcast(InterpreterState&, arith::BitcastOp op,\n                         const InterpreterValue& in) {\n  Type ty = op->getResultTypes()[0];\n  auto shaped_ty = dyn_cast<ShapedType>(ty);\n  auto result = DispatchScalarType(ty, [&](auto dummy) -> InterpreterValue {\n    TensorOrMemref<decltype(dummy)> result;\n    result.view = {};\n    if (shaped_ty) {\n      result.buffer = in.Clone().GetBuffer();\n    } else {\n      result.buffer = in.AsUnitTensor().GetBuffer();\n    }\n    return {result};\n  });\n  if (!shaped_ty) {\n    return result.ExtractElement({});\n  }\n  auto& out_view = result.View();\n  out_view.strides = BufferView::GetDefaultStrides(shaped_ty.getShape());\n  out_view.sizes = llvm::to_vector(shaped_ty.getShape());\n  return result;\n}\n\nInterpreterValue Constant(InterpreterState&, arith::ConstantOp constant) {\n  auto ty = constant->getResultTypes()[0];\n  auto shaped_ty = dyn_cast<ShapedType>(ty);\n  auto elem_ty = shaped_ty ? shaped_ty.getElementType() : ty;\n  return DispatchScalarType(elem_ty, [&](auto dummy) -> InterpreterValue {\n    using T = decltype(dummy);\n    if (shaped_ty) {\n      auto values = cast<DenseElementsAttr>(constant.getValue()).getValues<T>();\n      auto result = TensorOrMemref<T>::Empty(shaped_ty.getShape());\n      auto value_it = values.begin();\n      result.view.is_vector = isa<VectorType>(shaped_ty);\n      for (const auto& index : result.view.Indices(true)) {\n        result.at(index) = *value_it;\n        ++value_it;\n      }\n      return {result};\n    }\n\n    auto value = constant.getValue();\n    if (auto integer = value.dyn_cast<IntegerAttr>()) {\n      return {static_cast<T>(integer.getInt())};\n    }\n    if (auto float_value = value.dyn_cast<FloatAttr>()) {\n      return {static_cast<T>(float_value.getValueAsDouble())};\n    }\n\n    llvm_unreachable(\"unsupported constant type\");\n  });\n}\n\ntemplate <typename Op>\nInterpreterValue IntCast(InterpreterState&, Op op,\n                         const InterpreterValue& arg) {\n  if (arg.IsTensor()) {\n    return DispatchScalarType(\n        op->getResultTypes()[0], [&](auto dummy) -> InterpreterValue {\n          auto result = TensorOrMemref<decltype(dummy)>::EmptyLike(arg.View());\n          for (const auto& index : result.view.Indices()) {\n            result.at(index) =\n                static_cast<decltype(dummy)>(arg.ExtractElement(index).AsInt());\n          }\n          return {result};\n        });\n  }\n\n  return DispatchScalarType(\n      op->getResultTypes()[0], [&](auto dummy) -> InterpreterValue {\n        return {static_cast<decltype(dummy)>(arg.AsInt())};\n      });\n}\n\ntemplate <typename Op>\nInterpreterValue FloatCast(InterpreterState&, Op op,\n                           const InterpreterValue& arg) {\n  if (arg.IsTensor()) {\n    return DispatchScalarType(\n        op->getResultTypes()[0], [&](auto dummy) -> InterpreterValue {\n          auto result = TensorOrMemref<decltype(dummy)>::EmptyLike(arg.View());\n          for (const auto& index : result.view.Indices()) {\n            result.at(index) = static_cast<decltype(dummy)>(\n                arg.ExtractElement(index).AsDouble());\n          }\n          return {result};\n        });\n  }\n\n  return DispatchScalarType(\n      op->getResultTypes()[0], [&](auto dummy) -> InterpreterValue {\n        return {static_cast<decltype(dummy)>(arg.AsDouble())};\n      });\n}\n\nllvm::SmallVector<InterpreterValue> UiToFP(\n    MutableArrayRef<InterpreterValue> args, mlir::Operation* op,\n    InterpreterState&) {\n  if (args[0].IsTensor()) {\n    auto ty = op->getResultTypes()[0].cast<ShapedType>();\n    return {DispatchScalarType(\n        ty.getElementType(), [&](auto dummy) -> InterpreterValue {\n          auto result =\n              TensorOrMemref<decltype(dummy)>::EmptyLike(args[0].View());\n          for (const auto& index : result.view.Indices()) {\n            result.at(index) = static_cast<decltype(dummy)>(\n                args[0].ExtractElement(index).AsUInt());\n          }\n          return {result};\n        })};\n  }\n\n  return {DispatchScalarType(\n      op->getResultTypes()[0], [&](auto dummy) -> InterpreterValue {\n        return {static_cast<decltype(dummy)>(args[0].AsUInt())};\n      })};\n}\n\nInterpreterValue CmpI(InterpreterState&, arith::CmpIOp compare,\n                      const InterpreterValue& lhs,\n                      const InterpreterValue& rhs) {\n  switch (compare.getPredicate()) {\n    case arith::CmpIPredicate::eq:\n      return ApplyCwiseBinaryMap<Foeq>(lhs, rhs);\n    case arith::CmpIPredicate::ne:\n      return ApplyCwiseBinaryMap<Fone>(lhs, rhs);\n    case arith::CmpIPredicate::slt:\n      return ApplyCwiseBinaryMap<Folt>(lhs, rhs);\n    case arith::CmpIPredicate::sle:\n      return ApplyCwiseBinaryMap<Fole>(lhs, rhs);\n    case arith::CmpIPredicate::sgt:\n      return ApplyCwiseBinaryMap<Fogt>(lhs, rhs);\n    case arith::CmpIPredicate::sge:\n      return ApplyCwiseBinaryMap<Foge>(lhs, rhs);\n    case arith::CmpIPredicate::ult:\n      return ApplyCwiseBinaryMap<Iult>(lhs, rhs);\n    case arith::CmpIPredicate::ule:\n      return ApplyCwiseBinaryMap<Iule>(lhs, rhs);\n    case arith::CmpIPredicate::ugt:\n      return ApplyCwiseBinaryMap<Iugt>(lhs, rhs);\n    case arith::CmpIPredicate::uge:\n      return ApplyCwiseBinaryMap<Iuge>(lhs, rhs);\n  }\n}\n\ntemplate <bool value>\nstruct ConstFunctor : CwiseAll {\n  template <typename T>\n  static bool Apply(T, T) {\n    return value;\n  }\n};\n\nInterpreterValue CmpF(InterpreterState&, arith::CmpFOp compare,\n                      const InterpreterValue& lhs,\n                      const InterpreterValue& rhs) {\n  switch (compare.getPredicate()) {\n    case arith::CmpFPredicate::AlwaysFalse:\n      return ApplyCwiseBinaryMap<ConstFunctor<false>>(lhs, rhs);\n    case arith::CmpFPredicate::OEQ:\n      return ApplyCwiseBinaryMap<Foeq>(lhs, rhs);\n    case arith::CmpFPredicate::OGT:\n      return ApplyCwiseBinaryMap<Fogt>(lhs, rhs);\n    case arith::CmpFPredicate::OGE:\n      return ApplyCwiseBinaryMap<Foge>(lhs, rhs);\n    case arith::CmpFPredicate::OLT:\n      return ApplyCwiseBinaryMap<Folt>(lhs, rhs);\n    case arith::CmpFPredicate::OLE:\n      return ApplyCwiseBinaryMap<Fole>(lhs, rhs);\n    case arith::CmpFPredicate::ONE:\n      return ApplyCwiseBinaryMap<Fone>(lhs, rhs);\n    case arith::CmpFPredicate::ORD:\n      return ApplyCwiseBinaryMap<Ford>(lhs, rhs);\n    case arith::CmpFPredicate::UEQ:\n      return ApplyCwiseBinaryMap<Fueq>(lhs, rhs);\n    case arith::CmpFPredicate::UGT:\n      return ApplyCwiseBinaryMap<Fugt>(lhs, rhs);\n    case arith::CmpFPredicate::UGE:\n      return ApplyCwiseBinaryMap<Fuge>(lhs, rhs);\n    case arith::CmpFPredicate::ULT:\n      return ApplyCwiseBinaryMap<Fult>(lhs, rhs);\n    case arith::CmpFPredicate::ULE:\n      return ApplyCwiseBinaryMap<Fule>(lhs, rhs);\n    case arith::CmpFPredicate::UNE:\n      return ApplyCwiseBinaryMap<Fune>(lhs, rhs);\n    case arith::CmpFPredicate::UNO:\n      return ApplyCwiseBinaryMap<Funo>(lhs, rhs);\n    case arith::CmpFPredicate::AlwaysTrue:\n      return ApplyCwiseBinaryMap<ConstFunctor<true>>(lhs, rhs);\n  }\n}\n\nInterpreterValue Select(InterpreterState& state, arith::SelectOp,\n                        const InterpreterValue& cond,\n                        const InterpreterValue& true_value,\n                        const InterpreterValue& false_value) {\n  if (std::holds_alternative<bool>(cond.storage)) {\n    return std::get<bool>(cond.storage) ? true_value : false_value;\n  }\n\n  if (!cond.IsTensor() && !cond.View().is_vector) {\n    state.AddFailure(\"select requires a scalar or vector argument\");\n    return {};\n  }\n\n  auto ret = true_value.Clone();\n  for (const auto& index : cond.View().Indices(/*include_vector_dims=*/true)) {\n    if (cond.ExtractElement(index).AsInt() == 0) {\n      ret.InsertElement(index, false_value.ExtractElement(index));\n    }\n  }\n  return ret;\n}\n\ntemplate <typename R>\nstruct ExtFFunctor : CwiseFloat {\n  template <typename A>\n  static R Apply(A v) {\n    return v;\n  }\n};\n\nInterpreterValue ExtF(InterpreterState&, arith::ExtFOp op,\n                      const InterpreterValue& in) {\n  return DispatchScalarType(\n      op->getResultTypes()[0], [&](auto dummy) -> InterpreterValue {\n        return ApplyCwiseMap<ExtFFunctor<decltype(dummy)>>(in);\n      });\n}\n\nREGISTER_MLIR_INTERPRETER_OP(\"arith.addf\", ApplyCwiseBinaryMap<Plus>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.andi\", ApplyCwiseBinaryMap<BitAnd>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.divf\", ApplyCwiseBinaryMap<Divide>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.extui\", UiToFP);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.maxf\", ApplyCwiseBinaryMap<Max>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.minf\", ApplyCwiseBinaryMap<Min>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.mulf\", ApplyCwiseBinaryMap<Multiply>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.negf\", ApplyCwiseMap<Neg>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.ori\", ApplyCwiseBinaryMap<BitOr>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.remf\", ApplyCwiseBinaryMap<Remainder>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.subf\", ApplyCwiseBinaryMap<Minus>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.uitofp\", UiToFP);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.xori\", ApplyCwiseBinaryMap<BitXor>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.shrui\",\n                             ApplyCwiseBinaryMap<ShiftRightLogical>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.shrsi\",\n                             ApplyCwiseBinaryMap<ShiftRightArith>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.shli\", ApplyCwiseBinaryMap<ShiftLeft>);\n\n// The float implementations support ints too.\nREGISTER_MLIR_INTERPRETER_OP(\"arith.addi\", \"arith.addf\");\nREGISTER_MLIR_INTERPRETER_OP(\"arith.divsi\", \"arith.divf\");\nREGISTER_MLIR_INTERPRETER_OP(\"arith.maxsi\", \"arith.maxf\");\nREGISTER_MLIR_INTERPRETER_OP(\"arith.minsi\", \"arith.minf\");\nREGISTER_MLIR_INTERPRETER_OP(\"arith.muli\", \"arith.mulf\");\nREGISTER_MLIR_INTERPRETER_OP(\"arith.remsi\", \"arith.remf\");\nREGISTER_MLIR_INTERPRETER_OP(\"arith.subi\", \"arith.subf\");\n\nREGISTER_MLIR_INTERPRETER_OP(Bitcast);\nREGISTER_MLIR_INTERPRETER_OP(CmpF);\nREGISTER_MLIR_INTERPRETER_OP(CmpI);\nREGISTER_MLIR_INTERPRETER_OP(Constant);\nREGISTER_MLIR_INTERPRETER_OP(ExtF);\nREGISTER_MLIR_INTERPRETER_OP(FloatCast<arith::FPToSIOp>);\nREGISTER_MLIR_INTERPRETER_OP(IntCast<arith::ExtSIOp>);\nREGISTER_MLIR_INTERPRETER_OP(IntCast<arith::IndexCastOp>);\nREGISTER_MLIR_INTERPRETER_OP(IntCast<arith::SIToFPOp>);\nREGISTER_MLIR_INTERPRETER_OP(IntCast<arith::TruncIOp>);\nREGISTER_MLIR_INTERPRETER_OP(Select);\n\n}  // namespace\n}  // namespace interpreter\n}  // namespace mlir",
    "repo": "tensorflow/tensorflow",
    "path": "./datasets/diagrams-repos/tensorflow/tensorflow/third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/arith.cc",
    "query": "How are arithmetic operations registered in the interpreter?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'REGISTER_MLIR_INTERPRETER_OP', 'node_id': 'REGISTER_MLIR_INTERPRETER_OP', 'description': 'Macro for registering operations in the interpreter', 'visibility': 'public', 'return_type': None, 'params': 'const char* name, handler', 'source_class_id': None}, {'type': 'entity', 'name': 'ArithmeticOperations', 'node_id': 'ArithmeticOperations', 'description': 'Basic arithmetic operations (add, sub, mul, etc.)', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'ApplyCwiseBinaryMap', 'node_id': 'ApplyCwiseBinaryMap', 'description': 'Applies binary operation element-wise', 'visibility': 'public', 'return_type': None, 'params': 'template<typename Op>', 'source_class_id': None}], 'edges': [{'node_id_from': 'REGISTER_MLIR_INTERPRETER_OP', 'node_id_to': 'ArithmeticOperations', 'description': 'registers'}, {'node_id_from': 'ArithmeticOperations', 'node_id_to': 'ApplyCwiseBinaryMap', 'description': 'uses'}], 'packages': [{'package_id': 'arithmeticRegistration', 'children': ['REGISTER_MLIR_INTERPRETER_OP', 'ArithmeticOperations', 'ApplyCwiseBinaryMap'], 'description': 'Core arithmetic operation registration'}]}",
    "version": "minimal",
    "text_answer": "Arithmetic operations are registered using the REGISTER_MLIR_INTERPRETER_OP macro, which maps operation names to their implementations. Most operations use ApplyCwiseBinaryMap for element-wise execution, with float operations serving as base implementations for integer operations. Specialized handlers exist for comparisons and bit operations.",
    "possible_version": [
      "minimal"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include \"mlir/Dialect/Arith/IR/Arith.h\"\n\n#include <variant>  // NOLINT\n\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/Support/ErrorHandling.h\"\n#include \"mlir/IR/Builders.h\"\n#include \"mlir/IR/BuiltinAttributes.h\"\n#include \"mlir/IR/BuiltinTypeInterfaces.h\"\n#include \"mlir/IR/Types.h\"\n#include \"mlir/Support/LLVM.h\"\n#include \"xla/mlir/tools/mlir_interpreter/dialects/comparators.h\"\n#include \"xla/mlir/tools/mlir_interpreter/dialects/cwise_math.h\"\n#include \"xla/mlir/tools/mlir_interpreter/framework/interpreter.h\"\n#include \"xla/mlir/tools/mlir_interpreter/framework/interpreter_value.h\"\n#include \"xla/mlir/tools/mlir_interpreter/framework/interpreter_value_util.h\"\n#include \"xla/mlir/tools/mlir_interpreter/framework/registration.h\"\n#include \"xla/mlir/tools/mlir_interpreter/framework/tensor_or_memref.h\"\n\nnamespace mlir {\nnamespace interpreter {\nnamespace {\n\nInterpreterValue Bitcast(InterpreterState&, arith::BitcastOp op,\n                         const InterpreterValue& in) {\n  Type ty = op->getResultTypes()[0];\n  auto shaped_ty = dyn_cast<ShapedType>(ty);\n  auto result = DispatchScalarType(ty, [&](auto dummy) -> InterpreterValue {\n    TensorOrMemref<decltype(dummy)> result;\n    result.view = {};\n    if (shaped_ty) {\n      result.buffer = in.Clone().GetBuffer();\n    } else {\n      result.buffer = in.AsUnitTensor().GetBuffer();\n    }\n    return {result};\n  });\n  if (!shaped_ty) {\n    return result.ExtractElement({});\n  }\n  auto& out_view = result.View();\n  out_view.strides = BufferView::GetDefaultStrides(shaped_ty.getShape());\n  out_view.sizes = llvm::to_vector(shaped_ty.getShape());\n  return result;\n}\n\nInterpreterValue Constant(InterpreterState&, arith::ConstantOp constant) {\n  auto ty = constant->getResultTypes()[0];\n  auto shaped_ty = dyn_cast<ShapedType>(ty);\n  auto elem_ty = shaped_ty ? shaped_ty.getElementType() : ty;\n  return DispatchScalarType(elem_ty, [&](auto dummy) -> InterpreterValue {\n    using T = decltype(dummy);\n    if (shaped_ty) {\n      auto values = cast<DenseElementsAttr>(constant.getValue()).getValues<T>();\n      auto result = TensorOrMemref<T>::Empty(shaped_ty.getShape());\n      auto value_it = values.begin();\n      result.view.is_vector = isa<VectorType>(shaped_ty);\n      for (const auto& index : result.view.Indices(true)) {\n        result.at(index) = *value_it;\n        ++value_it;\n      }\n      return {result};\n    }\n\n    auto value = constant.getValue();\n    if (auto integer = value.dyn_cast<IntegerAttr>()) {\n      return {static_cast<T>(integer.getInt())};\n    }\n    if (auto float_value = value.dyn_cast<FloatAttr>()) {\n      return {static_cast<T>(float_value.getValueAsDouble())};\n    }\n\n    llvm_unreachable(\"unsupported constant type\");\n  });\n}\n\ntemplate <typename Op>\nInterpreterValue IntCast(InterpreterState&, Op op,\n                         const InterpreterValue& arg) {\n  if (arg.IsTensor()) {\n    return DispatchScalarType(\n        op->getResultTypes()[0], [&](auto dummy) -> InterpreterValue {\n          auto result = TensorOrMemref<decltype(dummy)>::EmptyLike(arg.View());\n          for (const auto& index : result.view.Indices()) {\n            result.at(index) =\n                static_cast<decltype(dummy)>(arg.ExtractElement(index).AsInt());\n          }\n          return {result};\n        });\n  }\n\n  return DispatchScalarType(\n      op->getResultTypes()[0], [&](auto dummy) -> InterpreterValue {\n        return {static_cast<decltype(dummy)>(arg.AsInt())};\n      });\n}\n\ntemplate <typename Op>\nInterpreterValue FloatCast(InterpreterState&, Op op,\n                           const InterpreterValue& arg) {\n  if (arg.IsTensor()) {\n    return DispatchScalarType(\n        op->getResultTypes()[0], [&](auto dummy) -> InterpreterValue {\n          auto result = TensorOrMemref<decltype(dummy)>::EmptyLike(arg.View());\n          for (const auto& index : result.view.Indices()) {\n            result.at(index) = static_cast<decltype(dummy)>(\n                arg.ExtractElement(index).AsDouble());\n          }\n          return {result};\n        });\n  }\n\n  return DispatchScalarType(\n      op->getResultTypes()[0], [&](auto dummy) -> InterpreterValue {\n        return {static_cast<decltype(dummy)>(arg.AsDouble())};\n      });\n}\n\nllvm::SmallVector<InterpreterValue> UiToFP(\n    MutableArrayRef<InterpreterValue> args, mlir::Operation* op,\n    InterpreterState&) {\n  if (args[0].IsTensor()) {\n    auto ty = op->getResultTypes()[0].cast<ShapedType>();\n    return {DispatchScalarType(\n        ty.getElementType(), [&](auto dummy) -> InterpreterValue {\n          auto result =\n              TensorOrMemref<decltype(dummy)>::EmptyLike(args[0].View());\n          for (const auto& index : result.view.Indices()) {\n            result.at(index) = static_cast<decltype(dummy)>(\n                args[0].ExtractElement(index).AsUInt());\n          }\n          return {result};\n        })};\n  }\n\n  return {DispatchScalarType(\n      op->getResultTypes()[0], [&](auto dummy) -> InterpreterValue {\n        return {static_cast<decltype(dummy)>(args[0].AsUInt())};\n      })};\n}\n\nInterpreterValue CmpI(InterpreterState&, arith::CmpIOp compare,\n                      const InterpreterValue& lhs,\n                      const InterpreterValue& rhs) {\n  switch (compare.getPredicate()) {\n    case arith::CmpIPredicate::eq:\n      return ApplyCwiseBinaryMap<Foeq>(lhs, rhs);\n    case arith::CmpIPredicate::ne:\n      return ApplyCwiseBinaryMap<Fone>(lhs, rhs);\n    case arith::CmpIPredicate::slt:\n      return ApplyCwiseBinaryMap<Folt>(lhs, rhs);\n    case arith::CmpIPredicate::sle:\n      return ApplyCwiseBinaryMap<Fole>(lhs, rhs);\n    case arith::CmpIPredicate::sgt:\n      return ApplyCwiseBinaryMap<Fogt>(lhs, rhs);\n    case arith::CmpIPredicate::sge:\n      return ApplyCwiseBinaryMap<Foge>(lhs, rhs);\n    case arith::CmpIPredicate::ult:\n      return ApplyCwiseBinaryMap<Iult>(lhs, rhs);\n    case arith::CmpIPredicate::ule:\n      return ApplyCwiseBinaryMap<Iule>(lhs, rhs);\n    case arith::CmpIPredicate::ugt:\n      return ApplyCwiseBinaryMap<Iugt>(lhs, rhs);\n    case arith::CmpIPredicate::uge:\n      return ApplyCwiseBinaryMap<Iuge>(lhs, rhs);\n  }\n}\n\ntemplate <bool value>\nstruct ConstFunctor : CwiseAll {\n  template <typename T>\n  static bool Apply(T, T) {\n    return value;\n  }\n};\n\nInterpreterValue CmpF(InterpreterState&, arith::CmpFOp compare,\n                      const InterpreterValue& lhs,\n                      const InterpreterValue& rhs) {\n  switch (compare.getPredicate()) {\n    case arith::CmpFPredicate::AlwaysFalse:\n      return ApplyCwiseBinaryMap<ConstFunctor<false>>(lhs, rhs);\n    case arith::CmpFPredicate::OEQ:\n      return ApplyCwiseBinaryMap<Foeq>(lhs, rhs);\n    case arith::CmpFPredicate::OGT:\n      return ApplyCwiseBinaryMap<Fogt>(lhs, rhs);\n    case arith::CmpFPredicate::OGE:\n      return ApplyCwiseBinaryMap<Foge>(lhs, rhs);\n    case arith::CmpFPredicate::OLT:\n      return ApplyCwiseBinaryMap<Folt>(lhs, rhs);\n    case arith::CmpFPredicate::OLE:\n      return ApplyCwiseBinaryMap<Fole>(lhs, rhs);\n    case arith::CmpFPredicate::ONE:\n      return ApplyCwiseBinaryMap<Fone>(lhs, rhs);\n    case arith::CmpFPredicate::ORD:\n      return ApplyCwiseBinaryMap<Ford>(lhs, rhs);\n    case arith::CmpFPredicate::UEQ:\n      return ApplyCwiseBinaryMap<Fueq>(lhs, rhs);\n    case arith::CmpFPredicate::UGT:\n      return ApplyCwiseBinaryMap<Fugt>(lhs, rhs);\n    case arith::CmpFPredicate::UGE:\n      return ApplyCwiseBinaryMap<Fuge>(lhs, rhs);\n    case arith::CmpFPredicate::ULT:\n      return ApplyCwiseBinaryMap<Fult>(lhs, rhs);\n    case arith::CmpFPredicate::ULE:\n      return ApplyCwiseBinaryMap<Fule>(lhs, rhs);\n    case arith::CmpFPredicate::UNE:\n      return ApplyCwiseBinaryMap<Fune>(lhs, rhs);\n    case arith::CmpFPredicate::UNO:\n      return ApplyCwiseBinaryMap<Funo>(lhs, rhs);\n    case arith::CmpFPredicate::AlwaysTrue:\n      return ApplyCwiseBinaryMap<ConstFunctor<true>>(lhs, rhs);\n  }\n}\n\nInterpreterValue Select(InterpreterState& state, arith::SelectOp,\n                        const InterpreterValue& cond,\n                        const InterpreterValue& true_value,\n                        const InterpreterValue& false_value) {\n  if (std::holds_alternative<bool>(cond.storage)) {\n    return std::get<bool>(cond.storage) ? true_value : false_value;\n  }\n\n  if (!cond.IsTensor() && !cond.View().is_vector) {\n    state.AddFailure(\"select requires a scalar or vector argument\");\n    return {};\n  }\n\n  auto ret = true_value.Clone();\n  for (const auto& index : cond.View().Indices(/*include_vector_dims=*/true)) {\n    if (cond.ExtractElement(index).AsInt() == 0) {\n      ret.InsertElement(index, false_value.ExtractElement(index));\n    }\n  }\n  return ret;\n}\n\ntemplate <typename R>\nstruct ExtFFunctor : CwiseFloat {\n  template <typename A>\n  static R Apply(A v) {\n    return v;\n  }\n};\n\nInterpreterValue ExtF(InterpreterState&, arith::ExtFOp op,\n                      const InterpreterValue& in) {\n  return DispatchScalarType(\n      op->getResultTypes()[0], [&](auto dummy) -> InterpreterValue {\n        return ApplyCwiseMap<ExtFFunctor<decltype(dummy)>>(in);\n      });\n}\n\nREGISTER_MLIR_INTERPRETER_OP(\"arith.addf\", ApplyCwiseBinaryMap<Plus>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.andi\", ApplyCwiseBinaryMap<BitAnd>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.divf\", ApplyCwiseBinaryMap<Divide>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.extui\", UiToFP);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.maxf\", ApplyCwiseBinaryMap<Max>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.minf\", ApplyCwiseBinaryMap<Min>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.mulf\", ApplyCwiseBinaryMap<Multiply>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.negf\", ApplyCwiseMap<Neg>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.ori\", ApplyCwiseBinaryMap<BitOr>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.remf\", ApplyCwiseBinaryMap<Remainder>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.subf\", ApplyCwiseBinaryMap<Minus>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.uitofp\", UiToFP);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.xori\", ApplyCwiseBinaryMap<BitXor>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.shrui\",\n                             ApplyCwiseBinaryMap<ShiftRightLogical>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.shrsi\",\n                             ApplyCwiseBinaryMap<ShiftRightArith>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.shli\", ApplyCwiseBinaryMap<ShiftLeft>);\n\n// The float implementations support ints too.\nREGISTER_MLIR_INTERPRETER_OP(\"arith.addi\", \"arith.addf\");\nREGISTER_MLIR_INTERPRETER_OP(\"arith.divsi\", \"arith.divf\");\nREGISTER_MLIR_INTERPRETER_OP(\"arith.maxsi\", \"arith.maxf\");\nREGISTER_MLIR_INTERPRETER_OP(\"arith.minsi\", \"arith.minf\");\nREGISTER_MLIR_INTERPRETER_OP(\"arith.muli\", \"arith.mulf\");\nREGISTER_MLIR_INTERPRETER_OP(\"arith.remsi\", \"arith.remf\");\nREGISTER_MLIR_INTERPRETER_OP(\"arith.subi\", \"arith.subf\");\n\nREGISTER_MLIR_INTERPRETER_OP(Bitcast);\nREGISTER_MLIR_INTERPRETER_OP(CmpF);\nREGISTER_MLIR_INTERPRETER_OP(CmpI);\nREGISTER_MLIR_INTERPRETER_OP(Constant);\nREGISTER_MLIR_INTERPRETER_OP(ExtF);\nREGISTER_MLIR_INTERPRETER_OP(FloatCast<arith::FPToSIOp>);\nREGISTER_MLIR_INTERPRETER_OP(IntCast<arith::ExtSIOp>);\nREGISTER_MLIR_INTERPRETER_OP(IntCast<arith::IndexCastOp>);\nREGISTER_MLIR_INTERPRETER_OP(IntCast<arith::SIToFPOp>);\nREGISTER_MLIR_INTERPRETER_OP(IntCast<arith::TruncIOp>);\nREGISTER_MLIR_INTERPRETER_OP(Select);\n\n}  // namespace\n}  // namespace interpreter\n}  // namespace mlir",
    "repo": "tensorflow/tensorflow",
    "path": "./datasets/diagrams-repos/tensorflow/tensorflow/third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/arith.cc",
    "query": "How are arithmetic operations registered in the interpreter?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'REGISTER_MLIR_INTERPRETER_OP', 'node_id': 'REGISTER_MLIR_INTERPRETER_OP', 'description': 'Macro for registering operations in the interpreter', 'visibility': 'public', 'return_type': None, 'params': 'const char* name, handler', 'source_class_id': None}, {'type': 'entity', 'name': 'FloatOperations', 'node_id': 'FloatOperations', 'description': 'Floating-point arithmetic operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'IntegerOperations', 'node_id': 'IntegerOperations', 'description': 'Integer arithmetic operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'ApplyCwiseBinaryMap', 'node_id': 'ApplyCwiseBinaryMap', 'description': 'Applies binary operation element-wise', 'visibility': 'public', 'return_type': None, 'params': 'template<typename Op>', 'source_class_id': None}, {'type': 'entity', 'name': 'CwiseOperators', 'node_id': 'CwiseOperators', 'description': 'Component-wise operation implementations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}], 'edges': [{'node_id_from': 'REGISTER_MLIR_INTERPRETER_OP', 'node_id_to': 'FloatOperations', 'description': 'registers'}, {'node_id_from': 'REGISTER_MLIR_INTERPRETER_OP', 'node_id_to': 'IntegerOperations', 'description': 'registers'}, {'node_id_from': 'FloatOperations', 'node_id_to': 'ApplyCwiseBinaryMap', 'description': 'uses'}, {'node_id_from': 'IntegerOperations', 'node_id_to': 'ApplyCwiseBinaryMap', 'description': 'uses'}, {'node_id_from': 'ApplyCwiseBinaryMap', 'node_id_to': 'CwiseOperators', 'description': 'implements'}], 'packages': [{'package_id': 'arithmeticRegistration', 'children': ['REGISTER_MLIR_INTERPRETER_OP', 'FloatOperations', 'IntegerOperations'], 'description': 'Arithmetic operation registration'}, {'package_id': 'implementation', 'children': ['ApplyCwiseBinaryMap', 'CwiseOperators'], 'description': 'Implementation details'}]}",
    "version": "medium",
    "text_answer": "Arithmetic operations are registered using the REGISTER_MLIR_INTERPRETER_OP macro, which maps operation names to their implementations. Most operations use ApplyCwiseBinaryMap for element-wise execution, with float operations serving as base implementations for integer operations. Specialized handlers exist for comparisons and bit operations.",
    "possible_version": [
      "medium"
    ]
  },
  {
    "language": "C++",
    "code": "\n#include \"mlir/Dialect/Arith/IR/Arith.h\"\n\n#include <variant>  // NOLINT\n\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/Support/ErrorHandling.h\"\n#include \"mlir/IR/Builders.h\"\n#include \"mlir/IR/BuiltinAttributes.h\"\n#include \"mlir/IR/BuiltinTypeInterfaces.h\"\n#include \"mlir/IR/Types.h\"\n#include \"mlir/Support/LLVM.h\"\n#include \"xla/mlir/tools/mlir_interpreter/dialects/comparators.h\"\n#include \"xla/mlir/tools/mlir_interpreter/dialects/cwise_math.h\"\n#include \"xla/mlir/tools/mlir_interpreter/framework/interpreter.h\"\n#include \"xla/mlir/tools/mlir_interpreter/framework/interpreter_value.h\"\n#include \"xla/mlir/tools/mlir_interpreter/framework/interpreter_value_util.h\"\n#include \"xla/mlir/tools/mlir_interpreter/framework/registration.h\"\n#include \"xla/mlir/tools/mlir_interpreter/framework/tensor_or_memref.h\"\n\nnamespace mlir {\nnamespace interpreter {\nnamespace {\n\nInterpreterValue Bitcast(InterpreterState&, arith::BitcastOp op,\n                         const InterpreterValue& in) {\n  Type ty = op->getResultTypes()[0];\n  auto shaped_ty = dyn_cast<ShapedType>(ty);\n  auto result = DispatchScalarType(ty, [&](auto dummy) -> InterpreterValue {\n    TensorOrMemref<decltype(dummy)> result;\n    result.view = {};\n    if (shaped_ty) {\n      result.buffer = in.Clone().GetBuffer();\n    } else {\n      result.buffer = in.AsUnitTensor().GetBuffer();\n    }\n    return {result};\n  });\n  if (!shaped_ty) {\n    return result.ExtractElement({});\n  }\n  auto& out_view = result.View();\n  out_view.strides = BufferView::GetDefaultStrides(shaped_ty.getShape());\n  out_view.sizes = llvm::to_vector(shaped_ty.getShape());\n  return result;\n}\n\nInterpreterValue Constant(InterpreterState&, arith::ConstantOp constant) {\n  auto ty = constant->getResultTypes()[0];\n  auto shaped_ty = dyn_cast<ShapedType>(ty);\n  auto elem_ty = shaped_ty ? shaped_ty.getElementType() : ty;\n  return DispatchScalarType(elem_ty, [&](auto dummy) -> InterpreterValue {\n    using T = decltype(dummy);\n    if (shaped_ty) {\n      auto values = cast<DenseElementsAttr>(constant.getValue()).getValues<T>();\n      auto result = TensorOrMemref<T>::Empty(shaped_ty.getShape());\n      auto value_it = values.begin();\n      result.view.is_vector = isa<VectorType>(shaped_ty);\n      for (const auto& index : result.view.Indices(true)) {\n        result.at(index) = *value_it;\n        ++value_it;\n      }\n      return {result};\n    }\n\n    auto value = constant.getValue();\n    if (auto integer = value.dyn_cast<IntegerAttr>()) {\n      return {static_cast<T>(integer.getInt())};\n    }\n    if (auto float_value = value.dyn_cast<FloatAttr>()) {\n      return {static_cast<T>(float_value.getValueAsDouble())};\n    }\n\n    llvm_unreachable(\"unsupported constant type\");\n  });\n}\n\ntemplate <typename Op>\nInterpreterValue IntCast(InterpreterState&, Op op,\n                         const InterpreterValue& arg) {\n  if (arg.IsTensor()) {\n    return DispatchScalarType(\n        op->getResultTypes()[0], [&](auto dummy) -> InterpreterValue {\n          auto result = TensorOrMemref<decltype(dummy)>::EmptyLike(arg.View());\n          for (const auto& index : result.view.Indices()) {\n            result.at(index) =\n                static_cast<decltype(dummy)>(arg.ExtractElement(index).AsInt());\n          }\n          return {result};\n        });\n  }\n\n  return DispatchScalarType(\n      op->getResultTypes()[0], [&](auto dummy) -> InterpreterValue {\n        return {static_cast<decltype(dummy)>(arg.AsInt())};\n      });\n}\n\ntemplate <typename Op>\nInterpreterValue FloatCast(InterpreterState&, Op op,\n                           const InterpreterValue& arg) {\n  if (arg.IsTensor()) {\n    return DispatchScalarType(\n        op->getResultTypes()[0], [&](auto dummy) -> InterpreterValue {\n          auto result = TensorOrMemref<decltype(dummy)>::EmptyLike(arg.View());\n          for (const auto& index : result.view.Indices()) {\n            result.at(index) = static_cast<decltype(dummy)>(\n                arg.ExtractElement(index).AsDouble());\n          }\n          return {result};\n        });\n  }\n\n  return DispatchScalarType(\n      op->getResultTypes()[0], [&](auto dummy) -> InterpreterValue {\n        return {static_cast<decltype(dummy)>(arg.AsDouble())};\n      });\n}\n\nllvm::SmallVector<InterpreterValue> UiToFP(\n    MutableArrayRef<InterpreterValue> args, mlir::Operation* op,\n    InterpreterState&) {\n  if (args[0].IsTensor()) {\n    auto ty = op->getResultTypes()[0].cast<ShapedType>();\n    return {DispatchScalarType(\n        ty.getElementType(), [&](auto dummy) -> InterpreterValue {\n          auto result =\n              TensorOrMemref<decltype(dummy)>::EmptyLike(args[0].View());\n          for (const auto& index : result.view.Indices()) {\n            result.at(index) = static_cast<decltype(dummy)>(\n                args[0].ExtractElement(index).AsUInt());\n          }\n          return {result};\n        })};\n  }\n\n  return {DispatchScalarType(\n      op->getResultTypes()[0], [&](auto dummy) -> InterpreterValue {\n        return {static_cast<decltype(dummy)>(args[0].AsUInt())};\n      })};\n}\n\nInterpreterValue CmpI(InterpreterState&, arith::CmpIOp compare,\n                      const InterpreterValue& lhs,\n                      const InterpreterValue& rhs) {\n  switch (compare.getPredicate()) {\n    case arith::CmpIPredicate::eq:\n      return ApplyCwiseBinaryMap<Foeq>(lhs, rhs);\n    case arith::CmpIPredicate::ne:\n      return ApplyCwiseBinaryMap<Fone>(lhs, rhs);\n    case arith::CmpIPredicate::slt:\n      return ApplyCwiseBinaryMap<Folt>(lhs, rhs);\n    case arith::CmpIPredicate::sle:\n      return ApplyCwiseBinaryMap<Fole>(lhs, rhs);\n    case arith::CmpIPredicate::sgt:\n      return ApplyCwiseBinaryMap<Fogt>(lhs, rhs);\n    case arith::CmpIPredicate::sge:\n      return ApplyCwiseBinaryMap<Foge>(lhs, rhs);\n    case arith::CmpIPredicate::ult:\n      return ApplyCwiseBinaryMap<Iult>(lhs, rhs);\n    case arith::CmpIPredicate::ule:\n      return ApplyCwiseBinaryMap<Iule>(lhs, rhs);\n    case arith::CmpIPredicate::ugt:\n      return ApplyCwiseBinaryMap<Iugt>(lhs, rhs);\n    case arith::CmpIPredicate::uge:\n      return ApplyCwiseBinaryMap<Iuge>(lhs, rhs);\n  }\n}\n\ntemplate <bool value>\nstruct ConstFunctor : CwiseAll {\n  template <typename T>\n  static bool Apply(T, T) {\n    return value;\n  }\n};\n\nInterpreterValue CmpF(InterpreterState&, arith::CmpFOp compare,\n                      const InterpreterValue& lhs,\n                      const InterpreterValue& rhs) {\n  switch (compare.getPredicate()) {\n    case arith::CmpFPredicate::AlwaysFalse:\n      return ApplyCwiseBinaryMap<ConstFunctor<false>>(lhs, rhs);\n    case arith::CmpFPredicate::OEQ:\n      return ApplyCwiseBinaryMap<Foeq>(lhs, rhs);\n    case arith::CmpFPredicate::OGT:\n      return ApplyCwiseBinaryMap<Fogt>(lhs, rhs);\n    case arith::CmpFPredicate::OGE:\n      return ApplyCwiseBinaryMap<Foge>(lhs, rhs);\n    case arith::CmpFPredicate::OLT:\n      return ApplyCwiseBinaryMap<Folt>(lhs, rhs);\n    case arith::CmpFPredicate::OLE:\n      return ApplyCwiseBinaryMap<Fole>(lhs, rhs);\n    case arith::CmpFPredicate::ONE:\n      return ApplyCwiseBinaryMap<Fone>(lhs, rhs);\n    case arith::CmpFPredicate::ORD:\n      return ApplyCwiseBinaryMap<Ford>(lhs, rhs);\n    case arith::CmpFPredicate::UEQ:\n      return ApplyCwiseBinaryMap<Fueq>(lhs, rhs);\n    case arith::CmpFPredicate::UGT:\n      return ApplyCwiseBinaryMap<Fugt>(lhs, rhs);\n    case arith::CmpFPredicate::UGE:\n      return ApplyCwiseBinaryMap<Fuge>(lhs, rhs);\n    case arith::CmpFPredicate::ULT:\n      return ApplyCwiseBinaryMap<Fult>(lhs, rhs);\n    case arith::CmpFPredicate::ULE:\n      return ApplyCwiseBinaryMap<Fule>(lhs, rhs);\n    case arith::CmpFPredicate::UNE:\n      return ApplyCwiseBinaryMap<Fune>(lhs, rhs);\n    case arith::CmpFPredicate::UNO:\n      return ApplyCwiseBinaryMap<Funo>(lhs, rhs);\n    case arith::CmpFPredicate::AlwaysTrue:\n      return ApplyCwiseBinaryMap<ConstFunctor<true>>(lhs, rhs);\n  }\n}\n\nInterpreterValue Select(InterpreterState& state, arith::SelectOp,\n                        const InterpreterValue& cond,\n                        const InterpreterValue& true_value,\n                        const InterpreterValue& false_value) {\n  if (std::holds_alternative<bool>(cond.storage)) {\n    return std::get<bool>(cond.storage) ? true_value : false_value;\n  }\n\n  if (!cond.IsTensor() && !cond.View().is_vector) {\n    state.AddFailure(\"select requires a scalar or vector argument\");\n    return {};\n  }\n\n  auto ret = true_value.Clone();\n  for (const auto& index : cond.View().Indices(/*include_vector_dims=*/true)) {\n    if (cond.ExtractElement(index).AsInt() == 0) {\n      ret.InsertElement(index, false_value.ExtractElement(index));\n    }\n  }\n  return ret;\n}\n\ntemplate <typename R>\nstruct ExtFFunctor : CwiseFloat {\n  template <typename A>\n  static R Apply(A v) {\n    return v;\n  }\n};\n\nInterpreterValue ExtF(InterpreterState&, arith::ExtFOp op,\n                      const InterpreterValue& in) {\n  return DispatchScalarType(\n      op->getResultTypes()[0], [&](auto dummy) -> InterpreterValue {\n        return ApplyCwiseMap<ExtFFunctor<decltype(dummy)>>(in);\n      });\n}\n\nREGISTER_MLIR_INTERPRETER_OP(\"arith.addf\", ApplyCwiseBinaryMap<Plus>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.andi\", ApplyCwiseBinaryMap<BitAnd>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.divf\", ApplyCwiseBinaryMap<Divide>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.extui\", UiToFP);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.maxf\", ApplyCwiseBinaryMap<Max>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.minf\", ApplyCwiseBinaryMap<Min>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.mulf\", ApplyCwiseBinaryMap<Multiply>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.negf\", ApplyCwiseMap<Neg>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.ori\", ApplyCwiseBinaryMap<BitOr>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.remf\", ApplyCwiseBinaryMap<Remainder>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.subf\", ApplyCwiseBinaryMap<Minus>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.uitofp\", UiToFP);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.xori\", ApplyCwiseBinaryMap<BitXor>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.shrui\",\n                             ApplyCwiseBinaryMap<ShiftRightLogical>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.shrsi\",\n                             ApplyCwiseBinaryMap<ShiftRightArith>);\nREGISTER_MLIR_INTERPRETER_OP(\"arith.shli\", ApplyCwiseBinaryMap<ShiftLeft>);\n\n// The float implementations support ints too.\nREGISTER_MLIR_INTERPRETER_OP(\"arith.addi\", \"arith.addf\");\nREGISTER_MLIR_INTERPRETER_OP(\"arith.divsi\", \"arith.divf\");\nREGISTER_MLIR_INTERPRETER_OP(\"arith.maxsi\", \"arith.maxf\");\nREGISTER_MLIR_INTERPRETER_OP(\"arith.minsi\", \"arith.minf\");\nREGISTER_MLIR_INTERPRETER_OP(\"arith.muli\", \"arith.mulf\");\nREGISTER_MLIR_INTERPRETER_OP(\"arith.remsi\", \"arith.remf\");\nREGISTER_MLIR_INTERPRETER_OP(\"arith.subi\", \"arith.subf\");\n\nREGISTER_MLIR_INTERPRETER_OP(Bitcast);\nREGISTER_MLIR_INTERPRETER_OP(CmpF);\nREGISTER_MLIR_INTERPRETER_OP(CmpI);\nREGISTER_MLIR_INTERPRETER_OP(Constant);\nREGISTER_MLIR_INTERPRETER_OP(ExtF);\nREGISTER_MLIR_INTERPRETER_OP(FloatCast<arith::FPToSIOp>);\nREGISTER_MLIR_INTERPRETER_OP(IntCast<arith::ExtSIOp>);\nREGISTER_MLIR_INTERPRETER_OP(IntCast<arith::IndexCastOp>);\nREGISTER_MLIR_INTERPRETER_OP(IntCast<arith::SIToFPOp>);\nREGISTER_MLIR_INTERPRETER_OP(IntCast<arith::TruncIOp>);\nREGISTER_MLIR_INTERPRETER_OP(Select);\n\n}  // namespace\n}  // namespace interpreter\n}  // namespace mlir",
    "repo": "tensorflow/tensorflow",
    "path": "./datasets/diagrams-repos/tensorflow/tensorflow/third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/arith.cc",
    "query": "How are arithmetic operations registered in the interpreter?",
    "diagram": "{'nodes': [{'type': 'function', 'name': 'REGISTER_MLIR_INTERPRETER_OP', 'node_id': 'REGISTER_MLIR_INTERPRETER_OP', 'description': 'Macro for registering operations in the interpreter', 'visibility': 'public', 'return_type': None, 'params': 'const char* name, handler', 'source_class_id': None}, {'type': 'entity', 'name': 'FloatOperations', 'node_id': 'FloatOperations', 'description': 'Floating-point arithmetic operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'IntegerOperations', 'node_id': 'IntegerOperations', 'description': 'Integer arithmetic operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'ComparisonOperations', 'node_id': 'ComparisonOperations', 'description': 'Comparison operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'entity', 'name': 'BitOperations', 'node_id': 'BitOperations', 'description': 'Bit manipulation operations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'ApplyCwiseBinaryMap', 'node_id': 'ApplyCwiseBinaryMap', 'description': 'Applies binary operation element-wise', 'visibility': 'public', 'return_type': None, 'params': 'template<typename Op>', 'source_class_id': None}, {'type': 'function', 'name': 'ApplyCwiseMap', 'node_id': 'ApplyCwiseMap', 'description': 'Applies unary operation element-wise', 'visibility': 'public', 'return_type': None, 'params': 'template<typename Op>', 'source_class_id': None}, {'type': 'entity', 'name': 'CwiseOperators', 'node_id': 'CwiseOperators', 'description': 'Component-wise operation implementations', 'visibility': 'public', 'return_type': None, 'params': None, 'source_class_id': None}, {'type': 'function', 'name': 'CmpF', 'node_id': 'CmpF', 'description': 'Float comparison implementation', 'visibility': 'public', 'return_type': None, 'params': 'InterpreterState&, arith::CmpFOp, const InterpreterValue&, const InterpreterValue&', 'source_class_id': None}, {'type': 'function', 'name': 'CmpI', 'node_id': 'CmpI', 'description': 'Integer comparison implementation', 'visibility': 'public', 'return_type': None, 'params': 'InterpreterState&, arith::CmpIOp, const InterpreterValue&, const InterpreterValue&', 'source_class_id': None}], 'edges': [{'node_id_from': 'REGISTER_MLIR_INTERPRETER_OP', 'node_id_to': 'FloatOperations', 'description': 'registers'}, {'node_id_from': 'REGISTER_MLIR_INTERPRETER_OP', 'node_id_to': 'IntegerOperations', 'description': 'registers'}, {'node_id_from': 'REGISTER_MLIR_INTERPRETER_OP', 'node_id_to': 'ComparisonOperations', 'description': 'registers'}, {'node_id_from': 'REGISTER_MLIR_INTERPRETER_OP', 'node_id_to': 'BitOperations', 'description': 'registers'}, {'node_id_from': 'FloatOperations', 'node_id_to': 'ApplyCwiseBinaryMap', 'description': 'uses'}, {'node_id_from': 'IntegerOperations', 'node_id_to': 'ApplyCwiseBinaryMap', 'description': 'uses'}, {'node_id_from': 'ComparisonOperations', 'node_id_to': 'CmpF', 'description': 'implements'}, {'node_id_from': 'ComparisonOperations', 'node_id_to': 'CmpI', 'description': 'implements'}, {'node_id_from': 'BitOperations', 'node_id_to': 'ApplyCwiseBinaryMap', 'description': 'uses'}, {'node_id_from': 'ApplyCwiseBinaryMap', 'node_id_to': 'CwiseOperators', 'description': 'implements'}, {'node_id_from': 'ApplyCwiseMap', 'node_id_to': 'CwiseOperators', 'description': 'implements'}], 'packages': [{'package_id': 'arithmeticRegistration', 'children': ['REGISTER_MLIR_INTERPRETER_OP', 'FloatOperations', 'IntegerOperations', 'ComparisonOperations', 'BitOperations'], 'description': 'Arithmetic operation registration'}, {'package_id': 'implementation', 'children': ['ApplyCwiseBinaryMap', 'ApplyCwiseMap', 'CwiseOperators', 'CmpF', 'CmpI'], 'description': 'Implementation details'}]}",
    "version": "full",
    "text_answer": "Arithmetic operations are registered using the REGISTER_MLIR_INTERPRETER_OP macro, which maps operation names to their implementations. Most operations use ApplyCwiseBinaryMap for element-wise execution, with float operations serving as base implementations for integer operations. Specialized handlers exist for comparisons and bit operations.",
    "possible_version": [
      "full"
    ]
  }
]